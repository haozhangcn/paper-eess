# ArXiv eess --Thu, 30 Jun 2022
### 1.Correctly Modeling TX and RX Chain in (Distributed) Massive MIMO -- New Fundamental Insights on Coherency  [ :arrow_down: ](https://arxiv.org/pdf/2206.14752.pdf)
>  This paper shows that the TX and RX models commonly used in literature for downlink (distributed) massive MIMO are inaccurate, leading also to inaccurate conclusions. In particular, the Local Oscillator (LO) effect should be modeled as $+\phi$ in the transmitter chain and $-\phi$ in the receiver chain, i.e., different signs. A common misconception in literature is to use the same sign for both chains. By correctly modeling TX and RX chain, one realizes that the LO phases are included in the reciprocity calibration and whenever the LO phases drift apart, a new reciprocity calibration becomes necessary (the same applies to time drifts). Thus, free-running LOs and the commonly made assumption of perfect reciprocity calibration (to enable blind DL channel estimation) are both not that useful, as they would require too much calibration overhead. Instead, the LOs at the base stations should be locked and relative reciprocity calibration in combination with downlink demodulation reference symbols should be employed.      
### 2.Nextformer: A ConvNeXt Augmented Conformer For End-To-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.14747.pdf)
>  Conformer models have achieved state-of-the-art(SOTA) results in end-to-end speech recognition. However Conformer mainly focuses on temporal modeling while pays less attention on time-frequency property of speech feature. In this paper we augment Conformer with ConvNeXt and propose Nextformer structure. We use stacks of ConvNeXt block to replace the commonly used subsampling module in Conformer for utilizing the information contained in time-frequency speech feature. Besides, we insert an additional downsampling module in middle of Conformer layers to make our model more efficient and accurate. We conduct experiments on two opening datasets, AISHELL-1 and WenetSpeech. On AISHELL-1, compared to Conformer baselines, Nextformer obtains 7.3% and 6.3% relative CER reduction in non-streaming and streaming mode respectively, and on a much larger WenetSpeech dataset, Nextformer gives 5.0%~6.5% and 7.5%~14.6% relative CER reduction in non-streaming and streaming mode, while keep the computational cost FLOPs comparable to Conformer. To the best of our knowledge, the proposed Nextformer model achieves SOTA results on AISHELL-1(CER 4.06%) and WenetSpeech(CER 7.56%/11.29%).      
### 3.Placenta Segmentation in Ultrasound Imaging: Addressing Sources of Uncertainty and Limited Field-of-View  [ :arrow_down: ](https://arxiv.org/pdf/2206.14746.pdf)
>  Automatic segmentation of the placenta in fetal ultrasound (US) is challenging due to the (i) high diversity of placenta appearance, (ii) the restricted quality in US resulting in highly variable reference annotations, and (iii) the limited field-of-view of US prohibiting whole placenta assessment at late gestation. In this work, we address these three challenges with a multi-task learning approach that combines the classification of placental location (e.g., anterior, posterior) and semantic placenta segmentation in a single convolutional neural network. Through the classification task the model can learn from larger and more diverse datasets while improving the accuracy of the segmentation task in particular in limited training set conditions. With this approach we investigate the variability in annotations from multiple raters and show that our automatic segmentations (Dice of 0.86 for anterior and 0.83 for posterior placentas) achieve human-level performance as compared to intra- and inter-observer variability. Lastly, our approach can deliver whole placenta segmentation using a multi-view US acquisition pipeline consisting of three stages: multi-probe image acquisition, image fusion and image segmentation. This results in high quality segmentation of larger structures such as the placenta in US with reduced image artifacts which are beyond the field-of-view of single probes.      
### 4.Generative Adversarial Networks for Pseudo-Radio-Signal Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2206.14742.pdf)
>  For many wireless communication applications, traffic pattern modeling of radio signals combined with channel effects is much needed. While analytical models are used to capture these phenomena, real world non-linear effects (e.g. device responses, interferences, distortions, noise) and especially the combination of such effects can be difficult to capture by these models. This is simply due to their complexity and degrees of freedom which can be hard to explicitize in compact expressions. In this paper, we propose a more model-free approach to jointly approximate an end-to-end black-boxed wireless communication scenario using software-defined radio platforms and optimize for an efficient synthesis of subsequently similar 'pseudo-radio-signals'. More precisely, we implement a generative adversarial network based solution that automatically learns radio properties from recorded prototypes in specific scenarios. This allows for a high degree of expressive freedom. Numerical results show that the prototypes' traffic patterns jointly with channel effects are learned without the introduction of assumptions about the scenario or the simplification to a parametric model.      
### 5.CONVIQT: Contrastive Video Quality Estimator  [ :arrow_down: ](https://arxiv.org/pdf/2206.14713.pdf)
>  Perceptual video quality assessment (VQA) is an integral component of many streaming and video sharing platforms. Here we consider the problem of learning perceptually relevant video quality representations in a self-supervised manner. Distortion type identification and degradation level determination is employed as an auxiliary task to train a deep learning model containing a deep Convolutional Neural Network (CNN) that extracts spatial features, as well as a recurrent unit that captures temporal information. The model is trained using a contrastive loss and we therefore refer to this training framework and resulting model as CONtrastive VIdeo Quality EstimaTor (CONVIQT). During testing, the weights of the trained model are frozen, and a linear regressor maps the learned features to quality scores in a no-reference (NR) setting. We conduct comprehensive evaluations of the proposed model on multiple VQA databases by analyzing the correlations between model predictions and ground-truth quality ratings, and achieve competitive performance when compared to state-of-the-art NR-VQA models, even though it is not trained on those databases. Our ablation experiments demonstrate that the learned representations are highly robust and generalize well across synthetic and realistic distortions. Our results indicate that compelling representations with perceptual bearing can be obtained using self-supervised learning. The implementations used in this work have been made available at <a class="link-external link-https" href="https://github.com/pavancm/CONVIQT" rel="external noopener nofollow">this https URL</a>.      
### 6.Decomposition of Industrial Systems for Energy Efficiency Optimization with OptTopo  [ :arrow_down: ](https://arxiv.org/pdf/2206.14700.pdf)
>  The operation of industrial facilities is a broad field for optimization. Industrial plants are often a) composed of several components, b) linked using network technology, c) physically interconnected and d) complex regarding the effect of set-points and operating points in every entity. This leads to the possibility of overall optimization but also to a high complexity of the emerging optimization problems. The decomposition of complex systems allows the modeling of individual models which can be structured according to the physical topology. A method for energy performance indicators (EnPI) helps to formulate an optimization problem. The optimization algorithm OptTopo achieves efficient set-points by traversing a graph representation of the overall system.      
### 7.BiometryNet: Landmark-based Fetal Biometry Estimation from Standard Ultrasound Planes  [ :arrow_down: ](https://arxiv.org/pdf/2206.14678.pdf)
>  Fetal growth assessment from ultrasound is based on a few biometric measurements that are performed manually and assessed relative to the expected gestational age. Reliable biometry estimation depends on the precise detection of landmarks in standard ultrasound planes. Manual annotation can be time-consuming and operator dependent task, and may results in high measurements variability. Existing methods for automatic fetal biometry rely on initial automatic fetal structure segmentation followed by geometric landmark detection. However, segmentation annotations are time-consuming and may be inaccurate, and landmark detection requires developing measurement-specific geometric methods. This paper describes BiometryNet, an end-to-end landmark regression framework for fetal biometry estimation that overcomes these limitations. It includes a novel Dynamic Orientation Determination (DOD) method for enforcing measurement-specific orientation consistency during network training. DOD reduces variabilities in network training, increases landmark localization accuracy, thus yields accurate and robust biometric measurements. To validate our method, we assembled a dataset of 3,398 ultrasound images from 1,829 subjects acquired in three clinical sites with seven different ultrasound devices. Comparison and cross-validation of three different biometric measurements on two independent datasets shows that BiometryNet is robust and yields accurate measurements whose errors are lower than the clinically permissible errors, outperforming other existing automated biometry estimation methods. Code is available at <a class="link-external link-https" href="https://github.com/netanellavisdris/fetalbiometry" rel="external noopener nofollow">this https URL</a>.      
### 8.Robust Unlimited Sampling Beyond Modulo  [ :arrow_down: ](https://arxiv.org/pdf/2206.14656.pdf)
>  Analog to digital converters (ADCs) act as a bridge between the analog and digital domains. Two important attributes of any ADC are sampling rate and its dynamic range. For bandlimited signals, the sampling should be above the Nyquist rate. It is also desired that the signals' dynamic range should be within that of the ADC's; otherwise, the signal will be clipped. Nonlinear operators such as modulo or companding can be used prior to sampling to avoid clipping. To recover the true signal from the samples of the nonlinear operator, either high sampling rates are required or strict constraints on the nonlinear operations are imposed, both of which are not desirable in practice. In this paper, we propose a generalized flexible nonlinear operator which is sampling efficient. Moreover, by carefully choosing its parameters, clipping, modulo, and companding can be seen as special cases of it. We show that bandlimited signals are uniquely identified from the nonlinear samples of the proposed operator when sampled above the Nyquist rate. Furthermore, we propose a robust algorithm to recover the true signal from the nonlinear samples. We show that our algorithm has the lowest mean-squared error while recovering the signal for a given sampling rate, noise level, and dynamic range of the compared to existing algorithms. Our results lead to less constrained hardware design to address the dynamic range issues while operating at the lowest rate possible.      
### 9.Simple and Effective Multi-sentence TTS with Expressive and Coherent Prosody  [ :arrow_down: ](https://arxiv.org/pdf/2206.14643.pdf)
>  Generating expressive and contextually appropriate prosody remains a challenge for modern text-to-speech (TTS) systems. This is particularly evident for long, multi-sentence inputs. In this paper, we examine simple extensions to a Transformer-based FastSpeech-like system, with the goal of improving prosody for multi-sentence TTS. We find that long context, powerful text features, and training on multi-speaker data all improve prosody. More interestingly, they result in synergies. Long context disambiguates prosody, improves coherence, and plays to the strengths of Transformers. Fine-tuning word-level features from a powerful language model, such as BERT, appears to profit from more training data, readily available in a multi-speaker setting. We look into objective metrics on pausing and pacing and perform thorough subjective evaluations for speech naturalness. Our main system, which incorporates all the extensions, achieves consistently strong results, including statistically significant improvements in speech naturalness over all its competitors.      
### 10.DDKtor: Automatic Diadochokinetic Speech Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.14639.pdf)
>  Diadochokinetic speech tasks (DDK), in which participants repeatedly produce syllables, are commonly used as part of the assessment of speech motor impairments. These studies rely on manual analyses that are time-intensive, subjective, and provide only a coarse-grained picture of speech. This paper presents two deep neural network models that automatically segment consonants and vowels from unannotated, untranscribed speech. Both models work on the raw waveform and use convolutional layers for feature extraction. The first model is based on an LSTM classifier followed by fully connected layers, while the second model adds more convolutional layers followed by fully connected layers. These segmentations predicted by the models are used to obtain measures of speech rate and sound duration. Results on a young healthy individuals dataset show that our LSTM model outperforms the current state-of-the-art systems and performs comparably to trained human annotators. Moreover, the LSTM model also presents comparable results to trained human annotators when evaluated on unseen older individuals with Parkinson's Disease dataset.      
### 11.Prespecified-time observer-based distributed control of battery energy storage systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14635.pdf)
>  This paper studies the state-of-charge (SoC) balancing and the total charging/discharging power tracking issues for battery energy storage systems (BESSs) with multiple distributed heterogeneous battery units. Different from the traditional cooperative control strategies based on the asymptotical or finite-time distributed observers, two distributed prespecified-time observers are proposed to estimate average battery units state and average desired power, respectively, which can be determined in advance and independent of initial states or control parameters. Finally, two simulation examples are given to verify the effectiveness and superiority of the proposed control strategy.      
### 12.Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14623.pdf)
>  End-2-end (E2E) models have become increasingly popular in some ASR tasks because of their performance and advantages. These E2E models directly approximate the posterior distribution of tokens given the acoustic inputs. Consequently, the E2E systems implicitly define a language model (LM) over the output tokens, which makes the exploitation of independently trained language models less straightforward than in conventional ASR systems. This makes it difficult to dynamically adapt E2E ASR system to contextual profiles for better recognizing special words such as named entities. In this work, we propose a contextual density ratio approach for both training a contextual aware E2E model and adapting the language model to named entities. We apply the aforementioned technique to an E2E ASR system, which transcribes doctor and patient conversations, for better adapting the E2E system to the names in the conversations. Our proposed technique achieves a relative improvement of up to 46.5% on the names over an E2E baseline without degrading the overall recognition accuracy of the whole test set. Moreover, it also surpasses a contextual shallow fusion baseline by 22.1 % relative.      
### 13.On the Prediction Network Architecture in RNN-T for ASR  [ :arrow_down: ](https://arxiv.org/pdf/2206.14618.pdf)
>  RNN-T models have gained popularity in the literature and in commercial systems because of their competitiveness and capability of operating in online streaming mode. In this work, we conduct an extensive study comparing several prediction network architectures for both monotonic and original RNN-T models. We compare 4 types of prediction networks based on a common state-of-the-art Conformer encoder and report results obtained on Librispeech and an internal medical conversation data set. Our study covers both offline batch-mode and online streaming scenarios. In contrast to some previous works, our results show that Transformer does not always outperform LSTM when used as prediction network along with Conformer encoder. Inspired by our scoreboard, we propose a new simple prediction network architecture, N-Concat, that outperforms the others in our on-line streaming benchmark. Transformer and n-gram reduced architectures perform very similarly yet with some important distinct behaviour in terms of previous context. Overall we obtained up to 4.1 % relative WER improvement compared to our LSTM baseline, while reducing prediction network parameters by nearly an order of magnitude (8.4 times).      
### 14.Observer-Based Coordinated Tracking Control for Nonlinear Multi-Agent Systems with Intermittent Communication under Heterogeneous Coupling Framework  [ :arrow_down: ](https://arxiv.org/pdf/2206.14562.pdf)
>  In this article, the observer-based coordinated tracking control problem for a class of nonlinear multi-agent systems(MASs) with intermittent communication and information constraints is studied under dynamic switching topology. First, a state observer is designed to estimate the unmeasurable actual state information in the system. Second, adjustable heterogeneous coupling weighting parameters are introduced in the dynamic switching topology, and the distributed coordinated tracking control protocol under heterogeneous coupling framework is proposed. Then, a new Lemma is constructed to realize the cooperative design of observer gain, state feedback gain and heterogeneous coupling gain matrices. Furthermore, the stability of the system is further proved, and the range of communication rate is obtained. On this basis, the intermittent communication mode is extended to three time interval cases, namely normal communication, leader-follower communication interruption and all agents communication interruption, and then the distributed coordinated tracking control method is improved to solve this problem. Finally, simulation experiments are conducted with nonlinear MASs to verify the correctness of methods.      
### 15.Power-efficient Joint Link Selection and Multi-hop Routing for Throughput Maximization in UAV Assisted FANETs  [ :arrow_down: ](https://arxiv.org/pdf/2206.14535.pdf)
>  This paper considers a multi-UAV network with a ground station (GS) that uses multi-hop relaying structure for data transmission in a power-efficient manner. The objective is to investigate the best possible multi-hop routing structure for data transmission to maximize the overall network throughput of a flying ad-hoc network (FANET) of UAVs. We formulate a problem to jointly optimize the multi-hop routing structure with the communication link selection for a given power budget so that the overall network throughput can be maximized. It appears that the formulated problem belongs to a class of nonconvex and integer optimization problems, thus making it NP-hard. To solve this problem efficiently, it is decoupled into two subproblems $\textbf{i)}$ power allocation with known Bellman Ford-based multi-hop routing structure and $\textbf{ii)}$ link selection problem. Further, these two subproblems are independently converted into convex problems by relaxation and solved in tandem for the best suboptimal solution to the main problem. Simulation results indicate that the proposed multi-hop routing schemes can achieve a significant improvement in network throughput compared to the other benchmark scheme.      
### 16.A light-weight full-band speech enhancement model  [ :arrow_down: ](https://arxiv.org/pdf/2206.14524.pdf)
>  Deep neural network based full-band speech enhancement systems face challenges of high demand of computational resources and imbalanced frequency distribution. In this paper, a light-weight full-band model is proposed with two dedicated strategies, i.e., a learnable spectral compression mapping for more effective high-band spectral information compression, and the utilization of the multi-head attention mechanism for more effective modeling of the global spectral pattern. Experiments validate the efficacy of the proposed strategies and show that the proposed model achieves competitive performance with only 0.89M parameters.      
### 17.Continuous Switch Model and Heuristics for Mixed-Integer Problems in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14510.pdf)
>  Power systems operation and planning analyses often determine dispatch and planning decisions by solving a mixed-integer nonlinear problem (MINLP) with binary variables devices to the grid. Binary variables, in addition to nonlinear AC network constraints, make this NP-hard problem computationally challenging for gradient-based methods to converge to a local minimum due to the discontinuous solution space. In this work, we form an equivalent-circuit model of the MINLP decision problem by representing binary decisions as a relaxed switch model. The relaxed switch model is characterized by a continuous function that preserves the physical behavior of a real-world switch. This effectively transforms the MINLP problem into an NLP problem by mapping the integrality constraints into a relaxed indicator function. To solve the transformed NLP problem, we develop homotopy and damping methods that rely on knowledge from the physical behavior of the switch. With these methods, we empirically demonstrate robust convergences for large realistic systems (&gt;70,000 buses) while satisfying the non-relaxed AC behavior of the system. The methodology is generalizable for various operation and planning problems, including unit commitment, transmission line switching, and shunt placement. Examples demonstrate superior convergence against state-of-the-art commercial tools and other binary-relaxation methods.      
### 18.DeepMB: Deep neural network for real-time model-based optoacoustic image reconstruction with adjustable speed of sound  [ :arrow_down: ](https://arxiv.org/pdf/2206.14485.pdf)
>  Multispectral optoacoustic tomography (MSOT) is a high-resolution functional imaging modality that can non-invasively access a broad range of pathophysiological phenomena by quantifying the contrast of endogenous chromophores in tissue. Real-time imaging is imperative to translate MSOT into clinical imaging, visualize dynamic pathophysiological changes associated with disease progression, and enable in situ diagnoses. Model-based reconstruction affords state-of-the-art optoacoustic images; however, the advanced image quality provided by model-based reconstruction remains inaccessible during real-time imaging because the algorithm is iterative and computationally demanding. Deep-learning may afford faster reconstructions for real-time optoacoustic imaging, but existing approaches only support oversimplified imaging settings and fail to generalize to in vivo data. In this work, we introduce a novel deep-learning framework, termed DeepMB, to learn the model-based reconstruction operator and infer optoacoustic images with state-of-the-art quality in less than 10 ms per image. DeepMB accurately generalizes to in vivo data after training on synthesized sinograms that are derived from real-world images. The framework affords in-focus images for a broad range of anatomical locations because it supports dynamic adjustment of the reconstruction speed of sound during imaging. Furthermore, DeepMB is compatible with the data rates and image sizes of modern multispectral optoacoustic tomography scanners. We evaluate DeepMB on a diverse dataset of in vivo images and demonstrate that the framework reconstructs images 3000 times faster than the iterative model-based reference method while affording near-identical image qualities. Accurate and real-time image reconstructions with DeepMB can enable full access to the high-resolution and multispectral contrast of handheld optoacoustic tomography.      
### 19.A contraction theory approach to observer-based controller design for glucose regulation in type 1 diabetes with intra-patient variability  [ :arrow_down: ](https://arxiv.org/pdf/2206.14436.pdf)
>  While the Artificial Pancreas is effective in regulating the blood glucose in the safe range of 70-180 mg/dl in type 1 diabetic patients, the high intra-patient variability, as well as exogenous meal disturbances, poses a serious challenge. The existing control algorithms thus require additional safety algorithms and feed-forward actions. Moreover, the unavailability of insulin sensors in Artificial Pancreas makes this task more difficult. In the present work, a subcutaneous model of type 1 diabetes (T1D) is considered for observer-based controller design in the framework of contraction analysis. A variety of realistic multiple-meal scenarios for three virtual T1D patients have been investigated with +30 % and -30 % of parametric variability. The average time spent by the three T1D patients is found to be 77 %, 73 % and 76 %, respectively. A significant reduction in the time spent in hyperglycemia (&gt;180 mg/dl) is achieved without any feed-forward action for meal compensation.      
### 20.Multi-user Downlink Beamforming using Uplink Downlink Duality with 1-bit Converters for Flat Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2206.14427.pdf)
>  The increased power consumption of high-resolution data converters at higher carrier frequencies and larger bandwidths is becoming a bottleneck for communication systems. In this paper, we consider a fully digital base station equipped with 1-bit analog-to-digital (in uplink) and digital-to-analog (in downlink) converters on each radio frequency chain. The base station communicates with multiple single antenna users with individual SINR constraints. We first establish the uplink downlink duality principle under 1-bit hardware constraints under an uncorrelated quantization noise assumption. We then present a linear solution to the multi-user downlink beamforming problem based on the uplink downlink duality principle. The proposed solution takes into account the hardware constraints and jointly optimizes the downlink beamformers and the power allocated to each user. Optimized dithering obtained by adding dummy users to the true system users ensures that the uncorrelated quantization noise assumption is true under realistic settings. Detailed simulations carried out using 3GPP channel models generated from Quadriga show that our proposed solution outperforms state of the art solutions in terms of the ergodic sum and minimum rate especially when the number of users is large. We also demonstrate that the proposed solution significantly reduces the performance gap from non-linear solutions in terms of the uncoded bit error rate at a fraction of the computational complexity.      
### 21.Constructing MDP Abstractions Using Data with Formal Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2206.14402.pdf)
>  This paper is concerned with a data-driven technique for constructing finite Markov decision processes (MDPs) as finite abstractions of discrete-time stochastic control systems with unknown dynamics while providing formal closeness guarantees. The proposed scheme is based on notions of stochastic bisimulation functions (SBF) to capture the probabilistic distance between state trajectories of an unknown stochastic system and those of finite MDP. In our proposed setting, we first reformulate corresponding conditions of SBF as a robust convex program (RCP). We then propose a scenario convex program (SCP) associated to the original RCP by collecting a finite number of data from trajectories of the system. We ultimately construct an SBF between the data-driven finite MDP and the unknown stochastic system with a given confidence level by establishing a probabilistic relation between optimal values of the SCP and the RCP. We also propose two different approaches for the construction of finite MDPs from data. We illustrate the efficacy of our results over a nonlinear jet engine compressor with unknown dynamics. We construct a data-driven finite MDP as a suitable substitute of the original system to synthesize controllers maintaining the system in a safe set with some probability of satisfaction and a desirable confidence level.      
### 22.GreenBIQA: A Lightweight Blind Image Quality Assessment Method  [ :arrow_down: ](https://arxiv.org/pdf/2206.14400.pdf)
>  Deep neural networks (DNNs) achieve great success in blind image quality assessment (BIQA) with large pre-trained models in recent years. Their solutions cannot be easily deployed at mobile or edge devices, and a lightweight solution is desired. In this work, we propose a novel BIQA model, called GreenBIQA, that aims at high performance, low computational complexity and a small model size. GreenBIQA adopts an unsupervised feature generation method and a supervised feature selection method to extract quality-aware features. Then, it trains an XGBoost regressor to predict quality scores of test images. We conduct experiments on four popular IQA datasets, which include two synthetic-distortion and two authentic-distortion datasets. Experimental results show that GreenBIQA is competitive in performance against state-of-the-art DNNs with lower complexity and smaller model sizes.      
### 23.Non-local Evasive Overtaking of Downstream Incidents in Distributed Behavior Planning of Connected Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2206.14391.pdf)
>  The prevalence of high-speed vehicle-to-everything (V2X) communication will likely significantly influence the future of vehicle autonomy. In several autonomous driving applications, however, the role such systems will play is seldom understood. In this paper, we explore the role of communication signals in enhancing the performance of lane change assistance systems in situations where downstream bottlenecks restrict the mobility of a few lanes. Building off of prior work on modeling lane change incentives, we design a controller that 1) encourages automated vehicles to subvert lanes in which distant downstream delays are likely to occur, while also 2) ignoring greedy local incentives when such delays are needed to maintain a specific route. Numerical results on different traffic conditions and penetration rates suggest that the model successfully subverts a significant portion of delays brought about by downstream bottlenecks, both globally and from the perspective of the controlled vehicles.      
### 24.Overview of Deep Learning-based CSI Feedback in Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14383.pdf)
>  Many performance gains achieved by massive multiple-input and multiple-output depend on the accuracy of the downlink channel state information (CSI) at the transmitter (base station), which is usually obtained by estimating at the receiver (user terminal) and feeding back to the transmitter. The overhead of CSI feedback occupies substantial uplink bandwidth resources, especially when the number of the transmit antennas is large. Deep learning (DL)-based CSI feedback refers to CSI compression and reconstruction by a DL-based autoencoder and can greatly reduce feedback overhead. In this paper, a comprehensive overview of state-of-the-art research on this topic is provided, beginning with basic DL concepts widely used in CSI feedback and then categorizing and describing some existing DL-based feedback works. The focus is on novel neural network architectures and utilization of communication expert knowledge to improve CSI feedback accuracy. Works on bit-level CSI feedback and joint design of CSI feedback with other communication modules are also introduced, and some practical issues, including training dataset collection, online training, complexity, generalization, and standardization effect, are discussed. At the end of the paper, some challenges and potential research directions associated with DL-based CSI feedback in future wireless communication systems are identified.      
### 25.Robust Online Voltage Control with an Unknown Grid Topology  [ :arrow_down: ](https://arxiv.org/pdf/2206.14369.pdf)
>  Voltage control generally requires accurate information about the grid's topology in order to guarantee network stability. However, accurate topology identification is a challenging problem for existing methods, especially as the grid is subject to increasingly frequent reconfiguration due to the adoption of renewable energy. Further, running existing control mechanisms with incorrect network information may lead to unstable control. In this work, we combine a nested convex body chasing algorithm with a robust predictive controller to achieve provably finite-time convergence to safe voltage limits in the online setting where the network topology is initially unknown. Specifically, the online controller does not know the true network topology and line parameters, but instead must learn them over time by narrowing down the set of network topologies and line parameters that are consistent with its observations and adjusting reactive power generation accordingly to keep voltages within desired safety limits. We demonstrate the effectiveness of the approach using a case study, which shows that in practical settings the controller is indeed able to narrow the set of consistent topologies quickly enough to make control decisions that ensure stability.      
### 26.Stability Analysis for Stochastic Hybrid Inclusions  [ :arrow_down: ](https://arxiv.org/pdf/2206.14360.pdf)
>  Stochastic hybrid inclusions (SHIs) address situations with the stochastic continuous evolution in a stochastic differential inclusions and random jumps in the difference inclusions due to the forced (the state reaching a boundary in the state space) and/or spontaneous (the state vector may occur spontaneously) transitions. An obvious characteristic of SHIs is the non-uniqueness of random solutions, which can be ensured by the mild regularity conditions, as well as nominal robustness. Basic sufficient conditions for stability/recurrence in probability are usually expressed based on different types of Lyapunov functions, including Lagrange/Lyapunov/Lyapunov-Forster functions respectively for Lagrange/Lyapunov/asymptotical stability in probability and Foster/Lagrange-Forster functions for recurrence, (weaker) relaxed Lyapunov-based sufficient conditions including Matrosov-Foster functions and the stochastic invariance principle, as well as Lyapunov-based necessary and sufficient conditions for asymptotical stability in probability or recurrence (i.e.,converse theorems), etc. The converse theorems involving smooth Lyapunov functions are guaranteed by the sequential compactness and thus robustness. In addition, the uniformity property and causality are analyzed for the stabilities in probability. Hence, serving as a partial roadmap for the theoretical development of SHIs, also serving as inspiration, we anticipate that many of the open questions, including the prediction problem, the filtering problem and the control problem, will be resolved based on the techniques of SHIs.      
### 27.Comparing Conventional Pitch Detection Algorithms with a Neural Network Approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.14357.pdf)
>  Despite much research, traditional methods to pitch prediction are still not perfect. With the emergence of neural networks (NNs), researchers hope to create a NN-based pitch predictor that outperforms traditional methods. Three pitch detection algorithms (PDAs), pYIN, YAAPT, and CREPE are compared in this paper. pYIN and YAAPT are conventional approaches considering time domain and frequency domain processing. CREPE utilizes a data-trained deep convolutional neural network to estimate pitch. It involves 6 densely connected convolutional hidden layers and determines pitch probabilities for a given input signal. The performance of CREPE representing neural network pitch predictors is compared to more classical approaches represented by pYIN and YAAPT. The figure of merit (FOM) will include the amount of unvoiced-to-voiced errors, voiced-to-voiced errors, gross pitch errors, and fine pitch errors.      
### 28.A biased random-key genetic algorithm for the home health care problem  [ :arrow_down: ](https://arxiv.org/pdf/2206.14347.pdf)
>  Home health care problems consist of scheduling visits to home patients by health professionals while following a series of requirements. This paper studies the Home Health Care Routing and Scheduling Problem, which comprises a multi-attribute vehicle routing problem with soft time windows. Additional route inter-dependency constraints apply for patients requesting multiple visits, either by simultaneous visits or visits with precedence. We apply a mathematical programming solver to obtain lower bounds for the problem. We also propose a biased random-key genetic algorithm, and we study the effects of additional state-of-art components recently proposed in the literature for this genetic algorithm. We perform computational experiment using a publicly available benchmark dataset. Regarding the previous local search-based methods, we find results up to 26.1% better than those of the literature. We find improvements from around 0.4% to 6.36% compared to previous results from a similar genetic algorithm.      
### 29.A wideband generalization of the near-field region for extremely large phased-arrays  [ :arrow_down: ](https://arxiv.org/pdf/2206.14323.pdf)
>  The narrowband and far-field assumption in conventional wireless system design leads to a mismatch with the optimal beamforming required for wideband and near-field systems. This discrepancy is exacerbated for larger apertures and bandwidths. To characterize the behavior of near-field and wideband systems, we derive the beamforming gain expression achieved by a frequency-flat phased array designed for plane-wave propagation. To determine the far-field to near-field boundary for a wideband system, we propose a frequency-selective distance metric. The proposed far-field threshold increases for frequencies away from the center frequency. The analysis results in a fundamental upper bound on the product of the array aperture and the system bandwidth. We present numerical results to illustrate how the gain threshold affects the maximum usable bandwidth for the n260 and n261 5G NR bands.      
### 30.Multistep Automated Data Labelling Procedure (MADLaP) for Thyroid Nodules on Ultrasound: An Artificial Intelligence Approach for Automating Image Annotation  [ :arrow_down: ](https://arxiv.org/pdf/2206.14305.pdf)
>  Machine learning (ML) for diagnosis of thyroid nodules on ultrasound is an active area of research. However, ML tools require large, well-labelled datasets, the curation of which is time-consuming and labor-intensive. The purpose of our study was to develop and test a deep-learning-based tool to facilitate and automate the data annotation process for thyroid nodules; we named our tool Multistep Automated Data Labelling Procedure (MADLaP). MADLaP was designed to take multiple inputs included pathology reports, ultrasound images, and radiology reports. Using multiple step-wise modules including rule-based natural language processing, deep-learning-based imaging segmentation, and optical character recognition, MADLaP automatically identified images of a specific thyroid nodule and correctly assigned a pathology label. The model was developed using a training set of 378 patients across our health system and tested on a separate set of 93 patients. Ground truths for both sets were selected by an experienced radiologist. Performance metrics including yield (how many labeled images the model produced) and accuracy (percentage correct) were measured using the test set. MADLaP achieved a yield of 63% and an accuracy of 83%. The yield progressively increased as the input data moved through each module, while accuracy peaked part way through. Error analysis showed that inputs from certain examination sites had lower accuracy (40%) than the other sites (90%, 100%). MADLaP successfully created curated datasets of labeled ultrasound images of thyroid nodules. While accurate, the relatively suboptimal yield of MADLaP exposed some challenges when trying to automatically label radiology images from heterogeneous sources. The complex task of image curation and annotation could be automated, allowing for enrichment of larger datasets for use in machine learning development.      
### 31.The Benefits of Hydrogen Energy Transmission and Conversion Systems to the Renewable Power Grids: Day-ahead Unit Commitment  [ :arrow_down: ](https://arxiv.org/pdf/2206.14279.pdf)
>  The curtailment of renewable energy is more frequently observed as the renewable penetration levels are rising rapidly in modern power systems. It is a waste of free and green renewable energy and implies current power grids are unable to accommodate more renewable sources. One major reason is that higher power transmission capacity is required for higher renewable penetration level. Another major reason is the volatility of the renewable generation. The hydrogen mix or pure hydrogen pipeline can both transfer and store the energy in the form of hydrogen. However, its potential of accelerating renewable integration has not been investigated. In this paper, hydrogen pipeline networks, combined with power-to-hydrogen (P2H) and hydrogen-to-power (H2P) facilities, are organized to form a Hydrogen Energy Transmission and Conversion System (HETCS). We investigate the operation of power systems coupled with HETCS, and propose the day-ahead security-constrained unit commitment (SCUC) with HETCS. The SCUC simulation is conducted on a modified IEEE 24-bus power system with HETCS. Simulation results show HETCS can substantially reduce the renewable curtailment, CO2 emission, load payment and total operational cost. This study validates the HETCS can be a promising solution to achieve net-zero renewable grids.      
### 32.Hyperspectral image reconstruction for spectral camera based on ghost imaging via sparsity constraints using V-DUnet  [ :arrow_down: ](https://arxiv.org/pdf/2206.14199.pdf)
>  Spectral camera based on ghost imaging via sparsity constraints (GISC spectral camera) obtains three-dimensional (3D) hyperspectral information with two-dimensional (2D) compressive measurements in a single shot, which has attracted much attention in recent years. However, its imaging quality and real-time performance of reconstruction still need to be further improved. Recently, deep learning has shown great potential in improving the reconstruction quality and reconstruction speed for computational imaging. When applying deep learning into GISC spectral camera, there are several challenges need to be solved: 1) how to deal with the large amount of 3D hyperspectral data, 2) how to reduce the influence caused by the uncertainty of the random reference measurements, 3) how to improve the reconstructed image quality as far as possible. In this paper, we present an end-to-end V-DUnet for the reconstruction of 3D hyperspectral data in GISC spectral camera. To reduce the influence caused by the uncertainty of the measurement matrix and enhance the reconstructed image quality, both differential ghost imaging results and the detected measurements are sent into the network's inputs. Compared with compressive sensing algorithm, such as PICHCS and TwIST, it not only significantly improves the imaging quality with high noise immunity, but also speeds up the reconstruction time by more than two orders of magnitude.      
### 33.System-level Simulation of Reconfigurable Intelligent Surface assisted Wireless Communications System  [ :arrow_down: ](https://arxiv.org/pdf/2206.14777.pdf)
>  Reconfigurable intelligent surface (RIS) is an emerging technique employing metasurface to reflect the signal from the source node to the destination node. By smartly reconfiguring the electromagnetic (EM) properties of the metasurface and adjusting the EM parameters of the reflected radio waves, RIS can turn the uncontrollable propagation environment into an artificially reconfigurable space, and thus, can significantly increase the communications capacity and improve the coverage of the system. In this paper, we investigate the far field channel in which the line-of-sight (LOS) propagation is dominant. We propose an antenna model that can characterize the radiation patterns of realistic RIS elements, and consider the signal power received from the two-hop path through RIS. System-level simulations of network performance under various scenarios and parameter.      
### 34.An Auto-Regressive Formulation for Smoothing and Moving Mean with Exponentially Tapered Windows  [ :arrow_down: ](https://arxiv.org/pdf/2206.14749.pdf)
>  We investigate an auto-regressive formulation for the problem of smoothing time-series by manipulating the inherent objective function of the traditional moving mean smoothers. Not only the auto-regressive smoothers enforce a higher degree of smoothing, they are just as efficient as the traditional moving means and can be optimized accordingly with respect to the input dataset. Interestingly, the auto-regressive models result in moving means with exponentially tapered windows.      
### 35.Key Factors of Wireless Real-Time Networks -- From Dependability to Timeliness  [ :arrow_down: ](https://arxiv.org/pdf/2206.14743.pdf)
>  Offering support for real-time communications on top of a wireless network infrastructure is both a hot topic and still an open challenge. Wireless networks are not on the same level of safety, dependability, and timeliness observed in the wired realm, but they are evolving towards it. Instead of focusing on the results that need to be delivered, the key factors of wireless real-time networks are on the foundation of the network operation, defining their capability of being dependable, safe, and timely on their roots. IEEE 802.15.4 and ISA100.11a are part of this context, which we show how to be strengthened. From dealing with network inaccessibility to touching the needs of reliable communication protocols to ensure the safe and sound exchange of information, this white paper describes how we can go from dependability to timeliness. This is achieved by visiting the roots of the network operation for securing the provided communication service as a dependable, safe, and timely asset for industrial automation. <br>Keywords: Dependability, Safety, Timeliness, Resilience, Real-Time Wireless Networks, Industrial Automation.      
### 36.DrumGAN VST: A Plugin for Drum Sound Analysis/Synthesis With Autoencoding Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.14723.pdf)
>  In contemporary popular music production, drum sound design is commonly performed by cumbersome browsing and processing of pre-recorded samples in sound libraries. One can also use specialized synthesis hardware, typically controlled through low-level, musically meaningless parameters. Today, the field of Deep Learning offers methods to control the synthesis process via learned high-level features and allows generating a wide variety of sounds. In this paper, we present DrumGAN VST, a plugin for synthesizing drum sounds using a Generative Adversarial Network. DrumGAN VST operates on 44.1 kHz sample-rate audio, offers independent and continuous instrument class controls, and features an encoding neural network that maps sounds into the GAN's latent space, enabling resynthesis and manipulation of pre-existing drum sounds. We provide numerous sound examples and a demo of the proposed VST plugin.      
### 37.Improving Deliberation by Text-Only and Semi-Supervised Training  [ :arrow_down: ](https://arxiv.org/pdf/2206.14716.pdf)
>  Text-only and semi-supervised training based on audio-only data has gained popularity recently due to the wide availability of unlabeled text and speech data. In this work, we propose incorporating text-only and semi-supervised training into an attention-based deliberation model. By incorporating text-only data in training a bidirectional encoder representation from transformer (BERT) for the deliberation text encoder, and large-scale text-to-speech and audio-only utterances using joint acoustic and text decoder (JATD) and semi-supervised training, we achieved 4%-12% WER reduction for various tasks compared to the baseline deliberation. Compared to a state-of-the-art language model (LM) rescoring method, the deliberation model reduces the Google Voice Search WER by 11% relative. We show that the deliberation model also achieves a positive human side-by-side evaluation compared to the state-of-the-art LM rescorer with reasonable endpointer latencies.      
### 38.Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2206.14697.pdf)
>  Recurrent State-space models (RSSMs) are highly expressive models for learning patterns in time series data and system identification. However, these models assume that the dynamics are fixed and unchanging, which is rarely the case in real-world scenarios. Many control applications often exhibit tasks with similar but not identical dynamics which can be modeled as a latent variable. We introduce the Hidden Parameter Recurrent State Space Models (HiP-RSSMs), a framework that parametrizes a family of related dynamical systems with a low-dimensional set of latent factors. We present a simple and effective way of learning and performing inference over this Gaussian graphical model that avoids approximations like variational inference. We show that HiP-RSSMs outperforms RSSMs and competing multi-task models on several challenging robotic benchmarks both on real-world systems and simulations.      
### 39.Computer-aided diagnosis and prediction in brain disorders  [ :arrow_down: ](https://arxiv.org/pdf/2206.14683.pdf)
>  Computer-aided methods have shown added value for diagnosing and predicting brain disorders and can thus support decision making in clinical care and treatment planning. This chapter will provide insight into the type of methods, their working, their input data - such as cognitive tests, imaging and genetic data - and the types of output they provide. We will focus on specific use cases for diagnosis, i.e. estimating the current 'condition' of the patient, such as early detection and diagnosis of dementia, differential diagnosis of brain tumours, and decision making in stroke. Regarding prediction, i.e. estimation of the future 'condition' of the patient, we will zoom in on use cases such as predicting the disease course in multiple sclerosis and predicting patient outcomes after treatment in brain cancer. Furthermore, based on these use cases, we will assess the current state-of-the-art methodology and highlight current efforts on benchmarking of these methods and the importance of open science therein. Finally, we assess the current clinical impact of computer-aided methods and discuss the required next steps to increase clinical impact.      
### 40.Deep Learning-Based Attenuation and Scatter Correction of Brain 18F-FDG PET Images in the Image Domain  [ :arrow_down: ](https://arxiv.org/pdf/2206.14673.pdf)
>  Attenuation and scatter correction (AC) is crucial for quantitative Positron Emission Tomography (PET) imaging. Recently, direct application of AC in the image domain using deep learning approaches has been proposed for the hybrid PET/MR and dedicated PET systems that lack accompanying transmission or anatomical imaging. This study set out to investigate deep learning-based AC in the image domain using different input settings.      
### 41.The THUEE System Description for the IARPA OpenASR21 Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2206.14660.pdf)
>  This paper describes the THUEE team's speech recognition system for the IARPA Open Automatic Speech Recognition Challenge (OpenASR21), with further experiment explorations. We achieve outstanding results under both the Constrained and Constrained-plus training conditions. For the Constrained training condition, we construct our basic ASR system based on the standard hybrid architecture. To alleviate the Out-Of-Vocabulary (OOV) problem, we extend the pronunciation lexicon using Grapheme-to-Phoneme (G2P) techniques for both OOV and potential new words. Standard acoustic model structures such as CNN-TDNN-F and CNN-TDNN-F-A are adopted. In addition, multiple data augmentation techniques are applied. For the Constrained-plus training condition, we use the self-supervised learning framework wav2vec2.0. We experiment with various fine-tuning techniques with the Connectionist Temporal Classification (CTC) criterion on top of the publicly available pre-trained model XLSR-53. We find that the frontend feature extractor plays an important role when applying the wav2vec2.0 pre-trained model to the encoder-decoder based CTC/Attention ASR architecture. Extra improvements can be achieved by using the CTC model finetuned in the target language as the frontend feature extractor.      
### 42.Language-Based Audio Retrieval with Converging Tied Layers and Contrastive Loss  [ :arrow_down: ](https://arxiv.org/pdf/2206.14659.pdf)
>  In this paper, we tackle the new Language-Based Audio Retrieval task proposed in DCASE 2022. Firstly, we introduce a simple, scalable architecture which ties both the audio and text encoder together. Secondly, we show that using this architecture along with contrastive loss allows the model to significantly beat the performance of the baseline model. Finally, in addition to having an extremely low training memory requirement, we are able to use pretrained models as it is without needing to finetune them. We test our methods and show that using a combination of our methods beats the baseline scores significantly.      
### 43.Generative Anomaly Detection for Time Series Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2206.14597.pdf)
>  Traffic congestion anomaly detection is of paramount importance in intelligent traffic systems. The goals of transportation agencies are two-fold: to monitor the general traffic conditions in the area of interest and to locate road segments under abnormal congestion states. Modeling congestion patterns can achieve these goals for citywide roadways, which amounts to learning the distribution of multivariate time series (MTS). However, existing works are either not scalable or unable to capture the spatial-temporal information in MTS simultaneously. To this end, we propose a principled and comprehensive framework consisting of a data-driven generative approach that can perform tractable density estimation for detecting traffic anomalies. Our approach first clusters segments in the feature space and then uses conditional normalizing flow to identify anomalous temporal snapshots at the cluster level in an unsupervised setting. Then, we identify anomalies at the segment level by using a kernel density estimator on the anomalous cluster. Extensive experiments on synthetic datasets show that our approach significantly outperforms several state-of-the-art congestion anomaly detection and diagnosis methods in terms of Recall and F1-Score. We also use the generative model to sample labeled data, which can train classifiers in a supervised setting, alleviating the lack of labeled data for anomaly detection in sparse settings.      
### 44.Finstreder: Simple and fast Spoken Language Understanding with Finite State Transducers using modern Speech-to-Text models  [ :arrow_down: ](https://arxiv.org/pdf/2206.14589.pdf)
>  In Spoken Language Understanding (SLU) the task is to extract important information from audio commands, like the intent of what a user wants the system to do and special entities like locations or numbers. This paper presents a simple method for embedding intents and entities into Finite State Transducers, and, in combination with a pretrained general-purpose Speech-to-Text model, allows building SLU-models without any additional training. Building those models is very fast and only takes a few seconds. It is also completely language independent. With a comparison on different benchmarks it is shown that this method can outperform multiple other, more resource demanding SLU approaches.      
### 45.Language-specific Characteristic Assistance for Code-switching Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.14580.pdf)
>  Dual-encoder structure successfully utilizes two language-specific encoders (LSEs) for code-switching speech recognition. Because LSEs are initialized by two pre-trained language-specific models (LSMs), the dual-encoder structure can exploit sufficient monolingual data and capture the individual language attributes. However, existing methods have no language constraints on LSEs and underutilize language-specific knowledge of LSMs. In this paper, we propose a language-specific characteristic assistance (LSCA) method to mitigate the above problems. Specifically, during training, we introduce two language-specific losses as language constraints and generate corresponding language-specific targets for them. During decoding, we take the decoding abilities of LSMs into account by combining the output probabilities of two LSMs and the mixture model to obtain the final predictions. Experiments show that either the training or decoding method of LSCA can improve the model's performance. Furthermore, the best result can obtain up to 15.4% relative error reduction on the code-switching test set by combining the training and decoding methods of LSCA. Moreover, the system can process code-switching speech recognition tasks well without extra shared parameters or even retraining based on two pre-trained LSMs by using our method.      
### 46.ADARP: A Multi Modal Dataset for Stress and Alcohol Relapse Quantification in Real Life Setting  [ :arrow_down: ](https://arxiv.org/pdf/2206.14568.pdf)
>  Stress detection and classification from wearable sensor data is an emerging area of research with significant implications for individuals' physical and mental health. In this work, we introduce a new dataset, ADARP, which contains physiological data and self-report outcomes collected in real-world ambulatory settings involving individuals diagnosed with alcohol use disorders. We describe the user study, present details of the dataset, establish the significant correlation between physiological data and self-reported outcomes, demonstrate stress classification, and make our dataset public to facilitate research.      
### 47.Imaging the time series of one single referenced EEG electrode for Epileptic Seizures Risk Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.14520.pdf)
>  The time series captured by a single scalp electrode (plus the reference electrode) of refractory epileptic patients is used to forecast seizures susceptibility. The time series is preprocessed, segmented, and each segment transformed into an image, using three different known methods: Recurrence Plot, Gramian Angular Field, Markov Transition Field. The likelihood of the occurrence of a seizure in a future predefined time window is computed by averaging the output of the softmax layer of a CNN, differently from the usual consideration of the output of the classification layer. By thresholding this likelihood, seizure forecasting has better performance. Interestingly, for almost every patient, the best threshold was different from 50%. The results show that this technique can predict with good results for some seizures and patients. However, more tests, namely more patients and more seizures, are needed to better understand the real potential of this technique.      
### 48.Auto-Encoder-Extreme Learning Machine Model for Boiler NOx Emission Concentration Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.14496.pdf)
>  An automatic encoder (AE) extreme learning machine (ELM)-AE-ELM model is proposed to predict the NOx emission concentration based on the combination of mutual information algorithm (MI), AE, and ELM. First, the importance of practical variables is computed by the MI algorithm, and the mechanism is analyzed to determine the variables related to the NOx emission concentration. Then, the time delay correlations between the selected variables and NOx emission concentration are further analyzed to reconstruct the modeling data. Subsequently, the AE is applied to extract hidden features within the input variables. Finally, an ELM algorithm establishes the relationship between the NOx emission concentration and deep features. The experimental results on practical data indicate that the proposed model shows promising performance compared to state-of-art models.      
### 49.Data augmentation for learning predictive models on EEG: a systematic comparison  [ :arrow_down: ](https://arxiv.org/pdf/2206.14483.pdf)
>  The use of deep learning for electroencephalography (EEG) classification tasks has been rapidly growing in the last years, yet its application has been limited by the relatively small size of EEG datasets. Data augmentation, which consists in artificially increasing the size of the dataset during training, has been a key ingredient to obtain state-of-the-art performances across applications such as computer vision or speech. While a few augmentation transformations for EEG data have been proposed in the literature, their positive impact on performance across tasks remains elusive. In this work, we propose a unified and exhaustive analysis of the main existing EEG augmentations, which are compared in a common experimental setting. Our results highlight the best data augmentations to consider for sleep stage classification and motor imagery brain computer interfaces, showing predictive power improvements greater than 10% in some cases.      
### 50.Intelligent Reflecting Surface for MIMO VLC: Joint Design of Surface Configuration and Transceiver Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.14465.pdf)
>  With the capability of reconfiguring the wireless electromagnetic environment, intelligent reflecting surface (IRS) is a new paradigm for designing future wireless communication systems. In this paper, we consider optical IRS for improving the performance of visible light communication (VLC) under a multiple-input and multiple-output (MIMO) setting. Specifically, we focus on the downlink communication of an indoor MIMO VLC system and aim to minimize the mean square error (MSE) of demodulated signals at the receiver. To this end, the MIMO channel gain of the IRS-aided VLC is first derived under the point source assumption, based on which the MSE minimization problem is then formulated subject to the emission power constraints. Next, we propose an alternating optimization algorithm, which decomposes the original problem into three subproblems, to iteratively optimize the IRS configuration, the precoding and detection matrices for minimizing the MSE. Moreover, theoretical analysis on the performance of the proposed algorithm in high and low signal-to-noise rate (SNR) regimes is provided, revealing that the joint optimization process can be simplified in such special cases, and the algorithm's convergence property and computational complexity are also discussed. Finally, numerical results show that IRS-aided schemes significantly reduce the MSE as compared to their counterparts without IRS, and the proposed algorithm outperforms other baseline schemes.      
### 51.Geometry parameter estimation for sparse X-ray log imaging  [ :arrow_down: ](https://arxiv.org/pdf/2206.14444.pdf)
>  We consider geometry parameter estimation in industrial sawmill fan-beam X-ray tomography. In such industrial settings, scanners do not always allow identification of the location of the source-detector pair, which creates the issue of unknown geometry. This work considers two approaches for geometry estimation. Our first approach is a calibration object correlation method in which we calculate the maximum cross-correlation between a known-sized calibration object image and its filtered backprojection reconstruction and use differential evolution as an optimiser. The second approach is projection trajectory simulation, where we use a set of known intersection points and a sequential Monte Carlo method for estimating the posterior density of the parameters. We show numerically that a large set of parameters can be used for artefact-free reconstruction. We deploy Bayesian inversion with Cauchy priors for synthetic and real sawmill data for detection of knots with a very low number of measurements and uncertain measurement geometry.      
### 52.Collaborative Navigation and Manipulation of a Cable-towed Load by Multiple Quadrupedal Robots  [ :arrow_down: ](https://arxiv.org/pdf/2206.14424.pdf)
>  This paper tackles the problem of robots collaboratively towing a load with cables to a specified goal location while avoiding collisions in real time. The introduction of cables (as opposed to rigid links) enables the robotic team to travel through narrow spaces by changing its intrinsic dimensions through slack/taut switches of the cable. However, this is a challenging problem because of the hybrid mode switches and the dynamical coupling among multiple robots and the load. Previous attempts at addressing such a problem were performed offline and do not consider avoiding obstacles online. In this paper, we introduce a cascaded planning scheme with a parallelized centralized trajectory optimization that deals with hybrid mode switches. We additionally develop a set of decentralized planners per robot, which enables our approach to solve the problem of collaborative load manipulation online. We develop and demonstrate one of the first collaborative autonomy framework that is able to move a cable-towed load, which is too heavy to move by a single robot, through narrow spaces with real-time feedback and reactive planning in experiments.      
### 53.Robust optimization for quantum reinforcement learning control using partial observations  [ :arrow_down: ](https://arxiv.org/pdf/2206.14420.pdf)
>  The current quantum reinforcement learning control models often assume that the quantum states are known a priori for control optimization. However, full observation of quantum state is experimentally infeasible due to the exponential scaling of the number of required quantum measurements on the number of qubits. In this paper, we investigate a robust reinforcement learning method using partial observations to overcome this difficulty. This control scheme is compatible with near-term quantum devices, where the noise is prevalent and predetermining the dynamics of quantum state is practically impossible. We show that this simplified control scheme can achieve similar or even better performance when compared to the conventional methods relying on full observation. We demonstrate the effectiveness of this scheme on examples of quantum state control and quantum approximate optimization algorithm. It has been shown that high-fidelity state control can be achieved even if the noise amplitude is at the same level as the control amplitude. Besides, an acceptable level of optimization accuracy can be achieved for QAOA with noisy control Hamiltonian. This robust control optimization model can be trained to compensate the uncertainties in practical quantum computing.      
### 54.Theoretical Perspectives on Deep Learning Methods in Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14373.pdf)
>  In recent years, there have been significant advances in the use of deep learning methods in inverse problems such as denoising, compressive sensing, inpainting, and super-resolution. While this line of works has predominantly been driven by practical algorithms and experiments, it has also given rise to a variety of intriguing theoretical problems. In this paper, we survey some of the prominent theoretical developments in this line of works, focusing in particular on generative priors, untrained neural network priors, and unfolding algorithms. In addition to summarizing existing results in these topics, we highlight several ongoing challenges and open problems.      
### 55.Lower Bounds on the Error Probability for Invariant Causal Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.14362.pdf)
>  It is common practice to collect observations of feature and response pairs from different environments. A natural question is how to identify features that have consistent prediction power across environments. The invariant causal prediction framework proposes to approach this problem through invariance, assuming a linear model that is invariant under different environments. In this work, we make an attempt to shed light on this framework by connecting it to the Gaussian multiple access channel problem. Specifically, we incorporate optimal code constructions and decoding methods to provide lower bounds on the error probability. We illustrate our findings by various simulation settings.      
### 56.Multiuser MISO PS-SWIPT Systems: Active or Passive RIS?  [ :arrow_down: ](https://arxiv.org/pdf/2206.14326.pdf)
>  Reconfigurable intelligent surface (RIS)-based communication networks promise to improve channel capacity and energy efficiency. However, the promised capacity gains could be negligible for passive RISs because of the double pathloss effect. Active RISs can overcome this issue because they have reflector elements with a low-cost amplifier. This letter studies the active RIS-aided simultaneous wireless information and power transfer (SWIPT) in a multiuser system. The users exploit power splitting (PS) to decode information and harvest energy simultaneously based on a realistic piecewise nonlinear energy harvesting model. The goal is to minimize the base station (BS) transmit power by optimizing its beamformers, PS ratios, and RIS phase shifts/amplification factors. The simulation results show significant improvements (e.g., 19% and 28%) with the maximum reflect power of 10 mW and 15 mW, respectively, compared to the passive RIS without higher computational complexity cost. We also show the robustness of the proposed algorithm against imperfect channel state information.      
### 57.Bottleneck Low-rank Transformers for Low-resource Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2206.14318.pdf)
>  End-to-end spoken language understanding (SLU) systems benefit from pretraining on large corpora, followed by fine-tuning on application-specific data. The resulting models are too large for on-edge applications. For instance, BERT-based systems contain over 110M parameters. Observing the model is overparameterized, we propose lean transformer structure where the dimension of the attention mechanism is automatically reduced using group sparsity. We propose a variant where the learned attention subspace is transferred to an attention bottleneck layer. In a low-resource setting and without pre-training, the resulting compact SLU model achieves accuracies competitive with pre-trained large models.      
### 58.Learning Time Delay Systems with Neural Ordinary Differential Equations  [ :arrow_down: ](https://arxiv.org/pdf/2206.14288.pdf)
>  A novel way of using neural networks to learn the dynamics of time delay systems from sequential data is proposed. A neural network with trainable delays is used to approximate the right hand side of a delay differential equation. We relate the delay differential equation to an ordinary differential equation by discretizing the time history and train the corresponding neural ordinary differential equation (NODE) to learn the dynamics. An example on learning the dynamics of the Mackey-Glass equation using data from chaotic behavior is given. After learning both the nonlinearity and the time delay, we demonstrate that the bifurcation diagram of the neural network matches that of the original system.      
### 59.Hausdorff Distance between Norm Balls and their Linear Maps  [ :arrow_down: ](https://arxiv.org/pdf/2206.12012.pdf)
>  We consider the problem of computing the (two-sided) Hausdorff distance between the unit $p_1$ and $p_2$ norm balls in finite dimensional Euclidean space for $1 &lt; p_1 &lt; p_2 \leq \infty$, and derive a closed-form formula for the same. When the two different norm balls are transformed via a common linear map, we obtain several estimates for the Hausdorff distance between the resulting convex sets. These estimates upper bound the Hausdorff distance or its expectation, depending on whether the linear map is arbitrary or random. We then generalize the developments for the Hausdorff distance between two set-valued integrals obtained by applying a parametric family of linear maps to the unit norm balls, and then taking the Minkowski sums of the resulting sets in a limiting sense. To illustrate an application, we show that the problem of computing the Hausdorff distance between the reach sets of a linear dynamical system with different unit norm ball-valued input uncertainties, reduces to this set-valued integral setting.      
### 60.High Resolution Point Clouds from mmWave Radar  [ :arrow_down: ](https://arxiv.org/pdf/2206.09273.pdf)
>  This paper explores a machine learning approach for generating high resolution point clouds from a single-chip mmWave radar. Unlike lidar and vision-based systems, mmWave radar can operate in harsh environments and see through occlusions like smoke, fog, and dust. Unfortunately, current mmWave processing techniques offer poor spatial resolution compared to lidar point clouds. This paper presents RadarHD, an end-to-end neural network that constructs lidar-like point clouds from low resolution radar input. Enhancing radar images is challenging due to the presence of specular and spurious reflections. Radar data also doesn't map well to traditional image processing techniques due to the signal's sinc-like spreading pattern. We overcome these challenges by training RadarHD on a large volume of raw I/Q radar data paired with lidar point clouds across diverse indoor settings. Our experiments show the ability to generate rich point clouds even in scenes unobserved during training and in the presence of heavy smoke occlusion. Further, RadarHD's point clouds are high-quality enough to work with existing lidar odometry and mapping workflows.      
