# ArXiv eess --Fri, 10 Jun 2022
### 1.VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2206.04647.pdf)
>  Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high fidelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a unified framework. However, most of them only support a fixed up-sampling scale, which limits their flexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and significantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at <a class="link-external link-http" href="http://zeyuan-chen.com/VideoINR/" rel="external noopener nofollow">this http URL</a> .      
### 2.Representing Lanes as Arc-length-based Parametric Curves to Facilitate Estimation in Vehicle Control  [ :arrow_down: ](https://arxiv.org/pdf/2206.04592.pdf)
>  This paper revisits the fundamental mathematics of Taylor series to approximate curves with function representation and arc-length-based parametric representation. Parametric representation is shown to preserve its form in coordinate transformation and parameter shifting. These preservations can significantly facilitate lane estimation in vehicle control since lanes perceived by cameras are typically represented in vehicle body-fixed frames which are translating and rotating. Then we derived the transformation from function representation to arc-length-based parametric representation and its inverse. We applied the transformation to lane estimation in vehicle control problem, and derived the evolution of coefficients for parametric representation that can be used for prediction. We come up with a procedure to simulate the whole process with perception, lane estimation and control for the path-following problem. Simulations are performed to demonstrate the efficacy of the proposed lane estimation algorithm using parametric representation. The results indicate that the proposed technique ensures that vehicle control can achieve reasonably good performance at very low perception updating rate.      
### 3.Classification of COVID-19 in Chest X-ray Images Using Fusion of Deep Features and LightGBM  [ :arrow_down: ](https://arxiv.org/pdf/2206.04548.pdf)
>  The COVID-19 disease was first discovered in Wuhan, China, and spread quickly worldwide. After the COVID-19 pandemic, many researchers have begun to identify a way to diagnose the COVID-19 using chest X-ray images. The early diagnosis of this disease can significantly impact the treatment process. In this article, we propose a new technique that is faster and more accurate than the other methods reported in the literature. The proposed method uses a combination of DenseNet169 and MobileNet Deep Neural Networks to extract the features of the patient's X-ray images. Using the univariate feature selection algorithm, we refined the features for the most important ones. Then we applied the selected features as input to the LightGBM (Light Gradient Boosting Machine) algorithm for classification. To assess the effectiveness of the proposed method, the ChestX-ray8 dataset, which includes 1125 X-ray images of the patient's chest, was used. The proposed method achieved 98.54% and 91.11% accuracies in the two-class (COVID-19, Healthy) and multi-class (COVID-19, Healthy, Pneumonia) classification problems, respectively. It is worth mentioning that we have used Gradient-weighted Class Activation Mapping (Grad-CAM) for further analysis.      
### 4.SAR Despeckling using a Denoising Diffusion Probabilistic Model  [ :arrow_down: ](https://arxiv.org/pdf/2206.04514.pdf)
>  Speckle is a multiplicative noise which affects all coherent imaging modalities including Synthetic Aperture Radar (SAR) images. The presence of speckle degrades the image quality and adversely affects the performance of SAR image understanding applications such as automatic target recognition and change detection. Thus, SAR despeckling is an important problem in remote sensing. In this paper, we introduce SAR-DDPM, a denoising diffusion probabilistic model for SAR despeckling. The proposed method comprises of a Markov chain that transforms clean images to white Gaussian noise by repeatedly adding random noise. The despeckled image is recovered by a reverse process which iteratively predicts the added noise using a noise predictor which is conditioned on the speckled image. In addition, we propose a new inference strategy based on cycle spinning to improve the despeckling performance. Our experiments on both synthetic and real SAR images demonstrate that the proposed method achieves significant improvements in both quantitative and qualitative results over the state-of-the-art despeckling methods.      
### 5.Abstract message passing and distributed graph signal processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.04498.pdf)
>  Graph signal processing is a framework to handle graph structured data. The fundamental concept is graph shift operator, giving rise to the graph Fourier transform. While the graph Fourier transform is a centralized procedure, distributed graph signal processing algorithms are needed to address challenges such as scalability and privacy. In this paper, we develop a theory of distributed graph signal processing based on the classical notion of message passing. However, we generalize the definition of a message to permit more abstract mathematical objects. The framework provides an alternative point of view that avoids the iterative nature of existing approaches to distributed graph signal processing. Moreover, our framework facilitates investigating theoretical questions such as solubility of distributed problems.      
### 6.From Dimension-Free Manifold to Dimension-varying (Control) System  [ :arrow_down: ](https://arxiv.org/pdf/2206.04461.pdf)
>  Starting from the projection among Euclidean space of different dimensions(ESDD), the inner product, norm, and distance of two vectors of different dimensions are proposed, which lead to an equivalence. As a quotient space of ESDDs over equivalence, the dimension-free Euclidean space (DFES) and dimension-free Euclidean manifold (DFEM) are obtained, which have bundled vector spaces as the tangent space at each point. Main objects for classical manifolds in differential geometry, such as functions, (co-)vector fields, tensor fields, etc., have been extended to DFEM. Using the natural projection from ESDDs to DFES, a fiber bundle structure is obtained, which has EFDDs as its total space and DFES as its base space. Then the dimension-varying dynamic system (DVDS) and dimension-varying control system (DVCS) are presented, which have DFEM as their state spaces. The realization, which is a lifting of dimension-free dynamic system (DFDS) or dimension-free control system (DFCS) from DFEM into ESDD, and the projection of DVDS or DVCS from ESDD onto DFEM are investigated.      
### 7.Seamless Accurate Positioning in Deep Urban Area based on Mode Switching Between DGNSS and Multipath Mitigation Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2206.04457.pdf)
>  Multipath and non-line-of-sight (NLOS) signals are the major causes of poor accuracy of a global navigation satellite system (GNSS) in urban areas. Despite the wide usage of the GNSS in populated urban areas, it is difficult to suggest a generalized method because multipath errors are user-specific errors that cannot be eliminated by the DGNSS or a real-time kinematic technique. This paper introduces a real-time multipath estimation and mitigation technique, which considers compensation for the time offset between constellations. It also presents a mode-switching algorithm between the DGNSS and multipath mitigating mode and shows that this technique can be effectively utilized for automobiles in a deep urban environment without any help from sensors other than GNSS. The availability is improved from 64% to 100% and the error RMS is reduced from 11.1 m to 1.2 m on Teheran-ro, Seoul, Korea. Because this method does not require prior information or additional sensor implementation for high-positioning performance in deep urban areas, it is expected to gain wide usage in not only the automotive industry but also future intelligent transportation systems.      
### 8.Convolutional Dictionary Learning by End-To-End Training of Iterative Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.04447.pdf)
>  Sparsity-based methods have a long history in the field of signal processing and have been successfully applied to various image reconstruction problems. The involved sparsifying transformations or dictionaries are typically either pre-trained using a model which reflects the assumed properties of the signals or adaptively learned during the reconstruction - yielding so-called blind Compressed Sensing approaches. However, by doing so, the transforms are never explicitly trained in conjunction with the physical model which generates the signals. In addition, properly choosing the involved regularization parameters remains a challenging task. Another recently emerged training-paradigm for regularization methods is to use iterative neural networks (INNs) - also known as unrolled networks - which contain the physical model. In this work, we construct an INN which can be used as a supervised and physics-informed online convolutional dictionary learning algorithm. We evaluated the proposed approach by applying it to a realistic large-scale dynamic MR reconstruction problem and compared it to several other recently published works. We show that the proposed INN improves over two conventional model-agnostic training methods and yields competitive results also compared to a deep INN. Further, it does not require to choose the regularization parameters and - in contrast to deep INNs - each network component is entirely interpretable.      
### 9.Discriminative and Generative Learning for Linear Estimation of Random Signals [Lecture Notes]  [ :arrow_down: ](https://arxiv.org/pdf/2206.04432.pdf)
>  Inference tasks in signal processing are often characterized by the availability of reliable statistical modeling with some missing instance-specific parameters. One conventional approach uses data to estimate these missing parameters and then infers based on the estimated model. Alternatively, data can also be leveraged to directly learn the inference mapping end-to-end. These approaches for combining partially-known statistical models and data in inference are related to the notions of generative and discriminative models used in the machine learning literature, typically considered in the context of classifiers. The goal of this lecture note is to introduce the concepts of generative and discriminative learning for inference with a partially-known statistical model. While machine learning systems often lack the interpretability of traditional signal processing methods, we focus on a simple setting where one can interpret and compare the approaches in a tractable manner that is accessible and relevant to signal processing readers. In particular, we exemplify the approaches for the task of Bayesian signal estimation in a jointly Gaussian setting with the mean-squared error (MSE) objective, i.e., a linear estimation setting.      
### 10.Cross-boosting of WNNM Image Denoising method by Directional Wavelet Packets  [ :arrow_down: ](https://arxiv.org/pdf/2206.04431.pdf)
>  The paper presents an image denoising scheme by combining a method that is based on directional quasi-analytic wavelet packets (qWPs) with the state-of-the-art Weighted Nuclear Norm Minimization (WNNM) denoising algorithm. The qWP-based denoising method (qWPdn) consists of multiscale qWP transform of the degraded image, application of adaptive localized soft thresholding to the transform coefficients using the Bivariate Shrinkage methodology, and restoration of the image from the thresholded coefficients from several decomposition levels. The combined method consists of several iterations of qWPdn and WNNM algorithms in a way that at each iteration the output from one algorithm boosts the input to the other. The proposed methodology couples the qWPdn capabilities to capture edges and fine texture patterns even in the severely corrupted images with utilizing the non-local self-similarity in real images that is inherent in the WNNM algorithm. <br>Multiple experiments, which compared the proposed methodology with six advanced denoising algorithms, including WNNM, confirmed that the combined cross-boosting algorithm outperforms most of them in terms of both quantitative measure and visual perception quality.      
### 11.Only-Train-Once MR Fingerprinting for Magnetization Transfer Contrast Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2206.04383.pdf)
>  Magnetization transfer contrast magnetic resonance fingerprinting (MTC-MRF) is a novel quantitative imaging technique that simultaneously measures several tissue parameters of semisolid macromolecule and free bulk water. In this study, we propose an Only-Train-Once MR fingerprinting (OTOM) framework that estimates the free bulk water and MTC tissue parameters from MR fingerprints regardless of MRF schedule, thereby avoiding time-consuming process such as generation of training dataset and network training according to each MRF schedule. A recurrent neural network is designed to cope with two types of variants of MRF schedules: 1) various lengths and 2) various patterns. Experiments on digital phantoms and in vivo data demonstrate that our approach can achieve accurate quantification for the water and MTC parameters with multiple MRF schedules. Moreover, the proposed method is in excellent agreement with the conventional deep learning and fitting methods. The flexible OTOM framework could be an efficient tissue quantification tool for various MRF protocols.      
### 12.How Asynchronous Events Encode Video  [ :arrow_down: ](https://arxiv.org/pdf/2206.04341.pdf)
>  As event-based sensing gains in popularity, theoretical understanding is needed to harness this technology's potential. Instead of recording video by capturing frames, event-based cameras have sensors that emit events when their inputs change, thus encoding information in the timing of events. This creates new challenges in establishing reconstruction guarantees and algorithms, but also provides advantages over frame-based video. We use time encoding machines to model event-based sensors: TEMs also encode their inputs by emitting events characterized by their timing and reconstruction from time encodings is well understood. We consider the case of time encoding bandlimited video and demonstrate a dependence between spatial sensor density and overall spatial and temporal resolution. Such a dependence does not occur in frame-based video, where temporal resolution depends solely on the frame rate of the video and spatial resolution depends solely on the pixel grid. However, this dependence arises naturally in event-based video and allows oversampling in space to provide better time resolution. As such, event-based vision encourages using more sensors that emit fewer events over time.      
### 13.Precoder and Decoder Co-Designs for Radar and Communication Spectrum Sharing  [ :arrow_down: ](https://arxiv.org/pdf/2206.04337.pdf)
>  Radar and modern communication systems are both evaluating towards higher frequency bands and massive antenna arrays, thus increasing their similarities in terms of hardware structure, channel characteristics, and signal processing pipelines. To suppress the cross-system interference caused by communications and radar systems with shared spectral and hardware resources, the co-design philosophy, wherein the communications and radar/sensing systems can operate in parallel with jointly optimized performance, has drawn substantial attention from both academia and industry. In this paper, we propose a nullspace-based joint precoder-decoder design for spectrum sharing between multicarrier radar and multiuser multicarrier communication systems, by employing the maximizing signal interference noise ratio (max-SINR) criterion and interference alignment (IA) constraints. By projecting the cross-system interference to the designed null spaces, a maximum degree of freedom upper bound for the $K+1$-radar-communication-user interference channel can be achieved. Our simulation studies demonstrate that interference can be practically fully canceled in both communication and radar systems. This leads to improved detection performance in radar and a higher rate in communication subsystems. A significant performance gain over a nullspace-based precoder-only design is also obtained.      
### 14.Joint Modeling of Image and Label Statistics for Enhancing Model Generalizability of Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.04336.pdf)
>  Although supervised deep-learning has achieved promising performance in medical image segmentation, many methods cannot generalize well on unseen data, limiting their real-world applicability. To address this problem, we propose a deep learning-based Bayesian framework, which jointly models image and label statistics, utilizing the domain-irrelevant contour of a medical image for segmentation. Specifically, we first decompose an image into components of contour and basis. Then, we model the expected label as a variable only related to the contour. Finally, we develop a variational Bayesian framework to infer the posterior distributions of these variables, including the contour, the basis, and the label. The framework is implemented with neural networks, thus is referred to as deep Bayesian segmentation. Results on the task of cross-sequence cardiac MRI segmentation show that our method set a new state of the art for model generalizability. Particularly, the BayeSeg model trained with LGE MRI generalized well on T2 images and outperformed other models with great margins, i.e., over 0.47 in terms of average Dice. Our code is available at <a class="link-external link-https" href="https://zmiclab.github.io/projects.html" rel="external noopener nofollow">this https URL</a>.      
### 15.Novel projection schemes for graph-based Light Field coding  [ :arrow_down: ](https://arxiv.org/pdf/2206.04328.pdf)
>  In Light Field compression, graph-based coding is powerful to exploit signal redundancy along irregular shapes and obtains good energy compaction. However, apart from high time complexity to process high dimensional graphs, their graph construction method is highly sensitive to the accuracy of disparity information between viewpoints. In real world Light Field or synthetic Light Field generated by computer software, the use of disparity information for super-rays projection might suffer from inaccuracy due to vignetting effect and large disparity between views in the two types of Light Fields respectively. This paper introduces two novel projection schemes resulting in less error in disparity information, in which one projection scheme can also significantly reduce time computation for both encoder and decoder. Experimental results show projection quality of super-pixels across views can be considerably enhanced using the proposals, along with rate-distortion performance when compared against original projection scheme and HEVC-based or JPEG Pleno-based coding approaches.      
### 16.Adaptive Frequency Band Selection for Accurate and Fast Positioning utilizing SOPs  [ :arrow_down: ](https://arxiv.org/pdf/2206.04312.pdf)
>  Signals of opportunity (SOPs) are a promising technique that can be used for relative positioning in areas where global navigation satellite system (GNSS) information is unreliable or unavailable. This technique processes features of the various signals transmitted over a broad wireless spectrum to enable a receiver to position itself in space. This work examines the frequency selection problem in order to achieve fast and accurate positioning using only the received signal strength (RSS) of the surrounding signals. Starting with a prior belief, the problem of searching for a frequency band that best matches a predicted location trajectory is investigated. To maximize the accuracy of the position estimate, a ranking-and-selection problem is mathematically formulated. A knowledge-gradient (KG) algorithm from optimal learning theory is proposed that uses correlations in the Bayesian prior beliefs of the frequency band values to dramatically reduce the algorithm's processing time. The technique is experimentally tested for a practical scenario of an unmanned aerial vehicle (UAV) moving around a GPS-denied environment, with obtained results demonstrating its validity and practical applicability.      
### 17.An Autonomous Drone System with Jamming and Relative Positioning Capabilities  [ :arrow_down: ](https://arxiv.org/pdf/2206.04307.pdf)
>  As the number of unauthorized operations of Unmanned Aerial Vehicles (UAVs) is rising, the implementation of a versatile counter-drone system is becoming a necessity. In this work, we develop a drone-based counter-drone system, that employs algorithms for detecting and tracking a rogue drone, in conjunction with wireless interception capabilities to jointly jam the rogue drone while achieving self positioning for the pursuer drone. In the proposed system a software-defined-radio (SDR) is used for switching between jamming transmissions and spectrum sweeping functionalities to achieve the desired GPS disruption and self-localization, respectively. Extensive field experiments demonstrate the effectiveness of the proposed solution in a realworld environment under various parameter settings.      
### 18.Context-based out-of-vocabulary word recovery for ASR systems in Indian languages  [ :arrow_down: ](https://arxiv.org/pdf/2206.04305.pdf)
>  Detecting and recovering out-of-vocabulary (OOV) words is always challenging for Automatic Speech Recognition (ASR) systems. Many existing methods focus on modeling OOV words by modifying acoustic and language models and integrating context words cleverly into models. To train such complex models, we need a large amount of data with context words, additional training time, and increased model size. However, after getting the ASR transcription to recover context-based OOV words, the post-processing method has not been explored much. In this work, we propose a post-processing technique to improve the performance of context-based OOV recovery. We created an acoustically boosted language model with a sub-graph made at phone level with an OOV words list. We proposed two methods to determine a suitable cost function to retrieve the OOV words based on the context. The cost function is defined based on phonetic and acoustic knowledge for matching and recovering the correct context words in the decode. The effectiveness of the proposed cost function is evaluated at both word-level and sentence-level. The evaluation results show that this approach can recover an average of 50% context-based OOV words across multiple categories.      
### 19.On the Performance of UAV Relaying with Reconfigurable Antenna and Media Based Modulation in the Presence of Shadowed Fading  [ :arrow_down: ](https://arxiv.org/pdf/2206.04302.pdf)
>  Unmanned aerial vehicles (UAVs) have attracted significant interest from the academia and industry most recently. Motivated by the wide usage of UAVs, this paper considers UAV communication with reconfigurable antenna (RA) in the presence of fading and shadowing effects which occur due to tall buildings and skyscrapers in urban areas. More precisely, RA offers to receive information through mirror activation patterns (MAPs) so that it can achieve a receive diversity with decreased error probability by using only one radio frequency (RF) chain. Also, media based modulation (MBM) technique for data transmission with MAPs can be exploited by using RAs with reduced cost. To quantify the performance of the proposed UAV system, we derive a tight upper bound for the overall error probability by considering approximated channel model to the standardization studies for UAVs. The results have shown that RAs can make the overall system more resilient to shadowing and fading effects in terms of error performance, and they are energy efficient.      
### 20.A No-Reference Deep Learning Quality Assessment Method for Super-resolution Images Based on Frequency Maps  [ :arrow_down: ](https://arxiv.org/pdf/2206.04289.pdf)
>  To support the application scenarios where high-resolution (HR) images are urgently needed, various single image super-resolution (SISR) algorithms are developed. However, SISR is an ill-posed inverse problem, which may bring artifacts like texture shift, blur, etc. to the reconstructed images, thus it is necessary to evaluate the quality of super-resolution images (SRIs). Note that most existing image quality assessment (IQA) methods were developed for synthetically distorted images, which may not work for SRIs since their distortions are more diverse and complicated. Therefore, in this paper, we propose a no-reference deep-learning image quality assessment method based on frequency maps because the artifacts caused by SISR algorithms are quite sensitive to frequency information. Specifically, we first obtain the high-frequency map (HM) and low-frequency map (LM) of SRI by using Sobel operator and piecewise smooth image approximation. Then, a two-stream network is employed to extract the quality-aware features of both frequency maps. Finally, the features are regressed into a single quality value using fully connected layers. The experimental results show that our method outperforms all compared IQA models on the selected three super-resolution quality assessment (SRQA) databases.      
### 21.The leaky integrator that could: Or recursive polynomial regression for online signal analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.04284.pdf)
>  Fitting a local polynomial model to a noisy sequence of uniformly sampled observations or measurements (i.e. regressing) by minimizing the sum of weighted squared errors (i.e. residuals) may be used to design digital filters for a diverse range of signal-analysis problems, such as detection, classification and tracking (i.e. smoothing or state estimation), in biomedical, financial, and aerospace applications, for instance. Furthermore, the recursive realization of such filters, using a network of so-called leaky integrators, yields simple digital components with a low computational complexity that are ideal in embedded online sensing systems with high data rates. Target tracking, pulse-edge detection, peak detection and anomaly/change detection are considered in this tutorial as illustrative examples. <br>Erlang-weighted polynomial regression provides a design framework within which the various design trade-offs of state estimators (e.g. bias errors vs. random errors) and IIR smoothers (e.g. frequency isolation vs. time localization) may be intuitively balanced. Erlang weights are configured using a smoothing parameter which determines the decay rate of the exponential tail; and a shape parameter which may be used to discount more recent data, so that a greater relative emphasize is placed on a past time interval. In Morrison's 1969 treatise on sequential smoothing and prediction, the exponential weight and the Laguerre polynomials that are orthogonal with respect to this weight, are described in detail; however, more general Erlang weights and the resulting associated Laguerre polynomials are not considered there, nor have they been covered in detail elsewhere since. Thus, one of the purposes of this tutorial is to explain how Erlang weights may be used to shape and improve the (impulse and frequency) response of recursive regression filters.      
### 22.Observation Site Selection for Physical Model Parameter Estimation toward Process-Driven Seismic Wavefield Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2206.04273.pdf)
>  The seismic data not only acquired by seismometers but also acquired by vibrometers installed in buildings and infrastructure and accelerometers installed in smartphones will be certainly utilized for seismic research in the near future. Since it is impractical to utilize all the seismic big data in terms of the computational cost, methods which can select observation sites depending on the purpose are indispensable. We propose an observation site selection method for the accurate reconstruction of the seismic wavefield by process-driven approaches. The proposed method selects observation sites suitable for accurately estimating physical model parameters such as subsurface structures and source information to be input into a numerical simulation of the seismic wavefield. The seismic wavefield is reconstructed by the numerical simulation using the parameters estimated based on the observed signals at only observation sites selected by the proposed method. The observation site selection in the proposed method is based on the sensitivity of each observation site candidate to the physical model parameters; the matrix corresponding to the sensitivity is constructed by approximately calculating the derivatives based on the simulations, and then, observation sites are selected by evaluating the quantity of the sensitivity matrix based on the D-optimality criterion proposed in the optimal design of experiments. In the present study, physical knowledge on the sensitivity to the parameters such as seismic velocity, layer thickness, and hypocenter location was obtained by investigating the characteristics of the sensitivity matrix. Furthermore, the effectiveness of the proposed method was shown by verifying the accuracy of seismic wavefield reconstruction using the observation sites selected by the proposed method.      
### 23.Formation Tracking for a Multi-Auv System Based on an Adaptive Sliding Mode Method in the Water Flow Environment  [ :arrow_down: ](https://arxiv.org/pdf/2206.04264.pdf)
>  In this paper, formation tracking for a multi-AUV system (MAS) using an improved adaptive sliding mode control method is studied in the Three Dimensional (3-D) underwater environment. Firstly, the kinematics model and the dynamic model of the AUVs are given as the Six Dimensions of Freedom (6-DOF) considered. Then, control law based on the mathematical model of the AUVs is proposed based on the improved sliding mode method. A second order sliding mode control method is adopted to eliminate the chatting phenomenon of the controller. Thirdly, considering the water flow in the underwater working environment of the AUVs, an adaptive module is added to the controller. With the adaptive approach, the finite disturbances caused by water flow could be handled with the controller. The proposed method achieves stability by substituting an adaptive continuous term for the switching term in the controller. At last, a robust sliding mode controller with continuous model predictive control strategy for the multi-AUV system is developed to achieve leader-follower formation tracking under the presence of bounded flow disturbances, and simulations are implemented to confirm the effectiveness of the proposed method.      
### 24.An Optimization Method-Assisted Ensemble Deep Reinforcement Learning Algorithm to Solve Unit Commitment Problems  [ :arrow_down: ](https://arxiv.org/pdf/2206.04249.pdf)
>  Unit commitment (UC) is a fundamental problem in the day-ahead electricity market, and it is critical to solve UC problems efficiently. Mathematical optimization techniques like dynamic programming, Lagrangian relaxation, and mixed-integer quadratic programming (MIQP) are commonly adopted for UC problems. However, the calculation time of these methods increases at an exponential rate with the amount of generators and energy resources, which is still the main bottleneck in industry. Recent advances in artificial intelligence have demonstrated the capability of reinforcement learning (RL) to solve UC problems. Unfortunately, the existing research on solving UC problems with RL suffers from the curse of dimensionality when the size of UC problems grows. To deal with these problems, we propose an optimization method-assisted ensemble deep reinforcement learning algorithm, where UC problems are formulated as a Markov Decision Process (MDP) and solved by multi-step deep Q-learning in an ensemble framework. The proposed algorithm establishes a candidate action set by solving tailored optimization problems to ensure a relatively high performance and the satisfaction of operational constraints. Numerical studies on IEEE 118 and 300-bus systems show that our algorithm outperforms the baseline RL algorithm and MIQP. Furthermore, the proposed algorithm shows strong generalization capacity under unforeseen operational conditions.      
### 25.Manifold Graph Signal Restoration using Gradient Graph Laplacian Regularizer  [ :arrow_down: ](https://arxiv.org/pdf/2206.04245.pdf)
>  In the graph signal processing (GSP) literature, graph Laplacian regularizer (GLR) was used for signal restoration to promote smooth reconstructions with respect to the underlying graph -- typically signals that are (piecewise) constant. However, for graph signals that are (piecewise) planar, GLR may suffer from the well-known "staircase" effect. In this paper, focusing on manifold graphs -- sets of uniform discrete samples on low-dimensional continuous manifolds -- we generalize GLR to gradient graph Laplacian regularizer (GGLR) that provably promotes piecewise planar (PWP) signal reconstruction. Specifically, for a graph endowed with latent space coordinates (e.g., 2D images, 3D point clouds), we first define a gradient operator, using which we construct a higher-order gradient graph for the computed gradients in each latent dimension. This maps to a gradient-induced nodal graph (GNG) and a Laplacian matrix for a signed graph that is provably positive semi-definite (PSD), thus suitable for quadratic regularization. For manifold graphs without explicit latent coordinates, we propose a fast parameter-free spectral method to first compute latent space coordinates for graph nodes based on generalized eigenvectors. We derive the means-square-error minimizing weight parameter for GGLR efficiently, trading off bias and variance of the signal estimate. Experimental results show that GGLR outperformed previous graph signal priors like GLR and graph total variation (GTV) in a range of graph signal restoration tasks.      
### 26.A Sparse Polynomial Chaos Expansion-Based Method for Probabilistic Transient Stability Assessment and Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2206.04244.pdf)
>  This paper proposes an adaptive sparse polynomial chaos expansion(PCE)-based method to quantify the impacts of uncertainties on critical clearing time (CCT) that is an important index in transient stability analysis. The proposed method can not only give fast and accurate estimations for the probabilistic characteristics (e.g., mean, variance, probability density function) of the probabilistic CCT (PCCT), but also provides crucial information about the sensitivity of random inputs with respect to the variance of PCCT. Utilizing the sensitivity information, mitigation measures can be developed for transient stability enhancement. Numerical studies on the WSCC 9-bus system demonstrate the high accuracy and efficiency of the proposed method compared to the Monte Carlo simulation method. The provided sensitivity information and the effectiveness of mitigation measures in transient stability enhancement are also verified.      
### 27.Cardiac Adipose Tissue Segmentation via Image-Level Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2206.04238.pdf)
>  Automatically identifying the structural substrates underlying cardiac abnormalities can potentially provide real-time guidance for interventional procedures. With the knowledge of cardiac tissue substrates, the treatment of complex arrhythmias such as atrial fibrillation and ventricular tachycardia can be further optimized by detecting arrhythmia substrates to target for treatment (i.e., adipose) and identifying critical structures to avoid. Optical coherence tomography (OCT) is a real-time imaging modality that aids in addressing this need. Existing approaches for cardiac image analysis mainly rely on fully supervised learning techniques, which suffer from the drawback of workload on labor-intensive annotation process of pixel-wise labeling. To lessen the need for pixel-wise labeling, we develop a two-stage deep learning framework for cardiac adipose tissue segmentation using image-level annotations on OCT images of human cardiac substrates. In particular, we integrate class activation mapping with superpixel segmentation to solve the sparse tissue seed challenge raised in cardiac tissue segmentation. Our study bridges the gap between the demand on automatic tissue analysis and the lack of high-quality pixel-wise annotations. To the best of our knowledge, this is the first study that attempts to address cardiac tissue segmentation on OCT images via weakly supervised learning techniques. Within an in-vitro human cardiac OCT dataset, we demonstrate that our weakly supervised approach on image-level annotations achieves comparable performance as fully supervised methods trained on pixel-wise annotations.      
### 28.Deep Estimation of Speckle Statistics Parametric Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.04145.pdf)
>  Quantitative Ultrasound (QUS) provides important information about the tissue properties. QUS parametric image can be formed by dividing the envelope data into small overlapping patches and computing different speckle statistics such as parameters of the Nakagami and Homodyned K-distributions (HK-distribution). The calculated QUS parametric images can be erroneous since only a few independent samples are available inside the patches. Another challenge is that the envelope samples inside the patch are assumed to come from the same distribution, an assumption that is often violated given that the tissue is usually not homogenous. In this paper, we propose a method based on Convolutional Neural Networks (CNN) to estimate QUS parametric images without patching. We construct a large dataset sampled from the HK-distribution, having regions with random shapes and QUS parameter values. We then use a well-known network to estimate QUS parameters in a multi-task learning fashion. Our results confirm that the proposed method is able to reduce errors and improve border definition in QUS parametric images.      
### 29.An Improved Deep Convolutional Neural Network by Using Hybrid Optimization Algorithms to Detect and Classify Brain Tumor Using Augmented MRI Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.04056.pdf)
>  Automated brain tumor detection is becoming a highly considerable medical diagnosis research. In recent medical diagnoses, detection and classification are highly considered to employ machine learning and deep learning techniques. Nevertheless, the accuracy and performance of current models need to be improved for suitable treatments. In this paper, an improvement in deep convolutional learning is ensured by adopting enhanced optimization algorithms, Thus, Deep Convolutional Neural Network (DCNN) based on improved Harris Hawks Optimization (HHO), called G-HHO has been considered. This hybridization features Grey Wolf Optimization (GWO) and HHO to give better results, limiting the convergence rate and enhancing performance. Moreover, Otsu thresholding is adopted to segment the tumor portion that emphasizes brain tumor detection. Experimental studies are conducted to validate the performance of the suggested method on a total number of 2073 augmented MRI images. The technique's performance was ensured by comparing it with the nine existing algorithms on huge augmented MRI images in terms of accuracy, precision, recall, f-measure, execution time, and memory usage. The performance comparison shows that the DCNN-G-HHO is much more successful than existing methods, especially on a scoring accuracy of 97%. Additionally, the statistical performance analysis indicates that the suggested approach is faster and utilizes less memory at identifying and categorizing brain tumor cancers on the MR images. The implementation of this validation is conducted on the Python platform. The relevant codes for the proposed approach are available at: <a class="link-external link-https" href="https://github.com/bryarahassan/DCNN-G-HHO" rel="external noopener nofollow">this https URL</a>.      
### 30.BigVGAN: A Universal Neural Vocoder with Large-Scale Training  [ :arrow_down: ](https://arxiv.org/pdf/2206.04658.pdf)
>  Despite recent progress in generative adversarial network(GAN)-based vocoders, where the model generates raw waveform conditioned on mel spectrogram, it is still challenging to synthesize high-fidelity audio for numerous speakers across varied recording environments. In this work, we present BigVGAN, a universal vocoder that generalizes well under various unseen conditions in zero-shot setting. We introduce periodic nonlinearities and anti-aliased representation into the generator, which brings the desired inductive bias for waveform synthesis and significantly improves audio quality. Based on our improved generator and the state-of-the-art discriminators, we train our GAN vocoder at the largest scale up to 112M parameters, which is unprecedented in the literature. In particular, we identify and address the training instabilities specific to such scale, while maintaining high-fidelity output without over-regularization. Our BigVGAN achieves the state-of-the-art zero-shot performance for various out-of-distribution scenarios, including new speakers, novel languages, singing voices, music and instrumental audio in unseen (even noisy) recording environments. We will release our code and model at: <a class="link-external link-https" href="https://github.com/NVIDIA/BigVGAN" rel="external noopener nofollow">this https URL</a>      
### 31.Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.04635.pdf)
>  In this extended abstract, we consider a dual-hop hybrid visible light communication (VLC)/radio frequency (RF) scenario where energy is harvested during the VLC transmission and used to power the relay. We formulate the optimization problem in the sense of maximizing the data rate under the assumption of decode-and-forward (DF) relaying. As the design parameters, the direct current (DC) bias and the assigned time duration for energy harvesting are taken into account. In particular, the joint optimization is split into two subproblems, which are then cyclically solved. Additional details and numerical results are left to be presented in the full paper.      
### 32.Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations  [ :arrow_down: ](https://arxiv.org/pdf/2206.04632.pdf)
>  Learning from demonstration (LfD) methods have shown promise for solving multi-step tasks; however, these approaches do not guarantee successful reproduction of the task given disturbances. In this work, we identify the roots of such a challenge as the failure of the learned continuous policy to satisfy the discrete plan implicit in the demonstration. By utilizing modes (rather than subgoals) as the discrete abstraction and motion policies with both mode invariance and goal reachability properties, we prove our learned continuous policy can simulate any discrete plan specified by a Linear Temporal Logic (LTL) formula. Consequently, the imitator is robust to both task- and motion-level disturbances and guaranteed to achieve task success. Project page: <a class="link-external link-https" href="https://sites.google.com/view/ltl-ds" rel="external noopener nofollow">this https URL</a>      
### 33.AttX: Attentive Cross-Connections for Fusion of Wearable Signals in Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.04625.pdf)
>  We propose cross-modal attentive connections, a new dynamic and effective technique for multimodal representation learning from wearable data. Our solution can be integrated into any stage of the pipeline, i.e., after any convolutional layer or block, to create intermediate connections between individual streams responsible for processing each modality. Additionally, our method benefits from two properties. First, it can share information uni-directionally (from one modality to the other) or bi-directionally. Second, it can be integrated into multiple stages at the same time to further allow network gradients to be exchanged in several touch-points. We perform extensive experiments on three public multimodal wearable datasets, WESAD, SWELL-KW, and CASE, and demonstrate that our method can effectively regulate and share information between different modalities to learn better representations. Our experiments further demonstrate that once integrated into simple CNN-based multimodal solutions (2, 3, or 4 modalities), our method can result in superior or competitive performance to state-of-the-art and outperform a variety of baseline uni-modal and classical multimodal methods.      
### 34.Autonomous Precision Drone Landing with Fiducial Markers and a Gimbal-Mounted Camera for Active Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2206.04617.pdf)
>  Precision landing is a remaining challenge in autonomous drone flight, with no widespread solution. Fiducial markers provide a computationally cheap way for a drone to locate a landing pad and autonomously execute precision landings. However, most work in this field has depended on fixed, downward-facing cameras which restrict the ability of the drone to detect the marker. We present a method of autonomous landing that uses a gimbal-mounted camera to quickly search for the landing pad by simply spinning in place while tilting the camera up and down, and to continually aim the camera at the landing pad during approach and landing. This method demonstrates successful search, tracking, and landing with 4 of 5 tested fiducial systems on a physical drone with no human intervention. Per fiducial system, we present the number of successful and unsuccessful landings, and the distributions of the distances from the drone to the center of the landing pad after each successful landing, with a statistical comparison among the systems. We also show representative examples of flight trajectories, marker tracking performance, and control outputs for each channel during the landing. Finally, we discuss qualitative strengths and weaknesses underlying the performance of each system.      
### 35.Linear Delta Arrays for Dexterous Distributed Manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2206.04596.pdf)
>  This paper presents a new type of distributed dexterous manipulators: delta arrays. Each delta array consists of a grid of linearly-actuated delta robots with compliant 3D-printed parallelogram links. These arrays can be used to perform planar transportation tasks, similar to smart conveyors. However, the deltas' additional degrees of freedom also afford a wide range of out-of-plane manipulations, as well as prehensile manipulations between sets of deltas. A delta array thus affords a wide range of distributed manipulation strategies. In this paper, we present the design of the delta arrays, including the individual deltas, a modular array structure, and distributed communication and control. We also construct and evaluate an 8x8 array using the proposed design. Our evaluations show that the resulting 192 DoF robot is capable of performing various coordinated distributed manipulations of a variety of objects, including translation, alignment, and prehensile squeezing.      
### 36.Revisiting End-to-End Speech-to-Text Translation From Scratch  [ :arrow_down: ](https://arxiv.org/pdf/2206.04571.pdf)
>  End-to-end (E2E) speech-to-text translation (ST) often depends on pretraining its encoder and/or decoder using source transcripts via speech recognition or text translation tasks, without which translation performance drops substantially. However, transcripts are not always available, and how significant such pretraining is for E2E ST has rarely been studied in the literature. In this paper, we revisit this question and explore the extent to which the quality of E2E ST trained on speech-translation pairs alone can be improved. We reexamine several techniques proven beneficial to ST previously, and offer a set of best practices that biases a Transformer-based E2E ST system toward training from scratch. Besides, we propose parameterized distance penalty to facilitate the modeling of locality in the self-attention model for speech. On four benchmarks covering 23 languages, our experiments show that, without using any transcripts or pretraining, the proposed system reaches and even outperforms previous studies adopting pretraining, although the gap remains in (extremely) low-resource settings. Finally, we discuss neural acoustic feature modeling, where a neural model is designed to extract acoustic features from raw speech signals directly, with the goal to simplify inductive biases and add freedom to the model in describing speech. For the first time, we demonstrate its feasibility and show encouraging results on ST tasks.      
### 37.Joint radar and communications with multicarrier chirp-based waveform  [ :arrow_down: ](https://arxiv.org/pdf/2206.04528.pdf)
>  We consider a multicarrier chirp-based waveform for joint radar and communication (JRC) systems and derive its time discrete periodic ambiguity function (AF). An advantage of the waveform is that it includes a set of waveform parameters (e.g., chirp rate) which together with the transmit sequence, can be selected to flexibly shape the AF to be thumbtack-like, or to be ridge-like, either along the delay axis or the Doppler axis. These shapes are applicable for different use cases, e.g., target detection or time- and frequency synchronization. The results show that better signal detection performance than OFDM and DFT-s-OFDM can be achieved on channels with large Doppler frequency. Furthermore, it is shown how transmit sequences can be selected in order to achieve 0 dB peak-to-average-power-ratio (PAPR) of the waveform.      
### 38.Large-Scale Crosstalk-Corrected Thermo-Optic Phase Shifter Arrays in Silicon Photonics  [ :arrow_down: ](https://arxiv.org/pdf/2206.04525.pdf)
>  We introduce a thermo-optic phase shifter (TOPS) array architecture with independent phase control of each phase shifter for large-scale and high-density photonic integrated circuits with two different control schemes: pulse amplitude modulation (PAM) and pulse width modulation (PWM). We realize a compact spiral TOPS and a 288-element high-density row-column TOPS array with this architecture and drive TOPS with waveforms of both control schemes and of different array sizes. We present a thermal excitation model and a finite difference method-based simulation to simulate large-scale TOPS arrays and compare both schemes experimentally and theoretically. We also analyze the effects of thermal crosstalk in the realized TOPS array and implement a thermal crosstalk correction algorithm with the developed model. The high-density TOPS array architecture and the thermal crosstalk correction algorithm pave the way for high-density TOPS arrays with independent phase control in large-scale photonic integrated circuits interfaced with electronics limited in voltage swing and bandwidth.      
### 39.Face-Dubbing++: Lip-Synchronous, Voice Preserving Translation of Videos  [ :arrow_down: ](https://arxiv.org/pdf/2206.04523.pdf)
>  In this paper, we propose a neural end-to-end system for voice preserving, lip-synchronous translation of videos. The system is designed to combine multiple component models and produces a video of the original speaker speaking in the target language that is lip-synchronous with the target speech, yet maintains emphases in speech, voice characteristics, face video of the original speaker. The pipeline starts with automatic speech recognition including emphasis detection, followed by a translation model. The translated text is then synthesized by a Text-to-Speech model that recreates the original emphases mapped from the original sentence. The resulting synthetic voice is then mapped back to the original speakers' voice using a voice conversion model. Finally, to synchronize the lips of the speaker with the translated audio, a conditional generative adversarial network-based model generates frames of adapted lip movements with respect to the input face image as well as the output of the voice conversion model. In the end, the system combines the generated video with the converted audio to produce the final output. The result is a video of a speaker speaking in another language without actually knowing it. To evaluate our design, we present a user study of the complete system as well as separate evaluations of the single components. Since there is no available dataset to evaluate our whole system, we collect a test set and evaluate our system on this test set. The results indicate that our system is able to generate convincing videos of the original speaker speaking the target language while preserving the original speaker's characteristics. The collected dataset will be shared.      
### 40.AAM-Gym: Artificial Intelligence Testbed for Advanced Air Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2206.04513.pdf)
>  We introduce AAM-Gym, a research and development testbed for Advanced Air Mobility (AAM). AAM has the potential to revolutionize travel by reducing ground traffic and emissions by leveraging new types of aircraft such as electric vertical take-off and landing (eVTOL) aircraft and new advanced artificial intelligence (AI) algorithms. Validation of AI algorithms require representative AAM scenarios, as well as a fast time simulation testbed to evaluate their performance. Until now, there has been no such testbed available for AAM to enable a common research platform for individuals in government, industry, or academia. MIT Lincoln Laboratory has developed AAM-Gym to address this gap by providing an ecosystem to develop, train, and validate new and established AI algorithms across a wide variety of AAM use-cases. In this paper, we use AAM-Gym to study the performance of two reinforcement learning algorithms on an AAM use-case, separation assurance in AAM corridors. The performance of the two algorithms is demonstrated based on a series of metrics provided by AAM-Gym, showing the testbed's utility to AAM research.      
### 41.Towards Understanding Graph Neural Networks: An Algorithm Unrolling Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2206.04471.pdf)
>  The graph neural network (GNN) has demonstrated its superior performance in various applications. The working mechanism behind it, however, remains mysterious. GNN models are designed to learn effective representations for graph-structured data, which intrinsically coincides with the principle of graph signal denoising (GSD). Algorithm unrolling, a "learning to optimize" technique, has gained increasing attention due to its prospects in building efficient and interpretable neural network architectures. In this paper, we introduce a class of unrolled networks built based on truncated optimization algorithms (e.g., gradient descent and proximal gradient descent) for GSD problems. They are shown to be tightly connected to many popular GNN models in that the forward propagations in these GNNs are in fact unrolled networks serving specific GSDs. Besides, the training process of a GNN model can be seen as solving a bilevel optimization problem with a GSD problem at the lower level. Such a connection brings a fresh view of GNNs, as we could try to understand their practical capabilities from their GSD counterparts, and it can also motivate designing new GNN models. Based on the algorithm unrolling perspective, an expressive model named UGDGNN, i.e., unrolled gradient descent GNN, is further proposed which inherits appealing theoretical properties. Extensive numerical simulations on seven benchmark datasets demonstrate that UGDGNN can achieve superior or competitive performance over the state-of-the-art models.      
### 42.Regret Analysis of Certainty Equivalence Policies in Continuous-Time Linear-Quadratic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.04434.pdf)
>  This work studies theoretical performance guarantees of a ubiquitous reinforcement learning policy for controlling the canonical model of stochastic linear-quadratic system. We show that randomized certainty equivalent policy addresses the exploration-exploitation dilemma for minimizing quadratic costs in linear dynamical systems that evolve according to stochastic differential equations. More precisely, we establish square-root of time regret bounds, indicating that randomized certainty equivalent policy learns optimal control actions fast from a single state trajectory. Further, linear scaling of the regret with the number of parameters is shown. The presented analysis introduces novel and useful technical approaches, and sheds light on fundamental challenges of continuous-time reinforcement learning.      
### 43.Security-Reliability Trade-Off Analysis for SWIPT- and AF-Based IoT Networks with Friendly Jammers  [ :arrow_down: ](https://arxiv.org/pdf/2206.04428.pdf)
>  Radio-frequency (RF) energy harvesting (EH) in wireless relaying networks has attracted considerable recent interest, especially for supplying energy to relay nodes in Internet-of-Things (IoT) systems to assist the information exchange between a source and a destination. Moreover, limited hardware, computational resources, and energy availability of IoT devices have raised various security challenges. To this end, physical layer security (PLS) has been proposed as an effective alternative to cryptographic methods for providing information security. In this study, we propose a PLS approach for simultaneous wireless information and power transfer (SWIPT)-based half-duplex (HD) amplify-and-forward (AF) relaying systems in the presence of an eavesdropper. Furthermore, we take into account both static power splitting relaying (SPSR) and dynamic power splitting relaying (DPSR) to thoroughly investigate the benefits of each one. To further enhance secure communication, we consider multiple friendly jammers to help prevent wiretapping attacks from the eavesdropper. More specifically, we provide a reliability and security analysis by deriving closed-form expressions of outage probability (OP) and intercept probability (IP), respectively, for both the SPSR and DPSR schemes. Then, simulations are also performed to validate our analysis and the effectiveness of the proposed schemes. Specifically, numerical results illustrate the non-trivial trade-off between reliability and security of the proposed system. In addition, we conclude from the simulation results that the proposed DPSR scheme outperforms the SPSR-based scheme in terms of OP and IP under the influences of different parameters on system performance.      
### 44.Neonatal EEG graded for severity of background abnormalities in hypoxic-ischaemic encephalopathy  [ :arrow_down: ](https://arxiv.org/pdf/2206.04420.pdf)
>  This report describes a set of neonatal electroencephalogram (EEG) recordings graded according to the severity of abnormalities in the background pattern. The dataset consists of 169 hours of multichannel EEG from 53 neonates recorded in a neonatal intensive care unit. All neonates received a diagnosis of hypoxic-ischaemic encephalopathy (HIE), the most common cause of brain injury in full term infants. For each neonate, multiple 1-hour epochs of good quality EEG were selected and then graded for background abnormalities. The grading system assesses EEG attributes such as amplitude and frequency, continuity, sleep-wake cycling, symmetry and synchrony, and abnormal waveforms. Background severity was then categorised into 4 grades: normal or mildly abnormal, moderately abnormal, severely abnormal, and inactive EEG. The data can be used as a reference set of multi-channel EEG for neonates with HIE, for EEG training purposes, or for developing and evaluating automated grading algorithms.      
### 45.Learning Vehicle Trajectory Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2206.04409.pdf)
>  The linear Kalman filter is commonly used for vehicle tracking. This filter requires knowledge of the vehicle trajectory and the statistics of the system and measurement models. In real-life scenarios, prior assumptions made while determining those models do not hold. As a consequence, the overall filter performance degrades and in some situations the estimated states diverge. To overcome the uncertainty in the {vehicle kinematic} trajectory modeling, additional artificial process noise may be added to the model or different types of adaptive filters may be employed. This paper proposes {a hybrid} adaptive Kalman filter based on {model and} machine learning algorithms. First, recurrent neural networks are employed to learn the vehicle's geometrical and kinematic features. In turn, those features are plugged into a supervised learning model, thereby providing the actual process noise covariance to be used in the Kalman framework. The proposed approach is evaluated and compared to six other adaptive filters using the Oxford RobotCar dataset. The proposed framework can be implemented in other estimation problems to accurately determine the process noise covariance in real-time scenarios.      
### 46.Unsupervised Learning of the Total Variation Flow  [ :arrow_down: ](https://arxiv.org/pdf/2206.04406.pdf)
>  The total variation (TV) flow generates a scale-space representation of an image based on the TV functional. This gradient flow observes desirable features for images such as sharp edges and enables spectral, scale, and texture analysis. The standard numerical approach for TV flow requires solving multiple non-smooth optimisation problems. Even with state-of-the-art convex optimisation techniques, this is often prohibitively expensive and strongly motivates the use of alternative, faster approaches. Inspired by and extending the framework of physics-informed neural networks (PINNs), we propose the TVflowNET, a neural network approach to compute the solution of the TV flow given an initial image and a time instance. We significantly speed up the computation time by more than one order of magnitude and show that the TVflowNET approximates the TV flow solution with high fidelity. This is a preliminary report, more details are to follow.      
### 47.The Classical Capacity of Quantum Jackson Networks with Waiting Time-Dependent Erasures  [ :arrow_down: ](https://arxiv.org/pdf/2206.04262.pdf)
>  We study the fundamental limits of classical communication using quantum states that decohere as they traverse through a network of queues. We consider a network of Markovian queues, known as a Jackson network, with a single source or multiple sources and a single destination. Qubits are communicated through this network with inevitable buffering at intermediate nodes. We model each node as a `queue-channel,' wherein as the qubits wait in buffer, they continue to interact with the environment and suffer a waiting time-dependent noise. Focusing on erasures, we first obtain explicit classical capacity expressions for simple topologies such as tandem queue-channel and parallel queue-channel. Using these as building blocks, we characterize the classical capacity of a general quantum Jackson network with waiting time-dependent erasures. Throughout, we study two types of quantum networks, namely, (i) Repeater-assisted and (ii) Repeater-less. We also obtain optimal pumping rates and routing probabilities to maximize capacity in simple topologies. More broadly, our work quantifies the impact of delay-induced decoherence on the fundamental limits of classical communication over quantum networks.      
### 48.Massive MIMO Hybrid Precoding for LEO Satellite Communications With Twin-Resolution Phase Shifters and Nonlinear Power Amplifiers  [ :arrow_down: ](https://arxiv.org/pdf/2206.04250.pdf)
>  The massive multiple-input multiple-output (MIMO) transmission technology has recently attracted much attention in the non-geostationary, e.g., low earth orbit (LEO) satellite communication (SATCOM) systems since it can significantly improve the energy efficiency (EE) and spectral efficiency. In this work, we develop a hybrid analog/digital precoding technique in the massive MIMO LEO SATCOM downlink, which reduces the onboard hardware complexity and power consumption. In the proposed scheme, the analog precoder is implemented via a more practical twin-resolution phase shifting (TRPS) network to make a meticulous tradeoff between the power consumption and array gain. In addition, we consider and study the impact of the distortion effect of the nonlinear power amplifiers (NPAs) in the system design. By jointly considering all the above factors, we propose an efficient algorithmic approach for the TRPS-based hybrid precoding problem with NPAs. Numerical results show the EE gains considering the nonlinear distortion and the performance superiority of the proposed TRPS-based hybrid precoding scheme over the baselines.      
### 49.Enhancement of Healthcare Data Transmission using the Levenberg-Marquardt Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2206.04240.pdf)
>  In the healthcare system, patients are required to use wearable devices for the remote data collection and real-time monitoring of health data and the status of health conditions. This adoption of wearables results in a significant increase in the volume of data that is collected and transmitted. As the devices are run by small battery power, they can be quickly diminished due to the high processing requirements of the device for data collection and transmission. Given the importance attached to medical data, it is imperative that all transmitted data adhere to strict integrity and availability requirements. Reducing the volume of healthcare data and the frequency of transmission will improve the device battery life via using inference algorithm. There is an issue of improving transmission metrics with accuracy and efficiency, which trade-off each other such as increasing accuracy reduces the efficiency. This paper demonstrates that machine learning can be used to analyze complex health data metrics such as the accuracy and efficiency of data transmission to overcome the trade-off problem using the Levenberg-Marquardt algorithm to enhance both metrics by taking fewer samples to transmit whilst maintaining the accuracy. The algorithm is tested with a standard heart rate dataset to compare the metrics. The result shows that the LMA has best performed with an efficiency of 3.33 times for reduced sample data size and accuracy of 79.17%, which has the similar accuracies in 7 different sampling cases adopted for testing but demonstrates improved efficiency. These proposed methods significantly improved both metrics using machine learning without sacrificing a metric over the other compared to the existing methods with high efficiency.      
### 50.Min-Max Latency Optimization for IRS-aided Cell-Free Mobile Edge Computing Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.04205.pdf)
>  Mobile-edge computing (MEC) is expected to provide low-latency computation service for wireless devices (WDs). However, when WDs are located at cell edge or communication links between base stations (BSs) and WDs are blocked, the offloading latency will be large. To address this issue, we propose an intelligent reflecting surface (IRS)-assisted cell-free MEC system consisting of multiple BSs and IRSs for improving the transmission environment. Consequently, we formulate a min-max latency optimization problem by jointly designing multi-user detection (MUD) matrices, IRSs' reflecting beamforming vectors, WDs' transmit power and edge computing resource, subject to constraints on edge computing capability and IRSs phase shifts. To solve it, an alternating optimization algorithm based on the block coordinate descent (BCD) technique is proposed, in which the original non-convex problem is decoupled into two subproblems for alternately optimizing computing and communication parameters. In particular, we optimize the MUD matrix based on the second-order cone programming (SOCP) technique, and then develop two efficient algorithms to optimize IRSs' reflecting vectors based on the semi-definite relaxation (SDR) and successive convex approximation (SCA) techniques, respectively. Numerical results show that employing IRSs in cell-free MEC systems outperforms conventional MEC systems, resulting in up to about 60% latency reduction can be attained. Moreover, numerical results confirm that our proposed algorithms enjoy a fast convergence, which is beneficial for practical implementation.      
### 51.Reinforced Inverse Scattering  [ :arrow_down: ](https://arxiv.org/pdf/2206.04186.pdf)
>  Inverse wave scattering aims at determining the properties of an object using data on how the object scatters incoming waves. In order to collect information, sensors are put in different locations to send and receive waves from each other. The choice of sensor positions and incident wave frequencies determines the reconstruction quality of scatterer properties. This paper introduces reinforcement learning to develop precision imaging that decides sensor positions and wave frequencies adaptive to different scatterers in an intelligent way, thus obtaining a significant improvement in reconstruction quality with limited imaging resources. Extensive numerical results will be provided to demonstrate the superiority of the proposed method over existing methods.      
### 52.CASS: Cross Architectural Self-Supervision for Medical Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.04170.pdf)
>  Recent advances in Deep Learning and Computer Vision have alleviated many of the bottlenecks, allowing algorithms to be label-free with better performance. Specifically, Transformers provide a global perspective of the image, which Convolutional Neural Networks (CNN) lack by design. Here we present Cross Architectural Self-Supervision, a novel self-supervised learning approach which leverages transformers and CNN simultaneously, while also being computationally accessible to general practitioners via easily available cloud services. Compared to existing state-of-the-art self-supervised learning approaches, we empirically show CASS trained CNNs, and Transformers gained an average of 8.5% with 100% labelled data, 7.3% with 10% labelled data, and 11.5% with 1% labelled data, across three diverse datasets. Notably, one of the employed datasets included histopathology slides of an autoimmune disease, a topic underrepresented in Medical Imaging and has minimal data. In addition, our findings reveal that CASS is twice as efficient as other state-of-the-art methods in terms of training time.      
### 53.DRHDR: A Dual branch Residual Network for Multi-Bracket High Dynamic Range Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2206.04124.pdf)
>  We introduce DRHDR, a Dual branch Residual Convolutional Neural Network for Multi-Bracket HDR Imaging. To address the challenges of fusing multiple brackets from dynamic scenes, we propose an efficient dual branch network that operates on two different resolutions. The full resolution branch uses a Deformable Convolutional Block to align features and retain high-frequency details. A low resolution branch with a Spatial Attention Block aims to attend wanted areas from the non-reference brackets, and suppress displaced features that could incur on ghosting artifacts. By using a dual branch approach we are able to achieve high quality results while constraining the computational resources required to estimate the HDR results.      
