# ArXiv eess --Fri, 3 Jun 2022
### 1.Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.01175.pdf)
>  In the last few years, researchers have applied machine learning strategies in the context of vehicular platoons to increase the safety and efficiency of cooperative transportation. Reinforcement Learning methods have been employed in the longitudinal spacing control of Cooperative Adaptive Cruise Control systems, but to date, none of those studies have addressed problems of disturbance rejection in such scenarios. Characteristics such as uncertain parameters in the model and external interferences may prevent agents from reaching null-spacing errors when traveling at cruising speed. On the other hand, complex communication topologies lead to specific training processes that can not be generalized to other contexts, demanding re-training every time the configuration changes. Therefore, in this paper, we propose an approach to generalize the training process of a vehicular platoon, such that the acceleration command of each agent becomes independent of the network topology. Also, we have modeled the acceleration input as a term with integral action, such that the Convolutional Neural Network is capable of learning corrective actions when the states are disturbed by unknown effects. We illustrate the effectiveness of our proposal with experiments using different network topologies, uncertain parameters, and external forces. Comparative analyses, in terms of the steady-state error and overshoot response, were conducted against the state-of-the-art literature. The findings offer new insights concerning generalization and robustness of using Reinforcement Learning in the control of autonomous platoons.      
### 2.Comparing Conventional and Deep Feature Models for Classifying Fundus Photography of Hemorrhages  [ :arrow_down: ](https://arxiv.org/pdf/2206.01118.pdf)
>  Diabetic retinopathy is an eye-related pathology creating abnormalities and causing visual impairment, proper treatment of which requires identifying irregularities. This research uses a hemorrhage detection method and compares classification of conventional and deep features. Especially, method identifies hemorrhage connected with blood vessels or reside at retinal border and reported challenging. Initially, adaptive brightness adjustment and contrast enhancement rectify degraded images. Prospective locations of hemorrhages are estimated by a Gaussian matched filter, entropy thresholding, and morphological operation. Hemorrhages are segmented by a novel technique based on regional variance of intensities. Features are then extracted by conventional methods and deep models for training support vector machines, and results evaluated. Evaluation metrics for each model are promising, but findings suggest that comparatively, deep models are more effective than conventional features.      
### 3.Noise2NoiseFlow: Realistic Camera Noise Modeling without Clean Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.01103.pdf)
>  Image noise modeling is a long-standing problem with many applications in computer vision. Early attempts that propose simple models, such as signal-independent additive white Gaussian noise or the heteroscedastic Gaussian noise model (a.k.a., camera noise level function) are not sufficient to learn the complex behavior of the camera sensor noise. Recently, more complex learning-based models have been proposed that yield better results in noise synthesis and downstream tasks, such as denoising. However, their dependence on supervised data (i.e., paired clean images) is a limiting factor given the challenges in producing ground-truth images. This paper proposes a framework for training a noise model and a denoiser simultaneously while relying only on pairs of noisy images rather than noisy/clean paired image data. We apply this framework to the training of the Noise Flow architecture. The noise synthesis and density estimation results show that our framework outperforms previous signal-processing-based noise models and is on par with its supervised counterpart. The trained denoiser is also shown to significantly improve upon both supervised and weakly supervised baseline denoising approaches. The results indicate that the joint training of a denoiser and a noise model yields significant improvements in the denoiser.      
### 4.A Dual-fusion Semantic Segmentation Framework With GAN For SAR Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.01096.pdf)
>  Deep learning based semantic segmentation is one of the popular methods in remote sensing image segmentation. In this paper, a network based on the widely used encoderdecoder architecture is proposed to accomplish the synthetic aperture radar (SAR) images segmentation. With the better representation capability of optical images, we propose to enrich SAR images with generated optical images via the generative adversative network (GAN) trained by numerous SAR and optical images. These optical images can be used as expansions of original SAR images, thus ensuring robust result of segmentation. Then the optical images generated by the GAN are stitched together with the corresponding real images. An attention module following the stitched data is used to strengthen the representation of the objects. Experiments indicate that our method is efficient compared to other commonly used methods      
### 5.Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.01088.pdf)
>  Cancer is a fatal disease caused by a combination of genetic diseases and a variety of biochemical abnormalities. Lung and colon cancer have emerged as two of the leading causes of death and disability in humans. The histopathological detection of such malignancies is usually the most important component in determining the best course of action. Early detection of the ailment on either front considerably decreases the likelihood of mortality. Machine learning and deep learning techniques can be utilized to speed up such cancer detection, allowing researchers to study a large number of patients in a much shorter amount of time and at a lower cost. In this research work, we introduced a hybrid ensemble feature extraction model to efficiently identify lung and colon cancer. It integrates deep feature extraction and ensemble learning with high-performance filtering for cancer image datasets. The model is evaluated on histopathological (LC25000) lung and colon datasets. According to the study findings, our hybrid model can detect lung, colon, and (lung and colon) cancer with accuracy rates of 99.05%, 100%, and 99.30%, respectively. The study's findings show that our proposed strategy outperforms existing models significantly. Thus, these models could be applicable in clinics to support the doctor in the diagnosis of cancers.      
### 6.Multi-stage Moving Target Defense: A Security-enhanced D-FACTS Implementation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.01051.pdf)
>  In recent studies, moving target defense (MTD) has been applied to detect false data injection (FDI) attacks using distributed flexible AC transmission system (D-FACTS) devices. However, the inherent conflict between the security goals of MTD (i.e., detecting FDI attacks) and the economic goals of D-FACTS devices (i.e., reducing power losses) would impede the application of MTD in real systems. Moreover, the detection capabilities of existing MTDs are often insufficient. This paper proposes a multi-stage MTD (MMTD) approach to resolve these two issues by adding a group of designed security-oriented schemes before D-FACTS' economic-oriented scheme to detect FDI attacks. We keep these security-oriented schemes for a very short time interval and then revert to the economic-oriented scheme for the remaining time to ensure the economic requirements. We prove that a designed MMTD can significantly improve the detection capability compared to existing one-stage MTDs. We find the supremum of MMTD's detection capability and study its relationship with system topology and D-FACTS deployment. Meanwhile, a greedy algorithm is proposed to search the MMTD strategy to reach this supremum. Simulation results show that the proposed MMTD can achieve the supremum against FDI attacks while outperforming current MTD strategies on economic indicators.      
### 7.Self-supervised Learning of Audio Representations from Audio-Visual Data using Spatial Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2206.00970.pdf)
>  Learning from audio-visual data offers many possibilities to express correspondence between the audio and visual content, similar to the human perception that relates aural and visual information. In this work, we present a method for self-supervised representation learning based on audio-visual spatial alignment (AVSA), a more sophisticated alignment task than the audio-visual correspondence (AVC). In addition to the correspondence, AVSA also learns from the spatial location of acoustic and visual content. Based on 360$^\text{o}$ video and Ambisonics audio, we propose selection of visual objects using object detection, and beamforming of the audio signal towards the detected objects, attempting to learn the spatial alignment between objects and the sound they produce. We investigate the use of spatial audio features to represent the audio input, and different audio formats: Ambisonics, mono, and stereo. Experimental results show a 10 $\%$ improvement on AVSA for the first order ambisonics intensity vector (FOA-IV) in comparison with log-mel spectrogram features; the addition of object-oriented crops also brings significant performance increases for the human action recognition downstream task. A number of audio-only downstream tasks are devised for testing the effectiveness of the learnt audio feature representation, obtaining performance comparable to state-of-the-art methods on acoustic scene classification from ambisonic and binaural audio.      
### 8.Pronunciation Dictionary-Free Multilingual Speech Synthesis by Combining Unsupervised and Supervised Phonetic Representations  [ :arrow_down: ](https://arxiv.org/pdf/2206.00951.pdf)
>  This paper proposes a multilingual speech synthesis method which combines unsupervised phonetic representations (UPR) and supervised phonetic representations (SPR) to avoid reliance on the pronunciation dictionaries of target languages. In this method, a pretrained wav2vec 2.0 model is adopted to extract UPRs and a language-independent automatic speech recognition (LI-ASR) model is built with a connectionist temporal classification (CTC) loss to extract segment-level SPRs from the audio data of target languages. Then, an acoustic model is designed, which first predicts UPRs and SPRs from texts separately and then combines the predicted UPRs and SPRs to generate mel-spectrograms. The results of our experiments on six languages show that the proposed method outperformed the methods that directly predicted mel-spectrograms from character or phoneme sequences and the ablated models that utilized only UPRs or SPRs.      
### 9.Revisiting the Wireless Channel from Physical Layer Security Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2206.00936.pdf)
>  Security has emerged as one of the critical requirements in future wireless networks. Unlike traditional cryptography-based security, physical layer security (PLS) exploits various features of the random wireless channel to secure not only the information being communicated but the whole communication process from any type of attack. Future wireless networks are envisioned to feature new technologies such as re-configurable intelligent surfaces, massive multiple input multiple output, and sensing, to accommodate the emerging use-cases. Both, the new technologies and the new use-cases have been found to enrich the channel characteristics by unveiling some new channel features which can be readily exploited to facilitate PLS. This article surveys these new channel features to reveal their potential for PLS implementation. In the course of the article, the assessments of important qualities while selecting a certain channel feature for the PLS application are discussed. The importance of the channel control concept and sensing technologies that facilitate the accessibility of certain channel features are highlighted from the PLS perspective. Security attacks aimed at channel characteristics, rather than the communication itself, in order to disrupt PLS implementations are also discussed. Finally, the article summarizes the possible research direction for channel-based PLS.      
### 10.Multivariate Empirical Mode Decomposition of EEG for Mental State Detection at Localized Brain Lobes  [ :arrow_down: ](https://arxiv.org/pdf/2206.00926.pdf)
>  In this study, the Multivariate Empirical Mode Decomposition (MEMD) approach is applied to extract features from multi-channel EEG signals for mental state classification. MEMD is a data-adaptive analysis approach which is suitable particularly for multi-dimensional non-linear signals like EEG. Applying MEMD results in a set of oscillatory modes called intrinsic mode functions (IMFs). As the decomposition process is data-dependent, the IMFs vary in accordance with signal variation caused by functional brain activity. Among the extracted IMFs, it is found that those corresponding to high-oscillation modes are most useful for detecting different mental states. Non-linear features are computed from the IMFs that contribute most to mental state detection. These MEMD features show a significant performance gain over the conventional tempo-spectral features obtained by Fourier transform and Wavelet transform. The dominance of specific brain region is observed by analysing the MEMD features extracted from associated EEG channels. The frontal region is found to be most significant with a classification accuracy of 98.06%. This multi-dimensional decomposition approach upholds joint channel properties and produces most discriminative features for EEG based mental state detection.      
### 11.MEMD-HHT based Emotion Detection from EEG using 3D CNN  [ :arrow_down: ](https://arxiv.org/pdf/2206.00918.pdf)
>  In this study, the Multivariate Empirical Mode Decomposition (MEMD) is applied to multichannel EEG to obtain scale-aligned intrinsic mode functions (IMFs) as input features for emotion detection. The IMFs capture local signal variation related to emotion changes. Among the extracted IMFs, the high oscillatory ones are found to be significant for the intended task. The Marginal Hilbert spectrum (MHS) is computed from the selected IMFs. A 3D convolutional neural network (CNN) is adopted to perform emotion detection with spatial-temporal-spectral feature representations that are constructed by stacking the multi-channel MHS over consecutive signal segments. The proposed approach is evaluated on the publicly available DEAP database. On binary classification of valence and arousal level (high versus low), the attained accuracies are 89.25% and 86.23% respectively, which significantly outperform previously reported systems with 2D CNN and/or conventional temporal and spectral features.      
### 12.Squeezeformer: An Efficient Transformer for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.00888.pdf)
>  The recently proposed Conformer model has become the de facto backbone model for various downstream speech tasks based on its hybrid attention-convolution architecture that captures both local and global features. However, through a series of systematic studies, we find that the Conformer architecture's design choices are not optimal. After reexamining the design choices for both the macro and micro-architecture of Conformer, we propose the Squeezeformer model, which consistently outperforms the state-of-the-art ASR models under the same training schemes. In particular, for the macro-architecture, Squeezeformer incorporates (i) the Temporal U-Net structure, which reduces the cost of the multi-head attention modules on long sequences, and (ii) a simpler block structure of feed-forward module, followed up by multi-head attention or convolution modules, instead of the Macaron structure proposed in Conformer. Furthermore, for the micro-architecture, Squeezeformer (i) simplifies the activations in the convolutional block, (ii) removes redundant Layer Normalization operations, and (iii) incorporates an efficient depth-wise downsampling layer to efficiently sub-sample the input signal. Squeezeformer achieves state-of-the-art results of 7.5%, 6.5%, and 6.0% word-error-rate on Librispeech test-other without external language models. This is 3.1%, 1.4%, and 0.6% better than Conformer-CTC with the same number of FLOPs. Our code is open-sourced and available online.      
### 13.Extension and Validation of 4D Model for Improving the Accuracy of Modulation-Dependent Nonlinear Interference  [ :arrow_down: ](https://arxiv.org/pdf/2206.00866.pdf)
>  Existing nonlinear interference (NLI) model underestimates the NLI of dual polarization four-dimensional (4D) modulation in long-haul transmission, due to the ignorance of nonlinearity caused by signal-ASE interaction. We propose an enhanced 4D model by lifting an underlying assumption, which could improve the performance prediction accuracy.      
### 14.Dynamic MRI using Learned Transform-based Deep Tensor Low-Rank Network (DTLR-Net)  [ :arrow_down: ](https://arxiv.org/pdf/2206.00850.pdf)
>  While low-rank matrix prior has been exploited in dynamic MR image reconstruction and has obtained satisfying performance, low-rank tensors models have recently emerged as powerful alternative representations for three-dimensional dynamic MR datasets. In this paper, we introduce a model-based deep learning network by learning the tensor low-rank prior of the cardiac dynamic MR images. Instead of representing the dynamic dataset as a low-rank tensor directly, we propose a learned transformation operator to exploit the tensor low-rank property in a transform domain. In particular, by generalizing the t-SVD tensor decomposition into a unitary transformed t-SVD, we define a transformed tensor nuclear norm (TTNN) to enforce the tensor low-rankness. The dynamic MRI reconstruction problem is thus formulated using a TTNN regularized optimization problem. An iterative algorithm based on ADMM used to minimize the cost is unrolled into a deep network, where the transform is learned using convolutional neural networks (CNNs) to promote the reconstruction quality in the feature domain. Experimental results on cardiac cine MRI reconstruction demonstrate that the proposed framework is able to provide improved recovery results compared with the state-of-the-art algorithms.      
### 15.Dynamic Cardiac MRI Reconstruction Using Combined Tensor Nuclear Norm and Casorati Matrix Nuclear Norm Regularizations  [ :arrow_down: ](https://arxiv.org/pdf/2206.00831.pdf)
>  Low-rank tensor models have been applied in accelerating dynamic magnetic resonance imaging (dMRI). Recently, a new tensor nuclear norm based on t-SVD has been proposed and applied to tensor completion. Inspired by the different properties of the tensor nuclear norm (TNN) and the Casorati matrix nuclear norm (MNN), we introduce a combined TNN and Casorati MNN regularizations framework to reconstruct dMRI, which we term as TMNN. The proposed method simultaneously exploits the spatial structure and the temporal correlation of the dynamic MR data. The optimization problem can be efficiently solved by the alternating direction method of multipliers (ADMM). In order to further improve the computational efficiency, we develop a fast algorithm under the Cartesian sampling scenario. Numerical experiments based on cardiac cine MRI and perfusion MRI data demonstrate the performance improvement over the traditional Casorati nuclear norm regularization method.      
### 16.Decentralized temperature and storage volume control in multi-producer district heating  [ :arrow_down: ](https://arxiv.org/pdf/2206.00828.pdf)
>  Modern district heating technologies have a great potential to make the energy sector more flexible and sustainable due to their capabilities to use energy sources of varied nature and to efficiently store energy for subsequent use. Central control tasks within these systems for the efficient and safe distribution of heat refer to the stabilization of overall system temperatures and the regulation of storage units state of charge. These are challenging goals when the networked and nonlinear nature of district heating system models is taken into consideration. In this letter, for district heating systems with multiple, distributed heat producers, we propose a decentralized control scheme to provably meet said tasks stably.      
### 17.Radix-2 Self-Recursive Sparse Factorizations of Delay Vandermonde Matrices for Wideband Multi-Beam Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2206.00779.pdf)
>  This paper presents a self-contained factorization for the Vandermonde matrices associated with true-time delay based wideband analog multi-beam beamforming using antenna arrays. The proposed factorization contains sparse and orthogonal matrices. Novel self-recursive radix-2 algorithms for Vandermonde matrices associated with true time delay based delay-sum filterbanks are presented to reduce the circuit complexity of multi-beam analog beamforming systems. The proposed algorithms for Vandermonde matrices by a vector attain $\mathcal{O}(N \log N)$ delay-amplifier circuit counts. Error bounds for the Vandermode matrices associated with true-time delay are established and then analyzed for numerical stability. The potential for real-world circuit implementation of the proposed algorithms will be shown through signal flow graphs that are the starting point for high-frequency analog circuit realizations.      
### 18.Efficient and Self-Recursive Delay Vandermonde Algorithm for Multi-Beam Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2206.00778.pdf)
>  This paper presents a self-contained factorization for the delay Vandermonde matrix (DVM), which is the super class of the discrete Fourier transform, using sparse and companion matrices. An efficient DVM algorithm is proposed to reduce the complexity of radio-frequency (RF) $N$-beam analog beamforming systems. There exist applications for wideband multi-beam beamformers in wireless communication networks such as 5G/6G systems, system capacity can be improved by exploiting the improvement of the signal to noise ratio (SNR) using coherent summation of propagating waves based on their directions of propagation. The presence of a multitude of RF beams allows multiple independent wireless links to be established at high SNR, or used in conjunction with multiple-input multiple-output (MIMO) wireless systems, with the overall goal of improving system SNR and therefore capacity. To realize such multi-beam beamformers at acceptable analog circuit complexities, we use sparse factorization of the DVM in order to derive a low arithmetic complexity DVM algorithm. The paper also establishes an error bound and stability analysis of the proposed DVM algorithm. The proposed efficient DVM algorithm is aimed at implementation using analog realizations. For purposes of evaluation, the algorithm can be realized using both digital hardware as well as software defined radio platforms.      
### 19.Adaptive Local Neighborhood-based Neural Networks for MR Image Reconstruction from Undersampled Data  [ :arrow_down: ](https://arxiv.org/pdf/2206.00775.pdf)
>  Recent medical image reconstruction techniques focus on generating high-quality medical images suitable for clinical use at the lowest possible cost and with the fewest possible adverse effects on patients. Recent works have shown significant promise for reconstructing MR images from sparsely sampled k-space data using deep learning. In this work, we propose a technique that rapidly estimates deep neural networks directly at reconstruction time by fitting them on small adaptively estimated neighborhoods of a training set. In brief, our algorithm alternates between searching for neighbors in a data set that are similar to the test reconstruction, and training a local network on these neighbors followed by updating the test reconstruction. Because our reconstruction model is learned on a dataset that is structurally similar to the image being reconstructed rather than being fit on a large, diverse training set, it is more adaptive to new scans. It can also handle changes in training sets and flexible scan settings, while being relatively fast. Our approach, dubbed LONDN-MRI, was validated on the FastMRI multi-coil knee data set using deep unrolled reconstruction networks. Reconstructions were performed at four fold and eight fold undersampling of k-space with 1D variable-density random phase-encode undersampling masks. Our results demonstrate that our proposed locally-trained method produces higher-quality reconstructions compared to models trained globally on larger datasets.      
### 20.Xavier-Enabled Extreme Reservoir Machine for Millimeter-Wave Beamspace Channel Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2206.00760.pdf)
>  In this paper, we propose an accurate two-phase millimeter-Wave (mmWave) beamspace channel tracking mechanism. Particularly in the first phase, we train an extreme reservoir machine (ERM) for tracking the historical features of the mmWave beamspace channel and predicting them in upcoming time steps. Towards a more accurate prediction, we further fine-tune the ERM by means of Xavier initializer technique, whereby the input weights in ERM are initially derived from a zero mean and finite variance Gaussian distribution, leading to 49% degradation in prediction variance of the conventional ERM. The proposed method numerically improves the achievable spectral efficiency (SE) of the existing counterparts, by 13%, when signal-to-noise-ratio (SNR) is 15dB. We further investigate an ensemble learning technique in the second phase by sequentially incorporating multiple ERMs to form an ensembled model, namely adaptive boosting (AdaBoost), which further reduces the prediction variance in conventional ERM by 56%, and concludes in 21% enhancement of achievable SE upon the existing schemes at SNR=15dB.      
### 21.Disturbance Observer Based Frequency &amp; Voltage Regulation for RES Integrated Uncertain Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.00751.pdf)
>  This paper proposes a disturbance-observer-based control (DOBC) scheme for frequency and voltage regulation for a renewable energy sources (RES) integrated power systems. The proposed approach acts a feed-forward control which improves the dynamic performance of the conventional proportional-integral-derivative (PID) controller. Robustness of the proposed control scheme has been validated through simulations under worst-case and stochastic uncertainties to mitigate real-time variability in RES output and load. The performance of the proposed control technique is compared to well established technique in presence of communication delay and white noise.      
### 22.Control hubs of complex networks and a polynomial-time identification algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2206.01188.pdf)
>  Unveiling the underlying control principles of complex networks is one of the ultimate goals of network science. We introduce a novel concept, control hub, to reveal a cornerstone of the control structure of a network. The control hubs of a network are the nodes that lie in the middle of a control path in every control scheme of the network. We present a theorem based on graph theory for identifying control hubs without computing all control schemes. We develop an algorithm to identify all control hubs in O(N0.5L) time complexity for a network of N nodes and L links.      
### 23.Block-Parallel Systolic-Array Architecture for 2-D NTT-based Fragile Watermark Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2206.01146.pdf)
>  Number-theoretic transforms (NTTs) have been applied in the fragile watermarking of digital images. A block-parallel systolic-array architecture is proposed for watermarking based on the 2-D special Hartley NTT (HNTT). The proposed core employs two 2-D special HNTT hardware cores, each using digital arithmetic over $\mathrm{GF}(3)$, and processes $4\times4$ blocks of pixels in parallel every clock cycle. Prototypes are operational on a Xilinx Sx35-10ff668 FPGA device. The maximum estimated throughput of the FPGA circuit is 100 million $4\times4$ HNTT fragile watermarked blocks per second, when clocked at 100 MHz. Potential applications exist in high-traffic back-end servers dealing with large amounts of protected digital images requiring authentication, in remote-sensing for high-security surveillance applications, in real-time video processing of information of a sensitive nature or matters of national security, in video/photographic content management of corporate clients, in authenticating multimedia for the entertainment industry, in the authentication of electronic evidence material, and in real-time news streaming.      
### 24.The match file format: Encoding Alignments between Scores and Performances  [ :arrow_down: ](https://arxiv.org/pdf/2206.01104.pdf)
>  This paper presents the specifications of match: a file format that extends a MIDI human performance with note-, beat-, and downbeat-level alignments to a corresponding musical score. This enables advanced analyses of the performance that are relevant for various tasks, such as expressive performance modeling, score following, music transcription, and performer classification. The match file includes a set of score-related descriptors that makes it usable also as a bare-bones score representation. For applications that require the use of structural score elements (e.g., voices, parts, beams, slurs), the match file can be easily combined with the symbolic score. To support the practical application of our work, we release a corrected and upgraded version of the Vienna4x22 dataset of scores and performances aligned with match files.      
### 25.2D-MRI of the Central Nervous System: The effect of a deep learning-based reconstruction pipeline on the overall image quality  [ :arrow_down: ](https://arxiv.org/pdf/2206.01082.pdf)
>  Purpose of this study was to evaluate the effect of a robust magnetic resonance reconstruction pipeline equipped with a deep convolutional neural network on the overall image quality, in terms of Gibbs artifact reduction, and SNR improvement. Sixteen (16) healthy volunteers enrolled in this study and were imaged at 3T. Representative images of each image series that were reconstructed through the pipeline that leverages a deep learning (DL) algorithm were retrospectively benchmarked against corresponding images reconstructed through a conventional pipeline. DL-reconstructed images showed significant SNR improvements compared to the corresponding conventionally reconstructed images. In addition to that, Gibbs artifacts were effectively eliminated, when the raw data were reconstructed through the DL pipeline. Gibbs artifact reduction was qualitatively assessed by two experienced medical physicists and two experienced radiologists. DL-based reconstruction can lead to an SNR surplus which can be further invested into either higher spatial resolution and thinner slices, or into shorter scan times.      
### 26.Partitura: A Python Package for Symbolic Music Processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.01071.pdf)
>  Partitura is a lightweight Python package for handling symbolic musical information. It provides easy access to features commonly used in music information retrieval tasks, like note arrays (lists of timed pitched events) and 2D piano roll matrices, as well as other score elements such as time and key signatures, performance directives, and repeat structures. Partitura can load musical scores (in MEI, MusicXML, Kern, and MIDI formats), MIDI performances, and score-to-performance alignments. The package includes some tools for music analysis, such as automatic pitch spelling, key signature identification, and voice separation. Partitura is an open-source project and is available at <a class="link-external link-https" href="https://github.com/CPJKU/partitura/" rel="external noopener nofollow">this https URL</a>.      
### 27.Nonlinear Equalization for Optical Communications Based on Entropy-Regularized Mean Square Error  [ :arrow_down: ](https://arxiv.org/pdf/2206.01004.pdf)
>  An entropy-regularized mean square error (MSE-X) cost function is proposed for nonlinear equalization of short-reach optical channels. For a coherent optical transmission experiment, MSE-X achieves the same bit error rate as the standard MSE cost function and a significantly higher achievable information rate.      
### 28.A Bhattacharyya Coefficient-Based Framework for Noise Model-Aware Random Walker Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.00947.pdf)
>  One well established method of interactive image segmentation is the random walker algorithm. Considerable research on this family of segmentation methods has been continuously conducted in recent years with numerous applications. These methods are common in using a simple Gaussian weight function which depends on a parameter that strongly influences the segmentation performance. In this work we propose a general framework of deriving weight functions based on probabilistic modeling. This framework can be concretized to cope with virtually any well-defined noise model. It eliminates the critical parameter and thus avoids time-consuming parameter search. We derive the specific weight functions for common noise types and show their superior performance on synthetic data as well as different biomedical image data (MRI images from the NYU fastMRI dataset, larvae images acquired with the FIM technique). Our framework can also be used in multiple other applications, e.g., the graph cut algorithm and its extensions.      
### 29.A Real-time Critical-scenario-generation Framework for Testing Autonomous Driving System  [ :arrow_down: ](https://arxiv.org/pdf/2206.00910.pdf)
>  In order to find the most likely failure scenarios which may occur under certain given operation domain, critical-scenario-based test is supposed as an effective and widely used method, which gives suggestions for designers to improve the developing algorithm. However, for the state of art, critical-scenario generation approaches commonly utilize random-search or reinforcement learning methods to generate series of scenarios for a specific algorithm, which takes amounts of computing resource for testing a developing target that is always changing, and inapplicable for testing a real-time system. In this paper, we proposed a real-time critical-scenario-generation (RTCSG) framework to address the above challenges. In our framework, an aggressive-driving algorithm is proposed in controlling the virtual agent vehicles, a specially designed cost function is presented to guide scenarios to evolve towards critical conditions, and a self-adaptive coefficient iteration is designed that enable the approach to operate successfully in different conditions. With our proposed method, the critical-scenarios can be directly generated for the target under test which is a black-box system, and the real-time critical-scenario test can be brought into reality. The simulation results show that our approach is able to obtain more critical scenarios in most conditions than current methods, with a higher stability of success. For a real-time testing, our approach improves the efficiency around 16 times.      
### 30.Musical Instrument Recognition by XGBoost Combining Feature Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2206.00901.pdf)
>  Musical instrument classification is one of the focuses of Music Information Retrieval (MIR). In order to solve the problem of poor performance of current musical instrument classification models, we propose a musical instrument classification algorithm based on multi-channel feature fusion and XGBoost. Based on audio feature extraction and fusion of the dataset, the features are input into the XGBoost model for training; secondly, we verified the superior performance of the algorithm in the musical instrument classification task by com-paring different feature combinations and several classical machine learning models such as Naive Bayes. The algorithm achieves an accuracy of 97.65% on the Medley-solos-DB dataset, outperforming existing models. The experiments provide a reference for feature selection in feature engineering for musical instrument classification.      
### 31.Modeling sRGB Camera Noise with Normalizing Flows  [ :arrow_down: ](https://arxiv.org/pdf/2206.00812.pdf)
>  Noise modeling and reduction are fundamental tasks in low-level computer vision. They are particularly important for smartphone cameras relying on small sensors that exhibit visually noticeable noise. There has recently been renewed interest in using data-driven approaches to improve camera noise models via neural networks. These data-driven approaches target noise present in the raw-sensor image before it has been processed by the camera's image signal processor (ISP). Modeling noise in the RAW-rgb domain is useful for improving and testing the in-camera denoising algorithm; however, there are situations where the camera's ISP does not apply denoising or additional denoising is desired when the RAW-rgb domain image is no longer available. In such cases, the sensor noise propagates through the ISP to the final rendered image encoded in standard RGB (sRGB). The nonlinear steps on the ISP culminate in a significantly more complex noise distribution in the sRGB domain and existing raw-domain noise models are unable to capture the sRGB noise distribution. We propose a new sRGB-domain noise model based on normalizing flows that is capable of learning the complex noise distribution found in sRGB images under various ISO levels. Our normalizing flows-based approach outperforms other models by a large margin in noise modeling and synthesis tasks. We also show that image denoisers trained on noisy images synthesized with our noise model outperforms those trained with noise from baselines models.      
### 32.Adaptive Sampling-based Motion Planning with Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2206.00795.pdf)
>  Sampling-based algorithms, such as Rapidly Exploring Random Trees (RRT) and its variants, have been used extensively for motion planning. Control barrier functions (CBFs) have been recently proposed to synthesize controllers for safety-critical systems. In this paper, we combine the effectiveness of RRT-based algorithms with the safety guarantees provided by CBFs in a method called CBF-RRT$^\ast$. CBFs are used for local trajectory planning for RRT$^\ast$, avoiding explicit collision checking of the extended paths. We prove that CBF-RRT$^\ast$ preserves the probabilistic completeness of RRT$^\ast$. Furthermore, in order to improve the sampling efficiency of the algorithm, we equip the algorithm with an adaptive sampling procedure, which is based on the cross-entropy method (CEM) for importance sampling (IS). The procedure exploits the tree of samples to focus the sampling in promising regions of the configuration space. We demonstrate the efficacy of the proposed algorithms through simulation examples.      
### 33.Neural Decoding with Optimization of Node Activations  [ :arrow_down: ](https://arxiv.org/pdf/2206.00786.pdf)
>  The problem of maximum likelihood decoding with a neural decoder for error-correcting code is considered. It is shown that the neural decoder can be improved with two novel loss terms on the node's activations. The first loss term imposes a sparse constraint on the node's activations. Whereas, the second loss term tried to mimic the node's activations from a teacher decoder which has better performance. The proposed method has the same run time complexity and model size as the neural Belief Propagation decoder, while improving the decoding performance by up to $1.1dB$ on BCH codes.      
### 34.Winning the 3rd Japan Automotive AI Challenge -- Autonomous Racing with the Autoware.Auto Open Source Software Stack  [ :arrow_down: ](https://arxiv.org/pdf/2206.00770.pdf)
>  The 3rd Japan Automotive AI Challenge was an international online autonomous racing challenge where 164 teams competed in December 2021. This paper outlines the winning strategy to this competition, and the advantages and challenges of using the Autoware.Auto open source autonomous driving platform for multi-agent racing. Our winning approach includes a lane-switching opponent overtaking strategy, a global raceline optimization, and the integration of various tools from Autoware.Auto including a Model-Predictive Controller. We describe the use of perception, planning and control modules for high-speed racing applications and provide experience-based insights on working with Autoware.Auto. While our approach is a rule-based strategy that is suitable for non-interactive opponents, it provides a good reference and benchmark for learning-enabled approaches.      
### 35.Energy-Efficient Hybrid Offloading for Backscatter-Assisted Wirelessly Powered MEC with Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2206.00756.pdf)
>  We investigate a wireless power transfer (WPT)-based backscatter-mobile edge computing (MEC) network with a {reconfigurable intelligent surface (RIS)}.In this network, wireless devices (WDs) offload task bits and harvest energy, and they can switch between backscatter communication (BC) and active transmission (AT) modes. We exploit the RIS to maximize energy efficiency (EE). To this end, we optimize the time/power allocations, local computing frequencies, execution times, backscattering coefficients, and RIS phase shifts.} This goal results in a multi-objective optimization problem (MOOP) with conflicting objectives. Thus, we simultaneously maximize system throughput and minimize energy consumption via the Tchebycheff method, transforming into two single-objective optimization problems (SOOPs). For throughput maximization, we exploit alternating optimization (AO) to yield two sub-problems. For the first one, we derive closed-form resource allocations. For the second one, we design the RIS phase shifts via semi-definite relaxation, a difference of convex functions programming, majorization minimization techniques, and a penalty function for enforcing a rank-one solution. For energy minimization, we derive closed-form resource allocations. We demonstrate the gains over several benchmarks. For instance, with a $20$-element RIS, EE can be as high as 3 (Mbits/Joule), a 150\% improvement over the no-RIS case (achieving only 2 (Mbits/Joule)).      
### 36.K-Receiver Wiretap Channel: Optimal Encoding Order and Signaling Design  [ :arrow_down: ](https://arxiv.org/pdf/2206.00717.pdf)
>  The K-receiver wiretap channel is a channel model where a transmitter broadcasts K independent messages to K intended receivers while keeping them secret from an eavesdropper. The capacity region of the K-receiver multiple-input multiple-output (MIMO) wiretap channel has been characterized by using dirty-paper coding and stochastic encoding. However, K factorial encoding orders may need to be enumerated to evaluate the capacity region, which makes the problem intractable. In addition, even though the capacity region is known, the optimal signaling to achieve the capacity region is unknown. In this paper, we determine one optimal encoding order to achieve every point on the capacity region, and thus reduce the encoding complexity K factorial times. We prove that the optimal decoding order for the K-receiver MIMO wiretap channel is the same as that for the MIMO broadcast channel without secrecy. To be specific, the descending weight ordering in the weighted sum-rate (WSR) maximization problem determines the optimal encoding order. Next, to reach the border of the secrecy capacity region, we form a WSR maximization problem and apply the block successive maximization method to solve this nonconvex problem and find the input covariance matrices corresponding to each message. Numerical results are used to verify the optimality of the encoding order and to demonstrate the efficacy of the proposed signaling design.      
