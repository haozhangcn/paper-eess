# ArXiv eess --Fri, 24 Jun 2022
### 1.SVSHI: Secure and Verified Smart Home Infrastructure  [ :arrow_down: ](https://arxiv.org/pdf/2206.11786.pdf)
>  Smart infrastructures uses are growing and with them the need for dependability and correctness. To provide better correctness guarantees and bring formal verification into the equation, we present SVSHI, a platform for developing, verifying, and running Python applications in KNX installations, one of the most used smart buildings standards. SVSHI leverages abstract syntax tree (AST) manipulation, code generation, symbolic execution, and static configuration verification to make writing advanced apps easy, quick, and safe. With SVSHI, the reliability and compatibility of the applications are guaranteed without foregoing users' productivity.      
### 2.Towards End-to-End Private Automatic Speaker Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.11750.pdf)
>  The development of privacy-preserving automatic speaker verification systems has been the focus of a number of studies with the intent of allowing users to authenticate themselves without risking the privacy of their voice. However, current privacy-preserving methods assume that the template voice representations (or speaker embeddings) used for authentication are extracted locally by the user. This poses two important issues: first, knowledge of the speaker embedding extraction model may create security and robustness liabilities for the authentication system, as this knowledge might help attackers in crafting adversarial examples able to mislead the system; second, from the point of view of a service provider the speaker embedding extraction model is arguably one of the most valuable components in the system and, as such, disclosing it would be highly undesirable. In this work, we show how speaker embeddings can be extracted while keeping both the speaker's voice and the service provider's model private, using Secure Multiparty Computation. Further, we show that it is possible to obtain reasonable trade-offs between security and computational cost. This work is complementary to those showing how authentication may be performed privately, and thus can be considered as another step towards fully private automatic speaker recognition.      
### 3.Flexible and disposable paper- and plastic-based gel micropads for nematode handling, imaging, and chemical testing  [ :arrow_down: ](https://arxiv.org/pdf/2206.11749.pdf)
>  Today, the area of point-of-care diagnostics is synonymous with paper microfluidics where cheap, disposable, and on-the-spot detection toolkits are being developed for a variety of chemical tests. In this work, we present a novel application of microfluidic paper-based analytical devices (microPADs) to study the behavior of a small model nematode, Caenorhabditis elegans. We describe schemes of microPAD fabrication on paper and plastic substrates where membranes are created in agarose and Pluronic gel. Methods are demonstrated for loading, visualizing, and transferring single and multiple nematodes. Using an anthelmintic drug, levamisole, we show that chemical testing on C. elegans is easily performed because of the open device structure. A custom program is written to automatically recognize individual worms on the microPADs and extract locomotion parameters in real-time. The combination of microPADs and the nematode tracking program provides a relatively low-cost, simple-to-fabricate imaging and screening assay (compared to standard agarose plates or polymeric microfluidic devices) for non-microfluidic, nematode laboratories.      
### 4.A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery  [ :arrow_down: ](https://arxiv.org/pdf/2206.11706.pdf)
>  Latent Dirichlet allocation (LDA) is widely used for unsupervised topic modelling on sets of documents. No temporal information is used in the model. However, there is often a relationship between the corresponding topics of consecutive tokens. In this paper, we present an extension to LDA that uses a Markov chain to model temporal information. We use this new model for acoustic unit discovery from speech. As input tokens, the model takes a discretised encoding of speech from a vector quantised (VQ) neural network with 512 codes. The goal is then to map these 512 VQ codes to 50 phone-like units (topics) in order to more closely resemble true phones. In contrast to the base LDA, which only considers how VQ codes co-occur within utterances (documents), the Markov chain LDA additionally captures how consecutive codes follow one another. This extension leads to an increase in cluster quality and phone segmentation results compared to the base LDA. Compared to a recent vector quantised neural network approach that also learns 50 units, the extended LDA model performs better in phone segmentation but worse in mutual information.      
### 5.Efficient Transformer-based Speech Enhancement Using Long Frames and STFT Magnitudes  [ :arrow_down: ](https://arxiv.org/pdf/2206.11703.pdf)
>  The SepFormer architecture shows very good results in speech separation. Like other learned-encoder models, it uses short frames, as they have been shown to obtain better performance in these cases. This results in a large number of frames at the input, which is problematic; since the SepFormer is transformer-based, its computational complexity drastically increases with longer sequences. In this paper, we employ the SepFormer in a speech enhancement task and show that by replacing the learned-encoder features with a magnitude short-time Fourier transform (STFT) representation, we can use long frames without compromising perceptual enhancement performance. We obtained equivalent quality and intelligibility evaluation scores while reducing the number of operations by a factor of approximately 8 for a 10-second utterance.      
### 6.Frequency Dependent Sound Event Detection for DCASE 2022 Challenge Task 4  [ :arrow_down: ](https://arxiv.org/pdf/2206.11645.pdf)
>  While many deep learning methods on other domains have been applied to sound event detection (SED), differences between original domains of the methods and SED have not been appropriately considered so far. As SED uses audio data with two dimensions (time and frequency) for input, thorough comprehension on these two dimensions is essential for application of methods from other domains on SED. Previous works proved that methods those address on frequency dimension are especially powerful in SED. By applying FilterAugment and frequency dynamic convolution those are frequency dependent methods proposed to enhance SED performance, our submitted models achieved best PSDS1 of 0.4704 and best PSDS2 of 0.8224.      
### 7.Speaker-Independent Microphone Identification in Noisy Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2206.11640.pdf)
>  This work proposes a method for source device identification from speech recordings that applies neural-network-based denoising, to mitigate the impact of counter-forensics attacks using noise injection. The method is evaluated by comparing the impact of denoising on three state-of-the-art features for microphone classification, determining their discriminating power with and without denoising being applied. The proposed framework achieves a significant performance increase for noisy material, and more generally, validates the usefulness of applying denoising prior to device identification for noisy recordings.      
### 8.Fundamental limitations on the control of lossless systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11636.pdf)
>  In this paper we derive fundamental limitations on the levels of $H_2$ and $H_\infty{}$ performance that can be achieved when controlling lossless systems. The results are applied to the swing equation power system model, where it is shown that the fundamental limit on the $H_2$ norm scales with the inverse of the harmonic mean of the inertias in the system. This indicates that power systems may see a degradation in performance as more renewables are integrated, further motivating the need for new control solutions to aid the energy transition.      
### 9.Dynamic consensus with prescribed convergence time for multi-leader formation tracking  [ :arrow_down: ](https://arxiv.org/pdf/2206.11608.pdf)
>  This work addresses the problem of distributed formation tracking for a group of follower holonomic mobile robots around a reference signal. The reference signal is comprised of the geometric center of the positions of multiple leaders. This work's main contribution is a novel Modulated Distributed Virtual Observer (MDVO) for the reference signal. Moreover, the proposed MDVO is based on an exact dynamic consensus algorithm with a prescribed convergence time. In addition, we provide simulation examples showcasing two different application scenarios for the proposal.      
### 10.Universal Learned Image Compression With Low Computational Cost  [ :arrow_down: ](https://arxiv.org/pdf/2206.11599.pdf)
>  Recently, learned image compression methods have developed rapidly and exhibited excellent rate-distortion performance when compared to traditional standards, such as JPEG, JPEG2000 and BPG. However, the learning-based methods suffer from high computational costs, which is not beneficial for deployment on devices with limited resources. To this end, we propose shift-addition parallel modules (SAPMs), including SAPM-E for the encoder and SAPM-D for the decoder, to largely reduce the energy consumption. To be specific, they can be taken as plug-and-play components to upgrade existing CNN-based architectures, where the shift branch is used to extract large-grained features as compared to small-grained features learned by the addition branch. Furthermore, we thoroughly analyze the probability distribution of latent representations and propose to use Laplace Mixture Likelihoods for more accurate entropy estimation. Experimental results demonstrate that the proposed methods can achieve comparable or even better performance on both PSNR and MS-SSIM metrics to that of the convolutional counterpart with an about 2x energy reduction.      
### 11.Two-pass Decoding and Cross-adaptation Based System Combination of End-to-end Conformer and Hybrid TDNN ASR Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11596.pdf)
>  Fundamental modelling differences between hybrid and end-to-end (E2E) automatic speech recognition (ASR) systems create large diversity and complementarity among them. This paper investigates multi-pass rescoring and cross adaptation based system combination approaches for hybrid TDNN and Conformer E2E ASR systems. In multi-pass rescoring, state-of-the-art hybrid LF-MMI trained CNN-TDNN system featuring speed perturbation, SpecAugment and Bayesian learning hidden unit contributions (LHUC) speaker adaptation was used to produce initial N-best outputs before being rescored by the speaker adapted Conformer system using a 2-way cross system score interpolation. In cross adaptation, the hybrid CNN-TDNN system was adapted to the 1-best output of the Conformer system or vice versa. Experiments on the 300-hour Switchboard corpus suggest that the combined systems derived using either of the two system combination approaches outperformed the individual systems. The best combined system obtained using multi-pass rescoring produced statistically significant word error rate (WER) reductions of 2.5% to 3.9% absolute (22.5% to 28.9% relative) over the stand alone Conformer system on the NIST Hub5'00, Rt03 and Rt02 evaluation data.      
### 12.Optimization paper production through digitalization by developing an assistance system for machine operators including quality forecast: a concept  [ :arrow_down: ](https://arxiv.org/pdf/2206.11581.pdf)
>  Nowadays cross-industry ranging challenges include the reduction of greenhouse gas emission and enabling a circular economy. However, the production of paper from waste paper is still a highly resource intensive task, especially in terms of energy consumption. While paper machines produce a lot of data, we have identified a lack of utilization of it and implement a concept using an operator assistance system and state-of-the-art machine learning techniques, e.g., classification, forecasting and alarm flood handling algorithms, to support daily operator tasks. Our main objective is to provide situation-specific knowledge to machine operators utilizing available data. We expect this will result in better adjusted parameters and therefore a lower footprint of the paper machines.      
### 13.A Proposed Sub-optimal Power Allocation using Simulated Annealing in Cognitive Radio Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.11572.pdf)
>  Due to the rapid demand for wireless services and the increase in the wireless device count, there is a lack of available spectrum bands which constrain the further development of wireless communication .Therefore, Cognitive Radio (CR) has been adopted as a promising solution because of its ability to exploit the inefficiently used spectrum of licensed bands. Orthogonal Frequency Division Multiplexing (OFDM) become the enabling technique for CR due to its flexibility of allocating the available spectrum in dynamic environment. In this paper, a proposed distributed resource allocation framework based on Simulated Annealing (SA) algorithm for downlink OFDM-Based Cognitive Radio Network (CRN) will be applied. This algorithm gives less computational complexity for maximizing the total SUs transmission capacity. Moreover, the interference introduced from other Secondary Users (SUs) will be considered. For the sake of comparison, Lagrange dual method will be used. Simulation results showed that the proposed algorithm gives a better transmission capacity compared with Lagrange dual method. The parameters which are considered for comparison are maximum transmitted power, number of Primary Users (PUs) and number of SUs.      
### 14.Adversarial Multi-Task Learning for Disentangling Timbre and Pitch in Singing Voice Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2206.11558.pdf)
>  Recently, deep learning-based generative models have been introduced to generate singing voices. One approach is to predict the parametric vocoder features consisting of explicit speech parameters. This approach has the advantage that the meaning of each feature is explicitly distinguished. Another approach is to predict mel-spectrograms for a neural vocoder. However, parametric vocoders have limitations of voice quality and the mel-spectrogram features are difficult to model because the timbre and pitch information are entangled. In this study, we propose a singing voice synthesis model with multi-task learning to use both approaches -- acoustic features for a parametric vocoder and mel-spectrograms for a neural vocoder. By using the parametric vocoder features as auxiliary features, the proposed model can efficiently disentangle and control the timbre and pitch components of the mel-spectrogram. Moreover, a generative adversarial network framework is applied to improve the quality of singing voices in a multi-singer model. Experimental results demonstrate that our proposed model can generate more natural singing voices than the single-task models, while performing better than the conventional parametric vocoder-based model.      
### 15.A Federated Reinforcement Learning Method with Quantization for Cooperative Edge Caching in Fog Radio Access Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.11556.pdf)
>  In this paper, cooperative edge caching problem is studied in fog radio access networks (F-RANs). Given the non-deterministic polynomial hard (NP-hard) property of the problem, a dueling deep Q network (Dueling DQN) based caching update algorithm is proposed to make an optimal caching decision by learning the dynamic network environment. In order to protect user data privacy and solve the problem of slow convergence of the single deep reinforcement learning (DRL) model training, we propose a federated reinforcement learning method with quantization (FRLQ) to implement cooperative training of models from multiple fog access points (F-APs) in F-RANs. To address the excessive consumption of communications resources caused by model transmission, we prune and quantize the shared DRL models to reduce the number of model transfer parameters. The communications interval is increased and the communications rounds are reduced by periodical model global aggregation. We analyze the global convergence and computational complexity of our policy. Simulation results verify that our policy has better performance in reducing user request delay and improving cache hit rate compared to benchmark schemes. The proposed policy is also shown to have faster training speed and higher communications efficiency with minimal loss of model accuracy.      
### 16.Modeling the System-Level Reliability towards a Convergence of Communication, Computing and Control  [ :arrow_down: ](https://arxiv.org/pdf/2206.11522.pdf)
>  Enabled and driven by modern advances in wireless telecommunication and artificial intelligence, the convergence of communication, computing, and control is becoming inevitable in future industrial applications. Analytical and optimizing frameworks, however, are not yet readily developed for this new technical trend. In this work we discuss the necessity and typical scenarios of this convergence, and propose a new approach to model the system-level reliability across all involved domainss      
### 17.A novel adversarial learning strategy for medical image classification  [ :arrow_down: ](https://arxiv.org/pdf/2206.11501.pdf)
>  Deep learning (DL) techniques have been extensively utilized for medical image classification. Most DL-based classification networks are generally structured hierarchically and optimized through the minimization of a single loss function measured at the end of the networks. However, such a single loss design could potentially lead to optimization of one specific value of interest but fail to leverage informative features from intermediate layers that might benefit classification performance and reduce the risk of overfitting. Recently, auxiliary convolutional neural networks (AuxCNNs) have been employed on top of traditional classification networks to facilitate the training of intermediate layers to improve classification performance and robustness. In this study, we proposed an adversarial learning-based AuxCNN to support the training of deep neural networks for medical image classification. Two main innovations were adopted in our AuxCNN classification framework. First, the proposed AuxCNN architecture includes an image generator and an image discriminator for extracting more informative image features for medical image classification, motivated by the concept of generative adversarial network (GAN) and its impressive ability in approximating target data distribution. Second, a hybrid loss function is designed to guide the model training by incorporating different objectives of the classification network and AuxCNN to reduce overfitting. Comprehensive experimental studies demonstrated the superior classification performance of the proposed model. The effect of the network-related factors on classification performance was investigated.      
### 18.Patient Aware Active Learning for Fine-Grained OCT Classification  [ :arrow_down: ](https://arxiv.org/pdf/2206.11485.pdf)
>  This paper considers making active learning more sensible from a medical perspective. In practice, a disease manifests itself in different forms across patient cohorts. Existing frameworks have primarily used mathematical constructs to engineer uncertainty or diversity-based methods for selecting the most informative samples. However, such algorithms do not present themselves naturally as usable by the medical community and healthcare providers. Thus, their deployment in clinical settings is very limited, if any. For this purpose, we propose a framework that incorporates clinical insights into the sample selection process of active learning that can be incorporated with existing algorithms. Our medically interpretable active learning framework captures diverse disease manifestations from patients to improve generalization performance of OCT classification. After comprehensive experiments, we report that incorporating patient insights within the active learning framework yields performance that matches or surpasses five commonly used paradigms on two architectures with a dataset having imbalanced patient distributions. Also, the framework integrates within existing medical practices and thus can be used by healthcare providers.      
### 19.Weighted Concordance Index Loss-based Multimodal Survival Modeling for Radiation Encephalopathy Assessment in Nasopharyngeal Carcinoma Radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2206.11458.pdf)
>  Radiation encephalopathy (REP) is the most common complication for nasopharyngeal carcinoma (NPC) radiotherapy. It is highly desirable to assist clinicians in optimizing the NPC radiotherapy regimen to reduce radiotherapy-induced temporal lobe injury (RTLI) according to the probability of REP onset. To the best of our knowledge, it is the first exploration of predicting radiotherapy-induced REP by jointly exploiting image and non-image data in NPC radiotherapy regimen. We cast REP prediction as a survival analysis task and evaluate the predictive accuracy in terms of the concordance index (CI). We design a deep multimodal survival network (MSN) with two feature extractors to learn discriminative features from multimodal data. One feature extractor imposes feature selection on non-image data, and the other learns visual features from images. Because the priorly balanced CI (BCI) loss function directly maximizing the CI is sensitive to uneven sampling per batch. Hence, we propose a novel weighted CI (WCI) loss function to leverage all REP samples effectively by assigning their different weights with a dual average operation. We further introduce a temperature hyper-parameter for our WCI to sharpen the risk difference of sample pairs to help model convergence. We extensively evaluate our WCI on a private dataset to demonstrate its favourability against its counterparts. The experimental results also show multimodal data of NPC radiotherapy can bring more gains for REP risk prediction.      
### 20.LoneSTAR: Analog Beamforming Codebooks for Full-Duplex Millimeter Wave Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11418.pdf)
>  This work develops LoneSTAR, a novel enabler of full-duplex millimeter wave (mmWave) communication systems through the design of analog beamforming codebooks. LoneSTAR codebooks deliver high beamforming gain and broad coverage while simultaneously reducing the self-interference coupled by transmit and receive beams at a full-duplex mmWave transceiver. Our design framework accomplishes this by tolerating some variability in transmit and receive beamforming gain to strategically shape beams that reject self-interference spatially while accounting for digitally-controlled analog beamforming networks and self-interference channel estimation error. By leveraging the coherence time of the self-interference channel, a mmWave system can use the same LoneSTAR design over many time slots to serve several downlink-uplink user pairs in a full-duplex fashion without the need for additional self-interference cancellation. Compared to those using conventional codebooks, full-duplex mmWave systems employing LoneSTAR codebooks can mitigate higher levels of self-interference, tolerate more cross-link interference, and demand lower SNRs in order to outperform half-duplex operation -- all while supporting beam alignment. This makes LoneSTAR a potential standalone solution for enabling simultaneous transmission and reception in mmWave systems, from which it derives its name.      
### 21.Decentralized and Coordinated Vf Control for Islanded Microgrids Considering DER Inadequacy and Demand Control  [ :arrow_down: ](https://arxiv.org/pdf/2206.11407.pdf)
>  This paper proposed a decentralized and coordinated voltage and frequency control framework for islanded microgrids, with full consideration of the limited capacity of distributed energy resources and Vf dependent load. First, we provide a comprehensive discussion of the DER inadequacy concept and the challenges it poses. Then, a decentralized and coordinated control framework is proposed to regulate the output of inverter based generations and reallocate limited DER capacity for Vf regulation. The control framework is composed of a power regulator and a Vf regulator, which generate the supplementary signals for the primary controller. The power regulator regulates the output of grid forming inverters according to the realtime capacity constraints of DERs, while the Vf regulator improves the Vf deviation by leveraging the load sensitivity to Vf. Next, the static feasibility and dynamic stability of the proposed method are rigorously proven through mathematical formulation and eigenvalue analysis. Finally, a MATLAB Simulink simulation demonstrates the functionalities of the control framework. A few goals are fulfilled within the decentralized and coordinated framework, such as making the best use of limited DER capacity, enhancing the DC side stability of inverter based generations, improving power sharing results, and reducing involuntary load shedding.      
### 22.On Surface Wave Propagation Characteristics of Porosity-Based Reconfigurable Surface  [ :arrow_down: ](https://arxiv.org/pdf/2206.11401.pdf)
>  Reconfigurable surfaces facilitating energy-efficient, intelligent surface wave propagation have recently emerged as a technology that finds applications in many-core systems and 6G wireless communications. In this paper, we consider the porosity-based reconfigurable surface where there are cavities that can be filled on-demand with fluid metal such as Galinstan, in order to create adaptable channels for efficient wave propagation. We aim to investigate the propagation phenomenon of signal fluctuation resulting from the diffraction of discrete porosity and study how different porosity patterns affect this phenomenon. Our results cover the frequency range between 21.7GHz and 31.6GHz when a WR-34 waveguide is used as the transducer.      
### 23.Fusion of Model-free Reinforcement Learning with Microgrid Control: Review and Insight  [ :arrow_down: ](https://arxiv.org/pdf/2206.11398.pdf)
>  Challenges and opportunities coexist in microgrids as a result of emerging large-scale distributed energy resources (DERs) and advanced control techniques. In this paper, a comprehensive review of microgrid control is presented with its fusion of model-free reinforcement learning (MFRL). A high-level research map of microgrid control is developed from six distinct perspectives, followed by bottom-level modularized control blocks illustrating the configurations of grid-following (GFL) and grid-forming (GFM) inverters. Then, mainstream MFRL algorithms are introduced with an explanation of how MFRL can be integrated into the existing control framework. Next, the application guideline of MFRL is summarized with a discussion of three fusing approaches, i.e., model identification and parameter tuning, supplementary signal generation, and controller substitution, with the existing control framework. Finally, the fundamental challenges associated with adopting MFRL in microgrid control and corresponding insights for addressing these concerns are fully discussed.      
### 24.Multi-Access Point Coordination for Next-Gen Wi-Fi Networks Aided by Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.11378.pdf)
>  Wi-Fi in the enterprise - characterized by overlapping Wi-Fi cells - constitutes the design challenge for next-generation networks. Standardization for recently started IEEE 802.11be (Wi-Fi 7) Working Groups has focused on significant medium access control layer changes that emphasize the role of the access point (AP) in radio resource management (RRM) for coordinating channel access due to the high collision probability with the distributed coordination function (DCF), especially in dense overlapping Wi-Fi networks. This paper proposes a novel multi-AP coordination system architecture aided by a centralized AP controller (APC). Meanwhile, a deep reinforcement learning channel access (DLCA) protocol is developed to replace the binary exponential backoff mechanism in DCF to enhance the network throughput by enabling the coordination of APs. First-Order Model-Agnostic Meta-Learning further enhances the network throughput. Subsequently, we also put forward a new greedy algorithm to maintain proportional fairness (PF) among multiple APs. Via the simulation, the performance of DLCA protocol in dense overlapping Wi-Fi networks is verified to have strong stability and outperform baselines such as Shared Transmission Opportunity (SH-TXOP) and Request-to-Send/Clear-to-Send (RTS/CTS) in terms of the network throughput by 10% and 3% as well as the network utility considering proportional fairness by 28.3% and 13.8%, respectively.      
### 25.On Grid Compressive Sensing for Spherical Field Measurements in Acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2206.11311.pdf)
>  We derive a theoretically guaranteed compressive sensing method for acoustic field reconstructions using spherical field measurements on a predefined grid. This method can be used to reconstruct sparse band-limited spherical harmonic or Wigner $D$-function series. Contrasting typical compressive sensing methods for spherical harmonic or Wigner $D$-function series that use random measurements on the sphere or rotation group, the new method samples on an equiangular grid in those domains, which is a commonly used sampling pattern. Using the periodic extension of the Wigner $D$-functions, we transform the reconstruction of a Wigner $D$-function series (of which spherical harmonics are a special case) into a multi-dimensional Fourier domain reconstruction problem. We establish that this transformation maintains sparsity in cases of interest and provide numerical studies of the transformation's effect on sparsity. We also provide numerical studies of the reconstruction performance of the compressive sensing approach compared to classical Nyquist sampling. In the cases tested, we find accurate compressive sensing reconstructions need only a fraction of the measurements dictated by the Nyquist sampling theorem. Moreover, using one-third of the measurements or less, the compressive sensing method can provide over 20 dB more denoising capabilities than oversampling with classical Fourier theory.      
### 26.Provably Efficient Model-Free Constrained RL with Linear Function Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2206.11889.pdf)
>  We study the constrained reinforcement learning problem, in which an agent aims to maximize the expected cumulative reward subject to a constraint on the expected total value of a utility function. In contrast to existing model-based approaches or model-free methods accompanied with a `simulator', we aim to develop the first model-free, simulator-free algorithm that achieves a sublinear regret and a sublinear constraint violation even in large-scale systems. To this end, we consider the episodic constrained Markov decision processes with linear function approximation, where the transition dynamics and the reward function can be represented as a linear function of some known feature mapping. We show that $\tilde{\mathcal{O}}(\sqrt{d^3H^3T})$ regret and $\tilde{\mathcal{O}}(\sqrt{d^3H^3T})$ constraint violation bounds can be achieved, where $d$ is the dimension of the feature mapping, $H$ is the length of the episode, and $T$ is the total number of steps. Our bounds are attained without explicitly estimating the unknown transition model or requiring a simulator, and they depend on the state space only through the dimension of the feature mapping. Hence our bounds hold even when the number of states goes to infinity. Our main results are achieved via novel adaptations of the standard LSVI-UCB algorithms. In particular, we first introduce primal-dual optimization into the LSVI-UCB algorithm to balance between regret and constraint violation. More importantly, we replace the standard greedy selection with respect to the state-action function in LSVI-UCB with a soft-max policy. This turns out to be key in establishing uniform concentration for the constrained case via its approximation-smoothness trade-off. We also show that one can achieve an even zero constraint violation while still maintaining the same order with respect to $T$.      
### 27.Design Exploration and Security Assessment of PUF-on-PUF Implementations  [ :arrow_down: ](https://arxiv.org/pdf/2206.11840.pdf)
>  We design, implement, and assess the security of several variations of the PUF-on-PUF (POP) architecture. We perform extensive experiments with deep neural networks (DNNs), showing results that endorse its resilience to learning attacks when using APUFs with 6, or more, stages in the first layer. Compositions using APUFs with 2, and 4 stages are shown vulnerable to DNN attacks. We reflect on such results, extending previous techniques of influential bits to assess stage bias in APUF instances. Our data shows that compositions not always preserve security properties of PUFs, the size of PUFs used plays a crucial role. We implemented a testchip in 65 nm CMOS to obtain accurate measurements of uniformity, uniqueness, and response stability for our POP implementations. Measurement results show that minimum bit error rate is obtained when using APUFs with 8 stages in the first layer, while fewer APUF stages lead to a large spread of bit error rate across different chips.      
### 28.Optimal Covariance Steering for Continuous-Time Linear Stochastic Systems With Multiplicative Noise  [ :arrow_down: ](https://arxiv.org/pdf/2206.11735.pdf)
>  In this paper we study the finite-horizon optimal covariance steering problem for a continuous-time linear stochastic system subject to both additive and multiplicative noise. The noise can be continuous or it may contain jumps. Additive noise does not depend on the state or the control, whereas multiplicative noise has a magnitude proportional to the current state. The cost is assumed to be quadratic in both the state and the control. First, the controllability of the state covariance is established under mild assumptions. Then, the optimal control for steering the covariance is provided. Lastly, the existence and uniqueness of the optimal control is shown. In the process, we provide a result of independent interest regarding the maximal interval of existence of the solution to a matrix Riccati differential equation.      
### 29.Cooperative Hybrid Networks with Active Relays and RISs for B5G: Applications, Challenges, and Research Directions  [ :arrow_down: ](https://arxiv.org/pdf/2206.11707.pdf)
>  Among the recent advances and innovations in wireless technologies, reconfigurable intelligent surfaces (RISs) have received much attention and are envisioned to be one of the enabling technologies for beyond 5G (B5G) networks. On the other hand, active (or classical) cooperative relays have played a key role in providing reliable and power-efficient communications in previous wireless generations. In this article, we focus on hybrid network architectures that amalgamate both active relays and RISs. The operation concept and protocols of each technology are first discussed. Subsequently, we present multiple use cases of cooperative hybrid networks where both active relays and RISs can coexist harmoniously for enhanced rate performance. Furthermore, a case study is provided which demonstrates the achievable rate performance of a communication network assisted by either an active relay, an RIS, or both, and with different relaying protocols. Finally, we provide the reader with the challenges and key research directions in this area.      
### 30.The SJTU X-LANCE Lab System for CNSRC 2022  [ :arrow_down: ](https://arxiv.org/pdf/2206.11699.pdf)
>  This technical report describes the SJTU X-LANCE Lab system for the three tracks in CNSRC 2022. In this challenge, we explored the speaker embedding modeling ability of deep ResNet (Deeper r-vector). All the systems are only trained on the Cnceleb training set and we use the same systems for the three tracks in CNSRC 2022. In this challenge, our system ranks the first place in the fixed track of speaker verification task. Our best single system and fusion system achieve 0.3164 and 0.2975 minDCF respectively. Besides, we submit the result of ResNet221 to the speaker retrieval track and achieve 0.4626 mAP.      
### 31.NTIRE 2022 Challenge on Perceptual Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2206.11695.pdf)
>  This paper reports on the NTIRE 2022 challenge on perceptual image quality assessment (IQA), held in conjunction with the New Trends in Image Restoration and Enhancement workshop (NTIRE) workshop at CVPR 2022. This challenge is held to address the emerging challenge of IQA by perceptual image processing algorithms. The output images of these algorithms have completely different characteristics from traditional distortions and are included in the PIPAL dataset used in this challenge. This challenge is divided into two tracks, a full-reference IQA track similar to the previous NTIRE IQA challenge and a new track that focuses on the no-reference IQA methods. The challenge has 192 and 179 registered participants for two tracks. In the final testing stage, 7 and 8 participating teams submitted their models and fact sheets. Almost all of them have achieved better results than existing IQA methods, and the winning method can demonstrate state-of-the-art performance.      
### 32.Capacity Optimality of OAMP in Coded Large Unitarily Invariant Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11680.pdf)
>  This paper investigates a large unitarily invariant system (LUIS) involving a unitarily invariant sensing matrix, an arbitrary fixed signal distribution, and forward error control (FEC) coding. Several area properties are established based on the state evolution of orthogonal approximate message passing (OAMP) in an un-coded LUIS. Under the assumptions that the state evolution for joint OAMP and FEC decoding is correct and the replica method is reliable, we analyze the achievable rate of OAMP. We prove that OAMP reaches the constrained capacity predicted by the replica method of the LUIS with an arbitrary signal distribution based on matched FEC coding. Meanwhile, we elaborate a constrained capacity-achieving coding principle for LUIS, based on which irregular low-density parity-check (LDPC) codes are optimized for binary signaling in the simulation results. We show that OAMP with the optimized codes has significant performance improvement over the un-optimized ones and the well-known Turbo linear MMSE algorithm. For quadrature phase-shift keying (QPSK) modulation, constrained capacity-approaching bit error rate (BER) performances are observed under various channel conditions.      
### 33.Sufficient Statistic Memory Approximate Message Passing  [ :arrow_down: ](https://arxiv.org/pdf/2206.11674.pdf)
>  Approximate message passing (AMP) type algorithms have been widely used in the signal reconstruction of certain large random linear systems. A key feature of the AMP-type algorithms is that their dynamics can be correctly described by state evolution. However, state evolution does not necessarily guarantee the convergence of iterative algorithms. To solve the convergence problem of AMP-type algorithms in principle, this paper proposes a memory AMP (MAMP) under a sufficient statistic condition, named sufficient statistic MAMP (SS-MAMP). We show that the covariance matrices of SS-MAMP are L-banded and convergent. Given an arbitrary MAMP, we can construct the SS-MAMP by damping, which not only ensures the convergence, but also preserves the orthogonality, i.e., its dynamics can be correctly described by state evolution.      
### 34.An Optimization-Based User Scheduling Framework for mmWave Massive MU-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11658.pdf)
>  We propose a novel user equipment (UE) scheduling framework for millimeter-wave (mmWave) massive multiuser (MU) multiple-input multiple-output (MIMO) wireless systems. Our framework determines (sub)sets of UEs that should transmit simultaneously in a given time slot by approximately solving a nonconvex optimization problem using forward-backward splitting. Our UE scheduling framework is flexible in the sense that it (i) supports a variety of cost functions, including post-equalization mean square error and sum rate, and (ii) enables precise control over the minimum and maximum number of resources the UEs should occupy. We demonstrate the efficacy of our framework using realistic mmWave channel vectors generated with a commercial ray-tracer. We show that our UE scheduler outperforms a range of existing scheduling methods and closely approaches the performance of an exhaustive search.      
### 35.Towards Green ASR: Lossless 4-bit Quantization of a Hybrid TDNN System on the 300-hr Switchboard Corpus  [ :arrow_down: ](https://arxiv.org/pdf/2206.11643.pdf)
>  State of the art time automatic speech recognition (ASR) systems are becoming increasingly complex and expensive for practical applications. This paper presents the development of a high performance and low-footprint 4-bit quantized LF-MMI trained factored time delay neural networks (TDNNs) based ASR system on the 300-hr Switchboard corpus. A key feature of the overall system design is to account for the fine-grained, varying performance sensitivity at different model components to quantization errors. To this end, a set of neural architectural compression and mixed precision quantization approaches were used to facilitate hidden layer level auto-configuration of optimal factored TDNN weight matrix subspace dimensionality and quantization bit-widths. The proposed techniques were also used to produce 2-bit mixed precision quantized Transformer language models. Experiments conducted on the Switchboard data suggest that the proposed neural architectural compression and mixed precision quantization techniques consistently outperform the uniform precision quantised baseline systems of comparable bit-widths in terms of word error rate (WER). An overall "lossless" compression ratio of 13.6 was obtained over the baseline full precision system including both the TDNN and Transformer components while incurring no statistically significant WER increase.      
### 36.Formant Estimation and Tracking using Probabilistic Heat-Maps  [ :arrow_down: ](https://arxiv.org/pdf/2206.11632.pdf)
>  Formants are the spectral maxima that result from acoustic resonances of the human vocal tract, and their accurate estimation is among the most fundamental speech processing problems. Recent work has been shown that those frequencies can accurately be estimated using deep learning techniques. However, when presented with a speech from a different domain than that in which they have been trained on, these methods exhibit a decline in performance, limiting their usage as generic tools. <br>The contribution of this paper is to propose a new network architecture that performs well on a variety of different speaker and speech domains. Our proposed model is composed of a shared encoder that gets as input a spectrogram and outputs a domain-invariant representation. Then, multiple decoders further process this representation, each responsible for predicting a different formant while considering the lower formant predictions. An advantage of our model is that it is based on heatmaps that generate a probability distribution over formant predictions. Results suggest that our proposed model better represents the signal over various domains and leads to better formant frequency tracking and estimation.      
### 37.Global Sensing and Measurements Reuse for Image Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2206.11629.pdf)
>  Recently, deep network-based image compressed sensing methods achieved high reconstruction quality and reduced computational overhead compared with traditional methods. However, existing methods obtain measurements only from partial features in the network and use them only once for image reconstruction. They ignore there are low, mid, and high-level features in the network\cite{zeiler2014visualizing} and all of them are essential for high-quality reconstruction. Moreover, using measurements only once may not be enough for extracting richer information from measurements. To address these issues, we propose a novel Measurements Reuse Convolutional Compressed Sensing Network (MR-CCSNet) which employs Global Sensing Module (GSM) to collect all level features for achieving an efficient sensing and Measurements Reuse Block (MRB) to reuse measurements multiple times on multi-scale. Finally, experimental results on three benchmark datasets show that our model can significantly outperform state-of-the-art methods.      
### 38.Waypoint Generation in Row-based Crops with Deep Learning and Contrastive Clustering  [ :arrow_down: ](https://arxiv.org/pdf/2206.11623.pdf)
>  The development of precision agriculture has gradually introduced automation in the agricultural process to support and rationalize all the activities related to field management. In particular, service robotics plays a predominant role in this evolution by deploying autonomous agents able to navigate in fields while executing different tasks without the need for human intervention, such as monitoring, spraying and harvesting. In this context, global path planning is the first necessary step for every robotic mission and ensures that the navigation is performed efficiently and with complete field coverage. In this paper, we propose a learning-based approach to tackle waypoint generation for planning a navigation path for row-based crops, starting from a top-view map of the region-of-interest. We present a novel methodology for waypoint clustering based on a contrastive loss, able to project the points to a separable latent space. The proposed deep neural network can simultaneously predict the waypoint position and cluster assignment with two specialized heads in a single forward pass. The extensive experimentation on simulated and real-world images demonstrates that the proposed approach effectively solves the waypoint generation problem for both straight and curved row-based crops, overcoming the limitations of previous state-of-the-art methodologies.      
### 39.Restoring speech intelligibility for hearing aid users with deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.11567.pdf)
>  Almost half a billion people world-wide suffer from disabling hearing loss. While hearing aids can partially compensate for this, a large proportion of users struggle to understand speech in situations with background noise. Here, we present a deep learning-based algorithm that selectively suppresses noise while maintaining speech signals. The algorithm restores speech intelligibility for hearing aid users to the level of control subjects with normal hearing. It consists of a deep network that is trained on a large custom database of noisy speech signals and is further optimized by a neural architecture search, using a novel deep learning-based metric for speech intelligibility. The network achieves state-of-the-art denoising on a range of human-graded assessments, generalizes across different noise categories and - in contrast to classic beamforming approaches - operates on a single microphone. The system runs in real time on a laptop, suggesting that large-scale deployment on hearing aid chips could be achieved within a few years. Deep learning-based denoising therefore holds the potential to improve the quality of life of millions of hearing impaired people soon.      
### 40.Reducing the Error Floor of the Sign-Preserving Min-Sum LDPC Decoder via Message Weighting of Low-Degree Variable Nodes  [ :arrow_down: ](https://arxiv.org/pdf/2206.11532.pdf)
>  Some low-complexity LDPC decoders suffer from error floors. We apply iteration-dependent weights to the degree-3 variable nodes to solve this problem. When the 802.3ca EPON LDPC code is considered, an error floor decrease of more than 3 orders of magnitude is achieved.      
### 41.ICOS Protein Expression Segmentation: Can Transformer Networks Give Better Results?  [ :arrow_down: ](https://arxiv.org/pdf/2206.11520.pdf)
>  Biomarkers identify a patients response to treatment. With the recent advances in artificial intelligence based on the Transformer networks, there is only limited research has been done to measure the performance on challenging histopathology images. In this paper, we investigate the efficacy of the numerous state-of-the-art Transformer networks for immune-checkpoint biomarker, Inducible Tcell COStimulator (ICOS) protein cell segmentation in colon cancer from immunohistochemistry (IHC) slides. Extensive and comprehensive experimental results confirm that MiSSFormer achieved the highest Dice score of 74.85% than the rest evaluated Transformer and Efficient U-Net methods.      
### 42.Communication by means of Thermal Noise: Towards Networks with Extremely Low Power Consumption  [ :arrow_down: ](https://arxiv.org/pdf/2206.11333.pdf)
>  In this paper, the paradigm of thermal noise communication (TherCom) is put forward for future wired/wireless networks with extremely low power consumption. Taking backscatter communication (BackCom) and reconfigurable intelligent surface (RIS)-based radio frequency chain-free transmitters one step further, a thermal noise-driven transmitter might enable zero-signal-power transmission by simply indexing resistors or other noise sources according to information bits. This preliminary paper aims to shed light on the theoretical foundations, transceiver designs, and error performance derivations as well as optimizations of two emerging TherCom solutions: Kirchhoff-law-Johnson-noise (KLJN) secure bit exchange and wireless thermal noise modulation (TherMod) schemes. Our theoretical and computer simulation findings reveal that noise variance detection, supported by sample variance estimation with carefully optimized decision thresholds, is a reliable way of extracting the embedded information from noise modulated signals, even with limited number of noise samples.      
### 43.An Application of a Modified Beta Factor Method for the Analysis of Software Common Cause Failures  [ :arrow_down: ](https://arxiv.org/pdf/2206.11321.pdf)
>  This paper presents an approach for modeling software common cause failures (CCFs) within digital instrumentation and control (I&amp;C) systems. CCFs consist of a concurrent failure between two or more components due to a shared failure cause and coupling mechanism. This work emphasizes the importance of identifying software-centric attributes related to the coupling mechanisms necessary for simultaneous failures of redundant software components. The groups of components that share coupling mechanisms are called common cause component groups (CCCGs). Most CCF models rely on operational data as the basis for establishing CCCG parameters and predicting CCFs. This work is motivated by two primary concerns: (1) a lack of operational and CCF data for estimating software CCF model parameters; and (2) the need to model single components as part of multiple CCCGs simultaneously. A hybrid approach was developed to account for these concerns by leveraging existing techniques: a modified beta factor model allows single components to be placed within multiple CCCGs, while a second technique provides software-specific model parameters for each CCCG. This hybrid approach provides a means to overcome the limitations of conventional methods while offering support for design decisions under the limited data scenario.      
### 44.Few-shot Long-Tailed Bird Audio Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.11260.pdf)
>  It is easier to hear birds than see them. However, they still play an essential role in nature and are excellent indicators of deteriorating environmental quality and pollution. Recent advances in Machine Learning and Convolutional Neural Networks allow us to process continuous audio data to detect and classify bird sounds. This technology can assist researchers in monitoring bird populations' status and trends and ecosystems' biodiversity. <br>We propose a sound detection and classification pipeline to analyze complex soundscape recordings and identify birdcalls in the background. Our method learns from weak labels and few data and acoustically recognizes the bird species. Our solution achieved 18th place of 807 teams at the BirdCLEF 2022 Challenge hosted on Kaggle.      
