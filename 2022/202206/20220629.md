# ArXiv eess --Wed, 29 Jun 2022
### 1.Expressive, Variable, and Controllable Duration Modelling in TTS  [ :arrow_down: ](https://arxiv.org/pdf/2206.14165.pdf)
>  Duration modelling has become an important research problem once more with the rise of non-attention neural text-to-speech systems. The current approaches largely fall back to relying on previous statistical parametric speech synthesis technology for duration prediction, which poorly models the expressiveness and variability in speech. In this paper, we propose two alternate approaches to improve duration modelling. First, we propose a duration model conditioned on phrasing that improves the predicted durations and provides better modelling of pauses. We show that the duration model conditioned on phrasing improves the naturalness of speech over our baseline duration model. Second, we also propose a multi-speaker duration model called Cauliflow, that uses normalising flows to predict durations that better match the complex target duration distribution. Cauliflow performs on par with our other proposed duration model in terms of naturalness, whilst providing variable durations for the same prompt and variable levels of expressiveness. Lastly, we propose to condition Cauliflow on parameters that provide an intuitive control of the pacing and pausing in the synthesised speech in a novel way.      
### 2.Towards Prescribed Accuracy in Under-tuned Super-Twisting Sliding Mode Control Loops -- Experimental Verification  [ :arrow_down: ](https://arxiv.org/pdf/2206.14094.pdf)
>  Obtaining prescribed accuracy bounds in super-twisting sliding mode control loops often falls short in terms of the applicability of the controller in high-performance systems. This is due to the fact that the selection of the controller gains that are derived from the conditions for finite-time convergence may be too restrictive in connection to actuator limitations and induced chatter. Previous work has shown that in case of periodic perturbations, there can be a systematic selection of much lower controller gains that guarantees boundedness of the closed-loop solutions within predetermined accuracy bounds. This study presents an experimental validation of these findings carried out on a commercial industrial motor system.      
### 3.Artificial Intelligence based Video Codec (AIVC) for CLIC 2022  [ :arrow_down: ](https://arxiv.org/pdf/2206.13934.pdf)
>  This paper presents the AIVC submission to the CLIC 2022 video track. AIVC is a fully-learned video codec based on conditional autoencoders. The flexibility of the AIVC models is leveraged to implement rate allocation and frame structure competition to select the optimal coding configuration per-sequence. This competition yields compelling compression performance, offering a rate reduction of -26 % compared with the absence of competition.      
### 4.Bi-Static Sensing for Near-Field RIS Localization  [ :arrow_down: ](https://arxiv.org/pdf/2206.13915.pdf)
>  We address the localization of a reconfigurable intelligent surface (RIS) for a single-input single-output multi-carrier system using bi-static sensing between a fixed transmitter and a fixed receiver. Due to the deployment of RISs with a large dimension, near-field (NF) scenarios are likely to occur, especially for indoor applications, and are the focus of this work. We first derive the Cramer-Rao bounds (CRBs) on the estimation error of the RIS position and orientation and the time of arrival (TOA) for the path transmitter-RIS-receiver. We propose a multi-stage low-complexity estimator for RIS localization purposes. In this proposed estimator, we first perform a line search to estimate the TOA. Then, we use the far-field approximation of the NF signal model to implicitly estimate the angle of arrival and the angle of departure at the RIS center. Finally, the RIS position and orientation estimate are refined via a quasi-Newton method. Simulation results reveal that the proposed estimator can attain the CRBs. We also investigate the effects of several influential factors on the accuracy of the proposed estimator like the RIS size, transmitted power, system bandwidth, and RIS position and orientation.      
### 5.AS-IntroVAE: Adversarial Similarity Distance Makes Robust IntroVAE  [ :arrow_down: ](https://arxiv.org/pdf/2206.13903.pdf)
>  Recently, introspective models like IntroVAE and S-IntroVAE have excelled in image generation and reconstruction tasks. The principal characteristic of introspective models is the adversarial learning of VAE, where the encoder attempts to distinguish between the real and the fake (i.e., synthesized) images. However, due to the unavailability of an effective metric to evaluate the difference between the real and the fake images, the posterior collapse and the vanishing gradient problem still exist, reducing the fidelity of the synthesized images. In this paper, we propose a new variation of IntroVAE called Adversarial Similarity Distance Introspective Variational Autoencoder (AS-IntroVAE). We theoretically analyze the vanishing gradient problem and construct a new Adversarial Similarity Distance (AS-Distance) using the 2-Wasserstein distance and the kernel trick. With weight annealing on AS-Distance and KL-Divergence, the AS-IntroVAE are able to generate stable and high-quality images. The posterior collapse problem is addressed by making per-batch attempts to transform the image so that it better fits the prior distribution in the latent space. Compared with the per-image approach, this strategy fosters more diverse distributions in the latent space, allowing our model to produce images of great diversity. Comprehensive experiments on benchmark datasets demonstrate the effectiveness of AS-IntroVAE on image generation and reconstruction tasks.      
### 6.Spatial Positioning Token (SPToken) for Smart Parking  [ :arrow_down: ](https://arxiv.org/pdf/2206.13880.pdf)
>  In this paper, we describe an approach to guide drivers searching for a parking space (PS). The proposed system suggests a sequence of routes that drivers should traverse in order to maximise the expected likelihood of finding a PS and minimise the travel distance. This system is built on our recent architecture SPToken, which combines both Distributed Ledger Technology (DLT) and Reinforcement Learning (RL) to realise a system for the estimation of an unknown distribution without disturbing the environment. For this, we use a number of virtual tokens that are passed from vehicle to vehicle to enable a massively parallelised RL system that estimates the best route for a given origin-destination (OD) pair, using crowdsourced information from participant vehicles. Additionally, a moving window with reward memory mechanism is included to better cope with non-stationary environments. Simulation results are given to illustrate the efficacy of our system.      
### 7.RetrieverTTS: Modeling Decomposed Factors for Text-Based Speech Insertion  [ :arrow_down: ](https://arxiv.org/pdf/2206.13865.pdf)
>  This paper proposes a new "decompose-and-edit" paradigm for the text-based speech insertion task that facilitates arbitrary-length speech insertion and even full sentence generation. In the proposed paradigm, global and local factors in speech are explicitly decomposed and separately manipulated to achieve high speaker similarity and continuous prosody. Specifically, we proposed to represent the global factors by multiple tokens, which are extracted by cross-attention operation and then injected back by link-attention operation. Due to the rich representation of global factors, we manage to achieve high speaker similarity in a zero-shot manner. In addition, we introduce a prosody smoothing task to make the local prosody factor context-aware and therefore achieve satisfactory prosody continuity. We further achieve high voice quality with an adversarial training stage. In the subjective test, our method achieves state-of-the-art performance in both naturalness and similarity. Audio samples can be found at <a class="link-external link-https" href="https://ydcustc.github.io/retrieverTTS-demo/" rel="external noopener nofollow">this https URL</a>.      
### 8.On the Calculation of the Variance of Algebraic Variables in Power System Dynamic Models with Stochastic Processes  [ :arrow_down: ](https://arxiv.org/pdf/2206.13839.pdf)
>  This letter presents a technique to calculate the variance of algebraic variables of power system models represented as a set of stochastic differential-algebraic equations. The technique utilizes the solution of a Lyapunov equation and requires the calculation of the state matrix of the system. The IEEE 14-bus system serves to demonstrate the accuracy of the proposed technique over a wide range of variances of stochastic processes. The accuracy is evaluated by comparing the results with those obtained with Monte Carlo time domain simulations. Finally, a case study based on a 1479-bus dynamic model of the all-island Irish transmission system shows the computational efficiency of the proposed approach compared to the Monte Carlo method.      
### 9.Inertia Estimation through Covariance Matrix  [ :arrow_down: ](https://arxiv.org/pdf/2206.13838.pdf)
>  This work presents a technique to estimate on-line the inertia of a power system based on environment measurements. The proposed approach utilizes the covariance matrix of these measurements and solves an optimization problem that fits such measurements to the synchronous machine classical model. We show that the proposed technique is adequate to accurately estimate the actual inertia of synchronous machines and also the virtual inertia provided by the controllers of converter-interfaced generators that emulate the behavior of synchronous machines. We also show that the proposed approach is able to estimate the damping of the machines. This feature is exploited to estimate the droop of grid-following converters. The technique is comprehensively tested on a modified version of the IEEE 39-bus system.      
### 10.Influence of a Medium on Capacitive Power Transfer Capability  [ :arrow_down: ](https://arxiv.org/pdf/2206.13811.pdf)
>  Despite the advantages of capacitive power transfer (CPT), inductive power transfer (IPT) is still preferred. The reason: IPT systems have a gap power density in air that is 400 times greater. Conclusively, IPT can transmit more power than CPT over greater distances in air, but what about other media? This paper gives an answer on how media, different from air, influence the power transfer over different distances. First, we analyze theoretically the capacitive coupling with different media in the gap. Next, we simulate the CPT system using finite element software and compared it with the theoretical analysis. Finally, we employ the results of the finite element simulation in a power electronic simulation to examine the influence of the medium on the electrical power transfer.      
### 11.Speaker Verification in Multi-Speaker Environments Using Temporal Feature Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2206.13808.pdf)
>  Verifying the identity of a speaker is crucial in modern human-machine interfaces, e.g., to ensure privacy protection or to enable biometric authentication. Classical speaker verification (SV) approaches estimate a fixed-dimensional embedding from a speech utterance that encodes the speaker's voice characteristics. A speaker is verified if his/her voice embedding is sufficiently similar to the embedding of the claimed speaker. However, such approaches assume that only a single speaker exists in the input. The presence of concurrent speakers is likely to have detrimental effects on the performance. To address SV in a multi-speaker environment, we propose an end-to-end deep learning-based SV system that detects whether the target speaker exists within an input or not. First, an embedding is estimated from a reference utterance to represent the target's characteristics. Second, frame-level features are estimated from the input mixture. The reference embedding is then fused frame-wise with the mixture's features to allow distinguishing the target from other speakers on a frame basis. Finally, the fused features are used to predict whether the target speaker is active in the speech segment or not. Experimental evaluation shows that the proposed method outperforms the x-vector in multi-speaker conditions.      
### 12.Two Methods for Spoofing-Aware Speaker Verification: Multi-Layer Perceptron Score Fusion Model and Integrated Embedding Projector  [ :arrow_down: ](https://arxiv.org/pdf/2206.13807.pdf)
>  The use of deep neural networks (DNN) has dramatically elevated the performance of automatic speaker verification (ASV) over the last decade. However, ASV systems can be easily neutralized by spoofing attacks. Therefore, the Spoofing-Aware Speaker Verification (SASV) challenge is designed and held to promote development of systems that can perform ASV considering spoofing attacks by integrating ASV and spoofing countermeasure (CM) systems. In this paper, we propose two back-end systems: multi-layer perceptron score fusion model (MSFM) and integrated embedding projector (IEP). The MSFM, score fusion back-end system, derived SASV score utilizing ASV and CM scores and embeddings. On the other hand,IEP combines ASV and CM embeddings into SASV embedding and calculates final SASV score based on the cosine similarity. We effectively integrated ASV and CM systems through proposed MSFM and IEP and achieved the SASV equal error rates 0.56%, 1.32% on the official evaluation trials of the SASV 2022 challenge.      
### 13.Multivariable Grid-Forming Converters with Direct States Control  [ :arrow_down: ](https://arxiv.org/pdf/2206.13804.pdf)
>  A multi-input multi-output based grid-forming (MIMO-GFM) converter has been proposed using multivariable feedback control, which has been proven as a superior and robust system using low-order controllers. However, the original MIMO-GFM control is easily affected by the high-frequency components especially for the converter without inner cascaded voltage and current loops and when it is connected into a strong grid. This paper proposes an improved MIMO-GFM control method, where the frequency and internal voltage are chosen as state variables to be controlled directly. In this way, the impact of high-frequency components is eliminated without increasing the complexity of the control system. The H-infinity synthesis is used to tune the parameters to obtain an optimized performance. Experimental results verify the effectiveness of the proposed method.      
### 14.Optimisation models for the day-ahead energy and reserve scheduling of a hybrid wind-battery virtual power plant  [ :arrow_down: ](https://arxiv.org/pdf/2206.13784.pdf)
>  This work presents a suite of two optimisation models for the short-term scheduling and redispatch of a virtual power plant (VPP) composed of a wind farm and a Li-ion battery, that participates in the day-ahead energy and secondary regulation reserve markets of the Iberian electricity market. First, a two-stage stochastic mixed-integer linear programming model is used to obtain the VPP's generation and reserve schedule and the opportunity cost of the energy stored in the battery. The model has an hourly resolution and a look-ahead period beyond the markets' scheduling horizon and considers the hourly battery degradation costs as a function of both the depth of discharge and the discharge rate. Different strategies are evaluated to forecast the real-time use of the committed secondary regulation reserves. Second, a deterministic MILP model is used to determine the redispatch of the VPP using as input the generation and reserve schedule and the VPP's storage opportunity cost provided by the former model and is executed on an hourly rolling basis. The results obtained show that the proposed models are effective for the short-term scheduling and redispatch of the VPP used with a low computational time, making them tractable and practical for their daily use.      
### 15.Assessment of U.S. Department of Transportation Lane-Level Map for Connected Vehicle Applications  [ :arrow_down: ](https://arxiv.org/pdf/2206.13774.pdf)
>  High-definition (Hi-Def) digital maps are an indispensable automated driving technology that is developing rapidly. There are various commercial or governmental map products in the market. It is notable that the U.S. Department of Transportation (USDOT) map tool allows the user to create MAP and Signal Phase and Timing (SPaT) messages with free access. However, an analysis of the accuracy of this map tool is currently lacking in the literature. This paper provides such an analysis. The analysis manually selects 39 feature points within about 200 meters of the verified point and 55 feature points over longer distances from the verified point. All feature locations are surveyed using GNSS and mapped using the USDOT tool. Different error sources are evaluated to allow assessment of the USDOT map accuracy. In this investigation, The USDOT map tool is demonstrated to achieve 17 centimeters horizontal accuracy, which meets the lane-level map requirement. The maximum horizontal map error is less than 30 centimeters.      
### 16.Algorithms for audio inpainting based on probabilistic nonnegative matrix factorization  [ :arrow_down: ](https://arxiv.org/pdf/2206.13768.pdf)
>  Audio inpainting, i.e., the task of restoring missing or occluded audio signal samples, usually relies on sparse representations or autoregressive modeling. In this paper, we propose to structure the spectrogram with nonnegative matrix factorization (NMF) in a probabilistic framework. First, we treat the missing samples as latent variables, and derive two expectation-maximization algorithms for estimating the parameters of the model, depending on whether we formulate the problem in the time- or time-frequency domain. Then, we treat the missing samples as parameters, and we address this novel problem by deriving an alternating minimization scheme. We assess the potential of these algorithms for the task of restoring short- to middle-length gaps in music signals. Experiments reveal great convergence properties of the proposed methods, as well as competitive performance when compared to state-of-the-art audio inpainting techniques.      
### 17.A Hierarchical Speaker Representation Framework for One-shot Singing Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2206.13762.pdf)
>  Typically, singing voice conversion (SVC) depends on an embedding vector, extracted from either a speaker lookup table (LUT) or a speaker recognition network (SRN), to model speaker identity. However, singing contains more expressive speaker characteristics than conversational speech. It is suspected that a single embedding vector may only capture averaged and coarse-grained speaker characteristics, which is insufficient for the SVC task. To this end, this work proposes a novel hierarchical speaker representation framework for SVC, which can capture fine-grained speaker characteristics at different granularity. It consists of an up-sampling stream and three down-sampling streams. The up-sampling stream transforms the linguistic features into audio samples, while one down-sampling stream of the three operates in the reverse direction. It is expected that the temporal statistics of each down-sampling block can represent speaker characteristics at different granularity, which will be engaged in the up-sampling blocks to enhance the speaker modeling. Experiment results verify that the proposed method outperforms both the LUT and SRN based SVC systems. Moreover, the proposed system supports the one-shot SVC with only a few seconds of reference audio.      
### 18.Interrelate Training and Searching: A Unified Online Clustering Framework for Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2206.13760.pdf)
>  For online speaker diarization, samples arrive incrementally, and the overall distribution of the samples is invisible. Moreover, in most existing clustering-based methods, the training objective of the embedding extractor is not designed specially for clustering. To improve online speaker diarization performance, we propose a unified online clustering framework, which provides an interactive manner between embedding extractors and clustering algorithms. Specifically, the framework consists of two highly coupled parts: clustering-guided recurrent training (CGRT) and truncated beam searching clustering (TBSC). The CGRT introduces the clustering algorithm into the training process of embedding extractors, which could provide not only cluster-aware information for the embedding extractor, but also crucial parameters for the clustering process afterward. And with these parameters, which contain preliminary information of the metric space, the TBSC penalizes the probability score of each cluster, in order to output more accurate clustering results in online fashion with low latency. With the above innovations, our proposed online clustering system achieves 14.48\% DER with collar 0.25 at 2.5s latency on the AISHELL-4, while the DER of the offline agglomerative hierarchical clustering is 14.57\%.      
### 19.GAN-based Super-Resolution and Segmentation of Retinal Layers in Optical coherence tomography Scans  [ :arrow_down: ](https://arxiv.org/pdf/2206.13740.pdf)
>  In this paper, we design a Generative Adversarial Network (GAN)-based solution for super-resolution and segmentation of optical coherence tomography (OCT) scans of the retinal layers. OCT has been identified as a non-invasive and inexpensive modality of imaging to discover potential biomarkers for the diagnosis and progress determination of neurodegenerative diseases, such as Alzheimer's Disease (AD). Current hypotheses presume the thickness of the retinal layers, which are analyzable within OCT scans, can be effective biomarkers. As a logical first step, this work concentrates on the challenging task of retinal layer segmentation and also super-resolution for higher clarity and accuracy. We propose a GAN-based segmentation model and evaluate incorporating popular networks, namely, U-Net and ResNet, in the GAN architecture with additional blocks of transposed convolution and sub-pixel convolution for the task of upscaling OCT images from low to high resolution by a factor of four. We also incorporate the Dice loss as an additional reconstruction loss term to improve the performance of this joint optimization task. Our best model configuration empirically achieved the Dice coefficient of 0.867 and mIOU of 0.765.      
### 20.Low Altitude 3-D Coverage Performance Analysis in Cell-Free Distributed Collaborative Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.13722.pdf)
>  To improve the poor performance of distributed operation and non-scalability of centralized operation in traditional cell-free massive MIMO, we propose a cell-free distributed collaborative (CFDC) massive multiple-input multiple-output (MIMO) system based on a novel two-layer model to take advantages of the distributed cloud-edge-end collaborative architecture in beyond 5G (B5G) internet of things (IoT) environment to provide strong flexibility and scalability. We further ultilize the proposed CFDC massive MIMO system to support the low altitude three-dimensional (3-D) coverage scenario with unmanned aerial vehicles (UAVs), while accounting for 3-D Rician channel estimation, user-centric association and different scalable receiving schemes. Since coexisted UAVs and ground users (GUEs) cause greater interference, we ultilize user-centric association strategy and minimum-mean-square error (MMSE) channel state information (CSI) estimation to obtain the estimated CSI of UAVs and GUEs. Under the CFDC scenarios, scalable receiving schemes as maximum ratio combing (MRC), partial zero-forcing (P-ZF) and partial minimum-mean-square error (P-MMSE) can be performed at edge servers and the closed-form expressions for uplink spectral efficiency (SE) are derived. Based on the derived expressions, we propose an efficient power control algorithm by solving a multi-objective optimization problem (MOOP) between maximizing the average SE of UAVs and GUEs simultaneously with Deep Q-Network (DQN). Numerical results verify the accuracy of the derived closed-form expressions and the effectiveness of the coexisted UAVs and GUEs transmission scheme in CFDC massive MIMO systems. The SE analysis under various system parameters offers numerous flexibilities for system optimization.      
### 21.Learning from human perception to improve automatic speaker verification in style-mismatched conditions  [ :arrow_down: ](https://arxiv.org/pdf/2206.13684.pdf)
>  Our prior experiments show that humans and machines seem to employ different approaches to speaker discrimination, especially in the presence of speaking style variability. The experiments examined read versus conversational speech. Listeners focused on speaker-specific idiosyncrasies while "telling speakers together", and on relative distances in a shared acoustic space when "telling speakers apart". However, automatic speaker verification (ASV) systems use the same loss function irrespective of target or non-target trials. To improve ASV performance in the presence of style variability, insights learnt from human perception are used to design a new training loss function that we refer to as "CllrCE loss". CllrCE loss uses both speaker-specific idiosyncrasies and relative acoustic distances between speakers to train the ASV system. When using the UCLA speaker variability database, in the x-vector and conditioning setups, CllrCE loss results in significant relative improvements in EER by 1-66%, and minDCF by 1-31% and 1-56%, respectively, when compared to the x-vector baseline. Using the SITW evaluation tasks, which involve different conversational speech tasks, the proposed loss combined with self-attention conditioning results in significant relative improvements in EER by 2-5% and minDCF by 6-12% over baseline. In the SITW case, performance improvements were consistent only with conditioning.      
### 22.Attention-based conditioning methods using variable frame rate for style-robust speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2206.13680.pdf)
>  We propose an approach to extract speaker embeddings that are robust to speaking style variations in text-independent speaker verification. Typically, speaker embedding extraction includes training a DNN for speaker classification and using the bottleneck features as speaker representations. Such a network has a pooling layer to transform frame-level to utterance-level features by calculating statistics over all utterance frames, with equal weighting. However, self-attentive embeddings perform weighted pooling such that the weights correspond to the importance of the frames in a speaker classification task. Entropy can capture acoustic variability due to speaking style variations. Hence, an entropy-based variable frame rate vector is proposed as an external conditioning vector for the self-attention layer to provide the network with information that can address style effects. This work explores five different approaches to conditioning. The best conditioning approach, concatenation with gating, provided statistically significant improvements over the x-vector baseline in 12/23 tasks and was the same as the baseline in 11/23 tasks when using the UCLA speaker variability database. It also significantly outperformed self-attention without conditioning in 9/23 tasks and was worse in 1/23. The method also showed significant improvements in multi-speaker scenarios of SITW.      
### 23.Omni-Seg+: A Scale-aware Dynamic Network for Pathological Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.13632.pdf)
>  Comprehensive semantic segmentation on renal pathological images is challenging due to the heterogeneous scales of the objects. For example, on a whole slide image (WSI), the cross-sectional areas of glomeruli can be 64 times larger than that of the peritubular capillaries, making it impractical to segment both objects on the same patch, at the same scale. To handle this scaling issue, prior studies have typically trained multiple segmentation networks in order to match the optimal pixel resolution of heterogeneous tissue types. This multi-network solution is resource-intensive and fails to model the spatial relationship between tissue types. In this paper, we propose the Omni-Seg+ network, a scale-aware dynamic neural network that achieves multi-object (six tissue types) and multi-scale (5X to 40X scale) pathological image segmentation via a single neural network. The contribution of this paper is three-fold: (1) a novel scale-aware controller is proposed to generalize the dynamic neural network from single-scale to multi-scale; (2) semi-supervised consistency regularization of pseudo-labels is introduced to model the inter-scale correlation of unannotated tissue types into a single end-to-end learning paradigm; and (3) superior scale-aware generalization is evidenced by directly applying a model trained on human kidney images to mouse kidney images, without retraining. By learning from ~150,000 human pathological image patches from six tissue types at three different resolutions, our approach achieved superior segmentation performance according to human visual assessment and evaluation of image-omics (i.e., spatial transcriptomics). The official implementation is available at <a class="link-external link-https" href="https://github.com/ddrrnn123/Omni-Seg" rel="external noopener nofollow">this https URL</a>.      
### 24.Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic MRI  [ :arrow_down: ](https://arxiv.org/pdf/2206.13618.pdf)
>  This work develops a fast, memory-efficient, and general algorithm for accelerated/undersampled dynamic MRI by assuming an approximate LR model on the matrix formed by the vectorized images of the sequence. By general, we mean that our algorithm can be used for multiple accelerated dynamic MRI applications and multiple sampling rates (acceleration rates) without any parameter changes. We show that our proposed algorithm, alternating Gradient Descent (GD) and minimization for MRI (altGDmin-MRI), outperforms many existing approaches on 6 different dynamic MRI applications, while also being faster (or much faster) than all of them. Our second contribution is a fully online and mini-batch extensions of this algorithm that can process new measurements and return reconstructions either as soon as measurements of a new image frame arrive, or after a short mini-batch of measurement vectors arrives.      
### 25.Flexible-Rate Learned Hierarchical Bi-Directional Video Compression With Motion Refinement and Frame-Level Bit Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2206.13613.pdf)
>  This paper presents improvements and novel additions to our recent work on end-to-end optimized hierarchical bi-directional video compression to further advance the state-of-the-art in learned video compression. As an improvement, we combine motion estimation and prediction modules and compress refined residual motion vectors for improved rate-distortion performance. As novel addition, we adapted the gain unit proposed for image compression to flexible-rate video compression in two ways: first, the gain unit enables a single encoder model to operate at multiple rate-distortion operating points; second, we exploit the gain unit to control bit allocation among intra-coded vs. bi-directionally coded frames by fine tuning corresponding models for truly flexible-rate learned video coding. Experimental results demonstrate that we obtain state-of-the-art rate-distortion performance exceeding those of all prior art in learned video coding.      
### 26.Reduced Optimal Power Flow Using Graph Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2206.13591.pdf)
>  OPF problems are formulated and solved for power system operations, especially for determining generation dispatch points in real-time. For large and complex power system networks with large numbers of variables and constraints, finding the optimal solution for real-time OPF in a timely manner requires a massive amount of computing power. This paper presents a new method to reduce the number of constraints in the original OPF problem using a graph neural network (GNN). GNN is an innovative machine learning model that utilizes features from nodes, edges, and network topology to maximize its performance. In this paper, we proposed a GNN model to predict which lines would be heavily loaded or congested with given load profiles and generation capacities. Only these critical lines will be monitored in an OPF problem, creating a reduced OPF (ROPF) problem. Significant saving in computing time is expected from the proposed ROPF model. A comprehensive analysis of predictions from the GNN model was also made. It is concluded that the application of GNN for ROPF is able to reduce computing time while retaining solution quality.      
### 27.Heterogeneous mixtures of dictionary functions to approximate subspace invariance in Koopman operators  [ :arrow_down: ](https://arxiv.org/pdf/2206.13585.pdf)
>  Koopman operators model nonlinear dynamics as a linear dynamic system acting on a nonlinear function as the state. This nonstandard state is often called a Koopman observable and is usually approximated numerically by a superposition of functions drawn from a \textit{dictionary}. A widely used algorithm, is \textit{Extended Dynamic Mode Decomposition}, where the dictionary functions are drawn from a fixed, homogeneous class of functions. Recently, deep learning combined with EDMD has been used to learn novel dictionary functions in an algorithm called deep dynamic mode decomposition (deepDMD). The learned representation both (1) accurately models and (2) scales well with the dimension of the original nonlinear system. In this paper we analyze the learned dictionaries from deepDMD and explore the theoretical basis for their strong performance. We discover a novel class of dictionary functions to approximate Koopman observables. Error analysis of these dictionary functions show they satisfy a property of subspace approximation, which we define as uniform finite approximate closure. We discover that structured mixing of heterogeneous dictionary functions drawn from different classes of nonlinear functions achieve the same accuracy and dimensional scaling as deepDMD. This mixed dictionary does so with an order of magnitude reduction in parameters, while maintaining geometric interpretability. Our results provide a hypothesis to explain the success of deep neural networks in learning numerical approximations to Koopman operators.      
### 28.Design and control analysis of a deployable clustered hyperbolic paraboloid cable net  [ :arrow_down: ](https://arxiv.org/pdf/2206.13511.pdf)
>  This paper presents an analytical and experimental design and deployment control analysis of a hyperbolic paraboloid cable net based on clustering actuation strategies. First, the dynamics and statics for clustered tensegrity structures (CTS) are given. Then, we propose the topology design of the deployable hyperbolic paraboloid cable net. The deployability of the cable net is achieved by using clustered cables. It is shown that the clustered cables significantly reduce the number of actuators required for control. The deployment trajectory and actuation prestress in the cables are designed to ensure the tensions are feasible during the deployment process. Then, we compare the deployment analysis's open-loop and closed-loop control strategies. Finally, a lab-scale model is constructed to validate the actuation laws. We test the static performance and deployment process of the experimental model. Results show that the closed-loop control approach is more stable and smoother than the open-loop one in the deployment process. The approaches developed in this paper can also be used for various deployable tensegrity structures.      
### 29.Tensor Recovery Based on A Novel Non-convex Function Minimax Logarithmic Concave Penalty Function  [ :arrow_down: ](https://arxiv.org/pdf/2206.13506.pdf)
>  Non-convex relaxation methods have been widely used in tensor recovery problems, and compared with convex relaxation methods, can achieve better recovery results. In this paper, a new non-convex function, Minimax Logarithmic Concave Penalty (MLCP) function, is proposed, and some of its intrinsic properties are analyzed, among which it is interesting to find that the Logarithmic function is an upper bound of the MLCP function. The proposed function is generalized to tensor cases, yielding tensor MLCP and weighted tensor $L\gamma$-norm. Consider that its explicit solution cannot be obtained when applying it directly to the tensor recovery problem. Therefore, the corresponding equivalence theorems to solve such problem are given, namely, tensor equivalent MLCP theorem and equivalent weighted tensor $L\gamma$-norm theorem. In addition, we propose two EMLCP-based models for classic tensor recovery problems, namely low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA), and design proximal alternate linearization minimization (PALM) algorithms to solve them individually. Furthermore, based on the Kurdyka-Łojasiwicz property, it is proved that the solution sequence of the proposed algorithm has finite length and converges to the critical point globally. Finally, Extensive experiments show that proposed algorithm achieve good results, and it is confirmed that the MLCP function is indeed better than the Logarithmic function in the minimization problem, which is consistent with the analysis of theoretical properties.      
### 30.Deep Learning-Based Defect Classification and Detection in SEM Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.13505.pdf)
>  This proposes a novel ensemble deep learning-based model to accurately classify, detect and localize different defect categories for aggressive pitches and thin resists (High NA applications).In particular, we train RetinaNet models using different ResNet, VGGNet architectures as backbone and present the comparison between the accuracies of these models and their performance analysis on SEM images with different types of defect patterns such as bridge, break and line collapses. Finally, we propose a preference-based ensemble strategy to combine the output predictions from different models in order to achieve better performance on classification and detection of defects. As CDSEM images inherently contain a significant level of noise, detailed feature information is often shadowed by noise. For certain resist profiles, the challenge is also to differentiate between a microbridge, footing, break, and zones of probable breaks. Therefore, we have applied an unsupervised machine learning model to denoise the SEM images to remove the False-Positive defects and optimize the effect of stochastic noise on structured pixels for better metrology and enhanced defect inspection. We repeated the defect inspection step with the same trained model and performed a comparative analysis for "robustness" and "accuracy" metric with conventional approach for both noisy/denoised image pair. The proposed ensemble method demonstrates improvement of the average precision metric (mAP) of the most difficult defect classes. In this work we have developed a novel robust supervised deep learning training scheme to accurately classify as well as localize different defect types in SEM images with high degree of accuracy. Our proposed approach demonstrates its effectiveness both quantitatively and qualitatively.      
### 31.AI-based computer-aided diagnostic system of chest digital tomography synthesis: Demonstrating comparative advantage with X-ray-based AI systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.13504.pdf)
>  Compared with chest X-ray (CXR) imaging, which is a single image projected from the front of the patient, chest digital tomosynthesis (CDTS) imaging can be more advantageous for lung lesion detection because it acquires multiple images projected from multiple angles of the patient. Various clinical comparative analysis and verification studies have been reported to demonstrate this, but there were no artificial intelligence (AI)-based comparative analysis studies. Existing AI-based computer-aided detection (CAD) systems for lung lesion diagnosis have been developed mainly based on CXR images; however, CAD-based on CDTS, which uses multi-angle images of patients in various directions, has not been proposed and verified for its usefulness compared to CXR-based counterparts. This study develops/tests a CDTS-based AI CAD system to detect lung lesions to demonstrate performance improvements compared to CXR-based AI CAD. We used multiple projection images as input for the CDTS-based AI model and a single-projection image as input for the CXR-based AI model to fairly compare and evaluate the performance between models. The proposed CDTS-based AI CAD system yielded sensitivities of 0.782 and 0.785 and accuracies of 0.895 and 0.837 for the performance of detecting tuberculosis and pneumonia, respectively, against normal subjects. These results show higher performance than sensitivities of 0.728 and 0.698 and accuracies of 0.874 and 0.826 for detecting tuberculosis and pneumonia through the CXR-based AI CAD, which only uses a single projection image in the frontal direction. We found that CDTS-based AI CAD improved the sensitivity of tuberculosis and pneumonia by 5.4% and 8.7% respectively, compared to CXR-based AI CAD without loss of accuracy. Therefore, we comparatively prove that CDTS-based AI CAD technology can improve performance more than CXR, enhancing the clinical applicability of CDTS.      
### 32.Zero-Shot Building Control  [ :arrow_down: ](https://arxiv.org/pdf/2206.14191.pdf)
>  Heating and cooling systems in buildings account for 31% of global energy use, much of which are regulated by Rule Based Controllers (RBCs) that neither maximise energy efficiency nor minimise emissions by interacting optimally with the grid. Control via Reinforcement Learning (RL) has been shown to significantly improve building energy efficiency, but existing solutions require pre-training in simulators that are prohibitively expensive to obtain for every building in the world. In response, we show it is possible to perform safe, zero-shot control of buildings by combining ideas from system identification and model-based RL. We call this combination PEARL (Probabilistic Emission-Abating Reinforcement Learning) and show it reduces emissions without pre-training, needing only a three hour commissioning period. In experiments across three varied building energy simulations, we show PEARL outperforms an existing RBC once, and popular RL baselines in all cases, reducing building emissions by as much as 31% whilst maintaining thermal comfort.      
### 33.Autonomous Smart Grid Fault Detection  [ :arrow_down: ](https://arxiv.org/pdf/2206.14150.pdf)
>  Smart grid plays a crucial role for the smart society and the upcoming carbon neutral society. Achieving autonomous smart grid fault detection is critical for smart grid system state awareness, maintenance and operation. This paper focuses on fault monitoring in smart grid and discusses the inherent technical challenges and solutions. In particular, we first present the basic principles of smart grid fault detection. Then, we explain the new requirements for autonomous smart grid fault detection, the technical challenges and their possible solutions. A case study is introduced, as a preliminary study for autonomous smart grid fault detection. In addition, we highlight relevant directions for future research.      
### 34.Let the paintings play  [ :arrow_down: ](https://arxiv.org/pdf/2206.14142.pdf)
>  In this paper, we introduce a mathematical method to extract similarities between paintings and musical tracks. Our approach is based on the digitalization of both paintings and musical tracks by means of finite expansions in terms of orthogonal basis functions (with both Fourier and wavelet bases). The best fit between a specific painting and a sample of musical tracks from a given composer is achieved via an $L^2$ projection upon a finite-dimensional subspace. Several examples are provided for the analysis of a collection of works of art by the Italian artist Marcello Morandini. Finally, we have developed an original applet that implements the process above and which can be freely downloaded from the site <a class="link-external link-https" href="https://github.com/pgerva/playing-paintings.git" rel="external noopener nofollow">this https URL</a>      
### 35.Learning Variable Impedance Control for Aerial Sliding on Uneven Heterogeneous Surfaces by Proprioceptive and Tactile Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2206.14122.pdf)
>  The recent development of novel aerial vehicles capable of physically interacting with the environment leads to new applications such as contact-based inspection. These tasks require the robotic system to exchange forces with partially-known environments, which may contain uncertainties including unknown spatially-varying friction properties and discontinuous variations of the surface geometry. Finding a control strategy that is robust against these environmental uncertainties remains an open challenge. This paper presents a learning-based adaptive control strategy for aerial sliding tasks. In particular, the gains of a standard impedance controller are adjusted in real-time by a policy based on the current control signals, proprioceptive measurements, and tactile sensing. This policy is trained in simulation with simplified actuator dynamics in a student-teacher learning setup. The real-world performance of the proposed approach is verified using a tilt-arm omnidirectional flying vehicle. The proposed controller structure combines data-driven and model-based control methods, enabling our approach to successfully transfer directly and without adaptation from simulation to the real platform. Compared to fine-tuned state of the art interaction control methods we achieve reduced tracking error and improved disturbance rejection.      
### 36.Equivariant Priors for Compressed Sensing with Unknown Orientation  [ :arrow_down: ](https://arxiv.org/pdf/2206.14069.pdf)
>  In compressed sensing, the goal is to reconstruct the signal from an underdetermined system of linear measurements. Thus, prior knowledge about the signal of interest and its structure is required. Additionally, in many scenarios, the signal has an unknown orientation prior to measurements. To address such recovery problems, we propose using equivariant generative models as a prior, which encapsulate orientation information in their latent space. Thereby, we show that signals with unknown orientations can be recovered with iterative gradient descent on the latent space of these models and provide additional theoretical recovery guarantees. We construct an equivariant variational autoencoder and use the decoder as generative prior for compressed sensing. We discuss additional potential gains of the proposed approach in terms of convergence and latency.      
### 37.Bengali Common Voice Speech Dataset for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.14053.pdf)
>  Bengali is one of the most spoken languages in the world with over 300 million speakers globally. Despite its popularity, research into the development of Bengali speech recognition systems is hindered due to the lack of diverse open-source datasets. As a way forward, we have crowdsourced the Bengali Common Voice Speech Dataset, which is a sentence-level automatic speech recognition corpus. Collected on the Mozilla Common Voice platform, the dataset is part of an ongoing campaign that has led to the collection of over 400 hours of data in 2 months and is growing rapidly. Our analysis shows that our dataset has more speaker, phoneme, and environmental diversity compared to the OpenSLR Bengali ASR dataset, the largest existing open-source Bengali speech dataset. We present insights obtained from the dataset and discuss key linguistic challenges that need to be addressed in future versions. Additionally, we report the current performance of a few Automatic Speech Recognition (ASR) algorithms and set a benchmark for future research.      
### 38.Show Me Your Face, And I'll Tell You How You Speak  [ :arrow_down: ](https://arxiv.org/pdf/2206.14009.pdf)
>  When we speak, the prosody and content of the speech can be inferred from the movement of our lips. In this work, we explore the task of lip to speech synthesis, i.e., learning to generate speech given only the lip movements of a speaker where we focus on learning accurate lip to speech mappings for multiple speakers in unconstrained, large vocabulary settings. We capture the speaker's voice identity through their facial characteristics, i.e., age, gender, ethnicity and condition them along with the lip movements to generate speaker identity aware speech. To this end, we present a novel method "Lip2Speech", with key design choices to achieve accurate lip to speech synthesis in unconstrained scenarios. We also perform various experiments and extensive evaluation using quantitative, qualitative metrics and human evaluation.      
### 39.Orthogonal Delay-Doppler Division Multiplexing Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2206.13999.pdf)
>  Inspired by the orthogonal time frequency space (OTFS) modulation, in this paper, we consider designing a multicarrier (MC) modulation on delay-Doppler (DD) plane, to couple the modulated signal with a doubly-selective channel having DD resolutions. A key challenge for the design of DD plane MC modulation is to investigate whether a realizable pulse orthogonal with respect to the DD plane's fine resolutions exists or not. To this end, we first indicate that a feasible DD plane MC modulation is essentially a type of staggered multitone modulation. Then, analogous to orthogonal frequency division multiplexing, we propose an orthogonal delay-Doppler division multiplexing (ODDM) modulation, and design the corresponding transmit pulse. Furthermore, we prove that the proposed transmit pulse is orthogonal with respect to the DD plane's resolutions and therefore a realizable DD plane orthogonal pulse does exist. The orthogonality of this particular pulse significantly eases the derivation of the ODDM's DD domain channel input-output relation, and yields a channel matrix with an elegant block-circulant-like structure. We demonstrate that the ODDM outperforms the OTFS in terms of out-of-band emission and bit error rate, by achieving perfect coupling between the modulated signal and the DD channel.      
### 40.Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data -- An Algorithm and A Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2206.13932.pdf)
>  This paper introduces an efficient algorithm for persistence diagram computation, given an input piecewise linear scalar field f defined on a d-dimensional simplicial complex K, with $d \leq 3$. Our method extends the seminal "PairCells" algorithm by introducing three main accelerations. First, we express this algorithm within the setting of discrete Morse theory, which considerably reduces the number of input simplices to consider. Second, we introduce a stratification approach to the problem, that we call "sandwiching". Specifically, minima-saddle persistence pairs ($D_0(f)$) and saddle-maximum persistence pairs ($D_{d-1}(f)$) are efficiently computed by respectively processing with a Union-Find the unstable sets of 1-saddles and the stable sets of (d-1)-saddles. This fast processing of the dimensions 0 and (d-1) further reduces, and drastically, the number of critical simplices to consider for the computation of $D_1(f)$, the intermediate layer of the sandwich. Third, we document several performance improvements via shared-memory parallelism. We provide an open-source implementation of our algorithm for reproducibility purposes. We also contribute a reproducible benchmark package, which exploits three-dimensional data from a public repository and compares our algorithm to a variety of publicly available implementations. Extensive experiments indicate that our algorithm improves by two orders of magnitude the time performance of the seminal "PairCells" algorithm it extends. Moreover, it also improves memory footprint and time performance over a selection of 14 competing approaches, with a substantial gain over the fastest available approaches, while producing a strictly identical output. We illustrate the utility of our contributions with an application to the fast and robust extraction of persistent 1-dimensional generators on surfaces, volume data and high-dimensional point clouds.      
### 41.Grid Tariffs for Peak Demand Reduction: Is there a Price Signal Conflict with Electricity Spot Prices?  [ :arrow_down: ](https://arxiv.org/pdf/2206.13916.pdf)
>  The electricity grid is expected to require vast investments due to the decarbonization-by-electrification trend, calling for a change in grid tariff design which provides proper incentives for reducing peak loads. However, price signals from grid tariffs could be distorted from electricity spot prices which also represents a significant of the total consumer electricity bill. This paper attempts to identify whether there is a price signal conflict between grid tariffs and spot prices. Four different grid tariff designs are compared, using a generic demand response model as part of a cost-minimizing linear program to simulate the reduction in peak load. The method is applied to metered electricity demand from 3608 consumers in Oslo, Norway. Results show that new grid tariff designs reduce peak loads by 1-4%, and that reduction in peak load is smaller when consumers are subject to electricity spot prices.      
### 42.QTI Submission to DCASE 2021: residual normalization for device-imbalanced acoustic scene classification with efficient design  [ :arrow_down: ](https://arxiv.org/pdf/2206.13909.pdf)
>  This technical report describes the details of our TASK1A submission of the DCASE2021 challenge. The goal of the task is to design an audio scene classification system for device-imbalanced datasets under the constraints of model complexity. This report introduces four methods to achieve the goal. First, we propose Residual Normalization, a novel feature normalization method that uses instance normalization with a shortcut path to discard unnecessary device-specific information without losing useful information for classification. Second, we design an efficient architecture, BC-ResNet-Mod, a modified version of the baseline architecture with a limited receptive field. Third, we exploit spectrogram-to-spectrogram translation from one to multiple devices to augment training data. Finally, we utilize three model compression schemes: pruning, quantization, and knowledge distillation to reduce model complexity. The proposed system achieves an average test accuracy of 76.3% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with 315k parameters, and average test accuracy of 75.3% after compression to 61.0KB of non-zero parameters.      
### 43.CSI Sensing from Heterogeneous User Feedbacks: A Constrained Phase Retrieval Approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.13882.pdf)
>  This paper investigates the downlink channel state information (CSI) sensing in 5G heterogeneous networks composed of user equipments (UEs) with different feedback capabilities. We aim to enhance the CSI accuracy of UEs only affording the low-resolution Type-I codebook. While existing works have demonstrated that the task can be accomplished by solving a phase retrieval (PR) formulation based on the feedback of precoding matrix indicator (PMI) and channel quality indicator (CQI), they need many feedback rounds. In this paper, we propose a novel CSI sensing scheme that can significantly reduce the feedback overhead. Our scheme involves a novel parameter dimension reduction design by exploiting the spatial consistency of wireless channels among nearby UEs, and a constrained PR (CPR) formulation that characterizes the feasible region of CSI by the PMI information. To address the computational challenge due to the non-convexity and the large number of constraints of CPR, we develop a two-stage algorithm that firstly identifies and removes inactive constraints, followed by a fast first-order algorithm. The study is further extended to multi-carrier systems. Extensive tests over DeepMIMO and QuaDriGa datasets showcase that our designs greatly outperform existing methods and achieve the high-resolution Type-II codebook performance with a few rounds of feedback.      
### 44.Comparison of Speech Representations for the MOS Prediction System  [ :arrow_down: ](https://arxiv.org/pdf/2206.13817.pdf)
>  Automatic methods to predict Mean Opinion Score (MOS) of listeners have been researched to assure the quality of Text-to-Speech systems. Many previous studies focus on architectural advances (e.g. MBNet, LDNet, etc.) to capture relations between spectral features and MOS in a more effective way and achieved high accuracy. However, the optimal representation in terms of generalization capability still largely remains unknown. To this end, we compare the performance of Self-Supervised Learning (SSL) features obtained by the wav2vec framework to that of spectral features such as magnitude of spectrogram and melspectrogram. Moreover, we propose to combine the SSL features and features which we believe to retain essential information to the automatic MOS to compensate each other for their drawbacks. We conduct comprehensive experiments on a large-scale listening test corpus collected from past Blizzard and Voice Conversion Challenges. We found that the wav2vec feature set showed the best generalization even though the given ground-truth was not always reliable. Furthermore, we found that the combinations performed the best and analyzed how they bridged the gap between spectral and the wav2vec feature sets.      
### 45.Joint Precoding for Active Intelligent Transmitting Surface Empowered Outdoor-to-Indoor Communication in mmWave Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.13801.pdf)
>  Outdoor-to-indoor communications in millimeter-wave (mmWave) cellular networks have been one challenging research problem due to the severe attenuation and the high penetration loss caused by the propagation characteristics of mmWave signals. We propose a viable solution to implement the outdoor-to-indoor mmWave communication system with the aid of an active intelligent transmitting surface (active-ITS), where the active-ITS allows the incoming signal from an outdoor base station (BS) to pass through the surface and be received by the indoor user-equipments (UEs) after shifting its phase and magnifying its amplitude. Then, the problem of joint precoding of the BS and active-ITS is investigated to maximize the weighted sum-rate (WSR) of the communication system. An efficient block coordinate descent (BCD) based algorithm is developed to solve it with the suboptimal solutions in nearly closed-forms. In addition, to reduce the size and hardware cost of an active-ITS, we provide a block-amplifying architecture to partially remove the circuit components for power-amplifying, where multiple transmissive-type elements (TEs) in each block share a same power amplifier. Simulations indicate that active-ITS has the potential of achieving a given performance with much fewer TEs compared to the passive-ITS under the same total system power consumption, which makes it suitable for application to the size-limited and aesthetic-needed scenario, and the inevitable performance degradation caused by the block-amplifying architecture is acceptable.      
### 46.Exploring linguistic feature and model combination for speech recognition based automatic AD detection  [ :arrow_down: ](https://arxiv.org/pdf/2206.13758.pdf)
>  Early diagnosis of Alzheimer's disease (AD) is crucial in facilitating preventive care and delay progression. Speech based automatic AD screening systems provide a non-intrusive and more scalable alternative to other clinical screening techniques. Scarcity of such specialist data leads to uncertainty in both model selection and feature learning when developing such systems. To this end, this paper investigates the use of feature and model combination approaches to improve the robustness of domain fine-tuning of BERT and Roberta pre-trained text encoders on limited data, before the resulting embedding features being fed into an ensemble of backend classifiers to produce the final AD detection decision via majority voting. Experiments conducted on the ADReSS20 Challenge dataset suggest consistent performance improvements were obtained using model and feature combination in system development. State-of-the-art AD detection accuracies of 91.67 percent and 93.75 percent were obtained using manual and ASR speech transcripts respectively on the ADReSS20 test set consisting of 48 elderly speakers.      
### 47.Sub-Block Rearranged Staircase Codes for Optical Transport Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.13752.pdf)
>  We propose a new family of spatially coupled product codes, called sub-block rearranged staircase (SR-staircase) codes. Each SR-staircase code block is constructed by encoding rearranged preceding code blocks and new information blocks, where the rearrangement involves sub-blocks decomposition and transposition. The proposed codes can be constructed to have each code block size of $1/q$ to that of the conventional staircase codes while having the same rate and component codes, for any positive integer $q$. In this regard, we can use strong algebraic component codes to construct SR-staircase codes with a similar or the same code block size and rate as staircase codes with weak component codes. Moreover, both waterfall and error floor performance can be further improved by using a large coupling width. The superior performance of the proposed codes is demonstrated through density evolution and error floor analysis as well as simulation.      
### 48.Prescribed-Time Synchronization of Multiweighted and Directed Complex Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.13723.pdf)
>  In this note, we study the prescribed-time (PT) synchronization of multiweighted and directed complex networks (MWDCNs) via pinning control. Unlike finite-time and fixed-time synchronization, the time for synchronization can be preset as needed, which is independent of initial values and parameters like coupling strength. First and foremost, we reveal the essence of PT stability by improper integral, L'Hospital rule and Taylor expansion theory. Many controllers established previously for PT stability can be included in our new model. Then, we apply this new result on MWDCNs as an application. The synchronization error at the prescribed time is discussed carefully, so, PT synchronization can be reached. The network topology can be directed and disconnected, which means that the outer coupling matrices (OCMs) can be asymmetric and not connected. The relationships between nodes are allowed to be cooperative or competitive, so elements in OCMs and inner coupling matrices (ICMs) can be positive or negative. We use the rearranging variables' order technique to combine ICMs and OCMs together to get the sum matrices, which can make a bridge between multiweighted and single-weighted networks. Finally, simulations are presented to illustrate the effectiveness of our theory.      
### 49.Personalized Keyword Spotting through Multi-task Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.13708.pdf)
>  Keyword spotting (KWS) plays an essential role in enabling speech-based user interaction on smart devices, and conventional KWS (C-KWS) approaches have concentrated on detecting user-agnostic pre-defined keywords. However, in practice, most user interactions come from target users enrolled in the device which motivates to construct personalized keyword spotting. We design two personalized KWS tasks; (1) Target user Biased KWS (TB-KWS) and (2) Target user Only KWS (TO-KWS). To solve the tasks, we propose personalized keyword spotting through multi-task learning (PK-MTL) that consists of multi-task learning and task-adaptation. First, we introduce applying multi-task learning on keyword spotting and speaker verification to leverage user information to the keyword spotting system. Next, we design task-specific scoring functions to adapt to the personalized KWS tasks thoroughly. We evaluate our framework on conventional and personalized scenarios, and the results show that PK-MTL can dramatically reduce the false alarm rate, especially in various practical scenarios.      
### 50.Domain Agnostic Few-shot Learning for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2206.13700.pdf)
>  Deep learning models for verification systems often fail to generalize to new users and new environments, even though they learn highly discriminative features. To address this problem, we propose a few-shot domain generalization framework that learns to tackle distribution shift for new users and new domains. Our framework consists of domain-specific and domain-aggregation networks, which are the experts on specific and combined domains, respectively. By using these networks, we generate episodes that mimic the presence of both novel users and novel domains in the training phase to eventually produce better generalization. To save memory, we reduce the number of domain-specific networks by clustering similar domains together. Upon extensive evaluation on artificially generated noise domains, we can explicitly show generalization ability of our framework. In addition, we apply our proposed methods to the existing competitive architecture on the standard benchmark, which shows further performance improvements.      
### 51.Dummy Prototypical Networks for Few-Shot Open-Set Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2206.13691.pdf)
>  Keyword spotting is the task of detecting a keyword in streaming audio. Conventional keyword spotting targets predefined keywords classification, but there is growing attention in few-shot (query-by-example) keyword spotting, e.g., N-way classification given M-shot support samples. Moreover, in real-world scenarios, there can be utterances from unexpected categories (open-set) which need to be rejected rather than classified as one of the N classes. Combining the two needs, we tackle few-shot open-set keyword spotting with a new benchmark setting, named splitGSC. We propose episode-known dummy prototypes based on metric learning to detect an open-set better and introduce a simple and powerful approach, Dummy Prototypical Networks (D-ProtoNets). Our D-ProtoNets shows clear margins compared to recent few-shot open-set recognition (FSOSR) approaches in the suggested splitGSC. We also verify our method on a standard benchmark, miniImageNet, and D-ProtoNets shows the state-of-the-art open-set detection rate in FSOSR.      
### 52.Tiny-Sepformer: A Tiny Time-Domain Transformer Network for Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2206.13689.pdf)
>  Time-domain Transformer neural networks have proven their superiority in speech separation tasks. However, these models usually have a large number of network parameters, thus often encountering the problem of GPU memory explosion. In this paper, we proposed Tiny-Sepformer, a tiny version of Transformer network for speech separation. We present two techniques to reduce the model parameters and memory consumption: (1) Convolution-Attention (CA) block, spliting the vanilla Transformer to two paths, multi-head attention and 1D depthwise separable convolution, (2) parameter sharing, sharing the layer parameters within the CA block. In our experiments, Tiny-Sepformer could greatly reduce the model size, and achieves comparable separation performance with vanilla Sepformer on WSJ0-2/3Mix datasets.      
### 53.Feature Refinement to Improve High Resolution Image Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2206.13644.pdf)
>  In this paper, we address the problem of degradation in inpainting quality of neural networks operating at high resolutions. Inpainting networks are often unable to generate globally coherent structures at resolutions higher than their training set. This is partially attributed to the receptive field remaining static, despite an increase in image resolution. Although downscaling the image prior to inpainting produces coherent structure, it inherently lacks detail present at higher resolutions. To get the best of both worlds, we optimize the intermediate featuremaps of a network by minimizing a multiscale consistency loss at inference. This runtime optimization improves the inpainting results and establishes a new state-of-the-art for high resolution inpainting. Code is available at: <a class="link-external link-https" href="https://github.com/geomagical/lama-with-refiner/tree/refinement" rel="external noopener nofollow">this https URL</a>.      
### 54.Nonparametric, Nonasymptotic Confidence Bands with Paley-Wiener Kernels for Band-Limited Functions  [ :arrow_down: ](https://arxiv.org/pdf/2206.13629.pdf)
>  The paper introduces a method to construct confidence bands for bounded, band-limited functions based on a finite sample of input-output pairs. The approach is distribution-free w.r.t. the observation noises and only the knowledge of the input distribution is assumed. It is nonparametric, that is, it does not require a parametric model of the regression function and the regions have non-asymptotic guarantees. The algorithm is based on the theory of Paley-Wiener reproducing kernel Hilbert spaces. The paper first studies the fully observable variant, when there are no noises on the observations and only the inputs are random; then it generalizes the ideas to the noisy case using gradient-perturbation methods. Finally, numerical experiments demonstrating both cases are presented.      
### 55.ClearBuds: Wireless Binaural Earbuds for Learning-Based Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2206.13611.pdf)
>  We present ClearBuds, the first hardware and software system that utilizes a neural network to enhance speech streamed from two wireless earbuds. Real-time speech enhancement for wireless earbuds requires high-quality sound separation and background cancellation, operating in real-time and on a mobile phone. Clear-Buds bridges state-of-the-art deep learning for blind audio source separation and in-ear mobile systems by making two key technical contributions: 1) a new wireless earbud design capable of operating as a synchronized, binaural microphone array, and 2) a lightweight dual-channel speech enhancement neural network that runs on a mobile device. Our neural network has a novel cascaded architecture that combines a time-domain conventional neural network with a spectrogram-based frequency masking neural network to reduce the artifacts in the audio output. Results show that our wireless earbuds achieve a synchronization error less than 64 microseconds and our network has a runtime of 21.4 milliseconds on an accompanying mobile phone. In-the-wild evaluation with eight users in previously unseen indoor and outdoor multipath scenarios demonstrates that our neural network generalizes to learn both spatial and acoustic cues to perform noise suppression and background speech removal. In a user-study with 37 participants who spent over 15.4 hours rating 1041 audio samples collected in-the-wild, our system achieves improved mean opinion score and background noise suppression. <br>Project page with demos: <a class="link-external link-https" href="https://clearbuds.cs.washington.edu" rel="external noopener nofollow">this https URL</a>      
### 56.BeamsNet: A data-driven Approach Enhancing Doppler Velocity Log Measurements for Autonomous Underwater Vehicle Navigation  [ :arrow_down: ](https://arxiv.org/pdf/2206.13603.pdf)
>  Autonomous underwater vehicles (AUV) perform various applications such as seafloor mapping and underwater structure health monitoring. Commonly, an inertial navigation system aided by a Doppler velocity log (DVL) is used to provide the vehicle's navigation solution. In such fusion, the DVL provides the velocity vector of the AUV, which determines the navigation solution's accuracy and helps estimate the navigation states. This paper proposes BeamsNet, an end-to-end deep learning framework to regress the estimated DVL velocity vector that improves the accuracy of the velocity vector estimate, and could replace the model-based approach. Two versions of BeamsNet, differing in their input to the network, are suggested. The first uses the current DVL beam measurements and inertial sensors data, while the other utilizes only DVL data, taking the current and past DVL measurements for the regression process. Both simulation and sea experiments were made to validate the proposed learning approach relative to the model-based approach. Sea experiments were made with the Snapir AUV in the Mediterranean Sea, collecting approximately four hours of DVL and inertial sensor data. Our results show that the proposed approach achieved an improvement of more than 60% in estimating the DVL velocity vector.      
