# ArXiv eess --Thu, 16 Jun 2022
### 1.Beamforming in Integrated Sensing and Communication Systems with Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2206.07679.pdf)
>  We consider transmit beamforming and reflection pattern design in reconfigurable intelligent surface (RIS)-assisted integrated sensing and communication (ISAC) systems to jointly precode communication symbols and radar waveforms. We treat two settings of multiple users and targets. In the first, we use a single RIS to enhance the communication performance of the ISAC system and design beams with good cross-correlation properties to match a desired beam pattern while guaranteeing a desired signal-to-interference plus noise ratio (SINR) for each user. In the second setting, we use two dedicated RISs to aid the ISAC system, wherein the beams are designed to maximize the worst-case target illumination power while guaranteeing a desired SINR for each user. We propose solvers based on alternating optimization as the design problems in both cases are non-convex optimization problems. Through a number of numerical simulations, we demonstrate the advantages of RIS-assisted ISAC systems. In particular, we show that the proposed single-RIS assisted ISAC system improves the minimum user SINR while suffering from a moderate loss in radar target illumination power. On the other hand, the dual-RIS assisted ISAC system improves both minimum user SINR as well as worst-case target illumination power at the targets, especially when the users and targets are not directly visible.      
### 2.CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.07664.pdf)
>  Accurate uncertainty estimation is a critical need for the medical imaging community. A variety of methods have been proposed, all direct extensions of classification uncertainty estimations techniques. The independent pixel-wise uncertainty estimates, often based on the probabilistic interpretation of neural networks, do not take into account anatomical prior knowledge and consequently provide sub-optimal results to many segmentation tasks. For this reason, we propose CRISP a ContRastive Image Segmentation for uncertainty Prediction method. At its core, CRISP implements a contrastive method to learn a joint latent space which encodes a distribution of valid segmentations and their corresponding images. We use this joint latent space to compare predictions to thousands of latent vectors and provide anatomically consistent uncertainty maps. Comprehensive studies performed on four medical image databases involving different modalities and organs underlines the superiority of our method compared to state-of-the-art approaches.      
### 3.Analysis of Augmentations for Contrastive ECG Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.07656.pdf)
>  This paper systematically investigates the effectiveness of various augmentations for contrastive self-supervised learning of electrocardiogram (ECG) signals and identifies the best parameters. The baseline of our proposed self-supervised framework consists of two main parts: the contrastive learning and the downstream task. In the first stage, we train an encoder using a number of augmentations to extract generalizable ECG signal representations. We then freeze the encoder and finetune a few linear layers with different amounts of labelled data for downstream arrhythmia detection. We then experiment with various augmentations techniques and explore a range of parameters. Our experiments are done on PTB-XL, a large and publicly available 12-lead ECG dataset. The results show that applying augmentations in a specific range of complexities works better for self-supervised contrastive learning. For instance, when adding Gaussian noise, a sigma in the range of 0.1 to 0.2 achieves better results, while poor training occurs when the added noise is too small or too large (outside of the specified range). A similar trend is observed with other augmentations, demonstrating the importance of selecting the optimum level of difficulty for the added augmentations, as augmentations that are too simple will not result in effective training, while augmentations that are too difficult will also prevent the model from effective learning of generalized representations. Our work can influence future research on self-supervised contrastive learning on bio-signals and aid in selecting optimum parameters for different augmentations.      
### 4.Classification of EEG Motor Imagery Using Deep Learning for Brain-Computer Interface Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.07655.pdf)
>  A trained T1 class Convolutional Neural Network (CNN) model will be used to examine its ability to successfully identify motor imagery when fed pre-processed electroencephalography (EEG) data. In theory, and if the model has been trained accurately, it should be able to identify a class and label it accordingly. The CNN model will then be restored and used to try and identify the same class of motor imagery data using much smaller sampled data in an attempt to simulate live data.      
### 5.Human Activity Recognition on Time Series Accelerometer Sensor Data using LSTM Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.07654.pdf)
>  The use of sensors available through smart devices has pervaded everyday life in several applications including human activity monitoring, healthcare, and social networks. In this study, we focus on the use of smartwatch accelerometer sensors to recognize eating activity. More specifically, we collected sensor data from 10 participants while consuming pizza. Using this information, and other comparable data available for similar events such as smoking and medication-taking, and dissimilar activities of jogging, we developed a LSTM-ANN architecture that has demonstrated 90% success in identifying individual bites compared to a puff, medication-taking or jogging activities.      
### 6.Two-stage Human Activity Recognition on Microcontrollers with Decision Trees and CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2206.07652.pdf)
>  Human Activity Recognition (HAR) has become an increasingly popular task for embedded devices such as smartwatches. Most HAR systems for ultra-low power devices are based on classic Machine Learning (ML) models, whereas Deep Learning (DL), although reaching state-of-the-art accuracy, is less popular due to its high energy consumption, which poses a significant challenge for battery-operated and resource-constrained devices. In this work, we bridge the gap between on-device HAR and DL thanks to a hierarchical architecture composed of a decision tree (DT) and a one dimensional Convolutional Neural Network (1D CNN). The two classifiers operate in a cascaded fashion on two different sub-tasks: the DT classifies only the easiest activities, while the CNN deals with more complex ones. With experiments on a state-of-the-art dataset and targeting a single-core RISC-V MCU, we show that this approach allows to save up to 67.7% energy w.r.t. a "stand-alone" DL architecture at iso-accuracy. Additionally, the two-stage system either introduces a negligible memory overhead (up to 200 B) or on the contrary, reduces the total memory occupation.      
### 7.Fault Diagnosis of Inter-turn Short Circuit in Permanent Magnet Synchronous Motors with Current Signal Imaging and Unsupervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.07651.pdf)
>  This paper proposes machine-independent feature engineering for winding inter-turn short circuit fault that uses electrical current signals. Electrical current signal collected from permanent magnet synchronous motor (PMSM) is subjected to different environmental and operational conditions. To solve these problems, robust current signal imaging method and deep learning-based feature extraction method are developed. The overall procedure includes the following three key steps: (1) transformation of a time-series current signal to two-dimensional image, (2) extracting features using convolutional neural networks, and (3) calculating a health indicator using Mahalanobis distance. Transformation of the time-series signal is based on recurrence plots (RP). The proposed RP method develops from feature engineering that provides the dominant fault feature representations in a robust way. The proposed RP is designed that maximizes the features of inter-turn short fault and minimizes the effect of noise from systems with various capacities. To demonstrate the validity of the proposed method, two case studies are conducted using an artificial fault seeded testbed with two different capacities of motor. By calculating the feature using only the electrical current signal of the motor without the parameters related to the capacity of the motor, the proposed feature can be applied to motors with different capacities while maintaining the same performance.      
### 8.Flexible Raman Amplifier Optimization Based on Machine Learning-aided Physical Stimulated Raman Scattering Model  [ :arrow_down: ](https://arxiv.org/pdf/2206.07650.pdf)
>  The problem of Raman amplifier optimization is studied. A differentiable interpolation function is obtained for the Raman gain coefficient using machine learning (ML), which allows for the gradient descent optimization of forward-propagating Raman pumps. Both the frequency and power of an arbitrary number of pumps in a forward pumping configuration are then optimized for an arbitrary data channel load and span length. The forward propagation model is combined with an experimentally-trained ML model of a backward-pumping Raman amplifier to jointly optimize the frequency and power of the forward amplifier's pumps and the powers of the backward amplifier's pumps. The joint forward and backward amplifier optimization is demonstrated for an unrepeatered transmission of 250 km. A gain flatness of $&lt;$ 1~dB over 4 THz is achieved. The optimized amplifiers are validated using a numerical simulator.      
### 9.Atrial Fibrillation Detection Using Weight-Pruned, Log-Quantised Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.07649.pdf)
>  Deep neural networks (DNN) are a promising tool in medical applications. However, the implementation of complex DNNs on battery-powered devices is challenging due to high energy costs for communication. In this work, a convolutional neural network model is developed for detecting atrial fibrillation from electrocardiogram (ECG) signals. The model demonstrates high performance despite being trained on limited, variable-length input data. Weight pruning and logarithmic quantisation are combined to introduce sparsity and reduce model size, which can be exploited for reduced data movement and lower computational complexity. The final model achieved a 91.1% model compression ratio while maintaining high model accuracy of 91.7% and less than 1% loss.      
### 10.Classification of ECG based on Hybrid Features using CNNs for Wearable Applications  [ :arrow_down: ](https://arxiv.org/pdf/2206.07648.pdf)
>  Sudden cardiac death and arrhythmia account for a large percentage of all deaths worldwide. Electrocardiography (ECG) is the most widely used screening tool for cardiovascular diseases. Traditionally, ECG signals are classified manually, requiring experience and great skill, while being time-consuming and prone to error. Thus machine learning algorithms have been widely adopted because of their ability to perform complex data analysis. Features derived from the points of interest in ECG - mainly Q, R, and S, are widely used for arrhythmia detection. In this work, we demonstrate improved performance for ECG classification using hybrid features and three different models, building on a 1-D convolutional neural network (CNN) model that we had proposed in the past. An RR interval features based model proposed in this work achieved an accuracy of 98.98%, which is an improvement over the baseline model. To make the model immune to noise, we updated the model using frequency features and achieved good sustained performance in presence of noise with a slightly lower accuracy of 98.69%. Further, another model combining the frequency features and the RR interval features was developed, which achieved a high accuracy of 99% with good sustained performance in noisy environments. Due to its high accuracy and noise immunity, the proposed model which combines multiple hybrid features, is well suited for ambulatory wearable sensing applications.      
### 11.Dynamic State Estimation of Nonlinear Differential Algebraic Equation Models of Power Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.07623.pdf)
>  This paper investigates the joint problems of dynamic state estimation of algebraic variables (voltage and phase angle) and generator states (rotor angle and frequency) of nonlinear differential algebraic equation (NDAE) power network models, under uncertainty. Traditionally, these two problems have been decoupled due to complexity of handling NDAE models. In particular, this paper offers the first attempt to solve the aforementioned problem in a coupled approach where the algebraic and generator states estimates are simultaneously computed. The proposed estimation algorithm herein is endowed with the following properties: (i) it is fairly simple to implement and based on well-understood Lyapunov theory; (ii) considers various sources of uncertainty from generator control inputs, loads, renewables, process and measurement noise; (iii) models phasor measurement unit installations at arbitrary buses; and (iv) is computationally less intensive than the decoupled approach in the literature.      
### 12.How GNNs Facilitate CNNs in Mining Geometric Information from Large-Scale Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.07599.pdf)
>  Gigapixel medical images provide massive data, both morphological textures and spatial information, to be mined. Due to the large data scale in histology, deep learning methods play an increasingly significant role as feature extractors. Existing solutions heavily rely on convolutional neural networks (CNNs) for global pixel-level analysis, leaving the underlying local geometric structure such as the interaction between cells in the tumor microenvironment unexplored. The topological structure in medical images, as proven to be closely related to tumor evolution, can be well characterized by graphs. To obtain a more comprehensive representation for downstream oncology tasks, we propose a fusion framework for enhancing the global image-level representation captured by CNNs with the geometry of cell-level spatial information learned by graph neural networks (GNN). The fusion layer optimizes an integration between collaborative features of global images and cell graphs. Two fusion strategies have been developed: one with MLP which is simple but turns out efficient through fine-tuning, and the other with Transformer gains a champion in fusing multiple networks. We evaluate our fusion strategies on histology datasets curated from large patient cohorts of colorectal and gastric cancers for three biomarker prediction tasks. Both two models outperform plain CNNs or GNNs, reaching a consistent AUC improvement of more than 5% on various network backbones. The experimental results yield the necessity for combining image-level morphological features with cell spatial relations in medical image analysis. Codes are available at <a class="link-external link-https" href="https://github.com/yiqings/HEGnnEnhanceCnn" rel="external noopener nofollow">this https URL</a>.      
### 13.BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and Clinical Data  [ :arrow_down: ](https://arxiv.org/pdf/2206.07595.pdf)
>  Fast and accurate detection of the disease can significantly help in reducing the strain on the healthcare facility of any country to reduce the mortality during any pandemic. The goal of this work is to create a multimodal system using a novel machine learning framework that uses both Chest X-ray (CXR) images and clinical data to predict severity in COVID-19 patients. In addition, the study presents a nomogram-based scoring technique for predicting the likelihood of death in high-risk patients. This study uses 25 biomarkers and CXR images in predicting the risk in 930 COVID-19 patients admitted during the first wave of COVID-19 (March-June 2020) in Italy. The proposed multimodal stacking technique produced the precision, sensitivity, and F1-score, of 89.03%, 90.44%, and 89.03%, respectively to identify low or high-risk patients. This multimodal approach improved the accuracy by 6% in comparison to the CXR image or clinical data alone. Finally, nomogram scoring system using multivariate logistic regression -- was used to stratify the mortality risk among the high-risk patients identified in the first stage. Lactate Dehydrogenase (LDH), O2 percentage, White Blood Cells (WBC) Count, Age, and C-reactive protein (CRP) were identified as useful predictor using random forest feature selection model. Five predictors parameters and a CXR image based nomogram score was developed for quantifying the probability of death and categorizing them into two risk groups: survived (&lt;50%), and death (&gt;=50%), respectively. The multi-modal technique was able to predict the death probability of high-risk patients with an F1 score of 92.88 %. The area under the curves for the development and validation cohorts are 0.981 and 0.939, respectively.      
### 14.End-to-End Voice Conversion with Information Perturbation  [ :arrow_down: ](https://arxiv.org/pdf/2206.07569.pdf)
>  The ideal goal of voice conversion is to convert the source speaker's speech to sound naturally like the target speaker while maintaining the linguistic content and the prosody of the source speech. However, current approaches are insufficient to achieve comprehensive source prosody transfer and target speaker timbre preservation in the converted speech, and the quality of the converted speech is also unsatisfied due to the mismatch between the acoustic model and the vocoder. In this paper, we leverage the recent advances in information perturbation and propose a fully end-to-end approach to conduct high-quality voice conversion. We first adopt information perturbation to remove speaker-related information in the source speech to disentangle speaker timbre and linguistic content and thus the linguistic information is subsequently modeled by a content encoder. To better transfer the prosody of the source speech to the target, we particularly introduce a speaker-related pitch encoder which can maintain the general pitch pattern of the source speaker while flexibly modifying the pitch intensity of the generated speech. Finally, one-shot voice conversion is set up through continuous speaker space modeling. Experimental results indicate that the proposed end-to-end approach significantly outperforms the state-of-the-art models in terms of intelligibility, naturalness, and speaker similarity.      
### 15.Learnable Frequency Filters for Speech Feature Extraction in Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2206.07563.pdf)
>  Mel-scale spectrum features are used in various recognition and classification tasks on speech signals. There is no reason to expect that these features are optimal for all different tasks, including speaker verification (SV). This paper describes a learnable front-end feature extraction model. The model comprises a group of filters to transform the Fourier spectrum. Model parameters that define these filters are trained end-to-end and optimized specifically for the task of speaker verification. Compared to the standard Mel-scale filter-bank, the filters' bandwidths and center frequencies are adjustable. Experimental results show that applying the learnable acoustic front-end improves speaker verification performance over conventional Mel-scale spectrum features. Analysis on the learned filter parameters suggests that narrow-band information benefits the SV system performance. The proposed model achieves a good balance between performance and computation cost. In resource-constrained computation settings, the model significantly outperforms CNN-based learnable front-ends. The generalization ability of the proposed model is also demonstrated on different embedding extraction models and datasets.      
### 16.EDITnet: A Lightweight Network for Unsupervised Domain Adaptation in Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2206.07548.pdf)
>  Performance degradation caused by language mismatch is a common problem when applying a speaker verification system on speech data in different languages. This paper proposes a domain transfer network, named EDITnet, to alleviate the language-mismatch problem on speaker embeddings without requiring speaker labels. The network leverages a conditional variational auto-encoder to transfer embeddings from the target domain into the source domain. A self-supervised learning strategy is imposed on the transferred embeddings so as to increase the cosine distance between embeddings from different speakers. In the training process of the EDITnet, the embedding extraction model is fixed without fine-tuning, which renders the training efficient and low-cost. Experiments on Voxceleb and CN-Celeb show that the embeddings transferred by EDITnet outperform the un-transferred ones by around 30% with the ECAPA-TDNN512. Performance improvement can also be achieved with other embedding extraction models, e.g., TDNN, SE-ResNet34.      
### 17.Autonomous Platoon Control with Integrated Deep Reinforcement Learning and Dynamic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2206.07536.pdf)
>  Deep Reinforcement Learning (DRL) is regarded as a potential method for car-following control and has been mostly studied to support a single following vehicle. However, it is more challenging to learn a stable and efficient car-following policy when there are multiple following vehicles in a platoon, especially with unpredictable leading vehicle behavior. In this context, we adopt an integrated DRL and Dynamic Programming (DP) approach to learn autonomous platoon control policies, which embeds the Deep Deterministic Policy Gradient (DDPG) algorithm into a finite-horizon value iteration framework. Although the DP framework can improve the stability and performance of DDPG, it has the limitations of lower sampling and training efficiency. In this paper, we propose an algorithm, namely Finite-Horizon-DDPG with Sweeping through reduced state space using Stationary approximation (FH-DDPG-SS), which uses three key ideas to overcome the above limitations, i.e., transferring network weights backward in time, stationary policy approximation for earlier time steps, and sweeping through reduced state space. In order to verify the effectiveness of FH-DDPG-SS, simulation using real driving data is performed, where the performance of FH-DDPG-SS is compared with those of the benchmark algorithms. Finally, platoon safety and string stability for FH-DDPG-SS are demonstrated.      
### 18.Optimal Synthesis of LTI Koopman Models for Nonlinear Systems with Inputs  [ :arrow_down: ](https://arxiv.org/pdf/2206.07534.pdf)
>  A popular technique used to obtain linear representations of nonlinear systems is the so-called Koopman approach, where the nonlinear dynamics are lifted to a (possibly infinite dimensional) linear space through nonlinear functions called observables. In the lifted space, the dynamics are linear and represented by a so-called Koopman operator. While the Koopman theory was originally introduced for autonomous systems, it has been widely used to derive linear time-invariant (LTI) models for nonlinear systems with inputs through various approximation schemes such as the extended dynamics mode decomposition (EDMD). However, recent extensions of the Koopman theory show that the lifting process for such systems results in a linear parameter-varying (LPV) model instead of an LTI form. As LTI Koopman model based control has been successfully used in practice and it is generally temping to use such LTI descriptions of nonlinear systems, due to the simplicity of the associated control tool chain, a systematic approach is needed to synthesise optimal LTI approximations of LPV Koopman models compared to the ad-hoc schemes such as EDMD, which is based on least-squares regression. In this work, we introduce optimal LTI Koopman approximations of exact Koopman models of nonlinear systems with inputs by using l2-gain and generalized H2 norm performance measures. We demonstrate the advantages of the proposed Koopman modelling procedure compared to EDMD.      
### 19.Explainable AI for Suicide Risk Assessment Using Eye Activities and Head Gestures  [ :arrow_down: ](https://arxiv.org/pdf/2206.07522.pdf)
>  The prevalence of suicide has been on the rise since the 20th century, causing severe emotional damage to individuals, families, and communities alike. Despite the severity of this suicide epidemic, there is so far no reliable and systematic way to assess suicide intent of a given individual. Through efforts to automate and systematize diagnosis of mental illnesses over the past few years, verbal and acoustic behaviors have received increasing attention as biomarkers, but little has been done to study eyelids, gaze, and head pose in evaluating suicide risk. This study explores statistical analysis, feature selection, and machine learning classification as means of suicide risk evaluation and nonverbal behavioral interpretation. Applying these methods to the eye and head signals extracted from our unique dataset, this study finds that high-risk suicidal individuals experience psycho-motor retardation and symptoms of anxiety and depression, characterized by eye contact avoidance, slower blinks and a downward eye gaze. By comparing results from different methods of classification, we determined that these features are highly capable of automatically classifying different levels of suicide risk consistently and with high accuracy, above 98%. Our conclusion corroborates psychological studies, and shows great potential of a systematic approach in suicide risk evaluation that is adoptable by both healthcare providers and naive observers.      
### 20.Smart Meter Data Anomaly Detection using Variational Recurrent Autoencoders with Attention  [ :arrow_down: ](https://arxiv.org/pdf/2206.07519.pdf)
>  In the digitization of energy systems, sensors and smart meters are increasingly being used to monitor production, operation and demand. Detection of anomalies based on smart meter data is crucial to identify potential risks and unusual events at an early stage, which can serve as a reference for timely initiation of appropriate actions and improving management. However, smart meter data from energy systems often lack labels and contain noise and various patterns without distinctively cyclical. Meanwhile, the vague definition of anomalies in different energy scenarios and highly complex temporal correlations pose a great challenge for anomaly detection. Many traditional unsupervised anomaly detection algorithms such as cluster-based or distance-based models are not robust to noise and not fully exploit the temporal dependency in a time series as well as other dependencies amongst multiple variables (sensors). This paper proposes an unsupervised anomaly detection method based on a Variational Recurrent Autoencoder with attention mechanism. with "dirty" data from smart meters, our method pre-detects missing values and global anomalies to shrink their contribution while training. This paper makes a quantitative comparison with the VAE-based baseline approach and four other unsupervised learning methods, demonstrating its effectiveness and superiority. This paper further validates the proposed method by a real case study of detecting the anomalies of water supply temperature from an industrial heating plant.      
### 21.Binary Single-dimensional Convolutional Neural Network for Seizure Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.07518.pdf)
>  Nowadays, several deep learning methods are proposed to tackle the challenge of epileptic seizure prediction. However, these methods still cannot be implemented as part of implantable or efficient wearable devices due to their large hardware and corresponding high-power consumption. They usually require complex feature extraction process, large memory for storing high precision parameters and complex arithmetic computation, which greatly increases required hardware resources. Moreover, available yield poor prediction performance, because they adopt network architecture directly from image recognition applications fails to accurately consider the characteristics of EEG signals. We propose in this paper a hardware-friendly network called Binary Single-dimensional Convolutional Neural Network (BSDCNN) intended for epileptic seizure prediction. BSDCNN utilizes 1D convolutional kernels to improve prediction performance. All parameters are binarized to reduce the required computation and storage, except the first layer. Overall area under curve, sensitivity, and false prediction rate reaches 0.915, 89.26%, 0.117/h and 0.970, 94.69%, 0.095/h on American Epilepsy Society Seizure Prediction Challenge (AES) dataset and the CHB-MIT one respectively. The proposed architecture outperforms recent works while offering 7.2 and 25.5 times reductions on the size of parameter and computation, respectively.      
### 22.Design of an electronic circuit for loudspeaker real-time digital signal processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.07516.pdf)
>  In modern audio systems, real-time digital signal processing algorithms are widely used for a variety of applications. The possibility of using a simple electronic circuit for variety of research projects has shown remarkable potential and is gradually attracting more and more attention from researchers and engineers. This contribution describes a design of such a board used in the framework of a PhD thesis whose subject is centred on the real-time correction of loudspeaker nonlinearities. The solution chosen in this work is based on a Teensy 3.6 microcontroller which is easy to program using the Arduino IDE and the libraries provided by Teensy. Two solutions are provided : one with an Audio board available on the market and another with a homemade board. Both solutions contain two inputs and at least one output (all 16 bits). This contribution does not detail the compensation algorithm related to the loudspeaker nonlinearities but focuses on the boards design, comparison of proposed solutions, and provides the basic codes to perform the real-time digital signal processing.      
### 23.A Deep Learning Network for the Classification of Intracardiac Electrograms in Atrial Tachycardia  [ :arrow_down: ](https://arxiv.org/pdf/2206.07515.pdf)
>  A key technology enabling the success of catheter ablation treatment for atrial tachycardia is activation mapping, which relies on manual local activation time (LAT) annotation of all acquired intracardiac electrogram (EGM) signals. This is a time-consuming and error-prone procedure, due to the difficulty in identifying the signal activation peaks for fractionated signals. This work presents a Deep Learning approach for the automated classification of EGM signals into three different types: normal, abnormal, and unclassified, which forms part of the LAT annotation pipeline, and contributes towards bypassing the need for manual annotations of the LAT. The Deep Learning network, the CNN-LSTM model, is a hybrid network architecture which combines convolutional neural network (CNN) layers with long short-term memory (LSTM) layers. 1452 EGM signals from a total of 9 patients undergoing clinically-indicated 3D cardiac mapping were used for the training, validation and testing of our models. From our findings, the CNN-LSTM model achieved an accuracy of 81% for the balanced dataset. For comparison, we separately developed a rule-based Decision Trees model which attained an accuracy of 67% for the same balanced dataset. Our work elucidates that analysing the EGM signals using a set of explicitly specified rules as proposed by the Decision Trees model is not suitable as EGM signals are complex. The CNN-LSTM model, on the other hand, has the ability to learn the complex, intrinsic features within the signals and identify useful features to differentiate the EGM signals.      
### 24.Preliminary study on the impact of EEG density on TMS-EEG classification in Alzheimer's disease  [ :arrow_down: ](https://arxiv.org/pdf/2206.07492.pdf)
>  Transcranial magnetic stimulation co-registered with electroencephalographic (TMS-EEG) has previously proven a helpful tool in the study of Alzheimer's disease (AD). In this work, we investigate the use of TMS-evoked EEG responses to classify AD patients from healthy controls (HC). By using a dataset containing 17AD and 17HC, we extract various time domain features from individual TMS responses and average them over a low, medium and high density EEG electrode set. Within a leave-one-subject-out validation scenario, the best classification performance for AD vs. HC was obtained using a high-density electrode with a Random Forest classifier. The accuracy, sensitivity and specificity were of 92.7%, 96.58% and 88.2% respectively.      
### 25.Demo: low-power communications based on RIS and AI for 6G  [ :arrow_down: ](https://arxiv.org/pdf/2206.07490.pdf)
>  Ultra-massive multiple-input-multiple-output (UM-MIMO) is promising to meet the high rate requirements for future 6G. However, due to the large number of antennas and high path loss, the hardware power consumption and computing power consumption of UM-MIMO will be unaffordable. To address this problem, we implement a low-power communication system based on reconfigurable intelligent surface (RIS) and artificial intelligence (AI) for 6G. For hardware design, we employ a 256-element RIS at the base station to replace the traditional phased array. Moreover, a 2304-element RIS is developed as a relay to assist communication with much reduced transmit power. For software implementation, we develop an AI-based transmission design to reduce computing power consumption. By jointly designing the hardware and software, this prototype can realize real-time 4K video transmission with much reduced power consumption.      
### 26.A Review of Driver Drowsiness Detection Systems: Techniques, Advantages and Limitations  [ :arrow_down: ](https://arxiv.org/pdf/2206.07489.pdf)
>  Driver Drowsiness is one of the most factors of road accidents, leading to severe injuries and deaths every year. Drowsiness means difficulty staying awake, which can lead to falling asleep. This paper introduces a literature review of driver drowsiness detection systems based on an analysis of physiological signals, facial features, and driving patterns. The paper also presents and details the recently proposed techniques for each class. We have also provided a comparative study of recently published works regarding the accuracy, reliability, hardware requirement, and intrusiveness. We have summarized and discussed the advantages and limitations of each class. As a result, each class of techniques has advantages and limitations. A hybrid system that combines two and more techniques will be efficient, robust, accurate, and used in real-time to take advantage of each technique.      
### 27.IoT- Based Low-Cost Soil Moisture and Soil Temperature Monitoring System  [ :arrow_down: ](https://arxiv.org/pdf/2206.07488.pdf)
>  Soil moisture (SM) is referred to as a finite amount of water molecules within the pore spaces and it is a crucial parameter of Hydro-Meteorological processes. The behaviour of soil moisture water changes spatially and temporally in response to topography, soil characteristics, and climate[1]. Soil moisture is overseen by various hydro-meteorological factors that vary vertically with depth, laterally across terrestrial shapes, and temporarily in feedback to the climate. The precise monitoring and quantification of high-resolution surface and subsurface soil moisture observations are very important [13]. This paper highlights the outcomes of the fieldwork carried out at IITM, Pune, wherein we have developed a soil moisture and temperature measurement system using Raspberry Pi and the Internet of things (IoT). The development is classified into three stages, the first stage includes the assembly of the sensor with the microprocessor. The deployment of the low-cost system, data generation, and communication through a wireless sensor network is part of the second stage. Finally, the third stage includes real-time data visualization using a mobile application and data server for analysing soil moisture and temperature. The soil moisture profile obtained through the sensor deployed is highly correlated (r=.9) with in-situ gravimetric observations, having a root mean square error (RMSE) of about 3.1%. Similarly, the temperature observations are well-matched with the in-situ standard temperature observation. Here we present the preliminary results and compare the accuracy with the state-of-the-art sensors.      
### 28.Bayesian Networks for Brain-Computer Interfaces: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2206.07487.pdf)
>  Brain-Computer Interface (BCI) is a rapidly developing technology that allows direct communications between the human brain and external devices, such as robotic arms and computers. Bayesian Networks is a powerful tool in machine learning for tackling with problems that requires understanding and modelling the uncertainty and complexity within complex system built by sub-modular components. Therefore, deploying Bayesian Networks in the application of Brain-Computer Interfaces becomes an increasingly popular approach in BCI research. This survey covers related existing works in relatively high-level perspectives, classifies the models and algorithms involved, and also summarizes the application of Bayesian Networks or its variants in the context of Brain-Computer Interfaces.      
### 29.Topological Simplification of Signals for Inference and Approximate Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2206.07486.pdf)
>  As Internet of Things (IoT) devices become both cheaper and more powerful, researchers are increasingly finding solutions to their scientific curiosities both financially and computationally feasible. When operating with restricted power or communications budgets, however, devices can only send highly-compressed data. Such circumstances are common for devices placed away from electric grids that can only communicate via satellite, a situation particularly plausible for environmental sensor networks. These restrictions can be further complicated by potential variability in the communications budget, for example a solar-powered device needing to expend less energy when transmitting data on a cloudy day. We propose a novel, topology-based, lossy compression method well-equipped for these restrictive yet variable circumstances. This technique, Topological Signal Compression, allows sending compressed signals that utilize the entirety of a variable communications budget. To demonstrate our algorithm's capabilities, we perform entropy calculations as well as a classification exercise on increasingly topologically simplified signals from the Free-Spoken Digit Dataset and explore the stability of the resulting performance against common baselines.      
### 30.Intelligent analysis of EEG signals to assess consumer decisions: A Study on Neuromarketing  [ :arrow_down: ](https://arxiv.org/pdf/2206.07484.pdf)
>  Neuromarketing is an emerging field that combines neuroscience and marketing to understand the factors that influence consumer decisions better. The study proposes a method to understand consumers' positive and negative reactions to advertisements (ads) and products by analysing electroencephalogram (EEG) signals. These signals are recorded using a low-cost single electrode headset from volunteers belonging to the ages 18-22. A detailed subject dependent (SD) and subject independent (SI) analysis was performed employing machine learning methods like Naive Bayes (NB), Support Vector Machine (SVM), k-nearest neighbour and Decision Tree and the proposed deep learning (DL) model. SVM and NB yielded an accuracy (Acc.) of 0.63 for the SD analysis. In SI analysis, SVM performed better for the advertisement, product and gender-based analysis. Furthermore, the performance of the DL model was on par with that of SVM, especially, in product and ads-based analysis.      
### 31.Blind Estimation of a Doubly Selective OFDM Channel: A Deep Learning Algorithm and Theory  [ :arrow_down: ](https://arxiv.org/pdf/2206.07483.pdf)
>  We provide a new generation solution to the fundamental old problem of a doubly selective fading channel estimation for orthogonal frequency division multiplexing (OFDM) systems. For systems based on OFDM, we propose a deep learning (DL)-based blind doubly selective channel estimator. This estimator does require no pilot symbols, unlike the corresponding state-of-the-art estimators, even during the estimation of a deep fading doubly selective channel. We also provide the first of its kind theory on the testing mean squared error (MSE) performance of our investigated blind OFDM channel estimator based on over-parameterized ReLU FNNs.      
### 32.A Survey of Detection Methods for Die Attachment and Wire Bonding Defects in Integrated Circuit Manufacturing  [ :arrow_down: ](https://arxiv.org/pdf/2206.07481.pdf)
>  Defect detection plays a vital role in the manufacturing process of integrated circuits (ICs). Die attachment and wire bonding are two steps of the manufacturing process that determine the power and signal transmission quality and dependability in an IC. This paper presents a survey or literature review of the methods used for detecting these defects based on different sensing modalities used including optical, radiological, acoustical, and infrared thermography. A discussion of the detection methods used is provided in this survey. Both conventional and deep learning approaches for detecting die attachment and wire bonding defects are considered along with challenges and future research directions.      
### 33.Self-Assessment for Single-Object Tracking in Clutter Using Subjective Logic  [ :arrow_down: ](https://arxiv.org/pdf/2206.07449.pdf)
>  Reliable tracking algorithms are essential for automated driving. However, the existing consistency measures are not sufficient to meet the increasing safety demands in the automotive sector. Therefore, this work presents a novel method for self-assessment of single-object tracking in clutter based on Kalman filtering and subjective logic. A key feature of the approach is that it additionally provides a measure of the collected statistical evidence in its online reliability scores. In this way, various aspects of reliability, such as the correctness of the assumed measurement noise, detection probability, and clutter rate, can be monitored in addition to the overall assessment based on the available evidence. Here, we present a mathematical derivation of the reference distribution used in our self-assessment module for our studied problem. Moreover, we introduce a formula that describes how a threshold should be chosen for the degree of conflict, the subjective logic comparison measure used for the reliability decision making. Our approach is evaluated in a challenging simulation scenario designed to model adverse weather conditions. The simulations show that our method can significantly improve the reliability checking of single-object tracking in clutter in several aspects.      
### 34.The ZevoMOS entry to VoiceMOS Challenge 2022  [ :arrow_down: ](https://arxiv.org/pdf/2206.07448.pdf)
>  This paper introduces the ZevoMOS entry to the main track of the VoiceMOS Challenge 2022. The ZevoMOS submission is based on a two-step finetuning of pretrained self-supervised learning (SSL) speech models. The first step uses a task of classifying natural versus synthetic speech, while the second step's task is to predict the MOS scores associated with each training sample. The results of the finetuning process are then combined with the confidence scores extracted from an automatic speech recognition model, as well as the raw embeddings of the training samples obtained from a wav2vec SSL speech model. <br>The team id assigned to the ZevoMOS system within the VoiceMOS Challenge is T01. The submission was placed on the 14th place with respect to the system-level SRCC, and on the 9th place with respect to the utterance-level MSE. The paper also introduces additional evaluations of the intermediate results.      
### 35.Residual Language Model for End-to-end Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.07430.pdf)
>  End-to-end automatic speech recognition suffers from adaptation to unknown target domain speech despite being trained with a large amount of paired audio--text data. Recent studies estimate a linguistic bias of the model as the internal language model (LM). To effectively adapt to the target domain, the internal LM is subtracted from the posterior during inference and fused with an external target-domain LM. However, this fusion complicates the inference and the estimation of the internal LM may not always be accurate. In this paper, we propose a simple external LM fusion method for domain adaptation, which considers the internal LM estimation in its training. We directly model the residual factor of the external and internal LMs, namely the residual LM. To stably train the residual LM, we propose smoothing the estimated internal LM and optimizing it with a combination of cross-entropy and mean-squared-error losses, which consider the statistical behaviors of the internal LM in the target domain data. We experimentally confirmed that the proposed residual LM performs better than the internal LM estimation in most of the cross-domain and intra-domain scenarios.      
### 36.Discrete-time Layered-network Epidemics Model with Time-varying Transition Rates and Multiple Resources  [ :arrow_down: ](https://arxiv.org/pdf/2206.07425.pdf)
>  This paper studies a discrete-time time-varying multi-layer networked SIWS (susceptible-infected-water-susceptible) model with multiple resources under both single-virus and competing multi-virus settings. Besides the human-to-human interaction, we also consider that the disease can diffuse on different types of medium. We use \emph{resources} to refer to any media that the pathogen of a virus can spread through, and do not restrict the resource only to be water. In the single-virus case, we give a full analysis of the system's behaviour related to its healthy state and endemic equilibrium. In the multi-virus case, we show analytically that different equilibria appear driven by the competition among all viruses. We also show that some analytical results of the time-invariant system can be expanded into time-varying cases. Finally, we illustrate the results through some simulations.      
### 37.Deep Neural Network Pruning for Nuclei Instance Segmentation in Hematoxylin &amp; Eosin-Stained Histological Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.07422.pdf)
>  Recently, pruning deep neural networks (DNNs) has received a lot of attention for improving accuracy and generalization power, reducing network size, and increasing inference speed on specialized hardwares. Although pruning was mainly tested on computer vision tasks, its application in the context of medical image analysis has hardly been explored. This work investigates the impact of well-known pruning techniques, namely layer-wise and network-wide magnitude pruning, on the nuclei instance segmentation performance in histological images. Our utilized instance segmentation model consists of two main branches: (1) a semantic segmentation branch, and (2) a deep regression branch. We investigate the impact of weight pruning on the performance of both branches separately and on the final nuclei instance segmentation result. Evaluated on two publicly available datasets, our results show that layer-wise pruning delivers slightly better performance than networkwide pruning for small compression ratios (CRs) while for large CRs, network-wide pruning yields superior performance. For semantic segmentation, deep regression and final instance segmentation, 93.75 %, 95 %, and 80 % of the model weights can be pruned by layer-wise pruning with less than 2 % reduction in the performance of respective models.      
### 38.Variance Reduction for Inverse Trace Estimation via Random Spanning Forests  [ :arrow_down: ](https://arxiv.org/pdf/2206.07421.pdf)
>  The trace $\tr(q(\ma{L} + q\ma{I})^{-1})$, where $\ma{L}$ is a symmetric diagonally dominant matrix, is the quantity of interest in some machine learning problems. However, its direct computation is impractical if the matrix size is large. State-of-the-art methods include Hutchinson's estimator combined with iterative solvers, as well as the estimator based on random spanning forests (a random process on graphs). In this work, we show two ways of improving the forest-based estimator via well-known variance reduction techniques, namely control variates and stratified sampling. Implementing these techniques is easy, and provides substantial variance reduction, yielding comparable or better performance relative to state-of-the-art algorithms.      
### 39.Interpretable differential diagnosis for Alzheimer's disease and Frontotemporal dementia  [ :arrow_down: ](https://arxiv.org/pdf/2206.07417.pdf)
>  Alzheimer's disease and Frontotemporal dementia are two major types of dementia. Their accurate diagnosis and differentiation is crucial for determining specific intervention and treatment. However, differential diagnosis of these two types of dementia remains difficult at the early stage of disease due to similar patterns of clinical symptoms. Therefore, the automatic classification of multiple types of dementia has an important clinical value. So far, this challenge has not been actively explored. Recent development of deep learning in the field of medical image has demonstrated high performance for various classification tasks. In this paper, we propose to take advantage of two types of biomarkers: structure grading and structure atrophy. To this end, we propose first to train a large ensemble of 3D U-Nets to locally discriminate healthy versus dementia anatomical patterns. The result of these models is an interpretable 3D grading map capable of indicating abnormal brain regions. This map can also be exploited in various classification tasks using graph convolutional neural network. Finally, we propose to combine deep grading and atrophy-based classifications to improve dementia type discrimination. The proposed framework showed competitive performance compared to state-of-the-art methods for different tasks of disease detection and differential diagnosis.      
### 40.Deep-based Film Grain Removal and Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2206.07411.pdf)
>  In this paper, deep learning-based techniques for film grain removal and synthesis that can be applied in video coding are proposed. Film grain is inherent in analog film content because of the physical process of capturing images and video on film. It can also be present in digital content where it is purposely added to reflect the era of analog film and to evoke certain emotions in the viewer or enhance the perceived quality. In the context of video coding, the random nature of film grain makes it both difficult to preserve and very expensive to compress. To better preserve it while compressing the content efficiently, film grain is removed and modeled before video encoding and then restored after video decoding. In this paper, a film grain removal model based on an encoder-decoder architecture and a film grain synthesis model based on a \ac{cgan} are proposed. Both models are trained on a large dataset of pairs of clean (grain-free) and grainy images. Quantitative and qualitative evaluations of the developed solutions were conducted and showed that the proposed film grain removal model is effective in filtering film grain at different intensity levels using two configurations: 1) a non-blind configuration where the film grain level of the grainy input is known and provided as input, 2) a blind configuration where the film grain level is unknown. As for the film grain synthesis task, the experimental results show that the proposed model is able to reproduce realistic film grain with a controllable intensity level specified as input.      
### 41.ParamNet: A Multi-Layer Parametric Network for Joint Channel Estimation and Symbol Detection  [ :arrow_down: ](https://arxiv.org/pdf/2206.07405.pdf)
>  This paper proposes a parametric-based network architecture for joint channel estimation and data detection in communications systems with hardware impairments. This architecture is composed of a data-augmented layer, a custom soft thresholding function, and several linear layers modeling the effect of channel effects and hardware impairments. In the proposed network, the soft thresholding function softly constrains the detected data to be within the considered constellation. The latter depends only on one one parameter that is optimized during training. The benefit of the proposed approach is illustrated through a communication chain corrupted by multiple impairments and noises.      
### 42.On the Relationship Between Ground- and Satellite- Based Global Horizontal Irradiance  [ :arrow_down: ](https://arxiv.org/pdf/2206.07404.pdf)
>  Global horizontal irradiance (GHI) plays a significant role in maintaining the earth's ecological balance and generating electricity in photovoltaic systems. While the satellites have more range, they have been shown to over/under-estimate the true values of GHI that are observed at the ground-based stations. Hence, this study aims at analyzing the relationship between these two sources of GHI data in order to better and effectively utilize the reach of satellites for GHI analysis. The paper identifies a near linear relationship between the two and thereby concludes that an approximate mapping from satellite- to ground-based GHI values can be obtained.      
### 43.Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2206.07364.pdf)
>  Recently, deep neural networks have greatly advanced undersampled Magnetic Resonance Image (MRI) reconstruction, wherein most studies follow the one-anatomy-one-network fashion, i.e., each expert network is trained and evaluated for a specific anatomy. Apart from inefficiency in training multiple independent models, such convention ignores the shared de-aliasing knowledge across various anatomies which can benefit each other. To explore the shared knowledge, one naive way is to combine all the data from various anatomies to train an all-round network. Unfortunately, despite the existence of the shared de-aliasing knowledge, we reveal that the exclusive knowledge across different anatomies can deteriorate specific reconstruction targets, yielding overall performance degradation. Observing this, in this study, we present a novel deep MRI reconstruction framework with both anatomy-shared and anatomy-specific parameterized learners, aiming to "seek common ground while reserving differences" across different anatomies.Particularly, the primary anatomy-shared learners are exposed to different anatomies to model flourishing shared knowledge, while the efficient anatomy-specific learners are trained with their target anatomy for exclusive knowledge. Four different implementations of anatomy-specific learners are presented and explored on the top of our framework in two MRI reconstruction networks. Comprehensive experiments on brain, knee and cardiac MRI datasets demonstrate that three of these learners are able to enhance reconstruction performance via multiple anatomy collaborative learning.      
### 44.Modelling of AC/DC Interactions of Converter-Interfaced Resources for Harmonic Power-Flow Studies in Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2206.07332.pdf)
>  Modern power distribution systems experience a large-scale integration of Converter-Interfaced Distributed Energy Resources (CIDERs). As acknowledged by recent literature, the interaction of individual CIDER components and different CIDERs through the grid can lead to undesirable amplifications of harmonic frequencies. In order to analyze and mitigate such phenomenon the authors of this paper recently proposed a Harmonic Power-Flow (HPF) computation framework of polyphase grids with a high share of CIDERs. This paper extends this HPF framework to include the DC-side dynamics of CIDERs. The DC side is modelled by a controlled current source and the DC-link capacitor, and the AC/DC converter is represented by an average model. Including the latter into the CIDER model introduces a nonlinearity that needs to be approximated for the numerical solution of the HPF. The CIDER model and HPF framework are extended to include this linearization. The accuracy of the linearized CIDER model and the extended HPF framework is assessed for individual resources and a modified version of the CIGRE low-voltage benchmark microgrid. Namely, the spectra obtained from the HPF method are compared against time-domain simulations with Simulink. The observed maximum errors are 7.86E-5p.u. w.r.t. voltage magnitude, 3.1E-4p.u. w.r.t. current magnitude, and 22mrad w.r.t. phase.      
### 45.Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging Features For Elderly And Dysarthric Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.07327.pdf)
>  Articulatory features are inherently invariant to acoustic signal distortion and have been successfully incorporated into automatic speech recognition (ASR) systems designed for normal speech. Their practical application to atypical task domains such as elderly and disordered speech across languages is often limited by the difficulty in collecting such specialist data from target speakers. This paper presents a cross-domain and cross-lingual A2A inversion approach that utilizes the parallel audio, visual and ultrasound tongue imaging (UTI) data of the 24-hour TaL corpus in A2A model pre-training before being cross-domain and cross-lingual adapted to three datasets across two languages: the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech corpora; and the English TORGO dysarthric speech data, to produce UTI based articulatory features. Experiments conducted on three tasks suggested incorporating the generated articulatory features consistently outperformed the baseline hybrid TDNN and Conformer based end-to-end systems constructed using acoustic features only by statistically significant word error rate or character error rate reductions up to 2.64%, 1.92% and 1.21% absolute (8.17%, 7.89% and 13.28% relative) after data augmentation and speaker adaptation were applied.      
### 46.ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance Image Reconstructions  [ :arrow_down: ](https://arxiv.org/pdf/2206.07280.pdf)
>  Magnetic resonance imaging (MRI) is one of the noninvasive imaging modalities that can produce high-quality images. However, the scan procedure is relatively slow, which causes patient discomfort and motion artifacts in images. Accelerating MRI hardware is constrained by physical and physiological limitations. A popular alternative approach to accelerated MRI is to undersample the k-space data. While undersampling speeds up the scan procedure, it generates artifacts in the images, and advanced reconstruction algorithms are needed to produce artifact-free images. Recently deep learning has emerged as a promising MRI reconstruction method to address this problem. However, straightforward adoption of the existing deep learning neural network architectures in MRI reconstructions is not usually optimal in terms of efficiency and reconstruction quality. In this work, MRI reconstruction from undersampled data was carried out using an optimized neural network using a novel evolutionary neural architecture search algorithm. Brain and knee MRI datasets show that the proposed algorithm outperforms manually designed neural network-based MR reconstruction models.      
### 47.Latency Control for Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2206.07261.pdf)
>  Conversational agents commonly utilize keyword spotting (KWS) to initiate voice interaction with the user. For user experience and privacy considerations, existing approaches to KWS largely focus on accuracy, which can often come at the expense of introduced latency. To address this tradeoff, we propose a novel approach to control KWS model latency and which generalizes to any loss function without explicit knowledge of the keyword endpoint. Through a single, tunable hyperparameter, our approach enables one to balance detection latency and accuracy for the targeted application. Empirically, we show that our approach gives superior performance under latency constraints when compared to existing methods. Namely, we make a substantial 25\% relative false accepts improvement for a fixed latency target when compared to the baseline state-of-the-art. We also show that when our approach is used in conjunction with a max-pooling loss, we are able to improve relative false accepts by 25 % at a fixed latency when compared to cross entropy loss.      
### 48.Coevolutionary Dynamics of Actions and Opinions in Social Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.07242.pdf)
>  Modeling opinion formation and decision-making processes, important in their own rights, have been treated as separate problems in the study of dynamical models for social networks. Empirical studies suggest a deep intertwining between these two processes, and in this paper, we bridge the gap in the existing research by proposing a novel coevolutionary model. In the model, each individual can select an action from a binary set, and also holds an opinion on which action they prefer. Actions and opinions coevolve on a two-layer network structure. Under some reasonable assumptions on the network structure and asynchronous updating mechanics, we use rigorous analysis to establish that for all initial conditions, the actions converge in a finite number of time steps while opinions converge asymptotically. Next, we provide sufficient conditions for the emergence and the stability of polarized equilibria, whereby the population splits into two communities, each selecting and supporting one of the actions. Finally, numerical simulations are used to examine "pluralistic ignorance", whereby a social group incorrectly assumes the opinions of others due to the actions observed.      
### 49.A Neural Network-Prepended GLRT Framework for Signal Detection Under Nonlinear Distortions  [ :arrow_down: ](https://arxiv.org/pdf/2206.07232.pdf)
>  Many communications and sensing applications hinge on the detection of a signal in a noisy, interference-heavy environment. Signal processing theory yields techniques such as the generalized likelihood ratio test (GLRT) to perform detection when the received samples correspond to a linear observation model. Numerous practical applications exist, however, where the received signal has passed through a nonlinearity, causing significant performance degradation of the GLRT. In this work, we propose prepending the GLRT detector with a neural network classifier capable of identifying the particular nonlinear time samples in a received signal. We show that pre-processing received nonlinear signals using our trained classifier to eliminate excessively nonlinear samples (i) improves the detection performance of the GLRT on nonlinear signals and (ii) retains the theoretical guarantees provided by the GLRT on linear observation models for accurate signal detection.      
### 50.A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects  [ :arrow_down: ](https://arxiv.org/pdf/2206.07219.pdf)
>  The recent development of deep learning combined with compressed sensing enables fast reconstruction of undersampled MR images and has achieved state-of-the-art performance for Cartesian k-space trajectories. However, non-Cartesian trajectories such as the radial trajectory need to be transformed onto a Cartesian grid in each iteration of the network training, slowing down the training process and posing inconvenience and delay during training. Multiple iterations of nonuniform Fourier transform in the networks offset the deep learning advantage of fast inference. Current approaches typically either work on image-to-image networks or grid the non-Cartesian trajectories before the network training to avoid the repeated gridding process. However, the image-to-image networks cannot ensure the k-space data consistency in the reconstructed images and the pre-processing of non-Cartesian k-space leads to gridding errors which cannot be compensated by the network training. Inspired by the Transformer network to handle long-range dependencies in sequence transduction tasks, we propose to rearrange the radial spokes to sequential data based on the chronological order of acquisition and use the Transformer to predict unacquired radial spokes from acquired ones. We propose novel data augmentation methods to generate a large amount of training data from a limited number of subjects. The network can be generated to different anatomical structures. Experimental results show superior performance of the proposed framework compared to state-of-the-art deep neural networks.      
### 51.Federated Multi-organ Segmentation with Partially Labeled Data  [ :arrow_down: ](https://arxiv.org/pdf/2206.07156.pdf)
>  Federated learning is an emerging paradigm allowing large-scale decentralized learning without sharing data across different data owners, which helps address the concern of data privacy in medical image analysis. However, the requirement for label consistency across clients by the existing methods largely narrows its application scope. In practice, each clinical site may only annotate certain organs of interest with partial or no overlap with other sites. Incorporating such partially labeled data into a unified federation is an unexplored problem with clinical significance and urgency. This work tackles the challenge by using a novel federated multi-encoding U-Net (Fed-MENU) method for multi-organ segmentation. In our method, a multi-encoding U-Net (MENU-Net) is proposed to extract organ-specific features through different encoding sub-networks. Each sub-network can be seen as an expert of a specific organ and trained for that client. Moreover, to encourage the organ-specific features extracted by different sub-networks to be informative and distinctive, we regularize the training of the MENU-Net by designing an auxiliary generic decoder (AGD). Extensive experiments on four public datasets show that our Fed-MENU method can effectively obtain a federated learning model using the partially labeled datasets with superior performance to other models trained by either localized or centralized learning methods. Source code will be made publicly available at the time of paper publication.      
### 52.Attacks on Perception-Based Control Systems: Modeling and Fundamental Limits  [ :arrow_down: ](https://arxiv.org/pdf/2206.07150.pdf)
>  In this work, we study performance of perception-based control systems in the presence of attacks. We focus on a wide class of stochastic nonlinear control systems, and provide methods for modeling and analysis of their resiliency to stealthy attacks on both physical and perception-based sensing. Specifically, we consider a general setup with a nonlinear affine physical plant controlled with a perception-based controller that maps both the physical sensor (e.g., IMUs) and perceptual (e.g., camera) measurements to the control input; in addition, the system is equipped with a statistical or learning-based anomaly detector (AD) to detect the presence of abnormal behaviours in the system. To enable general performance analysis, we model the attacks on perception and physical sensing in the most general form. Further, we introduce the notions of attack effectiveness and stealthiness that are independent of the employed AD; i.e., the attack remaining stealthy even from the best existing detectors. In such setting, we consider attacks with different levels of runtime knowledge about the plant and its states. We find sufficient conditions for existence of stealthy effective attacks that force the plant state into an unsafe region without being detected by any employed AD. We show that as the open-loop unstable plant dynamics diverges faster and the closed-loop system converges faster to an equilibrium point, the system will be more vulnerable to effective stealthy attacks. Specifically, we show that depending on runtime information available to the attacker, the probability of attack remaining stealthy (against any AD) can be arbitrarily close to one, if the attackers estimate of the plant state is arbitrarily close to the true plant state.      
### 53.Broadband Beamforming via Linear Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2206.07143.pdf)
>  In modern applications multi-sensor arrays are subject to an ever-present demand to accommodate signals with higher bandwidths. Standard methods for broadband beamforming, namely digital beamforming and true-time delay, are difficult and expensive to implement at scale. In this work, we explore an alternative method of broadband beamforming that uses a set of linear measurements and a robust low-dimensional signal subspace model. The linear measurements, taken directly from the sensors, serve as a method for dimensionality reduction and serve to limit the array readout. From these embedded samples, we show how the original samples can be recovered to within a provably small residual error using a Slepian subspace model. <br>Previous work in multi-sensor array subspace models have largely analyzed performance from a qualitative or asymptotic perspective. In contrast, we give quantitative estimates of how well different dimensionality reduction strategies preserve the array gain. We also show how spatial and temporal correlations can be used to relax the standard Nyquist sampling criterion, how recovery can be achieved through fast algorithms, and how "hardware friendly" linear measurements can be designed.      
### 54.Experimental Comparison of PAM-8 Probabilistic Shaping with Different Gaussian Orders at 200 Gb/s Net Rate in IM/DD System with O-Band TOSA  [ :arrow_down: ](https://arxiv.org/pdf/2206.07142.pdf)
>  For 200Gb/s net rates, cap probabilistic shaped PAM-8 with different Gaussian orders are experimentally compared against uniform PAM-8. In back-to-back and 5km measurements, cap-shaped 85-GBd PAM-8 with Gaussian order of 5 outperforms 71-GBd uniform PAM-8 by up to 2.90dB and 3.80dB in receiver sensitivity, respectively.      
### 55.Comparison of Different Configurations of Saturated Core Fault Current Limiters in a Power Grid by Numerical Method  [ :arrow_down: ](https://arxiv.org/pdf/2206.07077.pdf)
>  Short circuit fault currents are increasing due to growing demand for electricity and high complexity in power systems. Because the fault currents reach the highest value which the breakers are unable to restrict, the electrical grid security is under jeopardy. By entering a limiting impedance into a transmission line in series, these impedances restrict the rising amounts of fault currents to levels that are acceptable. Saturated core fault current limiters (SCFCLs) are a pivotal tool for limiting fault currents rise in power networks that have good performance characteristics. In a normal condition, these limiters have slight effects on the system and can effectively limit short circuit currents when occur. In this chapter, various structures of SCFCLs with different arrangements of ac windings &amp; dc windings are presented and the currents passing through the FCLs under the normal and faulty system conditions are assessed and compared. The flux density in various regions of the core in different arrangements has been investigated as well and the desired analyzes have been performed. Simulation will be presented based on COMSOL Multiphysics 5.4, a finite element software package which can provide a precious assessment to compare these protective devices with different configurations.      
### 56.A Novel RIS-Aided EMF-Aware Beamforming Using Directional Spreading, Truncation and Boosting  [ :arrow_down: ](https://arxiv.org/pdf/2206.07051.pdf)
>  This paper addresses a drawback of massive multiple-input multiple-output Maximum Ratio Transmission beamforming. In some propagation conditions, when the base station serves the same target user equipment for a long period, it reduces the transmit power (and degrades the received power) to avoid creating high exposure regions located in the vicinity of the antenna and concentrated in few directions (corresponding to the best propagation paths between the antenna and the receiver). In this paper, we propose a novel electromagnetic field aware beamforming scheme, which (i) spreads the beamforming radiation pattern in the angular domain by adding artificial propagation paths thanks to reconfigurable intelligent surfaces, (ii) truncates the pattern in strong directions, and (iii) boosts it in weak directions. Compared to existing solutions, it maximizes the received power. However, it also consumes more power. Finally, truncation alone is the best trade-off between received power and energy efficiency, under exposure constrain.      
### 57.Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.07050.pdf)
>  This work is concerned with the following fundamental question in scientific machine learning: Can deep-learning-based methods solve noise-free inverse problems to near-perfect accuracy? Positive evidence is provided for the first time, focusing on a prototypical computed tomography (CT) setup. We demonstrate that an iterative end-to-end network scheme enables reconstructions close to numerical precision, comparable to classical compressed sensing strategies. Our results build on our winning submission to the recent AAPM DL-Sparse-View CT Challenge. Its goal was to identify the state-of-the-art in solving the sparse-view CT inverse problem with data-driven techniques. A specific difficulty of the challenge setup was that the precise forward model remained unknown to the participants. Therefore, a key feature of our approach was to initially estimate the unknown fanbeam geometry in a data-driven calibration step. Apart from an in-depth analysis of our methodology, we also demonstrate its state-of-the-art performance on the open-access real-world dataset LoDoPaB CT.      
### 58.Residual Sparsity Connection Learning for Efficient Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2206.07687.pdf)
>  Lighter and faster models are crucial for the deployment of video super-resolution (VSR) on resource-limited devices, e.g., smartphones and wearable devices. In this paper, we develop Residual Sparsity Connection Learning (RSCL), a structured pruning scheme, to reduce the redundancy of convolution kernels and obtain a compact VSR network with a minor performance drop. However, residual blocks require the pruned filter indices of skip and residual connections to be the same, which is tricky for pruning. Thus, to mitigate the pruning restrictions of residual blocks, we design a Residual Sparsity Connection (RSC) scheme by preserving the feature channels and only operating on the important channels. Moreover, for the pixel-shuffle operation, we design a special pruning scheme by grouping several filters as pruning units to guarantee the accuracy of feature channel-space conversion after pruning. In addition, we introduce Temporal Finetuning (TF) to reduce the pruning error amplification of hidden states with temporal propagation. Extensive experiments show that the proposed RSCL significantly outperforms recent methods quantitatively and qualitatively. Codes and models will be released.      
### 59.AVATAR: Unconstrained Audiovisual Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.07684.pdf)
>  Audio-visual automatic speech recognition (AV-ASR) is an extension of ASR that incorporates visual cues, often from the movements of a speaker's mouth. Unlike works that simply focus on the lip motion, we investigate the contribution of entire visual frames (visual actions, objects, background etc.). This is particularly useful for unconstrained videos, where the speaker is not necessarily visible. To solve this task, we propose a new sequence-to-sequence AudioVisual ASR TrAnsformeR (AVATAR) which is trained end-to-end from spectrograms and full-frame RGB. To prevent the audio stream from dominating training, we propose different word-masking strategies, thereby encouraging our model to pay attention to the visual stream. We demonstrate the contribution of the visual modality on the How2 AV-ASR benchmark, especially in the presence of simulated noise, and show that our model outperforms all other prior work by a large margin. Finally, we also create a new, real-world test bed for AV-ASR called VisSpeech, which demonstrates the contribution of the visual modality under challenging audio conditions.      
### 60.Experimental Validation of Spectral-Spatial Power Evolution Design Using Raman Amplifiers  [ :arrow_down: ](https://arxiv.org/pdf/2206.07658.pdf)
>  We experimentally validate a machine learning-enabled Raman amplification framework, capable of jointly shaping the signal power evolution in two domains: frequency and fiber distance. The proposed experiment addresses the amplification in the whole C-band, by optimizing four first-order counter-propagating Raman pumps.      
### 61.Exploring Capabilities of Monolingual Audio Transformers using Large Datasets in Automatic Speech Recognition of Czech  [ :arrow_down: ](https://arxiv.org/pdf/2206.07627.pdf)
>  In this paper, we present our progress in pretraining Czech monolingual audio transformers from a large dataset containing more than 80 thousand hours of unlabeled speech, and subsequently fine-tuning the model on automatic speech recognition tasks using a combination of in-domain data and almost 6 thousand hours of out-of-domain transcribed speech. We are presenting a large palette of experiments with various fine-tuning setups evaluated on two public datasets (CommonVoice and VoxPopuli) and one extremely challenging dataset from the MALACH project. Our results show that monolingual Wav2Vec 2.0 models are robust ASR systems, which can take advantage of large labeled and unlabeled datasets and successfully compete with state-of-the-art LVCSR systems. Moreover, Wav2Vec models proved to be good zero-shot learners when no training data are available for the target ASR task.      
### 62.A Deep Generative Model of Neonatal Cortical Surface Development  [ :arrow_down: ](https://arxiv.org/pdf/2206.07542.pdf)
>  The neonatal cortical surface is known to be affected by preterm birth, and the subsequent changes to cortical organisation have been associated with poorer neurodevelopmental outcomes. Deep Generative models have the potential to lead to clinically interpretable models of disease, but developing these on the cortical surface is challenging since established techniques for learning convolutional filters are inappropriate on non-flat topologies. To close this gap, we implement a surface-based CycleGAN using mixture model CNNs (MoNet) to translate sphericalised neonatal cortical surface features (curvature and T1w/T2w cortical myelin) between different stages of cortical maturity. Results show our method is able to reliably predict changes in individual patterns of cortical organisation at later stages of gestation, validated by comparison to longitudinal data; and translate appearance between preterm and term gestation (&gt; 37 weeks gestation), validated through comparison with a trained term/preterm classifier. Simulated differences in cortical maturation are consistent with observations in the literature.      
### 63.Investigating Multi-Feature Selection and Ensembling for Audio Classification  [ :arrow_down: ](https://arxiv.org/pdf/2206.07511.pdf)
>  Deep Learning (DL) algorithms have shown impressive performance in diverse domains. Among them, audio has attracted many researchers over the last couple of decades due to some interesting patterns--particularly in classification of audio data. For better performance of audio classification, feature selection and combination play a key role as they have the potential to make or break the performance of any DL model. To investigate this role, we conduct an extensive evaluation of the performance of several cutting-edge DL models (i.e., Convolutional Neural Network, EfficientNet, MobileNet, Supper Vector Machine and Multi-Perceptron) with various state-of-the-art audio features (i.e., Mel Spectrogram, Mel Frequency Cepstral Coefficients, and Zero Crossing Rate) either independently or as a combination (i.e., through ensembling) on three different datasets (i.e., Free Spoken Digits Dataset, Audio Urdu Digits Dataset, and Audio Gujarati Digits Dataset). Overall, results suggest feature selection depends on both the dataset and the model. However, feature combinations should be restricted to the only features that already achieve good performances when used individually (i.e., mostly Mel Spectrogram, Mel Frequency Cepstral Coefficients). Such feature combination/ensembling enabled us to outperform the previous state-of-the-art results irrespective of our choice of DL model.      
### 64.Mitigating Intra-Cell Pilot Contamination in Massive MIMO: A Rate Splitting Approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.07499.pdf)
>  Massive MIMO (MaMIMO) has become an integral part of the 5G standard, and is envisioned to be further developed in beyond 5G networks. With a massive number of antennas at the base station (BS), MaMIMO is best equipped to cater prominent use cases of B5G networks such as enhanced mobile broadband (eMBB), ultra-reliable low-latency communications (URLLC) and massive machine-type communications (mMTC) or combinations thereof. However, one of the critical challenges to this pursuit is the sporadic access behaviour of the massive number of devices in practical networks that inevitably leads to the conspicuous pilot contamination problem. Conventional linearly precoded physical layer strategies employed for downlink transmission in time division duplex (TDD) MaMIMO would incur a noticeable spectral efficiency (SE) loss in the presence of this pilot contamination. In this paper, we aim to integrate a robust multiple access and interference management strategy named rate-splitting multiple access (RSMA) with TDD MaMIMO for downlink transmission and investigate its SE performance. We propose a novel downlink transmission framework of RSMA in TDD MaMIMO, devise a precoder design strategy and power allocation schemes to maximize different network utility functions. Numerical results reveal that RSMA is significantly more robust to pilot contamination and always achieves a SE performance that is equal to or better than the conventional linearly precoded MaMIMO transmission strategy.      
### 65.Coarse-to-fine Deep Video Coding with Hyperprior-guided Mode Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.07460.pdf)
>  The previous deep video compression approaches only use the single scale motion compensation strategy and rarely adopt the mode prediction technique from the traditional standards like H.264/H.265 for both motion and residual compression. In this work, we first propose a coarse-to-fine (C2F) deep video compression framework for better motion compensation, in which we perform motion estimation, compression and compensation twice in a coarse to fine manner. Our C2F framework can achieve better motion compensation results without significantly increasing bit costs. Observing hyperprior information (i.e., the mean and variance values) from the hyperprior networks contains discriminant statistical information of different patches, we also propose two efficient hyperprior-guided mode prediction methods. Specifically, using hyperprior information as the input, we propose two mode prediction networks to respectively predict the optimal block resolutions for better motion coding and decide whether to skip residual information from each block for better residual coding without introducing additional bit cost while bringing negligible extra computation cost. Comprehensive experimental results demonstrate our proposed C2F video compression framework equipped with the new hyperprior-guided mode prediction methods achieves the state-of-the-art performance on HEVC, UVG and MCL-JCV datasets.      
### 66.VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection  [ :arrow_down: ](https://arxiv.org/pdf/2206.07458.pdf)
>  The goal of this work is to reconstruct speech from a silent talking face video. Recent studies have shown impressive performance on synthesizing speech from silent talking face videos. However, they have not explicitly considered on varying identity characteristics of different speakers, which place a challenge in the video-to-speech synthesis, and this becomes more critical in unseen-speaker settings. Distinct from the previous methods, our approach is to separate the speech content and the visage-style from a given silent talking face video. By guiding the model to independently focus on modeling the two representations, we can obtain the speech of high intelligibility from the model even when the input video of an unseen subject is given. To this end, we introduce speech-visage selection module that separates the speech content and the speaker identity from the visual features of the input video. The disentangled representations are jointly incorporated to synthesize speech through visage-style based synthesizer which generates speech by coating the visage-styles while maintaining the speech content. Thus, the proposed framework brings the advantage of synthesizing the speech containing the right content even when the silent talking face video of an unseen subject is given. We validate the effectiveness of the proposed framework on the GRID, TCD-TIMIT volunteer, and LRW datasets. The synthesized speech can be heard in supplementary materials.      
### 67.NatiQ: An End-to-end Text-to-Speech System for Arabic  [ :arrow_down: ](https://arxiv.org/pdf/2206.07373.pdf)
>  NatiQ is end-to-end text-to-speech system for Arabic. Our speech synthesizer uses an encoder-decoder architecture with attention. We used both tacotron-based models (tacotron-1 and tacotron-2) and the faster transformer model for generating mel-spectrograms from characters. We concatenated Tacotron1 with the WaveRNN vocoder, Tacotron2 with the WaveGlow vocoder and ESPnet transformer with the parallel wavegan vocoder to synthesize waveforms from the spectrograms. We used in-house speech data for two voices: 1) neutral male "Hamza"- narrating general content and news, and 2) expressive female "Amina"- narrating children story books to train our models. Our best systems achieve an average Mean Opinion Score (MOS) of 4.21 and 4.40 for Amina and Hamza respectively. The objective evaluation of the systems using word and character error rate (WER and CER) as well as the response time measured by real-time factor favored the end-to-end architecture ESPnet. NatiQ demo is available on-line at <a class="link-external link-https" href="https://tts.qcri.org" rel="external noopener nofollow">this https URL</a>      
### 68.Robust SAR ATR on MSTAR with Deep Learning Models trained on Full Synthetic MOCEM data  [ :arrow_down: ](https://arxiv.org/pdf/2206.07352.pdf)
>  The promising potential of Deep Learning for Automatic Target Recognition (ATR) on Synthetic Aperture Radar (SAR) images vanishes when considering the complexity of collecting training datasets measurements. Simulation can overcome this issue by producing synthetic training datasets. However, because of the limited representativeness of simulation, models trained in a classical way with synthetic images have limited generalization abilities when dealing with real measurement at test time. Previous works identified a set of equally promising deep-learning algorithms to tackle this issue. However, these approaches have been evaluated in a very favorable scenario with a synthetic training dataset that overfits the ground truth of the measured test data. In this work, we study the ATR problem outside of this ideal condition, which is unlikely to occur in real operational contexts. Our contribution is threefold. (1) Using the MOCEM simulator (developed by SCALIAN DS for the French MoD/DGA), we produce a synthetic MSTAR training dataset that differs significantly from the real measurements. (2) We experimentally demonstrate the limits of the state-of-the-art. (3) We show that domain randomization techniques and adversarial training can be combined to overcome this issue. We demonstrate that this approach is more robust than the state-of-the-art, with an accuracy of 75 %, while having a limited impact on computing performance during training.      
### 69.On the Use of Deep Mask Estimation Module for Neural Source Separation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.07347.pdf)
>  Most of the recent neural source separation systems rely on a masking-based pipeline where a set of multiplicative masks are estimated from and applied to a signal representation of the input mixture. The estimation of such masks, in almost all network architectures, is done by a single layer followed by an optional nonlinear activation function. However, recent literatures have investigated the use of a deep mask estimation module and observed performance improvement compared to a shallow mask estimation module. In this paper, we analyze the role of such deeper mask estimation module by connecting it to a recently proposed unsupervised source separation method, and empirically show that the deep mask estimation module is an efficient approximation of the so-called overseparation-grouping paradigm with the conventional shallow mask estimation layers.      
### 70.On the Design and Training Strategies for RNN-based Online Neural Speech Separation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.07340.pdf)
>  While the performance of offline neural speech separation systems has been greatly advanced by the recent development of novel neural network architectures, there is typically an inevitable performance gap between the systems and their online variants. In this paper, we investigate how RNN-based offline neural speech separation systems can be changed into their online counterparts while mitigating the performance degradation. We decompose or reorganize the forward and backward RNN layers in a bidirectional RNN layer to form an online path and an offline path, which enables the model to perform both online and offline processing with a same set of model parameters. We further introduce two training strategies for improving the online model via either a pretrained offline model or a multitask training objective. Experiment results show that compared to the online models that are trained from scratch, the proposed layer decomposition and reorganization schemes and training strategies can effectively mitigate the performance gap between two RNN-based offline separation models and their online variants.      
### 71.VCT: A Video Compression Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2206.07307.pdf)
>  We show how transformers can be used to vastly simplify neural video compression. Previous methods have been relying on an increasing number of architectural biases and priors, including motion prediction and warping operations, resulting in complex models. Instead, we independently map input frames to representations and use a transformer to model their dependencies, letting it predict the distribution of future representations given the past. The resulting video compression transformer outperforms previous methods on standard video compression data sets. Experiments on synthetic data show that our model learns to handle complex motion patterns such as panning, blurring and fading purely from data. Our approach is easy to implement, and we release code to facilitate future research.      
### 72.FRCRN: Boosting Feature Representation using Frequency Recurrence for Monaural Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2206.07293.pdf)
>  Convolutional recurrent networks (CRN) integrating a convolutional encoder-decoder (CED) structure and a recurrent structure have achieved promising performance for monaural speech enhancement. However, feature representation across frequency context is highly constrained due to limited receptive fields in the convolutions of CED. In this paper, we propose a convolutional recurrent encoder-decoder (CRED) structure to boost feature representation along the frequency axis. The CRED applies frequency recurrence on 3D convolutional feature maps along the frequency axis following each convolution, therefore, it is capable of catching long-range frequency correlations and enhancing feature representations of speech inputs. The proposed frequency recurrence is realized efficiently using a feedforward sequential memory network (FSMN). Besides the CRED, we insert two stacked FSMN layers between the encoder and the decoder to model further temporal dynamics. We name the proposed framework as Frequency Recurrent CRN (FRCRN). We design FRCRN to predict complex Ideal Ratio Mask (cIRM) in complex-valued domain and optimize FRCRN using both time-frequency-domain and time-domain losses. Our proposed approach achieved state-of-the-art performance on wideband benchmark datasets and achieved 2nd place for the real-time fullband track in terms of Mean Opinion Score (MOS) and Word Accuracy (WAcc) in the ICASSP 2022 Deep Noise Suppression (DNS) challenge.      
### 73.Text-Aware End-to-end Mispronunciation Detection and Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2206.07289.pdf)
>  Mispronunciation detection and diagnosis (MDD) technology is a key component of computer-assisted pronunciation training system (CAPT). In the field of assessing the pronunciation quality of constrained speech, the given transcriptions can play the role of a teacher. Conventional methods have fully utilized the prior texts for the model construction or improving the system performance, e.g. forced-alignment and extended recognition networks. Recently, some end-to-end based methods attempt to incorporate the prior texts into model training and preliminarily show the effectiveness. However, previous studies mostly consider applying raw attention mechanism to fuse audio representations with text representations, without taking possible text-pronunciation mismatch into account. In this paper, we present a gating strategy that assigns more importance to the relevant audio features while suppressing irrelevant text information. Moreover, given the transcriptions, we design an extra contrastive loss to reduce the gap between the learning objective of phoneme recognition and MDD. We conducted experiments using two publicly available datasets (TIMIT and L2-Arctic) and our best model improved the F1 score from $57.51\%$ to $61.75\%$ compared to the baselines. Besides, we provide a detailed analysis to shed light on the effectiveness of gating mechanism and contrastive learning on MDD.      
### 74.Streaming non-autoregressive model for any-to-many voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2206.07288.pdf)
>  Voice conversion models have developed for decades, and current mainstream research focuses on non-streaming voice conversion. However, streaming voice conversion is more suitable for practical application scenarios than non-streaming voice conversion. In this paper, we propose a streaming any-to-many voice conversion based on fully non-autoregressive model, which includes a streaming transformer based acoustic model and a streaming vocoder. Streaming transformer based acoustic model is composed of a pre-trained encoder from streaming end-to-end based automatic speech recognition model and a decoder modified on FastSpeech blocks. Streaming vocoder is designed for streaming task with pseudo quadrature mirror filter bank and causal convolution. Experimental results show that the proposed method achieves significant performance both in latency and conversion quality and can be real-time on CPU and GPU.      
### 75.Two-Timescale Optimization for Intelligent Reflecting Surface-Assisted MIMO Transmission in Fast-Changing Channels  [ :arrow_down: ](https://arxiv.org/pdf/2206.07276.pdf)
>  The application of intelligent reflecting surface (IRS) depends on the knowledge of channel state information (CSI), and has been hindered by the heavy overhead of channel training, estimation, and feedback in fast-changing channels. This paper presents a new two-timescale beamforming approach to maximizing the average achievable rate (AAR) of IRS-assisted MIMO systems, where the IRS is configured relatively infrequently based on statistical CSI (S-CSI) and the base station precoder and power allocation are updated frequently based on quickly outdated instantaneous CSI (I-CSI). The key idea is that we first reveal the optimal small-timescale power allocation based on outdated I-CSI yields a water-filling structure. Given the optimal power allocation, a new mini-batch sampling (mbs)- based particle swarm optimization (PSO) algorithm is developed to optimize the large-timescale IRS configuration with reduced channel samples. Another important aspect is that we develop a model-driven PSO algorithm to optimize the IRS configuration, which maximizes a lower bound of the AAR by only using the S-CSI and eliminates the need of channel samples. The modeldriven PSO serves as a dependable lower bound for the mbs-PSO. Simulations corroborate the superiority of the new two-timescale beamforming strategy to its alternatives in terms of the AAR and efficiency, with the benefits of the IRS demonstrated.      
### 76.Resilience and Energy-Awareness in Constraint-Driven-Controlled Multi-Robot Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.07231.pdf)
>  In the context of constraint-driven control of multi-robot systems, in this paper, we propose an optimization-based framework that is able to ensure resilience and energy-awareness of teams of robots. The approach is based on a novel, frame-theoretic, measure of resilience which allows us to analyze and enforce resilient behaviors of multi-robot systems. The properties of resilience and energy-awareness are encoded as constraints of a convex optimization program which is used to synthesize the robot control inputs. This allows for the combination of such properties with the execution of coordinated tasks to achieve resilient and energy-aware robot operations. The effectiveness of the proposed method is illustrated in a simulated scenario where a team of robots is deployed to execute two tasks subject to energy and resilience constraints.      
### 77.Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on Data-Driven Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.07229.pdf)
>  Emotion classification of speech and assessment of the emotion strength are required in applications such as emotional text-to-speech and voice conversion. The emotion attribute ranking function based on Support Vector Machine (SVM) was proposed to predict emotion strength for emotional speech corpus. However, the trained ranking function doesn't generalize to new domains, which limits the scope of applications, especially for out-of-domain or unseen speech. In this paper, we propose a data-driven deep learning model, i.e. StrengthNet, to improve the generalization of emotion strength assessment for seen and unseen speech. This is achieved by the fusion of emotional data from various domains. We follow a multi-task learning network architecture that includes an acoustic encoder, a strength predictor, and an auxiliary emotion predictor. Experiments show that the predicted emotion strength of the proposed StrengthNet is highly correlated with ground truth scores for both seen and unseen speech. We release the source codes at: <a class="link-external link-https" href="https://github.com/ttslr/StrengthNet" rel="external noopener nofollow">this https URL</a>.      
### 78.Defending Observation Attacks in Deep Reinforcement Learning via Detection and Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2206.07188.pdf)
>  Neural network policies trained using Deep Reinforcement Learning (DRL) are well-known to be susceptible to adversarial attacks. In this paper, we consider attacks manifesting as perturbations in the observation space managed by the external environment. These attacks have been shown to downgrade policy performance significantly. We focus our attention on well-trained deterministic and stochastic neural network policies in the context of continuous control benchmarks subject to four well-studied observation space adversarial attacks. To defend against these attacks, we propose a novel defense strategy using a detect-and-denoise schema. Unlike previous adversarial training approaches that sample data in adversarial scenarios, our solution does not require sampling data in an environment under attack, thereby greatly reducing risk during training. Detailed experimental results show that our technique is comparable with state-of-the-art adversarial training approaches.      
### 79.Frequency-centroid features for word recognition of non-native English speakers  [ :arrow_down: ](https://arxiv.org/pdf/2206.07176.pdf)
>  The objective of this work is to investigate complementary features which can aid the quintessential Mel frequency cepstral coefficients (MFCCs) in the task of closed, limited set word recognition for non-native English speakers of different mother-tongues. Unlike the MFCCs, which are derived from the spectral energy of the speech signal, the proposed frequency-centroids (FCs) encapsulate the spectral centres of the different bands of the speech spectrum, with the bands defined by the Mel filterbank. These features, in combination with the MFCCs, are observed to provide relative performance improvement in English word recognition, particularly under varied noisy conditions. A two-stage Convolution Neural Network (CNN) is used to model the features of the English words uttered with Arabic, French and Spanish accents.      
### 80.DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method  [ :arrow_down: ](https://arxiv.org/pdf/2206.07163.pdf)
>  Joint 2D cardiac segmentation and 3D volume reconstruction are fundamental to building statistical cardiac anatomy models and understanding functional mechanisms from motion patterns. However, due to the low through-plane resolution of cine MR and high inter-subject variance, accurately segmenting cardiac images and reconstructing the 3D volume are challenging. In this study, we propose an end-to-end latent-space-based framework, DeepRecon, that generates multiple clinically essential outcomes, including accurate image segmentation, synthetic high-resolution 3D image, and 3D reconstructed volume. Our method identifies the optimal latent representation of the cine image that contains accurate semantic information for cardiac structures. In particular, our model jointly generates synthetic images with accurate semantic information and segmentation of the cardiac structures using the optimal latent representation. We further explore downstream applications of 3D shape reconstruction and 4D motion pattern adaptation by the different latent-space manipulation strategies.The simultaneously generated high-resolution images present a high interpretable value to assess the cardiac shape and motion.Experimental results demonstrate the effectiveness of our approach on multiple fronts including 2D segmentation, 3D reconstruction, downstream 4D motion pattern adaption performance.      
### 81.Stability of image reconstruction algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2206.07128.pdf)
>  Robustness and stability of image reconstruction algorithms have recently come under scrutiny. Their importance to medical imaging cannot be overstated. We review the known results for the topical variational regularization strategies ($\ell_2$ and $\ell_1$ regularization), and present new stability results for $\ell_p$ regularized linear inverse problems for $p\in(1,\infty)$. Our results generalize well to the respective $L_p(\Omega)$ function spaces.      
### 82.Learning the Structure of Large Networked Systems Obeying Conservation Laws  [ :arrow_down: ](https://arxiv.org/pdf/2206.07083.pdf)
>  Many networked systems such as electric networks, the brain, and social networks of opinion dynamics are known to obey conservation laws. Examples of this phenomenon include the Kirchoff laws in electric networks and opinion consensus in social networks. Conservation laws in networked systems may be modeled as balance equations of the form $X = B^{*} Y$, where the sparsity pattern of $B^{*}$ captures the connectivity of the network, and $Y, X \in \mathbb{R}^p$ are vectors of "potentials" and "injected flows" at the nodes respectively. The node potentials $Y$ cause flows across edges and the flows $X$ injected at the nodes are extraneous to the network dynamics. In several practical systems, the network structure is often unknown and needs to be estimated from data. Towards this, one has access to samples of the node potentials $Y$, but only the statistics of the node injections $X$. Motivated by this important problem, we study the estimation of the sparsity structure of the matrix $B^{*}$ from $n$ samples of $Y$ under the assumption that the node injections $X$ follow a Gaussian distribution with a known covariance $\Sigma_X$. We propose a new $\ell_{1}$-regularized maximum likelihood estimator for this problem in the high-dimensional regime where the size of the network $p$ is larger than sample size $n$. We show that this optimization problem is convex in the objective and admits a unique solution. Under a new mutual incoherence condition, we establish sufficient conditions on the triple $(n,p,d)$ for which exact sparsity recovery of $B^{*}$ is possible with high probability; $d$ is the degree of the graph. We also establish guarantees for the recovery of $B^{*}$ in the element-wise maximum, Frobenius, and operator norms. Finally, we complement these theoretical results with experimental validation of the performance of the proposed estimator on synthetic and real-world data.      
### 83.Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience  [ :arrow_down: ](https://arxiv.org/pdf/2206.07081.pdf)
>  Generative adversarial networks (GANs) are one powerful type of deep learning models that have been successfully utilized in numerous fields. They belong to a broader family called generative methods, which generate new data with a probabilistic model by learning sample distribution from real examples. In the clinical context, GANs have shown enhanced capabilities in capturing spatially complex, nonlinear, and potentially subtle disease effects compared to traditional generative methods. This review appraises the existing literature on the applications of GANs in imaging studies of various neurological conditions, including Alzheimer's disease, brain tumors, brain aging, and multiple sclerosis. We provide an intuitive explanation of various GAN methods for each application and further discuss the main challenges, open questions, and promising future directions of leveraging GANs in neuroimaging. We aim to bridge the gap between advanced deep learning methods and neurology research by highlighting how GANs can be leveraged to support clinical decision making and contribute to a better understanding of the structural and functional patterns of brain diseases.      
