# ArXiv eess --Mon, 27 Jun 2022
### 1.Cooperative Control in Eco-Driving of Electric Connected and Autonomous Vehicles in an Un-Signalized Urban Intersection  [ :arrow_down: ](https://arxiv.org/pdf/2206.12360.pdf)
>  This paper addresses the problem of finding the optimal Eco-Driving (ED) speed profile of an electric Connected and Automated Vehicle (CAV) in an isolated urban un-signalized intersection. The problem is formulated as a single-level optimization and solved using Pontryagin's Minimum Principle (PMP). Analytical solutions are presented for various conflicts that occur at an intersection. Cooperation is introduced amongst CAVs as the ability to share intentions. Two levels of cooperation, namely the Cooperative ED (C-ED) and Non-Cooperative (NC-ED) algorithms are evaluated, in a simulation environment, for energy efficiency with Intelligent Driver Model (IDM) as the baseline.      
### 2.Segmentation-free PVC for Cardiac SPECT using a Densely-connected Multi-dimensional Dynamic Network  [ :arrow_down: ](https://arxiv.org/pdf/2206.12344.pdf)
>  In nuclear imaging, limited resolution causes partial volume effects (PVEs) that affect image sharpness and quantitative accuracy. Partial volume correction (PVC) methods incorporating high-resolution anatomical information from CT or MRI have been demonstrated to be effective. However, such anatomical-guided methods typically require tedious image registration and segmentation steps. Accurately segmented organ templates are also hard to obtain, particularly in cardiac SPECT imaging, due to the lack of hybrid SPECT/CT scanners with high-end CT and associated motion artifacts. Slight mis-registration/mis-segmentation would result in severe degradation in image quality after PVC. In this work, we develop a deep-learning-based method for fast cardiac SPECT PVC without anatomical information and associated organ segmentation. The proposed network involves a densely-connected multi-dimensional dynamic mechanism, allowing the convolutional kernels to be adapted based on the input images, even after the network is fully trained. Intramyocardial blood volume (IMBV) is introduced as an additional clinical-relevant loss function for network optimization. The proposed network demonstrated promising performance on 28 canine studies acquired on a GE Discovery NM/CT 570c dedicated cardiac SPECT scanner with a 64-slice CT using Technetium-99m-labeled red blood cells. This work showed that the proposed network with densely-connected dynamic mechanism produced superior results compared with the same network without such mechanism. Results also showed that the proposed network without anatomical information could produce images with statistically comparable IMBV measurements to the images generated by anatomical-guided PVC methods, which could be helpful in clinical translation.      
### 3.Analyzing the impact of SARS-CoV-2 variants on respiratory sound signals  [ :arrow_down: ](https://arxiv.org/pdf/2206.12309.pdf)
>  The COVID-19 outbreak resulted in multiple waves of infections that have been associated with different SARS-CoV-2 variants. Studies have reported differential impact of the variants on respiratory health of patients. We explore whether acoustic signals, collected from COVID-19 subjects, show computationally distinguishable acoustic patterns suggesting a possibility to predict the underlying virus variant. We analyze the Coswara dataset which is collected from three subject pools, namely, i) healthy, ii) COVID-19 subjects recorded during the delta variant dominant period, and iii) data from COVID-19 subjects recorded during the omicron surge. Our findings suggest that multiple sound categories, such as cough, breathing, and speech, indicate significant acoustic feature differences when comparing COVID-19 subjects with omicron and delta variants. The classification areas-under-the-curve are significantly above chance for differentiating subjects infected by omicron from those infected by delta. Using a score fusion from multiple sound categories, we obtained an area-under-the-curve of 89% and 52.4% sensitivity at 95% specificity. Additionally, a hierarchical three class approach was used to classify the acoustic data into healthy and COVID-19 positive, and further COVID-19 subjects into delta and omicron variants providing high level of 3-class classification accuracy. These results suggest new ways for designing sound based COVID-19 diagnosis approaches.      
### 4.Automatic extraction of coronary arteries using deep learning in invasive coronary angiograms  [ :arrow_down: ](https://arxiv.org/pdf/2206.12300.pdf)
>  Accurate extraction of coronary arteries from invasive coronary angiography (ICA) is important in clinical decision-making for the diagnosis and risk stratification of coronary artery disease (CAD). In this study, we develop a method using deep learning to automatically extract the coronary artery lumen. Methods. A deep learning model U-Net 3+, which incorporates the full-scale skip connections and deep supervisions, was proposed for automatic extraction of coronary arteries from ICAs. Transfer learning and a hybrid loss function were employed in this novel coronary artery extraction framework. Results. A data set containing 616 ICAs obtained from 210 patients was used. In the technical evaluation, the U-Net 3+ achieved a Dice score of 0.8942 and a sensitivity of 0.8735, which is higher than U-Net ++ (Dice score: 0.8814, the sensitivity of 0.8331) and U-net (Dice score: 0.8799, the sensitivity of 0.8305). Conclusion. Our study demonstrates that the U-Net 3+ is superior to other segmentation frameworks for the automatic extraction of the coronary arteries from ICAs. This result suggests great promise for clinical use.      
### 5.SAQAM: Spatial Audio Quality Assessment Metric  [ :arrow_down: ](https://arxiv.org/pdf/2206.12297.pdf)
>  Audio quality assessment is critical for assessing the perceptual realism of sounds. However, the time and expense of obtaining ''gold standard'' human judgments limit the availability of such data. For AR&amp;VR, good perceived sound quality and localizability of sources are among the key elements to ensure complete immersion of the user. Our work introduces SAQAM which uses a multi-task learning framework to assess listening quality (LQ) and spatialization quality (SQ) between any given pair of binaural signals without using any subjective data. We model LQ by training on a simulated dataset of triplet human judgments, and SQ by utilizing activation-level distances from networks trained for direction of arrival (DOA) estimation. We show that SAQAM correlates well with human responses across four diverse datasets. Since it is a deep network, the metric is differentiable, making it suitable as a loss function for other tasks. For example, simply replacing an existing loss with our metric yields improvement in a speech-enhancement network.      
### 6.Optimiziation of Geometric Constellation Shaping for Wiener Phase Noise Channels with Varying Channel Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2206.12288.pdf)
>  We present a novel method to investigate the effects of varying channel parameters on geometrically shaped constellations for communication systems employing the blind phase search algorithm. We show that introduced asymmetries significantly improve performance if adapted to changing channel parameters.      
### 7.Speech Quality Assessment through MOS using Non-Matching References  [ :arrow_down: ](https://arxiv.org/pdf/2206.12285.pdf)
>  Human judgments obtained through Mean Opinion Scores (MOS) are the most reliable way to assess the quality of speech signals. However, several recent attempts to automatically estimate MOS using deep learning approaches lack robustness and generalization capabilities, limiting their use in real-world applications. In this work, we present a novel framework, NORESQA-MOS, for estimating the MOS of a speech signal. Unlike prior works, our approach uses non-matching references as a form of conditioning to ground the MOS estimation by neural networks. We show that NORESQA-MOS provides better generalization and more robust MOS estimation than previous state-of-the-art methods such as DNSMOS and NISQA, even though we use a smaller training set. Moreover, we also show that our generic framework can be combined with other learning methods such as self-supervised learning and can further supplement the benefits from these methods.      
### 8.Open-source objective-oriented framework for head-related transfer function  [ :arrow_down: ](https://arxiv.org/pdf/2206.12283.pdf)
>  Throughout last 30 years, numerous head-related transfer function (HRTF) models have been developed and there are more to come. This paper describes a framework based on objective-oriented programming paradigm, in which each HRTF representation method can be implemented as a separate class. Its modular structure allows the source code to be conveniently shared between researchers, while common interface provides easy access to data regardless of the internal structure of the classes. The paper discusses difficulties of designing the framework, maintaining the balance between its flexibility and finding common features of every possible directivity representation. Exemplary use cases are included and explained. Adoption of the framework will enhance possibilities of accuracy comparison between various HRTF models, thus improving the evaluation of current and future representation methods. The framework, developed in the form of a MATLAB toolbox, is designed to handle not only HRTFs but also other types of spatial data, such as e.g. sound source directivity, microphone directivity, etc.      
### 9.Real-time Dual-channel 2 * 2 MIMO Fiber-THz-Fiber Seamless Integration System at 385 GHz and 435 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2206.12281.pdf)
>  We demonstrate the first practical real-time dual-channel fiber-THz-fiber 2 * 2 MIMO seamless integration system with a record net data rate of 2 * 103.125 Gb/s at 385 GHz and 435 GHz over two spans of 20 km SSMF and 3 m wireless link.      
### 10.Iterative Sound Source Localization for Unknown Number of Sources  [ :arrow_down: ](https://arxiv.org/pdf/2206.12273.pdf)
>  Sound source localization aims to seek the direction of arrival (DOA) of all sound sources from the observed multi-channel audio. For the practical problem of unknown number of sources, existing localization algorithms attempt to predict a likelihood-based coding (i.e., spatial spectrum) and employ a pre-determined threshold to detect the source number and corresponding DOA value. However, these threshold-based algorithms are not stable since they are limited by the careful choice of threshold. To address this problem, we propose an iterative sound source localization approach called ISSL, which can iteratively extract each source's DOA without threshold until the termination criterion is met. Unlike threshold-based algorithms, ISSL designs an active source detector network based on binary classifier to accept residual spatial spectrum and decide whether to stop the iteration. By doing so, our ISSL can deal with an arbitrary number of sources, even more than the number of sources seen during the training stage. The experimental results show that our ISSL achieves significant performance improvements in both DOA estimation and source number detection compared with the existing threshold-based algorithms.      
### 11.Adaptive Nonlinear Regulation via Gaussian Process  [ :arrow_down: ](https://arxiv.org/pdf/2206.12225.pdf)
>  The paper deals with the problem of output regulation of nonlinear systems by presenting a learning-based adaptive internal model-based design strategy. We borrow from the adaptive internal model design technique recently proposed in [1] and extend it by means of a Gaussian process regressor. The learning-based adaptation is performed by following an "event-triggered" logic so that hybrid tools are used to analyse the resulting closed-loop system. Unlike the approach proposed in [1] where the friend is supposed to belong to a specific finite-dimensional model set, here we only require smoothness of the ideal steady-state control action. The paper also presents numerical simulations showing how the proposed method outperforms previous approaches.      
### 12.Joint Beam Hopping and Carrier Aggregation in High Throughput Multi-Beam Satellite Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.12217.pdf)
>  Beam hopping (BH) and carrier aggregation (CA) are two promising technologies for the next generation satellite communication systems to achieve several orders of magnitude increase in system capacity and to significantly improve the spectral efficiency. While BH allows a great flexibility in adapting the offered capacity to the heterogeneous demand, CA further enhances the user quality-of-service (QoS) by allowing it to pool resources from multiple adjacent beams. In this paper, we consider a multi-beam high throughput satellite (HTS) system that employs BH in conjunction with CA to capitalize on the mutual interplay between both techniques. Particularly, an innovative joint BH-CA scheme is proposed and analyzed in this work to utilize their individual competencies. This includes designing an efficient joint time-space beam illumination pattern for BH and multi-user aggregation strategy for CA. Through this, user-carrier assignment, transponder filling-rates, beams hopping pattern, and illumination duration are all simultaneously optimized by formulating a joint optimization problem as a multi-objective mixed integer linear programming problem (MINLP). Simulation results are provided to corroborate our analysis, demonstrate the design tradeoffs, and point out the potentials of the proposed joint BH-CA concept. Advantages of our BH-CA scheme versus the conventional BH method without employing CA are investigated and presented under the same system circumstances.      
### 13.Optimization-Based Exploration of the Feasible Power Flow Space for Rapid Data Collection  [ :arrow_down: ](https://arxiv.org/pdf/2206.12214.pdf)
>  This paper provides a systematic investigation into the various nonlinear objective functions which can be used to explore the feasible space associated with the optimal power flow problem. A total of 40 nonlinear objective functions are tested, and their results are compared to the data generated by a novel exhaustive rejection sampling routine. The Hausdorff distance, which is a min-max set dissimilarity metric, is then used to assess how well each nonlinear objective function performed (i.e., how well the tested objective functions were able to explore the non-convex power flow space). Exhaustive test results were collected from five PGLib test-cases and systematically analyzed.      
### 14.Computational Complexity Evaluation of Neural Network Applications in Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.12191.pdf)
>  In this paper, we provide a systematic approach for assessing and comparing the computational complexity of neural network layers in digital signal processing. We provide and link four software-to-hardware complexity measures, defining how the different complexity metrics relate to the layers' hyper-parameters. This paper explains how to compute these four metrics for feed-forward and recurrent layers, and defines in which case we ought to use a particular metric depending on whether we characterize a more soft- or hardware-oriented application. One of the four metrics, called `the number of additions and bit shifts (NABS)', is newly introduced for heterogeneous quantization. NABS characterizes the impact of not only the bitwidth used in the operation but also the type of quantization used in the arithmetical operations. We intend this work to serve as a baseline for the different levels (purposes) of complexity estimation related to the neural networks' application in real-time digital signal processing, aiming at unifying the computational complexity estimation.      
### 15.Dynamic network congestion pricing based on deep reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.12188.pdf)
>  Traffic congestion is a serious problem in urban areas. Dynamic congestion pricing is one of the useful schemes to eliminate traffic congestion in strategic scale. However, in the reality, an optimal dynamic congestion pricing is very difficult or impossible to determine theoretically, because road networks are usually large and complicated, and behavior of road users is uncertain. To account for this challenge, this work proposes a dynamic congestion pricing method using deep reinforcement learning (DRL). It is designed to eliminate traffic congestion based on observable data in general large-scale road networks, by leveraging the data-driven nature of deep reinforcement learning. One of the novel elements of the proposed method is the distributed and cooperative learning scheme. Specifically, the DRL is implemented by a spatial-temporally distributed manner, and cooperation among DRL agents is established by novel techniques we call spatially shared reward and temporally switching learning. It enables fast and computationally efficient learning in large-scale networks. The numerical experiments using Sioux Falls Network showed that the proposed method works well thanks to the novel learning scheme.      
### 16.Rate-Distortion Optimal Transform Coefficient Selection for Unoccupied Regions in Video-Based Point Cloud Compression  [ :arrow_down: ](https://arxiv.org/pdf/2206.12186.pdf)
>  This paper presents a novel method to determine rate-distortion optimized transform coefficients for efficient compression of videos generated from point clouds. The method exploits a generalized frequency selective extrapolation approach that iteratively determines rate-distortion-optimized coefficients for all basis functions of two-dimensional discrete cosine and sine transforms. The method is applied to blocks containing both occupied and unoccupied pixels in video based point cloud compression for HEVC encoding. In the proposed algorithm, only the values of the transform coefficients are changed such that resulting bit streams are compliant to the V-PCC standard. For all-intra coded point clouds, bitrate savings of more than 4% for geometry and more than 6% for texture error metrics with respect to standard encoding can be observed. These savings are more than twice as high as savings obtained using competing methods from literature. In the randomaccess case, our proposed method outperforms competing V-PCC methods by more than 0.5%.      
### 17.Towards FPGA Implementation of Neural Network-Based Nonlinearity Mitigation Equalizers in Coherent Optical Transmission Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.12180.pdf)
>  For the first time, recurrent and feedforward neural network-based equalizers for nonlinearity compensation are implemented in an FPGA, with a level of complexity comparable to that of a dispersion equalizer. We demonstrate that the NN-based equalizers can outperform a 1 step-per-span DBP.      
### 18.Feature Representation Learning for Robust Retinal Disease Detection from Optical Coherence Tomography Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.12136.pdf)
>  Ophthalmic images may contain identical-looking pathologies that can cause failure in automated techniques to distinguish different retinal degenerative diseases. Additionally, reliance on large annotated datasets and lack of knowledge distillation can restrict ML-based clinical support systems' deployment in real-world environments. To improve the robustness and transferability of knowledge, an enhanced feature-learning module is required to extract meaningful spatial representations from the retinal subspace. Such a module, if used effectively, can detect unique disease traits and differentiate the severity of such retinal degenerative pathologies. In this work, we propose a robust disease detection architecture with three learning heads, i) A supervised encoder for retinal disease classification, ii) An unsupervised decoder for the reconstruction of disease-specific spatial information, and iii) A novel representation learning module for learning the similarity between encoder-decoder feature and enhancing the accuracy of the model. Our experimental results on two publicly available OCT datasets illustrate that the proposed model outperforms existing state-of-the-art models in terms of accuracy, interpretability, and robustness for out-of-distribution retinal disease detection.      
### 19.SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2206.12132.pdf)
>  In this paper, we present SANE-TTS, a stable and natural end-to-end multilingual TTS model. By the difficulty of obtaining multilingual corpus for given speaker, training multilingual TTS model with monolingual corpora is unavoidable. We introduce speaker regularization loss that improves speech naturalness during cross-lingual synthesis as well as domain adversarial training, which is applied in other multilingual TTS models. Furthermore, by adding speaker regularization loss, replacing speaker embedding with zero vector in duration predictor stabilizes cross-lingual inference. With this replacement, our model generates speeches with moderate rhythm regardless of source speaker in cross-lingual synthesis. In MOS evaluation, SANE-TTS achieves naturalness score above 3.80 both in cross-lingual and intralingual synthesis, where the ground truth score is 3.99. Also, SANE-TTS maintains speaker similarity close to that of ground truth even in cross-lingual inference. Audio samples are available on our web page.      
### 20.Implicit Channel Learning for Machine Learning Applications in 6G Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.12127.pdf)
>  With the deployment of the fifth generation (5G) wireless systems gathering momentum across the world, possible technologies for 6G are under active research discussions. In particular, the role of machine learning (ML) in 6G is expected to enhance and aid emerging applications such as virtual and augmented reality, vehicular autonomy, and computer vision. This will result in large segments of wireless data traffic comprising image, video and speech. The ML algorithms process these for classification/recognition/estimation through the learning models located on cloud servers. This requires wireless transmission of data from edge devices to the cloud server. Channel estimation, handled separately from recognition step, is critical for accurate learning performance. Toward combining the learning for both channel and the ML data, we introduce implicit channel learning to perform the ML tasks without estimating the wireless channel. Here, the ML models are trained with channel-corrupted datasets in place of nominal data. Without channel estimation, the proposed approach exhibits approximately 60% improvement in image and speech classification tasks for diverse scenarios such as millimeter wave and IEEE 802.11p vehicular channels.      
### 21.Dissecting U-net for Seismic Application: An In-Depth Study on Deep Learning Multiple Removal  [ :arrow_down: ](https://arxiv.org/pdf/2206.12112.pdf)
>  Seismic processing often requires suppressing multiples that appear when collecting data. To tackle these artifacts, practitioners usually rely on Radon transform-based algorithms as post-migration gather conditioning. However, such traditional approaches are both time-consuming and parameter-dependent, making them fairly complex. In this work, we present a deep learning-based alternative that provides competitive results, while reducing its usage's complexity, and hence democratizing its applicability. We observe an excellent performance of our network when inferring complex field data, despite the fact of being solely trained on synthetics. Furthermore, extensive experiments show that our proposal can preserve the inherent characteristics of the data, avoiding undesired over-smoothed results, while removing the multiples. Finally, we conduct an in-depth analysis of the model, where we pinpoint the effects of the main hyperparameters with physical events. To the best of our knowledge, this study pioneers the unboxing of neural networks for the demultiple process, helping the user to gain insights into the inside running of the network.      
### 22.Deep-Learning-Aided Distributed Clock Synchronization for Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.12097.pdf)
>  The proliferation of wireless communications networks over the past decades, combined with the scarcity of the wireless spectrum, have motivated a significant effort towards increasing the throughput of wireless networks. One of the major factors which limits the throughput in wireless communications networks is the accuracy of the time synchronization between the nodes in the network, as a higher throughput requires higher synchronization accuracy. Existing time synchronization schemes, and particularly, methods based on pulse-coupled oscillators (PCOs), which are the focus of the current work, have the advantage of simple implementation and achieve high accuracy when the nodes are closely located, yet tend to achieve poor synchronization performance for distant nodes. In this study, we propose a robust PCO-based time synchronization algorithm which retains the simple structure of existing approaches while operating reliably and converging quickly for both distant and closely located nodes. This is achieved by augmenting PCO-based synchronization with deep learning tools that are trainable in a distributed manner, thus allowing the nodes to train their neural network component of the synchronization algorithm without requiring additional exchange of information or central coordination. The numerical results show that our proposed deep learning-aided scheme is notably robust to propagation delays resulting from deployments over large areas, and to relative clock frequency offsets. It is also shown that the proposed approach rapidly attains full (i.e., clock frequency and phase) synchronization for all nodes in the wireless network, while the classic model-based implementation does not.      
### 23.Using Differential Geometry to Revisit the Paradoxes of the Instantaneous Frequen  [ :arrow_down: ](https://arxiv.org/pdf/2206.12091.pdf)
>  This paper proposes a general framework to interpret the concept of Instantaneous Frequency (IF) in three-phase systems. The paper first recalls the conventional frequency-domain analysis based on the Fourier transform as well as the definition of IF which is based on the concept of analytic signals. The link between analytic signals and Clarke transform of three-phase voltages of an ac power system is also shown. Then the well-known five paradoxes of the IF are stated. In the second part of the paper, an approach based on a geometric interpretation of the frequency is proposed. This approach serves to revisit the five IF paradoxes and explain them through a common framework. The case study illustrates the features of the proposed framework based on a variety of examples and on a detailed model of the IEEE 39-bus system.      
### 24.Dual Power Spectrum Manifold and Toeplitz HPD Manifold: Enhancement and Analysis for Matrix CFAR Detection  [ :arrow_down: ](https://arxiv.org/pdf/2206.12060.pdf)
>  Recently, an innovative matrix CFAR detection scheme based on information geometry, also referred to as the geometric detector, has been developed speedily and exhibits distinct advantages in several practical applications. These advantages benefit from the geometry of the Toeplitz Hermitian positive definite (HPD) manifold $\mathcal{M}_{\mathcal{T}H_{++}}$, but the sophisticated geometry also results in some challenges for geometric detectors, such as the implementation of the enhanced detector to improve the SCR (signal-to-clutter ratio) and the analysis of the detection performance. To meet these challenges, this paper develops the dual power spectrum manifold $\mathcal{M}_{\text{P}}$ as the dual space of $\mathcal{M}_{\mathcal{T}H_{++}}$. For each affine invariant geometric measure on $\mathcal{M}_{\mathcal{T}H_{++}}$, we show that there exists an equivalent function named induced potential function on $\mathcal{M}_{\text{P}}$. By the induced potential function, the measurements of the dissimilarity between two matrices can be implemented on $\mathcal{M}_{\text{P}}$, and the geometric detectors can be reformulated as the form related to the power spectrum. The induced potential function leads to two contributions: 1) The enhancement of the geometric detector, which is formulated as an optimization problem concerning $\mathcal{M}_{\mathcal{T}H_{++}}$, is transformed to an equivalent and simpler optimization on $\mathcal{M}_{\text{P}}$. In the presented example of the enhancement, the closed-form solution, instead of the gradient descent method, is provided through the equivalent optimization. 2) The detection performance is analyzed based on $\mathcal{M}_{\text{P}}$, and the advantageous characteristics, which benefit the detection performance, can be deduced by analyzing the corresponding power spectrum to the maximal point of the induced potential function.      
### 25.Data Augmentation and Squeeze-and-Excitation Network on Multiple Dimension for Sound Event Localization and Detection in Real Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2206.12059.pdf)
>  Performance of sound event localization and detection (SELD) in real scenes is limited by small size of SELD dataset, due to difficulty in obtaining sufficient amount of realistic multi-channel audio data recordings with accurate label. We used two main strategies to solve problems arising from the small real SELD dataset. First, we applied various data augmentation methods on all data dimensions: channel, frequency and time. We also propose original data augmentation method named Moderate Mixup in order to simulate situations where noise floor or interfering events exist. Second, we applied Squeeze-and-Excitation block on channel and frequency dimensions to efficiently extract feature characteristics. Result of our trained models on the STARSS22 test dataset achieved the best ER, F1, LE, and LR of 0.53, 49.8%, 16.0deg., and 56.2% respectively.      
### 26.Learning the policy for mixed electric platoon control of automated and human-driven vehicles at signalized intersection: a random search approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.12052.pdf)
>  The upgrading and updating of vehicles have accelerated in the past decades. Out of the need for environmental friendliness and intelligence, electric vehicles (EVs) and connected and automated vehicles (CAVs) have become new components of transportation systems. This paper develops a reinforcement learning framework to implement adaptive control for an electric platoon composed of CAVs and human-driven vehicles (HDVs) at a signalized intersection. Firstly, a Markov Decision Process (MDP) model is proposed to describe the decision process of the mixed platoon. Novel state representation and reward function are designed for the model to consider the behavior of the whole platoon. Secondly, in order to deal with the delayed reward, an Augmented Random Search (ARS) algorithm is proposed. The control policy learned by the agent can guide the longitudinal motion of the CAV, which serves as the leader of the platoon. Finally, a series of simulations are carried out in simulation suite SUMO. Compared with several state-of-the-art (SOTA) reinforcement learning approaches, the proposed method can obtain a higher reward. Meanwhile, the simulation results demonstrate the effectiveness of the delay reward, which is designed to outperform distributed reward mechanism} Compared with normal car-following behavior, the sensitivity analysis reveals that the energy can be saved to different extends (39.27%-82.51%) by adjusting the relative importance of the optimization goal. On the premise that travel delay is not sacrificed, the proposed control method can save up to 53.64% electric energy.      
### 27.Confidence Score Based Conformer Speaker Adaptation for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.12045.pdf)
>  A key challenge for automatic speech recognition (ASR) systems is to model the speaker level variability. In this paper, compact speaker dependent learning hidden unit contributions (LHUC) are used to facilitate both speaker adaptive training (SAT) and test time unsupervised speaker adaptation for state-of-the-art Conformer based end-to-end ASR systems. The sensitivity during adaptation to supervision error rate is reduced using confidence score based selection of the more "trustworthy" subset of speaker specific data. A confidence estimation module is used to smooth the over-confident Conformer decoder output probabilities before serving as confidence scores. The increased data sparsity due to speaker level data selection is addressed using Bayesian estimation of LHUC parameters. Experiments on the 300-hour Switchboard corpus suggest that the proposed LHUC-SAT Conformer with confidence score based test time unsupervised adaptation outperformed the baseline speaker independent and i-vector adapted Conformer systems by up to 1.0%, 1.0%, and 1.2% absolute (9.0%, 7.9%, and 8.9% relative) word error rate (WER) reductions on the NIST Hub5'00, RT02, and RT03 evaluation sets respectively. Consistent performance improvements were retained after external Transformer and LSTM language models were used for rescoring.      
### 28.End-to-End Text-to-Speech Based on Latent Representation of Speaking Styles Using Spontaneous Dialogue  [ :arrow_down: ](https://arxiv.org/pdf/2206.12040.pdf)
>  The recent text-to-speech (TTS) has achieved quality comparable to that of humans; however, its application in spoken dialogue has not been widely studied. This study aims to realize a TTS that closely resembles human dialogue. First, we record and transcribe actual spontaneous dialogues. Then, the proposed dialogue TTS is trained in two stages: first stage, variational autoencoder (VAE)-VITS or Gaussian mixture variational autoencoder (GMVAE)-VITS is trained, which introduces an utterance-level latent variable into variational inference with adversarial learning for end-to-end text-to-speech (VITS), a recently proposed end-to-end TTS model. A style encoder that extracts a latent speaking style representation from speech is trained jointly with TTS. In the second stage, a style predictor is trained to predict the speaking style to be synthesized from dialogue history. During inference, by passing the speaking style representation predicted by the style predictor to VAE/GMVAE-VITS, speech can be synthesized in a style appropriate to the context of the dialogue. Subjective evaluation results demonstrate that the proposed method outperforms the original VITS in terms of dialogue-level naturalness.      
### 29.Three Applications of Conformal Prediction for Rating Breast Density in Mammography  [ :arrow_down: ](https://arxiv.org/pdf/2206.12008.pdf)
>  Breast cancer is the most common cancers and early detection from mammography screening is crucial in improving patient outcomes. Assessing mammographic breast density is clinically important as the denser breasts have higher risk and are more likely to occlude tumors. Manual assessment by experts is both time-consuming and subject to inter-rater variability. As such, there has been increased interest in the development of deep learning methods for mammographic breast density assessment. Despite deep learning having demonstrated impressive performance in several prediction tasks for applications in mammography, clinical deployment of deep learning systems in still relatively rare; historically, mammography Computer-Aided Diagnoses (CAD) have over-promised and failed to deliver. This is in part due to the inability to intuitively quantify uncertainty of the algorithm for the clinician, which would greatly enhance usability. Conformal prediction is well suited to increase reliably and trust in deep learning tools but they lack realistic evaluations on medical datasets. In this paper, we present a detailed analysis of three possible applications of conformal prediction applied to medical imaging tasks: distribution shift characterization, prediction quality improvement, and subgroup fairness analysis. Our results show the potential of distribution-free uncertainty quantification techniques to enhance trust on AI algorithms and expedite their translation to usage.      
### 30.Path Integral Methods with Stochastic Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2206.11985.pdf)
>  Safe control designs for robotic systems remain challenging because of the difficulties of explicitly solving optimal control with nonlinear dynamics perturbed by stochastic noise. However, recent technological advances in computing devices enable online optimization or sampling-based methods to solve control problems. For example, Control Barrier Functions (CBFs), a Lyapunov-like control algorithm, have been proposed to numerically solve convex optimizations that determine control input to stay in the safe set. Model Predictive Path Integral (MPPI) uses forward sampling of stochastic differential equations to solve optimal control problems online. Both control algorithms are widely used for nonlinear systems because they avoid calculating the derivatives of the nonlinear dynamic function. In this paper, we utilize Stochastic Control Barrier Functions (SCBFs) constraints to limit sample regions in the sample-based algorithm, ensuring safety in a probabilistic sense and improving sample efficiency with a stochastic differential equation. We provide a sampling complexity analysis for the required sample size of our algorithm and show that our algorithm needs fewer samples than the original MPPI algorithm does. Finally, we apply our algorithm to a path planning problem in a cluttered environment and compare the performance of the algorithms.      
### 31.Frame-type Sensitive RDO Control for Content-Adaptive-encoding  [ :arrow_down: ](https://arxiv.org/pdf/2206.11976.pdf)
>  Video transcoding is an increasingly important application in the streaming media industry. It has become important to investigate the optimisation of transcoder parameters for a single clip simply because of the immense number of playbacks for popular clips. In this paper, we explore the use of a canned optimiser to estimate the optimal RD tradeoff achievable for a particular clip. We show that by adjusting the Lagrange multiplier in RD optimisation on keyframes alone we can achieve more than 10$\times$ the previous BD-Rate gains possible without affecting quality for any operating point.      
### 32.A physics-guided data-driven feedforward tracking controller for systems with unmodeled dynamics -- applied to 3D printing  [ :arrow_down: ](https://arxiv.org/pdf/2206.11960.pdf)
>  A hybrid (i.e., physics-guided data-driven) feedforward tracking controller is proposed for systems with unmodeled linear or nonlinear dynamics. The controller is based on the filtered basis function (FBF) approach, hence it is called a hybrid FBF controller. It formulates the feedforward control input to a system as a linear combination of a set of basis functions whose coefficients are selected to minimize tracking errors. The basis functions are filtered using a combination of two linear models to predict and minimize the tracking errors. The first model is physics-based and remains unaltered during the execution of the controller, while the second is data-driven and is continuously updated during the execution of the controller. To ensure its practicality and safe learning, the proposed hybrid FBF controller is equipped with the ability to handle delays in data acquisition and to detect impending instability due to its inherent data-driven feedback loop. Its effectiveness is demonstrated via application to vibration compensation of a 3D printer with unmodeled linear and nonlinear dynamics. Thanks to the proposed hybrid FBF controller, the tracking accuracy of the 3D printer is significantly improved in experiments involving high-speed printing, compared to a standard FBF controller that does not incorporate a data-driven model. Furthermore, the ability of the hybrid FBF controller to detect and, hence, potentially avoid impending instability is demonstrated offline using data collected online from experiments.      
### 33.TIAger: Tumor-Infiltrating Lymphocyte Scoring in Breast Cancer for the TiGER Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2206.11943.pdf)
>  The quantification of tumor-infiltrating lymphocytes (TILs) has been shown to be an independent predictor for prognosis of breast cancer patients. Typically, pathologists give an estimate of the proportion of the stromal region that contains TILs to obtain a TILs score. The Tumor InfiltratinG lymphocytes in breast cancER (TiGER) challenge, aims to assess the prognostic significance of computer-generated TILs scores for predicting survival as part of a Cox proportional hazards model. For this challenge, as the TIAger team, we have developed an algorithm to first segment tumor vs. stroma, before localising the tumor bulk region for TILs detection. Finally, we use these outputs to generate a TILs score for each case. On preliminary testing, our approach achieved a tumor-stroma weighted Dice score of 0.791 and a FROC score of 0.572 for lymphocytic detection. For predicting survival, our model achieved a C-index of 0.719. These results achieved first place across the preliminary testing leaderboards of the TiGER challenge.      
### 34.MPC-based Imitation Learning for Safe and Human-like Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2206.12348.pdf)
>  To ensure user acceptance of autonomous vehicles (AVs), control systems are being developed to mimic human drivers from demonstrations of desired driving behaviors. Imitation learning (IL) algorithms serve this purpose, but struggle to provide safety guarantees on the resulting closed-loop system trajectories. On the other hand, Model Predictive Control (MPC) can handle nonlinear systems with safety constraints, but realizing human-like driving with it requires extensive domain knowledge. This work suggests the use of a seamless combination of the two techniques to learn safe AV controllers from demonstrations of desired driving behaviors, by using MPC as a differentiable control layer within a hierarchical IL policy. With this strategy, IL is performed in closed-loop and end-to-end, through parameters in the MPC cost, model or constraints. Experimental results of this methodology are analyzed for the design of a lane keeping control system, learned via behavioral cloning from observations (BCO), given human demonstrations on a fixed-base driving simulator.      
### 35.How to hide your voice: Noise-cancelling bird photography blind  [ :arrow_down: ](https://arxiv.org/pdf/2206.12340.pdf)
>  Getting close to birds is a great challenge in wildlife photography. Bird photography blinds may be the most effective and least intrusive way. These essential structures can allow to visually and audibly conceal photographers from the habitat if properly designed. However, the acoustic design of the blinds has been overlooked. Herein, we present noise-cancelling blinds which allow photographing birds at close range. Firstly, we conduct a questionnaire in the eco-tourism centre located in Yunnan, China. Thus, we determine the birders' expectations of the indoor sound environment. We then identify four variables to examine the impact of architectural and acoustic decisions on noise propagation. The numerical simulations are performed in the acoustic module of Comsol MultiPhysics. Minimizing the structural size and planning the building with closed windows is a proper decision to reduce noise in the architectural design process. Sound-absorbing materials reduce the acoustic energy indoors, thus decreasing the outdoor noise. Sound-proofing materials help to cancel the acoustic transmission indoors to outdoors. Using sound-absorbing and proofing materials together is the best way to minimize noise both indoors and outdoors. Our study demonstrated that photography blinds require a strong and thorough acoustic design for both human and bird well-being.      
### 36.PoCaP Corpus: A Multimodal Dataset for Smart Operating Room Speech Assistant using Interventional Radiology Workflow Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.12320.pdf)
>  This paper presents a new multimodal interventional radiology dataset, called PoCaP (Port Catheter Placement) Corpus. This corpus consists of speech and audio signals in German, X-ray images, and system commands collected from 31 PoCaP interventions by six surgeons with average duration of 81.4 $\pm$ 41.0 minutes. The corpus aims to provide a resource for developing a smart speech assistant in operating rooms. In particular, it may be used to develop a speech controlled system that enables surgeons to control the operation parameters such as C-arm movements and table positions. In order to record the dataset, we acquired consent by the institutional review board and workers council in the University Hospital Erlangen and by the patients for data privacy. We describe the recording set-up, data structure, workflow and preprocessing steps, and report the first PoCaP Corpus speech recognition analysis results with 11.52 $\%$ word error rate using pretrained models. The findings suggest that the data has the potential to build a robust command recognition system and will allow the development of a novel intervention support systems using speech and image processing in the medical domain.      
### 37.Physically Consistent Learning of Conservative Lagrangian Systems with Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2206.12272.pdf)
>  This paper proposes a physically consistent Gaussian Process (GP) enabling the identification of uncertain Lagrangian systems. The function space is tailored according to the energy components of the Lagrangian and the differential equation structure, analytically guaranteeing physical and mathematical properties such as energy conservation and quadratic form. The novel formulation of Cholesky decomposed matrix kernels allow the probabilistic preservation of positive definiteness. Only differential input-to-output measurements of the function map are required while Gaussian noise is permitted in torques, velocities, and accelerations. We demonstrate the effectiveness of the approach in numerical simulation.      
### 38.Intersecting near-optimal spaces: European power systems with more resilience to weather variability  [ :arrow_down: ](https://arxiv.org/pdf/2206.12242.pdf)
>  We suggest a new methodology for designing robust energy systems. For this, we investigate so-called near-optimal solutions to energy system optimisation models; solutions whose objective values deviate only marginally from the optimum. Using a refined method for obtaining explicit geometric descriptions of these near-optimal feasible spaces, we find designs that are as robust as possible to perturbations. This contributes to the ongoing debate on how to define and work with robustness in energy systems modelling. We apply our methods in an investigation using multiple decades of weather data. For the first time, we run a capacity expansion model of the European power system (one node per country) with a three-hourly temporal resolution with 41 years of weather data. While an optimisation with 41 weather years is at the limits of computational feasibility, we use the near-optimal feasible spaces of single years to gain an understanding of the design space over the full time period. Specifically, we intersect all near-optimal feasible spaces for the individual years in order to get designs that are likely to be feasible over the entire time period. We find significant potential for flexibility, and verify the feasibility of these designs by simulating the resulting dispatch problem with four decades of weather data. They are characterised by a shift towards more onshore wind and solar power, while emitting up to 60\% less \ch{CO2} than a cost-optimal solution over that period. Our work builds on recent developments in the field, including techniques such as Modelling to Generate Alternatives and Modelling All Alternatives, and provides new insights into the geometry of near-optimal feasible spaces and the importance of multi-decade weather variability for energy systems design. We also provide an effective way of working with a multi-decade time frame in a highly parallelised manner.      
### 39.A Fundamental Limit of Distributed Hypothesis Testing Under Memoryless Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2206.12232.pdf)
>  We study a distributed hypothesis testing setup where peripheral nodes send quantized data to the fusion center in a memoryless fashion. The \emph{expected} number of bits sent by each node under the null hypothesis is kept limited. We characterize the optimal decay rate of the mis-detection (type-II error) probability provided that false alarms (type-I error) are rare, and study the tradeoff between the communication rate and maximal type-II error decay rate. We resort to rate-distortion methods to provide upper bounds to the tradeoff curve and show that at high rates lattice quantization achieves near-optimal performance. We also characterize the tradeoff for the case where nodes are allowed to record and quantize a fixed number of samples. Moreover, under sum-rate constraints, we show that an upper bound to the tradeoff curve is obtained with a water-filling solution.      
### 40.Deformable CNN and Imbalance-Aware Feature Learning for Singing Technique Classification  [ :arrow_down: ](https://arxiv.org/pdf/2206.12230.pdf)
>  Singing techniques are used for expressive vocal performances by employing temporal fluctuations of the timbre, the pitch, and other components of the voice. Their classification is a challenging task, because of mainly two factors: 1) the fluctuations in singing techniques have a wide variety and are affected by many factors and 2) existing datasets are imbalanced. To deal with these problems, we developed a novel audio feature learning method based on deformable convolution with decoupled training of the feature extractor and the classifier using a class-weighted loss function. The experimental results show the following: 1) the deformable convolution improves the classification results, particularly when it is applied to the last two convolutional layers, and 2) both re-training the classifier and weighting the cross-entropy loss function by a smoothed inverse frequency enhance the classification performance.      
### 41.Prosody Cloning in Zero-Shot Multispeaker Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2206.12229.pdf)
>  The cloning of a speaker's voice using an untranscribed reference sample is one of the great advances of modern neural text-to-speech (TTS) methods. Approaches for mimicking the prosody of a transcribed reference audio have also been proposed recently. In this work, we bring these two tasks together for the first time through utterance level normalization in conjunction with an utterance level speaker embedding. We further introduce a lightweight aligner for extracting fine-grained prosodic features, that can be finetuned on individual samples within seconds. We show that it is possible to clone the voice of a speaker as well as the prosody of a spoken reference independently without any degradation in quality and high similarity to both original voice and prosody, as our objective evaluation and human study show. All of our code and trained models are available, alongside static and interactive demos.      
### 42.Experimental graybox quantum control  [ :arrow_down: ](https://arxiv.org/pdf/2206.12201.pdf)
>  Understanding and controlling engineered quantum systems is key to developing practical quantum technology. However, given the current technological limitations, such as fabrication imperfections and environmental noise, this is not always possible. To address these issues, a great deal of theoretical and numerical methods for quantum system identification and control have been developed. These methods range from traditional curve fittings, which are limited by the accuracy of the model that describes the system, to machine learning methods, including neural networks, which provide efficient control solutions but do not provide control beyond the output of the model, nor insights into the underlying physical process. Here we experimentally demonstrate a "graybox" approach for characterizing and controlling quantum devices. We report superior performance over model fitting, while generating unitaries and Hamiltonians which are inaccessible with machine learning techniques. Our approach combines prior physics knowledge with high accuracy machine learning and is effective with any problem where the required controlled quantities are not directly accessible from the training set. This method naturally extends to time-dependent and open quantum systems, with applications in quantum noise spectroscopy and cancellation.      
### 43.On Data-Driven Log-Optimal Portfolio: A Sliding Window Approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.12148.pdf)
>  In this paper, we propose a data-driven sliding window approach to solve a log-optimal portfolio problem. In contrast to many of the existing papers, this approach leads to a trading strategy with time-varying portfolio weights rather than fixed constant weights. We show, by conducting various empirical studies, that the approach possesses a superior trading performance to the classical log-optimal portfolio in the sense of having a higher cumulative rate of returns.      
### 44.Signal Knowledge Graph  [ :arrow_down: ](https://arxiv.org/pdf/2206.12111.pdf)
>  This paper presents an knowledge graph to assist in reasoning over signals for intelligence purposes. We highlight limitations of existing knowledge graphs and reasoning systems for this purpose, using inference of an attack using combined data from microphones, cameras and social media as an example. Rather than acting directly on the received signal, our approach considers attacker behaviour, signal emission, receiver characteristics, and how signals are summarised to support inferring the underlying cause of the signal.      
### 45.Multi-modal Sensor Data Fusion for In-situ Classification of Animal Behavior Using Accelerometry and GNSS Data  [ :arrow_down: ](https://arxiv.org/pdf/2206.12078.pdf)
>  We examine using data from multiple sensing modes, i.e., accelerometry and global navigation satellite system (GNSS), for classifying animal behavior. We extract three new features from the GNSS data, namely, the distance from the water point, median speed, and median estimated horizontal position error. We consider two approaches for combining the information available from the accelerometry and GNSS data. The first approach is based on concatenating the features extracted from both sensor data and feeding the concatenated feature vector into a multi-layer perceptron (MLP) classifier. The second approach is based on fusing the posterior probabilities predicted by two MLP classifiers each taking the features extracted from the data of one sensor as input. We evaluate the performance of the developed multi-modal animal behavior classification algorithms using two real-world datasets collected via smart cattle collar and ear tags. The leave-one-animal-out cross-validation results show that both approaches improve the classification performance appreciably compared with using the data from only one sensing mode, in particular, for the infrequent but important behaviors of walking and drinking. The algorithms developed based on both approaches require rather small computational and memory resources hence are suitable for implementation on embedded systems of our collar and ear tags. However, the multi-modal animal behavior classification algorithm based on posterior probability fusion is preferable to the one based on feature concatenation as it delivers better classification accuracy, has less computational and memory complexity, is more robust to sensor data failure, and enjoys better modularity.      
### 46.Bilateral Network with Channel Splitting Network and Transformer for Thermal Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2206.12046.pdf)
>  In recent years, the Thermal Image Super-Resolution (TISR) problem has become an attractive research topic. TISR would been used in a wide range of fields, including military, medical, agricultural and animal ecology. Due to the success of PBVS-2020 and PBVS-2021 workshop challenge, the result of TISR keeps improving and attracts more researchers to sign up for PBVS-2022 challenge. In this paper, we will introduce the technical details of our submission to PBVS-2022 challenge designing a Bilateral Network with Channel Splitting Network and Transformer(BN-CSNT) to tackle the TISR problem. Firstly, we designed a context branch based on channel splitting network with transformer to obtain sufficient context information. Secondly, we designed a spatial branch with shallow transformer to extract low level features which can preserve the spatial information. Finally, for the context branch in order to fuse the features from channel splitting network and transformer, we proposed an attention refinement module, and then features from context branch and spatial branch are fused by proposed feature fusion module. The proposed method can achieve PSNR=33.64, SSIM=0.9263 for x4 and PSNR=21.08, SSIM=0.7803 for x2 in the PBVS-2022 challenge test dataset.      
### 47.BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping  [ :arrow_down: ](https://arxiv.org/pdf/2206.12038.pdf)
>  Methods for extracting audio and speech features have been studied since pioneering work on spectrum analysis decades ago. Recent efforts are guided by the ambition to develop general-purpose audio representations. For example, deep neural networks can extract optimal embeddings if they are trained on large audio datasets. This work extends existing methods based on self-supervised learning by bootstrapping, proposes various encoder architectures, and explores the effects of using different pre-training datasets. Lastly, we present a novel training framework to come up with a hybrid audio representation, which combines handcrafted and data-driven learned audio features. All the proposed representations were evaluated within the HEAR NeurIPS 2021 challenge for auditory scene classification and timestamp detection tasks. Our results indicate that the hybrid model with a convolutional transformer as the encoder yields superior performance in most HEAR challenge tasks.      
### 48.The Real Deal: A Review of Challenges and Opportunities in Moving Reinforcement Learning-Based Traffic Signal Control Systems Towards Reality  [ :arrow_down: ](https://arxiv.org/pdf/2206.11996.pdf)
>  Traffic signal control (TSC) is a high-stakes domain that is growing in importance as traffic volume grows globally. An increasing number of works are applying reinforcement learning (RL) to TSC; RL can draw on an abundance of traffic data to improve signalling efficiency. However, RL-based signal controllers have never been deployed. In this work, we provide the first review of challenges that must be addressed before RL can be deployed for TSC. We focus on four challenges involving (1) uncertainty in detection, (2) reliability of communications, (3) compliance and interpretability, and (4) heterogeneous road users. We show that the literature on RL-based TSC has made some progress towards addressing each challenge. However, more work should take a systems thinking approach that considers the impacts of other pipeline components on RL.      
### 49.Comparing supervised and self-supervised embedding for ExVo Multi-Task learning track  [ :arrow_down: ](https://arxiv.org/pdf/2206.11968.pdf)
>  The ICML Expressive Vocalizations (ExVo) Multi-task challenge 2022, focuses on understanding the emotional facets of the non-linguistic vocalizations (vocal bursts (VB)). The objective of this challenge is to predict emotional intensities for VB, being a multi-task challenge it also requires to predict speakers' age and native-country. For this challenge we study and compare two distinct embedding spaces namely, self-supervised learning (SSL) based embeddings and task-specific supervised learning based embeddings. Towards that, we investigate feature representations obtained from several pre-trained SSL neural networks and task-specific supervised classification neural networks. Our studies show that the best performance is obtained with a hybrid approach, where predictions derived via both SSL and task-specific supervised learning are used. Our best system on test-set surpasses the ComPARE baseline (harmonic mean of all sub-task scores i.e., $S_{MTL}$) by a relative $13\%$ margin.      
### 50.Risk-Constrained Nonconvex Dynamic Resource Allocation has Zero Duality Gap  [ :arrow_down: ](https://arxiv.org/pdf/2206.11948.pdf)
>  We show that risk-constrained dynamic resource allocation problems with general integrable nonconvex instantaneous service functions exhibit zero duality gap. We consider risk constraints which involve convex and positively homogeneous risk measures admitting dual representations with bounded risk envelopes, and are strictly more general than expectations. Beyond expectations, particular risk measures supported within our setting include the conditional value-at-risk, the mean-absolute deviation (including the non-monotone case), certain distributionally robust representations and more generally all real-valued coherent risk measures on the space ${\cal L}_{1}$. Our proof technique relies on risk duality in tandem with Uhl's weak extension of Lyapunov's convexity theorem for vector measures taking values in general Banach spaces.      
