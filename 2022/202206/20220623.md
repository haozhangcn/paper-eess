# ArXiv eess --Thu, 23 Jun 2022
### 1.Time-Limited Waveforms with Minimum Time Broadening for the Nonlinear SchrÃ¶dinger Channel  [ :arrow_down: ](https://arxiv.org/pdf/2206.11240.pdf)
>  Simple fiber optic communication systems can be implemented using energy modulation of isolated time-limited pulses. Fundamental solitons are one possible solution for such pulses which offer a fundamental advantage: their shape is not affected by fiber disperison and nonlinearity. Furthermore, a simple energy detector can be used at the receiver to detect the transmitted information. However, systems based on energy modulation of solitons are not competitive in terms of data rates. This is partly due to the fact that the effective time duration of a soliton depends on its chosen amplitude. In this paper, we propose to replace fundamental solitons by new time-limited waveforms that can be detected using an energy detector, and that are immune to fiber distortions. Our proposed solution relies on the prolate spheroidal wave functions and a numerical optimization routine. Time-limited waveforms that undergo minimum time broadening along an optical fiber are obtained and shown to outperform fundamental solitons. In the case of binary transmission and a single span of fiber, we report rate increases of 33.8% and 12% over lossy and lossless fibers, respectively. Furthermore, we show that the transmission rate of the proposed system increases as the number of used energy levels increases, which is not the case for fundamental solitons due to their effective time-amplitude constraint. For example, rate increases of 164% and 70% over lossy and lossless fibers respectively are reported when using four energy levels.      
### 2.Intensity-Sensitive Similarity Indexes for Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2206.11207.pdf)
>  The importance of Image quality assessment (IQA) is ever increasing due to the fast paced advances in imaging technology and computer vision. Among the numerous IQA methods, Structural SIMilarity (SSIM) index and its variants are better matched to the perceived quality of the human visual system. However, SSIM methods are insufficiently sensitive, when images contain low information, where the important information only occupies a low proportion of the image while most of the image is noise-like, which is common in scientific data. Therefore, we propose two new IQA methods, InTensity Weighted SSIM index and Low-Information Similarity Index, for such low information images. In addition, auxiliary indexes are proposed to assist with the assessment. The application of these new IQA methods to natural images and field-specific images, such as radio astronomical images, medical images, and remote sensing images, are also demonstrated. The results show that our IQA methods perform better than state-of-the-art SSIM methods for differences in high-intensity parts of the input images and have similar performance to that of the original and gradient-based SSIM for differences in low-intensity parts. Different similarity indexes are suitable for different applications, which we demonstrate in our results.      
### 3.Optimal Covariance Steering for Continuous-Time Linear Stochastic Systems With Additive Generic Noise  [ :arrow_down: ](https://arxiv.org/pdf/2206.11201.pdf)
>  In this paper we study the problem of how to optimally steer the state covariance of a continuous-time linear stochastic system over a finite time interval subject to additive "generic noise." Optimality here means reaching a target state covariance with minimal control energy. Generic noise includes a combination of white Gaussian noise and abrupt "jump noise" that is discontinuous in time. We first establish the controllability of the state covariance for linear time-varying stochastic systems under these assumptions. We then derive the optimal control to steer the covariance subject to generic noise. The optimal control entails solving two dynamically coupled ordinary matrix differential equations (ODEs) with split boundary conditions. We show the existence and uniqueness of the solution of these coupled matrix ODEs.      
### 4.On the Role of Spatial, Spectral, and Temporal Processing for DNN-based Non-linear Multi-channel Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2206.11181.pdf)
>  Employing deep neural networks (DNNs) to directly learn filters for multi-channel speech enhancement has potentially two key advantages over a traditional approach combining a linear spatial filter with an independent tempo-spectral post-filter: 1) non-linear spatial filtering allows to overcome potential restrictions originating from a linear processing model and 2) joint processing of spatial and tempo-spectral information allows to exploit interdependencies between different sources of information. A variety of DNN-based non-linear filters have been proposed recently, for which good enhancement performance is reported. However, little is known about the internal mechanisms which turns network architecture design into a game of chance. Therefore, in this paper, we perform experiments to better understand the internal processing of spatial, spectral and temporal information by DNN-based non-linear filters. On the one hand, our experiments in a difficult speech extraction scenario confirm the importance of non-linear spatial filtering, which outperforms an oracle linear spatial filter by 0.24 POLQA score. On the other hand, we demonstrate that joint processing results in a large performance gap of 0.4 POLQA score between network architectures exploiting spectral versus temporal information besides spatial information.      
### 5.Conformer with dual-mode chunked attention for joint online and offline ASR  [ :arrow_down: ](https://arxiv.org/pdf/2206.11157.pdf)
>  In this paper, we present an in-depth study on online attention mechanisms and distillation techniques for dual-mode (i.e., joint online and offline) ASR using the Conformer Transducer. In the dual-mode Conformer Transducer model, layers can function in online or offline mode while sharing parameters, and in-place knowledge distillation from offline to online mode is applied in training to improve online accuracy. In our study, we first demonstrate accuracy improvements from using chunked attention in the Conformer encoder compared to autoregressive attention with and without lookahead. Furthermore, we explore the efficient KLD and 1-best KLD losses with different shifts between online and offline outputs in the knowledge distillation. Finally, we show that a simplified dual-mode Conformer that only has mode-specific self-attention performs equally well as the one also having mode-specific convolutions and normalization. Our experiments are based on two very different datasets: the Librispeech task and an internal corpus of medical conversations. Results show that the proposed dual-mode system using chunked attention yields 5% and 4% relative WER improvement on the Librispeech and medical tasks, compared to the dual-mode system using autoregressive attention with similar average lookahead.      
### 6.CNN-based fully automatic wrist cartilage volume quantification in MR Image  [ :arrow_down: ](https://arxiv.org/pdf/2206.11127.pdf)
>  Detection of cartilage loss is crucial for the diagnosis of osteo- and rheumatoid arthritis. A large number of automatic segmentation tools have been reported so far for cartilage assessment in magnetic resonance images of large joints. As compared to knee or hip, wrist cartilage has a more complex structure so that automatic tools developed for large joints are not expected to be operational for wrist cartilage segmentation. In that respect, a fully automatic wrist cartilage segmentation method would be of high clinical interest. We assessed the performance of four optimized variants of the U-Net architecture with truncation of its depth and addition of attention layers (U-Net_AL). The corresponding results were compared to those from a patch-based convolutional neural network (CNN) we previously designed. The segmentation quality was assessed on the basis of a comparative analysis with manual segmentation using several morphological (2D DSC, 3D DSC, precision) and a volumetric metrics. The four networks outperformed the patch-based CNN in terms of segmentation homogeneity and quality. The median 3D DSC value computed with the U-Net_AL (0.817) was significantly larger than the corresponding DSC values computed with the other networks. In addition, the U-Net_AL CNN provided the lowest mean volume error (17%) and the highest Pearson correlation coefficient (0.765) with respect to the ground truth. Of interest, the reproducibility computed from using U-Net_AL was larger than the reproducibility of the manual segmentation. U-net convolutional neural network with additional attention layers provides the best wrist cartilage segmentation performance. In order to be used in clinical conditions, the trained network can be fine-tuned on a dataset representing a group of specific patients. The error of cartilage volume measurement should be assessed independently using a non-MRI method.      
### 7.Estimation of Electric Vehicle Public Charging Demand using Cellphone Data and Points of Interest-based Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.11065.pdf)
>  The race for road electrification has started, and convincing drivers to switch from fuel-powered vehicles to electric vehicles requires robust Electric Vehicle (EV) charging infrastructure. This article proposes an innovative EV charging demand estimation and segmentation method. First, we estimate the charging demand at a neighborhood granularity using cellular signaling data. Second, we propose a segmentation model to partition the total charging needs among different charging technology: normal, semi-rapid, and fast charging. The segmentation model, an approach based on the city's points of interest, is a state-of-the-art method that derives useful trends applicable to city planning. A case study for the city of Brussels is proposed.      
### 8.Automated GI tract segmentation using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.11048.pdf)
>  The job of Radiation oncologists is to deliver x-ray beams pointed toward the tumor and at the same time avoid the stomach and intestines. With MR-Linacs (magnetic resonance imaging and linear accelerator systems), oncologists can visualize the position of the tumor and allow for precise dose according to tumor cell presence which can vary from day to day. The current job of outlining the position of the stomach and intestines to adjust the X-ray beams direction for the dose delivery to the tumor while avoiding the organs. This is a time-consuming and labor-intensive process that can easily prolong treatments from 15 minutes to an hour a day unless deep learning methods can automate the segmentation process. This paper discusses an automated segmentation process using deep learning to make this process faster and allow more patients to get effective treatment.      
### 9.COVYT: Introducing the Coronavirus YouTube and TikTok speech dataset featuring the same speakers with and without infection  [ :arrow_down: ](https://arxiv.org/pdf/2206.11045.pdf)
>  More than two years after its outbreak, the COVID-19 pandemic continues to plague medical systems around the world, putting a strain on scarce resources, and claiming human lives. From the very beginning, various AI-based COVID-19 detection and monitoring tools have been pursued in an attempt to stem the tide of infections through timely diagnosis. In particular, computer audition has been suggested as a non-invasive, cost-efficient, and eco-friendly alternative for detecting COVID-19 infections through vocal sounds. However, like all AI methods, also computer audition is heavily dependent on the quantity and quality of available data, and large-scale COVID-19 sound datasets are difficult to acquire -- amongst other reasons -- due to the sensitive nature of such data. To that end, we introduce the COVYT dataset -- a novel COVID-19 dataset collected from public sources containing more than 8 hours of speech from 65 speakers. As compared to other existing COVID-19 sound datasets, the unique feature of the COVYT dataset is that it comprises both COVID-19 positive and negative samples from all 65 speakers. We analyse the acoustic manifestation of COVID-19 on the basis of these perfectly speaker characteristic balanced `in-the-wild' data using interpretable audio descriptors, and investigate several classification scenarios that shed light into proper partitioning strategies for a fair speech-based COVID-19 detection.      
### 10.Event-triggered and distributed model predictive control for guaranteed collision avoidance in UAV swarms  [ :arrow_down: ](https://arxiv.org/pdf/2206.11020.pdf)
>  Distributed model predictive control (DMPC) is often used to tackle path planning for unmanned aerial vehicle (UAV) swarms. However, it requires considerable computations on-board the UAV, leading to increased weight and power consumption. In this work, we propose to offload path planning computations to multiple ground-based computation units. As simultaneously communicating and recomputing all trajectories is not feasible for a large swarm with tight timing requirements, we develop a novel event-triggered DMPC that selects a subset of most relevant UAV trajectories to be replanned. The resulting architecture reduces UAV weight and power consumption, while the active redundancy provides robustness against computation unit failures. Moreover, the DMPC guarantees feasible and collision-free trajectories for UAVs with linear dynamics. In simulations, we demonstrate that our method can reliably plan trajectories, while saving 60% of network traffic and required computational power. Hardware-in-the-loop experiments show that it is suitable to control real quadcopter swarms.      
### 11.A Systematic Comparison of Phonetic Aware Techniques for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2206.11000.pdf)
>  Speech enhancement has seen great improvement in recent years using end-to-end neural networks. However, most models are agnostic to the spoken phonetic content. Recently, several studies suggested phonetic-aware speech enhancement, mostly using perceptual supervision. Yet, injecting phonetic features during model optimization can take additional forms (e.g., model conditioning). In this paper, we conduct a systematic comparison between different methods of incorporating phonetic information in a speech enhancement model. By conducting a series of controlled experiments, we observe the influence of different phonetic content models as well as various feature-injection techniques on enhancement performance, considering both causal and non-causal models. Specifically, we evaluate three settings for injecting phonetic information, namely: i) feature conditioning; ii) perceptual supervision; and iii) regularization. Phonetic features are obtained using an intermediate layer of either a supervised pre-trained Automatic Speech Recognition (ASR) model or by using a pre-trained Self-Supervised Learning (SSL) model. We further observe the effect of choosing different embedding layers on performance, considering both manual and learned configurations. Results suggest that using a SSL model as phonetic features outperforms the ASR one in most cases. Interestingly, the conditioning setting performs best among the evaluated configurations.      
### 12.Adversarial Reconfigurable Intelligent Surface Against Physical Layer Key Generation  [ :arrow_down: ](https://arxiv.org/pdf/2206.10955.pdf)
>  The development of reconfigurable intelligent surface (RIS) has recently advanced the research of physical layer security (PLS). Beneficial impact of RIS includes but is not limited to offering a new domain of freedom (DoF) for key-less PLS optimization, and increasing channel randomness for physical layer secret key generation (PL-SKG). However, there is a lack of research studying how adversarial RIS can be used to damage the communication confidentiality. In this work, we show how a Eve controlled adversarial RIS (Eve-RIS) can be used to reconstruct the shared PLS secret key between legitimate users (Alice and Bob). This is achieved by Eve-RIS overlaying the legitimate channel with an artificial random and reciprocal channel. The resulting Eve-RIS corrupted channel enable Eve to successfully attack the PL-SKG process. To operationalize this novel concept, we design Eve-RIS schemes against two PL-SKG techniques used: (i) the channel estimation based PL-SKG, and (ii) the two-way cross multiplication based PL-SKG. Our results show a high key match rate between the designed Eve-RIS and the legitimate users. We also present theoretical key match rate between Eve-RIS and legitimate users. Our novel scheme is different from the existing spoofing-Eve, in that the latter can be easily detected by comparing the channel estimation results of the legitimate users. Indeed, our proposed Eve-RIS can maintain the legitimate channel reciprocity, which makes detection challenging. This means the novel Eve-RIS provides a new eavesdropping threat on PL-SKG, which can spur new research areas to counter adversarial RIS attacks.      
### 13.AI-based software for lung nodule detection in chest X-rays -- Time for a second reader approach?  [ :arrow_down: ](https://arxiv.org/pdf/2206.10912.pdf)
>  Objectives: To compare artificial intelligence (AI) as a second reader in detecting lung nodules on chest X-rays (CXR) versus radiologists of two binational institutions, and to evaluate AI performance when using two different modes: automated versus assisted (additional remote radiologist review). <br>Methods: The CXR public database (n = 247) of the Japanese Society of Radiological Technology with various types and sizes of lung nodules was analyzed. Eight radiologists evaluated the CXR images with regard to the presence of lung nodules and nodule conspicuity. After radiologist review, the AI software processed and flagged the CXR with the highest probability of missed nodules. The calculated accuracy metrics were the area under the curve (AUC), sensitivity, specificity, F1 score, false negative case number (FN), and the effect of different AI modes (automated/assisted) on the accuracy of nodule detection. <br>Results: For radiologists, the average AUC value was 0.77 $\pm$ 0.07, while the average FN was 52.63 $\pm$ 17.53 (all studies) and 32 $\pm$ 11.59 (studies containing a nodule of malignant etiology = 32% rate of missed malignant nodules). Both AI modes -- automated and assisted -- produced an average increase in sensitivity (by 14% and 12%) and of F1-score (5% and 6%) and a decrease in specificity (by 10% and 3%, respectively). <br>Conclusions: Both AI modes flagged the pulmonary nodules missed by radiologists in a significant number of cases. AI as a second reader has a high potential to improve diagnostic accuracy and radiology workflow. AI might detect certain pulmonary nodules earlier than radiologists, with a potentially significant impact on patient outcomes.      
### 14.Influence of uncertainty estimation techniques on false-positive reduction in liver lesion detection  [ :arrow_down: ](https://arxiv.org/pdf/2206.10911.pdf)
>  Deep learning techniques show success in detecting objects in medical images, but still suffer from false-positive predictions that may hinder accurate diagnosis. The estimated uncertainty of the neural network output has been used to flag incorrect predictions. We study the role played by features computed from neural network uncertainty estimates and shape-based features computed from binary predictions in reducing false positives in liver lesion detection by developing a classification-based post-processing step for different uncertainty estimation methods. We demonstrate an improvement in the lesion detection performance of the neural network (with respect to F1-score) for all uncertainty estimation methods on two datasets, comprising abdominal MR and CT images respectively. We show that features computed from neural network uncertainty estimates tend not to contribute much toward reducing false positives. Our results show that factors like class imbalance (true over false positive ratio) and shape-based features extracted from uncertainty maps play an important role in distinguishing false positive from true positive predictions      
### 15.A Multimodal Perceived Stress Classification Framework using Wearable Physiological Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2206.10846.pdf)
>  Mental stress is a largely prevalent condition known to affect many people and could be a serious health concern. The quality of human life can be significantly improved if mental health is properly managed. Towards this, we propose a robust method for perceived stress classification, which is based on using multimodal data, acquired from forty subjects, including three (electroencephalography (EEG), galvanic skin response (GSR), and photoplethysmography (PPG)) physiological modalities. The data is acquired for three minutes duration in an open eyes condition. A perceived stress scale (PSS) questionnaire is used to record the stress of participants, which is then used to assign stress labels (two- and three classes). Time (four from GSR and PPG signals) and frequency (four from EEG signal) domain features are extracted. Among EEG based features, using a frequency band selection algorithm for selecting the optimum EEG frequency subband, the theta band was selected. Further, a wrapper-based method is used for optimal feature selection. Human stress level classification is performed using three different classifiers, which are fed with a fusion of the selected set of features from three modalities. A significant accuracy (95% for two classes, and 77.5% for three classes) was achieved using the multilayer perceptron classifier.      
### 16.Frequency Domain Identifiability and Sloppiness of Descriptor Systems with an LFT Structure  [ :arrow_down: ](https://arxiv.org/pdf/2206.10814.pdf)
>  Identifiability and sloppiness are investigated in this paper for the parameters of a descriptor system based on its frequency response samples. Two metrics are suggested respectively for measuring absolute and relative sloppiness of the parameter vector at a prescribed value. In this descriptor system, system matrices are assumed to depend on its parameters through a linear fractional transformation (LFT). When an associated transfer function matrix (TFM) is of full normal row rank, a matrix rank based necessary and sufficient condition is derived for parameter identifiability with a set of finitely many frequency responses. This condition can be verified recursively which is computationally quite appealing, especially when the system is of a large scale. From this condition, an algorithm is suggested to find a set of frequencies with which the frequency responses of the system are capable to uniquely determine its parameters. An ellipsoid approximation is given for the set consisting of all the parameter values with which the associated descriptor system has a frequency response that deviates within a prescribed distance, from that corresponding to a globally identifiable parameter vector value. Explicit formulas are also derived for the suggested absolute and relative sloppiness metrics.      
### 17.No Attention is Needed: Grouped Spatial-temporal Shift for Simple and Efficient Video Restorers  [ :arrow_down: ](https://arxiv.org/pdf/2206.10810.pdf)
>  Video restoration, aiming at restoring clear frames from degraded videos, has been attracting increasing attention. Video restoration is required to establish the temporal correspondences from multiple misaligned frames. To achieve that end, existing deep methods generally adopt complicated network architectures, such as integrating optical flow, deformable convolution, cross-frame or cross-pixel self-attention layers, resulting in expensive computational cost. We argue that with proper design, temporal information utilization in video restoration can be much more efficient and effective. In this study, we propose a simple, fast yet effective framework for video restoration. The key of our framework is the grouped spatial-temporal shift, which is simple and lightweight, but can implicitly establish inter-frame correspondences and achieve multi-frame aggregation. Coupled with basic 2D U-Nets for frame-wise encoding and decoding, such an efficient spatial-temporal shift module can effectively tackle the challenges in video restoration. Extensive experiments show that our framework surpasses previous state-of-the-art method with 43% of its computational cost on both video deblurring and video denoising.      
### 18.SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI  [ :arrow_down: ](https://arxiv.org/pdf/2206.10802.pdf)
>  Volumetric reconstruction of fetal brains from multiple stacks of MR slices, acquired in the presence of almost unpredictable and often severe subject motion, is a challenging task that is highly sensitive to the initialization of slice-to-volume transformations. We propose a novel slice-to-volume registration method using Transformers trained on synthetically transformed data, which model multiple stacks of MR slices as a sequence. With the attention mechanism, our model automatically detects the relevance between slices and predicts the transformation of one slice using information from other slices. We also estimate the underlying 3D volume to assist slice-to-volume registration and update the volume and transformations alternately to improve accuracy. Results on synthetic data show that our method achieves lower registration error and better reconstruction quality compared with existing state-of-the-art methods. Experiments with real-world MRI data are also performed to demonstrate the ability of the proposed model to improve the quality of 3D reconstruction under severe fetal motion.      
### 19.Chirp-Based Over-the-Air Computation for Long-Range Federated Edge Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.10784.pdf)
>  In this study, we propose circularly-shifted chirp (CSC)-based majority vote (MV) (CSC-MV), a power-efficient over-the-air computation (OAC) scheme, to achieve long-range federated edge learning (FEEL). The proposed approach maps the votes (i.e., the sign of the local gradients) from the edge devices (EDs) to the linear CSCs constructed with a discrete Fourier transform-spread orthogonal frequency division multiplexing (DFT-s-OFDM) transmitter. At the edge server (ES), the MV is calculated with an energy detector. We compare our proposed scheme with one-bit broadband digital aggregation (OBDA) and show that the output-power back-off (OBO) requirement of the transmitters with an adjacent-channel-leakage ratio (ACLR) constraint for CSC-MV is lower than the one with OBDA. For example, with an ACLR constraint of -22 dB, CSC-MV can have an OBO requirement of 6-7 dB less than the one with OBDA. When the power amplifier (PA) non-linearity is considered, we demonstrate that CSC-MV outperforms OBDA in terms of test accuracy for both homogeneous and heterogeneous data distributions, without using channel state information (CSI) at the ES and EDs.      
### 20.An Overview of Drone Energy Consumption Factors and Models  [ :arrow_down: ](https://arxiv.org/pdf/2206.10775.pdf)
>  Today, there are increasing demands for flying drones with diverse capabilities for civilian and military uses, and there is growing attention given to this topic. When it comes to drone operations, the amount of energy they consume is a determining factor in their ability to achieve their full potential. According to the nature of the problem, it appears that it is necessary to identify the factors affecting the energy consumption of UAVs during the execution of missions as well as examine the general factors that influence the consumption of energy. The purpose of this chapter is to provide an overview of the current state of research in the area of UAV energy consumption. This is followed by general categorizations of factors affecting UAV's energy consumption as well as an investigation of different energy models.      
### 21.Drone Delivery Systems and Energy Management: A Review and Future Trends  [ :arrow_down: ](https://arxiv.org/pdf/2206.10765.pdf)
>  Due to technology breakthroughs, mobility services are witnessing exceptional levels of innovation. These technology advancements in autonomous unmanned aerial vehicles (UAVs or drones), as well as developing regulations, may soon pave the path for their widespread use in delivery systems. The optimally of these growing delivery systems has been considered an essential aspect due to the necessity of energy-saving, CO2 emission, and ultimately environmental benefits in recent years. To accomplish the optimality of these systems, drones often employ a hybrid power supply system architecture to boost endurance and performance. Fuel cells, batteries, solar cells, and supercapacitors are examples of power sources that may be combined in a hybrid power architecture. To allow the effective functioning of modern drones, not only an appropriate energy management system must be chosen, but also accurate and optimal modeling should be provided. This chapter proposes a comprehensive review on drone energy supply management and strategies systems to identify gaps and provide insights and recommendations for future research.      
### 22.Pointing Error Modeling of mmWave to THz High-Directional Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2206.10756.pdf)
>  This paper focuses on providing an analytical framework for the quantification and evaluation of the pointing error at high-frequency millimeter wave (mmWave) and terahertz (THz) communication links. For this aim, we first characterize the channel of a point-to-point communication link between to unstable transmitter (Tx) and receiver (Rx) and then, we derive the probability density function (PDF) and cumulative distribution functions (CDF) of the pointing error in the presence of an unstable Tx and Rx as a function of the antennas' pattern. Specifically, for the standard array antenna, a closed-form expression is provided for PDF of the pointing error, which is a function of the number of antenna elements. Moreover, a more tractable approximate model is provided for the CDF and PDF of pointing error. In addition, using $\alpha-\mu$ distribution, which is a common model for small-scale fading of THz links, the end-to-end PDF of the considered channel is derived and used to calculate the outage probability of the considered system. Finally, by employing Monte-Carlo simulations, the accuracy of the analytical expressions is verified and the performance of the system is studied.      
### 23.Floor Map Reconstruction Through Radio Sensing and Learning By a Large Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2206.10750.pdf)
>  Environmental scene reconstruction is of great interest for autonomous robotic applications, since an accurate representation of the environment is necessary to ensure safe interaction with robots. Equally important, it is also vital to ensure reliable communication between the robot and its controller. Large Intelligent Surface (LIS) is a technology that has been extensively studied due to its communication capabilities. Moreover, due to the number of antenna elements, these surfaces arise as a powerful solution to radio sensing. This paper presents a novel method to translate radio environmental maps obtained at the LIS to floor plans of the indoor environment built of scatterers spread along its area. The usage of a Least Squares (LS) based method, U-Net (UN) and conditional Generative Adversarial Networks (cGANs) were leveraged to perform this task. We show that the floor plan can be correctly reconstructed using both local and global measurements.      
### 24.Asymmetric Learned Image Compression with Multi-Scale Residual Block, Importance Map, and Post-Quantization Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2206.10618.pdf)
>  Recently, deep learning-based image compression has made signifcant progresses, and has achieved better ratedistortion (R-D) performance than the latest traditional method, H.266/VVC, in both subjective metric and the more challenging objective metric. However, a major problem is that many leading learned schemes cannot maintain a good trade-off between performance and complexity. In this paper, we propose an effcient and effective image coding framework, which achieves similar R-D performance with lower complexity than the state of the art. First, we develop an improved multi-scale residual block (MSRB) that can expand the receptive feld and is easier to obtain global information. It can further capture and reduce the spatial correlation of the latent representations. Second, a more advanced importance map network is introduced to adaptively allocate bits to different regions of the image. Third, we apply a 2D post-quantization flter (PQF) to reduce the quantization error, motivated by the Sample Adaptive Offset (SAO) flter in video coding. Moreover, We fnd that the complexity of encoder and decoder have different effects on image compression performance. Based on this observation, we design an asymmetric paradigm, in which the encoder employs three stages of MSRBs to improve the learning capacity, whereas the decoder only needs one stage of MSRB to yield satisfactory reconstruction, thereby reducing the decoding complexity without sacrifcing performance. Experimental results show that compared to the state-of-the-art method, the encoding and decoding time of the proposed method are about 17 times faster, and the R-D performance is only reduced by less than 1% on both Kodak and Tecnick datasets, which is still better than H.266/VVC(4:4:4) and other recent learning-based methods. Our source code is publicly available at <a class="link-external link-https" href="https://github.com/fengyurenpingsheng" rel="external noopener nofollow">this https URL</a>.      
### 25.Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2206.11233.pdf)
>  Autism spectrum disorder (ASD) is a brain condition characterized by diverse signs and symptoms that appear in early childhood. ASD is also associated with communication deficits and repetitive behavior in affected individuals. Various ASD detection methods have been developed, including neuroimaging modalities and psychological tests. Among these methods, magnetic resonance imaging (MRI) imaging modalities are of paramount importance to physicians. Clinicians rely on MRI modalities to diagnose ASD accurately. The MRI modalities are non-invasive methods that include functional (fMRI) and structural (sMRI) neuroimaging methods. However, the process of diagnosing ASD with fMRI and sMRI for specialists is often laborious and time-consuming; therefore, several computer-aided design systems (CADS) based on artificial intelligence (AI) have been developed to assist the specialist physicians. Conventional machine learning (ML) and deep learning (DL) are the most popular schemes of AI used for diagnosing ASD. This study aims to review the automated detection of ASD using AI. We review several CADS that have been developed using ML techniques for the automated diagnosis of ASD using MRI modalities. There has been very limited work on the use of DL techniques to develop automated diagnostic models for ASD. A summary of the studies developed using DL is provided in the appendix. Then, the challenges encountered during the automated diagnosis of ASD using MRI and AI techniques are described in detail. Additionally, a graphical comparison of studies using ML and DL to diagnose ASD automatically is discussed. We conclude by suggesting future approaches to detecting ASDs using AI techniques and MRI neuroimaging.      
### 26.Deep reinforcement learning for fMRI prediction of Autism Spectrum Disorder  [ :arrow_down: ](https://arxiv.org/pdf/2206.11224.pdf)
>  Purpose : Because functional MRI (fMRI) data sets are in general small, we sought a data efficient approach to resting state fMRI classification of autism spectrum disorder (ASD) versus neurotypical (NT) controls. We hypothesized that a Deep Reinforcement Learning (DRL) classifier could learn effectively on a small fMRI training set. <br>Methods : We trained a Deep Reinforcement Learning (DRL) classifier on 100 graph-label pairs from the Autism Brain Imaging Data Exchange (ABIDE) database. For comparison, we trained a Supervised Deep Learning (SDL) classifier on the same training set. <br>Results : DRL significantly outperformed SDL, with a p-value of 2.4 x 10^(-7). DRL achieved superior results for a variety of classifier performance metrics, including an F1 score of 76, versus 67 for SDL. Whereas SDL quickly overfit the training data, DRL learned in a progressive manner that generalised to the separate testing set. <br>Conclusion : DRL can learn to classify ASD versus NT in a data efficient manner, doing so for a small training set. Future work will involve optimizing the neural network for data efficiency and applying the approach to other fMRI data sets, namely for brain cancer patients.      
### 27.Paint shop vehicle sequencing based on quantum computing considering color changeover and painting quality  [ :arrow_down: ](https://arxiv.org/pdf/2206.11204.pdf)
>  As customer demands become increasingly diverse, the colors and styles of vehicles offered by automotive companies have also grown substantially. It poses great challenges to design and management of automotive manufacturing system, among which is the proper sequencing of vehicles in everyday operation of the paint shop. With typically hundreds of vehicles in one shift, the paint shop sequencing problem is intractable in classical computing. In this paper, we propose to solve a general paint shop sequencing problem using state-of-the-art quantum computing algorithms. Most existing works are solely focused on reducing color changeover costs, i.e., costs incurred by different colors between consecutive vehicles. This work reveals that different sequencing of vehicles also significantly affects the quality performance of the painting process. We use a machine learning model pretrained on historical data to predict the probability of painting defect. The problem is formulated as a combinational optimization problem with two cost components, i.e., color changeover cost and repair cost. The problem is further converted to a quantum optimization problem and solved with Quantum Approximation Optimization Algorithm (QAOA). As a matter of fact, current quantum computers are still limited in accuracy and scalability. However, with a simplified case study, we demonstrate how the classic sequencing problem in paint shop can be formulated and solved using quantum computing and demonstrate the potential of quantum computing in solving real problems in manufacturing systems.      
### 28.Counterexample-guided computation of polyhedral Lyapunov functions for hybrid systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.11176.pdf)
>  This paper presents a counterexample-guided iterative algorithm to compute convex, piecewise linear (polyhedral) Lyapunov functions for uncertain continuous-time linear hybrid systems. Polyhedral Lyapunov functions provide an alternative to commonly used polynomial Lyapunov functions. Our approach first characterizes intrinsic properties of a polyhedral Lyapunov function including its "eccentricity" and "robustness" to perturbations. We then derive an algorithm that either computes a polyhedral Lyapunov function proving that the system is stable, or concludes that no polyhedral Lyapunov function exists whose eccentricity and robustness parameters satisfy some user-provided limits. Significantly, our approach places no a priori bounds on the number of linear pieces that make up the desired polyhedral Lyapunov function. <br>The algorithm alternates between a learning step and a verification step, always maintaining a finite set of witness states. The learning step solves a linear program to compute a candidate Lyapunov function compatible with a finite set of witness states. In the verification step, our approach verifies whether the candidate Lyapunov function is a valid Lyapunov function for the system. If verification fails, we obtain a new witness. We prove a theoretical bound on the maximum number of iterations needed by our algorithm. We demonstrate the applicability of the algorithm on numerical examples.      
### 29.On-the-fly control of unknown nonlinear systems with sublinear regret  [ :arrow_down: ](https://arxiv.org/pdf/2206.11103.pdf)
>  We study the problem of data-driven, constrained control of unknown nonlinear dynamics from a single ongoing and finite-horizon trajectory. We consider a one-step optimal control problem with a smooth, black-box objective, typically a composition of a known cost function and the unknown dynamics. We investigate an on-the-fly control paradigm, i.e., at each time step, the evolution of the dynamics and the first-order information of the cost are provided only for the executed control action. We propose an optimization-based control algorithm that iteratively minimizes a data-driven surrogate function for the unknown objective. We prove that the proposed approach incurs sublinear cumulative regret (step-wise suboptimality with respect to an optimal one-step controller) and is worst-case optimal among a broad class of data-driven control algorithms. We also present tractable reformulations of the approach that can leverage off-the-shelf solvers for efficient implementations.      
### 30.A High Resolution Multi-exposure Stereoscopic Image &amp; Video Database of Natural Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2206.11095.pdf)
>  Immersive displays such as VR headsets, AR glasses, Multiview displays, Free point televisions have emerged as a new class of display technologies in recent years, offering a better visual experience and viewer engagement as compared to conventional displays. With the evolution of 3D video and display technologies, the consumer market for High Dynamic Range (HDR) cameras and displays is quickly growing. The lack of appropriate experimental data is a critical hindrance for the development of primary research efforts in the field of 3D HDR video technology. Also, the unavailability of sufficient real world multi-exposure experimental dataset is a major bottleneck for HDR imaging research, thereby limiting the quality of experience (QoE) for the viewers. In this paper, we introduce a diversified stereoscopic multi-exposure dataset captured within the campus of Indian Institute of Technology Madras, which is home to a diverse flora and fauna. The dataset is captured using ZED stereoscopic camera and provides intricate scenes of outdoor locations such as gardens, roadside views, festival venues, buildings and indoor locations such as academic and residential areas. The proposed dataset accommodates wide depth range, complex depth structure, complicate object movement, illumination variations, rich color dynamics, texture discrepancy in addition to significant randomness introduced by moving camera and background motion. The proposed dataset is made publicly available to the research community. Furthermore, the procedure for capturing, aligning and calibrating multi-exposure stereo videos and images is described in detail. Finally, we have discussed the progress, challenges, potential use cases and future research opportunities with respect to HDR imaging, depth estimation, consistent tone mapping and 3D HDR coding.      
### 31.System Architecture and Communication Infrastructure for the RoboVaaS project  [ :arrow_down: ](https://arxiv.org/pdf/2206.11082.pdf)
>  Current advancements in waterborne autonomous systems, together with the development of cloud-based service-oriented architectures and the recent availability of low-cost underwater acoustic modems and long-range above water wireless devices, enabled the development of new applications to support ships and port activities. Unmanned Surface Vehicle (USV) can, for instance, be used to perform bathymetry and environmental data collection tasks to ensure under-keel clearance and to monitor the quality of the water. Similarly, Remotely Operated Vehicles (ROVs) can be deployed to inspect ship hulls and typical port infrastructure elements, such as quay and sheet pilling walls. In this paper we present the complete system deployed for the small-scale demonstrations of the Robotic Vessels as-a-Service (RoboVaaS) project, which introduces an on-demand service-based cloud system that dispatches Unmanned Vehicles (UVs) capable of performing the required service either autonomously or piloted. These vessels are able to interact with sensors deployed in the port and with the shore station through an integrated underwater and above water network. The developed system has been validated through sea trials and showcased through an underwater sensor data collection service. The results of the test presented in this paper provide a proof-of-concept of the system design and indicate its technical feasibility. It also shows the need for further developments for a mature technology allowing on-demand robotic maritime assistance services in real operational scenarios.      
### 32.Radio2Speech: High Quality Speech Recovery from Radio Frequency Signals  [ :arrow_down: ](https://arxiv.org/pdf/2206.11066.pdf)
>  Considering the microphone is easily affected by noise and soundproof materials, the radio frequency (RF) signal is a promising candidate to recover audio as it is immune to noise and can traverse many soundproof objects. In this paper, we introduce Radio2Speech, a system that uses RF signals to recover high quality speech from the loudspeaker. Radio2Speech can recover speech comparable to the quality of the microphone, advancing from recovering only single tone music or incomprehensible speech in existing approaches. We use Radio UNet to accurately recover speech in time-frequency domain from RF signals with limited frequency band. Also, we incorporate the neural vocoder to synthesize the speech waveform from the estimated time-frequency representation without using the contaminated phase. Quantitative and qualitative evaluations show that in quiet, noisy and soundproof scenarios, Radio2Speech achieves state-of-the-art performance and is on par with the microphone that works in quiet scenarios.      
### 33.Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2206.11053.pdf)
>  Visual question answering (VQA) in surgery is largely unexplored. Expert surgeons are scarce and are often overloaded with clinical and academic workloads. This overload often limits their time answering questionnaires from patients, medical students or junior residents related to surgical procedures. At times, students and junior residents also refrain from asking too many questions during classes to reduce disruption. While computer-aided simulators and recording of past surgical procedures have been made available for them to observe and improve their skills, they still hugely rely on medical experts to answer their questions. Having a Surgical-VQA system as a reliable 'second opinion' could act as a backup and ease the load on the medical experts in answering these questions. The lack of annotated medical data and the presence of domain-specific terms has limited the exploration of VQA for surgical procedures. In this work, we design a Surgical-VQA task that answers questionnaires on surgical procedures based on the surgical scene. Extending the MICCAI endoscopic vision challenge 2018 dataset and workflow recognition dataset further, we introduce two Surgical-VQA datasets with classification and sentence-based answers. To perform Surgical-VQA, we employ vision-text transformers models. We further introduce a residual MLP-based VisualBert encoder model that enforces interaction between visual and text tokens, improving performance in classification-based answering. Furthermore, we study the influence of the number of input image patches and temporal visual features on the model performance in both classification and sentence-based answering.      
### 34.Dynamic Restrained Uncertainty Weighting Loss for Multitask Learning of Vocal Expression  [ :arrow_down: ](https://arxiv.org/pdf/2206.11049.pdf)
>  We propose a novel Dynamic Restrained Uncertainty Weighting Loss to experimentally handle the problem of balancing the contributions of multiple tasks on the ICML ExVo 2022 Challenge. The multitask aims to recognize expressed emotions and demographic traits from vocal bursts jointly. Our strategy combines the advantages of Uncertainty Weight and Dynamic Weight Average, by extending weights with a restraint term to make the learning process more explainable. We use a lightweight multi-exit CNN architecture to implement our proposed loss approach. The experimental H-Mean score (0.394) shows a substantial improvement over the baseline H-Mean score (0.335).      
### 35.KeyCLD: Learning Constrained Lagrangian Dynamics in Keypoint Coordinates from Images  [ :arrow_down: ](https://arxiv.org/pdf/2206.11030.pdf)
>  We present KeyCLD, a framework to learn Lagrangian dynamics from images. Learned keypoints represent semantic landmarks in images and can directly represent state dynamics. Interpreting this state as Cartesian coordinates coupled with explicit holonomic constraints, allows expressing the dynamics with a constrained Lagrangian. Our method explicitly models kinetic and potential energy, thus allowing energy based control. We are the first to demonstrate learning of Lagrangian dynamics from images on the dm_control pendulum, cartpole and acrobot environments. This is a step forward towards learning Lagrangian dynamics from real-world images, since previous work in literature was only applied to minimalistic images with monochromatic shapes on empty backgrounds. Please refer to our project page for code and additional results: <a class="link-external link-https" href="https://rdaems.github.io/keycld/" rel="external noopener nofollow">this https URL</a>      
### 36.Closed-Form and Asymptotic BER Analysis of the Fluctuating Double-Rayleigh with Line-of-Sight Fading Channel  [ :arrow_down: ](https://arxiv.org/pdf/2206.10995.pdf)
>  Recently, a generalization of the double-Rayleigh with line-of-sight channel fading model taking into account shadowing of the line-of-sight component has been proposed. In this research, a closed-form analysis of the average bit error rate for MPSK/MQAM modulations is performed. The derived solution is accompanied by proposed numerically efficient approximation and all possible asymptotic expressions that correspond to extreme channel parameters. Lastly, a numerical simulation was performed that demonstrated the correctness of the derived results.      
### 37.Traffic Congestion Prediction Using Machine Learning Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2206.10983.pdf)
>  The prediction of traffic congestion can serve a crucial role in making future decisions. Although many studies have been conducted regarding congestion, most of these could not cover all the important factors (e.g., weather conditions). We proposed a prediction model for traffic congestion that can predict congestion based on day, time and several weather data (e.g., temperature, humidity). To evaluate our model, it has been tested against the traffic data of New Delhi. With this model, congestion of a road can be predicted one week ahead with an average RMSE of 1.12. Therefore, this model can be used to take preventive measure beforehand.      
### 38.Hierarchical Sampling based Particle Filter for Visual-inertial Gimbal in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2206.10981.pdf)
>  The gimbal platform has been widely used in photogrammetry and robot perceptual module to stabilize the camera pose, thereby improving the captured video quality. Usually a gimbal is mainly composed of sensors and actuator parts. The orientation measurements from sensor can be inputted directly to actuator to steer camera towards proper pose. But the off-the-shelf custom product is either quite expensive, or depending on highly precise IMU and Brushless DC motor with hall sensor to estimate angles, which is prone to suffer from accumulative drift over long-term operation. In this paper, a CV based new tracking and fusion algorithm dedicated for gimbal system on drones operating in nature is proposed, main contributions are listed as below: a) a light-weight Resnet -18 backbone based network model was trained from scratch, and deployed onto Jetson Nano platform to segment the image into binary parts (ground and sky). b) geometric primitives tracking of the skyline and ground plane in 3D as cues, along with orientation estimation from IMU can provide multiple guesses for orientation. c) spherical surface based adaptive particle sampling can fuse orientation from aforementioned sensor sources efficiently. The final prototyping algorithm is tested on the real-time embedded system, and with both simulation on ground and real functional tests in the air.      
### 39.Toward Multiple Integrated Sensing and Communication Base Station Systems: Collaborative Precoding Design with Power Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2206.10950.pdf)
>  The collaborative sensing of multiple Integrated sensing and communication (ISAC) base stations is one of the important technologies to achieve intelligent transportation. Interference elimination between ISAC base stations is the prerequisite for realizing collaborative sensing. In this paper, we focus on the mutual interference elimination problem in collaborative sensing of multiple ISAC base stations that can communicate and radar sense simultaneously by transmitting ISAC signals. We establish a mutual interference model of multiple ISAC base stations, which consists of communication and radar sensing related interference. Moreover, we propose a joint optimization algorithm (JOA) to solve the collaborative precoding problem with total power constraint (TPC) and perantenna power constraint (PPC). The optimal precoding design can be obtained by using JOA to set appropriate tradeoff coefficient between sensing and communication performance. The proposed collaborative precoding design algorithm is evaluated by considering sensing and communication performance via numerical results. The complexity of JOA for collaborative precoding under TPC and PPC is also compared and simulated in this paper.      
### 40.Exploration of User Privacy in 802.11 Probe Requests with MAC Address Randomization Using Temporal Pattern Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.10927.pdf)
>  Wireless networks have become an integral part of our daily lives and lately there is increased concern about privacy and protecting the identity of individual users. In this paper we address the evolution of privacy measures in Wi-Fi probe request frames. We focus on the lack of privacy measures before the implementation of MAC Address Randomization, and on the way anti-tracking measures evolved throughout the last decade. We do not try to reverse MAC address randomization to get the real ad-dress of the device, but instead analyse the possibility of further tracking/localization without needing the real MAC address of the specific users. To gain better analysis results, we introduce temporal pattern matching approach to identification of devices using randomized MAC addresses.      
### 41.Model-Driven Deep Learning-Based MIMO-OFDM Detector: Design, Simulation, and Experimental Results  [ :arrow_down: ](https://arxiv.org/pdf/2206.10909.pdf)
>  Multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM), a fundamental transmission scheme, promises high throughput and robustness against multipath fading. However, these benefits rely on the efficient detection strategy at the receiver and come at the expense of the extra bandwidth consumed by the cyclic prefix (CP). We use the iterative orthogonal approximate message passing (OAMP) algorithm in this paper as the prototype of the detector because of its remarkable potential for interference suppression. However, OAMP is computationally expensive for the matrix inversion per iteration. We replace the matrix inversion with the conjugate gradient (CG) method to reduce the complexity of OAMP. We further unfold the CG-based OAMP algorithm into a network and tune the critical parameters through deep learning (DL) to enhance detection performance. Simulation results and complexity analysis show that the proposed scheme has significant gain over other iterative detection methods and exhibits comparable performance to the state-of-the-art DL-based detector at a reduced computational cost. Furthermore, we design a highly efficient CP-free MIMO-OFDM receiver architecture to remove the CP overhead. This architecture first eliminates the intersymbol interference by buffering the previously recovered data and then detects the signal using the proposed detector. Numerical experiments demonstrate that the designed receiver offers a higher spectral efficiency than traditional receivers. Finally, over-the-air tests verify the effectiveness and robustness of the proposed scheme in realistic environments.      
### 42.UniCon+: ICTCAS-UCAS Submission to the AVA-ActiveSpeaker Task at ActivityNet Challenge 2022  [ :arrow_down: ](https://arxiv.org/pdf/2206.10861.pdf)
>  This report presents a brief description of our winning solution to the AVA Active Speaker Detection (ASD) task at ActivityNet Challenge 2022. Our underlying model UniCon+ continues to build on our previous work, the Unified Context Network (UniCon) and Extended UniCon which are designed for robust scene-level ASD. We augment the architecture with a simple GRU-based module that allows information of recurring identities to flow across scenes through read and update operations. We report a best result of 94.47% mAP on the AVA-ActiveSpeaker test set, which continues to rank first on this year's challenge leaderboard and significantly pushes the state-of-the-art.      
### 43.Play It Cool: Dynamic Shifting Prevents Thermal Throttling  [ :arrow_down: ](https://arxiv.org/pdf/2206.10849.pdf)
>  Machine learning (ML) has entered the mobile era where an enormous number of ML models are deployed on edge devices. However, running common ML models on edge devices continuously may generate excessive heat from the computation, forcing the device to "slow down" to prevent overheating, a phenomenon called thermal throttling. This paper studies the impact of thermal throttling on mobile phones: when it occurs, the CPU clock frequency is reduced, and the model inference latency may increase dramatically. This unpleasant inconsistent behavior has a substantial negative effect on user experience, but it has been overlooked for a long time. To counter thermal throttling, we propose to utilize dynamic networks with shared weights and dynamically shift between large and small ML models seamlessly according to their thermal profile, i.e., shifting to a small model when the system is about to throttle. With the proposed dynamic shifting, the application runs consistently without experiencing CPU clock frequency degradation and latency increase. In addition, we also study the resulting accuracy when dynamic shifting is deployed and show that our approach provides a reasonable trade-off between model latency and model accuracy.      
### 44.Learning Distribution Grid Topologies: A Tutorial  [ :arrow_down: ](https://arxiv.org/pdf/2206.10837.pdf)
>  Unveiling feeder topologies from data is of paramount importance to advance situational awareness and proper utilization of smart resources in power distribution grids. This tutorial summarizes, contrasts, and establishes useful links between recent works on topology identification and detection schemes that have been proposed for power distribution grids.% under different regimes of measurement type, observability, and sampling. The primary focus is to highlight methods that overcome the limited availability of measurement devices in distribution grids, while enhancing topology estimates using conservation laws of power-flow physics and structural properties of feeders. Grid data from phasor measurement units or smart meters can be collected either passively in the traditional way, or actively, upon actuating grid resources and measuring the feeder's voltage response. Analytical claims on feeder identifiability and detectability are reviewed under disparate meter placement scenarios. Such topology learning claims can be attained exactly or approximately so via algorithmic solutions with various levels of computational complexity, ranging from least-squares fits to convex optimization problems, and from polynomial-time searches over graphs to mixed-integer programs. This tutorial aspires to provide researchers and engineers with knowledge of the current state-of-the-art in tractable distribution grid learning and insights into future directions of work.      
### 45.On Local Linear Convergence of Projected Gradient Descent for Unit-Modulus Least Squares  [ :arrow_down: ](https://arxiv.org/pdf/2206.10832.pdf)
>  The unit-modulus least squares (UMLS) problem has a wide spectrum of applications in signal processing, e.g., phase-only beamforming, phase retrieval, radar code design, and sensor network localization. Scalable first-order methods such as projected gradient descent (PGD) have recently been studied as a simple yet efficient approach to solving the UMLS problem. Existing results on the convergence of PGD for UMLS often focus on global convergence to stationary points. As a non-convex problem, only sublinear convergence rate has been established. However, these results do not explain the fast convergence of PGD frequently observed in practice. This manuscript presents a novel analysis of convergence of PGD for UMLS, justifying the linear convergence behavior of the algorithm near the solution. By exploiting the local structure of the objective function and the constraint set, we establish an exact expression of the convergence rate and characterize the conditions for linear convergence. Simulations show that our theoretical analysis corroborates numerical examples. Furthermore, variants of PGD with adaptive step sizes are proposed based on the new insight revealed in our convergence analysis. The variants show substantial acceleration in practice.      
### 46.MultiEarth 2022 Deforestation Challenge -- ForestGump  [ :arrow_down: ](https://arxiv.org/pdf/2206.10831.pdf)
>  The estimation of deforestation in the Amazon Forest is challenge task because of the vast size of the area and the difficulty of direct human access. However, it is a crucial problem in that deforestation results in serious environmental problems such as global climate change, reduced biodiversity, etc. In order to effectively solve the problems, satellite imagery would be a good alternative to estimate the deforestation of the Amazon. With a combination of optical images and Synthetic aperture radar (SAR) images, observation of such a massive area regardless of weather conditions become possible. In this paper, we present an accurate deforestation estimation method with conventional UNet and comprehensive data processing. The diverse channels of Sentinel-1, Sentinel-2 and Landsat 8 are carefully selected and utilized to train deep neural networks. With the proposed method, deforestation status for novel queries are successfully estimated with high accuracy.      
### 47.Jointist: Joint Learning for Multi-instrument Transcription and Its Applications  [ :arrow_down: ](https://arxiv.org/pdf/2206.10805.pdf)
>  In this paper, we introduce Jointist, an instrument-aware multi-instrument framework that is capable of transcribing, recognizing, and separating multiple musical instruments from an audio clip. Jointist consists of the instrument recognition module that conditions the other modules: the transcription module that outputs instrument-specific piano rolls, and the source separation module that utilizes instrument information and transcription results. <br>The instrument conditioning is designed for an explicit multi-instrument functionality while the connection between the transcription and source separation modules is for better transcription performance. Our challenging problem formulation makes the model highly useful in the real world given that modern popular music typically consists of multiple instruments. However, its novelty necessitates a new perspective on how to evaluate such a model. During the experiment, we assess the model from various aspects, providing a new evaluation perspective for multi-instrument transcription. We also argue that transcription models can be utilized as a preprocessing module for other music analysis tasks. In the experiment on several downstream tasks, the symbolic representation provided by our transcription model turned out to be helpful to spectrograms in solving downbeat detection, chord recognition, and key estimation.      
### 48.Panoramic Panoptic Segmentation: Insights Into Surrounding Parsing for Mobile Agents via Unsupervised Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.10711.pdf)
>  In this work, we introduce panoramic panoptic segmentation, as the most holistic scene understanding, both in terms of Field of View (FoV) and image-level understanding for standard camera-based input. A complete surrounding understanding provides a maximum of information to a mobile agent, which is essential for any intelligent vehicle in order to make informed decisions in a safety-critical dynamic environment such as real-world traffic. In order to overcome the lack of annotated panoramic images, we propose a framework which allows model training on standard pinhole images and transfers the learned features to a different domain in a cost-minimizing way. Using our proposed method with dense contrastive learning, we manage to achieve significant improvements over a non-adapted approach. Depending on the efficient panoptic segmentation architecture, we can improve 3.5-6.5% measured in Panoptic Quality (PQ) over non-adapted models on our established Wild Panoramic Panoptic Segmentation (WildPPS) dataset. Furthermore, our efficient framework does not need access to the images of the target domain, making it a feasible domain generalization approach suitable for a limited hardware setting. As additional contributions, we publish WildPPS: The first panoramic panoptic image dataset to foster progress in surrounding perception and explore a novel training procedure combining supervised and contrastive training.      
### 49.Low-latency Imaging and Inference from LoRa-enabled CubeSats  [ :arrow_down: ](https://arxiv.org/pdf/2206.10703.pdf)
>  Recent years have seen the rapid deployment of low-cost CubeSats in low-Earth orbit, primarily for research, education, and Earth observation. The vast majority of these CubeSats experience significant latency (several hours) from the time an image is captured to the time it is available on the ground. This is primarily due to the limited availability of dedicated satellite ground stations that tend to be bulky to deploy and expensive to rent. This paper explores using LoRa radios in the ISM band for low-latency downlink communication from CubeSats, primarily due to the availability of extensive ground LoRa infrastructure and minimal interference to terrestrial communication. However, the limited bandwidth of LoRa precludes rich satellite Earth images to be sent - instead, the CubeSats can at best send short messages (a few hundred bytes). <br>This paper details our experience in communicating with a LoRa-enabled CubeSat launched by our team. We present Vista, a communication system that makes software modifications to LoRa encoding onboard a CubeSat and decoding on commercial LoRa ground stations to allow for satellite imagery to be communicated, as well as wide-ranging machine learning inference on these images. This is achieved through a LoRa-channel-aware image encoding that is informed by the structure of satellite images, the tasks performed on it, as well as the Doppler variation of satellite signals. A detailed evaluation of Vista through trace-driven emulation with traces from the LoRa-CubeSat launch (in 2021) shows 4.56 dB improvement in LoRa image PSNR and 1.38x improvement in land-use classification over those images.      
### 50.Exploring the Effectiveness of Self-supervised Learning and Classifier Chains in Emotion Recognition of Nonverbal Vocalizations  [ :arrow_down: ](https://arxiv.org/pdf/2206.10695.pdf)
>  We present an emotion recognition system for nonverbal vocalizations (NVs) submitted to the ExVo Few-Shot track of the ICML Expressive Vocalizations Competition 2022. The proposed method uses self-supervised learning (SSL) models to extract features from NVs and uses a classifier chain to model the label dependency between emotions. Experimental results demonstrate that the proposed method can significantly improve the performance of this task compared to several baseline methods. Our proposed method obtained a mean concordance correlation coefficient (CCC) of $0.725$ in the validation set and $0.739$ in the test set, while the best baseline method only obtained $0.554$ in the validation set. We publicate our code at <a class="link-external link-https" href="https://github.com/Aria-K-Alethia/ExVo" rel="external noopener nofollow">this https URL</a> to help others to reproduce our experimental results.      
### 51.A consistent and flexible framework for deep matrix factorizations  [ :arrow_down: ](https://arxiv.org/pdf/2206.10693.pdf)
>  Deep matrix factorizations (deep MFs) are recent unsupervised data mining techniques inspired by constrained low-rank approximations. They aim to extract complex hierarchies of features within high-dimensional datasets. Most of the loss functions proposed in the literature to evaluate the quality of deep MF models and the underlying optimization frameworks are not consistent because different losses are used at different layers. In this paper, we introduce two meaningful loss functions for deep MF and present a generic framework to solve the corresponding optimization problems. We illustrate the effectiveness of this approach through the integration of various constraints and regularizations, such as sparsity, nonnegativity and minimum-volume. The models are successfully applied on both synthetic and real data, namely for hyperspectral unmixing and extraction of facial features.      
### 52.ConTraNet: A single end-to-end hybrid network for EEG-based and EMG-based human machine interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2206.10677.pdf)
>  Objective: Electroencephalography (EEG) and electromyography (EMG) are two non-invasive bio-signals, which are widely used in human machine interface (HMI) technologies (EEG-HMI and EMG-HMI paradigm) for the rehabilitation of physically disabled people. Successful decoding of EEG and EMG signals into respective control command is a pivotal step in the rehabilitation process. Recently, several Convolutional neural networks (CNNs) based architectures are proposed that directly map the raw time-series signal into decision space and the process of meaningful features extraction and classification are performed simultaneously. However, these networks are tailored to the learn the expected characteristics of the given bio-signal and are limited to single paradigm. In this work, we addressed the question that can we build a single architecture which is able to learn distinct features from different HMI paradigms and still successfully classify them. Approach: In this work, we introduce a single hybrid model called ConTraNet, which is based on CNN and Transformer architectures that is equally useful for EEG-HMI and EMG-HMI paradigms. ConTraNet uses CNN block to introduce inductive bias in the model and learn local dependencies, whereas the Transformer block uses the self-attention mechanism to learn the long-range dependencies in the signal, which are crucial for the classification of EEG and EMG signals. Main results: We evaluated and compared the ConTraNet with state-of-the-art methods on three publicly available datasets which belong to EEG-HMI and EMG-HMI paradigms. ConTraNet outperformed its counterparts in all the different category tasks (2-class, 3-class, 4-class, and 10-class decoding tasks). Significance: The results suggest that ConTraNet is robust to learn distinct features from different HMI paradigms and generalizes well as compared to the current state of the art algorithms.      
### 53.Identifying Electrocardiogram Abnormalities Using a Handcrafted-Rule-Enhanced Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2206.10592.pdf)
>  A large number of people suffer from life-threatening cardiac abnormalities, and electrocardiogram (ECG) analysis is beneficial to determining whether an individual is at risk of such abnormalities. Automatic ECG classification methods, especially the deep learning based ones, have been proposed to detect cardiac abnormalities using ECG records, showing good potential to improve clinical diagnosis and help early prevention of cardiovascular diseases. However, the predictions of the known neural networks still do not satisfactorily meet the needs of clinicians, and this phenomenon suggests that some information used in clinical diagnosis may not be well captured and utilized by these methods. In this paper, we introduce some rules into convolutional neural networks, which help present clinical knowledge to deep learning based ECG analysis, in order to improve automated ECG diagnosis performance. Specifically, we propose a Handcrafted-Rule-enhanced Neural Network (called HRNN) for ECG classification with standard 12-lead ECG input, which consists of a rule inference module and a deep learning module. Experiments on two large-scale public ECG datasets show that our new approach considerably outperforms existing state-of-the-art methods. Further, our proposed approach not only can improve the diagnosis performance, but also can assist in detecting mislabelled ECG samples. Our codes are available at <a class="link-external link-https" href="https://github.com/alwaysbyx/ecg_processing" rel="external noopener nofollow">this https URL</a>.      
