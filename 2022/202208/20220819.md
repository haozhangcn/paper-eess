# ArXiv eess --Fri, 19 Aug 2022
### 1.Optimal Energy Management in Autonomous Power Systems with Probabilistic Security Constraints and Adaptive Frequency Control  [ :arrow_down: ](https://arxiv.org/pdf/2208.08953.pdf)
>  The decarbonization of many heavy power-consuming industries is dependent on the integration of renewable energy sources and energy storage systems in isolated autonomous power systems. The optimal energy management in such schemes becomes harder due to the increased complexity and stability requirements, the rapidly varying operating conditions and uncertainty of renewable sources, the conflicting objectives across different timescales, the limited amount of reliable power sources and energy storage. The state of charge management when energy storage is used for multiple services, such as optimal scheduling and frequency support, is one of the most notorious problems in this context. To address this issue, an optimal energy management system is proposed in this paper. It co-optimizes the primary frequency control layer and the dispatch schedule of conventional generators and energy storage by taking advantage of an algorithm that provides adaptive active power demand uncertainty quantification, theoretical guarantees for frequency stability, and bounds for the reserves for frequency support assigned to the energy storage system. A convex reformulation is derived enabling the efficient solution of the involved optimization problem, being a test case of an isolated offshore oil and gas platform presented for validation.      
### 2.Safe Perception-Based Control with Minimal Worst-Case Dynamic Regret  [ :arrow_down: ](https://arxiv.org/pdf/2208.08929.pdf)
>  We enable safe control of linear time-varying systems in the presence of unknown and unpredictable process and measurement noise. We introduce a control algorithm that minimizes dynamic regret, i.e., that minimizes the suboptimality against an optimal clairvoyant controller that knows the unpredictable future a priori. Specifically, our algorithm minimizes the worst-case dynamic regret among all possible noise realizations given a worst-case total noise magnitude. To this end, the control algorithm accounts for three key challenges: safety constraints; partially-observed time-varying systems; and unpredictable process and measurement noise. We are motivated by the future of autonomy where robots will autonomously perform complex tasks despite unknown and unpredictable disturbances leveraging their on-board control and perception capabilities. To synthesize our minimal-regret perception-based controller, we formulate a constrained semi-definite program based on a System Level Synthesis approach we enable for partially-observed time-varying systems. We validate our algorithm in simulated scenarios, including trajectory tracking scenarios of a hovering quadrotor collecting GPS and IMU measurements and of an omnidirectional robot collecting range measurements from landmarks. Our algorithm is observed to be superior to either or both the $\mathcal{H}_2$ and $\mathcal{H}_\infty$ controllers, demonstrating a Best of Both Worlds performance.      
### 3.Using Active Distribution Network Flexibility to Increase Transmission System Voltage Stability Margins  [ :arrow_down: ](https://arxiv.org/pdf/2208.08920.pdf)
>  The increasing penetration of Distributed Energy Resources (DER) in the distribution network creates new challenges in the operation of both the transmission and the distribution network. However, the controllability of the converter interfaced devices (CIG), also unveils opportunities for flexible operation and provision of ancillary services with or without economic incentives. The main scope of this work is to create a framework in order to calculate the operational flexibility of an Active Distribution Network and use it to address a centralized Optimal Power Flow Problem by the Transmission System Operator, and in particular the Voltage Stability Margin maximization. Two different approaches are proposed to calculate the Flexibility Region (FR) in the PQ plane, and the centralized optimization is applied to simple and more complex transmission test systems and feeder configurations.      
### 4.EEG-BBNet: a Hybrid Framework for Brain Biometric using Graph Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2208.08901.pdf)
>  Brain biometrics based on electroencephalography (EEG) have been used increasingly for personal identification. Traditional machine learning techniques as well as modern day deep learning methods have been applied with promising results. In this paper we present EEG-BBNet, a hybrid network which integrates convolutional neural networks (CNN) with graph convolutional neural networks (GCNN). The benefit of the CNN in automatic feature extraction and the capability of GCNN in learning connectivity between EEG electrodes through graph representation are jointly exploited. We examine various connectivity measures, namely the Euclidean distance, Pearson's correlation coefficient, phase-locked value, phase-lag index, and Rho index. The performance of the proposed method is assessed on a benchmark dataset consisting of various brain-computer interface (BCI) tasks and compared to other state-of-the-art approaches. We found that our models outperform all baselines in the event-related potential (ERP) task with an average correct recognition rates up to 99.26% using intra-session data. EEG-BBNet with Pearson's correlation and RHO index provide the best classification results. In addition, our model demonstrates greater adaptability using inter-session and inter-task data. We also investigate the practicality of our proposed model with smaller number of electrodes. Electrode placements over the frontal lobe region appears to be most appropriate with minimal lost in performance.      
### 5.EEG Machine Learning for Analysis of Mild Traumatic Brain Injury: A survey  [ :arrow_down: ](https://arxiv.org/pdf/2208.08894.pdf)
>  Mild Traumatic Brain Injury (mTBI) is a common brain injury and affects a diverse group of people: soldiers, constructors, athletes, drivers, children, elders, and nearly everyone. Thus, having a well-established, fast, cheap, and accurate classification method is crucial for the well-being of people around the globe. Luckily, using Machine Learning (ML) on electroencephalography (EEG) data shows promising results. This survey analyzed the most cutting-edge articles from 2017 to the present. The articles were searched from the Google Scholar database and went through an elimination process based on our criteria. We reviewed, summarized, and compared the fourteen most cutting-edge machine learning research papers for predicting and classifying mTBI in terms of 1) EEG data types, 2) data preprocessing methods, 3) machine learning feature representations, 4) feature extraction methods, and 5) machine learning classifiers and predictions. The most common EEG data type was human resting-state EEG, with most studies using filters to clean the data. The power spectral, especially alpha and theta power, was the most prevalent feature. The other non-power spectral features, such as entropy, also show their great potential. The Fourier transform is the most common feature extraction method while using neural networks as automatic feature extraction generally returns a high accuracy result. Lastly, Support Vector Machine (SVM) was our survey's most common ML classifier due to its lower computational complexity and solid mathematical theoretical basis. The purpose of this study was to collect and explore a sparsely populated sector of ML, and we hope that our survey has shined some light on the inherent trends, advantages, disadvantages, and preferences of the current state of machine learning-based EEG analysis for mTBI.      
### 6.An Alternative Derivation of the Gaussian Noise model  [ :arrow_down: ](https://arxiv.org/pdf/2208.08891.pdf)
>  By extending the results in Bononi 2012, we provide here a complete alternative derivation of Turin Gaussian Noise (GN) model for dual-polarization dispersion uncompensated coherent optical links. This paper contains the lecture notes used by the authors first on July 19, 2012, and then again on june 6, 2016 at the University of Parma.      
### 7.Energy-Exergy Analysis and Optimal Design of a Hydrogen Turbofan Engine  [ :arrow_down: ](https://arxiv.org/pdf/2208.08890.pdf)
>  In this study, the effect of inlet air cooling and fuel type on the performance parameters of thrust-specific fuel consumption (TSFC), thermal and exergetic efficiencies, entropy generation rate, and Nitrogen oxide emission intensity index (SNOx) of the GENX 1B70 engine is analyzed in two states of take-off and on design. The results show that with a 20-degree delicious reduction in inlet air temperature on design conditions and JP10 fuel usage, the thermal efficiency and entropy generation rate, thrust and fuel mass flow rate, and TSFC of the engine increase by 1.85 percent, 16.51 percent, 11.76 percent, 10.53 percent, and 2.15 percent and SNOx and exergetic efficiency decrease by 2.11 percent and 26.60 percent, respectively. Also, optimization of the GENX 1B70 engine cycle as hydrogen fuel usage with three separate objective functions: thrust maximization, thermal efficiency maximization, and propulsive efficiency maximization on design point condition was performed based on the Genetic algorithm. Based on the economic approach and exero-environmental, the best cycles from the optimal states were selected using the TOPSIS algorithm. In on design conditions, entropy generation rate, nitrogen oxide production rate, and TSFC for the chosen cycle based on the economic approach +18.89 percent, +10.01 percent, and -0.21percent, respectively, and based on the exero-environmental approach -54.03percent, -42.02percent, and +21.44percent change compared to the base engine, respectively.      
### 8.Visible light backscattering with applications to the Internet of Things: State-of-the-art, challenges, and opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2208.08889.pdf)
>  Visible light backscatter (VLB) is an innovative optical transmission paradigm to enable ultra low-power passive communication and localization for the Internet of Things (IoT), by overcoming some of the limitations of conventional (i.e., active) visible light communication (VLC) as well as active/passive radio-frequency (RF) technologies. In this paper, we provide a comprehensive survey of recent research activities in the VLB field. After describing the principles of operation and the main enabling technologies, we classify the existing VLB techniques according to several features, discussing their merits and limitations. Moreover, we introduce the potential applications of VLB techniques in several IoT domains. Finally, we present the main open challenges in this area and delineate a number of future research directions      
### 9.Data-driven End-to-end Learning of Pole Placement Control for Nonlinear Dynamics via Koopman Invariant Subspaces  [ :arrow_down: ](https://arxiv.org/pdf/2208.08883.pdf)
>  We propose a data-driven method for controlling the frequency and convergence rate of black-box nonlinear dynamical systems based on the Koopman operator theory. With the proposed method, a policy network is trained such that the eigenvalues of a Koopman operator of controlled dynamics are close to the target eigenvalues. The policy network consists of a neural network to find a Koopman invariant subspace, and a pole placement module to adjust the eigenvalues of the Koopman operator. Since the policy network is differentiable, we can train it in an end-to-end fashion using reinforcement learning. We demonstrate that the proposed method achieves better performance than model-free reinforcement learning and model-based control with system identification.      
### 10.On the Observability of Gaussian Models using Discrete Density Approximations  [ :arrow_down: ](https://arxiv.org/pdf/2208.08870.pdf)
>  This paper proposes a novel method for testing observability in Gaussian models using discrete density approximations (deterministic samples) of (multivariate) Gaussians. Our notion of observability is defined by the existence of the maximum a posteriori estimator. In the first step of the proposed algorithm, the discrete density approximations are used to generate a single representative design observation vector to test for observability. In the second step, a number of carefully chosen design observation vectors are used to obtain information on the properties of the estimator. By using measures like the variance and the so-called local variance, we do not only obtain a binary answer to the question of observability but also provide a quantitative measure.      
### 11.Evaluation of a multimode receiver with a photonic integrated combiner for satellite to ground optical communications  [ :arrow_down: ](https://arxiv.org/pdf/2208.08869.pdf)
>  Multimode receivers based on spatial or modal diversity are promising architectures to mitigate in real time the atmospheric turbulence effects for free space optical (FSO) communications. In this paper, we evaluate and comment on the dynamical communication performances of a FSO mode diversity receiver, based on a spatial demultiplexer and a silicon photonic coherent combiner, for an optical link from a GEO satellite to an optical ground station (OGS). We simulate time series of distorted wavefronts received by the OGS and we show numerically that the coherent combination of spatial modes mitigate the signal fading compared to a conventional single mode fiber (SMF) receiver. We verify this property in a laboratory environment by generating the wavefronts corresponding to the use case with an atmospheric propagation channel emulator. Then we modulate the optical carrier prior to the wavefront emulator with 10G OOK and DPSK data sequences to measure the BER performance of the proposed receiver during the time series emulation. Finally, we study and comment on the influence of the number of modes combined and the wavelength multiplexing on the BER performances. We prove that the mode diversity receiver provide a higher collection efficiency, has better BER performances and much less synchronization losses.      
### 12.Physics-Informed Neural Operator for Fast and Scalable Optical Fiber Channel Modelling in Multi-Span Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2208.08868.pdf)
>  We propose efficient modelling of optical fiber channel via NLSE-constrained physics-informed neural operator without reference solutions. This method can be easily scalable for distance, sequence length, launch power, and signal formats, and is implemented for ultra-fast simulations of 16-QAM signal transmission with ASE noise.      
### 13.A Unified Algorithmic Framework for Distributed Adaptive Signal and Feature Fusion Problems -- Part I: Algorithm Derivation  [ :arrow_down: ](https://arxiv.org/pdf/2208.08867.pdf)
>  In this paper, we describe a general algorithmic framework for solving linear signal or feature fusion optimization problems in a distributed setting, for example in a wireless sensor network (WSN). These problems require linearly combining the observed signals (or features thereof) collected at the various sensor nodes to satisfy a pre-defined optimization criterion. The framework covers several classical spatial filtering problems, including minimum variance beamformers, multi-channel Wiener filters, principal component analysis, canonical correlation analysis, (generalized) eigenvalue problems, etc. The proposed distributed adaptive signal fusion (DASF) algorithm is an iterative method which solves these types of problems by letting each node share a linearly compressed version of the local sensor signal observations with its neighbors to reduce the energy and bandwidth requirements of the network. We first discuss the case of fully-connected networks and then extend the analysis to more general network topologies. The general DASF algorithm is shown to have several existing distributed algorithms from the literature as a special case, while at the same time allowing to solve new distributed problems as well with guaranteed convergence and optimality. This paper focuses on the algorithm derivation of the DASF framework along with simulations demonstrating its performance. A technical analysis along with convergence conditions and proofs are provided in a companion paper.      
### 14.IoT based Smart Water Quality Prediction for Biofloc Aquaculture  [ :arrow_down: ](https://arxiv.org/pdf/2208.08866.pdf)
>  Traditional fish farming faces several challenges, including water pollution, temperature imbalance, feed, space, cost, etc. Biofloc technology in aquaculture transforms the manual into an advanced system that allows the reuse of unused feed by converting them into microbial protein. The objective of the research is to propose an IoT-based solution to aquaculture that increases efficiency and productivity. The article presented a system that collects data using sensors, analyzes them using a machine learning model, generates decisions with the help of Artificial Intelligence (AI), and sends notifications to the user. The proposed system has been implemented and tested to validate and achieve a satisfactory result.      
### 15.An intertwined neural network model for EEG classification in brain-computer interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2208.08860.pdf)
>  The brain computer interface (BCI) is a nonstimulatory direct and occasionally bidirectional communication link between the brain and a computer or an external device. Classically, EEG-based BCI algorithms have relied on models such as support vector machines and linear discriminant analysis or multiclass common spatial patterns. During the last decade, however, more sophisticated machine learning architectures, such as convolutional neural networks, recurrent neural networks, long short-term memory networks and gated recurrent unit networks, have been extensively used to enhance discriminability in multiclass BCI tasks. Additionally, preprocessing and denoising of EEG signals has always been key in the successful decoding of brain activity, and the determination of an optimal and standardized EEG preprocessing activity is an active area of research. In this paper, we present a deep neural network architecture specifically engineered to a) provide state-of-the-art performance in multiclass motor imagery classification and b) remain robust to preprocessing to enable real-time processing of raw data as it streams from EEG and BCI equipment. It is based on the intertwined use of time-distributed fully connected (tdFC) and space-distributed 1D temporal convolutional layers (sdConv) and explicitly addresses the possibility that interaction of spatial and temporal features of the EEG signal occurs at all levels of complexity. Numerical experiments demonstrate that our architecture provides superior performance compared baselines based on a combination of 3D convolutions and recurrent neural networks in a six-class motor imagery network, with a subjectwise accuracy that reaches 99%. Importantly, these results remain unchanged when minimal or extensive preprocessing is applied, possibly paving the way for a more transversal and real-time use of deep learning architectures in EEG classification.      
### 16.Psychophysiological Arousal in Young Children Who Stutter: An Interpretable AI Approach  [ :arrow_down: ](https://arxiv.org/pdf/2208.08859.pdf)
>  The presented first-of-its-kind study effectively identifies and visualizes the second-by-second pattern differences in the physiological arousal of preschool-age children who do stutter (CWS) and who do not stutter (CWNS) while speaking perceptually fluently in two challenging conditions i.e speaking in stressful situations and narration. The first condition may affect children's speech due to high arousal; the latter introduces linguistic, cognitive, and communicative demands on speakers. We collected physiological parameters data from 70 children in the two target conditions. First, we adopt a novel modality-wise multiple-instance-learning (MI-MIL) approach to classify CWS vs. CWNS in different conditions effectively. The evaluation of this classifier addresses four critical research questions that align with state-of-the-art speech science studies' interests. Later, we leverage SHAP classifier interpretations to visualize the salient, fine-grain, and temporal physiological parameters unique to CWS at the population/group-level and personalized-level. While group-level identification of distinct patterns would enhance our understanding of stuttering etiology and development, the personalized-level identification would enable remote, continuous, and real-time assessment of stuttering children's physiological arousal, which may lead to personalized, just-in-time interventions, resulting in an improvement in speech fluency. The presented MI-MIL approach is novel, generalizable to different domains, and real-time executable. Finally, comprehensive evaluations are done on multiple datasets, presented framework, and several baselines that identified notable insights on CWSs' physiological arousal during speech production.      
### 17.Estimating Sunlight Using GNSS Signal Strength from Smartphone  [ :arrow_down: ](https://arxiv.org/pdf/2208.08858.pdf)
>  Excessive or inadequate exposure to ultraviolet light (UV) is harmful to health and causes osteoporosis, colon cancer, and skin cancer. The UV Index, a standard scale of UV light, tends to increase in sunny places and sharply decrease in the shade. A method for distinguishing shady and sunny places would help us to prevent and cure diseases caused by UV. However, the existing methods, such as carrying UV sensors, impose a load on the user, whereas city-level UV forecasts do not have enough granularity for monitoring an individual's UV exposure. This paper proposes a method to detect sunny and shady places by using an off-the-shelf mobile device. The method detects these places by using a characteristic of the GNSS signal strength that is attenuated by objects around the device. As a dataset, we collected GNSS signal data, such as C/N0, satellite ID, satellite angle, and sun angle, together with reference data (i.e., sunny and shady place information every minute) for four days from five locations. Using the dataset, we created twelve classification models by using supervised machine learning methods and evaluated their performance by 4-fold cross-validation. In addition, we investigated the feature importance and the effect of combining features. The performance evaluation showed that our classification model could classify sunny and shady places with more than 97% accuracy in the best case. Moreover, our investigation revealed that the value of C/N0 at a moment and its time series (i.e., C/N0 value before and after the moment) are more important features.      
### 18.Study of General Robust Subband Adaptive Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2208.08856.pdf)
>  In this paper, we propose a general robust subband adaptive filtering (GR-SAF) scheme against impulsive noise by minimizing the mean square deviation under the random-walk model with individual weight uncertainty. Specifically, by choosing different scaling factors such as from the M-estimate and maximum correntropy robust criteria in the GR-SAF scheme, we can easily obtain different GR-SAF algorithms. Importantly, the proposed GR-SAF algorithm can be reduced to a variable regularization robust normalized SAF algorithm, thus having fast convergence rate and low steady-state error. Simulations in the contexts of system identification with impulsive noise and echo cancellation with double-talk have verified that the proposed GR-SAF algorithms outperforms its counterparts.      
### 19.Adaptive Partially-Observed Sequential Change Detection and Isolation  [ :arrow_down: ](https://arxiv.org/pdf/2208.08855.pdf)
>  High-dimensional data has become popular due to the easy accessibility of sensors in modern industrial applications. However, one specific challenge is that it is often not easy to obtain complete measurements due to limited sensing powers and resource constraints. Furthermore, distinct failure patterns may exist in the systems, and it is necessary to identify the true failure pattern. This work focuses on the online adaptive monitoring of high-dimensional data in resource-constrained environments with multiple potential failure modes. To achieve this, we propose to apply the Shiryaev-Roberts procedure on the failure mode level and utilize the multi-arm bandit to balance the exploration and exploitation. We further discuss the theoretical property of the proposed algorithm to show that the proposed method can correctly isolate the failure mode. Finally, extensive simulations and two case studies demonstrate that the change point detection performance and the failure mode isolation accuracy can be greatly improved.      
### 20.Automatic Detection of Noisy Electrocardiogram Signals without Explicit Noise Labels  [ :arrow_down: ](https://arxiv.org/pdf/2208.08853.pdf)
>  Electrocardiogram (ECG) signals are beneficial in diagnosing cardiovascular diseases, which are one of the leading causes of death. However, they are often contaminated by noise artifacts and affect the automatic and manual diagnosis process. Automatic deep learning-based examination of ECG signals can lead to inaccurate diagnosis, and manual analysis involves rejection of noisy ECG samples by clinicians, which might cost extra time. To address this limitation, we present a two-stage deep learning-based framework to automatically detect the noisy ECG samples. Through extensive experiments and analysis on two different datasets, we observe that the deep learning-based framework can detect slightly and highly noisy ECG samples effectively. We also study the transfer of the model learned on one dataset to another dataset and observe that the framework effectively detects noisy ECG samples.      
### 21.Outlier Detection using Self-Organizing Maps for Automated Blood Cell Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2208.08834.pdf)
>  The quality of datasets plays a crucial role in the successful training and deployment of deep learning models. Especially in the medical field, where system performance may impact the health of patients, clean datasets are a safety requirement for reliable predictions. Therefore, outlier detection is an essential process when building autonomous clinical decision systems. In this work, we assess the suitability of Self-Organizing Maps for outlier detection specifically on a medical dataset containing quantitative phase images of white blood cells. We detect and evaluate outliers based on quantization errors and distance maps. Our findings confirm the suitability of Self-Organizing Maps for unsupervised Out-Of-Distribution detection on the dataset at hand. Self-Organizing Maps perform on par with a manually specified filter based on expert domain knowledge. Additionally, they show promise as a tool in the exploration and cleaning of medical datasets. As a direction for future research, we suggest a combination of Self-Organizing Maps and feature extraction based on deep learning.      
### 22.Dynamic State Estimation-Based Protection for Induction Motor Loads  [ :arrow_down: ](https://arxiv.org/pdf/2208.08825.pdf)
>  Ensuring protective device coordination is critical to maintain the resilience and improve the reliability of large microgrids. Inverter-interfaced generation, however, poses significant challenges when designing protection systems. Traditional time-overcurrent protective devices are unsuitable on account of the lack of fault current. Present industry practice is to force all inverters to shut down during faults, which prevents large microgrids from operating in a resilient and reliable manner. Dynamic state estimation (DSE) has been proposed for line protection, and more recently for the protection of load buses or downstream radial portions of microgrids. However, only passive loads with series resistive-inductive loads have been tested with DSE, even though the behavior of dynamic loads -- such as induction motors or power electronics -- may differ significantly during faults. This paper considers the case of applying DSE to protecting a load bus serving a three-phase induction motor.      
### 23.Neuro-Adaptive Boundary Force Control of Dual One-Link Flexible Arms with Unmodeled Dynamics and Input Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2208.08804.pdf)
>  The primary purpose of this article is to accomplish safe grasping task by means of dual one-link flexible manipulators. In order to design a force-sensor-less force control, the direct force control problem is reduced to common motion control problem, in a way that by satisfying new control objectives the grasping task is established. Afterwards, for the first time in the field of dual one-link flexible manipulators, intelligent control methods are combined with robust control approaches in an effort to; i) accomplish motion control objectives, ii) handle uncertainties in the system, and iii) consider unknown, mixed input constraints, resulting in NABFC (Neuro-Adaptive Boundary Force Control). Moreover, to deal with unknown model uncertainties as well as unknown input saturation and dead zones, Radial Basic Function Neural-Networks (RBFNNs) are used. In the same way, adaptive control is utilized to estimate unknown parameters. By exploiting Lyapunov's direct method, proper Lyapunov functional and Energy multiplier method are defined to express well-known yet strong stability procedure, which compensates a complex stability procedure proposed in the previous works. In the presence of the designed controller, the presented stability procedure resulted in a uniform ultimate boundedness (UUB) stability for the system. Finally, for comparison aim between the designed controller with other controllers, numerical analysis is used to demonstrate both the excellent performance of the proposed controller and the correctness of the stability analysis outcomes.      
### 24.An Enhanced Gradient Based Optimized Controller for Load Frequency Control of a Two Area Automatic Generation Control System  [ :arrow_down: ](https://arxiv.org/pdf/2208.08787.pdf)
>  This work proposes the adoption of Enhanced Gradient-Based Optimizer (EGBO) as a new approach to the Load Frequency Control (LFC) problem in a two-area interconnected power system. The importance of determining the optimal parameters for the controllers for the LFC problem cannot be overstated, and the fact that estimating these parameters require complex and nonlinear computations makes the optimization procedure even more unique and challenging. Consequently, application of an efficient optimization algorithm to successfully attain optimal controller parameters is critical. To accomplish this task, the proposed EGBO algorithm is compared to the fundamental Gradient-Based Optimizer (GBO), Chimp Optimization Algorithm (ChOA), Sine Cosine Algorithm (SCA), Grey Wolf Optimization (GWO), and Particle Swarm Optimization (PSO) for optimizing an Integral-Time-multiplied-Absolute-Error (ITAE) based objective function. The relevant findings show that the EGBO algorithm is competitively superior in terms of resilience, precision, and latency when compared to other optimization methods. Lastly, the statistical comparison further strengthens the outcome of the study.      
### 25.Performance Analysis of RIS-Assisted Large-Scale Wireless Networks Using Stochastic Geometry  [ :arrow_down: ](https://arxiv.org/pdf/2208.08773.pdf)
>  In this paper, we investigate the performance of a reconfigurable intelligent surface (RIS) assisted large-scale network by characterizing the coverage probability and the average achievable rate using stochastic geometry. Considering the spatial correlation between transmitters (TXs) and RISs, their locations are jointly modelled by a Gauss-Poisson process (GPP). Two association strategies, i.e., nearest association and fixed association, are both discussed. For the RIS-aided transmission, the signal power distribution with a direct link is approximated by a gamma random variable using a moment matching method, and the Laplace transform of the aggregate interference power is derived in closed form. Based on these expressions, we analyze the channel hardening effect in the RIS-assisted transmission, the coverage probability, and the average achievable rate of the typical user. We derive the coverage probability expressions for the fixed association strategy and the nearest association strategy in an interference-limited scenario in closed form. Numerical results are provided to validate the analysis and illustrate the effectiveness of RIS-assisted transmission with passive beamforming in improving the system performance. Furthermore, it is also unveiled that the system performance is independent of the density of TXs with the nearest association strategy in the interference-limited scenario.      
### 26.Speech Representation Disentanglement with Adversarial Mutual Information Learning for One-shot Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2208.08757.pdf)
>  One-shot voice conversion (VC) with only a single target speaker's speech for reference has become a hot research topic. Existing works generally disentangle timbre, while information about pitch, rhythm and content is still mixed together. To perform one-shot VC effectively with further disentangling these speech components, we employ random resampling for pitch and content encoder and use the variational contrastive log-ratio upper bound of mutual information and gradient reversal layer based adversarial mutual information learning to ensure the different parts of the latent space containing only the desired disentangled representation during training. Experiments on the VCTK dataset show the model achieves state-of-the-art performance for one-shot VC in terms of naturalness and intellgibility. In addition, we can transfer characteristics of one-shot VC on timbre, pitch and rhythm separately by speech representation disentanglement. Our code, pre-trained models and demo are available at <a class="link-external link-https" href="https://im1eon.github.io/IS2022-SRDVC/" rel="external noopener nofollow">this https URL</a>.      
### 27.A Self-Replicating Single-Shape Tiling Technique for the Design of Highly Modular Planar Phased Arrays -- The Case of L-Shaped Rep-Tiles  [ :arrow_down: ](https://arxiv.org/pdf/2208.08727.pdf)
>  The design of irregular planar phased arrays (PAs) characterized by a highly-modular architecture is addressed. By exploiting the property of self-replicating tile shapes, also known as rep-tiles, the arising array layouts consist of tiles having different sizes, but equal shape, all being generated by assembling a finite number of smaller and congruent copies of a single elementary building-block. Towards this end, a deterministic optimization strategy is used so that the arising rep-tile arrangement of the planar PA is an optimal trade-off between complexity, costs, and fitting of user-defined requirements on the radiated power pattern, while guaranteeing the complete overlay of the array aperture. As a representative instance, such a synthesis method is applied to tile rectangular apertures with L-shaped tromino tiles. A set of representative results, concerned with ideal and real antenna models, as well, is reported for validation purposes, but also to point out the possibility/effectiveness of the proposed approach, unlike state-of-the-art tiling techniques, to reliably handle large-size array apertures.      
### 28.Efficient Signed Graph Sampling via Balancing &amp; Gershgorin Disc Perfect Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2208.08726.pdf)
>  A basic premise in graph signal processing (GSP) is that a graph encoding pairwise (anti-)correlations of the targeted signal as edge weights is exploited for graph filtering. However, existing fast graph sampling schemes are designed and tested only for positive graphs describing positive correlations. In this paper, we show that for datasets with strong inherent anti-correlations, a suitable graph contains both positive and negative edge weights. In response, we propose a linear-time signed graph sampling method centered on the concept of balanced signed graphs. Specifically, given an empirical covariance data matrix $\bar{\bf{C}}$, we first learn a sparse inverse matrix (graph Laplacian) $\mathcal{L}$ corresponding to a signed graph $\mathcal{G}$. We define the eigenvectors of Laplacian $\mathcal{L}_B$ for a balanced signed graph $\mathcal{G}_B$ -- approximating $\mathcal{G}$ via edge weight augmentation -- as graph frequency components. Next, we choose samples to minimize the low-pass filter reconstruction error in two steps. We first align all Gershgorin disc left-ends of Laplacian $\mathcal{L}_B$ at smallest eigenvalue $\lambda_{\min}(\mathcal{L}_B)$ via similarity transform $\mathcal{L}_p = §\mathcal{L}_B §^{-1}$, leveraging a recent linear algebra theorem called Gershgorin disc perfect alignment (GDPA). We then perform sampling on $\mathcal{L}_p$ using a previous fast Gershgorin disc alignment sampling (GDAS) scheme. Experimental results show that our signed graph sampling method outperformed existing fast sampling schemes noticeably on various datasets.      
### 29.Adaptive Pulse Compression for Sidelobes Reduction in Stretch Processing based MIMO Radars  [ :arrow_down: ](https://arxiv.org/pdf/2208.08705.pdf)
>  Multiple-Input Multiple-Output (MIMO) radars provide various advantages as compared to conventional radars. Among these advantages, improved angular diversity feature is being explored for future fully autonomous vehicles. Improved angular diversity requires use of orthogonal waveforms at transmit as well as receive sides. This orthogonality between waveforms is critical as the cross-correlation between signals can inhibit the detection of weaker targets due to sidelobes of stronger targets. This paper investigates the Reiterative Minimum Mean Squared Error (RMMSE) mismatch filter design for range sidelobes reduction for a Slow-Time Phase-Coded (ST-PC) Frequency Modulated Continuous Wave (FMCW) MIMO radar. Initially, the performance degradation of RMMSE filter is analyzed for improperly decoded received pulses. It is then shown mathematically that proper decoding of received pulses requires phase compensation related to any phase distortions caused due to doppler and spatial locations of targets. To cater for these phase distortions, it is proposed to re-adjust the traditional order of operations in radar signal processing to doppler, angle and range. Additionally, it is also proposed to incorporate sidelobes decoherence for further suppression of sidelobes. This is achieved by modification of the structured covariance matrix of baseline single-input RMMSE mismatch filter. The modified structured covariance matrix is proposed to include the range estimates corresponding to each transmitter. These proposed modifications provide additional sidelobes suppression while it also provides additional fidelity for target peaks. The proposed approach is demonstrated through simulations as well as field experiments. Superior performance in terms of range sidelobes suppression is observed when compared with baseline RMMSE and traditional Hanning windowed range response.      
### 30.RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG Respiratory Rate Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2208.08672.pdf)
>  Respiratory rate (RR) is an important biomarker as RR changes can reflect severe medical events such as heart disease, lung disease, and sleep disorders. Unfortunately, however, standard manual RR counting is prone to human error and cannot be performed continuously. This study proposes a method for continuously estimating RR, RRWaveNet. The method is a compact end-to-end deep learning model which does not require feature engineering and can use low-cost raw photoplethysmography (PPG) as input signal. RRWaveNet was tested subject-independently and compared to baseline in three datasets (BIDMC, CapnoBase, and WESAD) and using three window sizes (16, 32, and 64 seconds). RRWaveNet outperformed current state-of-the-art methods with mean absolute errors at optimal window size of 1.66 \pm 1.01, 1.59 \pm 1.08, and 1.92 \pm 0.96 breaths per minute for each dataset. In remote monitoring settings, such as in the WESAD dataset, we apply transfer learning to two other ICU datasets, reducing the MAE to 1.52 \pm 0.50 breaths per minute, showing this model allows accurate and practical estimation of RR on affordable and wearable devices. Our study shows feasibility of remote RR monitoring in the context of telemedicine and at home.      
### 31.Visual Pursuit Control based on Gaussian Processes with Switched Motion Trajectories  [ :arrow_down: ](https://arxiv.org/pdf/2208.08645.pdf)
>  This paper considers a scenario of pursuing a moving target that may switch behaviors due to external factors in a dynamic environment by motion estimation using visual sensors. First, we present an improved Visual Motion Observer with switched Gaussian Process models for an extended class of target motion profiles. We then propose a pursuit control law with an online method to estimate the switching behavior of the target by the GP model uncertainty. Next, we prove ultimate boundedness of the control and estimation errors for the switch in target behavior with high probability. Finally, a Digital Twin simulation demonstrates the effectiveness of the proposed switching estimation and control law to prove applicability to real world scenarios.      
### 32.Energy Minimization in RIS-Assisted UAV-Enabled Wireless Power Transfer Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.08639.pdf)
>  Unmanned aerial vehicle (UAV)-enabled wireless power transfer (WPT) systems offer significant advantages in coverage and deployment flexibility, but suffer from endurance limitations due to the limited onboard energy. This paper proposes to improve the energy efficiency of UAV-enabled WPT systems with multiple ground sensors by utilizing reconfigurable intelligent surface (RIS). Specifically, the total energy consumption of the UAV is minimized, while meeting the energy requirement of each sensor. Firstly, we consider a fly-hover-broadcast (FHB) protocol, in which the UAV radiates radio frequency (RF) signals only at several hovering locations. The energy minimization problem is formulated to jointly optimize the UAV's trajectory, hovering time and the RIS's reflection coefficients. To solve this complex non-convex problem, we propose an efficient algorithm. Specifically, the successive convex approximation (SCA) framework is adopted to jointly optimize the UAV's trajectory and hovering time, in which a minorization-maximization (MM) algorithm that maximizes the minimum charged energy of all sensors is provided to update the reflection coefficients. Then, we investigate the general scenario in which the RF signals are radiated during the flight, aiming to minimize the total energy consumption of the UAV by jointly optimizing the UAV's trajectory, flight time and the RIS's reflection coefficients. By applying the path discretization (PD) protocol, the optimization problem is formulated with a finite number of variables. A high-quality solution for this more challenging problem is obtained. Finally, our simulation results demonstrate the effectiveness of the proposed algorithm and the benefits of RIS in energy saving.      
### 33.Towards Practical Single-shot Phase Retrieval with Physics-Driven Deep Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2208.08604.pdf)
>  Phase retrieval (PR), a long-established challenge for recovering a complex-valued signal from its Fourier intensity-only measurements, has attracted considerable attention due to its widespread applications in digital imaging. Recently, deep learning-based approaches were developed that achieved some success in single-shot PR. These approaches require a single Fourier intensity measurement without the need to impose any additional constraints on the measured data. Nevertheless, vanilla deep neural networks (DNN) do not give good performance due to the substantial disparity between the input and output domains of the PR problems. Physics-informed approaches try to incorporate the Fourier intensity measurements into an iterative approach to increase the reconstruction accuracy. It, however, requires a lengthy computation process, and the accuracy still cannot be guaranteed. Besides, many of these approaches work on simulation data that ignore some common problems such as saturation and quantization errors in practical optical PR systems. In this paper, a novel physics-driven multi-scale DNN structure dubbed PPRNet is proposed. Similar to other deep learning-based PR methods, PPRNet requires only a single Fourier intensity measurement. It is physics-driven that the network is guided to follow the Fourier intensity measurement at different scales to enhance the reconstruction accuracy. PPRNet has a feedforward structure and can be end-to-end trained. Thus, it is much faster and more accurate than the traditional physics-driven PR approaches. Extensive simulations and experiments on a practical optical platform were conducted. The results demonstrate the superiority and practicality of the proposed PPRNet over the traditional learning-based PR methods.      
### 34.Quickest Detection for Human-Sensor Systems using Quantum Decision Theory  [ :arrow_down: ](https://arxiv.org/pdf/2208.08583.pdf)
>  In mathematical psychology, recent models for human decision-making use Quantum Decision Theory to capture important human-centric features such as order effects and violation of the sure-thing principle (total probability law). We construct and analyze a human-sensor system where a quickest detector aims to detect a change in an underlying state by observing human decisions that are influenced by the state. <br>Apart from providing an analytical framework for such human-sensor systems, we also analyze the structure of the quickest detection policy. We show that the quickest detection policy has a single threshold and the optimal cost incurred is lower bounded by that of the classical quickest detector. This indicates that intermediate human decisions strictly hinder detection performance. We also analyze the sensitivity of the quickest detection cost with respect to the quantum decision parameters of the human decision maker, revealing that the performance is robust to inaccurate knowledge of the decision-making process. Numerical results are provided which suggest that observing the decisions of more rational decision makers will improve the quickest detection performance. Finally, we illustrate a numerical implementation of this quickest detector in the context of the Prisoner's Dilemma problem, in which it has been observed that Quantum Decision Theory can uniquely model empirically tested violations of the sure-thing principle.      
### 35.Precoding for High Throughput Satellite Communication Systems: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2208.08542.pdf)
>  With the expanding demand for high data rates and extensive coverage, high throughput satellite (HTS) communication systems are emerging as a key technology for future communication generations. However, current frequency bands are increasingly congested. Until the maturity of communication systems to operate on higher bands, the solution is to exploit the already existing frequency bands more efficiently. In this context, precoding emerges as one of the prolific approaches to increasing spectral efficiency. This survey presents an overview and a classification of the recent precoding techniques for HTS communication systems from two main perspectives: 1) a problem formulation perspective and 2) a system design perspective. From a problem formulation point of view, precoding techniques are classified according to the precoding objective, group, and level. From a system design standpoint, precoding is categorized based on the system architecture, the precoding implementation, and the type of the provided service. Further, practical system impairments are discussed, and robust precoding techniques are presented. Finally, future trends in precoding for satellites are addressed to spur further research.      
### 36.To charge in-flight or not: an inquiry into parallel-hybrid electric aircraft configurations via optimal control  [ :arrow_down: ](https://arxiv.org/pdf/2208.08969.pdf)
>  We examine two configurations for parallel hybrid electric aircraft, one with, and one without, a mechanical connection between the engines and the electric motors. For this two designs, we then review the power allocation problem in the context of aircraft energy management for a 19-seat conceptual Hybrid Electric Aircraft. We then represent the original optimal control problem as a finite-dimensional optimization and validate the second-order sufficient conditions for global optimality of the obtained solution. This is then followed by a sensitivity analysis of the fuel consumption on the initial aircraft weight and flight endurance. Our simulation and theoretical results clarify the limited benefit of charging the battery in-flight for this class of hybrid electric aircraft to reduce $CO_2$ emissions.      
### 37.Deploying Enhanced Speech Feature Decreased Audio Complaints at SVT Play VOD Service  [ :arrow_down: ](https://arxiv.org/pdf/2208.08960.pdf)
>  At Public Service Broadcaster SVT in Sweden, background music and sounds in programs have for many years been one of the most common complaints from the viewers. The most sensitive group are people with hearing disabilities, but many others also find background sounds annoying. To address this problem SVT has added Enhanced Speech, a feature with lower background noise, to a number of TV programs in VOD service SVT Play. As a result, when the number of programs with the Enhanced Speech feature increased, the level of audio complaints to customer service decreased. The Enhanced Speech feature got the rating 8.3/10 in a survey with 86 participants. The rating for possible future usage was 9.0/10. In this article we describe this feature's design and development process, as well as its technical specification, limitations and future development opportunities.      
### 38.Transformer Networks for Predictive Group Elevator Control  [ :arrow_down: ](https://arxiv.org/pdf/2208.08948.pdf)
>  We propose a Predictive Group Elevator Scheduler by using predictive information of passengers arrivals from a Transformer based destination predictor and a linear regression model that predicts remaining time to destinations. Through extensive empirical evaluation, we find that the savings of Average Waiting Time (AWT) could be as high as above 50% for light arrival streams and around 15% for medium arrival streams in afternoon down-peak traffic regimes. Such results can be obtained after carefully setting the Predicted Probability of Going to Elevator (PPGE) threshold, thus avoiding a majority of false predictions for people heading to the elevator, while achieving as high as 80% of true predictive elevator landings as early as after having seen only 60% of the whole trajectory of a passenger.      
### 39.Autism spectrum disorder classification based on interpersonal neural synchrony: Can classification be improved by dyadic neural biomarkers using unsupervised graph representation learning?  [ :arrow_down: ](https://arxiv.org/pdf/2208.08902.pdf)
>  Research in machine learning for autism spectrum disorder (ASD) classification bears the promise to improve clinical diagnoses. However, recent studies in clinical imaging have shown the limited generalization of biomarkers across and beyond benchmark datasets. Despite increasing model complexity and sample size in neuroimaging, the classification performance of ASD remains far away from clinical application. This raises the question of how we can overcome these barriers to develop early biomarkers for ASD. One approach might be to rethink how we operationalize the theoretical basis of this disease in machine learning models. Here we introduced unsupervised graph representations that explicitly map the neural mechanisms of a core aspect of ASD, deficits in dyadic social interaction, as assessed by dual brain recordings, termed hyperscanning, and evaluated their predictive performance. The proposed method differs from existing approaches in that it is more suitable to capture social interaction deficits on a neural level and is applicable to young children and infants. First results from functional-near infrared spectroscopy data indicate potential predictive capacities of a task-agnostic, interpretable graph representation. This first effort to leverage interaction-related deficits on neural level to classify ASD may stimulate new approaches and methods to enhance existing models to achieve developmental ASD biomarkers in the future.      
### 40.Adversarial Learning Based Structural Brain-network Generative Model for Analyzing Mild Cognitive Impairment  [ :arrow_down: ](https://arxiv.org/pdf/2208.08896.pdf)
>  Mild cognitive impairment(MCI) is a precursor of Alzheimer's disease(AD), and the detection of MCI is of great clinical significance. Analyzing the structural brain networks of patients is vital for the recognition of MCI. However, the current studies on structural brain networks are totally dependent on specific toolboxes, which is time-consuming and subjective. Few tools can obtain the structural brain networks from brain diffusion tensor images. In this work, an adversarial learning-based structural brain-network generative model(SBGM) is proposed to directly learn the structural connections from brain diffusion tensor images. By analyzing the differences in structural brain networks across subjects, we found that the structural brain networks of subjects showed a consistent trend from elderly normal controls(NC) to early mild cognitive impairment(EMCI) to late mild cognitive impairment(LMCI): structural connectivity progressed in a progressively weaker direction as the condition worsened. In addition, our proposed model tri-classifies EMCI, LMCI, and NC subjects, achieving a classification accuracy of 83.33\% on the Alzheimer's Disease Neuroimaging Initiative(ADNI) database.      
### 41.Synergistic Integration of Techniques of VC, Communication Technologies and Unities of Calculation Transportable for Generate a System Embedded That Monitors Pyroclastic Flows in Real Time  [ :arrow_down: ](https://arxiv.org/pdf/2208.08884.pdf)
>  At the end of an extensive investigation of the volcanic eruptions in the world, we determined patterns that coincide in this process, this data can be analyzed by artificial vision, obtaining the largest amount of information from images in an embedded system, using monitoring algorithms for compare continuous matrices, control camera positioning and link this information with mass communication technologies. The present work shows the development of a viable early warning technology solution that allows to analyze the behavior of volcanic flows automatically in a rash in real time, with a very high level of efficiency in the analysis of possible trajectories, direction and quantity of the lava flows as well as the massive mass media directed to the affected people.      
### 42.Robust Artificial Delay based Impedance Control of Robotic Manipulators with Uncertain Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2208.08873.pdf)
>  In this paper an artificial delay based impedance controller is proposed for robotic manipulators with uncertainty in dynamics. The control law unites the time delayed estimation (TDE) framework with a second order switching controller of super twisting algorithm (STA) type via a novel generalized filtered tracking error (GFTE). While time delayed estimation framework eliminates the need for accurate modelling of robot dynamics by estimating the uncertain robot dynamics and interaction forces from immediate past data of state and control effort, the second order switching control law in the outer loop provides robustness against the time delayed estimation (TDE) error that arises due to approximation of the manipulator dynamics. Thus, the proposed control law tries to establish a desired impedance model between the robot end effector variables i.e. force and motion in presence of uncertainties, both when it is encountering smooth contact forces and during free motion. Simulation results for a two link manipulator using the proposed controller along with convergence analysis are shown to validate the proposition.      
### 43.Automatic laser steering for middle ear surgery  [ :arrow_down: ](https://arxiv.org/pdf/2208.08812.pdf)
>  This paper deals with the control of laser spot in the context of minimally invasive surgery of the middle ear, e.g., cholesteatoma removal. More precisely, our work is concerned with the exhaustive burring of residual infected cells after primary mechanical resection of the pathological tissues since the latter cannot guarantee the treatment of all the infected tissues, the remaining infected cells cause regeneration of the diseases in 20%-25\-% of cases, which require a second surgery 12-18 months later. To tackle such a complex surgery, we have developed a robotic platform that consists of the combination of a macro-scale system (7 degrees of freedom (DoFs) robotic arm) and a micro-scale flexible system (2 DoFs) which operates inside the middle ear cavity. To be able to treat the residual cholesteatoma regions, we proposed a method to automatically generate optimal laser scanning trajectories inside the regions and between them. The trajectories are tacked using an image-based control scheme. The proposed method and materials were validated experimentally using the lab-made robotic platform. The obtained results in terms of accuracy and behaviour meet perfectly the laser surgery requirements.      
### 44.An Adjustable Farthest Point Sampling Method for Approximately-sorted Point Cloud Data  [ :arrow_down: ](https://arxiv.org/pdf/2208.08795.pdf)
>  Sampling is an essential part of raw point cloud data processing such as in the popular PointNet++ scheme. Farthest Point Sampling (FPS), which iteratively samples the farthest point and performs distance updating, is one of the most popular sampling schemes. Unfortunately it suffers from low efficiency and can become the bottleneck of point cloud applications. We propose adjustable FPS (AFPS), parameterized by M, to aggressively reduce the complexity of FPS without compromising on the sampling performance. Specifically, it divides the original point cloud into M small point clouds and samples M points simultaneously. It exploits the dimensional locality of an approximately sorted point cloud data to minimize its performance degradation. AFPS method can achieve 22 to 30x speedup over original FPS. Furthermore, we propose the nearest-point-distance-updating (NPDU) method to limit the number of distance updates to a constant number. The combined NPDU on AFPS method can achieve a 34-280x speedup on a point cloud with 2K-32K points with algorithmic performance that is comparable to the original FPS. For instance, for the ShapeNet part segmentation task, it achieves 0.8490 instance average mIoU (mean Intersection of Union), which is only 0.0035 drop compared to the original FPS.      
### 45.Rate Splitting in MIMO RIS-assisted Systems with Hardware Impairments and Improper Signaling  [ :arrow_down: ](https://arxiv.org/pdf/2208.08753.pdf)
>  In this paper, we propose an optimization framework for rate splitting (RS) techniques in multiple-input multiple-output (MIMO) reconfigurable intelligent surface (RIS)-assisted systems, possibly with I/Q imbalance (IQI). This framework can be applied to any optimization problem in which the objective and/or constraints are linear functions of the rates and/or transmit covariance matrices. Such problems include minimum-weighted and weighted-sum rate maximization, total power minimization for a target rate, minimum-weighted energy efficiency (EE) and global EE maximization. The framework may be applied to any interference-limited system with hardware impairments. For the sake of illustration, we consider a multicell MIMO RIS-assisted broadcast channel (BC) in which the base stations (BSs) and/or the users may suffer from IQI. Since IQI generates improper noise, we consider improper Gaussian signaling (IGS) as an interference-management technique that can additionally compensate for IQI. We show that RS when combined with IGS can substantially improve the spectral and energy efficiency of overloaded networks (i.e., when the number of users per cell is larger than the number of transmit/receive antennas).      
### 46.Musika! Fast Infinite Waveform Music Generation  [ :arrow_down: ](https://arxiv.org/pdf/2208.08706.pdf)
>  Fast and user-controllable music generation could enable novel ways of composing or performing music. However, state-of-the-art music generation systems require large amounts of data and computational resources for training, and are slow at inference. This makes them impractical for real-time interactive use. In this work, we introduce Musika, a music generation system that can be trained on hundreds of hours of music using a single consumer GPU, and that allows for much faster than real-time generation of music of arbitrary length on a consumer CPU. We achieve this by first learning a compact invertible representation of spectrogram magnitudes and phases with adversarial autoencoders, then training a Generative Adversarial Network (GAN) on this representation for a particular music domain. A latent coordinate system enables generating arbitrarily long sequences of excerpts in parallel, while a global context vector allows the music to remain stylistically coherent through time. We perform quantitative evaluations to assess the quality of the generated samples and showcase options for user control in piano and techno music generation. We release the source code and pretrained autoencoder weights at <a class="link-external link-http" href="http://github.com/marcoppasini/musika" rel="external noopener nofollow">this http URL</a>, such that a GAN can be trained on a new music domain with a single GPU in a matter of hours.      
### 47.On an Application of Generative Adversarial Networks on Remaining Lifetime Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2208.08666.pdf)
>  A major problem of structural health monitoring (SHM) has been the prognosis of damage and the definition of the remaining useful life of a structure. Both tasks depend on many parameters, many of which are often uncertain. Many models have been developed for the aforementioned tasks but they have been either deterministic or stochastic with the ability to take into account only a restricted amount of past states of the structure. In the current work, a generative model is proposed in order to make predictions about the damage evolution of structures. The model is able to perform in a population-based SHM (PBSHM) framework, to take into account many past states of the damaged structure, to incorporate uncertainties in the modelling process and to generate potential damage evolution outcomes according to data acquired from a structure. The algorithm is tested on a simulated damage evolution example and the results reveal that it is able to provide quite confident predictions about the remaining useful life of structures within a population.      
### 48.Rethinking the Performance of ISAC System: From Efficiency and Utility Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2208.08654.pdf)
>  Integrated sensing and communications (ISAC) is an essential technology for the 6G communication system, which enables the conventional wireless communication network capable of sensing targets around. The shared use of pilots is a promising strategy to achieve ISAC. It brings a trade-off between communication and sensing, which is still unclear under the imperfect channel estimation condition. To provide some insights, the trade-off between ergodic capacity with imperfect channel estimation and ergodic Cramer-Rao bound (CRB) of range sensing is investigated. Firstly, the closedform expressions of ergodic capacity and ergodic range CRB are derived, which are associated with the number of pilots. Secondly, two novel metrics named efficiency and utility are firstly proposed to evaluate the joint performance of capacity and range sensing error. Specifically, efficiency is used to evaluate the achievable capacity per unit of the sensing error, and utility is designed to evaluate the utilization degree of ISAC. Moreover, an algorithm of pilot length optimization is designed to achieve the best efficiency. Finally, simulation results are given to verify the accuracy of analytical results, and provide some insights on designing the slot structure.      
### 49.Ghost Synthetic Aperture with Computational Wavefront Shaping  [ :arrow_down: ](https://arxiv.org/pdf/2208.08644.pdf)
>  Although optical synthetic aperture has been generally accepted as preferred technique to achieve very large pupil, the optical cophase of all the gaint subapertures is still a difficult task currently. Besides, the associated adaptive optics combatting the atmospheric turbulence presents hard to conduct. Here we demonstrate an incoherent optical synthetic aperture based on lensless ghost imaging method, in which diffraction-limited imaging can be performed even when the distributed sub-sources is non-cophased. Better yet, the wavefront shaping is computationally implement via an iterative algorithm, rather than actual optical modulation process. These enhancement makes the presented technique far easy under current techniques, and promising in many optcial sensing applications.      
### 50.Group-based control of large-scale micro-robot swarms with on-board Physical Finite-State Machines  [ :arrow_down: ](https://arxiv.org/pdf/2208.08614.pdf)
>  An important problem in microrobotics is how to control a large group of microrobots with a global control signal. This paper focuses on controlling a large-scale swarm of MicroStressBots with on-board physical finite-state machines. We introduce the concept of group-based control, which makes it possible to scale up the swarm size while reducing the complexity both of robot fabrication as well as swarm control. We prove that the group-based control system is locally accessible in terms of the robot positions. We further hypothesize based on extensive simulations that the system is globally controllable. A nonlinear optimization strategy is proposed to control the swarm by minimizing control effort. We also propose a probabilistically complete collision avoidance method that is suitable for online use. The paper concludes with an evaluation of the proposed methods in simulations.      
### 51.Event-triggered Finite-time Control Using Inverse-optimal Implicit Lyapunov Function  [ :arrow_down: ](https://arxiv.org/pdf/2208.08607.pdf)
>  This work deals with the event-triggered finite-time control for high-order systems based on an implicit Lyapunov function (ILF). With the construction of an inverse optimal problem, a novel expression of ILF is obtained. By designing the event-triggering mechanism elaborately, it is guaranteed that the trivial solution of the closed-loop system is globally finite-time stable and there exists no Zeno phenomenon. Extensions to the scenario with a multi-agent system are studied where a finite-time tracking control drives all the agents to reach a consensus. The obtained theoretical results are supported by numerical simulations.      
### 52.Physical Computing for Materials Acceleration Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2208.08566.pdf)
>  A ''technology lottery'' describes a research idea or technology succeeding over others because it is suited to the available software and hardware, not necessarily because it is superior to alternative directions--examples abound, from the synergies of deep learning and GPUs to the disconnect of urban design and autonomous vehicles. The nascent field of Self-Driving Laboratories (SDL), particularly those implemented as Materials Acceleration Platforms (MAPs), is at risk of an analogous pitfall: the next logical step for building MAPs is to take existing lab equipment and workflows and mix in some AI and automation. In this whitepaper, we argue that the same simulation and AI tools that will accelerate the search for new materials, as part of the MAPs research program, also make possible the design of fundamentally new computing mediums. We need not be constrained by existing biases in science, mechatronics, and general-purpose computing, but rather we can pursue new vectors of engineering physics with advances in cyber-physical learning and closed-loop, self-optimizing systems. Here we outline a simulation-based MAP program to design computers that use physics itself to solve optimization problems. Such systems mitigate the hardware-software-substrate-user information losses present in every other class of MAPs and they perfect alignment between computing problems and computing mediums eliminating any technology lottery. We offer concrete steps toward early ''Physical Computing (PC) -MAP'' advances and the longer term cyber-physical R&amp;D which we expect to introduce a new era of innovative collaboration between materials researchers and computer scientists.      
### 53.Analyzing Robustness of End-to-End Neural Models for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2208.08509.pdf)
>  We investigate robustness properties of pre-trained neural models for automatic speech recognition. Real life data in machine learning is usually very noisy and almost never clean, which can be attributed to various factors depending on the domain, e.g. outliers, random noise and adversarial noise. Therefore, the models we develop for various tasks should be robust to such kinds of noisy data, which led to the thriving field of robust machine learning. We consider this important issue in the setting of automatic speech recognition. With the increasing popularity of pre-trained models, it's an important question to analyze and understand the robustness of such models to noise. In this work, we perform a robustness analysis of the pre-trained neural models wav2vec2, HuBERT and DistilHuBERT on the LibriSpeech and TIMIT datasets. We use different kinds of noising mechanisms and measure the model performances as quantified by the inference time and the standard Word Error Rate metric. We also do an in-depth layer-wise analysis of the wav2vec2 model when injecting noise in between layers, enabling us to predict at a high level what each layer learns. Finally for this model, we visualize the propagation of errors across the layers and compare how it behaves on clean versus noisy data. Our experiments conform the predictions of Pasad et al. [2021] and also raise interesting directions for future work.      
### 54.Complex-Value Spatio-temporal Graph Convolutional Neural Networks and its Applications to Electric Power Systems AI  [ :arrow_down: ](https://arxiv.org/pdf/2208.08485.pdf)
>  The effective representation, precessing, analysis, and visualization of large-scale structured data over graphs are gaining a lot of attention. So far most of the literature has focused on real-valued signals. However, signals are often sparse in the Fourier domain, and more informative and compact representations for them can be obtained using the complex envelope of their spectral components, as opposed to the original real-valued signals. Motivated by this fact, in this work we generalize graph convolutional neural networks (GCN) to the complex domain, deriving the theory that allows to incorporate a complex-valued graph shift operators (GSO) in the definition of graph filters (GF) and process complex-valued graph signals (GS). The theory developed can handle spatio-temporal complex network processes. We prove that complex-valued GCNs are stable with respect to perturbations of the underlying graph support, the bound of the transfer error and the bound of error propagation through multiply layers. Then we apply complex GCN to power grid state forecasting, power grid cyber-attack detection and localization.      
### 55.Performance Evaluation of Selective Fixed-filter Active Noise Control based on Different Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.08440.pdf)
>  Due to its rapid response time and a high degree of robustness, the selective fixed-filter active noise control (SFANC) method appears to be a viable candidate for widespread use in a variety of practical active noise control (ANC) systems. In comparison to conventional fixed-filter ANC methods, SFANC can select the pre-trained control filters for different types of noise. Deep learning technologies, thus, can be used in SFANC methods to enable a more flexible selection of the most appropriate control filters for attenuating various noises. Furthermore, with the assistance of a deep neural network, the selecting strategy can be learned automatically from noise data rather than through trial and error, which significantly simplifies and improves the practicability of ANC design. Therefore, this paper investigates the performance of SFANC based on different one-dimensional and two-dimensional convolutional neural networks. Additionally, we conducted comparative analyses of several network training strategies and discovered that fine-tuning could improve selection performance.      
