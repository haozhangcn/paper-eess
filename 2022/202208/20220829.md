# ArXiv eess --Mon, 29 Aug 2022
### 1.Joint Performance Metrics for Integrated Sensing and Communication Systems in Automotive Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2208.12790.pdf)
>  In this paper, multiple metrics are presented in order to jointly evaluate the performance of the radar and communication functions in scenarios involving Dual Function Radar Communication (DFRC) systems using stochastic geometry. These metrics are applied in an automotive scenario involving a two-lane road with vehicles and smart traffic lights, both equipped with DFRC systems. First, the performance achieved with these metrics are validated using Monte-Carlo (MC) simulations. Additionally, optimisation w.r.t. the power of the vehicles and smart traffic lights is performed based on the metrics. Then, the model is extended to include interference cancellation for the radar and/or communication function in all the metrics. Either full interference cancellation is applied, or a new model is proposed for imperfect interference cancellation.      
### 2.Battery and Hydrogen Energy Storage Control in a Smart Energy Network with Flexible Energy Demand using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2208.12779.pdf)
>  Smart energy networks provide for an effective means to accommodate high penetrations of variable renewable energy sources like solar and wind, which are key for deep decarbonisation of energy production. However, given the variability of the renewables as well as the energy demand, it is imperative to develop effective control and energy storage schemes to manage the variable energy generation and achieve desired system economics and environmental goals. In this paper, we introduce a hybrid energy storage system composed of battery and hydrogen energy storage to handle the uncertainties related to electricity prices, renewable energy production and consumption. We aim to improve renewable energy utilisation and minimise energy costs and carbon emissions while ensuring energy reliability and stability within the network. To achieve this, we propose a multi-agent deep deterministic policy gradient approach, which is a deep reinforcement learning-based control strategy to optimise the scheduling of the hybrid energy storage system and energy demand in real-time. The proposed approach is model-free and does not require explicit knowledge and rigorous mathematical models of the smart energy network environment. Simulation results based on real-world data show that: (i) integration and optimised operation of the hybrid energy storage system and energy demand reduces carbon emissions by 78.69%, improves cost savings by 23.5% and renewable energy utilisation by over 13.2% compared to other baseline models and (ii) the proposed algorithm outperforms the state-of-the-art self-learning algorithms like deep-Q network.      
### 3.IRIS: Integrated Retinal Functionality in Image Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2208.12707.pdf)
>  Neuromorphic image sensors draw inspiration from the biological retina to implement visual computations in electronic hardware. Gain control in phototransduction and temporal differentiation at the first retinal synapse inspired the first generation of neuromorphic sensors, but processing in downstream retinal circuits, much of which has been discovered in the past decade, has not been implemented in image sensor technology. We present a technology-circuit co-design solution that implements two motion computations occurring at the output of the retina that could have wide applications for vision based decision making in dynamic environments. Our simulations on Globalfoundries 22nm technology node show that, by taking advantage of the recent advances in semiconductor chip stacking technology, the proposed retina-inspired circuits can be fabricated on image sensing platforms in existing semiconductor foundries. Integrated Retinal Functionality in Image Sensors (IRIS) technology could drive advances in machine vision applications that demand robust, high-speed, energy-efficient and low-bandwidth real-time decision making.      
### 4.From Observability to Observer Realization: A path via elementary block-diagram manipulations  [ :arrow_down: ](https://arxiv.org/pdf/2208.12691.pdf)
>  Introductory state-space linear control courses focus on linear, time-invariant systems and spend intense efforts by introducing system realizations that allow the student to grasp fundamental concepts, among which controllability, observability, and controller and observer design. This note describes a graphical mechanism to transform a system expressed in observability form into its observer form based on elementary block diagram manipulations, a technique whose pedagogical usefulness tends to be overlooked. Given the well-known duality principle in linear systems with respect to controllability and observability, the proposed graphical mechanism is applicable to transform from controllability to controller realization.      
### 5.Reinforcement Learning based Multi-connectivity Resource Allocation in Factory Automation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.12662.pdf)
>  We propose joint user association, channel assignment and power allocation for mobile robot Ultra-Reliable and Low Latency Communications (URLLC) based on multi-connectivity and reinforcement learning. The mobile robots require control messages from the central guidance system at regular intervals. We use a two-phase communication scheme where robots can form multiple clusters. The robots in a cluster are close to each other and can have reliable Device-to-Device (D2D) communications. In Phase I, the APs transmit the combined payload of a cluster to the cluster leader within a latency constraint. The cluster leader broadcasts this message to its members in Phase II. We develop a distributed Multi-Agent Reinforcement Learning (MARL) algorithm for joint user association and resource allocation (RA) for Phase I. The cluster leaders use their local Channel State Information (CSI) to decide the APs for connection along with the sub-band and power level. The cluster leaders utilize multi-connectivity to connect to multiple APs to increase their reliability. The objective is to maximize the successful payload delivery probability for all robots. Illustrative simulation results indicate that the proposed scheme can approach the performance of the centralized algorithm and offer a substantial gain in reliability as compared to single-connectivity (when cluster leaders are able to connect to 1 AP).      
### 6.A Two Step Approach for Whole Slide Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2208.12635.pdf)
>  Multi-stain whole-slide-image (WSI) registration is an active field of research. It is unclear, however, how the current WSI registration methods would perform on a real-world data set. AutomatiC Registration Of Breast cAncer Tissue (ACROBAT) challenge is held to verify the performance of the current WSI registration methods by using a new dataset that originates from routine diagnostics to assess real-world applicability. In this report, we present our solution for the ACROBAT challenge. We employ a two-step approach including rigid and non-rigid transforms. The experimental results show that the median 90th percentile is 1,250 um for the validation dataset.      
### 7.Real-Time Distributed Model Predictive Control with Limited Communication Data Rates  [ :arrow_down: ](https://arxiv.org/pdf/2208.12531.pdf)
>  The application of distributed model predictive controllers (DMPC) for multi-agent systems (MASs) necessitates communication between agents, yet the consequence of communication data rates is typically overlooked. This work focuses on developing stability-guaranteed control methods for MASs with limited data rates. Initially, a distributed optimization algorithm with dynamic quantization is considered for solving the DMPC problem. Due to the limited data rate, the optimization process suffers from inexact iterations caused by quantization noise and premature termination, leading to sub-optimal solutions. In response, we propose a novel real-time DMPC framework with a quantization refinement scheme that updates the quantization parameters on-line so that both the quantization noise and the optimization sub-optimality decrease asymptotically. To facilitate the stability analysis, we treat the sub-optimally controlled MAS, the quantization refinement scheme, and the optimization process as three interconnected subsystems. The cyclic-small-gain theorem is used to derive sufficient conditions on the data rate for guaranteeing the asymptotic stability of the system. Finally, the proposed algorithm and theoretical findings are demonstrated on a multi-AUV formation control example.      
### 8.Graph-Based Estimation of Time-Varying DOAs  [ :arrow_down: ](https://arxiv.org/pdf/2208.12472.pdf)
>  This paper presents a graph-based estimation method for sequential direction finding. The proposed method estimates an unknown number of directions of arrivals (DOAs) by performing message passing on the factor graph that represents the statistical model of the estimation problem. At each time step, belief propagation predicts the number of DOAs and their DOAs based on a new state-transition model and utilizing posterior probability density functions from previous time steps. Mean field message passing updates the DOAs and their number iteratively. The method promotes sparse solutions through a Bernoulli-Gaussian amplitude model, is gridless, and provides marginal posterior probability density functions from which DOA estimates and their uncertainties can be extracted. To propagate source existence and DOA information across time steps, a Bernoulli-von Mises state transition model is introduced. Compared to non-sequential approaches, the method can reduce DOA estimation errors in scenarios involving multiple time steps and time-varying DOAs. Simulation results demonstrate performance improvements compared to state-of-the-art methods. We evaluate the proposed method using ocean acoustic experimental data.      
### 9.Nuclei &amp; Glands Instance Segmentation in Histology Images: A Narrative Review  [ :arrow_down: ](https://arxiv.org/pdf/2208.12460.pdf)
>  Instance segmentation of nuclei and glands in the histology images is an important step in computational pathology workflow for cancer diagnosis, treatment planning and survival analysis. With the advent of modern hardware, the recent availability of large-scale quality public datasets and the community organized grand challenges have seen a surge in automated methods focusing on domain specific challenges, which is pivotal for technology advancements and clinical translation. In this survey, 126 papers illustrating the AI based methods for nuclei and glands instance segmentation published in the last five years (2017-2022) are deeply analyzed, the limitations of current approaches and the open challenges are discussed. Moreover, the potential future research direction is presented and the contribution of state-of-the-art methods is summarized. Further, a generalized summary of publicly available datasets and a detailed insights on the grand challenges illustrating the top performing methods specific to each challenge is also provided. Besides, we intended to give the reader current state of existing research and pointers to the future directions in developing methods that can be used in clinical practice enabling improved diagnosis, grading, prognosis, and treatment planning of cancer. To the best of our knowledge, no previous work has reviewed the instance segmentation in histology images focusing towards this direction.      
### 10.MuLan: A Joint Embedding of Music Audio and Natural Language  [ :arrow_down: ](https://arxiv.org/pdf/2208.12415.pdf)
>  Music tagging and content-based retrieval systems have traditionally been constructed using pre-defined ontologies covering a rigid set of music attributes or text queries. This paper presents MuLan: a first attempt at a new generation of acoustic models that link music audio directly to unconstrained natural language music descriptions. MuLan takes the form of a two-tower, joint audio-text embedding model trained using 44 million music recordings (370K hours) and weakly-associated, free-form text annotations. Through its compatibility with a wide range of music genres and text styles (including conventional music tags), the resulting audio-text representation subsumes existing ontologies while graduating to true zero-shot functionalities. We demonstrate the versatility of the MuLan embeddings with a range of experiments including transfer learning, zero-shot music tagging, language understanding in the music domain, and cross-modal retrieval applications.      
### 11.Extending the practical applicability of the Kalman Filter  [ :arrow_down: ](https://arxiv.org/pdf/2208.12402.pdf)
>  A Schmidt filter is a modification of the Kalman filter that allows to append system parameters as states and considers their uncertainty effect in the filtering process without attempting to estimate such parameters. The states that are only considered but not estimated, are generally known as \textit{consider} or \textit{considered} states. The main contributions of this research are the formulations of a Schmidt-Kalman filter that incorporates the numerical robustness of the well-known square root and factorized filtering forms plus the capacity of actively attempting to update the \textit{considered} states. The filters formulations proposed in this research are a fundamental extension of the Kalman filter. Therefore, the formulations of this work also apply within the Extended Kalman filter framework. More importantly, they are shown to handle nonlinearities, larger initial uncertainties, and poorly conditioned systems better than a typical Extended or Schmidt Kalman filter. Because the new filters are directly based on the Schmidt filter, they offer a novel and straight-forward filtering framework, allowing the use of a more simple filter where a more advanced or elaborated technique could have been needed.      
### 12.Improved Pump Setpoint Selection Using a Calibrated Hydraulic Model of a High-Pressure Irrigation System  [ :arrow_down: ](https://arxiv.org/pdf/2208.12395.pdf)
>  This paper presents a case study of the operational management of the Robinvale high-pressure piped irrigation water delivery system (RVHPS) in Australia. Based on datasets available, improved pump setpoint selection using a calibrated hydraulic model is investigated. The first step was to implement pre-processing of measured flow and pressure data to identify errors in the data and possible faulty sensors. An EPANET hydraulic simulation model was updated with calibrated pipe roughness height values by using the processed pressure and flow data. Then, new pump setpoints were selected using the calibrated model given the actual measured demands such that the pressures in the network were minimized subject to required customer service standards. Based on a two-day simulation, it was estimated that 4.7% savings in pumping energy cost as well as 4.7% reduction in greenhouse gas emissions can be achieved by applying the new pump setpoints.      
### 13.VEViD: Vision Enhancement via Virtual diffraction and coherent Detection  [ :arrow_down: ](https://arxiv.org/pdf/2208.12366.pdf)
>  The history of computing started with analog computers consisting of physical devices performing specialized functions such as predicting the trajectory of cannon balls. In modern times, this idea has been extended, for example, to ultrafast nonlinear optics serving as a surrogate analog computer to probe the behavior of complex phenomena such as rogue waves. Here we discuss a new paradigm where physical phenomena coded as an algorithm perform computational imaging tasks. Specifically, diffraction followed by coherent detection, not in its analog realization but when coded as an algorithm, becomes an image enhancement tool. Vision Enhancement via Virtual diffraction and coherent Detection (VEViD) introduced here reimagines a digital image as a spatially varying metaphoric light field and then subjects the field to the physical processes akin to diffraction and coherent detection. The term "Virtual" captures the deviation from the physical world. The light field is pixelated and the propagation imparts a phase with an arbitrary dependence on frequency which can be different from the quadratic behavior of physical diffraction. Temporal frequencies exist in three bands corresponding to the RGB color channels of a digital image. The phase of the output, not the intensity, represents the output image. VEViD is a high-performance low-light-level and color enhancement tool that emerges from this paradigm. The algorithm is interpretable and computationally efficient. We demonstrate image enhancement of 4k video at 200frames per second and show the utility of this physical algorithm in improving the accuracy of object detection by neural networks without having to retrain model for low-light conditions. The application of VEViD to color enhancement is also demonstrated.      
### 14.Using Atom-Like Local Image Features to Study Human Genetics and Neuroanatomy in Large Sets of 3D Medical Image Volumes  [ :arrow_down: ](https://arxiv.org/pdf/2208.12361.pdf)
>  The contributions of this thesis stem from technology developed to analyse large sets of volumetric images in terms of atom-like features extracted in 3D image space, following SIFT algorithm in 2D image space. New feature properties are introduced including a binary feature sign, analogous to an electrical charge, and a discrete set of symmetric feature orientation states in 3D space. These new properties are leveraged to extend feature invariance to include the sign inversion and parity (SP) transform, analogous to the charge conjugation and parity (CP) transform between a particle and its antiparticle in quantum mechanics, thereby accounting for local intensity contrast inversion between imaging modalities and axis reflections due to shape symmetry. A novel exponential kernel is proposed to quantify the similarity of a pair of features extracted in different images from their properties including location, scale, orientation, sign and appearance. A novel measure entitled the soft Jaccard is proposed to quantify the similarity of a pair of feature sets based on their overlap or intersection-over-union, where a kernel establishes non-binary or soft equivalence between a pair of feature elements. The soft Jaccard may be used to identify pairs of feature sets extracted from the same individuals or families with high accuracy, and a simple distance threshold led to the surprising discovery of previously unknown individual and family labeling errors in major public neuroimage datasets. A new algorithm is proposed to register or spatially align a pair of feature sets, entitled SIFT Coherent Point Drift (SIFT-CPD), by identifying a transform that maximizes the soft Jaccard between a fixed feature set and a transformed set. SIFT-CPD achieves faster and more accurate registration than the original CPD algorithm based on feature location information alone, in a variety of challenging.      
### 15.Image Reconstruction by Splitting Expectation Propagation Techniques from Iterative Inversion  [ :arrow_down: ](https://arxiv.org/pdf/2208.12340.pdf)
>  Reconstructing images from downsampled and noisy measurements, such as MRI and low dose Computed Tomography (CT), is a mathematically ill-posed inverse problem. We propose an easy-to-use reconstruction method based on Expectation Propagation (EP) techniques. We incorporate the Monte Carlo (MC) method, Markov Chain Monte Carlo (MCMC), and Alternating Direction Method of Multiplier (ADMM) algorithm into EP method to address the intractability issue encountered in EP. We demonstrate the approach on complex Bayesian models for image reconstruction. Our technique is applied to images from Gamma-camera scans. We compare EPMC, EP-MCMC, EP-ADMM methods with MCMC only. The metrics are the better image reconstruction, speed, and parameters estimation. Experiments with Gamma-camera imaging in real and simulated data show that our proposed method is convincingly less computationally expensive than MCMC and produces relatively a better image reconstruction.      
### 16.On the relationship between extended state observer and unknown input observer  [ :arrow_down: ](https://arxiv.org/pdf/2208.12314.pdf)
>  This paper explores the differences and similarities between unknown input observer (UIO) and extended state observer (ESO) for discrete-time linear time-invariant systems with uncertainties, both internal and external. It is shown that, with the relative degree of the plant higher than one, a UIO with delay produces exactly the same disturbance estimation as that of an ESO with poles all placed at origin. Hence, ESO has the ability to estimate arbitrary unknown disturbances like UIO. However, UIO with delay is not appropriate for real-time feedback control, while ESO is a popular tool for feedback control in industry. Our proofs in these differences and similarities show that the design of ESO must follow a principle of no invariant zero between the total disturbance input and the measurement output. Finally, based on above insights, a new, generalized ESO is proposed to add zero dynamics into the observer design unlike conventional ESO.      
### 17.Sparse Array Beamformer Design via ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2208.12313.pdf)
>  In this paper, we devise a sparse array design algorithm for adaptive beamforming. Our strategy is based on finding a sparse beamformer weight to maximize the output signal-to-interference-plus-noise ratio (SINR). The proposed method utilizes the alternating direction method of multipliers (ADMM), and admits closed-form solutions at each ADMM iteration. The algorithm convergence properties are analyzed by showing the monotonicity and boundedness of the augmented Lagrangian function. In addition, we prove that the proposed algorithm converges to the set of Karush-Kuhn-Tucker stationary points. Numerical results exhibit its excellent performance, which is comparable to that of the exhaustive search approach, slightly better than those of the state-of-the-art solvers, including the semidefinite relaxation (SDR), its variant (SDR-V), and the successive convex approximation (SCA) approaches, and significantly outperforms several other sparse array design strategies, in terms of output SINR. Moreover, the proposed ADMM algorithm outperforms the SDR, SDR-V, and SCA methods, in terms of computational complexity.      
### 18.Sub-aperture SAR Imaging with Uncertainty Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2208.12292.pdf)
>  In the problem of spotlight mode airborne synthetic aperture radar (SAR) image formation, it is well-known that data collected over a wide azimuthal angle violate the isotropic scattering property typically assumed. Many techniques have been proposed to account for this issue, including both full-aperture and sub-aperture methods based on filtering, regularized least squares, and Bayesian methods. A full-aperture method that uses a hierarchical Bayesian prior to incorporate appropriate speckle modeling and reduction was recently introduced to produce samples of the posterior density rather than a single image estimate. This uncertainty quantification information is more robust as it can generate a variety of statistics for the scene. As proposed, the method was not well-suited for large problems, however, as the sampling was inefficient. Moreover, the method was not explicitly designed to mitigate the effects of the faulty isotropic scattering assumption. In this work we therefore propose a new sub-aperture SAR imaging method that uses a sparse Bayesian learning-type algorithm to more efficiently produce approximate posterior densities for each sub-aperture window. These estimates may be useful in and of themselves, or when of interest, the statistics from these distributions can be combined to form a composite image. Furthermore, unlike the often-employed lp-regularized least squares methods, no user-defined parameters are required. Application-specific adjustments are made to reduce the typically burdensome runtime and storage requirements so that appropriately large images can be generated. Finally, this paper focuses on incorporating these techniques into SAR image formation process. That is, for the problem starting with SAR phase history data, so that no additional processing errors are incurred.      
### 19.The Effect of Frequency Droop Damping on System Parameters and Battery Sizing During Load Change Condition  [ :arrow_down: ](https://arxiv.org/pdf/2208.12291.pdf)
>  Inverter-based resources (IBR) have been widely studied for their advantages on the current power systems. This increase in the penetration of renewable energy has raised some concerns about the stability of the existing grid. Historically, power systems are dominated by synchronous generators that can easily react to system instability due to high inertia and damping characteristics. However, with IBR, the control of the inverter plays a crucial role in contributing to the system stability and enhancing the functionality of the inverters. One of these novel control methods is droop control. Droop characteristics are used to control voltage, frequency, and active and reactive power. This paper presents the impact of frequency droop damping on system frequency, real power, and the rate of change of frequency with distributed energy resources. Also, battery sizing is suggested based on the results. The results also show the need for optimal selection for the frequency droop damping to fulfill the appropriate battery size in terms of cost and performance. The simulations are carried out in an electromagnetic transient program (EMTP)      
### 20.Neuro-Dynamic State Estimation for Networked Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2208.12288.pdf)
>  We devise neuro-dynamic state estimation (Neuro-DSE), a learning-based dynamic state estimation (DSE) algorithm for networked microgrids (NMs) under unknown subsystems. Our contributions include: 1) a data-driven Neuro-DSE algorithm for NMs DSE with partially unidentified dynamic models, which incorporates the neural-ordinary-differential-equations (ODE-Net) into Kalman filters; 2) a self-refining Neuro-DSE algorithm (Neuro-DSE+) which enables data-driven DSE under limited and noisy measurements by establishing an automatic filtering, augmenting and correcting framework; 3) a Neuro-KalmanNet-DSE algorithm which further integrates KalmanNet with Neuro-DSE to relieve the model mismatch of both neural- and physics-based dynamic models; and 4) an augmented Neuro-DSE for joint estimation of NMs states and unknown parameters (e.g., inertia). Extensive case studies demonstrate the efficacy of Neuro-DSE and its variants under different noise levels, control modes, power sources, observabilities and model knowledge, respectively.      
### 21.Decoding speech from non-invasive brain recordings  [ :arrow_down: ](https://arxiv.org/pdf/2208.12266.pdf)
>  Decoding language from brain activity is a long-awaited goal in both healthcare and neuroscience. Major milestones have recently been reached thanks to intracranial devices: subject-specific pipelines trained on invasive brain responses to basic language tasks now start to efficiently decode interpretable features (e.g. letters, words, spectrograms). However, scaling this approach to natural speech and non-invasive brain recordings remains a major challenge. Here, we propose a single end-to-end architecture trained with contrastive learning across a large cohort of individuals to predict self-supervised representations of natural speech. We evaluate our model on four public datasets, encompassing 169 volunteers recorded with magneto- or electro-encephalography (M/EEG), while they listened to natural speech. The results show that our model can identify, from 3s of MEG signals, the corresponding speech segment with up to 72.5% top-10 accuracy out of 1,594 distinct segments (and 44% top-1 accuracy), and up to 19.1% out of 2,604 segments for EEG recordings -- hence allowing the decoding of phrases absent from the training set. Model comparison and ablation analyses show that these performances directly benefit from our original design choices, namely the use of (i) a contrastive objective, (ii) pretrained representations of speech and (iii) a common convolutional architecture simultaneously trained across several participants. Together, these results delineate a promising path to decode natural language processing in real time from non-invasive recordings of brain activity.      
### 22.Algebraically Explainable Controllers: Decision Trees and Support Vector Machines Join Forces  [ :arrow_down: ](https://arxiv.org/pdf/2208.12804.pdf)
>  Recently, decision trees (DT) have been used as an explainable representation of controllers (a.k.a. strategies, policies, schedulers). Although they are often very efficient and produce small and understandable controllers for discrete systems, complex continuous dynamics still pose a challenge. In particular, when the relationships between variables take more complex forms, such as polynomials, they cannot be obtained using the available DT learning procedures. In contrast, support vector machines provide a more powerful representation, capable of discovering many such relationships, but not in an explainable form. Therefore, we suggest to combine the two frameworks in order to obtain an understandable representation over richer, domain-relevant algebraic predicates. We demonstrate and evaluate the proposed method experimentally on established benchmarks.      
### 23.Mel Spectrogram Inversion with Stable Pitch  [ :arrow_down: ](https://arxiv.org/pdf/2208.12782.pdf)
>  Vocoders are models capable of transforming a low-dimensional spectral representation of an audio signal, typically the mel spectrogram, to a waveform. Modern speech generation pipelines use a vocoder as their final component. Recent vocoder models developed for speech achieve a high degree of realism, such that it is natural to wonder how they would perform on music signals. Compared to speech, the heterogeneity and structure of the musical sound texture offers new challenges. In this work we focus on one specific artifact that some vocoder models designed for speech tend to exhibit when applied to music: the perceived instability of pitch when synthesizing sustained notes. We argue that the characteristic sound of this artifact is due to the lack of horizontal phase coherence, which is often the result of using a time-domain target space with a model that is invariant to time-shifts, such as a convolutional neural network. We propose a new vocoder model that is specifically designed for music. Key to improving the pitch stability is the choice of a shift-invariant target space that consists of the magnitude spectrum and the phase gradient. We discuss the reasons that inspired us to re-formulate the vocoder task, outline a working example, and evaluate it on musical signals. Our method results in 60% and 10% improved reconstruction of sustained notes and chords with respect to existing models, using a novel harmonic error metric.      
### 24.Spatio-Temporal Representation Learning Enhanced Source Cell-phone Recognition from Speech Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2208.12753.pdf)
>  The existing source cell-phone recognition method lacks the long-term feature characterization of the source device, resulting in inaccurate representation of the source cell-phone related features which leads to insufficient recognition accuracy. In this paper, we propose a source cell-phone recognition method based on spatio-temporal representation learning, which includes two main parts: extraction of sequential Gaussian mean matrix features and construction of a recognition model based on spatio-temporal representation learning. In the feature extraction part, based on the analysis of time-series representation of recording source signals, we extract sequential Gaussian mean matrix with long-term and short-term representation ability by using the sensitivity of Gaussian mixture model to data distribution. In the model construction part, we design a structured spatio-temporal representation learning network C3D-BiLSTM to fully characterize the spatio-temporal information, combine 3D convolutional network and bidirectional long short-term memory network for short-term spectral information and long-time fluctuation information representation learning, and achieve accurate recognition of cell-phones by fusing spatio-temporal feature information of recording source signals. The method achieves an average accuracy of 99.03% for the closed-set recognition of 45 cell-phones under the CCNU\_Mobile dataset, and 98.18% in small sample size experiments, with recognition performance better than the existing state-of-the-art methods. The experimental results show that the method exhibits excellent recognition performance in multi-class cell-phones recognition.      
### 25.Effectiveness of Mining Audio and Text Pairs from Public Data for Improving ASR Systems for Low-Resource Languages  [ :arrow_down: ](https://arxiv.org/pdf/2208.12666.pdf)
>  End-to-end (E2E) models have become the default choice for state-of-the-art speech recognition systems. Such models are trained on large amounts of labelled data, which are often not available for low-resource languages. Techniques such as self-supervised learning and transfer learning hold promise, but have not yet been effective in training accurate models. On the other hand, collecting labelled datasets on a diverse set of domains and speakers is very expensive. In this work, we demonstrate an inexpensive and effective alternative to these approaches by ``mining'' text and audio pairs for Indian languages from public sources, specifically from the public archives of All India Radio. As a key component, we adapt the Needleman-Wunsch algorithm to align sentences with corresponding audio segments given a long audio and a PDF of its transcript, while being robust to errors due to OCR, extraneous text, and non-transcribed speech. We thus create Shrutilipi, a dataset which contains over 6,400 hours of labelled audio across 12 Indian languages totalling to 4.95M sentences. On average, Shrutilipi results in a 2.3x increase over publicly available labelled data. We establish the quality of Shrutilipi with 21 human evaluators across the 12 languages. We also establish the diversity of Shrutilipi in terms of represented regions, speakers, and mentioned named entities. Significantly, we show that adding Shrutilipi to the training set of Wav2Vec models leads to an average decrease in WER of 5.8\% for 7 languages on the IndicSUPERB benchmark. For Hindi, which has the most benchmarks (7), the average WER falls from 18.8% to 13.5%. This improvement extends to efficient models: We show a 2.3% drop in WER for a Conformer model (10x smaller than Wav2Vec). Finally, we demonstrate the diversity of Shrutilipi by showing that the model trained with it is more robust to noisy input.      
### 26.Robust and Efficient Depth-based Obstacle Avoidance for Autonomous Miniaturized UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2208.12624.pdf)
>  Nano-size drones hold enormous potential to explore unknown and complex environments. Their small size makes them agile and safe for operation close to humans and allows them to navigate through narrow spaces. However, their tiny size and payload restrict the possibilities for on-board computation and sensing, making fully autonomous flight extremely challenging. The first step towards full autonomy is reliable obstacle avoidance, which has proven to be technically challenging by itself in a generic indoor environment. Current approaches utilize vision-based or 1-dimensional sensors to support nano-drone perception algorithms. This work presents a lightweight obstacle avoidance system based on a novel millimeter form factor 64 pixels multi-zone Time-of-Flight (ToF) sensor and a generalized model-free control policy. Reported in-field tests are based on the Crazyflie 2.1, extended by a custom multi-zone ToF deck, featuring a total flight mass of 35g. The algorithm only uses 0.3% of the on-board processing power (210uS execution time) with a frame rate of 15fps, providing an excellent foundation for many future applications. Less than 10% of the total drone power is needed to operate the proposed perception system, including both lifting and operating the sensor. The presented autonomous nano-size drone reaches 100% reliability at 0.5m/s in a generic and previously unexplored indoor environment. The proposed system is released open-source with an extensive dataset including ToF and gray-scale camera data, coupled with UAV position ground truth from motion capture.      
### 27.SOFFLFM: Super-resolution optical fluctuation Fourier light-field microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2208.12599.pdf)
>  Fourier light-field microscopy (FLFM) uses a micro-lens array (MLA) to segment the Fourier Plane of the microscopic objective lens to generate multiple two-dimensional perspective views, thereby reconstructing the three-dimensional(3D) structure of the sample using 3D deconvolution calculation without scanning. However, the resolution of FLFM is still limited by diffraction, and furthermore, dependent on the aperture division. In order to improve its resolution, a Super-resolution optical fluctuation Fourier light field microscopy (SOFFLFM) was proposed here, in which the Sofi method with ability of super-resolution was introduced into FLFM. SOFFLFM uses higher-order cumulants statistical analysis on an image sequence collected by FLFM, and then carries out 3D deconvolution calculation to reconstruct the 3D structure of the sample. Theoretical basis of SOFFLFM on improving resolution was explained and then verified with simulations. Simulation results demonstrated that SOFFLFM improved lateral and axial resolution by more than sqrt(2) and 2 times in the 2nd and 4th order accumulations, compared with that of FLFM.      
### 28.Efficient LiDAR Point Cloud Geometry Compression Through Neighborhood Point Attention  [ :arrow_down: ](https://arxiv.org/pdf/2208.12573.pdf)
>  Although convolutional representation of multiscale sparse tensor demonstrated its superior efficiency to accurately model the occupancy probability for the compression of geometry component of dense object point clouds, its capacity for representing sparse LiDAR point cloud geometry (PCG) was largely limited. This is because 1) fixed receptive field of the convolution cannot characterize extremely and unevenly distributed sparse LiDAR points very well; and 2) pretrained convolutions with fixed weights are insufficient to dynamically capture information conditioned on the input. This work therefore suggests the neighborhood point attention (NPA) to tackle them, where we first use k nearest neighbors (kNN) to construct adaptive local neighborhood; and then leverage the self-attention mechanism to dynamically aggregate information within this neighborhood. Such NPA is devised as a NPAFormer to best exploit cross-scale and same-scale correlations for geometric occupancy probability estimation. Compared with the anchor using standardized G-PCC, our method provides &gt;17% BD-rate gains for lossy compression, and &gt;14% bitrate reduction for lossless scenario using popular LiDAR point clouds in SemanticKITTI and Ford datasets. Compared with the state-of-the-art (SOTA) solution using attention optimized octree coding method, our approach requires much less decoding runtime with about 640 times speedup on average, while still presenting better compression efficiency.      
### 29.Deep learning-based fast time-resolved flame emission spectroscopy in high-pressure combustion environment  [ :arrow_down: ](https://arxiv.org/pdf/2208.12544.pdf)
>  A novel deep learning strategy is developed for fast and accurate gas property measurements using flame emission spectroscopy (FES). Particularly, the short-gated fast FES is essential to resolve fast-evolving combustion behaviors. However, as the exposure time for capturing the flame emission spectrum gets shorter, the signal-to-noise ratio (SNR) decreases, and characteristic spectral features indicating the gas properties become relatively weaker. Then, the property estimation based on the short-gated spectrum is difficult and inaccurate. Denoising convolutional neural networks (CNN) can enhance the SNR of the short-gated spectrum. A new CNN architecture including a reversible down- and up-sampling (DU) operator and a loss function based on proper orthogonal decomposition (POD) coefficients is proposed. For training and testing the CNN, flame chemiluminescence spectra were captured from a stable methane-air flat flame using a portable spectrometer (spectral range: 250-850 nm, resolution: 0.5 nm) with varied equivalence ratio (0.8-1.2), pressure (1-10 bar), and exposure time (0.05, 0.2, 0.4, and 2 s). The long exposure (2 s) spectra were used as the ground truth when training the denoising CNN. A kriging model with POD is trained by the long-gated spectra for calibration and then prediction of the gas properties taking the denoised short-gated spectrum as the input. The measurement or property prediction errors of pressure and equivalence ratio using the new technique were estimated to be 5.7% and 1.5% with 0.2 s exposure, which are exceptionally good and typically not achievable with such low SNR spectrum signals without a signal amplifier.      
### 30.Learning energy-efficient driving behaviors by imitating experts  [ :arrow_down: ](https://arxiv.org/pdf/2208.12534.pdf)
>  The rise of vehicle automation has generated significant interest in the potential role of future automated vehicles (AVs). In particular, in highly dense traffic settings, AVs are expected to serve as congestion-dampeners, mitigating the presence of instabilities that arise from various sources. However, in many applications, such maneuvers rely heavily on non-local sensing or coordination by interacting AVs, thereby rendering their adaptation to real-world settings a particularly difficult challenge. To address this challenge, this paper examines the role of imitation learning in bridging the gap between such control strategies and realistic limitations in communication and sensing. Treating one such controller as an "expert", we demonstrate that imitation learning can succeed in deriving policies that, if adopted by 5% of vehicles, may boost the energy-efficiency of networks with varying traffic conditions by 15% using only local observations. Results and code are available online at <a class="link-external link-https" href="https://sites.google.com/view/il-traffic/home" rel="external noopener nofollow">this https URL</a>.      
### 31.Enabling Massage Actions: An Interactive Parallel Robot with Compliant Joints  [ :arrow_down: ](https://arxiv.org/pdf/2208.12517.pdf)
>  We propose a parallel massage robot with compliant joints based on the series elastic actuator (SEA), offering a unified force-position control approach. First, the kinematic and static force models are established for obtaining the corresponding control variables. Then, a novel force-position control strategy is proposed to separately control the force-position along the normal direction of the surface and another two-direction displacement, without the requirement of a robotic dynamics model. To evaluate its performance, we implement a series of robotic massage experiments. The results demonstrate that the proposed massage manipulator can successfully achieve desired forces and motion patterns of massage tasks, arriving at a high-score user experience.      
### 32.Deformation equivariant cross-modality image synthesis with paired non-aligned training data  [ :arrow_down: ](https://arxiv.org/pdf/2208.12491.pdf)
>  Cross-modality image synthesis is an active research topic with multiple medical clinically relevant applications. Recently, methods allowing training with paired but misaligned data have started to emerge. However, no robust and well-performing methods applicable to a wide range of real world data sets exist. In this work, we propose a generic solution to the problem of cross-modality image synthesis with paired but non-aligned data by introducing new deformation equivariance encouraging loss functions. The method consists of joint training of an image synthesis network together with separate registration networks and allows adversarial training conditioned on the input even with misaligned data. The work lowers the bar for new clinical applications by allowing effortless training of cross-modality image synthesis networks for more difficult data sets and opens up opportunities for the development of new generic learning based cross-modality registration algorithms.      
### 33.Concept-Based Techniques for "Musicologist-friendly" Explanations in a Deep Music Classifier  [ :arrow_down: ](https://arxiv.org/pdf/2208.12485.pdf)
>  Current approaches for explaining deep learning systems applied to musical data provide results in a low-level feature space, e.g., by highlighting potentially relevant time-frequency bins in a spectrogram or time-pitch bins in a piano roll. This can be difficult to understand, particularly for musicologists without technical knowledge. To address this issue, we focus on more human-friendly explanations based on high-level musical concepts. Our research targets trained systems (post-hoc explanations) and explores two approaches: a supervised one, where the user can define a musical concept and test if it is relevant to the system; and an unsupervised one, where musical excerpts containing relevant concepts are automatically selected and given to the user for interpretation. We demonstrate both techniques on an existing symbolic composer classification system, showcase their potential, and highlight their intrinsic limitations.      
### 34.Laplacian Pyramid-like Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2208.12484.pdf)
>  In this paper, we develop the Laplacian pyramid-like autoencoder (LPAE) by adding the Laplacian pyramid (LP) concept widely used to analyze images in Signal Processing. LPAE decomposes an image into the approximation image and the detail image in the encoder part and then tries to reconstruct the original image in the decoder part using the two components. We use LPAE for experiments on classifications and super-resolution areas. Using the detail image and the smaller-sized approximation image as inputs of a classification network, our LPAE makes the model lighter. Moreover, we show that the performance of the connected classification networks has remained substantially high. In a super-resolution area, we show that the decoder part gets a high-quality reconstruction image by setting to resemble the structure of LP. Consequently, LPAE improves the original results by combining the decoder part of the autoencoder and the super-resolution network.      
### 35.Leveraging Symmetrical Convolutional Transformer Networks for Speech to Singing Voice Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2208.12410.pdf)
>  In this paper, we propose a model to perform style transfer of speech to singing voice. Contrary to the previous signal processing-based methods, which require high-quality singing templates or phoneme synchronization, we explore a data-driven approach for the problem of converting natural speech to singing voice. We develop a novel neural network architecture, called SymNet, which models the alignment of the input speech with the target melody while preserving the speaker identity and naturalness. The proposed SymNet model is comprised of symmetrical stack of three types of layers - convolutional, transformer, and self-attention layers. The paper also explores novel data augmentation and generative loss annealing methods to facilitate the model training. Experiments are performed on the <br>NUS and NHSS datasets which consist of parallel data of speech and singing voice. In these experiments, we show that the proposed SymNet model improves the objective reconstruction quality significantly over the previously published methods and baseline architectures. Further, a subjective listening test confirms the improved quality of the audio obtained using the proposed approach (absolute improvement of 0.37 in mean opinion score measure over the baseline system).      
### 36.Music Separation Enhancement with Generative Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2208.12387.pdf)
>  Despite phenomenal progress in recent years, state-of-the-art music separation systems produce source estimates with significant perceptual shortcomings, such as adding extraneous noise or removing harmonics. We propose a post-processing model (the Make it Sound Good (MSG) post-processor) to enhance the output of music source separation systems. We apply our post-processing model to state-of-the-art waveform-based and spectrogram-based music source separators, including a separator unseen by MSG during training. Our analysis of the errors produced by source separators shows that waveform models tend to introduce more high-frequency noise, while spectrogram models tend to lose transients and high frequency content. We introduce objective measures to quantify both kinds of errors and show MSG improves the source reconstruction of both kinds of errors. Crowdsourced subjective evaluations demonstrate that human listeners prefer source estimates of bass and drums that have been post-processed by MSG.      
### 37.The Far-/Near-Field Beam Squint and Solutions for THz Intelligent Reflecting Surface Communications  [ :arrow_down: ](https://arxiv.org/pdf/2208.12385.pdf)
>  Terahertz (THz) and intelligent reflecting surface (IRS) have been regarded as two promising technologies to improve the capacity and coverage for future 6G networks. Generally, IRS is usually equipped with large-scale elements when implemented at THz frequency. In this case, the near-field model and beam squint should be considered. Therefore, in this paper, we investigate the far-field and near-field beam squint problems in THz IRS communications for the first time. The far-field and near-field channel models are constructed based on the different electromagnetic radiation characteristics. Next, we first analyze the far-field beam squint and its effect for the beam gain based on the cascaded base station (BS)-IRS-user channel model, and then the near-field case is studied. To overcome the far-field and near-field beam squint effects, we propose to apply delay adjustable metasurface (DAM) to IRS, and develop a scheme of optimizing the reflecting phase shifts and time delays of IRS elements, which effectively eliminates the beam gain loss caused by beam squint. Finally, simulations are conducted to demonstrate the effectiveness of our proposed schemes in combating the near and far field beam squint.      
### 38.Bokeh-Loss GAN: Multi-Stage Adversarial Training for Realistic Edge-Aware Bokeh  [ :arrow_down: ](https://arxiv.org/pdf/2208.12343.pdf)
>  In this paper, we tackle the problem of monocular bokeh synthesis, where we attempt to render a shallow depth of field image from a single all-in-focus image. Unlike in DSLR cameras, this effect can not be captured directly in mobile cameras due to the physical constraints of the mobile aperture. We thus propose a network-based approach that is capable of rendering realistic monocular bokeh from single image inputs. To do this, we introduce three new edge-aware Bokeh Losses based on a predicted monocular depth map, that sharpens the foreground edges while blurring the background. This model is then finetuned using an adversarial loss to generate a realistic Bokeh effect. Experimental results show that our approach is capable of generating a pleasing, natural Bokeh effect with sharp edges while handling complicated scenes.      
### 39.2nd Place Solutions for UG2+ Challenge 2022 -- D$^{3}$Net for Mitigating Atmospheric Turbulence from Images  [ :arrow_down: ](https://arxiv.org/pdf/2208.12332.pdf)
>  This technical report briefly introduces to the D$^{3}$Net proposed by our team "TUK-IKLAB" for Atmospheric Turbulence Mitigation in $UG2^{+}$ Challenge at CVPR 2022. In the light of test and validation results on textual images to improve text recognition performance and hot-air balloon images for image enhancement, we can say that the proposed method achieves state-of-the-art performance. Furthermore, we also provide a visual comparison with publicly available denoising, deblurring, and frame averaging methods with respect to the proposed work. The proposed method ranked 2nd on the final leader-board of the aforementioned challenge in the testing phase, respectively.      
