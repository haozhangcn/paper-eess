# ArXiv eess --Thu, 4 Aug 2022
### 1.Estimating Uncertainty of Autonomous Vehicle Systems with Generalized Polynomial Chaos  [ :arrow_down: ](https://arxiv.org/pdf/2208.02232.pdf)
>  Modern autonomous vehicle systems use complex perception and control components and must cope with uncertain data received from sensors. To estimate the probability that such vehicles remain in a safe state, developers often resort to time-consuming simulation methods. <br>This paper presents an alternative methodology for analyzing autonomy pipelines in vehicular systems, based on Generalized Polynomial Chaos (GPC). We also present GAS, the first algorithm for creating and using GPC models of complex vehicle systems. GAS replaces complex perception components with a perception model to reduce complexity. Then, it constructs the GPC model and uses it for estimating state distribution and/or probability of entering an unsafe state. <br>We evaluate GAS on five scenarios used in crop management vehicles, self driving cars, and aerial drones - each system uses at least one complex perception or control component. We show that GAS calculates state distributions that closely match those produced by Monte Carlo Simulation, while also providing 2.3x-3.0x speedups.      
### 2.Internet of Things (IoT) based ECG System for Rural Health Care  [ :arrow_down: ](https://arxiv.org/pdf/2208.02226.pdf)
>  Nearly 30% of the people in the rural areas of Bangladesh are below the poverty level. Moreover, due to the unavailability of modernized healthcare-related technology, nursing and diagnosis facilities are limited for rural people. Therefore, rural people are deprived of proper healthcare. In this perspective, modern technology can be facilitated to mitigate their health problems. ECG sensing tools are interfaced with the human chest, and requisite cardiovascular data is collected through an IoT device. These data are stored in the cloud incorporates with the MQTT and HTTP servers. An innovative IoT-based method for ECG monitoring systems on cardiovascular or heart patients has been suggested in this study. The ECG signal parameters P, Q, R, S, T are collected, pre-processed, and predicted to monitor the cardiovascular conditions for further health management. The machine learning algorithm is used to determine the significance of ECG signal parameters and error rate. The logistic regression model fitted the better agreements between the train and test data. The prediction has been performed to determine the variation of PQRST quality and its suitability in the ECG Monitoring System. Considering the values of quality parameters, satisfactory results are obtained. The proposed IoT-based ECG system reduces the health care cost and complexity of cardiovascular diseases in the future.      
### 3.A Study of Modeling Rising Intonation in Cantonese Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2208.02189.pdf)
>  In human speech, the attitude of a speaker cannot be fully expressed only by the textual content. It has to come along with the intonation. Declarative questions are commonly used in daily Cantonese conversations, and they are usually uttered with rising intonation. Vanilla neural text-to-speech (TTS) systems are not capable of synthesizing rising intonation for these sentences due to the loss of semantic information. Though it has become more common to complement the systems with extra language models, their performance in modeling rising intonation is not well studied. In this paper, we propose to complement the Cantonese TTS model with a BERT-based statement/question classifier. We design different training strategies and compare their performance. We conduct our experiments on a Cantonese corpus named CanTTS. Empirical results show that the separate training approach obtains the best generalization performance and feasibility.      
### 4.Conv-NILM-Net, a causal and multi-appliance model for energy source separation  [ :arrow_down: ](https://arxiv.org/pdf/2208.02173.pdf)
>  Non-Intrusive Load Monitoring (NILM) seeks to save energy by estimating individual appliance power usage from a single aggregate measurement. Deep neural networks have become increasingly popular in attempting to solve NILM problems. However most used models are used for Load Identification rather than online Source Separation. Among source separation models, most use a single-task learning approach in which a neural network is trained exclusively for each appliance. This strategy is computationally expensive and ignores the fact that multiple appliances can be active simultaneously and dependencies between them. The rest of models are not causal, which is important for real-time application. Inspired by Convtas-Net, a model for speech separation, we propose Conv-NILM-net, a fully convolutional framework for end-to-end NILM. Conv-NILM-net is a causal model for multi appliance source separation. Our model is tested on two real datasets REDD and UK-DALE and clearly outperforms the state of the art while keeping a significantly smaller size than the competing models.      
### 5.Photonics-assisted analog wideband self-interference cancellation for in-band full-duplex MIMO systems with adaptive digital amplitude and delay pre-matching  [ :arrow_down: ](https://arxiv.org/pdf/2208.02172.pdf)
>  A photonics-assisted analog wideband RF self-interference (SI) cancellation and frequency downconversion approach for in-band full-duplex (IBFD) multiple-input multiple-output (MIMO) systems with adaptive digital amplitude and delay pre-matching is proposed based on a dual-parallel Mach-Zehnder modulator (DP-MZM). In each MIMO receiving antenna, the received signal, including different SI signals from different transmitting antennas and the signal of interest, is applied to one arm of the upper dual-drive Mach-ehnder modulator (DD-MZM) of the DP-MZM, the reference signal is applied to the other arm of the upper DD-MZM, and the local oscillator signal is applied to the lower DD-MZM. The SI signals are canceled in the optical domain in the upper DD-MZM and the frequency downconversion is achieved after photodetection. To cancel the SI signals, the reference signal is constructed in the digital domain, while the amplitude and delay of the constructed reference are adjusted digitally by upsampling with high accuracy. Experiments are performed when two different SI signals are employed. The genetic algorithm and least-squares algorithm are combined with segmented searching respectively for the SI signal reconstruction and amplitude and delay pre-matching. A cancellation depth of around 20 dB is achieved for the 1-Gbaud 16 quadrature-amplitude modulation orthogonal frequency-division multiplexing signal.      
### 6.Integrated Sensing and Communication for 6G: Ten Key Machine Learning Roles  [ :arrow_down: ](https://arxiv.org/pdf/2208.02157.pdf)
>  Integrating sensing and communication is a defining theme for future wireless systems. This is motivated by the promising performance gains, especially as they assist each other, and by the better utilization of the wireless and hardware resources. Realizing these gains in practice, however, is subject to several challenges where leveraging machine learning can provide a potential solution. This article focuses on ten key machine learning roles for joint sensing and communication, sensing-aided communication, and communication-aided sensing systems, explains why and how machine learning can be utilized, and highlights important directions for future research. The article also presents real-world results for some of these machine learning roles based on the large-scale real-world dataset DeepSense 6G, which could be adopted in investigating a wide range of integrated sensing and communication problems.      
### 7.Digitally-assisted photonic analog domain self-interference cancellation for in-band full-duplex MIMO systems via LS algorithm with adaptive order  [ :arrow_down: ](https://arxiv.org/pdf/2208.02149.pdf)
>  A digitally-assisted photonic analog domain self-interference cancellation (SIC) and frequency downconversion method is proposed for in-band full-duplex multiple-input multiple-output (MIMO) systems using the least square (LS) algorithm with adaptive order. The SIC and frequency downconversion are achieved in the optical domain via a dual-parallel Mach-Zehnder modulator (DP-MZM), while the downconverted signal is processed by the LS algorithm with adaptive order that is used to track the response of the multipath self-interference (SI) channel and reconstruct the reference signal for SIC. The proposed method can overcome the reconstruction difficulty of the multipath analog reference signal for SIC with high complexity in the MIMO scenario and can also solve the problem that the order of the reference reconstruction algorithm is not optimized when the wireless environment changes. An experiment is carried out to verify the concept. 30.2, 26.9, 23.5, 19.5, and 15.8 dB SIC depths are achieved when the SI signal has a carrier frequency of 10 GHz and baud rates of 0.1, 0.25, 0.5, 1, and 2 Gbaud, respectively. The convergence of the LS algorithm with adaptive order is also verified for different MIMO multipath SI signals.      
### 8.Subject-Specific Lesion Generation and Pseudo-Healthy Synthesis for Multiple Sclerosis Brain Images  [ :arrow_down: ](https://arxiv.org/pdf/2208.02135.pdf)
>  Understanding the intensity characteristics of brain lesions is key for defining image-based biomarkers in neurological studies and for predicting disease burden and outcome. In this work, we present a novel foreground-based generative method for modelling the local lesion characteristics that can both generate synthetic lesions on healthy images and synthesize subject-specific pseudo-healthy images from pathological images. Furthermore, the proposed method can be used as a data augmentation module to generate synthetic images for training brain image segmentation networks. Experiments on multiple sclerosis (MS) brain images acquired on magnetic resonance imaging (MRI) demonstrate that the proposed method can generate highly realistic pseudo-healthy and pseudo-pathological brain images. Data augmentation using the synthetic images improves the brain image segmentation performance compared to traditional data augmentation methods as well as a recent lesion-aware data augmentation technique, CarveMix. The code will be released at <a class="link-external link-https" href="https://github.com/dogabasaran/lesion-synthesis" rel="external noopener nofollow">this https URL</a>.      
### 9.LSSANet: A Long Short Slice-Aware Network for Pulmonary Nodule Detection  [ :arrow_down: ](https://arxiv.org/pdf/2208.02122.pdf)
>  Convolutional neural networks (CNNs) have been demonstrated to be highly effective in the field of pulmonary nodule detection. However, existing CNN based pulmonary nodule detection methods lack the ability to capture long-range dependencies, which is vital for global information extraction. In computer vision tasks, non-local operations have been widely utilized, but the computational cost could be very high for 3D computed tomography (CT) images. To address this issue, we propose a long short slice-aware network (LSSANet) for the detection of pulmonary nodules. In particular, we develop a new non-local mechanism termed long short slice grouping (LSSG), which splits the compact non-local embeddings into a short-distance slice grouped one and a long-distance slice grouped counterpart. This not only reduces the computational burden, but also keeps long-range dependencies among any elements across slices and in the whole feature map. The proposed LSSG is easy-to-use and can be plugged into many pulmonary nodule detection networks. To verify the performance of LSSANet, we compare with several recently proposed and competitive detection approaches based on 2D/3D CNN. Promising evaluation results on the large-scale PN9 dataset demonstrate the effectiveness of our method. Code is at <a class="link-external link-https" href="https://github.com/Ruixxxx/LSSANet" rel="external noopener nofollow">this https URL</a>.      
### 10.Considerate and Cooperative Model Predictive Control for Energy-Efficient Truck Platooning of Heterogeneous Fleets  [ :arrow_down: ](https://arxiv.org/pdf/2208.02119.pdf)
>  Connectivity-enabled automation of distributed control systems allow for better anticipation of system disturbances and better prediction of the effects of actuator limitations on individual agents when incorporating a model. Automated convoy of heavy-duty trucks in the form of platooning is one such application designed to maintain close gaps between trucks to exploit drafting benefits and improve fuel economy, and has traditionally been handled with classically-designed connected and adaptive cruise control (CACC). This paper is motivated by demonstrated limitations of such a control strategy, in which a classical CACC was unable to efficiently handle real-world road grade and velocity transient disturbances without the assistance of fleet operator intervention, and is non-adaptive to varied hardware and loading conditions of the operating truck. This automation strategy is addressed by forming a cooperative model predictive control (MPC) for eco-platooning that considers interactions with trailing trucks to incentivize platoon harmonization under road disturbances, velocity transients, and engine limitations, and further improves energy economy by reducing unnecessary engine effort. This is accomplished for each truck by sharing load, maximum engine power, transmission ratios, control states, and intended trajectories with its nearest neighbors. The performance of the considerate and cooperative strategy was demonstrated on a real-world driving scenario against a similar non-considerate control strategy, and overall it was found that the considerate strategy significantly improved harmonization between the platooned trucks in a real-time implementable manner.      
### 11.Texture features in medical image analysis: a survey  [ :arrow_down: ](https://arxiv.org/pdf/2208.02046.pdf)
>  The texture is defined as spatial structure of the intensities of the pixels in an image that is repeated periodically in the whole image or regions, and makes the concept of the image. Texture, color and shape are three main components which are used by human visual system to recognize image contents. In this paper, first of all, efficient and updated texture analysis operators are survived with details. Next, some state-of-the-art methods are survived that use texture analysis in medical applications and disease diagnosis. Finally, different approaches are compared in terms of accuracy, dataset, application, etc. Results demonstrate that texture features separately or in joint of different feature sets such as deep, color or shape features provide high accuracy in medical image classification.      
### 12.Safety Analysis Methods for Complex Systems in Aviation  [ :arrow_down: ](https://arxiv.org/pdf/2208.02018.pdf)
>  Each new concept of operation and equipment generation in aviation becomes more automated, integrated and interconnected. In the case of Unmanned Aircraft Systems (UAS), this evolution allows drastically decreasing aircraft weight and operational cost, but these benefits are also realized in highly automated manned aircraft and ground Air Traffic Control (ATC) systems. The downside of these advances is overwhelmingly more complex software and hardware, making it harder to identify potential failure paths. Although there are mandatory certification processes based on broadly accepted standards, such as ARP4754 and its family, ESARR 4 and others, these standards do not allow proof or disproof of safety of disruptive technology changes, such as GBAS Precision Approaches, Autonomous UAS, aircraft self-separation and others. In order to leverage the introduction of such concepts, it is necessary to develop solid knowledge on the foundations of safety in complex systems and use this knowledge to elaborate sound demonstrations of either safety or unsafety of new system designs. These demonstrations at early design stages will help reducing costs both on development of new technology as well as reducing the risk of such technology causing accidents when in use. <br>This paper presents some safety analysis methods which are not in the industry standards but which we identify as having benefits for analyzing safety of advanced technological concepts in aviation.      
### 13.Funnel Control Under Hard and Soft Output Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2208.02006.pdf)
>  This paper proposes a funnel control method under time-varying hard and soft output constraints. First, an online funnel planning scheme is designed that generates a constraint consistent funnel, which always respects hard (safety) constraints, and soft (performance) constraints are met only when they are not conflicting with the hard constraints. Next, the prescribed performance control method is employed for designing a robust low-complexity funnel-based controller for uncertain nonlinear Euler-Lagrangian systems such that the outputs always remain within the planned constraint consistent funnels. Finally, the results are verified with a simulation example of a mobile robot tracking a moving object while staying in a box-constrained safe space.      
### 14.Impacts of Real Hands on 5G Millimeter-Wave Cellphone Antennas: Measurements and Electromagnetic Models  [ :arrow_down: ](https://arxiv.org/pdf/2208.01966.pdf)
>  Penetration of cellphones into markets requires their robust operation in time-varying radio environments, especially for millimeter-wave communications. Hands and fingers of a human cause significant changes in the physical environments of cellphones, which influence the communication qualities to a large extent. In this paper, electromagnetic models of real hands and cellphone antennas are developed, and their efficacy is verified through measurements for the first time in the literature. Referential cellphone antenna arrays at $28$ and $39$~GHz are designed. Their radiation properties are evaluated through near-field scanning of the two prototypes, first in free space for calibration of the antenna measurement system and for building simplified models of the cellphone arrays. Next, radiation measurements are set up with real hands so that they are compared with electromagnetic simulations of the interaction between hands and simplified models of the arrays. The comparison showed a close agreement in terms of spherical coverage, indicating the efficacy of the hand and antenna array models along with the measurement approach. The repeatability of the measurements is $0.5$~dB difference in terms of cumulative distributions of the spherical coverage at the median level.      
### 15.Integrating Black Start Capabilities into Offshore Wind Farms by Grid-Forming Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2208.01883.pdf)
>  Power systems are currently experiencing a transition towards decarbonisation of electrical generation through large-scale deployment of renewable energy sources. These are gradually replacing conventional thermal power plants which today are the main providers of black start (BS) services. Consequently, in case of a total/partial blackout, conventional black-start resources are not ready for operation. Offshore wind farms (OWFs), with their large capacity and fast controllers, have potential as novel BS units. This new service introduces a need for a new design for wind power systems to be able to fulfil the black start requirements for non-traditional generation units. In this paper, challenges, and possible solutions in integrating BS services into OWFs will be presented. A first challenge is represented by the implementation of a BS unit. The BS unit should be capable of firstly forming the wind farm power island and withstanding transient phenomena due to energisation. There could be several different solutions, e.g., the integration of grid-forming converters in the wind farm design which could be battery energy storage systems (BESSs). In this paper, specific challenges are analysed using simulations on a wind farm equipped with a grid-forming BESS, and the proposed solutions discussed. It can be concluded that a hybrid system comprised of a BESS and an OWF, in combination with novel technologies such as grid-forming control, soft-charging, etc. represents a feasible proposal for being able to provide BS services with OWFs.      
### 16.Joint Sensing and Communications for Deep Reinforcement Learning-based Beam Management in 6G  [ :arrow_down: ](https://arxiv.org/pdf/2208.01880.pdf)
>  User location is a piece of critical information for network management and control. However, location uncertainty is unavoidable in certain settings leading to localization errors. In this paper, we consider the user location uncertainty in the mmWave networks, and investigate joint vision-aided sensing and communications using deep reinforcement learning-based beam management for future 6G networks. In particular, we first extract pixel characteristic-based features from satellite images to improve localization accuracy. Then we propose a UK-medoids based method for user clustering with location uncertainty, and the clustering results are consequently used for the beam management. Finally, we apply the DRL algorithm for intra-beam radio resource allocation. The simulations first show that our proposed vision-aided method can substantially reduce the localization error. The proposed UK-medoids and DRL based scheme (UKM-DRL) is compared with two other schemes: K-means based clustering and DRL based resource allocation (K-DRL) and UK-means based clustering and DRL based resource allocation (UK-DRL). The proposed method has 17.2% higher throughput and 7.7% lower delay than UK-DRL, and more than doubled throughput and 55.8% lower delay than K-DRL.      
### 17.Joint Optimization of DNN Inference Delay and Energy under Accuracy Constraints for AR Applications  [ :arrow_down: ](https://arxiv.org/pdf/2208.01860.pdf)
>  The high computational complexity and high energy consumption of artificial intelligence (AI) algorithms hinder their application in augmented reality (AR) systems. This paper considers the scene of completing video-based AI inference tasks in the mobile edge computing (MEC) system. We use multiply-and-accumulate operations (MACs) for problem analysis and optimize delay and energy consumption under accuracy constraints. To solve this problem, we first assume that offloading policy is known and decouple the problem into two subproblems. After solving these two subproblems, we propose an iterative-based scheduling algorithm to obtain the optimal offloading policy. We also experimentally discuss the relationship between delay, energy consumption, and inference accuracy.      
### 18.Joint Beamforming Design for RIS-Assisted Integrated Sensing and Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.01854.pdf)
>  Integrated sensing and communication (ISAC) has been envisioned as a promising technology to tackle the spectrum congestion problem for future networks. In this correspondence, we investigate to deploy a reconfigurable intelligent surface (RIS) in an ISAC system for achieving better performance. In particular, a multi-antenna base station (BS) simultaneously serves multiple single-antenna users with the assistance of a RIS and detects potential targets. The active beamforming of the BS and the passive beamforming of the RIS are jointly optimized to maximize the achievable sum-rate of the communication users while satisfying the constraint of beampattern similarity for radar sensing, the restriction of the RIS, and the transmit power budget. An efficient alternating algorithm based on the fractional programming (FP), majorization-minimization (MM), and manifold optimization methods is developed to convert the resulting non-convex optimization problem into two solvable sub-problems and iteratively solve them. Simulation studies illustrate the advancement of deploying RIS in ISAC systems and the effectiveness of the proposed algorithm.      
### 19.Multi-Feature Vision Transformer via Self-Supervised Representation Learning for Improvement of COVID-19 Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2208.01843.pdf)
>  The role of chest X-ray (CXR) imaging, due to being more cost-effective, widely available, and having a faster acquisition time compared to CT, has evolved during the COVID-19 pandemic. To improve the diagnostic performance of CXR imaging a growing number of studies have investigated whether supervised deep learning methods can provide additional support. However, supervised methods rely on a large number of labeled radiology images, which is a time-consuming and complex procedure requiring expert clinician input. Due to the relative scarcity of COVID-19 patient data and the costly labeling process, self-supervised learning methods have gained momentum and has been proposed achieving comparable results to fully supervised learning approaches. In this work, we study the effectiveness of self-supervised learning in the context of diagnosing COVID-19 disease from CXR images. We propose a multi-feature Vision Transformer (ViT) guided architecture where we deploy a cross-attention mechanism to learn information from both original CXR images and corresponding enhanced local phase CXR images. We demonstrate the performance of the baseline self-supervised learning models can be further improved by leveraging the local phase-based enhanced CXR images. By using 10\% labeled CXR scans, the proposed model achieves 91.10\% and 96.21\% overall accuracy tested on total 35,483 CXR images of healthy (8,851), regular pneumonia (6,045), and COVID-19 (18,159) scans and shows significant improvement over state-of-the-art techniques. Code is available <a class="link-external link-https" href="https://github.com/endiqq/Multi-Feature-ViT" rel="external noopener nofollow">this https URL</a>      
### 20.Medical image registration using unsupervised deep neural network: A scoping literature review  [ :arrow_down: ](https://arxiv.org/pdf/2208.01825.pdf)
>  In medicine, image registration is vital in image-guided interventions and other clinical applications. However, it is a difficult subject to be addressed which by the advent of machine learning, there have been considerable progress in algorithmic performance has recently been achieved for medical image registration in this area. The implementation of deep neural networks provides an opportunity for some medical applications such as conducting image registration in less time with high accuracy, playing a key role in countering tumors during the operation. The current study presents a comprehensive scoping review on the state-of-the-art literature of medical image registration studies based on unsupervised deep neural networks is conducted, encompassing all the related studies published in this field to this date. Here, we have tried to summarize the latest developments and applications of unsupervised deep learning-based registration methods in the medical field. Fundamental and main concepts, techniques, statistical analysis from different viewpoints, novelties, and future directions are elaborately discussed and conveyed in the current comprehensive scoping review. Besides, this review hopes to help those active readers, who are riveted by this field, achieve deep insight into this exciting field.      
### 21.Asymptotic Tracking Control of Uncertain MIMO Nonlinear Systems with Less Conservative Controllability Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2208.01822.pdf)
>  For uncertain multiple inputs multi-outputs (MIMO) nonlinear systems, it is nontrivial to achieve asymptotic tracking, and most existing methods normally demand certain controllability conditions that are rather restrictive or even impractical if unexpected actuator faults are involved. In this note, we present a method capable of achieving zero-error steady-state tracking with less conservative (more practical) controllability condition. By incorporating a novel Nussbaum gain technique and some positive integrable function into the control design, we develop a robust adaptive asymptotic tracking control scheme for the system with time-varying control gain being unknown its magnitude and direction. By resorting to the existence of some feasible auxiliary matrix, the current state-of-art controllability condition is further relaxed, which enlarges the class of systems that can be considered in the proposed control scheme. All the closed-loop signals are ensured to be globally ultimately uniformly bounded. Moreover, such control methodology is further extended to the case involving intermittent actuator faults, with application to robotic systems. Finally, simulation studies are carried out to demonstrate the effectiveness and flexibility of this method.      
### 22.Distributed Event-Triggered Nonlinear Fusion Estimation under Resource Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2208.01812.pdf)
>  This paper studies the event-triggered distributed fusion estimation problems for a class of nonlinear networked multisensor fusion systems without noise statistical characteristics. When considering the limited resource problems of two kinds of communication channels (i.e., sensor-to-remote estimator channel and smart sensor-to-fusion center channel), an event-triggered strategy and a dimensionality reduction strategy are introduced in a unified networked framework to lighten the communication burden. Then, two kinds of compensation strategies in terms of a unified model are designed to restructure the untransmitted information, and the local/fusion estimators are proposed based on the compensation information. Furthermore, the linearization errors caused by the Taylor expansion are modeled by the state-dependent matrices with uncertain parameters when establishing estimation error systems, and then different robust recursive optimization problems are constructed to determine the estimator gains and the fusion criteria. Meanwhile, the stability conditions are also proposed such that the square errors of the designed nonlinear estimators are bounded. Finally, a vehicle localization system is employed to demonstrate the effectiveness and advantages of the proposed methods.      
### 23.A comprehensive survey on computer-aided diagnostic systems in diabetic retinopathy screening  [ :arrow_down: ](https://arxiv.org/pdf/2208.01810.pdf)
>  Diabetes Mellitus (DM) can lead to significant microvasculature disruptions that eventually causes diabetic retinopathy (DR), or complications in the eye due to diabetes. If left unchecked, this disease can increase over time and eventually cause complete vision loss. The general method to detect such optical developments is through examining the vessels, optic nerve head, microaneurysms, haemorrhage, exudates, etc. from retinal images. Ultimately this is limited by the number of experienced ophthalmologists and the vastly growing number of DM cases. To enable earlier and efficient DR diagnosis, the field of ophthalmology requires robust computer aided diagnosis (CAD) systems. Our review is intended for anyone, from student to established researcher, who wants to understand what can be accomplished with CAD systems and their algorithms to modeling and where the field of retinal image processing in computer vision and pattern recognition is headed. For someone just getting started, we place a special emphasis on the logic, strengths and shortcomings of different databases and algorithms frameworks with a focus on very recent approaches.      
### 24.Post-hoc Interpretability based Parameter Selection for Data Oriented Nuclear Reactor Accident Diagnosis System  [ :arrow_down: ](https://arxiv.org/pdf/2208.01805.pdf)
>  During applying data-oriented diagnosis systems to distinguishing the type of and evaluating the severity of nuclear power plant initial events, it is of vital importance to decide which parameters to be used as the system input. However, although several diagnosis systems have already achieved acceptable performance in diagnosis precision and speed, hardly have the researchers discussed the method of monitoring point choosing and its layout. For this reason, redundant measuring data are used to train the diagnostic model, leading to high uncertainty of the classification, extra training time consumption, and higher probability of overfitting while training. In this study, a method of choosing thermal hydraulics parameters of a nuclear power plant is proposed, using the theory of post-hoc interpretability theory in deep learning. At the start, a novel Time-sequential Residual Convolutional Neural Network (TRES-CNN) diagnosis model is introduced to identify the position and hydrodynamic diameter of breaks in LOCA, using 38 parameters manually chosen on HPR1000 empirically. Afterwards, post-hoc interpretability methods are applied to evaluate the attributions of diagnosis model's outputs, deciding which 15 parameters to be more decisive in diagnosing LOCA details. The results show that the TRES-CNN based diagnostic model successfully predicts the position and size of breaks in LOCA via selected 15 parameters of HPR1000, with 25% of time consumption while training the model compared the process using total 38 parameters. In addition, the relative diagnostic accuracy error is within 1.5 percent compared with the model using parameters chosen empirically, which can be regarded as the same amount of diagnostic reliability.      
### 25.Segmented Learning for Class-of-Service Network Traffic Classification  [ :arrow_down: ](https://arxiv.org/pdf/2208.01793.pdf)
>  Class-of-service (CoS) network traffic classification (NTC) classifies a group of similar traffic applications. The CoS classification is advantageous in resource scheduling for Internet service providers and avoids the necessity of remodelling. Our goal is to find a robust, lightweight, and fast-converging CoS classifier that uses fewer data in modelling and does not require specialized tools in feature extraction. The commonality of statistical features among the network flow segments motivates us to propose novel segmented learning that includes essential vector representation and a simple-segment method of classification. We represent the segmented traffic in the vector form using the EVR. Then, the segmented traffic is modelled for classification using random forest. Our solution's success relies on finding the optimal segment size and a minimum number of segments required in modelling. The solution is validated on multiple datasets for various CoS services, including virtual reality (VR). Significant findings of the research work are i) Synchronous services that require acknowledgment and request to continue communication are classified with 99% accuracy, ii) Initial 1,000 packets in any session are good enough to model a CoS traffic for promising results, and we therefore can quickly deploy a CoS classifier, and iii) Test results remain consistent even when trained on one dataset and tested on a different dataset. In summary, our solution is the first to propose segmentation learning NTC that uses fewer features to classify most CoS traffic with an accuracy of 99%. The implementation of our solution is available on GitHub.      
### 26.On-Demand Resource Management for 6G Wireless Networks Using Knowledge-Assisted Dynamic Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.01785.pdf)
>  On-demand service provisioning is a critical yet challenging issue in 6G wireless communication networks, since emerging services have significantly diverse requirements and the network resources become increasingly heterogeneous and dynamic. In this paper, we study the on-demand wireless resource orchestration problem with the focus on the computing delay in orchestration decision-making process. Specifically, we take the decision-making delay into the optimization problem. Then, a dynamic neural network (DyNN)-based method is proposed, where the model complexity can be adjusted according to the service requirements. We further build a knowledge base representing the relationship among the service requirements, available computing resources, and the resource allocation performance. By exploiting the knowledge, the width of DyNN can be selected in a timely manner, further improving the performance of orchestration. Simulation results show that the proposed scheme significantly outperforms the traditional static neural network, and also shows sufficient flexibility in on-demand service provisioning.      
### 27.Data-Driven Fast Frequency Control using Inverter-Based Resources  [ :arrow_down: ](https://arxiv.org/pdf/2208.01761.pdf)
>  We develop and test a data-driven and area-based fast frequency control scheme, which rapidly redispatches inverter-based resources to compensate for local power imbalances within the bulk power system. The approach requires no explicit system model information, relying only on historical measurement sequences for the computation of control actions. Our technical approach fuses developments in low-gain estimator design and data-driven control to provide a model-free and practical solution for fast frequency control. Theoretical results and extensive simulation scenarios on a three area system are provided to support the approach.      
### 28.Streaming Reconstruction from Non-uniform Samples  [ :arrow_down: ](https://arxiv.org/pdf/2208.01719.pdf)
>  We present an online algorithm for reconstructing a signal from a set of non-uniform samples. By representing the signal using compactly supported basis functions, we show how estimating the expansion coefficients using least-squares can be implemented in a streaming manner: as batches of samples over subsequent time intervals are presented, the algorithm forms an initial estimate of the signal over the sampling interval then updates its estimates over previous intervals. We give conditions under which this reconstruction procedure is stable and show that the least-squares estimates in each interval converge exponentially, meaning that the updates can be performed with finite memory with almost no loss in accuracy. We also discuss how our framework extends to more general types of measurements including time-varying convolution with a compactly supported kernel.      
### 29.Non-Line-of-Sight Tracking and Mapping with an Active Corner Camera  [ :arrow_down: ](https://arxiv.org/pdf/2208.01702.pdf)
>  The ability to form non-line-of-sight (NLOS) images of changing scenes could be transformative in a variety of fields, including search and rescue, autonomous vehicle navigation, and reconnaissance. Most existing active NLOS methods illuminate the hidden scene using a pulsed laser directed at a relay surface and collect time-resolved measurements of returning light. The prevailing approaches include raster scanning of a rectangular grid on a vertical wall opposite the volume of interest to generate a collection of confocal measurements. These are inherently limited by the need for laser scanning. Methods that avoid laser scanning track the moving parts of the hidden scene as one or two point targets. In this work, based on more complete optical response modeling yet still without multiple illumination positions, we demonstrate accurate reconstructions of objects in motion and a 'map' of the stationary scenery behind them. The ability to count, localize, and characterize the sizes of hidden objects in motion, combined with mapping of the stationary hidden scene, could greatly improve indoor situational awareness in a variety of applications.      
### 30.Compositional Synthesis for Linear Systems via Convex Optimization of Assume-Guarantee Contracts  [ :arrow_down: ](https://arxiv.org/pdf/2208.01701.pdf)
>  We take a divide and conquer approach to design controllers for reachability problems given large-scale linear systems with polyhedral constraints on states, controls, and disturbances. Such systems are made of small subsystems with coupled dynamics. We treat the couplings as additional disturbances and use assume-guarantee (AG) contracts to characterize these disturbance sets. For each subsystem, we design and implement a robust controller locally, subject to its own constraints and contracts. The main contribution of this paper is a method to derive the contracts via a novel parameterization and a corresponding potential function that characterizes the distance to the correct composition of controllers and contracts, where all contracts are held. We show that the potential function is convex in the contract parameters. This enables the subsystems to negotiate the contracts with the gradient information from the dual of their local synthesis optimization problems in a distributed way, facilitating compositional control synthesis that scales to large systems. We present numerical examples, including a scalability study on a system with tens of thousands of dimensions, and a case study on applying our method to a distributed Model Predictive Control (MPC) problem in a power system.      
### 31.Representer Theorem for Learning Koopman Operators  [ :arrow_down: ](https://arxiv.org/pdf/2208.01681.pdf)
>  In this work, the problem of learning Koopman operator of a discrete-time autonomous system is considered. The learning problem is formulated as a constrained regularized empirical loss minimization in the infinite-dimensional space of linear operators. We show that under certain but general conditions, a representer theorem holds for the learning problem. This allows reformulating the problem in a finite-dimensional space without any approximation and loss of precision. Following this, we consider various cases of regularization and constraints in the learning problem, including the operator norm, the Frobenius norm, rank, nuclear norm, and stability. Subsequently, we derive the corresponding finite-dimensional problem. Furthermore, we discuss the connection between the proposed formulation and the extended dynamic mode decomposition. Finally, we provide an illustrative numerical example.      
### 32.Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2208.01674.pdf)
>  Artificial intelligence holds great promise in medical imaging, especially histopathological imaging. However, artificial intelligence algorithms cannot fully explain the thought processes during decision-making. This situation has brought the problem of explainability, i.e., the black box problem, of artificial intelligence applications to the agenda: an algorithm simply responds without stating the reasons for the given images. To overcome the problem and improve the explainability, explainable artificial intelligence (XAI) has come to the fore, and piqued the interest of many researchers. Against this backdrop, this study examines a new and original dataset using the deep learning algorithm, and visualizes the output with gradient-weighted class activation mapping (Grad-CAM), one of the XAI applications. Afterwards, a detailed questionnaire survey was conducted with the pathologists on these images. Both the decision-making processes and the explanations were verified, and the accuracy of the output was tested. The research results greatly help pathologists in the diagnosis of paratuberculosis.      
### 33.CTooth+: A Large-scale Dental Cone Beam Computed Tomography Dataset and Benchmark for Tooth Volume Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01643.pdf)
>  Accurate tooth volume segmentation is a prerequisite for computer-aided dental analysis. Deep learning-based tooth segmentation methods have achieved satisfying performances but require a large quantity of tooth data with ground truth. The dental data publicly available is limited meaning the existing methods can not be reproduced, evaluated and applied in clinical practice. In this paper, we establish a 3D dental CBCT dataset CTooth+, with 22 fully annotated volumes and 146 unlabeled volumes. We further evaluate several state-of-the-art tooth volume segmentation strategies based on fully-supervised learning, semi-supervised learning and active learning, and define the performance principles. This work provides a new benchmark for the tooth volume segmentation task, and the experiment can serve as the baseline for future AI-based dental imaging research and clinical application development.      
### 34.Streaming-capable High-performance Architecture of Learned Image Compression Codecs  [ :arrow_down: ](https://arxiv.org/pdf/2208.01641.pdf)
>  Learned image compression allows achieving state-of-the-art accuracy and compression ratios, but their relatively slow runtime performance limits their usage. While previous attempts on optimizing learned image codecs focused more on the neural model and entropy coding, we present an alternative method to improving the runtime performance of various learned image compression models. We introduce multi-threaded pipelining and an optimized memory model to enable GPU and CPU workloads asynchronous execution, fully taking advantage of computational resources. Our architecture alone already produces excellent performance without any change to the neural model itself. We also demonstrate that combining our architecture with previous tweaks to the neural models can further improve runtime performance. We show that our implementations excel in throughput and latency compared to the baseline and demonstrate the performance of our implementations by creating a real-time video streaming encoder-decoder sample application, with the encoder running on an embedded device.      
### 35.Comparative Analysis of State-of-the-Art Deep Learning Models for Detecting COVID-19 Lung Infection from Chest X-Ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2208.01637.pdf)
>  The ongoing COVID-19 pandemic has already taken millions of lives and damaged economies across the globe. Most COVID-19 deaths and economic losses are reported from densely crowded cities. It is comprehensible that the effective control and prevention of epidemic/pandemic infectious diseases is vital. According to WHO, testing and diagnosis is the best strategy to control pandemics. Scientists worldwide are attempting to develop various innovative and cost-efficient methods to speed up the testing process. This paper comprehensively evaluates the applicability of the recent top ten state-of-the-art Deep Convolutional Neural Networks (CNNs) for automatically detecting COVID-19 infection using chest X-ray images. Moreover, it provides a comparative analysis of these models in terms of accuracy. This study identifies the effective methodologies to control and prevent infectious respiratory diseases. Our trained models have demonstrated outstanding results in classifying the COVID-19 infected chest x-rays. In particular, our trained models MobileNet, EfficentNet, and InceptionV3 achieved a classification average accuracy of 95\%, 95\%, and 94\% test set for COVID-19 class classification, respectively. Thus, it can be beneficial for clinical practitioners and radiologists to speed up the testing, detection, and follow-up of COVID-19 cases.      
### 36.Physiological Signal Processing in Heart Rate Variability Measurement: A Focus on Spectral Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2208.02234.pdf)
>  Fast Fourier Transform (FFT) relies on the HRV frequency-domain analysis techniques. It requires re-sampling of the inherently unevenly sampled heartbeat time-series (RR tachogram) to produce an evenly sampled time series of the heartbeat. However, re-sampling of the heartbeat time -- series is found to produce a substantial error when estimating an artificial RR tachogram.      
### 37.Blockchain associated machine learning and IoT based hypoglycemia detection system with auto-injection feature  [ :arrow_down: ](https://arxiv.org/pdf/2208.02222.pdf)
>  Hypoglycemia is an unpleasant phenomenon caused by low blood glucose. The disease can lead a person to death or a high level of body damage. To avoid significant damage, patients need sugar. The research aims at implementing an automatic system to detect hypoglycemia and perform automatic sugar injections to save a life. Receiving the benefits of the internet of things (IoT), the sensor data was transferred using the hypertext transfer protocol (HTTP) protocol. To ensure the safety of health-related data, blockchain technology was utilized. The glucose sensor and smartwatch data were processed via Fog and sent to the cloud. A Random Forest algorithm was proposed and utilized to decide hypoglycemic events. When the hypoglycemic event was detected, the system sent a notification to the mobile application and auto-injection device to push the condensed sugar into the victims body. XGBoost, k-nearest neighbors (KNN), support vector machine (SVM), and decision tree were implemented to compare the proposed models performance. The random forest performed 0.942 testing accuracy, better than other models in detecting hypoglycemic events. The systems performance was measured in several conditions, and satisfactory results were achieved. The system can benefit hypoglycemia patients to survive this disease.      
### 38.Multimodal sensor fusion in the latent representation space  [ :arrow_down: ](https://arxiv.org/pdf/2208.02183.pdf)
>  A new method for multimodal sensor fusion is introduced. The technique relies on a two-stage process. In the first stage, a multimodal generative model is constructed from unlabelled training data. In the second stage, the generative model serves as a reconstruction prior and the search manifold for the sensor fusion tasks. The method also handles cases where observations are accessed only via subsampling i.e. compressed sensing. We demonstrate the effectiveness and excellent performance on a range of multimodal fusion experiments such as multisensory classification, denoising, and recovery from subsampled observations.      
### 39.Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2208.02089.pdf)
>  In recent years, considerable advancements have been made in the area of Generative Adversarial Networks (GANs), particularly with the advent of style-based architectures that address many key shortcomings - both in terms of modeling capabilities and network interpretability. Despite these improvements, the adoption of such approaches in the domain of satellite imagery is not straightforward. Typical vision datasets used in generative tasks are well-aligned and annotated, and exhibit limited variability. In contrast, satellite imagery exhibits great spatial and spectral variability, wide presence of fine, high-frequency details, while the tedious nature of annotating satellite imagery leads to annotation scarcity - further motivating developments in unsupervised learning. In this light, we present the first pre-trained style- and wavelet-based GAN model that can readily synthesize a wide gamut of realistic satellite images in a variety of settings and conditions - while also preserving high-frequency information. Furthermore, we show that by analyzing the intermediate activations of our network, one can discover a multitude of interpretable semantic directions that facilitate the guided synthesis of satellite images in terms of high-level concepts (e.g., urbanization) without using any form of supervision. Via a set of qualitative and quantitative experiments we demonstrate the efficacy of our framework, in terms of suitability for downstream tasks (e.g., data augmentation), quality of synthetic imagery, as well as generalization capabilities to unseen datasets.      
### 40.Audio-visual scene classification via contrastive event-object alignment and semantic-based fusion  [ :arrow_down: ](https://arxiv.org/pdf/2208.02086.pdf)
>  Previous works on scene classification are mainly based on audio or visual signals, while humans perceive the environmental scenes through multiple senses. Recent studies on audio-visual scene classification separately fine-tune the largescale audio and image pre-trained models on the target dataset, then either fuse the intermediate representations of the audio model and the visual model, or fuse the coarse-grained decision of both models at the clip level. Such methods ignore the detailed audio events and visual objects in audio-visual scenes (AVS), while humans often identify different scenes through audio events and visual objects within and the congruence between them. To exploit the fine-grained information of audio events and visual objects in AVS, and coordinate the implicit relationship between audio events and visual objects, this paper proposes a multibranch model equipped with contrastive event-object alignment (CEOA) and semantic-based fusion (SF) for AVSC. CEOA aims to align the learned embeddings of audio events and visual objects by comparing the difference between audio-visual event-object pairs. Then, visual objects associated with certain audio events and vice versa are accentuated by cross-attention and undergo SF for semantic-level fusion. Experiments show that: 1) the proposed AVSC model equipped with CEOA and SF outperforms the results of audio-only and visual-only models, i.e., the audio-visual results are better than the results from a single modality. 2) CEOA aligns the embeddings of audio events and related visual objects on a fine-grained level, and the SF effectively integrates both; 3) Compared with other large-scale integrated systems, the proposed model shows competitive performance, even without using additional datasets and data augmentation tricks.      
### 41.Learning Shape Control of Elastoplastic Deformable Linear Objects  [ :arrow_down: ](https://arxiv.org/pdf/2208.02067.pdf)
>  Deformable object manipulation tasks have long been regarded as challenging robotic problems. However, until recently very little work has been done on the subject, with most robotic manipulation methods being developed for rigid objects. Deformable objects are more difficult to model and simulate, which has limited the use of model-free Reinforcement Learning (RL) strategies, due to their need for large amounts of data that can only be satisfied in simulation. This paper proposes a new shape control task for Deformable Linear Objects (DLOs). More notably, we present the first study on the effects of elastoplastic properties on this type of problem. Objects with elastoplasticity such as metal wires, are found in various applications and are challenging to manipulate due to their nonlinear behavior. We first highlight the challenges of solving such a manipulation task from an RL perspective, particularly in defining the reward. Then, based on concepts from differential geometry, we propose an intrinsic shape representation using discrete curvature and torsion. Finally, we show through an empirical study that in order to successfully solve the proposed task using Deep Deterministic Policy Gradient (DDPG), the reward needs to include intrinsic information about the shape of the DLO.      
### 42.Nonsmooth Herglotz variational principle  [ :arrow_down: ](https://arxiv.org/pdf/2208.02033.pdf)
>  In this paper, the theory of smooth action-dependent Lagrangian mechanics (also known as contact Lagrangians) is extended to a non-smooth context appropriate for collision problems. In particular, we develop a Herglotz variational principle for non-smooth action-dependent Lagrangians which leads to the preservation of energy and momentum at impacts. By defining appropriately a Legendre transform, we can obtain the Hamilton equations of motion for the corresponding non-smooth Hamiltonian system. We apply the result to a billiard problem in the presence of dissipation.      
### 43.Vision-Based Safety System for Barrierless Human-Robot Collaboration  [ :arrow_down: ](https://arxiv.org/pdf/2208.02010.pdf)
>  Human safety has always been the main priority when working near an industrial robot. With the rise of Human-Robot Collaborative environments, physical barriers to avoiding collisions have been disappearing, increasing the risk of accidents and the need for solutions that ensure a safe Human-Robot Collaboration. This paper proposes a safety system that implements Speed and Separation Monitoring (SSM) type of operation. For this, safety zones are defined in the robot's workspace following current standards for industrial collaborative robots. A deep learning-based computer vision system detects, tracks, and estimates the 3D position of operators close to the robot. The robot control system receives the operator's 3D position and generates 3D representations of them in a simulation environment. Depending on the zone where the closest operator was detected, the robot stops or changes its operating speed. Three different operation modes in which the human and robot interact are presented. Results show that the vision-based system can correctly detect and classify in which safety zone an operator is located and that the different proposed operation modes ensure that the robot's reaction and stop time are within the required time limits to guarantee safety.      
### 44.Cruise Controllers for Lane-Free Ring-Roads based on Control Lyapunov Functions  [ :arrow_down: ](https://arxiv.org/pdf/2208.01977.pdf)
>  The paper introduces novel families of cruise controllers for autonomous vehicles on lane-free ring-roads. The design of the cruise controllers is based on the appropriate selection of a Control Lyapunov Function expressed on measures of the energy of the system with the kinetic energy expressed in ways similar to Newtonian or relativistic mechanics. The derived feedback laws (cruise controllers) are decentralized (per vehicle), as each vehicle determines its control input based on: (i) its own state; (ii) either only the distance from adjacent vehicles (inviscid cruise controllers) or the state of adjacent vehicles (viscous cruise controllers); and (iii) its distance from the boundaries of the ring-road. A detailed analysis of the differences and similarities between lane-free straight roads and lane-free ring-roads is also presented.      
### 45.Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoisin  [ :arrow_down: ](https://arxiv.org/pdf/2208.01948.pdf)
>  Unpaired image denoising has achieved promising development over the last few years. Regardless of the performance, methods tend to heavily rely on underlying noise properties or any assumption which is not always practical. Alternatively, if we can ground the problem from a structural perspective rather than noise statistics, we can achieve a more robust solution. with such motivation, we propose a self-supervised denoising scheme that is unpaired and relies on spatial degradation followed by a regularized refinement. Our method shows considerable improvement over previous methods and exhibited consistent performance over different data domains.      
### 46.A Multi-Dimensional Matrix Pencil-Based Channel Prediction Method for Massive MIMO with Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2208.01935.pdf)
>  This paper addresses the mobility problem in massive multiple-input multiple-output systems, which leads to significant performance losses in the practical deployment of the fifth generation mobile communication networks. We propose a novel channel prediction method based on multi-dimensional matrix pencil (MDMP), which estimates the path parameters by exploiting the angular-frequency-domain and angular-time-domain structures of the wideband channel. The MDMP method also entails a novel path pairing scheme to pair the delay and Doppler, based on the super-resolution property of the angle estimation. Our method is able to deal with the realistic constraint of time-varying path delays introduced by user movements, which has not been considered so far in the literature. We prove theoretically that in the scenario with time-varying path delays, the prediction error converges to zero with the increasing number of the base station (BS) antennas, providing that only two arbitrary channel samples are known. We also derive a lower-bound of the number of the BS antennas to achieve a satisfactory performance. Simulation results under the industrial channel model of 3GPP demonstrate that our proposed MDMP method approaches the performance of the stationary scenario even when the users' velocity reaches 120 km/h and the latency of the channel state information is as large as 16 ms.      
### 47.The SJTU System for Short-duration Speaker Verification Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2208.01933.pdf)
>  This paper presents the SJTU system for both text-dependent and text-independent tasks in short-duration speaker verification (SdSV) challenge 2021. In this challenge, we explored different strong embedding extractors to extract robust speaker embedding. For text-independent task, language-dependent adaptive snorm is explored to improve the system performance under the cross-lingual verification condition. For text-dependent task, we mainly focus on the in-domain fine-tuning strategies based on the model pre-trained on large-scale out-of-domain data. In order to improve the distinction between different speakers uttering the same phrase, we proposed several novel phrase-aware fine-tuning strategies and phrase-aware neural PLDA. With such strategies, the system performance is further improved. Finally, we fused the scores of different systems, and our fusion systems achieved 0.0473 in Task1 (rank 3) and 0.0581 in Task2 (rank 8) on the primary evaluation metric.      
### 48.Self-Supervised Speaker Verification Using Dynamic Loss-Gate and Label Correction  [ :arrow_down: ](https://arxiv.org/pdf/2208.01928.pdf)
>  For self-supervised speaker verification, the quality of pseudo labels decides the upper bound of the system due to the massive unreliable labels. In this work, we propose dynamic loss-gate and label correction (DLG-LC) to alleviate the performance degradation caused by unreliable estimated labels. In DLG, we adopt Gaussian Mixture Model (GMM) to dynamically model the loss distribution and use the estimated GMM to distinguish the reliable and unreliable labels automatically. Besides, to better utilize the unreliable data instead of dropping them directly, we correct the unreliable label with model predictions. Moreover, we apply the negative-pairs-free DINO framework in our experiments for further improvement. Compared to the best-known speaker verification system with self-supervised learning, our proposed DLG-LC converges faster and achieves 11.45%, 18.35% and 15.16% relative improvement on Vox-O, Vox-E and Vox-H trials of Voxceleb1 evaluation dataset.      
### 49.Zero-Shot Style Transfer for Gesture Animation driven by Text and Speech using Adversarial Disentanglement of Multimodal Style Encoding  [ :arrow_down: ](https://arxiv.org/pdf/2208.01917.pdf)
>  Modeling virtual agents with behavior style is one factor for personalizing human agent interaction. We propose an efficient yet effective machine learning approach to synthesize gestures driven by prosodic features and text in the style of different speakers including those unseen during training. Our model performs zero shot multimodal style transfer driven by multimodal data from the PATS database containing videos of various speakers. We view style as being pervasive while speaking, it colors the communicative behaviors expressivity while speech content is carried by multimodal signals and text. This disentanglement scheme of content and style allows us to directly infer the style embedding even of speaker whose data are not part of the training phase, without requiring any further training or fine tuning. The first goal of our model is to generate the gestures of a source speaker based on the content of two audio and text modalities. The second goal is to condition the source speaker predicted gestures on the multimodal behavior style embedding of a target speaker. The third goal is to allow zero shot style transfer of speakers unseen during training without retraining the model. Our system consists of: (1) a speaker style encoder network that learns to generate a fixed dimensional speaker embedding style from a target speaker multimodal data and (2) a sequence to sequence synthesis network that synthesizes gestures based on the content of the input modalities of a source speaker and conditioned on the speaker style embedding. We evaluate that our model can synthesize gestures of a source speaker and transfer the knowledge of target speaker style variability to the gesture generation task in a zero shot setup. We convert the 2D gestures to 3D poses and produce 3D animations. We conduct objective and subjective evaluations to validate our approach and compare it with a baseline.      
### 50.Graph Signal Processing for Heterogeneous Change Detection Part I: Vertex Domain Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2208.01881.pdf)
>  This paper provides a new strategy for the Heterogeneous Change Detection (HCD) problem: solving HCD from the perspective of Graph Signal Processing (GSP). We construct a graph for each image to capture the structure information, and treat each image as the graph signal. In this way, we convert the HCD into a GSP problem: a comparison of the responses of the two signals on different systems defined on the two graphs, which attempts to find structural differences (Part I) and signal differences (Part II) due to the changes between heterogeneous images. In this first part, we analyze the HCD with GSP from the vertex domain. We first show that for the unchanged images, their structures are consistent, and then the outputs of the same signal on systems defined on the two graphs are similar. However, once a region has changed, the local structure of the image changes, i.e., the connectivity of the vertex containing this region changes. Then, we can compare the output signals of the same input graph signal passing through filters defined on the two graphs to detect changes. We design different filters from the vertex domain, which can flexibly explore the high-order neighborhood information hidden in original graphs. We also analyze the detrimental effects of changing regions on the change detection results from the viewpoint of signal propagation. Experiments conducted on seven real data sets show the effectiveness of the vertex domain filtering based HCD method.      
### 51.Joint Optimization for Secure and Reliable Communications in Finite Blocklength Regime  [ :arrow_down: ](https://arxiv.org/pdf/2208.01870.pdf)
>  To realize ultra-reliable low latency communications with high spectral efficiency and security, we investigate a joint optimization problem for downlink communications with multiple users and eavesdroppers in the finite blocklength (FBL) regime. We formulate a multi-objective optimization problem to maximize a sum secrecy rate by developing a secure precoder and to minimize a maximum error probability and information leakage rate. The main challenges arise from the complicated multi-objective problem, non-tractable back-off factors from the FBL assumption, non-convexity and non-smoothness of the secrecy rate, and the intertwined optimization variables. To address these challenges, we adopt an alternating optimization approach by decomposing the problem into two phases: secure precoding design, and maximum error probability and information leakage rate minimization. In the first phase, we obtain a lower bound of the secrecy rate and derive a first-order Karush-Kuhn-Tucker (KKT) condition to identify local optimal solutions with respect to the precoders. Interpreting the condition as a generalized eigenvalue problem, we solve the problem by using a power iteration-based method. In the second phase, we adopt a weighted-sum approach and derive KKT conditions in terms of the error probabilities and leakage rates for given precoders. Simulations validate the proposed algorithm.      
### 52.LEO Satellite-Enabled Grant-Free Random Access with MIMO-OTFS  [ :arrow_down: ](https://arxiv.org/pdf/2208.01828.pdf)
>  This paper investigates joint channel estimation and device activity detection in the LEO satellite-enabled grant-free random access systems with large differential delay and Doppler shift. In addition, the multiple-input multiple-output (MIMO) with orthogonal time-frequency space modulation (OTFS) is utilized to combat the dynamics of the terrestrial-satellite link. To simplify the computation process, we estimate the channel tensor in parallel along the delay dimension. Then, the deep learning and expectation-maximization approach are integrated into the generalized approximate message passing with cross-correlation--based Gaussian prior to capture the channel sparsity in the delay-Doppler-angle domain and learn the hyperparameters. Finally, active devices are detected by computing energy of the estimated channel. Simulation results demonstrate that the proposed algorithms outperform conventional methods.      
### 53.Fast Hierarchical Deep Unfolding Network for Image Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2208.01827.pdf)
>  By integrating certain optimization solvers with deep neural network, deep unfolding network (DUN) has attracted much attention in recent years for image compressed sensing (CS). However, there still exist several issues in existing DUNs: 1) For each iteration, a simple stacked convolutional network is usually adopted, which apparently limits the expressiveness of these models. 2) Once the training is completed, most hyperparameters of existing DUNs are fixed for any input content, which significantly weakens their adaptability. In this paper, by unfolding the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), a novel fast hierarchical DUN, dubbed FHDUN, is proposed for image compressed sensing, in which a well-designed hierarchical unfolding architecture is developed to cooperatively explore richer contextual prior information in multi-scale spaces. To further enhance the adaptability, series of hyperparametric generation networks are developed in our framework to dynamically produce the corresponding optimal hyperparameters according to the input content. Furthermore, due to the accelerated policy in FISTA, the newly embedded acceleration module makes the proposed FHDUN save more than 50% of the iterative loops against recent DUNs. Extensive CS experiments manifest that the proposed FHDUN outperforms existing state-of-the-art CS methods, while maintaining fewer iterations.      
### 54.A Lightweight Transmission Parameter Selection Scheme Using Reinforcement Learning for LoRaWAN  [ :arrow_down: ](https://arxiv.org/pdf/2208.01824.pdf)
>  The number of IoT devices is predicted to reach 125 billion by 2023. The growth of IoT devices will intensify the collisions between devices, degrading communication performance. Selecting appropriate transmission parameters, such as channel and spreading factor (SF), can effectively reduce the collisions between long-range (LoRa) devices. However, most of the schemes proposed in the current literature are not easy to implement on an IoT device with limited computational complexity and memory. To solve this issue, we propose a lightweight transmission-parameter selection scheme, i.e., a joint channel and SF selection scheme using reinforcement learning for low-power wide area networking (LoRaWAN). In the proposed scheme, appropriate transmission parameters can be selected by simple four arithmetic operations using only Acknowledge (ACK) information. Additionally, we theoretically analyze the computational complexity and memory requirement of our proposed scheme, which verified that our proposed scheme could select transmission parameters with extremely low computational complexity and memory requirement. Moreover, a large number of experiments were implemented on the LoRa devices in the real world to evaluate the effectiveness of our proposed scheme. The experimental results demonstrate the following main phenomena. (1) Compared to other lightweight transmission-parameter selection schemes, collisions between LoRa devices can be efficiently avoided by our proposed scheme in LoRaWAN irrespective of changes in the available channels. (2) The frame success rate (FSR) can be improved by selecting access channels and using SFs as opposed to only selecting access channels. (3) Since interference exists between adjacent channels, FSR and fairness can be improved by increasing the interval of adjacent available channels.      
### 55.VQ-T: RNN Transducers using Vector-Quantized Prediction Network States  [ :arrow_down: ](https://arxiv.org/pdf/2208.01818.pdf)
>  Beam search, which is the dominant ASR decoding algorithm for end-to-end models, generates tree-structured hypotheses. However, recent studies have shown that decoding with hypothesis merging can achieve a more efficient search with comparable or better performance. But, the full context in recurrent networks is not compatible with hypothesis merging. We propose to use vector-quantized long short-term memory units (VQ-LSTM) in the prediction network of RNN transducers. By training the discrete representation jointly with the ASR network, hypotheses can be actively merged for lattice generation. Our experiments on the Switchboard corpus show that the proposed VQ RNN transducers improve ASR performance over transducers with regular prediction networks while also producing denser lattices with a very low oracle word error rate (WER) for the same beam size. Additional language model rescoring experiments also demonstrate the effectiveness of the proposed lattice generation scheme.      
### 56.Resolved Motion Control for 3D Underactuated Bipedal Walking using Linear Inverted Pendulum Dynamics and Neural Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01786.pdf)
>  We present a framework to generate periodic trajectory references for a 3D under-actuated bipedal robot, using a linear inverted pendulum (LIP) based controller with adaptive neural regulation. We use the LIP template model to estimate the robot's center of mass (CoM) position and velocity at the end of the current step, and formulate a discrete controller that determines the next footstep location to achieve a desired walking profile. This controller is equipped on the frontal plane with a Neural-Network-based adaptive term that reduces the model mismatch between the template and physical robot that particularly affects the lateral motion. Then, the foot placement location computed for the LIP model is used to generate task space trajectories (CoM and swing foot trajectories) for the actual robot to realize stable walking. We use a fast, real-time QP-based inverse kinematics algorithm that produces joint references from the task space trajectories, which makes the formulation independent of the knowledge of the robot dynamics. Finally, we implemented and evaluated the proposed approach in simulation and hardware experiments with a Digit robot obtaining stable periodic locomotion for both cases.      
### 57.Digital Twin-Assisted Efficient Reinforcement Learning for Edge Task Scheduling  [ :arrow_down: ](https://arxiv.org/pdf/2208.01781.pdf)
>  Task scheduling is a critical problem when one user offloads multiple different tasks to the edge server. When a user has multiple tasks to offload and only one task can be transmitted to server at a time, while server processes tasks according to the transmission order, the problem is NP-hard. However, it is difficult for traditional optimization methods to quickly obtain the optimal solution, while approaches based on reinforcement learning face with the challenge of excessively large action space and slow convergence. In this paper, we propose a Digital Twin (DT)-assisted RL-based task scheduling method in order to improve the performance and convergence of the RL. We use DT to simulate the results of different decisions made by the agent, so that one agent can try multiple actions at a time, or, similarly, multiple agents can interact with environment in parallel in DT. In this way, the exploration efficiency of RL can be significantly improved via DT, and thus RL can converges faster and local optimality is less likely to happen. Particularly, two algorithms are designed to made task scheduling decisions, i.e., DT-assisted asynchronous Q-learning (DTAQL) and DT-assisted exploring Q-learning (DTEQL). Simulation results show that both algorithms significantly improve the convergence speed of Q-learning by increasing the exploration efficiency.      
### 58.Reciprocity of Algorithms Solving Distributed Consensus-Based Optimization and Distributed Resource Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01777.pdf)
>  This paper aims at proposing a procedure to derive distributed algorithms for distributed consensus-based optimization by using distributed algorithms for network resource allocation and vice versa over switching networks with/without synchronous protocol. It is shown that first-order gradient distributed consensus-based optimization algorithms can be used for finding an optimal solution of distributed resource allocation with synchronous protocol under weaker assumptions than those given in the literature for non-switching (static) networks. It is shown that first-order gradient distributed resource allocation algorithms can be utilized for finding an optimal solution of distributed consensus-based optimization. The results presented here can be applied to time-varying and random directed networks with or without synchronous protocol with arbitrary initialization. As a result, several algorithms can now be used to derive distributed algorithms for both consensus-based optimization and resource allocation, that can overcome limitations of the existing results. While the focus of this paper is on the first-order gradient algorithms, it is to be noted that the results also work with second-order gradient algorithms.      
### 59.Optimizing Information Freshness Leveraging Multi-RISs in NOMA-based IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.01750.pdf)
>  This paper investigates the benefits of integrating multiple reconfigurable intelligent surfaces (RISs) in enhancing the timeliness performance of uplink Internet-of-Things (IoT) network, where IoT devices (IoTDs) upload their time-stamped status update information to a base station (BS) using non-orthogonal multiple access (NOMA). Accounting to the potential unreliable wireless channels due to the impurities of the propagation environments, such as deep fading, blockages, etc., multiple RISs are deployed in the considered IoT network to mitigate the propagation-induced impairments, to enhance the quality of the wireless links, and to ensure that the required freshness of information is achieved. In this setup, an optimization problem has been formulated to minimize the average sum Age of Information (AoI) by optimizing the transmit power of the IoTDs, the IoTDs clustering policy, and the RISs configurations. The formulated problem ends up to be a mixed-integer non-convex problem. In order to tackle this challenge, the RISs configurations are first obtained by adopting a semi-definite relaxation (SDR) approach. Then, the joint power allocation and user-clustering problem is solved using the concept of bi-level optimization, where the original problem is decomposed into an outer IoTDs clustering problem and an inner power allocation problem. Optimal closed-form expressions are derived for the inner problem and the Hungarian method is invoked to solve the outer problem. Numerical results demonstrate that our proposed approach achieves lowest AoI compared to the other baseline approaches.      
### 60.From Single Aircraft to Communities: A Neutral Interpretation of Air Traffic Complexity Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2208.01740.pdf)
>  Present air traffic complexity metrics are defined considering the interests of different management layers of ATM. These layers have different objectives which in practice compete to maximize their own goals, which leads to fragmented decision making. This fragmentation together with competing KPAs requires transparent and neutral air traffic information to pave the way for an explainable set of actions. In this paper, we introduce the concept of single aircraft complexity, to determine the contribution of each aircraft to the overall complexity of air traffic. Furthermore, we describe a methodology extending this concept to define complex communities, which are groups of interdependent aircraft that contribute the majority of the complexity in a certain airspace. In order to showcase the methodology, a tool that visualizes different outputs of the algorithm is developed. Through use-cases based on synthetic and real historical traffic, we first show that the algorithm can serve to formalize controller decisions as well as guide controllers to better decisions. Further, we investigate how the provided information can be used to increase transparency of the decision makers towards different airspace users, which serves also to increase fairness and equity. Lastly, a sensitivity analysis is conducted in order to systematically analyse how each input affects the methodology.      
### 61.Federated Deep Reinforcement Learning for Resource Allocation in O-RAN Slicing  [ :arrow_down: ](https://arxiv.org/pdf/2208.01736.pdf)
>  Recently, open radio access network (O-RAN) has become a promising technology to provide an open environment for network vendors and operators. Coordinating the x-applications (xAPPs) is critical to increase flexibility and guarantee high overall network performance in O-RAN. Meanwhile, federated reinforcement learning has been proposed as a promising technique to enhance the collaboration among distributed reinforcement learning agents and improve learning efficiency. In this paper, we propose a federated deep reinforcement learning algorithm to coordinate multiple independent xAPPs in O-RAN for network slicing. We design two xAPPs, namely a power control xAPP and a slice-based resource allocation xAPP, and we use a federated learning model to coordinate two xAPP agents to enhance learning efficiency and improve network performance. Compared with conventional deep reinforcement learning, our proposed algorithm can achieve 11% higher throughput for enhanced mobile broadband (eMBB) slices and 33% lower delay for ultra-reliable low-latency communication (URLLC) slices.      
### 62.Analysis of a microcirculatory windkessel model using photoplethysmography with green light: A pilot study  [ :arrow_down: ](https://arxiv.org/pdf/2208.01734.pdf)
>  In this study, a vasomotion quantification method using a photoplethysmography prototype, which performs near-infrared spectroscopy in combination with green light, is proposed. A structure that suppresses the motion artifact and that is held by the eyeglasses on the back of the ear enables the relative concentration changes of total hemoglobin and pulse wave amplitude to be measured during exercise with and without the presence of wind impacting the face. We established a microcirculatory windkessel model including arteriovenous anastomoses estimated from the blood flow changes in the depth direction that were acquired using three wavelengths of light and reproduced the vasomotion on a computer. The values predicted by the model were in good agreement with the measured values. The extracted vasomotion can be used to understand autonomic control by the central nervous system.      
### 63.The Importance of the Instantaneous Phase in Detecting Faces with Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.01638.pdf)
>  Convolutional Neural Networks (CNN) have provided new and accurate methods for processing digital images and videos. Yet, training CNNs is extremely demanding in terms of computational resources. Also, for specific applications, the standard use of transfer learning also tends to require far more resources than what may be needed. Furthermore, the final systems tend to operate as black boxes that are difficult to interpret. The current thesis considers the problem of detecting faces from the AOLME video dataset. The AOLME dataset consists of a large video collection of group interactions that are recorded in unconstrained classroom environments. For the thesis, still image frames were extracted at every minute from 18 24-minute videos. Then, each video frame was divided into 9x5 blocks with 50x50 pixels each. For each of the 19440 blocks, the percentage of face pixels was set as ground truth. Face detection was then defined as a regression problem for determining the face pixel percentage for each block. For testing different methods, 12 videos were used for training and validation. The remaining 6 videos were used for testing. The thesis examines the impact of using the instantaneous phase for the AOLME block-based face detection application. For comparison, the thesis compares the use of the Frequency Modulation image based on the instantaneous phase, the use of the instantaneous amplitude, and the original gray scale image. To generate the FM and AM inputs, the thesis uses dominant component analysis that aims to decrease the training overhead while maintaining interpretability.      
