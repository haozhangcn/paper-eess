# ArXiv eess --Tue, 23 Aug 2022
### 1.GEO Payload Power Minimization: Joint Precoding and Beam Hopping Design  [ :arrow_down: ](https://arxiv.org/pdf/2208.10474.pdf)
>  This paper aims to jointly determine linear precoding (LP) vectors, beam hopping (BH), and discrete DVB-S2X transmission rates for the GEO satellite communication systems to minimize the payload power consumption and satisfy ground users' demands within a time window. Regarding constraint on the maximum number of illuminated beams per time slot, the technical requirement is formulated as a sparse optimization problem in which the hardware-related beam illumination energy is modeled in a sparsity form of the LP vectors. To cope with this problem, the compressed sensing method is employed to transform the sparsity parts into the quadratic form of precoders. Then, an iterative window-based algorithm is developed to update the LP vectors sequentially to an efficient solution. Additionally, two other two-phase frameworks are also proposed for comparison purposes. In the first phase, these methods aim to determine the MODCOD transmission schemes for users to meet their demands by using a heuristic approach or DNN tool. In the second phase, the LP vectors of each time slot will be optimized separately based on the determined MODCOD schemes.      
### 2.Nonlinear Control Allocation Using A Piecewise Multi-Linear Representation  [ :arrow_down: ](https://arxiv.org/pdf/2208.10411.pdf)
>  Nonlinear control allocation is an important part of modern nonlinear dynamic inversion based flight control systems which require highly accurate model of aircraft aerodynamics. Generally, an accurately implemented onboard model determines how well the system nonlinearities can be canceled. Thus, more accurate model results in better cancellation, leading to the higher performance of the controller. In this paper, a new control system is presented that combines nonlinear dynamic inversion with a piecewise multi-linear representation based control allocation. The piecewise multi-linear representation is developed through a new generalization of Kronecker product for block matrices, combined with the canonical piecewise linear representation of nonlinear functions. Analytical expressions for the Jacobian of the piecewise multi-linear model are also presented. Proposed formulation gives an exact representation of piecewise multi-linear aerodynamic data and thus is capable of accurately modeling nonlinear aerodynamics over the entire flight envelope of an aircraft. Resulting nonlinear controller is applied to control of a tailless flying wing aircraft with ten independently operating control surfaces. The simulation results for two innovative control surface configurations indicate that perfect control allocation performance can be achieved, leading to better tracking performance compared with ordinary polynomial-based control allocation.      
### 3.Enhanced IoT Batteryless D2D Communications Using Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2208.10379.pdf)
>  Recent research on reconfigurable intelligent surfaces (RIS) suggests that the RIS panel, containing passive elements, enhances channel performance for the internet of things (IoT) systems by reflecting transmitted signals to the receiving nodes. This paper investigates RIS panel assisted-wireless network to instigate minimal base station (BS) transmit power in the form of energy harvesting for batteryless IoT sensors to maximize bits transmission in the significant multi-path environment, such as urban areas. Batteryless IoT sensors harvest energy through the RIS panel from external sources, such as from nearby BS radio frequency (RF) signal in the first optimal time frame, for a given time frame. The bits transmission among IoT sensors, followed by a device-to-device (D2D) communications protocol, is maximized using harvested energy in the final optimal time frame. The bits transmission is at least equal to the number of bits sampled by the IoT sensor. We formulate a non-convex mixed-integer non-linear problem to maximize the number of communicating bits subject to energy harvesting from BS RF signals, RIS panel energy consumption, and required time. We propose a robust solution by presenting an iterative algorithm. We perform extensive simulation results based on the 3GPP Urban Micro channel model to validate our model.      
### 4.What Does a One-Bit Quanta Image Sensor Offer?  [ :arrow_down: ](https://arxiv.org/pdf/2208.10350.pdf)
>  The one-bit quanta image sensor (QIS) is a photon-counting device that captures image intensities using binary bits. Assuming that the analog voltage generated at the floating diffusion of the photodiode follows a Poisson-Gaussian distribution, the sensor produces either a ``1'' if the voltage is above a certain threshold or ``0'' if it is below the threshold. The concept of this binary sensor has been proposed for more than a decade, and physical devices have been built to realize the concept. However, what benefits does a one-bit QIS offer compared to a conventional multi-bit CMOS image sensor? Besides the known empirical results, are there theoretical proofs to support these findings? <br>The goal of this paper is to provide new theoretical support from a signal processing perspective. In particular, it is theoretically found that the sensor can offer three benefits: (1) Low-light: One-bit QIS performs better at low-light because it has a low read noise, and its one-bit quantization can produce an error-free measurement. However, this requires the exposure time to be appropriately configured. (2) Frame rate: One-bit sensors can operate at a much higher speed because a response is generated as soon as a photon is detected. However, in the presence of read noise, there exists an optimal frame rate beyond which the performance will degrade. A Closed-form expression of the optimal frame rate is derived. (3) Dynamic range: One-bit QIS offers a higher dynamic range. The benefit is brought by two complementary characteristics of the sensor: nonlinearity and exposure bracketing. The decoupling of the two factors is theoretically proved, and closed-form expressions are derived.      
### 5.Optimal Topology Transition  [ :arrow_down: ](https://arxiv.org/pdf/2208.10338.pdf)
>  Network topology has significant impacts on operational performance of power systems. While extensive research efforts have been devoted to optimization of network topology for improving various system performances, the problem of how to transition from the initial topology to the desired optimal topology requires study. To address this problem, we propose the concept of optimal topology transition (OTT). This aims to find the topology transition trajectory from an initial topology to a desired terminal topology, which optimizes certain transition performance and satisfies operational constraints. The OTT problem is further formulated as a mixed-integer program under certain assumptions. Next, we propose the formulation of transition-embedded topology optimization that is capable of optimizing network topology and its transition trajectory simultaneously. Considering the time complexity of directly solving the mixed-integer programs, an efficient problem-specific solution algorithm is developed. Finally, numerical studies demonstrate the effectiveness of the proposed OTT and transition-embedded topology optimization models, as well as the superiority of the obtained optimal transition trajectories compared to ad hoc transition trajectories.      
### 6.Exploiting Temporal Structures of Cyclostationary Signals for Data-Driven Single-Channel Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2208.10325.pdf)
>  We study the problem of single-channel source separation (SCSS), and focus on cyclostationary signals, which are particularly suitable in a variety of application domains. Unlike classical SCSS approaches, we consider a setting where only examples of the sources are available rather than their models, inspiring a data-driven approach. For source models with underlying cyclostationary Gaussian constituents, we establish a lower bound on the attainable mean squared error (MSE) for any separation method, model-based or data-driven. Our analysis further reveals the operation for optimal separation and the associated implementation challenges. As a computationally attractive alternative, we propose a deep learning approach using a U-Net architecture, which is competitive with the minimum MSE estimator. We demonstrate in simulation that, with suitable domain-informed architectural choices, our U-Net method can approach the optimal performance with substantially reduced computational burden.      
### 7.Optimising Chest X-Rays for Image Analysis by Identifying and Removing Confounding Factors  [ :arrow_down: ](https://arxiv.org/pdf/2208.10320.pdf)
>  During the COVID-19 pandemic, the sheer volume of imaging performed in an emergency setting for COVID-19 diagnosis has resulted in a wide variability of clinical CXR acquisitions. This variation is seen in the CXR projections used, image annotations added and in the inspiratory effort and degree of rotation of clinical images. The image analysis community has attempted to ease the burden on overstretched radiology departments during the pandemic by developing automated COVID-19 diagnostic algorithms, the input for which has been CXR imaging. Large publicly available CXR datasets have been leveraged to improve deep learning algorithms for COVID-19 diagnosis. Yet the variable quality of clinically-acquired CXRs within publicly available datasets could have a profound effect on algorithm performance. COVID-19 diagnosis may be inferred by an algorithm from non-anatomical features on an image such as image labels. These imaging shortcuts may be dataset-specific and limit the generalisability of AI systems. Understanding and correcting key potential biases in CXR images is therefore an essential first step prior to CXR image analysis. In this study, we propose a simple and effective step-wise approach to pre-processing a COVID-19 chest X-ray dataset to remove undesired biases. We perform ablation studies to show the impact of each individual step. The results suggest that using our proposed pipeline could increase accuracy of the baseline COVID-19 detection algorithm by up to 13%.      
### 8.Data-Driven Control of Distributed Event-Triggered Network Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.10303.pdf)
>  The present paper deals with data-driven event-triggered control of a class of unknown discrete-time interconnected systems (a.k.a. network systems). To this end, we start by putting forth a novel distributed event-triggering transmission strategy based on periodic sampling, under which a model-based stability criterion for the closed-loop network system is derived, by leveraging a discrete-time looped-functional approach. Marrying the model-based criterion with a data-driven system representation recently developed in the literature, a purely data-driven stability criterion expressed in the form of linear matrix inequalities (LMIs) is established. Meanwhile, the data-driven stability criterion suggests a means for co-designing the event-triggering coefficient matrix and the feedback control gain matrix using only some offline collected state-input data. Finally, numerical results corroborate the efficacy of the proposed distributed data-driven ETS in cutting off data transmissions and the co-design procedure.      
### 9.A Survey on Chirp Spread Spectrum-based Waveform Design for IoT  [ :arrow_down: ](https://arxiv.org/pdf/2208.10274.pdf)
>  Long Range (LoRa) is one of the most promising and widespread chirp spread spectrum (CSS)-based physical (PHY) layer technique for low-power wide-area networks (LPWANs). Using different spreading factors, LoRa can attain different spectral/energy efficiencies, and can target multitude of Internet-of-Thing (IoT) applications. However, one of the limiting factors for LoRa is the low bit rate. Little to no effort has been made in order to improve the achievable rate of LoRa, until recently, when a number of CSS-based PHY layer LoRa alternative are proposed for LPWANs. In this survey, for the first time, we present a comprehensive waveform design of these CSS-based schemes that have been proposed between 2019 to 2022. In total, fifteen alternatives to LoRa are compared. Other survey articles related to LoRa mostly tackle different issues, such as LoRa networking, LoRa deployment in massive IoT networks, and LoRa architectures, etc. This survey, on the other hand, comprehensively elucidates the waveform design of LoRa alternatives. The CSS schemes studied in this survey are divided into single chirp, multiple chirp, and index modulation based on the multiplexing pattern of the chirps. Complete transceiver architecture of these CSS schemes is studied, and performance is evaluated in terms of energy efficiency (EE), spectral efficiency (SE), bit-error rate (BER) performance in additive white Gaussian noise, BER in the presence of phase and frequency offsets. It has been observed that the EE, SE and robustness against the offsets is primarily linked to transmit symbol frame structure. The public versions of the MATLAB codes for the CSS schemes studied in this survey shall be provided to promote reproducible research.      
### 10.Doppler Exploitation in Bistatic mmWave Radio SLAM  [ :arrow_down: ](https://arxiv.org/pdf/2208.10204.pdf)
>  Networks in 5G and beyond utilize millimeter wave (mmWave) radio signals, large bandwidths, and large antenna arrays, which bring opportunities in jointly localizing the user equipment and mapping the propagation environment, termed as simultaneous localization and mapping (SLAM). Existing approaches mainly rely on delays and angles, and ignore the Doppler, although it contains geometric information. In this paper, we study the benefits of exploiting Doppler in SLAM through deriving the posterior CramÃ©r-Rao bounds (PCRBs) and formulating the extended Kalman-Poisson multi-Bernoulli sequential filtering solution with Doppler as one of the involved measurements. Both theoretical PCRB analysis and simulation results demonstrate the efficacy of utilizing Doppler.      
### 11.Algorithms of Real-Time Navigation and Control of Autonomous Unmanned Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2208.10172.pdf)
>  The rapid development of robotics has benefited by more and more people putting their attention to it. With the demand for robots is growing for the purpose of fulfilling tasks instead of humans, how to control the robot better is becoming a hot topic. For obstacle avoidance, we proposed algorithms for both 2D planar environments and 3D space environments. The example cases we raise are those that need to be addressed but have always been ignored. In addition, we put efforts into trajectory planning for robots. The two scenarios we set are self-driving cars on the road and reconnaissance and surveillance of drones. For future expectations, there are some possible directions. How to combine traditional navigation algorithms and high-tech algorithms together so as to fulfill the tasks perfectly while the computational efficiency is not too high is a worthy topic. In addition, extending the obstacle avoidance algorithms to more competitive situations. Moreover, cooperation among multi robots are worth attention by researchers. All in all, there is still a long way to go for the development of navigation and control of mobile robots. Despite this, we believe we do not need to wait for too long time to see the revolution of robots.      
### 12.Noise-Adaptive Intelligent Programmable Meta-Imager  [ :arrow_down: ](https://arxiv.org/pdf/2208.10171.pdf)
>  We present an intelligent programmable computational meta-imager that tailors its sequence of coherent scene illuminations not only to a specific information-extraction task (e.g., object recognition) but also adapts to different types and levels of noise. We systematically study how the learned illumination patterns depend on the noise, and we discover that trends in intensity and overlap of the learned illumination patterns can be understood intuitively. We conduct our analysis based on an analytical coupled-dipole forward model of a microwave dynamic metasurface antenna (DMA); we formulate a differentiable end-to-end information-flow pipeline comprising the programmable physical measurement process including noise as well as the subsequent digital processing layers. This pipeline allows us to jointly inverse-design the programmable physical weights (DMA configurations that determine the coherent scene illuminations) and the trainable digital weights. Our noise-adaptive intelligent meta-imager outperforms the conventional use of pseudo-random illumination patterns most clearly under conditions that make the extraction of sufficient task-relevant information challenging: latency constraints (limiting the number of allowed measurements) and strong noise. Programmable microwave meta-imagers in indoor surveillance and earth observation will be confronted with these conditions.      
### 13.ArNet-ECG: Deep Learning for the Detection of Atrial Fibrillation from the Raw Electrocardiogram  [ :arrow_down: ](https://arxiv.org/pdf/2208.10153.pdf)
>  Atrial fibrillation (AF) is the most prevalent heart arrhythmia. AF manifests on the electrocardiogram (ECG) though irregular beat-to-beat time interval variation, the absence of P-wave and the presence of fibrillatory waves (f-wave). We hypothesize that a deep learning (DL) approach trained on the raw ECG will enable robust detection of AF events and the estimation of the AF burden (AFB). We further hypothesize that the performance reached leveraging the raw ECG will be superior to previously developed methods using the beat-to-beat interval variation time series. Consequently, we develop a new DL algorithm, denoted ArNet-ECG, to robustly detect AF events and estimate the AFB from the raw ECG and benchmark this algorithms against previous work. Methods: A dataset including 2,247 adult patients and totaling over 53,753 hours of continuous ECG from the University of Virginia (UVAF) was used. Results: ArNet-ECG obtained an F1 of 0.96 and ArNet2 obtained an F1 0.94. Discussion and conclusion: ArNet-ECG outperformed ArNet2 thus demonstrating that using the raw ECG provides added performance over the beat-to-beat interval time series. The main reason found for explaining the higher performance of ArNet-ECG was its high performance on atrial flutter examples versus poor performance on these recordings for ArNet2.      
### 14.Deep 3D Vessel Segmentation based on Cross Transformer Network  [ :arrow_down: ](https://arxiv.org/pdf/2208.10148.pdf)
>  The coronary microvascular disease poses a great threat to human health. Computer-aided analysis/diagnosis systems help physicians intervene in the disease at early stages, where 3D vessel segmentation is a fundamental step. However, there is a lack of carefully annotated dataset to support algorithm development and evaluation. On the other hand, the commonly-used U-Net structures often yield disconnected and inaccurate segmentation results, especially for small vessel structures. In this paper, motivated by the data scarcity, we first construct two large-scale vessel segmentation datasets consisting of 100 and 500 computed tomography (CT) volumes with pixel-level annotations by experienced radiologists. To enhance the U-Net, we further propose the cross transformer network (CTN) for fine-grained vessel segmentation. In CTN, a transformer module is constructed in parallel to a U-Net to learn long-distance dependencies between different anatomical regions; and these dependencies are communicated to the U-Net at multiple stages to endow it with global awareness. Experimental results on the two in-house datasets indicate that this hybrid model alleviates unexpected disconnections by considering topological information across regions. Our codes, together with the trained models are made publicly available at <a class="link-external link-https" href="https://github.com/qibaolian/ctn" rel="external noopener nofollow">this https URL</a>.      
### 15.Doubling the Number of Connected Devices in Narrow-band Internet of Things while Maintaining System Performance: An STC-based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2208.10112.pdf)
>  Narrow-band Internet of Things (NB-IoT) is a low-power wide-area network (LPWAN) method that was first launched by the 3rd generation partnership project (3GPP) Rel- 13 with the purpose of enabling low-cost, low-power and wide-area cellular connection for the Internet of Things (IoT). As the demand for over-the-air services grows and with the number of linked wireless devices reaching 100 billion, wireless spectrum is becoming scarce, necessitating creative techniques that can increase the number of connected devices within a restricted spectral resource in order to satisfy service needs. Consequently, it is vital that academics develop efficient solutions to fulfill the quality of service (QoS) criteria of the NB-IoT in the context of 5th generation (5G) and beyond. This study paves the way for 5G networks and beyond to have increased capacity and data rate for NB-IoT. Whereas, this article suggests a method for increasing the number of connected devices by using a technique known as symbol time compression (STC). The suggested method compresses the occupied bandwidth of each device without increasing complexity, losing data throughput or bit error rate (BER) performance. The STC approach is proposed in the literature to work with the conventional orthogonal frequency division multiplexing (OFDM) to reduce bandwidth usage by 50% and improve the peak-to-average power ratio (PAPR). Specifically, An STC-based method is proposed that exploits the unused bandwidth to double the number of connected devices while keeping system performance and complexity. Furthermore, the {\mu}-law companding technique is leveraged to reduce the PAPR of the transmitted signals. The obtained simulation results reveal that the proposed approach using the {\mu}-law companding technique increases the transmitted data by twice and reduces the PAPR by 3.22 dB while maintaining the same complexity and BER.      
### 16.Iterative Sparse Recovery based Passive Localization in Perceptive Mobile Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.10092.pdf)
>  Perceptive mobile networks (PMNs) were proposed to integrate sensing capability into current cellular networks where multiple sensing nodes (SNs) can collaboratively sense the same targets. Besides the active sensing in traditional radar systems, passive sensing based on the uplink communication signals from mobile user equipment may play a more important role in PMNs, especially for targets with weak electromagnetic wave reflection, e.g., pedestrians. However, without the properly designed active sensing waveform, passive sensing normally suffers from low signal to noise power ratio (SNR). As a result, most existing methods require a large number of data samples to achieve an accurate estimate of the covariance matrix for the received signals, based on which a power spectrum is constructed for localization purposes. Such a requirement will create heavy communication workload for PMNs because the data samples need to be transferred over the network for collaborative sensing. To tackle this issue, in this paper we leverage the sparse structure of the localization problem to reduce the searching space and propose an iterative sparse recovery (ISR) algorithm that estimates the covariance matrix and the power spectrum in an iterative manner. Experiment results show that, with very few samples in the low SNR regime, the ISR algorithm can achieve much better localization performance than existing methods.      
### 17.Abstraction-Free Control Synthesis to Satisfy Temporal Logic Constraints under Sensor Faults and Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2208.10060.pdf)
>  We study the problem of synthesizing a controller to satisfy a complex task in the presence of sensor faults and attacks. We model the task using Gaussian distribution temporal logic (GDTL), and propose a solution approach that does not rely on computing any finite abstraction to model the system. We decompose the GDTL specification into a sequence of reach-avoid sub-tasks. We develop a class of fault-tolerant finite time convergence control barrier functions (CBFs) to guarantee that a dynamical system reaches a set within finite time almost surely in the presence of malicious attacks. We use the fault-tolerant finite time convergence CBFs to guarantee the satisfaction of `reach' property. We ensure `avoid' part in each sub-task using fault-tolerant zeroing CBFs. These fault-tolerant CBFs formulate a set of linear constraints on the control input for each sub-task. We prove that if the error incurred by system state estimation is bounded by a certain threshold, then our synthesized controller fulfills each reach-avoid sub-task almost surely for any possible sensor fault and attack, and thus the GDTL specification is satisfied with probability one. We demonstrate our proposed approach using a numerical study on the coordination of two wheeled mobile robots.      
### 18.Observer-based Leader-following Consensus for Positive Multi-agent Systems Over Time-varying Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2208.10051.pdf)
>  This paper is devoted to the leader-following consensus problem for a collection of discrete-time positive linear systems. In this problem, the state variables of all agents are confined in the positive orthant and we aim at distributed rules for the followers to track a reference signal generated by a positive leader. To tackle such a problem, we first propose a novel distributed positive observer of the positive leader over time-varying communication topologies. Then, we construct both state feedback and output feedback rules for these followers combing the developed distributed positive observers to solve the formulated leader-following positive consensus problem. We also provide a simulation example to illustrate the effectiveness of our design.      
### 19.Towards Unifying Resilience and Sustainability for Transportation Infrastructure Systems: Conceptual Framework, Critical Indicators, and Research Needs  [ :arrow_down: ](https://arxiv.org/pdf/2208.10039.pdf)
>  Sustainability aspects of transportation infrastructure systems primarily focus on system performance based on environmental, social, and economic impacts. In contrast, resilience aspects demonstrate the ability to withstand external shocks i.e. robustness as well as to recover from the loss of functionality due to such disruptions i.e. rapidity. Therefore, sustainability and resilience are two key aspects which should be given adequate attention during the planning, design, construction, operations, and maintenance phases of any civil infrastructure system. As both concepts are equally important to sustain an infrastructure for a longer duration, their concurrent assessments within a unified framework are highly desirable. While there has been a recent focus towards solving this dilemma, review of existing studies revealed the lack of such unifying frameworks that can quantify sustainability and resilience indicators to simultaneously assess system performance. Moreover, a single decision or performance indicator could reinforce one and undermine another. As such, this study proposed a forward-looking unification framework, where the sustainability and resilience of transportation infrastructure systems can be analyzed simultaneously. In this regard, the proposed unifying framework is explained using seven critical indicators including emission, speed, temperature, energy consumption, delay, mobility, and accessibility. This study also investigates the interdependencies, relationships, and tradeoffs between sustainability and resilience based on these indices. While some indices would help the system to attain both at the same time, they are compromised in some cases. Finally, the study identifies immediate research needs as well as the ones in the long-term.      
### 20.A Two-phase On-line Joint Scheduling of Pricing and Control for Welfare Maximization of Charging Station  [ :arrow_down: ](https://arxiv.org/pdf/2208.10011.pdf)
>  The large adoption of EVs brings practical interest to the operation optimization of the charging station. The joint scheduling of pricing and charging control will achieve a win-win situation both for the charging station and EV drivers, thus enhancing the operational capability of the station. We consider this important problem in this paper and make the following contributions. First, a joint scheduling model of pricing and charging control is developed to maximize the expected social welfare of the charging station considering the Quality of Service and the price fluctuation sensitivity of EV drivers. It is formulated as a Markov decision process with variance criterion to capture uncertainties during operation. Second, a two-phase on-line policy learning algorithm is proposed to solve this joint scheduling problem. In the first phase, it implements event-based policy iteration to find the optimal pricing scheme, while in the second phase, it implements scenario-based model predictive control for smart charging under the updated pricing scheme. Third, by leveraging the performance difference theory, the optimality of the proposed algorithm is theoretically analyzed. Numerical experiments for a charging station with distributed generation and hydrogen energy storage demonstrate the effectiveness of the proposed method and the improved social warfare of the charging station.      
### 21.An Improved Equiangular Division Algorithm for SBR based Ray Tracing Channel Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2208.10009.pdf)
>  Compared with image method (IM) based ray tracing (RT), shooting and bouncing ray (SBR) method is characterized by fast speed but low accuracy. In this paper, an iterative precise algorithm based on equiangular division is proposed to make rough paths accurate, allowing SBR to calculate exact channel information. Different ray launching methods are compared to obtain a better launching method. By using equiangular division, rays are launched more uniformly from transmitter (Tx) compared with the current equidistant division method. With the proposed iterative precise algorithm, error of angle of departure (AOD) and angle of arrival (AOA) is below 0.01 degree. The relationship between the number of iterations and error reduction is also given. It is illustrated that the proposed method has the same accuracy as IM by comparing the power delay profile (PDP) and angle distribution of paths. This can solve the problem of low accuracy brougth by SBR.      
### 22.An Improved Ray Tracing Acceleration Algorithm Based on Bounding Volume Hierarchies  [ :arrow_down: ](https://arxiv.org/pdf/2208.10008.pdf)
>  Ray tracing is an efficient channel modeling method. However, the traditional ray tracing method has high computation complexity. To solve this problem, an improved bounding volume hierarchies (BVH) algorithm is proposed in this paper. Based on surface area heuristic (SAH) and spatial distance, the proposed algorithm can effectively reduce the number of unnecessary intersection tests between ray and triangular facets. In addition, the algorithm fully considers the influence of ray action range, which can not only make up for the defects of spatial division based on uniform grid method and k-dimensional (KD) tree, but also solve the problem of unsatisfactory spatial division based on traditional BVH algorithm. The simulation results show that compared with the traditional BVH algorithm, the proposed algorithm can improve the computation efficiency by 20% to 35% while ensuring the computation accuracy.      
### 23.A Weighted Random Forest Based PositioningAlgorithm for 6G Indoor Communications  [ :arrow_down: ](https://arxiv.org/pdf/2208.10007.pdf)
>  Due to the indoor none-line-of-sight (NLoS) propagation and multi-access interference (MAI), it is a great challenge to achieve centimeter-level positioning accuracy in indoor scenarios. However, the sixth generation (6G) wireless communications provide a good opportunity for the centimeter-level positioning. In 6G, the millimeter wave (mmWave) and terahertz (THz) communications have ultra-broad bandwidth so that the channel state information (CSI) will have a high resolution. In this paper, a weighted random forest (WRF) based indoor positioning algorithm using CSI based channel fingerprint feature is proposed to achieve high-precision positioning for 6G indoor communications. In addition, ray-tracing (RT) is used to improve the efficiency of establishing channel fingerprint database. The simulation results demonstrate the accuracy and robustness of the proposed algorithm. It is shown that the positioning accuracy of the algorithm is stable within 6 cm in different indoor scenarios with the channel fingerprint database established at 0.2 m intervals.      
### 24.An SBR Based Ray Tracing Channel Modeling Method for THz and Massive MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2208.10006.pdf)
>  Terahertz (THz) communication and the application of massive multiple-input multiple-output (MIMO) technology have been proved significant for the sixth generation (6G) communication systems, and have gained global interests. In this paper, we employ the shooting and bouncing ray (SBR) method integrated with acceleration technology to model THz and massive MIMO channel. The results of ray tracing (RT) simulation in this paper, i.e., angle of departure (AoD), angle of arrival (AoA), and power delay profile (PDP) under the frequency band supported by the commercial RT software Wireless Insite (WI) are in agreement with those produced by WI. Based on the Kirchhoff scattering effect on material surfaces and atmospheric absorption loss showing at THz frequency band, the modified propagation models of Fresnel reflection coefficients and free-space attenuation are consistent with the measured results. For massive MIMO, the channel capacity and the stochastic power distribution are analyzed. The results indicate the applicability of SBR method for building deterministic models of THz and massive MIMO channels with extensive functions and acceptable accuracy.      
### 25.Spatially Selective Active Noise Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.09997.pdf)
>  Wearable active noise control (ANC) systems are commonly designed to achieve maximal sound reduction regardless of the incident direction of the sound. When desired sound is present, the state-of-the-art methods add a separate system to reconstruct it, often with distortion and latency. In this work, we propose a multi-channel ANC system that only controls the sound from the undesired directions. The system truly preserves the desired sound instead of reproducing it. The proposed algorithm imposes a spatial constraint on the hybrid ANC cost function to achieve spatial selectivity. We simulated the proposed algorithm based on a microphone array on a pair of augmented eye-glasses and compared it with the existing methods in the literature. Not only did the proposed system provide better noise reduction while preserving the physical sound wave from the desired source, but it also consumed much less energy, which is critical for lightweight wearable devices. Overall, the proposed method has demonstrated significant advantages over the state-of-the-art methods.      
### 26.Repetitive transcranial magnetic stimulation and epilepsy: A brief essay  [ :arrow_down: ](https://arxiv.org/pdf/2208.09936.pdf)
>  During the last three decades, many studies have been conducted in the field of treatment with non-invasive methods. In this way, researchers try to use alternative methods including the use of electromagnetic waves in the treatment of diseases. As a result, the therapeutic use of electromagnetic waves in the treatment of neurological diseases has made significant progress. Among the various techniques that have revolutionized the non-invasive treatment of neurological disorders, there is a remarkable technique called Repetitive Transcranial Magnetic Stimulation (rTMS). On the other hand, there is a wide range of neurological conditions (like epilepsy) that are somewhat drug-resistant or can only be controlled with high-risk treatments. In this article, the effect of rTMS on epilepsy is investigated.      
### 27.Forensic Dental Age Estimation Using Modified Deep Learning Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2208.09799.pdf)
>  Dental age is one of the most reliable methods to identify an individual's age. By using dental panoramic radiography (DPR) images, physicians and pathologists in forensic sciences try to establish the chronological age of individuals with no valid legal records or registered patients. The current methods in practice demand intensive labor, time, and qualified experts. The development of deep learning algorithms in the field of medical image processing has improved the sensitivity of predicting truth values while reducing the processing speed of imaging time. This study proposed an automated approach to estimate the forensic ages of individuals ranging in age from 8 to 68 using 1,332 DPR images. Initially, experimental analyses were performed with the transfer learning-based models, including InceptionV3, DenseNet201, EfficientNetB4, MobileNetV2, VGG16, and ResNet50V2; and accordingly, the best-performing model, InceptionV3, was modified, and a new neural network model was developed. Reducing the number of the parameters already available in the developed model architecture resulted in a faster and more accurate dental age estimation. The performance metrics of the results attained were as follows: mean absolute error (MAE) was 3.13, root mean square error (RMSE) was 4.77, and correlation coefficient R$^2$ was 87%. It is conceivable to propose the new model as potentially dependable and practical ancillary equipment in forensic sciences and dental medicine.      
### 28.Simultaneous Beam and User Selection for the Beamspace mmWave/THz Massive MIMO Downlink  [ :arrow_down: ](https://arxiv.org/pdf/2208.09792.pdf)
>  Beamspace millimeter-wave (mmWave) and terahertz (THz) massive MIMO constitute attractive schemes for next-generation communications, given their abundant bandwidth and high throughput. However, their user and beam selection problem has to be efficiently addressed. Inspired by this challenge, we develop low-complexity solutions explicitly. We introduce the dirty paper coding (DPC) into the joint user and beam selection problem, unveil the compelling properties of the DPC sum rate optimization in beamspace massive MIMO and exploit them for substantially simplifying the problem. We also develop three algorithms for solving the simplified problem, each having its unique merits. Furthermore, we derive the sum rate bound of the algorithms and analyze their complexity. Our simulation results validate the effectiveness of the proposed design and analysis, confirming their superiority over prior solutions.      
### 29.Joint Communications and Sensing Employing Optimized MIMO-OFDM Signals  [ :arrow_down: ](https://arxiv.org/pdf/2208.09791.pdf)
>  Joint communication and sensing (JCAS) has the potential to improve the overall energy, cost and frequency efficiency of IoT systems. As a first effort, we propose to optimize the MIMO-OFDM data symbols carried by sub-carriers for better time- and spatial-domain signal orthogonality. This not only boosts the availability of usable signals for JCAS, but also significantly facilitates Internet-of-Things (IoT) devices to perform high-quality sensing. We establish an optimization problem that modifies data symbols on sub-carriers to enhance the above-mentioned signal orthogonality. We also develop an efficient algorithm to solve the problem based on the majorization-minimization framework. Moreover, we discover unique signal structures and features from the newly modeled problem, which substantially reduce the complexity of majorizing the objective function. We also develop new projectors to enforce the feasibility of the obtained solution. Simulations show that, compared with the original communication waveform to achieve the same sensing performance, the optimized waveform can reduce the signal-to-noise ratio (SNR) requirement by 3~4.5 dB, while the SNR loss for the uncoded bit error rate is only 1~1.5 dB.      
### 30.Preemptive Scheduling of EV Charging for Providing Demand Response Services  [ :arrow_down: ](https://arxiv.org/pdf/2208.09790.pdf)
>  We develop a new algorithm for scheduling the charging process of a large number of electric vehicles (EVs) over a finite horizon. We assume that EVs arrive at the charging stations with different charge levels and different flexibility windows. The arrival process is assumed to have a known distribution and that the charging process of EVs can be preemptive. We pose the scheduling problem as a dynamic program with constraints. We show that the resulting formulation leads to a monotone dynamic program with Lipschitz continuous value functions that are robust against perturbation of system parameters. We propose a simulation based fitted value iteration algorithm to determine the value function approximately, and derive the sample complexity for computing the approximately optimal solution.      
### 31.A New Radar Signal Multiparameter-Based Deinterleaving Method  [ :arrow_down: ](https://arxiv.org/pdf/2208.09786.pdf)
>  Radar signal deinterleaving has been extensively and thoroughly investigated in the electronic reconnaissance field. In this work, a new radar signal multiparameter-based deinterleaving method is proposed. In this method, semantic information composed of the pulse repetition interval (PRI), pulse width (PW), radio frequency (RF), and pulse amplitude (PA) of a radar signal is used to deinterleave radar signals. A bidirectional gated recurrent unit (BGRU) is employed, and the difference of time of arrival (DTOA)/RF, DTOA/PW, and DTOA/PA of the pulse stream are input into the BGRU. Based on the semantic information contained in different radar signal types, each pulse in the obtained pulse stream is classified according to the semantic information category, and the radar signals are deinterleaved. Compared to the PRI-based deinterleaving methods, the proposed method utilizes the multidimensional information of radar signals. As a result, higher deinterleaving accuracy is achieved. Compared to other existing radar signal multiparameter-based deinterleaving methods, the proposed method can adapt to radar signals with complex parameter features as well as to complex signal environments, and can complete the use of multiparameter in one step.      
### 32.High-Performance Transmission Mechanism Design of Multi-Stream Carrier Aggregation for 5G Non-Standalone Network  [ :arrow_down: ](https://arxiv.org/pdf/2208.09785.pdf)
>  Multi-stream carrier aggregation is a key technology to expand bandwidth and improve the throughput of the fifth-generation wireless communication systems. However, due to the diversified propagation properties of different frequency bands, the traffic migration task is much more challenging, especially in hybrid sub-6 GHz and millimeter wave bands scenario. Existing schemes either neglected to consider the transmission rate difference between multi-stream carrier, or only consider simple low mobility scenario. In this paper, we propose a low-complexity traffic splitting algorithm based on fuzzy proportional integral derivative control mechanism. The proposed algorithm only relies on the local radio link control buffer information of sub-6 GHz and mmWave bands, while frequent feedback from user equipment (UE) side is minimized. As shown in the numerical examples, the proposed traffic splitting mechanism can achieve more than 90% link resource utilization ratio for different UE transmission requirements with different mobilities, which corresponds to 10% improvement if compared with conventional baselines.      
### 33.Green Joint Communications and Sensing Employing Analogue Multi-Beam Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2208.09782.pdf)
>  Joint communications and sensing (JCAS) is potentially a hallmark technology for the sixth generation mobile network (6G). Most existing JCAS designs are based on digital arrays, analog arrays with tunable phase shifters, or hybrid arrays, which are effective but are generally complicated to design and power inefficient. This article introduces the energy-efficient and easy-to-design multi-beam antenna arrays (MBAAs) for JCAS. Using pre-designed and fixed analog devices, such as lens or Butler matrix, MBAA can simultaneously steer multiple beams yet with negligible power consumption compared with other techniques. Moreover, MBAAs enable flexible beam synthesis, accurate angle-of-arrival estimation, and easy handling/utilization of the beam squint effect. All these features have not been well captured by the JACS community yet. To promote the awareness of them, we intuitively illustrate them and also exploit them for constructing a multi-beam JCAS framework. Finally, the challenges and opportunities are discussed to foster the development of green JCAS systems.      
### 34.Co-optimizing Distributed Energy Resources in Linear Complexity under Net Energy Metering  [ :arrow_down: ](https://arxiv.org/pdf/2208.09781.pdf)
>  The co-optimization of behind-the-meter distributed energy resources is considered for residential and commercial prosumers. The distributed energy resources include renewable generations, flexible demands, and battery storage. An energy management system schedules the consumptions and battery storage based on locally available stochastic renewables by maximizing the expected operation surplus under the net energy metering tariff. A stochastic dynamic programming formulation is introduced for which structural properties of the dynamic optimization are derived. A closed-form scheduling of co-optimized consumption and storage is proposed, which achieves optimality when the storage capacity constraint is nonbinding. The closed-form solution results in a linear-complexity storage-consumption co-optimization that can be implemented in a decentralized fashion. The economic benefits of the prosumers and the distribution system operator are evaluated in numerical simulations.      
### 35.Visualising Model Training via Vowel Space for Text-To-Speech Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.09775.pdf)
>  With the recent developments in speech synthesis via machine learning, this study explores incorporating linguistics knowledge to visualise and evaluate synthetic speech model training. If changes to the first and second formant (in turn, the vowel space) can be seen and heard in synthetic speech, this knowledge can inform speech synthesis technology developers. A speech synthesis model trained on a large General American English database was fine-tuned into a New Zealand English voice to identify if the changes in the vowel space of synthetic speech could be seen and heard. The vowel spaces at different intervals during the fine-tuning were analysed to determine if the model learned the New Zealand English vowel space. Our findings based on vowel space analysis show that we can visualise how a speech synthesis model learns the vowel space of the database it is trained on. Perception tests confirmed that humans could perceive when a speech synthesis model has learned characteristics of the speech database it is training on. Using the vowel space as an intermediary evaluation helps understand what sounds are to be added to the training database and build speech synthesis models based on linguistics knowledge.      
### 36.Study on the Concept and Development of a Mobile Incubator  [ :arrow_down: ](https://arxiv.org/pdf/2208.09697.pdf)
>  Creating the best possible conditions is essential for proper cell growth. Incubators, a type of biotechnological instrument, are used to simulate this condition and maintain the cells within them. The processes involved in creating a mobile incubator, which are essential for monitoring a cell culture's physiological parameters, are outlined in this article. The goal is to keep image-taking during cell development from compromising data accuracy. The cell culture is prone to contamination once it has been removed from the incubation environment for further monitoring. The proposed approach allows for on-the-go monitoring of the cell culture. Moreover, it enables constant monitoring.      
### 37.PARSE challenge 2022: Pulmonary Arteries Segmentation using Swin U-Net Transformer(Swin UNETR) and U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2208.09636.pdf)
>  In this work, we present our proposed method to segment the pulmonary arteries from the CT scans using Swin UNETR and U-Net-based deep neural network architecture. Six models, three models based on Swin UNETR, and three models based on 3D U-net with residual units were ensemble using a weighted average to make the final segmentation masks. Our team achieved a multi-level dice score of 84.36 percent through this method. The code of our work is available on the following link: <a class="link-external link-https" href="https://github.com/akansh12/parse2022" rel="external noopener nofollow">this https URL</a>. This work is part of the MICCAI PARSE 2022 challenge.      
### 38.MISO Wireless Localization in The Presence of Reconfigurable Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2208.09546.pdf)
>  Reconfigurable Intelligent Surface (RIS) plays a pivotal role in the sixth generation networks to enhance communication rate and localization accuracy. In this letter, we propose a positioning algorithm in a RIS-assisted environment, where the Base Station (BS) is multi-antenna, and the Mobile Station (MS) is single-antenna. We show that our method can achieve a high-precision positioning if the line-of-sight (LOS) is obstructed and three RISs are available. We send several known signals to the receiver in different time slots and change the phase shifters of the RISs simultaneously in a proper way, and we propose a technique to eliminate the destructive effect of the angle-of-departure (AoD) in order to determine the distances between each RISs and the MS. The accuracy of the proposed algorithm is better than the algorithms which do not estimate the AoD, shown in the numerical result section.      
### 39.Blind Image Deblurring with Unknown Kernel Size and Substantial Noise  [ :arrow_down: ](https://arxiv.org/pdf/2208.09483.pdf)
>  Blind image deblurring (BID) has been extensively studied in computer vision and adjacent fields. Modern methods for BID can be grouped into two categories: single-instance methods that deal with individual instances using statistical inference and numerical optimization, and data-driven methods that train deep-learning models to deblur future instances directly. Data-driven methods can be free from the difficulty in deriving accurate blur models, but are fundamentally limited by the diversity and quality of the training data -- collecting sufficiently expressive and realistic training data is a standing challenge. In this paper, we focus on single-instance methods that remain competitive and indispensable. However, most such methods do not prescribe how to deal with unknown kernel size and substantial noise, precluding practical deployment. Indeed, we show that several state-of-the-art (SOTA) single-instance methods are unstable when the kernel size is overspecified, and/or the noise level is high. On the positive side, we propose a practical BID method that is stable against both, the first of its kind. Our method builds on the recent ideas of solving inverse problems by integrating the physical models and structured deep neural networks, without extra training data. We introduce several crucial modifications to achieve the desired stability. Extensive empirical tests on standard synthetic datasets, as well as real-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and practicality of our BID method compared to SOTA single-instance as well as data-driven methods. The code of our method is available at: \url{<a class="link-external link-https" href="https://github.com/sun-umn/Blind-Image-Deblurring" rel="external noopener nofollow">this https URL</a>}.      
### 40.Survey of Machine Learning Techniques To Predict Heartbeat Arrhythmias  [ :arrow_down: ](https://arxiv.org/pdf/2208.10463.pdf)
>  Many works in biomedical computer science research use machine learning techniques to give accurate results. However, these techniques may not be feasible for real-time analysis of data pulled from live hospital feeds. In this project, different machine learning techniques are compared from various sources to find one that provides not only high accuracy but also low latency and memory overhead to be used in real-world health care systems.      
### 41.Minimax-Optimal Multi-Agent RL in Zero-Sum Markov Games With a Generative Model  [ :arrow_down: ](https://arxiv.org/pdf/2208.10458.pdf)
>  This paper is concerned with two-player zero-sum Markov games -- arguably the most basic setting in multi-agent reinforcement learning -- with the goal of learning a Nash equilibrium (NE) sample-optimally. All prior results suffer from at least one of the two obstacles: the curse of multiple agents and the barrier of long horizon, regardless of the sampling protocol in use. We take a step towards settling this problem, assuming access to a flexible sampling mechanism: the generative model. Focusing on non-stationary finite-horizon Markov games, we develop a learning algorithm $\mathsf{Nash}\text{-}\mathsf{Q}\text{-}\mathsf{FTRL}$ and an adaptive sampling scheme that leverage the optimism principle in adversarial learning (particularly the Follow-the-Regularized-Leader (FTRL) method), with a delicate design of bonus terms that ensure certain decomposability under the FTRL dynamics. Our algorithm learns an $\varepsilon$-approximate Markov NE policy using <br>$$ \widetilde{O}\bigg( \frac{H^4 S(A+B)}{\varepsilon^2} \bigg) $$ samples, where $S$ is the number of states, $H$ is the horizon, and $A$ (resp.~$B$) denotes the number of actions for the max-player (resp.~min-player). This is nearly un-improvable in a minimax sense. Along the way, we derive a refined regret bound for FTRL that makes explicit the role of variance-type quantities, which might be of independent interest.      
### 42.Examining Audio Communication Mechanisms for Supervising Fleets of Agricultural Robots  [ :arrow_down: ](https://arxiv.org/pdf/2208.10455.pdf)
>  Agriculture is facing a labor crisis, leading to increased interest in fleets of small, under-canopy robots (agbots) that can perform precise, targeted actions (e.g., crop scouting, weeding, fertilization), while being supervised by human operators remotely. However, farmers are not necessarily experts in robotics technology and will not adopt technologies that add to their workload or do not provide an immediate payoff. In this work, we explore methods for communication between a remote human operator and multiple agbots and examine the impact of audio communication on the operator's preferences and productivity. We develop a simulation platform where agbots are deployed across a field, randomly encounter failures, and call for help from the operator. As the agbots report errors, various audio communication mechanisms are tested to convey which robot failed and what type of failure occurs. The human is tasked with verbally diagnosing the failure while completing a secondary task. A user study was conducted to test three audio communication methods: earcons, single-phrase commands, and full sentence communication. Each participant completed a survey to determine their preferences and each method's overall effectiveness. Our results suggest that the system using single phrases is the most positively perceived by participants and may allow for the human to complete the secondary task more efficiently. The code is available at: <a class="link-external link-https" href="https://github.com/akamboj2/Agbot-Sim" rel="external noopener nofollow">this https URL</a>.      
### 43.The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation  [ :arrow_down: ](https://arxiv.org/pdf/2208.10441.pdf)
>  This paper reports on the second GENEA Challenge to benchmark data-driven automatic co-speech gesture generation. Participating teams used the same speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. Unlike when comparing different research papers, differences in results are here only due to differences between methods, enabling direct comparison between systems. This year's dataset was based on 18 hours of full-body motion capture, including fingers, of different persons engaging in dyadic conversation. Ten teams participated in the challenge across two tiers: full-body and upper-body gesticulation. For each tier we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech signal. Our evaluations decouple human-likeness from gesture appropriateness, which previously was a major challenge in the field. <br>The evaluation results are a revolution, and a revelation. Some synthetic conditions are rated as significantly more human-like than human motion capture. To the best of our knowledge, this has never been shown before on a high-fidelity avatar. On the other hand, all synthetic motion is found to be vastly less appropriate for the speech than the original motion-capture recordings. Additional material is available via the project website at <a class="link-external link-https" href="https://youngwoo-yoon.github.io/GENEAchallenge2022/" rel="external noopener nofollow">this https URL</a>      
### 44.Fast identification and stabilization of unknown linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.10392.pdf)
>  In the present paper, we present a simple algorithm for stabilizing an unknown linear time-invariant system in the minimum time of $n+m$ steps, where $n$ is the dimension of the state of the considered system and $m$ is the dimension of the input. Our approach is based on first identifying the system matrices on the controllable subspace, which we do in minimum time by applying a suitable exciting input signal and then choosing a stabilizing controller gain.      
### 45.Multi-View Attention Transfer for Efficient Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2208.10367.pdf)
>  Recent deep learning models have achieved high performance in speech enhancement; however, it is still challenging to obtain a fast and low-complexity model without significant performance degradation. Previous knowledge distillation studies on speech enhancement could not solve this problem because their output distillation methods do not fit the speech enhancement task in some aspects. In this study, we propose multi-view attention transfer (MV-AT), a feature-based distillation, to obtain efficient speech enhancement models in the time domain. Based on the multi-view features extraction model, MV-AT transfers multi-view knowledge of the teacher network to the student network without additional parameters. The experimental results show that the proposed method consistently improved the performance of student models of various sizes on the Valentini and deep noise suppression (DNS) datasets. MANNER-S-8.1GF with our proposed method, a lightweight model for efficient deployment, achieved 15.4x and 4.71x fewer parameters and floating-point operations (FLOPs), respectively, compared to the baseline model with similar performance.      
### 46.Data-driven distributionally robust optimization over a network via distributed semi-infinite programming  [ :arrow_down: ](https://arxiv.org/pdf/2208.10321.pdf)
>  This paper focuses on solving a data-driven distributionally robust optimization problem over a network of agents. The agents aim to minimize the worst-case expected cost computed over a Wasserstein ambiguity set that is centered at the empirical distribution. The samples of the uncertainty are distributed across the agents. Our approach consists of reformulating the problem as a semi-infinite program and then designing a distributed algorithm that solves a generic semi-infinite problem that has the same information structure as the reformulated problem. In particular, the decision variables consist of both local ones that agents are free to optimize over and global ones where they need to agree on. Our distributed algorithm is an iterative procedure that combines the notions of distributed ADMM and the cutting-surface method. We show that the iterates converge asymptotically to a solution of the distributionally robust problem to any pre-specified accuracy. Simulations illustrate our results.      
### 47.Event-Triggered Model Predictive Control with Deep Reinforcement Learning for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2208.10302.pdf)
>  Event-triggered model predictive control (eMPC) is a popular optimal control method with an aim to alleviate the computation and/or communication burden of MPC. However, it generally requires priori knowledge of the closed-loop system behavior along with the communication characteristics for designing the event-trigger policy. This paper attempts to solve this challenge by proposing an efficient eMPC framework and demonstrate successful implementation of this framework on the autonomous vehicle path following. First of all, a model-free reinforcement learning (RL) agent is used to learn the optimal event-trigger policy without the need for a complete dynamical system and communication knowledge in this framework. Furthermore, techniques including prioritized experience replay (PER) buffer and long-short term memory (LSTM) are employed to foster exploration and improve training efficiency. In this paper, we use the proposed framework with three deep RL algorithms, i.e., Double Q-learning (DDQN), Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC), to solve this problem. Experimental results show that all three deep RL-based eMPC (deep-RL-eMPC) can achieve better evaluation performance than the conventional threshold-based and previous linear Q-based approach in the autonomous path following. In particular, PPO-eMPC with LSTM and DDQN-eMPC with PER and LSTM obtains a superior balance between the closed-loop control performance and event-trigger frequency. The associated code is open-sourced and available at: <a class="link-external link-https" href="https://github.com/DangFengying/RL-based-event-triggered-MPC" rel="external noopener nofollow">this https URL</a>.      
### 48.Physical LiDAR Simulation in Real-Time Engine  [ :arrow_down: ](https://arxiv.org/pdf/2208.10295.pdf)
>  Designing and validating sensor applications and algorithms in simulation is an important step in the modern development process. Furthermore, modern open-source multi-sensor simulation frameworks are moving towards the usage of video-game engines such as the Unreal Engine. Simulation of a sensor such as a LiDAR can prove to be difficult in such real-time software. In this paper we present a GPU-accelerated simulation of LiDAR based on its physical properties and interaction with the environment. We provide a generation of the depth and intensity data based on the properties of the sensor as well as the surface material and incidence angle at which the light beams hit the surface. It is validated against a real LiDAR sensor and shown to be accurate and precise although highly depended on the spectral data used for the material properties.      
### 49.Contributions Ã  l'asservissement visuel et Ã  l'imagerie en mÃ©decine  [ :arrow_down: ](https://arxiv.org/pdf/2208.10284.pdf)
>  This manuscript gives an overview of my research work carried out within the FEMTO-ST institute in BesanÃ§on, more particularly in the Automatic and Micro-Mechatronic Systems (AS2M) department. It is above all the result of my (co)-supervision of interns, PhD students and postdocs. I would like to pay tribute to them, for their major contribution to scientific research, here and elsewhere.      
### 50.Meta-Learning Online Control for Linear Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.10259.pdf)
>  In this paper, we consider the problem of finding a meta-learning online control algorithm that can learn across the tasks when faced with a sequence of $N$ (similar) control tasks. Each task involves controlling a linear dynamical system for a finite horizon of $T$ time steps. The cost function and system noise at each time step are adversarial and unknown to the controller before taking the control action. Meta-learning is a broad approach where the goal is to prescribe an online policy for any new unseen task exploiting the information from other tasks and the similarity between the tasks. We propose a meta-learning online control algorithm for the control setting and characterize its performance by \textit{meta-regret}, the average cumulative regret across the tasks. We show that when the number of tasks are sufficiently large, our proposed approach achieves a meta-regret that is smaller by a factor $D/D^{*}$ compared to an independent-learning online control algorithm which does not perform learning across the tasks, where $D$ is a problem constant and $D^{*}$ is a scalar that decreases with increase in the similarity between tasks. Thus, when the sequence of tasks are similar the regret of the proposed meta-learning online control is significantly lower than that of the naive approaches without meta-learning. We also present experiment results to demonstrate the superior performance achieved by our meta-learning algorithm.      
### 51.Time Encoding via Unlimited Sampling: Theory, Algorithms and Hardware Validation  [ :arrow_down: ](https://arxiv.org/pdf/2208.10234.pdf)
>  An alternative to conventional uniform sampling is that of time encoding, which converts continuous-time signals into streams of trigger times. This gives rise to Event-Driven Sampling (EDS) models. The data-driven nature of EDS acquisition is advantageous in terms of power consumption and time resolution and is inspired by the information representation in biological nervous systems. If an analog signal is outside a predefined dynamic range, then EDS generates a low density of trigger times, which in turn leads to recovery distortion due to aliasing. In this paper, inspired by the Unlimited Sensing Framework (USF), we propose a new EDS architecture that incorporates a modulo nonlinearity prior to acquisition that we refer to as the modulo EDS or MEDS. In MEDS, the modulo nonlinearity folds high dynamic range inputs into low dynamic range amplitudes, thus avoiding recovery distortion. In particular, we consider the asynchronous sigma-delta modulator (ASDM), previously used for low power analog-to-digital conversion. This novel MEDS based acquisition is enabled by a recent generalization of the modulo nonlinearity called modulo-hysteresis. We design a mathematically guaranteed recovery algorithm for bandlimited inputs based on a sampling rate criterion and provide reconstruction error bounds. We go beyond numerical experiments and also provide a first hardware validation of our approach, thus bridging the gap between theory and practice, while corroborating the conceptual underpinnings of our work.      
### 52.Local Geometry of Nonconvex Spike Deconvolution from Low-Pass Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2208.10073.pdf)
>  Spike deconvolution is the problem of recovering the point sources from their convolution with a known point spread function, which plays a fundamental role in many sensing and imaging applications. In this paper, we investigate the local geometry of recovering the parameters of point sources$\unicode{x2014}$including both amplitudes and locations$\unicode{x2014}$by minimizing a natural nonconvex least-squares loss function measuring the observation residuals. We propose preconditioned variants of gradient descent (GD), where the search direction is scaled via some carefully designed preconditioning matrices. We begin with a simple fixed preconditioner design, which adjusts the learning rates of the locations at a different scale from those of the amplitudes, and show it achieves a linear rate of convergence$\unicode{x2014}$in terms of entrywise errors$\unicode{x2014}$when initialized close to the ground truth, as long as the separation between the true spikes is sufficiently large. However, the convergence rate slows down significantly when the dynamic range of the source amplitudes is large. To bridge this issue, we introduce an adaptive preconditioner design, which compensates for the learning rates of different sources in an iteration-varying manner based on the current estimate. The adaptive design provably leads to an accelerated convergence rate that is independent of the dynamic range, highlighting the benefit of adaptive preconditioning in nonconvex spike deconvolution. Numerical experiments are provided to corroborate the theoretical findings.      
### 53.Sampling Gaussian Stationary Random Fields: A Stochastic Realization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2208.10059.pdf)
>  Generating large-scale samples of stationary random fields is of great importance in the fields such as geomaterial modeling and uncertainty quantification. Traditional methodologies based on covariance matrix decomposition have the diffculty of being computationally expensive, which is even more serious when the dimension of the random field is large. This paper proposes an effcient stochastic realization approach for sampling Gaussian stationary random fields from a systems and control point of view. Specifically, we take the exponential and Gaussian covariance functions as examples and make a decoupling assumption when there are multiple dimensions. Then a rational spectral density is constructed in each dimension using techniques from covariance extension, and the corresponding autoregressive moving-average (ARMA) model is obtained via spectral factorization. As a result, samples of the random field with a specific covariance function can be generated very effciently in the space domain by implementing the ARMA recursion using a white noise input. Such a procedure is computationally cheap due to the fact that the constructed ARMA model has a low order. Furthermore, the same method is integrated to multiscale simulations where interpolations of the generated samples are achieved when one zooms into finer scales. Both theoretical analysis and simulation results show that our approach performs favorably compared with covariance matrix decomposition methods.      
### 54.Equalization and Brightness Mapping Modes of Color-to-Gray Projection Operators  [ :arrow_down: ](https://arxiv.org/pdf/2208.09950.pdf)
>  In this article, the conversion of color RGB images to grayscale is covered by characterizing the mathematical operators used to project 3 color channels to a single one. Based on the fact that most operators assign each of the $256^3$ colors a single gray level, ranging from 0 to 255, they are clustering algorithms that distribute the color population into 256 clusters of increasing brightness. To visualize the way operators work the sizes of the clusters and the average brightness of each cluster are plotted. The equalization mode (EQ) introduced in this work focuses on cluster sizes, while the brightness mapping (BM) mode describes the CIE L* luminance distribution per cluster. Three classes of EQ modes and two classes of BM modes were found in linear operators, defining a 6-class taxonomy. The theoretical/methodological framework introduced was applied in a case study considering the equal-weights uniform operator, the NTSC standard operator, and an operator chosen as ideal to lighten the faces of black people to improve facial recognition in current biased classifiers. It was found that most current metrics used to assess the quality of color-to-gray conversions better assess one of the two BM mode classes, but the ideal operator chosen by a human team belongs to the other class. Therefore, this cautions against using these general metrics for specific purpose color-to-gray conversions. It should be noted that eventual applications of this framework to non-linear operators can give rise to new classes of EQ and BM modes. The main contribution of this article is to provide a tool to better understand color to gray converters in general, even those based on machine learning, within the current trend of better explainability of models.      
### 55.Improving GANs for Long-Tailed Data through Group Spectral Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2208.09932.pdf)
>  Deep long-tailed learning aims to train useful deep networks on practical, real-world imbalanced distributions, wherein most labels of the tail classes are associated with a few samples. There has been a large body of work to train discriminative models for visual recognition on long-tailed distribution. In contrast, we aim to train conditional Generative Adversarial Networks, a class of image generation models on long-tailed distributions. We find that similar to recognition, state-of-the-art methods for image generation also suffer from performance degradation on tail classes. The performance degradation is mainly due to class-specific mode collapse for tail classes, which we observe to be correlated with the spectral explosion of the conditioning parameter matrix. We propose a novel group Spectral Regularizer (gSR) that prevents the spectral explosion alleviating mode collapse, which results in diverse and plausible image generation even for tail classes. We find that gSR effectively combines with existing augmentation and regularization techniques, leading to state-of-the-art image generation performance on long-tailed data. Extensive experiments demonstrate the efficacy of our regularizer on long-tailed datasets with different degrees of imbalance.      
### 56.HST: Hierarchical Swin Transformer for Compressed Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2208.09885.pdf)
>  Compressed Image Super-resolution has achieved great attention in recent years, where images are degraded with compression artifacts and low-resolution artifacts. Since the complex hybrid distortions, it is hard to restore the distorted image with the simple cooperation of super-resolution and compression artifacts removing. In this paper, we take a step forward to propose the Hierarchical Swin Transformer (HST) network to restore the low-resolution compressed image, which jointly captures the hierarchical feature representations and enhances each-scale representation with Swin transformer, respectively. Moreover, we find that the pretraining with Super-resolution (SR) task is vital in compressed image super-resolution. To explore the effects of different SR pretraining, we take the commonly-used SR tasks (e.g., bicubic and different real super-resolution simulations) as our pretraining tasks, and reveal that SR plays an irreplaceable role in the compressed image super-resolution. With the cooperation of HST and pre-training, our HST achieves the fifth place in AIM 2022 challenge on the low-quality compressed image super-resolution track, with the PSNR of 23.51dB. Extensive experiments and ablation studies have validated the effectiveness of our proposed methods.      
### 57.Multi-task Learning for Monocular Depth and Defocus Estimations with Real Images  [ :arrow_down: ](https://arxiv.org/pdf/2208.09848.pdf)
>  Monocular depth estimation and defocus estimation are two fundamental tasks in computer vision. Most existing methods treat depth estimation and defocus estimation as two separate tasks, ignoring the strong connection between them. In this work, we propose a multi-task learning network consisting of an encoder with two decoders to estimate the depth and defocus map from a single focused image. Through the multi-task network, the depth estimation facilitates the defocus estimation to get better results in the weak texture region and the defocus estimation facilitates the depth estimation by the strong physical connection between the two maps. We set up a dataset (named ALL-in-3D dataset) which is the first all-real image dataset consisting of 100K sets of all-in-focus images, focused images with focus depth, depth maps, and defocus maps. It enables the network to learn features and solid physical connections between the depth and real defocus images. Experiments demonstrate that the network learns more solid features from the real focused images than the synthetic focused images. Benefiting from this multi-task structure where different tasks facilitate each other, our depth and defocus estimations achieve significantly better performance than other state-of-art algorithms. The code and dataset will be publicly available at <a class="link-external link-https" href="https://github.com/cubhe/MDDNet" rel="external noopener nofollow">this https URL</a>.      
### 58.Representation Learning with Graph Neural Networks for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2208.09830.pdf)
>  Learning expressive representation is crucial in deep learning. In speech emotion recognition (SER), vacuum regions or noises in the speech interfere with expressive representation learning. However, traditional RNN-based models are susceptible to such noise. Recently, Graph Neural Network (GNN) has demonstrated its effectiveness for representation learning, and we adopt this framework for SER. In particular, we propose a cosine similarity-based graph as an ideal graph structure for representation learning in SER. We present a Cosine similarity-based Graph Convolutional Network (CoGCN) that is robust to perturbation and noise. Experimental results show that our method outperforms state-of-the-art methods or provides competitive results with a significant model size reduction with only 1/30 parameters.      
### 59.Hilti-Oxford Dataset: A Millimetre-Accurate Benchmark for Simultaneous Localization and Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2208.09825.pdf)
>  Simultaneous Localization and Mapping (SLAM) is being deployed in real-world applications, however many state-of-the-art solutions still struggle in many common scenarios. A key necessity in progressing SLAM research is the availability of high-quality datasets and fair and transparent benchmarking. To this end, we have created the Hilti-Oxford Dataset, to push state-of-the-art SLAM systems to their limits. The dataset has a variety of challenges ranging from sparse and regular construction sites to a 17th century neoclassical building with fine details and curved surfaces. To encourage multi-modal SLAM approaches, we designed a data collection platform featuring a lidar, five cameras, and an IMU (Inertial Measurement Unit). With the goal of benchmarking SLAM algorithms for tasks where accuracy and robustness are paramount, we implemented a novel ground truth collection method that enables our dataset to accurately measure SLAM pose errors with millimeter accuracy. To further ensure accuracy, the extrinsics of our platform were verified with a micrometer-accurate scanner, and temporal calibration was managed online using hardware time synchronization. The multi-modality and diversity of our dataset attracted a large field of academic and industrial researchers to enter the second edition of the Hilti SLAM challenge, which concluded in June 2022. The results of the challenge show that while the top three teams could achieve accuracy of 2cm or better for some sequences, the performance dropped off in more difficult sequences.      
### 60.Rate-Splitting Multiple Access for Intelligent Reflecting Surface-Aided Secure Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2208.09818.pdf)
>  In this letter, we study a rate-splitting multiple access (RSMA)-based intelligent reflecting surface (IRS)-aided multi-user multiple-input single-output (MISO) secure communication system with a potential eavesdropper (Eve). Aiming to maximize the minimum secrecy rate (SR) among all the legitimate users (LUs), a design problem for jointly optimizing the transmit beamforming with artificial noise (AN), the IRS beamforming, and the secrecy common rate allocation is formulated. Since the design problem is highly non-convex with coupled optimization variables, we develop a computationally efficient algorithm based on the alternating optimization (AO) technique to solve it suboptimally. Numerical results demonstrate that the proposed design can significantly improve the max-min SR over the benchmark schemes adopting other multiple access techniques. In particular, employing the RSMA strategy can substantially reduce the required numbers of IRS elements for achieving a target level of secrecy performance compared with the benchmark schemes.      
### 61.Learning Sub-Pixel Disparity Distribution for Light Field Depth Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2208.09688.pdf)
>  Existing light field (LF) depth estimation methods generally consider depth estimation as a regression problem, supervised by a pixel-wise L1 loss between the regressed disparity map and the groundtruth one. However, the disparity map is only a sub-space projection (i.e., an expectation) of the disparity distribution, while the latter one is more essential for models to learn. In this paper, we propose a simple yet effective method to learn the sub-pixel disparity distribution by fully utilizing the power of deep networks. In our method, we construct the cost volume at sub-pixel level to produce a finer depth distribution and design an uncertainty-aware focal loss to supervise the disparity distribution to be close to the groundtruth one. Extensive experimental results demonstrate the effectiveness of our method. Our method, called SubFocal, ranks the first place among 99 submitted algorithms on the HCI 4D LF Benchmark in terms of all the five accuracy metrics (i.e., BadPix0.01, BadPix0.03, BadPix0.07, MSE and Q25), and significantly outperforms recent state-of-the-art LF depth methods such as OACC-Net and AttMLFNet. Code and model are available at <a class="link-external link-https" href="https://github.com/chaowentao/SubFocal" rel="external noopener nofollow">this https URL</a>.      
### 62.An Initial Investigation for Detecting Vocoder Fingerprints of Fake Audio  [ :arrow_down: ](https://arxiv.org/pdf/2208.09646.pdf)
>  Many effective attempts have been made for fake audio detection. However, they can only provide detection results but no countermeasures to curb this harm. For many related practical applications, what model or algorithm generated the fake audio also is needed. Therefore, We propose a new problem for detecting vocoder fingerprints of fake audio. Experiments are conducted on the datasets synthesized by eight state-of-the-art vocoders. We have preliminarily explored the features and model architectures. The t-SNE visualization shows that different vocoders generate distinct vocoder fingerprints.      
### 63.Mobile Robot Navigation in Complex Polygonal Workspaces Using Conformal Navigation Transformations  [ :arrow_down: ](https://arxiv.org/pdf/2208.09635.pdf)
>  This work proposes a novel transformation termed the conformal navigation transformation to achieve collision-free navigation of a robot in a workspace populated with arbitrary polygonal obstacles. The properties of the conformal navigation transformation in the polygonal workspace are investigated in this work as well as its capability to provide a solution to the navigation problem. %The properties of the conformal navigation transformation are investigated, which contribute to the solution of the robot navigation problem in complex polygonal environments. %which facilitates the navigation of robots in complex environments. The definition of the navigation function is generalized to accommodate non-smooth obstacle boundaries. Based on the proposed transformation and the generalized navigation function, a provably correct feedback controller is derived for the automatic guidance and motion control of the kinematic mobile robot. Moreover, an iterative method is proposed to construct the conformal navigation transformation in a multi-connected polygonal workspace, which transforms the multi-connected problem into multiple single-connected problems to achieve fast <a class="link-external link-http" href="http://convergence.In" rel="external noopener nofollow">this http URL</a> addition to the analytic guarantees, the simulation study verifies the effectiveness of the proposed methodology in a workspace with non-trivial polygonal obstacles.      
### 64.Phase Shift-Free Passive Beamforming for Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2208.09627.pdf)
>  Reconfigurable intelligent surface (RIS)-assisted communications recently appeared as a game-changing technology for next-generation wireless communications due to its unprecedented ability to reform the propagation environment. One of the main aspects of using RISs is the exploitation of the so-called passive beamforming (PB), which is carried out by adjusting the reflection coefficients (mainly the phase shifts) of the individual RIS elements. However, practically, this individual phase shift adjustment is associated with many issues in hardware implementation, limiting the RIS achievable gain. In this paper, we propose a low-cost, phase shift-free and novel PB scheme by only optimizing the on/off states of the RIS elements while fixing their phase shifts. The proposed PB scheme is shown to achieve the same scaling law (quadratic growth with the RIS size) for the signal-to-noise ratio as in the classical phase shift-based PB scheme, yet, with far less sensitivity to spatial correlation and phase errors. We provide a unified mathematical analysis that characterizes the performance of the proposed PB scheme and obtain the outage probability for the considered RIS-assisted system. Based on the provided computer simulations, the proposed PB scheme is shown to have a clear superiority over the classical one under different performance metrics.      
### 65.Fully Automated End-to-End Fake Audio Detection  [ :arrow_down: ](https://arxiv.org/pdf/2208.09618.pdf)
>  The existing fake audio detection systems often rely on expert experience to design the acoustic features or manually design the hyperparameters of the network structure. However, artificial adjustment of the parameters can have a relatively obvious influence on the results. It is almost impossible to manually set the best set of parameters. Therefore this paper proposes a fully automated end-toend fake audio detection method. We first use wav2vec pre-trained model to obtain a high-level representation of the speech. Furthermore, for the network structure, we use a modified version of the differentiable architecture search (DARTS) named light-DARTS. It learns deep speech representations while automatically learning and optimizing complex neural structures consisting of convolutional operations and residual blocks. The experimental results on the ASVspoof 2019 LA dataset show that our proposed system achieves an equal error rate (EER) of 1.08%, which outperforms the state-of-the-art single system.      
