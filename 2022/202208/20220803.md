# ArXiv eess --Wed, 3 Aug 2022
### 1.Sensor Deployment and Link Analysis in Satellite IoT Systems for Wildfire Detection  [ :arrow_down: ](https://arxiv.org/pdf/2208.01632.pdf)
>  Climate change has been identified as one of the most critical threats to human civilization and sustainability. Wildfires, which produce huge amounts of carbon emission, are both drivers and results of climate change. An early and timely wildfire detection system can constrain fires to short and small ones and yield significant carbon reduction. In this paper, we propose to use ground sensor deployment and satellite Internet of Things (IoT) technologies for wildfire detection by taking advantage of satellites' ubiquitous global coverage. We first develop an optimal IoT sensor placement strategy based on fire ignition and detection models. Then, we analyze the uplink satellite communication budget and the bandwidth required for wildfire detection under the narrowband IoT (NB-IoT) radio interface. Finally, we conduct simulations on the California wildfire database and quantify the potential economical benefits by factoring in carbon emission reductions and sensor/bandwidth costs.      
### 2.Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study  [ :arrow_down: ](https://arxiv.org/pdf/2208.01602.pdf)
>  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for implicit neural representation of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.      
### 3.Tunable high-resolution synthetic aperture radar imaging  [ :arrow_down: ](https://arxiv.org/pdf/2208.01596.pdf)
>  We have recently introduced a modification of the multiple signal <br>classification (MUSIC) method for synthetic aperture radar. This <br>method depends on a tunable, user-defined parameter, <br>$\epsilon$, that allows for quantitative high-resolution imaging. It <br>requires however, relative large single-to-noise ratios (SNR) to <br>work effectively. Here, we first identify the fundamental mechanism <br>in that method that produces high-resolution images. Then we <br>introduce a modification to Kirchhoff Migration (KM) that uses the same <br>mechanism to produces tunable, high-resolution images. This modified <br>KM method can be applied to low SNR measurements. We show simulation <br>results that demonstrate the features of this method.      
### 4.The design and optimization of synchronization sequence for Ultraviolet communication  [ :arrow_down: ](https://arxiv.org/pdf/2208.01559.pdf)
>  In the ultraviolet (UV) scattering communication, the received signals exhibit the characteristics of discrete photoelectrons due to path loss. The synchronization is based on maximum Pulse Number-Sequence correlation problem. First of all, the accuracy of synchronization is vital to channel estimation and decoding. This article focuses on improving synchronization accuracy by designing and optimizing synchronization sequences. As for the maximum Pulse Number-Sequence correlation problem, it is assumed that the correlation values satisfy the Gaussian distribution and their mathematical expectation, variance and covariance are derived to express the upper bound of synchronization offset. The synchronization sequence we designed has two equilong RANDOM parts (Symbols meet Bernoulli distribution with equal probability.) and a $\{1,0,1,0,1,0,...,1,0,1,0\}$ part between them with $ \alpha $ as its proportion of entire sequence. On the premise of ensuring the synchronization reliability, the synchronization deviation can be reduced by optimizing $ \alpha $. <br>There are simulation experiments to verify correctness of the derivation, reasonableness of the hypothesis and reliability of optimization. Compared with equilong random sequence, the synchronization accuracy of the optimized synchronization sequence is significantly improved.      
### 5.Low-complexity CNNs for Acoustic Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2208.01555.pdf)
>  This technical report describes the SurreyAudioTeam22s submission for DCASE 2022 ASC Task 1, Low-Complexity Acoustic Scene Classification (ASC). The task has two rules, (a) the ASC framework should have maximum 128K parameters, and (b) there should be a maximum of 30 millions multiply-accumulate operations (MACs) per inference. In this report, we present low-complexity systems for ASC that follow the rules intended for the task.      
### 6.IterMiUnet: A lightweight architecture for automatic blood vessel segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01485.pdf)
>  The automatic segmentation of blood vessels in fundus images can help analyze the condition of retinal vasculature, which is crucial for identifying various systemic diseases like hypertension, diabetes, etc. Despite the success of Deep Learning-based models in this segmentation task, most of them are heavily parametrized and thus have limited use in practical applications. This paper proposes IterMiUnet, a new lightweight convolution-based segmentation model that requires significantly fewer parameters and yet delivers performance similar to existing models. The model makes use of the excellent segmentation capabilities of Iternet architecture but overcomes its heavily parametrized nature by incorporating the encoder-decoder structure of MiUnet model within it. Thus, the new model reduces parameters without any compromise with the network's depth, which is necessary to learn abstract hierarchical concepts in deep models. This lightweight segmentation model speeds up training and inference time and is potentially helpful in the medical domain where data is scarce and, therefore, heavily parametrized models tend to overfit. The proposed model was evaluated on three publicly available datasets: DRIVE, STARE, and CHASE-DB1. Further cross-training and inter-rater variability evaluations have also been performed. The proposed model has a lot of potential to be utilized as a tool for the early diagnosis of many diseases.      
### 7.A Python-based Mixed Discrete-Continuous Simulation Framework for Digital Twins  [ :arrow_down: ](https://arxiv.org/pdf/2208.01408.pdf)
>  The use of Digital Twins is set to transform the manufacturing sector by aiding monitoring and real-time decision making. For several applications in this sector, the system to be modeled consists of a mix of discrete-event and continuous processes interacting with each other. Building simulation-based Digital Twins of such systems necessitates an open, flexible simulation framework which can support easy modeling and fast simulation of both continuous and discrete-event components, and their interactions. In this paper, we present an outline and key design aspects of a Python-based framework for performing mixed discrete-continuous simulations. The continuous processes in the system are assumed to be loosely coupled to other components via pre-defined events. For example, a continuous state variable crossing a threshold may trigger an external event. Similarly, external events may lead to a sudden change in the trajectory, state value or boundary conditions in a continuous process. We first present a systematic events-based interface using which such interactions can be modeled and simulated. We then discuss implementation details of the framework along with a detailed example. In our implementation, the advancement of time is controlled and performed using the event-stepped engine of SimPy (a popular discrete-event simulation library in Python). The continuous processes are modelled using existing frameworks with a Python wrapper providing the events interface. We discuss possible improvements to the time advancement scheme, a roadmap and use cases for the framework.      
### 8.Signal corrector and decoupling estimations for UAV control  [ :arrow_down: ](https://arxiv.org/pdf/2208.01402.pdf)
>  For a class of uncertain systems with large-error sensing, according to completely decoupling estimation, the nonlinear low-order stable signal corrector is presented for signal correction, and the extended state observer is used for uncertainty estimation. The signal corrector can reject the large error in global position sensing even the existence of stochastic non-Gaussian noise. In order to be fit for the hardware computational environments in engineering practice and to select the parameters more easily, the linear version of the low-order stable signal corrector is also developed, and the error transfer method is presented to prove it. The correctors and observers are applied to a UAV navigation and control for large-error corrections in position/attitude angle and the uncertainties estimation in the UAV flight dynamics. The control laws are designed according to the correction-estimation results. Finally, the experiments demonstrate the effectiveness of the proposed method.      
### 9.A New Probabilistic V-Net Model with Hierarchical Spatial Feature Transform for Efficient Abdominal Multi-Organ Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01382.pdf)
>  Accurate and robust abdominal multi-organ segmentation from CT imaging of different modalities is a challenging task due to complex inter- and intra-organ shape and appearance variations among abdominal organs. In this paper, we propose a probabilistic multi-organ segmentation network with hierarchical spatial-wise feature modulation to capture flexible organ semantic variants and inject the learnt variants into different scales of feature maps for guiding segmentation. More specifically, we design an input decomposition module via a conditional variational auto-encoder to learn organ-specific distributions on the low dimensional latent space and model richer organ semantic variations that is conditioned on input images.Then by integrating these learned variations into the V-Net decoder hierarchically via spatial feature transformation, which has the ability to convert the variations into conditional Affine transformation parameters for spatial-wise feature maps modulating and guiding the fine-scale segmentation. The proposed method is trained on the publicly available AbdomenCT-1K dataset and evaluated on two other open datasets, i.e., 100 challenging/pathological testing patient cases from AbdomenCT-1K fully-supervised abdominal organ segmentation benchmark and 90 cases from TCIA+&amp;BTCV dataset. Highly competitive or superior quantitative segmentation results have been achieved using these datasets for four abdominal organs of liver, kidney, spleen and pancreas with reported Dice scores improved by 7.3% for kidneys and 9.7% for pancreas, while being ~7 times faster than two strong baseline segmentation methods(nnUNet and CoTr).      
### 10.Control theoretically explainable application of autoencoder methods to fault detection in nonlinear dynamic systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.01291.pdf)
>  This paper is dedicated to control theoretically explainable application of autoencoders to optimal fault detection in nonlinear dynamic systems. Autoencoder-based learning is a standard method of machine learning technique and widely applied for fault (anomaly) detection and classification. In the context of representation learning, the so-called latent (hidden) variable plays an important role towards an optimal fault detection. In ideal case, the latent variable should be a minimal sufficient statistic. The existing autoencoder-based fault detection schemes are mainly application-oriented, and few efforts have been devoted to optimal autoencoder-based fault detection and explainable applications. The main objective of our work is to establish a framework for learning autoencoder-based optimal fault detection in nonlinear dynamic systems. To this aim, a process model form for dynamic systems is firstly introduced with the aid of control and system theory, which also leads to a clear system interpretation of the latent variable. The major efforts are devoted to the development of a control theoretical solution to the optimal fault detection problem, in which an analog concept to minimal sufficient statistic, the so-called lossless information compression, is introduced for dynamic systems and fault detection specifications. In particular, the existence conditions for such a latent variable are derived, based on which a loss function and further a learning algorithm are developed. This learning algorithm enables optimally training of autoencoders to achieve an optimal fault detection in nonlinear dynamic systems. A case study on three-tank system is given at the end of this paper to illustrate the capability of the proposed autoencoder-based fault detection and to explain the essential role of the latent variable in the proposed fault detection system.      
### 11.Terahertz-Band Integrated Sensing and Communications: Challenges and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2208.01235.pdf)
>  The sixth generation (6G) wireless networks aim to achieve ultra-high data transmission rates, very low latency and enhanced energy-efficiency. To this end, terahertz (THz) band is one of the key enablers of 6G to meet such requirements. The THz-band systems are also quickly merging as high-resolution sensing devices because of their ultra-wide bandwidth and very narrow beamwidth. As a means to efficiently utilize spectrum and thereby save cost and power, THz integrated sensing and communications (ISAC) paradigm envisages a single integrated hardware platform with common signaling mechanism. However, ISAC at THz-band entails several design challenges such as beam split, range-dependent bandwidth, near-field beamforming, and distinct channel model. This article examines the technologies that have the potential to bring forth ISAC and THz transmission together. In particular, it provides an overview of antenna and array design, hybrid beamforming, integration with reflecting surfaces and data-driven techniques such as machine learning. These systems also provide research opportunities in developing novel methodologies for channel estimation, near-field beam split, waveform design and beam misalignment.      
### 12.Optimal Measurement of Drone Swarm in RSS-based Passive Localization with Region Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2208.01227.pdf)
>  Passive geolocation by multiple unmanned aerial vehicles (UAVs) covers a wide range of military and civilian applications including rescue, wild life tracking and electronic warfare. The sensor-target geometry is known to significantly affect the localization precision. The existing sensor placement strategies mainly work on the cases without any constraints on the sensors locations. However, UAVs cannot fly/hover simply in arbitrary region due to realistic constraints, such as the geographical limitations, the security issues, and the max flying speed. In this paper, optimal geometrical configurations of UAVs in received signal strength (RSS)-based localization under region constraints are investigated. Employing the D-optimal criteria, i.e., minimizing the determinate of Fisher information matrix (FIM), such optimal problem is formulated. Based on the rigorous algebra and geometrical derivations, optimal and also closed form configurations of UAVs under different flying states are proposed. Finally, the effectiveness and practicality of the proposed configurations are demonstrated by simulation examples.      
### 13.Time-Dependent Performance Modeling for Platooning Communications at Intersection  [ :arrow_down: ](https://arxiv.org/pdf/2208.01213.pdf)
>  With the development of internet of vehicles, platooning strategy has been widely studied as the potential approach to ensure the safety of autonomous driving. Vehicles in the form of platoon adopt 802.11p to exchange messages through vehicle to vehicle (V2V) communications. When multiple platoons arrive at an intersection, the leader vehicle of each platoon adjusts its movement characteristics to ensure that it can cross the intersection and thus the following vehicles have to adjust their movement characteristics accordingly. In this case, the time-varying connectivity among vehicles leads to the significant non-stationary performance change in platooning communications, which may incur safety issues. In this paper, we construct the time-dependent model to evaluate the platooning communication performance at the intersection based on the initial movement characteristics. We first consider the movement behaviors of vehicles at the intersection including turning, accelerating, decelerating and stopping as well as the periodic change of traffic lights to construct movement model, and then establish a hearing network to reflect the time-varying connectivity among vehicles. Afterwards, we adopt the pointwise stationary fluid flow approximation (PSFFA) to model the non-stationary behavior of transmission queue. Then, we consider four access categories (ACs) and continuous backoff freezing of 802.11p to construct the models to describe the time-dependent access process of 802.11p. Finally, based on the time-dependent model, the packet transmission delay and packet delivery ratio are derived. The accuracy of our proposed model is verified by comparing the simulation results with analytical results.      
### 14.Multi-user Downlink Beamforming using Uplink Downlink Duality with CEQs for Frequency Selective Channels  [ :arrow_down: ](https://arxiv.org/pdf/2208.01151.pdf)
>  High-resolution fully digital transceivers are infeasible at millimeter-wave (mmWave) due to their increased power consumption, cost, and hardware complexity. The use of low-resolution converters is one possible solution to realize fully digital architectures at mmWave. In this paper, we consider a setting in which a fully digital base station with constant envelope quantized (CEQ) digital-to-analog converters on each radio frequency chain communicates with multiple single antenna users with individual signal-to-quantization-plus-interference-plus-noise ratio (SQINR) constraints over frequency selective channels. We first establish uplink downlink duality for the system with CEQ hardware constraints and OFDM-based transmission considered in this paper. Based on the uplink downlink duality principle, we present a solution to the multi-user multi-carrier beamforming and power allocation problem that maximizes the minimum SQINR over all users and sub-carriers. We then present a per sub-carrier version of the originally proposed solution that decouples all sub-carriers of the OFDM waveform resulting in smaller sub-problems that can be solved in a parallel manner. Our numerical results based on 3GPP channel models generated from Quadriga demonstrate improvements in terms of ergodic sum rate and ergodic minimum rate over state-of-the-art linear solutions. We also show improved performance over non-linear solutions in terms of the coded bit error rate with the increased flexibility of assigning individual user SQINRs built into the proposed framework.      
### 15.A knee cannot have lung disease: out-of-distribution detection with in-distribution voting using the medical example of chest X-ray classification  [ :arrow_down: ](https://arxiv.org/pdf/2208.01077.pdf)
>  Deep learning models are being applied to more and more use cases with astonishing success stories, but how do they perform in the real world? To test a model, a specific cleaned data set is assembled. However, when deployed in the real world, the model will face unexpected, out-of-distribution (OOD) data. In this work, we show that the so-called "radiologist-level" CheXnet model fails to recognize all OOD images and classifies them as having lung disease. To address this issue, we propose in-distribution voting, a novel method to classify out-of-distribution images for multi-label classification. Using independent class-wise in-distribution (ID) predictors trained on ID and OOD data we achieve, on average, 99 % ID classification specificity and 98 % sensitivity, improving the end-to-end performance significantly compared to previous works on the chest X-ray 14 data set. Our method surpasses other output-based OOD detectors even when trained solely with ImageNet as OOD data and tested with X-ray OOD images.      
### 16.Voice Analysis for Stress Detection and Application in Virtual Reality to Improve Public Speaking in Real-time: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2208.01041.pdf)
>  Stress during public speaking is common and adversely affects performance and self-confidence. Extensive research has been carried out to develop various models to recognize emotional states. However, minimal research has been conducted to detect stress during public speaking in real time using voice analysis. In this context, the current review showed that the application of algorithms was not properly explored and helped identify the main obstacles in creating a suitable testing environment while accounting for current complexities and limitations. In this paper, we present our main idea and propose a stress detection computational algorithmic model that could be integrated into a Virtual Reality (VR) application to create an intelligent virtual audience for improving public speaking skills. The developed model, when integrated with VR, will be able to detect excessive stress in real time by analysing voice features correlated to physiological parameters indicative of stress and help users gradually control excessive stress and improve public speaking performance      
### 17.Learning to estimate a surrogate respiratory signal from cardiac motion by signal-to-signal translation  [ :arrow_down: ](https://arxiv.org/pdf/2208.01034.pdf)
>  In this work, we develop a neural network-based method to convert a noisy motion signal generated from segmenting rebinned list-mode cardiac SPECT images, to that of a high-quality surrogate signal, such as those seen from external motion tracking systems (EMTs). This synthetic surrogate will be used as input to our pre-existing motion correction technique developed for EMT surrogate signals. In our method, we test two families of neural networks to translate noisy internal motion to external surrogate: 1) fully connected networks and 2) convolutional neural networks. Our dataset consists of cardiac perfusion SPECT acquisitions for which cardiac motion was estimated (input: center-of-count-mass - COM signals) in conjunction with a respiratory surrogate motion signal acquired using a commercial Vicon Motion Tracking System (GT: EMT signals). We obtained an average R-score of 0.76 between the predicted surrogate and the EMT signal. Our goal is to lay a foundation to guide the optimization of neural networks for respiratory motion correction from SPECT without the need for an EMT.      
### 18.Stochastic Primal-Dual Three Operator Splitting with Arbitrary Sampling and Preconditioning  [ :arrow_down: ](https://arxiv.org/pdf/2208.01631.pdf)
>  In this work we propose a stochastic primal-dual preconditioned three-operator splitting algorithm for solving a class of convex three-composite optimization problems. Our proposed scheme is a direct three-operator splitting extension of the SPDHG algorithm [Chambolle et al. 2018]. We provide theoretical convergence analysis showing ergodic O(1/K) convergence rate, and demonstrate the effectiveness of our approach in imaging inverse problems.      
### 19.Super-Wideband Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2208.01556.pdf)
>  We present a unified model for connected antenna arrays with a massive (but finite) number of tightly integrated (i.e., coupled) antennas in a compact space within the context of massive multiple-input multiple-output (MIMO) communication. We refer to this system as tightly-coupled massive MIMO. From an information-theoretic perspective, scaling the design of tightly-coupled massive MIMO systems in terms of the number of antennas, the operational bandwidth, and form factor was not addressed in prior art and hence not clearly understood. We investigate this open research problem using a physically consistent modeling approach for far-field (FF) MIMO communication based on multi-port circuit theory. In doing so, we turn mutual coupling (MC) from a foe to a friend of MIMO systems design, thereby challenging a basic percept in antenna systems engineering that promotes MC mitigation/compensation. We show that tight MC widens the operational bandwidth of antenna arrays thereby unleashing a missing MIMO gain that we coin "bandwidth gain". Furthermore, we derive analytically the asymptotically optimum spacing-to-antenna-size ratio by establishing a condition for tight coupling in the limit of large-size antenna arrays with quasi-continuous apertures. We also optimize the antenna array size while maximizing the achievable rate under fixed transmit power and inter-element spacing. Then, we study the impact of MC on the achievable rate of MIMO systems under light-of-sight (LoS) and Rayleigh fading channels. These results reveal new insights into the design of tightly-coupled massive antenna arrays as opposed to the widely-adopted "disconnected" designs that disregard MC by putting faith in the half-wavelength spacing rule.      
### 20.Safe Supervisory Control of Soft Robot Actuators  [ :arrow_down: ](https://arxiv.org/pdf/2208.01547.pdf)
>  Although soft robots show safer interactions with their environment than traditional robots, soft mechanisms and actuators still have significant potential for damage or degradation particularly during unmodeled contact. This article introduces a feedback strategy for safe soft actuator operation during control of a soft robot. To do so, a supervisory controller monitors actuator state and dynamically saturates control inputs to avoid conditions that could lead to physical damage. We prove that, under certain conditions, the supervisory controller is stable and verifiably safe. We then demonstrate completely onboard operation of the supervisory controller using a soft thermally-actuated robot limb with embedded shape memory alloy (SMA) actuators and sensing. Tests performed with the supervisor verify its theoretical properties and show stabilization of the robot limb's pose in free space. Finally, experiments show that our approach prevents overheating during contact (including environmental constraints and human contact) or when infeasible motions are commanded. This supervisory controller, and its ability to be executed with completely onboard sensing, has the potential to make soft robot actuators reliable enough for practical use.      
### 21.Optimal Friendly Jamming and Transmit Power Allocation in RIS-assisted Secure Communication  [ :arrow_down: ](https://arxiv.org/pdf/2208.01537.pdf)
>  This paper analyzes the secrecy performance of a reconfigurable intelligent surface (RIS) assisted wireless communication system with a friendly jammer in the presence of an eavesdropper. The friendly jammer enhances the secrecy by introducing artificial noise towards the eavesdropper without degrading the reception at the destination. Approximate secrecy outage probability (SOP) is derived in closed form. We also provide a simpler approximate closed-form expression for the SOP in order to understand the effect of system parameters on the performance and to find the optimal power allocation for the transmitter and jammer. The optimal transmit and jamming power allocation factor is derived by minimizing the SOP assuming a total power constraint. It is shown that the SOP performance is significantly improved by the introduction of the jammer and a gain of approximately $3$ dB is achieved at an SOP of $10^{-4}$ by optimally allocating power compared to the case of equal power allocation.      
### 22.Mitigating Smart Jammers in Multi-User MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2208.01453.pdf)
>  Wireless systems must be resilient to jamming attacks. Existing mitigation methods based on multi-antenna processing require knowledge of the jammer's transmit characteristics that may be difficult to acquire, especially for smart jammers that evade mitigation by transmitting only at specific instants. We propose a novel method to mitigate smart jamming attacks on the massive multi-user multiple-input multiple-output (MU-MIMO) uplink which does not require the jammer to be active at any specific instant. By formulating an optimization problem that unifies jammer estimation and mitigation, channel estimation, and data detection, we exploit that a jammer cannot change its subspace within a coherence interval. Theoretical results for our problem formulation show that its solution is guaranteed to recover the users' data symbols under certain conditions. We develop two efficient iterative algorithms for approximately solving the proposed problem formulation: MAED, a parameter-free algorithm which uses forward-backward splitting with a box symbol prior, and SO-MAED, which replaces the prior of MAED with soft-output symbol estimates that exploit the discrete transmit constellation and which uses deep unfolding to optimize algorithm parameters. We use simulations to demonstrate that the proposed algorithms effectively mitigate a wide range of smart jammers without a priori knowledge about the attack type.      
### 23.Superdirective Arrays with Finite-Length Dipoles: Modeling and New Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2208.01422.pdf)
>  Dense arrays can facilitate the integration of multiple antennas into finite volumes. In addition to the compact size, sub-wavelength spacing enables superdirectivity for endfire operation, a phenomenon that has been mainly studied for isotropic and infinitesimal radiators. In this work, we focus on linear dipoles of arbitrary yet finite length. Specifically, we first introduce an array model that accounts for the sinusoidal current distribution (SCD) on very thin dipoles. Based on the SCD, the loss resistance of each dipole antenna is precisely determined. Capitalizing on the derived model, we next investigate the maximum achievable rate under a fixed power constraint. The optimal design entails conjugate power matching along with maximizing the array gain. Our theoretical analysis is corroborated by the method of moments under the thin-wire approximation, as well as by full-wave simulations. Numerical results showcase that a super-gain is attainable with high radiation efficiency when the dipole antennas are not too short and thin.      
### 24.UniPreCIS : A data pre-processing solution for collocated services on shared IoT  [ :arrow_down: ](https://arxiv.org/pdf/2208.01394.pdf)
>  Next-generation smart city applications, attributed by the power of Internet of Things (IoT) and Cyber-Physical Systems (CPS), significantly rely on the quality of sensing data. With an exponential increase in intelligent applications for urban development and enterprises offering sensing-as-aservice these days, it is imperative to provision for a shared sensing infrastructure for better utilization of resources. However, a shared sensing infrastructure that leverages low-cost sensing devices for a cost effective solution, still remains an unexplored territory. A significant research effort is still needed to make edge based data shaping solutions, more reliable, feature-rich and costeffective while addressing the associated challenges in sharing the sensing infrastructure among multiple collocated services with diverse Quality of Service (QoS) requirements. Towards this, we propose a novel edge based data pre-processing solution, named UniPreCIS that accounts for the inherent characteristics of lowcost ambient sensors and the exhibited measurement dynamics with respect to application-specific QoS. UniPreCIS aims to identify and select quality data sources by performing sensor ranking and selection followed by multimodal data pre-processing in order to meet heterogeneous application QoS and at the same time reducing the resource consumption footprint for the resource constrained network edge. As observed, the processing time and memory utilization has been reduced in the proposed approach while achieving upto 90% accuracy which is arguably significant as compared to state-of-the-art techniques for sensing. The effectiveness of UniPreCIS has been evaluated on a testbed for a specific use case of indoor occupancy estimation that proves its effectiveness.      
### 25.Joint optimal beamforming and power control in cell-free massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2208.01385.pdf)
>  We derive a fast and optimal algorithm for solving practical weighted max-min SINR problems in cell-free massive MIMO networks. For the first time, the optimization problem jointly covers long-term power control and distributed beamforming design under imperfect cooperation. In particular, we consider user-centric clusters of access points cooperating on the basis of possibly limited channel state information sharing. Our optimal algorithm merges powerful power control tools based on interference calculus with the recently developed team theoretic framework for distributed beamforming design. In addition, we propose a variation that shows faster convergence in practice.      
### 26.The Face of Affective Disorders  [ :arrow_down: ](https://arxiv.org/pdf/2208.01369.pdf)
>  We study the statistical properties of facial behaviour altered by the regulation of brain arousal in the clinical domain of psychiatry. The underlying mechanism is linked to the empirical interpretation of the vigilance continuum as behavioral surrogate measurement for certain states of mind. We name the presented measurement in the sense of the classical scalp based obtrusive sensors Opto Electronic Encephalography (OEG) which relies solely on modern camera based real-time signal processing and computer vision. Based upon a stochastic representation as coherence of the face dynamics, reflecting the hemifacial asymmetry in emotion expressions, we demonstrate an almost flawless distinction between patients and healthy controls as well as between the mental disorders depression and schizophrenia and the symptom severity. In contrast to the standard diagnostic process, which is time-consuming, subjective and does not incorporate neurobiological data such as real-time face dynamics, the objective stochastic modeling of the affective responsiveness only requires a few minutes of video-based facial recordings. We also highlight the potential of the methodology as a causal inference model in transdiagnostic analysis to predict the outcome of pharmacological treatment. All results are obtained on a clinical longitudinal data collection with an amount of 100 patients and 50 controls.      
### 27.Encoding information in the mutual coherence of spatially separated light beams  [ :arrow_down: ](https://arxiv.org/pdf/2208.01364.pdf)
>  Coherence has been used as a resource for optical communications since its earliest days. It is widely used for multiplexing of data, but not for encoding of data. Here we introduce a coding scheme, which we call \textit{mutual coherence coding}, to encode information in the mutual coherence of spatially separated light beams. We describe its implementation and analyze its performance by deriving the relevant figures of merit (signal-to-noise ratio, maximum bit-rate, and spectral efficiency) with respect to the number of transmitted beams. Mutual coherence coding yields a quadratic scaling of the number of transmitted signals with the number of employed light beams, which might have benefits for cryptography and data security.      
### 28.Distributed Sum-Rate Maximization of Cellular Communications with Multiple Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2208.01354.pdf)
>  The technology of Reconfigurable Intelligent Surfaces (RISs) has lately attracted considerable interest from both academia and industry as a low-cost solution for coverage extension and signal propagation control. In this paper, we study the downlink of a multi-cell wideband communication system comprising single-antenna Base Stations (BSs) and their associated single-antenna users, as well as multiple passive RISs. We assume that each BS controls a separate RIS and performs Orthogonal Frequency Division Multiplexing (OFDM) transmissions. Differently from various previous works where the RIS unit elements are considered as frequency-flat phase shifters, we model them as Lorentzian resonators and present a joint design of the BSs' power allocation, as well as the phase profiles of the multiple RISs, targeting the sum-rate maximization of the multi-cell system. We formulate a challenging distributed nonconvex optimization problem, which is solved via successive concave approximation. The distributed implementation of the proposed design is discussed, and the presented simulation results showcase the interplay of the various system parameters on the sum rate, verifying the performance boosting role of RISs.      
### 29.Interplay between Distributed AI Workflow and URLLC  [ :arrow_down: ](https://arxiv.org/pdf/2208.01352.pdf)
>  Distributed artificial intelligence (AI) has recently accomplished tremendous breakthroughs in various communication services, ranging from fault-tolerant factory automation to smart cities. When distributed learning is run over a set of wireless connected devices, random channel fluctuations, and the incumbent services simultaneously running on the same network affect the performance of distributed learning. In this paper, we investigate the interplay between distributed AI workflow and ultra-reliable low latency communication (URLLC) services running concurrently over a network. Using 3GPP compliant simulations in a factory automation use case, we show the impact of various distributed AI settings (e.g., model size and the number of participating devices) on the convergence time of distributed AI and the application layer performance of URLLC. Unless we leverage the existing 5G-NR quality of service handling mechanisms to separate the traffic from the two services, our simulation results show that the impact of distributed AI on the availability of the URLLC devices is significant. Moreover, with proper setting of distributed AI (e.g., proper user selection), we can substantially reduce network resource utilization, leading to lower latency for distributed AI and higher availability for the URLLC users. Our results provide important insights for future 6G and AI standardization.      
### 30.Differential Coded Aperture Single-Snapshot Spectral Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2208.01309.pdf)
>  We propose a novel concept of differential coded aperture snapshot spectral imaging (D-CASSI) technique exploiting the benefits of using {-1,+1} random mask, which is demonstrated by a broadband single-snapshot hyperspectral camera using compressed sensing. To double the information, we encode the image by two complementary random masks, which proved to be superior to two independent patterns. We utilize dispersed and non-dispersed encoded images captured in parallel onto a single detector. We explored several different approaches to processing the measured data, which demonstrates significant improvement in retrieving complex hyperspectral scenes. The experiments were completed by simulations in order to quantify the reconstruction fidelity. The concept of differential CASSI could be easily implemented also by multi-snapshot CASSI without any need for optical system modification.      
### 31.Enhancement of CASSI by a zero-order image employing a single detector  [ :arrow_down: ](https://arxiv.org/pdf/2208.01308.pdf)
>  Coded aperture snapshot spectral imaging (CASSI) makes it possible to recover 3D hyperspectral data from a single 2D image. However, the reconstruction problem is severely underdetermined and efforts to improve the compression ratio typically make the imaging system more complex and cause a significant loss of incoming light intensity. In this paper, we propose a novel approach to CASSI which enables capturing both spectrally sheared and integrated image of a scene with a single camera. We performed hyperspectral imaging of three different testing scenes in the spectral range of 500-900 nm. We demonstrate the prominent effect of using the non-diffracted image on the reconstruction of data from our camera. The use of the spectrally integrated image improves the reconstruction quality and we observed an approx. fivefold reduction in reconstruction time.      
### 32.Towards V2I Age-aware Fairness Access: A DQN Based Intelligent Vehicular Node Training and Test Method  [ :arrow_down: ](https://arxiv.org/pdf/2208.01283.pdf)
>  Vehicles on the road exchange data with base station (BS) frequently through vehicle to infrastructure (V2I) communications to ensure the normal use of vehicular applications, where the IEEE 802.11 distributed coordination function (DCF) is employed to allocate a minimum contention window (MCW) for channel access. Each vehicle may change its MCW to achieve more access opportunities at the expense of others, which results in unfair communication performance. Moreover, the key access parameters MCW is the privacy information and each vehicle are not willing to share it with other vehicles. In this uncertain setting, age of information (AoI) is an important communication metric to measure the freshness of data, we design an intelligent vehicular node to learn the dynamic environment and predict the optimal MCW which can make it achieve age fairness. In order to allocate the optimal MCW for the vehicular node, we employ a learning algorithm to make a desirable decision by learning from replay history data. In particular, the algorithm is proposed by extending the traditional DQN training and testing method. Finally, by comparing with other methods, it is proved that the proposed DQN method can significantly improve the age fairness of the intelligent node.      
### 33.Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.01221.pdf)
>  Emerging six generation (6G) is the integration of heterogeneous wireless networks, which can seamlessly support anywhere and anytime networking. But high Quality-of-Trust should be offered by 6G to meet mobile user expectations. Artificial intelligence (AI) is considered as one of the most important components in 6G. Then AI-based trust management is a promising paradigm to provide trusted and reliable services. In this article, a generative adversarial learning-enabled trust management method is presented for 6G wireless networks. Some typical AI-based trust management schemes are first reviewed, and then a potential heterogeneous and intelligent 6G architecture is introduced. Next, the integration of AI and trust management is developed to optimize the intelligence and security. Finally, the presented AI-based trust management method is applied to secure clustering to achieve reliable and real-time communications. Simulation results have demonstrated its excellent performance in guaranteeing network security and service quality.      
### 34.GeoECG: Data Augmentation via Wasserstein Geodesic Perturbation for Robust Electrocardiogram Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2208.01220.pdf)
>  There has been an increased interest in applying deep neural networks to automatically interpret and analyze the 12-lead electrocardiogram (ECG). The current paradigms with machine learning methods are often limited by the amount of labeled data. This phenomenon is particularly problematic for clinically-relevant data, where labeling at scale can be time-consuming and costly in terms of the specialized expertise and human effort required. Moreover, deep learning classifiers may be vulnerable to adversarial examples and perturbations, which could have catastrophic consequences, for example, when applied in the context of medical treatment, clinical trials, or insurance claims. In this paper, we propose a physiologically-inspired data augmentation method to improve performance and increase the robustness of heart disease detection based on ECG signals. We obtain augmented samples by perturbing the data distribution towards other classes along the geodesic in Wasserstein space. To better utilize domain-specific knowledge, we design a ground metric that recognizes the difference between ECG signals based on physiologically determined features. Learning from 12-lead ECG signals, our model is able to distinguish five categories of cardiac conditions. Our results demonstrate improvements in accuracy and robustness, reflecting the effectiveness of our data augmentation method.      
### 35.Audio Deepfake Detection Based on a Combination of F0 Information and Real Plus Imaginary Spectrogram Features  [ :arrow_down: ](https://arxiv.org/pdf/2208.01214.pdf)
>  Recently, pioneer research works have proposed a large number of acoustic features (log power spectrogram, linear frequency cepstral coefficients, constant Q cepstral coefficients, etc.) for audio deepfake detection, obtaining good performance, and showing that different subbands have different contributions to audio deepfake detection. However, this lacks an explanation of the specific information in the subband, and these features also lose information such as phase. Inspired by the mechanism of synthetic speech, the fundamental frequency (F0) information is used to improve the quality of synthetic speech, while the F0 of synthetic speech is still too average, which differs significantly from that of real speech. It is expected that F0 can be used as important information to discriminate between bonafide and fake speech, while this information cannot be used directly due to the irregular distribution of F0. Insteadly, the frequency band containing most of F0 is selected as the input feature. Meanwhile, to make full use of the phase and full-band information, we also propose to use real and imaginary spectrogram features as complementary input features and model the disjoint subbands separately. Finally, the results of F0, real and imaginary spectrogram features are fused. Experimental results on the ASVspoof 2019 LA dataset show that our proposed system is very effective for the audio deepfake detection task, achieving an equivalent error rate (EER) of 0.43%, which surpasses almost all systems.      
### 36.Analog Gated Recurrent Neural Network for Detecting Chewing Events  [ :arrow_down: ](https://arxiv.org/pdf/2208.01201.pdf)
>  We present a novel gated recurrent neural network to detect when a person is chewing on food. We implemented the neural network as a custom analog integrated circuit in a 0.18 um CMOS technology. The neural network was trained on 6.4 hours of data collected from a contact microphone that was mounted on volunteers' mastoid bones. When tested on 1.6 hours of previously-unseen data, the neural network identified chewing events at a 24-second time resolution. It achieved a recall of 91% and an F1-score of 94% while consuming 1.1 uW of power. A system for detecting whole eating episodes -- like meals and snacks -- that is based on the novel analog neural network consumes an estimated 18.8uW of power.      
### 37.Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot  [ :arrow_down: ](https://arxiv.org/pdf/2208.01160.pdf)
>  We address the problem of enabling quadrupedal robots to perform precise shooting skills in the real world using reinforcement learning. Developing algorithms to enable a legged robot to shoot a soccer ball to a given target is a challenging problem that combines robot motion control and planning into one task. To solve this problem, we need to consider the dynamics limitation and motion stability during the control of a dynamic legged robot. Moreover, we need to consider motion planning to shoot the hard-to-model deformable ball rolling on the ground with uncertain friction to a desired location. In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion to shoot a soccer ball to a target. We deploy the proposed framework on an A1 quadrupedal robot and enable it to accurately shoot the ball to random targets in the real world.      
### 38.Vertical GaN Diode BV Maximization through Rapid TCAD Simulation and ML-enabled Surrogate Model  [ :arrow_down: ](https://arxiv.org/pdf/2208.01142.pdf)
>  In this paper, two methodologies are used to speed up the maximization of the breakdown volt-age (BV) of a vertical GaN diode that has a theoretical maximum BV of ~2100V. Firstly, we demonstrated a 5X faster accurate simulation method in Technology Computer-Aided-Design (TCAD). This allows us to find 50% more numbers of high BV (&gt;1400V) designs at a given simulation time. Secondly, a machine learning (ML) model is developed using TCAD-generated data and used as a surrogate model for differential evolution optimization. It can inversely design an out-of-the-training-range structure with BV as high as 1887V (89% of the ideal case) compared to ~1100V designed with human domain expertise.      
### 39.SampleMatch: Drum Sample Retrieval by Musical Context  [ :arrow_down: ](https://arxiv.org/pdf/2208.01141.pdf)
>  Modern digital music production typically involves combining numerous acoustic elements to compile a piece of music. Important types of such elements are drum samples, which determine the characteristics of the percussive components of the piece. Artists must use their aesthetic judgement to assess whether a given drum sample fits the current musical context. However, selecting drum samples from a potentially large library is tedious and may interrupt the creative flow. In this work, we explore the automatic drum sample retrieval based on aesthetic principles learned from data. As a result, artists can rank the samples in their library by fit to some musical context at different stages of the production process (i.e., by fit to incomplete song mixtures). To this end, we use contrastive learning to maximize the score of drum samples originating from the same song as the mixture. We conduct a listening test to determine whether the human ratings match the automatic scoring function. We also perform objective quantitative analyses to evaluate the efficacy of our approach.      
### 40.Energy Efficiency Maximization for Backscatter-Enabled Coded-Cooperative NOMA Under Imperfect SIC  [ :arrow_down: ](https://arxiv.org/pdf/2208.01123.pdf)
>  In this manuscript, we propose an optimization framework to maximize the energy efficiency of the BSC-enabled cooperative NOMA system under imperfect successive interference cancellation (SIC) decoding at the receiver. Specifically, the energy efficiency of the system is maximized by optimizing the transmit power of the source, power allocation coefficients (PAC) of NOMA users, and power of the relay node. A low-complexity energy-efficient alternating optimization framework is introduced which simultaneously optimizes the transmit power of the source, PAC, and power of the relay node by considering the quality of service (QoS), power budget, and cooperation constraints under the imperfect SIC decoding. Subsequently, a joint channel coding framework is provided to enhance the performance of far user which has no direct communication link with the base station (BS) and has bad channel conditions. In the destination node, the far user data is jointly decoded using a Sum-product algorithm (SPA) based joint iterative decoder realized by jointly-designed Quasi-cyclic Low-density parity-check (QC-LDPC) codes obtained from cyclic balanced sampling plans excluding contiguous units (CBSEC). Simulation results evince that the proposed BSC-enabled cooperative NOMA system outperforms its counterpart by providing an efficient performance in terms of energy efficiency. Also, proposed jointly-designed QC-LDPC codes provide an excellent bit-error-rate (BER) performance by jointly decoding the far user data for considered BSC cooperative NOMA system with only a few decoding iterations under Rayleigh-fading transmission.      
### 41.Efficient Personalized Learning for Wearable Health Applications using HyperDimensional Computing  [ :arrow_down: ](https://arxiv.org/pdf/2208.01095.pdf)
>  Health monitoring applications increasingly rely on machine learning techniques to learn end-user physiological and behavioral patterns in everyday settings. Considering the significant role of wearable devices in monitoring human body parameters, on-device learning can be utilized to build personalized models for behavioral and physiological patterns, and provide data privacy for users at the same time. However, resource constraints on most of these wearable devices prevent the ability to perform online learning on them. To address this issue, it is required to rethink the machine learning models from the algorithmic perspective to be suitable to run on wearable devices. Hyperdimensional computing (HDC) offers a well-suited on-device learning solution for resource-constrained devices and provides support for privacy-preserving personalization. Our HDC-based method offers flexibility, high efficiency, resilience, and performance while enabling on-device personalization and privacy protection. We evaluate the efficacy of our approach using three case studies and show that our system improves the energy efficiency of training by up to $45.8\times$ compared with the state-of-the-art Deep Neural Network (DNN) algorithms while offering a comparable accuracy.      
### 42.Amino Acid Classification in 2D NMR Spectra via Acoustic Signal Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2208.00935.pdf)
>  Nuclear Magnetic Resonance (NMR) is used in structural biology to experimentally determine the structure of proteins, which is used in many areas of biology and is an important part of drug development. Unfortunately, NMR data can cost thousands of dollars per sample to collect and it can take a specialist weeks to assign the observed resonances to specific chemical groups. There has thus been growing interest in the NMR community to use deep learning to automate NMR data annotation. Due to similarities between NMR and audio data, we propose that methods used in acoustic signal processing can be applied to NMR as well. Using a simulated amino acid dataset, we show that by swapping out filter banks with a trainable convolutional encoder, acoustic signal embeddings from speaker verification models can be used for amino acid classification in 2D NMR spectra by treating each amino acid as a unique speaker. On an NMR dataset comparable in size with of 46 hours of audio, we achieve a classification performance of 97.7% on a 20-class problem. We also achieve a 23% relative improvement by using an acoustic embedding model compared to an existing NMR-based model.      
