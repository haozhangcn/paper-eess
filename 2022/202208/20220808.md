# ArXiv eess --Mon, 8 Aug 2022
### 1.Deep Learning-based Segmentation of Pleural Effusion From Ultrasound Using Coordinate Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2208.03305.pdf)
>  In many low-to-middle income (LMIC) countries, ultrasound is used for assessment of pleural effusion. Typically, the extent of the effusion is manually measured by a sonographer, leading to significant intra-/inter-observer variability. In this work, we investigate the use of deep learning (DL) to automate the process of pleural effusion segmentation from ultrasound images. On two datasets acquired in a LMIC setting, we achieve median Dice Similarity Coefficients (DSCs) of 0.82 and 0.74 respectively using the nnU-net DL model. We also investigate the use of coordinate convolutions in the DL model and find that this results in a statistically significant improvement in the median DSC on the first dataset to 0.85, with no significant change on the second dataset. This work showcases, for the first time, the potential of DL in automating the process of effusion assessment from ultrasound in LMIC settings where there is often a lack of experienced radiologists to perform such tasks.      
### 2.Phase Difference based Doppler Disambiguation Method for TDM-MIMOFMCW Radars  [ :arrow_down: ](https://arxiv.org/pdf/2208.03231.pdf)
>  State-of-the-art automotive radar sensors use a Mutliple-Input Mutiple-Output (MIMO) approach to obtain a better angular resolution. Time-Division Multiplexing (TDM) scheme is commonly applied to realize the orthogonality in time at the transmitter. Apart from its simplicity in implementation, TDM scheme has the drawback of a reduced maximum unambiguous Doppler proportional to the number of transmitters. In this paper, a phase difference based Doppler disambiguation method is proposed to regain the maximum unambiguous Doppler which is equivalent to only one transmitter. This method works well when the number of transmitters is large. The proposed method is demonstrated with simulation and measurement data.      
### 3.Distance-based detection of out-of-distribution silent failures for Covid-19 lung lesion segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2208.03217.pdf)
>  Automatic segmentation of ground glass opacities and consolidations in chest computer tomography (CT) scans can potentially ease the burden of radiologists during times of high resource utilisation. However, deep learning models are not trusted in the clinical routine due to failing silently on out-of-distribution (OOD) data. We propose a lightweight OOD detection method that leverages the Mahalanobis distance in the feature space and seamlessly integrates into state-of-the-art segmentation pipelines. The simple approach can even augment pre-trained models with clinically relevant uncertainty quantification. We validate our method across four chest CT distribution shifts and two magnetic resonance imaging applications, namely segmentation of the hippocampus and the prostate. Our results show that the proposed method effectively detects far- and near-OOD samples across all explored scenarios.      
### 4.Adversarial Robustness of MR Image Reconstruction under Realistic Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2208.03161.pdf)
>  Deep Learning (DL) methods have shown promising results for solving ill-posed inverse problems such as MR image reconstruction from undersampled $k$-space data. However, these approaches currently have no guarantees for reconstruction quality and the reliability of such algorithms is only poorly understood. Adversarial attacks offer a valuable tool to understand possible failure modes and worst case performance of DL-based reconstruction algorithms. In this paper we describe adversarial attacks on multi-coil $k$-space measurements and evaluate them on the recently proposed E2E-VarNet and a simpler UNet-based model. In contrast to prior work, the attacks are targeted to specifically alter diagnostically relevant regions. Using two realistic attack models (adversarial $k$-space noise and adversarial rotations) we are able to show that current state-of-the-art DL-based reconstruction algorithms are indeed sensitive to such perturbations to a degree where relevant diagnostic information may be lost. Surprisingly, in our experiments the UNet and the more sophisticated E2E-VarNet were similarly sensitive to such attacks. Our findings add further to the evidence that caution must be exercised as DL-based methods move closer to clinical practice.      
### 5.Microwave QR Code: An IRS-Based Solution  [ :arrow_down: ](https://arxiv.org/pdf/2208.03137.pdf)
>  This letter proposes to employ intelligent reflecting surface (IRS) as an information media to display a microwave quick response (QR) code for Internet-of-Things applications. To be specific, an IRS is used to form a dynamic bitmap image thanks to its tunable elements. With a QR code shown on the IRS, the transmitting and receiving antenna arrays are jointly designed to scan it by radiating electromagnetic wave as well as receiving and detecting the reflected signal. Based on such an idea, an IRS enabled information and communication system is modelled. Accordingly, some fundamental systematic operating mechanisms are investigated, involving derivation of average bit error probability for signal modulation, QR code implementation on an IRS, transmission design, detection, etc. The simulations are performed to show the achievable communication performance of system and confirm the feasibility of IRS-based microwave QR code.      
### 6.Time-Frequency Distributions of Heart Sound Signals: A Comparative Study using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.03128.pdf)
>  Time-Frequency Distributions (TFDs) support the heart sound characterisation and classification in early cardiac screening. However, despite the frequent use of TFDs in signal analysis, no study comprehensively compared their performances on deep learning for automatic diagnosis. Furthermore, the combination of signal processing methods as inputs for Convolutional Neural Networks (CNNs) has been proved as a practical approach to increasing signal classification performance. Therefore, this study aimed to investigate the optimal use of TFD/ combined TFDs as input for CNNs. The presented results revealed that: 1) The transformation of the heart sound signal into the TF domain achieves higher classification performance than using of raw signals. Among the TFDs, the difference in the performance was slight for all the CNN models (within $1.3\%$ in average accuracy). However, Continuous wavelet transform (CWT) and Chirplet transform (CT) outperformed the rest. 2) The appropriate increase of the CNN capacity and architecture optimisation can improve the performance, while the network architecture should not be overly complicated. Based on the ResNet or SEResNet family results, the increase in the number of parameters and the depth of the structure do not improve the performance apparently. 3) Combining TFDs as CNN inputs did not significantly improve the classification results. The findings of this study provided the knowledge for selecting TFDs as CNN input and designing CNN architecture for heart sound classification.      
### 7.Expanded Adaptive Scaling Normalization for End to End Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2208.03049.pdf)
>  Recently, learning-based image compression methods that utilize convolutional neural layers have been developed rapidly. Rescaling modules such as batch normalization which are often used in convolutional neural networks do not operate adaptively for the various inputs. Therefore, Generalized Divisible Normalization(GDN) has been widely used in image compression to rescale the input features adaptively across both spatial and channel axes. However, the representation power or degree of freedom of GDN is severely limited. Additionally, GDN cannot consider the spatial correlation of an image. To handle the limitations of GDN, we construct an expanded form of the adaptive scaling module, named Expanded Adaptive Scaling Normalization(EASN). First, we exploit the swish function to increase the representation ability. Then, we increase the receptive field to make the adaptive rescaling module consider the spatial correlation. Furthermore, we introduce an input mapping function to give the module a higher degree of freedom. We demonstrate how our EASN works in an image compression network using the visualization results of the feature map, and we conduct extensive experiments to show that our EASN increases the rate-distortion performance remarkably, and even outperforms the VVC intra at a high bit rate.      
### 8.Low-Light Hyperspectral Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2208.03042.pdf)
>  Due to inadequate energy captured by the hyperspectral camera sensor in poor illumination conditions, low-light hyperspectral images (HSIs) usually suffer from low visibility, spectral distortion, and various noises. A range of HSI restoration methods have been developed, yet their effectiveness in enhancing low-light HSIs is constrained. This work focuses on the low-light HSI enhancement task, which aims to reveal the spatial-spectral information hidden in darkened areas. To facilitate the development of low-light HSI processing, we collect a low-light HSI (LHSI) dataset of both indoor and outdoor scenes. Based on Laplacian pyramid decomposition and reconstruction, we developed an end-to-end data-driven low-light HSI enhancement (HSIE) approach trained on the LHSI dataset. With the observation that illumination is related to the low-frequency component of HSI, while textural details are closely correlated to the high-frequency component, the proposed HSIE is designed to have two branches. The illumination enhancement branch is adopted to enlighten the low-frequency component with reduced resolution. The high-frequency refinement branch is utilized for refining the high-frequency component via a predicted mask. In addition, to improve information flow and boost performance, we introduce an effective channel attention block (CAB) with residual dense connection, which served as the basic block of the illumination enhancement branch. The effectiveness and efficiency of HSIE both in quantitative assessment measures and visual effects are demonstrated by experimental results on the LHSI dataset. According to the classification performance on the remote sensing Indian Pines dataset, downstream tasks benefit from the enhanced HSI. Datasets and codes are available: \href{<a class="link-external link-https" href="https://github.com/guanguanboy/HSIE" rel="external noopener nofollow">this https URL</a>}{<a class="link-external link-https" href="https://github.com/guanguanboy/HSIE" rel="external noopener nofollow">this https URL</a>}.      
### 9.BrainFormer: A Hybrid CNN-Transformer Model for Brain fMRI Data Classification  [ :arrow_down: ](https://arxiv.org/pdf/2208.03028.pdf)
>  In neuroimaging analysis, functional magnetic resonance imaging (fMRI) can well assess brain function changes for brain diseases with no obvious structural lesions. So far, most deep-learning-based fMRI studies take functional connectivity as the basic feature in disease classification. However, functional connectivity is often calculated based on time series of predefined regions of interest and neglects detailed information contained in each voxel, which may accordingly deteriorate the performance of diagnostic models. Another methodological drawback is the limited sample size for the training of deep models. In this study, we propose BrainFormer, a general hybrid Transformer architecture for brain disease classification with single fMRI volume to fully exploit the voxel-wise details with sufficient data dimensions and sizes. BrainFormer is constructed by modeling the local cues within each voxel with 3D convolutions and capturing the global relations among distant regions with two global attention blocks. The local and global cues are aggregated in BrainFormer by a single-stream model. To handle multisite data, we propose a normalization layer to normalize the data into identical distribution. Finally, a Gradient-based Localization-map Visualization method is utilized for locating the possible disease-related biomarker. We evaluate BrainFormer on five independently acquired datasets including ABIDE, ADNI, MPILMBB, ADHD-200 and ECHO, with diseases of autism, Alzheimer's disease, depression, attention deficit hyperactivity disorder, and headache disorders. The results demonstrate the effectiveness and generalizability of BrainFormer for multiple brain diseases diagnosis. BrainFormer may promote neuroimaging-based precision diagnosis in clinical practice and motivate future study in fMRI analysis. Code is available at: <a class="link-external link-https" href="https://github.com/ZiyaoZhangforPCL/BrainFormer" rel="external noopener nofollow">this https URL</a>.      
### 10.AID: Open-source Anechoic Interferer Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2208.03023.pdf)
>  A dataset of anechoic recordings of various sound sources encountered in domestic environments is presented. The dataset is intended to be a resource of non-stationary, environmental noise signals that, when convolved with acoustic impulse responses, can be used to simulate complex acoustic scenes. Additionally, a Python library is provided to generate random mixtures of the recordings in the dataset, which can be used as non-stationary interference signals.      
### 11.Calibrate the inter-observer segmentation uncertainty via diagnosis-first principle  [ :arrow_down: ](https://arxiv.org/pdf/2208.03016.pdf)
>  On the medical images, many of the tissues/lesions may be ambiguous. That is why the medical segmentation is typically annotated by a group of clinical experts to mitigate the personal bias. However, this clinical routine also brings new challenges to the application of machine learning algorithms. Without a definite ground-truth, it will be difficult to train and evaluate the deep learning models. When the annotations are collected from different graders, a common choice is majority vote. However such a strategy ignores the difference between the grader expertness. In this paper, we consider the task of predicting the segmentation with the calibrated inter-observer uncertainty. We note that in clinical practice, the medical image segmentation is usually used to assist the disease diagnosis. Inspired by this observation, we propose diagnosis-first principle, which is to take disease diagnosis as the criterion to calibrate the inter-observer segmentation uncertainty. Following this idea, a framework named Diagnosis First segmentation Framework (DiFF) is proposed to estimate diagnosis-first segmentation from the raw images.Specifically, DiFF will first learn to fuse the multi-rater segmentation labels to a single ground-truth which could maximize the disease diagnosis performance. We dubbed the fused ground-truth as Diagnosis First Ground-truth (DF-GT).Then, we further propose Take and Give Modelto segment DF-GT from the raw image. We verify the effectiveness of DiFF on three different medical segmentation tasks: OD/OC segmentation on fundus images, thyroid nodule segmentation on ultrasound images, and skin lesion segmentation on dermoscopic images. Experimental results show that the proposed DiFF is able to significantly facilitate the corresponding disease diagnosis, which outperforms previous state-of-the-art multi-rater learning methods.      
### 12.Effective Non-Iterative Phase Retrieval of 2-D Bandlimited Signals with Applications to Antenna Characterization and Diagnostics  [ :arrow_down: ](https://arxiv.org/pdf/2208.03015.pdf)
>  The Phase Retrieval problem is dealt with for the challenging case where just a single set of (phaseless) radiated field data is available. In particular, even still emulating the solution of crosswords puzzles, we provide decisive improvements over our recent approaches. In fact, by exploiting bandlimitedness and a suitable set of intersecting curves, we definitively lower the computational complexity (thus eliminating drawbacks) of our previous techniques. Numerical examples, concerning applications of actual interest, support the given theory and confirm the effectiveness of the developed procedure.      
### 13.Rethinking Degradation: Radiograph Super-Resolution via AID-SRGAN  [ :arrow_down: ](https://arxiv.org/pdf/2208.03008.pdf)
>  In this paper, we present a medical AttentIon Denoising Super Resolution Generative Adversarial Network (AID-SRGAN) for diographic image super-resolution. First, we present a medical practical degradation model that considers various degradation factors beyond downsampling. To the best of our knowledge, this is the first composite degradation model proposed for radiographic images. Furthermore, we propose AID-SRGAN, which can simultaneously denoise and generate high-resolution (HR) radiographs. In this model, we introduce an attention mechanism into the denoising module to make it more robust to complicated degradation. Finally, the SR module reconstructs the HR radiographs using the "clean" low-resolution (LR) radiographs. In addition, we propose a separate-joint training approach to train the model, and extensive experiments are conducted to show that the proposed method is superior to its counterparts. e.g., our proposed method achieves $31.90$ of PSNR with a scale factor of $4 \times$, which is $7.05 \%$ higher than that obtained by recent work, SPSR [16]. Our dataset and code will be made available at: <a class="link-external link-https" href="https://github.com/yongsongH/AIDSRGAN-MICCAI2022" rel="external noopener nofollow">this https URL</a>.      
### 14.Integrated Adaptive Control and Reference Governors for Constrained Systems with State-Dependent Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2208.02985.pdf)
>  This paper presents an adaptive reference governor (RG) framework for a linear system with matched nonlinear uncertainties that can depend on both time and states, subject to both state and input constraints. The proposed framework leverages an L1 adaptive controller (L1AC) that estimates and compensates for the uncertainties, and provides guaranteed transient performance, in terms of uniform bounds on the error between actual states and inputs and those of a nominal (i.e., uncertainty-free) system. The uniform performance bounds provided by the L1AC are used to tighten the pre-specified state and control constraints. A reference governor is then designed for the nominal system using the tightened constraints, and guarantees robust constraint satisfaction. Moreover, the conservatism introduced by the constraint tightening can be systematically reduced by tuning some parameters within the L1AC. Compared with existing solutions, the proposed adaptive RG framework can potentially yield less conservative results for constraint enforcement due to the removal of uncertainty propagation along a prediction horizon, and improved tracking performance due to the inherent uncertainty compensation mechanism. Simulation results for a flight control example illustrate the efficacy of the proposed framework.      
### 15.Continuous Beam Alignment for Mobile MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2208.02945.pdf)
>  Millimeter-wave transceivers use large antenna arrays to form narrow high-directional beams and overcome severe attenuation. Narrow beams require large signaling overhead to be aligned if no prior information about beam directions is available. Moreover, beams drift with time due to user mobility and may need to be realigned. Beam tracking is commonly used to keep the beams tightly coupled and eliminate the overhead associated with realignment. Hence, with periodic measurements, beams are adjusted before they lose alignment. We propose a model where the receiver adjusts beam direction "continuously" over each physical-layer sample according to a carefully calculated estimate of the continuous variation of the beams. In our approach, the change of direction is updated using the estimate of the variation rate of beam angles via two different methods, a Continuous-Discrete Kalman filter and an MMSE of a first-order approximation of the variation. Our approach incurs no additional overhead in pilots, yet, the performance of beam tracking is improved significantly. Numerical results reveal an SNR enhancement associated with reducing the MSE of the beam directions. In addition, our approach reduces the pilot overhead by 60% and up to 87% while achieving a similar total tracking duration as the state-of-the-art.      
### 16.Rate Splitting Multiple Access for Cognitive Radio GEO-LEO Co-Existing Satellite Networks  [ :arrow_down: ](https://arxiv.org/pdf/2208.02924.pdf)
>  LEO satellite communication has drawn particular attention recently due to its high data rate services and low round-trip latency. It is low-cost to launch and can provide global coverage. However, the spectrum scarcity might be one of the critical challenges in the growth of LEO satellites, impacting severe restrictions on the development of ground-space integrated networks. To address this issue, we propose RSMA for CR enabled GEO-LEO coexisting satellite network. In particular, this work aims to maximize the system's sum rate by simultaneously optimizing the power allocation and subcarrier beam assignment of LEO satellite communication while restricting the interference temperature to GEO satellite users. The problem of sum rate maximization is formulated as non-convex and a Global optimal solution is challenging to obtain. Therefore, we first employ the successive convex approximation technique to reduce the complexity and make the problem more tractable. Then for the power allocation, we exploit KKT condition and adopt an efficient algorithm based on the greedy approach for subcarrier beam assignment. We also propose two suboptimal schemes with fixed power allocation and random subcarrier beam assignment as the benchmark. Results demonstrate the benefits of the proposed scheme compared to the benchmark schemes.      
### 17.Unsupervised Tissue Segmentation via Deep Constrained Gaussian Network  [ :arrow_down: ](https://arxiv.org/pdf/2208.02912.pdf)
>  Tissue segmentation is the mainstay of pathological examination, whereas the manual delineation is unduly burdensome. To assist this time-consuming and subjective manual step, researchers have devised methods to automatically segment structures in pathological images. Recently, automated machine and deep learning based methods dominate tissue segmentation research studies. However, most machine and deep learning based approaches are supervised and developed using a large number of training samples, in which the pixelwise annotations are expensive and sometimes can be impossible to obtain. This paper introduces a novel unsupervised learning paradigm by integrating an end-to-end deep mixture model with a constrained indicator to acquire accurate semantic tissue segmentation. This constraint aims to centralise the components of deep mixture models during the calculation of the optimisation function. In so doing, the redundant or empty class issues, which are common in current unsupervised learning methods, can be greatly reduced. By validation on both public and in-house datasets, the proposed deep constrained Gaussian network achieves significantly (Wilcoxon signed-rank test) better performance (with the average Dice scores of 0.737 and 0.735, respectively) on tissue segmentation with improved stability and robustness, compared to other existing unsupervised segmentation approaches. Furthermore, the proposed method presents a similar performance (p-value &gt; 0.05) compared to the fully supervised U-Net.      
### 18.A Novel Automated Classification and Segmentation for COVID-19 using 3D CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2208.02910.pdf)
>  Medical image classification and segmentation based on deep learning (DL) are emergency research topics for diagnosing variant viruses of the current COVID-19 situation. In COVID-19 computed tomography (CT) images of the lungs, ground glass turbidity is the most common finding that requires specialist diagnosis. Based on this situation, some researchers propose the relevant DL models which can replace professional diagnostic specialists in clinics when lacking expertise. However, although DL methods have a stunning performance in medical image processing, the limited datasets can be a challenge in developing the accuracy of diagnosis at the human level. In addition, deep learning algorithms face the challenge of classifying and segmenting medical images in three or even multiple dimensions and maintaining high accuracy rates. Consequently, with a guaranteed high level of accuracy, our model can classify the patients' CT images into three types: Normal, Pneumonia and COVID. Subsequently, two datasets are used for segmentation, one of the datasets even has only a limited amount of data (20 cases). Our system combined the classification model and the segmentation model together, a fully integrated diagnostic model was built on the basis of ResNet50 and 3D U-Net algorithm. By feeding with different datasets, the COVID image segmentation of the infected area will be carried out according to classification results. Our model achieves 94.52% accuracy in the classification of lung lesions by 3 types: COVID, Pneumonia and Normal. For future medical use, embedding the model into the medical facilities might be an efficient way of assisting or substituting doctors with diagnoses, therefore, a broader range of the problem of variant viruses in the COVID-19 situation may also be successfully solved.      
### 19.Automatic Segmentation of the Placenta in BOLD MRI Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2208.02895.pdf)
>  Blood oxygen level dependent (BOLD) MRI with maternal hyperoxia can assess oxygen transport within the placenta and has emerged as a promising tool to study placental function. Measuring signal changes over time requires segmenting the placenta in each volume of the time series. Due to the large number of volumes in the BOLD time series, existing studies rely on registration to map all volumes to a manually segmented template. As the placenta can undergo large deformation due to fetal motion, maternal motion, and contractions, this approach often results in a large number of discarded volumes, where the registration approach fails. In this work, we propose a machine learning model based on a U-Net neural network architecture to automatically segment the placenta in BOLD MRI and apply it to segmenting each volume in a time series. We use a boundary-weighted loss function to accurately capture the placental shape. Our model is trained and tested on a cohort of 91 subjects containing healthy fetuses, fetuses with fetal growth restriction, and mothers with high BMI. We achieve a Dice score of 0.83+/-0.04 when matching with ground truth labels and our model performs reliably in segmenting volumes in both normoxic and hyperoxic points in the BOLD time series. Our code and trained model are available at <a class="link-external link-https" href="https://github.com/mabulnaga/automatic-placenta-segmentation" rel="external noopener nofollow">this https URL</a>.      
### 20.Effect of State of Charge Uncertainty on Battery Energy Storage Systems  [ :arrow_down: ](https://arxiv.org/pdf/2208.02873.pdf)
>  Battery energy storage systems (BESSs) provide many benefits to the electricity grid, including stability, backup power, and flexibility in introducing more clean energy sources. As BESS penetration grows, knowledge of the uncertainty in the battery's state of charge (SOC) estimate is crucial for planning optimal BESS power injection trajectories. This paper proposes a framework for quantifying SOC estimation uncertainty based on battery rest periods. An uncertainty analysis is presented for a BESS participating in the frequency regulation market.      
### 21.Safe and Human-Like Autonomous Driving: A Predictor-Corrector Potential Game Approach  [ :arrow_down: ](https://arxiv.org/pdf/2208.02835.pdf)
>  This paper proposes a novel decision-making framework for autonomous vehicles (AVs), called predictor-corrector potential game (PCPG), composed of a Predictor and a Corrector. To enable human-like reasoning and characterize agent interactions, a receding-horizon multi-player game is formulated. To address the challenges caused by the complexity in solving a multi-player game and by the requirement of real-time operation, a potential game (PG) based decision-making framework is developed. In the PG Predictor, the agent cost functions are heuristically predefined. We acknowledge that the behaviors of other traffic agents, e.g., human-driven vehicles and pedestrians, may not necessarily be consistent with the predefined cost functions. To address this issue, a best response-based PG Corrector is designed. In the Corrector, the action deviation between the ego vehicle prediction and the surrounding agent actual behaviors are measured and are fed back to the ego vehicle decision-making, to correct the prediction errors caused by the inaccurate predefined cost functions and to improve the ego vehicle strategies. <br>Distinguished from most existing game-theoretic approaches, this PCPG 1) deals with multi-player games and guarantees the existence of a pure-strategy Nash equilibrium (PSNE), convergence of the PSNE seeking algorithm, and global optimality of the derived PSNE when multiple PSNE exist; 2) is computationally scalable in a multi-agent scenario; 3) guarantees the ego vehicle safety under certain conditions; and 4) approximates the actual PSNE of the system despite the unknown cost functions of others. Comparative studies between the PG, the PCPG, and the control barrier function (CBF) based approaches are conducted in diverse traffic scenarios, including oncoming traffic scenario and multi-vehicle intersection-crossing scenario.      
### 22.A Non-Asymptotic Framework for Approximate Message Passing in Spiked Models  [ :arrow_down: ](https://arxiv.org/pdf/2208.03313.pdf)
>  Approximate message passing (AMP) emerges as an effective iterative paradigm for solving high-dimensional statistical problems. However, prior AMP theory -- which focused mostly on high-dimensional asymptotics -- fell short of predicting the AMP dynamics when the number of iterations surpasses $o\big(\frac{\log n}{\log\log n}\big)$ (with $n$ the problem dimension). To address this inadequacy, this paper develops a non-asymptotic framework for understanding AMP in spiked matrix estimation. Built upon new decomposition of AMP updates and controllable residual terms, we lay out an analysis recipe to characterize the finite-sample behavior of AMP in the presence of an independent initialization, which is further generalized to allow for spectral initialization. As two concrete consequences of the proposed analysis recipe: (i) when solving $\mathbb{Z}_2$ synchronization, we predict the behavior of spectrally initialized AMP for up to $O\big(\frac{n}{\mathrm{poly}\log n}\big)$ iterations, showing that the algorithm succeeds without the need of a subsequent refinement stage (as conjectured recently by \citet{celentano2021local}); (ii) we characterize the non-asymptotic behavior of AMP in sparse PCA (in the spiked Wigner model) for a broad range of signal-to-noise ratio.      
### 23.A Model You Can Hear: Audio Identification with Playable Prototypes  [ :arrow_down: ](https://arxiv.org/pdf/2208.03311.pdf)
>  Machine learning techniques have proved useful for classifying and analyzing audio content. However, recent methods typically rely on abstract and high-dimensional representations that are difficult to interpret. Inspired by transformation-invariant approaches developed for image and 3D data, we propose an audio identification model based on learnable spectral prototypes. Equipped with dedicated transformation networks, these prototypes can be used to cluster and classify input audio samples from large collections of sounds. Our model can be trained with or without supervision and reaches state-of-the-art results for speaker and instrument identification, while remaining easily interpretable. The code is available at: <a class="link-external link-https" href="https://github.com/romainloiseau/a-model-you-can-hear" rel="external noopener nofollow">this https URL</a>      
### 24.Brain Lesion Synthesis via Progressive Adversarial Variational Auto-Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2208.03203.pdf)
>  Laser interstitial thermal therapy (LITT) is a novel minimally invasive treatment that is used to ablate intracranial structures to treat mesial temporal lobe epilepsy (MTLE). Region of interest (ROI) segmentation before and after LITT would enable automated lesion quantification to objectively assess treatment efficacy. Deep learning techniques, such as convolutional neural networks (CNNs) are state-of-the-art solutions for ROI segmentation, but require large amounts of annotated data during the training. However, collecting large datasets from emerging treatments such as LITT is impractical. In this paper, we propose a progressive brain lesion synthesis framework (PAVAE) to expand both the quantity and diversity of the training dataset. Concretely, our framework consists of two sequential networks: a mask synthesis network and a mask-guided lesion synthesis network. To better employ extrinsic information to provide additional supervision during network training, we design a condition embedding block (CEB) and a mask embedding block (MEB) to encode inherent conditions of masks to the feature space. Finally, a segmentation network is trained using raw and synthetic lesion images to evaluate the effectiveness of the proposed framework. Experimental results show that our method can achieve realistic synthetic results and boost the performance of down-stream segmentation tasks above traditional data augmentation techniques.      
### 25.Robust Acoustic Domain Identification with its Application to Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2208.03162.pdf)
>  With the rise in multimedia content over the years, more variety is observed in the recording environments of audio. An audio processing system might benefit when it has a module to identify the acoustic domain at its front-end. In this paper, we demonstrate the idea of \emph{acoustic domain identification} (ADI) for \emph{speaker diarization}. For this, we first present a detailed study of the various domains of the third DIHARD challenge highlighting the factors that differentiated them from each other. Our main contribution is to develop a simple and efficient solution for ADI. In the present work, we explore speaker embeddings for this task. Next, we integrate the ADI module with the speaker diarization framework of the DIHARD III challenge. The performance substantially improved over that of the baseline when the thresholds for agglomerative hierarchical clustering were optimized according to the respective domains. We achieved a relative improvement of more than $5\%$ and $8\%$ in DER for core and full conditions, respectively, on Track 1 of the DIHARD III evaluation set.      
### 26.A Lightweight Machine Learning Pipeline for LiDAR-simulation  [ :arrow_down: ](https://arxiv.org/pdf/2208.03130.pdf)
>  Virtual testing is a crucial task to ensure safety in autonomous driving, and sensor simulation is an important task in this domain. Most current LiDAR simulations are very simplistic and are mainly used to perform initial tests, while the majority of insights are gathered on the road. In this paper, we propose a lightweight approach for more realistic LiDAR simulation that learns a real sensor's behavior from test drive data and transforms this to the virtual domain. The central idea is to cast the simulation into an image-to-image translation problem. We train our pix2pix based architecture on two real world data sets, namely the popular KITTI data set and the Audi Autonomous Driving Dataset which provide both, RGB and LiDAR images. We apply this network on synthetic renderings and show that it generalizes sufficiently from real images to simulated images. This strategy enables to skip the sensor-specific, expensive and complex LiDAR physics simulation in our synthetic world and avoids oversimplification and a large domain-gap through the clean synthetic environment.      
### 27.A Design of Low-Projection SCMA Codebooks for Downlink Satellite Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2208.03118.pdf)
>  This paper presents a systematic investigation on codebook design of sparse code multiple access (SCMA) communication in downlink satellite Internet-of-Things (S-IoT) systems that are generally characterized by Rician fading channels. To serve a huge number of low-end IoT sensors, we aim to develop enhanced SCMA codebooks which enable ultra-low decoding complexity, while achieving good error performance. By analysing the pair-wise probability in Rician fading channels, we deduce the design metrics for multi-dimensional constellation construction and sparse codebook optimization. To reduce the decoding complexity, we advocate the key idea of projecting the multi-dimensional constellation elements to a few overlapped complex numbers in each dimension, called low projection (LP). We consider golden angle modulation (GAM), thus the resultant multi-dimensional constellation is called LPGAM. With the proposed design metrics and based on LPGAM, we propose an efficient approach of multi-stage optimization of sparse codebooks. Numerical and simulation results show the superiority of the proposed LP codebooks (LPCBs) in terms of decoding complexity and error rate performance. In particular, some of the proposed LPCBs can reduce the decoding complexity by 97\% compared to the conventional codebooks, and own the largest minimum Euclidean distance among existing codebooks. The proposed LPCBs are available at \url{<a class="link-external link-https" href="https://github.com/ethanlq/SCMA-codebook" rel="external noopener nofollow">this https URL</a>}.      
### 28.Deep Feature Learning for Medical Acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2208.03084.pdf)
>  The purpose of this paper is to compare different learnable frontends in medical acoustics tasks. A framework has been implemented to classify human respiratory sounds and heartbeats in two categories, i.e. healthy or affected by pathologies. After obtaining two suitable datasets, we proceeded to classify the sounds using two learnable state-of-art frontends -- LEAF and nnAudio -- plus a non-learnable baseline frontend, i.e. Mel-filterbanks. The computed features are then fed into two different CNN models, namely VGG16 and EfficientNet. The frontends are carefully benchmarked in terms of the number of parameters, computational resources, and effectiveness. <br>This work demonstrates how the integration of learnable frontends in neural audio classification systems may improve performance, especially in the field of medical acoustics. However, the usage of such frameworks makes the needed amount of data even larger. Consequently, they are useful if the amount of data available for training is adequately large to assist the feature learning process.      
### 29.Activity Detection in Distributed MIMO: Distributed AMP via Likelihood Ratio Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2208.03070.pdf)
>  We develop a new algorithm for activity detection for grant-free multiple access in distributed multiple-input multiple-output (MIMO). The algorithm is a distributed version of the approximate message passing (AMP) based on a soft combination of likelihood ratios computed independently at multiple access points. The underpinning theoretical basis of our algorithm is a new observation that we made about the state evolution in the AMP. Specifically, with a minimum mean-square error denoiser, the state maintains a block-diagonal structure whenever the covariance matrices of the signals have such a structure. We show by numerical examples that the algorithm outperforms competing schemes from the literature.      
### 30.Large vocabulary speech recognition for languages of Africa: multilingual modeling and self-supervised learning  [ :arrow_down: ](https://arxiv.org/pdf/2208.03067.pdf)
>  Almost none of the 2,000+ languages spoken in Africa have widely available automatic speech recognition systems, and the required data is also only available for a few languages. We have experimented with two techniques which may provide pathways to large vocabulary speech recognition for African languages: multilingual modeling and self-supervised learning. We gathered available open source data and collected data for 15 languages, and trained experimental models using these techniques. Our results show that pooling the small amounts of data available in multilingual end-to-end models, and pre-training on unsupervised data can help improve speech recognition quality for many African languages.      
### 31.Multi-Axis Control of a Qubit in the Presence of Unknown Non-Markovian Quantum Noise  [ :arrow_down: ](https://arxiv.org/pdf/2208.03058.pdf)
>  In this paper, we consider the problem of open-loop control of a qubit that is coupled to an unknown fully quantum non-Markovian noise (either bosonic or fermionic). A graybox model that is empirically obtained from measurement data is employed to approximately represent the unknown quantum noise. The estimated model is then used to calculate the open-loop control pulses under constraints on the pulse amplitude and timing. For the control pulse optimization, we explore the use of gradient descent and genetic optimization methods. We consider the effect of finite sampling on estimating expectation values of observables and show results for single- and multi-axis control of a qubit.      
### 32.Joint Beamforming Design in DFRC Systems for Wideband Sensing and OFDM Communications  [ :arrow_down: ](https://arxiv.org/pdf/2208.03055.pdf)
>  Dual-function radar-communication (DFRC) systems, which can efficiently utilize the congested spectrum and costly hardware resources by employing one common waveform for both sensing and communication (S&amp;C), have attracted increasing attention. While the orthogonal frequency division multiplexing (OFDM) technique has been widely adopted to support high-quality communications, it also has great potentials of improving radar sensing performance and providing flexible S&amp;C. In this paper, we propose to jointly design the dual-functional transmit signals occupying several subcarriers to realize multi-user OFDM communications and detect one moving target in the presence of clutter. Meanwhile, the signals in other frequency subcarriers can be optimized in a similar way to perform other tasks. The transmit beamforming and receive filter are jointly optimized to maximize the radar output signal-to-interference-plus-noise ratio (SINR), while satisfying the communication SINR requirement and the power budget. An majorization minimization (MM) method based algorithm is developed to solve the resulting non-convex optimization problem. Numerical results reveal the significant wideband sensing gain brought by jointly designing the transmit signals in different subcarriers, and demonstrate the advantages of our proposed scheme and the effectiveness of the developed algorithm.      
### 33.Hybrid Multimodal Feature Extraction, Mining and Fusion for Sentiment Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2208.03051.pdf)
>  In this paper, we present our solutions for the Multimodal Sentiment Analysis Challenge (MuSe) 2022, which includes MuSe-Humor, MuSe-Reaction and MuSe-Stress Sub-challenges. The MuSe 2022 focuses on humor detection, emotional reactions and multimodal emotional stress utilising different modalities and data sets. In our work, different kinds of multimodal features are extracted, including acoustic, visual, text and biological features. These features are fused by TEMMA and GRU with self-attention mechanism frameworks. In this paper, 1) several new audio features, facial expression features and paragraph-level text embeddings are extracted for accuracy improvement. 2) we substantially improve the accuracy and reliability for multimodal sentiment prediction by mining and blending the multimodal features. 3) effective data augmentation strategies are applied in model training to alleviate the problem of sample imbalance and prevent the model form learning biased subject characters. For the MuSe-Humor sub-challenge, our model obtains the AUC score of 0.8932. For the MuSe-Reaction sub-challenge, the Pearson's Correlations Coefficient of our approach on the test set is 0.3879, which outperforms all other participants. For the MuSe-Stress sub-challenge, our approach outperforms the baseline in both arousal and valence on the test dataset, reaching a final combined result of 0.5151.      
### 34.Alignment of Free-Space Coupling of Few-Mode Fibre to Multi-Mode Fibre using Digital Holography  [ :arrow_down: ](https://arxiv.org/pdf/2208.02904.pdf)
>  Off-axis digital holography is used to align a few-mode fiber to a multi-mode fiber in a free-space optical setup. Alignment based on power coupling measurements alone cannot guarantee low mode-dependent loss. The proposed alignment method enables reliable fiber coupling with low mode-dependent loss and crosstalk.      
### 35.Deep Surrogate of Modular Multi Pump using Active Learning  [ :arrow_down: ](https://arxiv.org/pdf/2208.02840.pdf)
>  Due to the high cost and reliability of sensors, the designers of a pump reduce the needed number of sensors for the estimation of the feasible operating point as much as possible. The major challenge to obtain a good estimation is the low amount of data available. Using this amount of data, the performance of the estimation method is not enough to satisfy the client requests. To solve this problem of scarcity of data, getting high quality data is important to obtain a good estimation. Based on these considerations, we develop an active learning framework for estimating the operating point of a Modular Multi Pump used in energy field. In particular we focus on the estimation of the surge distance. We apply Active learning to estimate the surge distance with minimal dataset. Results report that active learning is a valuable technique also for real application.      
### 36.Core and Periphery as Closed-System Precepts for Engineering General Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2208.02837.pdf)
>  Engineering methods are centered around traditional notions of decomposition and recomposition that rely on partitioning the inputs and outputs of components to allow for component-level properties to hold after their composition. In artificial intelligence (AI), however, systems are often expected to influence their environments, and, by way of their environments, to influence themselves. Thus, it is unclear if an AI system's inputs will be independent of its outputs, and, therefore, if AI systems can be treated as traditional components. This paper posits that engineering general intelligence requires new general systems precepts, termed the core and periphery, and explores their theoretical uses. The new precepts are elaborated using abstract systems theory and the Law of Requisite Variety. By using the presented material, engineers can better understand the general character of regulating the outcomes of AI to achieve stakeholder needs and how the general systems nature of embodiment challenges traditional engineering practice.      
