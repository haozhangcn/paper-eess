# ArXiv eess --Tue, 15 Mar 2022
### 1.Accelerating Plug-and-Play Image Reconstruction via Multi-Stage Sketched Gradients  [ :arrow_down: ](https://arxiv.org/pdf/2203.07308.pdf)
>  In this work we propose a new paradigm for designing fast plug-and-play (PnP) algorithms using dimensionality reduction techniques. Unlike existing approaches which utilize stochastic gradient iterations for acceleration, we propose novel multi-stage sketched gradient iterations which first perform downsampling dimensionality reduction in the image space, and then efficiently approximate the true gradient using the sketched gradient in the low-dimensional space. This sketched gradient scheme can also be naturally combined with PnP-SGD methods for further improvement on computational complexity. As a generic acceleration scheme, it can be applied to accelerate any existing PnP/RED algorithm. Our numerical experiments on X-ray fan-beam CT demonstrate the remarkable effectiveness of our scheme, that a computational free-lunch can be obtained using this dimensionality reduction in the image space.      
### 2.An Observer-Based Composite Identifier for Online Estimation of the Thevenin Equivalent Parameters of a Power System  [ :arrow_down: ](https://arxiv.org/pdf/2203.07273.pdf)
>  We consider a ThÃ©venin equivalent circuit capturing the dynamics of a power grid as seen from the point of common coupling with a power electronic converter, and provide a solution to the problem of online identification of the corresponding circuit parameters. For this purpose, we first derive a linear regression model in the conventional abc coordinates and next design a bounded observer-based composite identifier that requires local measurements and knowledge of the grid frequency only. An extension that guarantees exponential convergence of the estimates, under the additional assumption of knowledge of the grid X/R ratio, is further provided. The performance of the proposed identifier, which subsumes a conventional gradient descent algorithm, is illustrated via detailed computer simulations.      
### 3.Constrained RIS Phase Profile Optimization and Time Sharing for Near-field Localization  [ :arrow_down: ](https://arxiv.org/pdf/2203.07269.pdf)
>  The rising concept of reconfigurable intelligent surface (RIS) has promising potential for Beyond 5G localization applications. We herein investigate different phase profile designs at a reflective RIS, which enable non-line-of-sight positioning in nearfield from downlink single antenna transmissions. We first derive the closed-form expressions of the corresponding Fisher information matrix (FIM) and position error bound (PEB). Accordingly, we then propose a new localization-optimal phase profile design, assuming prior knowledge of the user equipment location. Numerical simulations in a canonical scenario show that our proposal outperforms conventional RIS random and directional beam codebook designs in terms of PEB. We also illustrate the four beams allocated at the RIS (i.e., one directional beam, along with its derivatives with respect to space dimensions) and show how their relative weights according to the optimal solution can be practically implemented through time sharing (i.e., considering feasible beams sequentially).      
### 4.Modulating Retroreflector Based Free Space Optical Link for UAV-to-Ground Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.07234.pdf)
>  Weight reduction and low power consumption are key requirements in the next generation of unmanned aerial vehicle (UAV) networks. Employing modulating retro-reflector (MRR)-based free space optical (FSO) technology is an innovative technique for UAV-to-ground communication in order to reduce the payload weight and power consumption of UAVs which leads to increased maneuverability and flight time of UAV. In this paper, we consider an MRR-based FSO system for UAV-to-ground communication. We will show that the performance of the considered system is very sensitive to tracking errors. Therefore, to assess the benefits of MRR-based UAV deployment for FSO communications, the MRR-based UAV FSO channel is characterized by taking into account tracking system errors along with UAV's orientation fluctuations, link length, UAV's height, optical beam divergence angle, effective area of MRR, atmospheric turbulence and optical channel loss in the double-pass channels. To enable effective performance analysis, tractable and closed-form expressions are derived for probability density function of end-to-end signal to noise ratio, outage probability and bit error rate of the considered system under both weak-to-moderate and moderate-to-strong atmospheric turbulence conditions. The accuracy of the analytical expressions is verified by extensive simulations. Analytical results are then used to study the relationship between the optimal system design and tracking system errors.      
### 5.Allocation of spinning reserves for autonomous grids subject to frequency stability constraints and short-term renewable power variations  [ :arrow_down: ](https://arxiv.org/pdf/2203.07233.pdf)
>  Low-inertia, isolated power systems face the problem of resiliency to power variations. The integration of renewable energy sources, such as wind and solar photovoltaic, pushes the boundaries of this issue further. Higher shares of renewables requires better evaluations of electrical system stability, to avoid severe safety and economic consequences. Accounting for frequency stability requirements and allocating proper spinning reserves, therefore becomes a topic of pivotal importance in the long-term planning and operational management of power systems. In this paper, dynamic frequency constraints are proposed to ensure resiliency during short-term power variations due to, for example, wind gusts or cloud passage. The use of the proposed constraints is exemplified in a case study, the constraints being integrated into a mixed-integer linear programming algorithm for sizing the optimal capacities of solar photovoltaic and battery energy storage resources in an isolated industrial plant. Outcomes of this case study show that reductions in the levelized cost of energy and carbon emissions can be overestimated by 8.0% and 10.8% respectively, where frequency constraints are neglected. The proposed optimal sizing is validated using time-domain simulations of the case study. The results indicate that this optimal system is frequency stable under the worst-case contingency.      
### 6.Arbitrary Beam Pattern Approximation via RISs with Measured Element Responses  [ :arrow_down: ](https://arxiv.org/pdf/2203.07225.pdf)
>  Smart radio environments (SREs) are seen as a key rising concept of next generation wireless networks, where propagation channels between transmitters and receivers are purposely controlled. One promising approach to achieve such channel flexibility relies on semipassive reflective Reconfigurable intelligent surfaces (RISs), which can shape the bouncing multipath signals for enhancing communication quality of service, making localization feasible in adverse operating conditions, or reducing unwanted electromagnetic emissions. This paper introduces a generic framework that aims at optimizing the end-to-end precoder controlled by RISs, so that arbitrary beam patterns can be generated, given a predefined lookup table of RIS element-wise complex reflection coefficients. This method is validated and illustrated for different targeted beam patterns in both the far-field and the near-field regimes, while considering the prior characterization of real-life RIS hardware prototypes. These results show how, and to which extent, RIS configuration optimization can approximate the desired beams under realistic hardware limitations and low-complexity implementation practicability, or conversely, which RIS elements' lookup tables would be more suitable. The latter can provide useful guidelines for future RIS hardware designs.      
### 7.Mixture Components Inference for Sparse Regression: Introduction and Application for Estimation of Neuronal Signal from fMRI BOLD  [ :arrow_down: ](https://arxiv.org/pdf/2203.07209.pdf)
>  Sparse linear regression methods including the well-known LASSO and the Dantzig selector have become ubiquitous in the engineering practice, including in medical imaging. Among other tasks, they have been successfully applied for the estimation of neuronal activity from functional magnetic resonance data without prior knowledge of the stimulus or activation timing, utilizing an approximate knowledge of the hemodynamic response to local neuronal activity. These methods work by generating a parametric family of solutions with different sparsity, among which an ultimate choice is made using an information criteria. We propose a novel approach, that instead of selecting a single option from the family of regularized solutions, utilizes the whole family of such sparse regression solutions. Namely, their ensemble provides a first approximation of probability of activation at each time-point, and together with the conditional neuronal activity distributions estimated with the theory of mixtures with varying concentrations, they serve as the inputs to a Bayes classifier eventually deciding on the verity of activation at each time-point. We show in extensive numerical simulations that this new method performs favourably in comparison with standard approaches in a range of realistic scenarios. This is mainly due to the avoidance of overfitting and underfitting that commonly plague the solutions based on sparse regression combined with model selection methods, including the corrected Akaike Information Criterion. This advantage is finally documented in selected fMRI task datasets.      
### 8.Pulses with Minimum Residual Intersymbol Interference for Faster than Nyquist Signaling  [ :arrow_down: ](https://arxiv.org/pdf/2203.07156.pdf)
>  Faster than Nyquist signaling increases the spectral efficiency of pulse amplitude modulation by accepting intersymbol interference, where an equalizer is needed at the receiver. Since the complexity of an optimal equalizer increases exponentially with the number of the interfering symbols, practical truncated equalizers assume shorter memory. The power of the resulting residual interference depends on the transmit filter and limits the performance of truncated equalizers. In this paper, we use numerical optimizations and the prolate spheroidal wave functions to find optimal time-limited pulses that achieve minimum residual interference. Compared to root raised cosine pulses, the new pulses decrease the residual interference by an order of magnitude, for example, a decrease by 32 dB is achieved for an equalizer that considers four interfering symbols at 57% faster transmissions. As a proof of concept, for the 57% faster transmissions of binary symbols, we showed that using the new pulse with a 4-state equalizer has better bit error rate performance compared to using a root raised cosine pulse with a 128-state equalizer.      
### 9.WSSAMNet: Weakly Supervised Semantic Attentive Medical Image Registration Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.07114.pdf)
>  We present WSSAMNet, a weakly supervised method for medical image registration. Ours is a two step method, with the first step being the computation of segmentation masks of the fixed and moving volumes. These masks are then used to attend to the input volume, which are then provided as inputs to a registration network in the second step. The registration network computes the deformation field to perform the alignment between the fixed and the moving volumes. We study the effectiveness of our technique on the BraTSReg challenge data against ANTs and VoxelMorph, where we demonstrate that our method performs competitively.      
### 10.Incremental Control System Design and Flight Tests of a Micro-Coaxial Rotor UAV  [ :arrow_down: ](https://arxiv.org/pdf/2203.07087.pdf)
>  In this paper, the incremental nonlinear dynamic inversion (INDI) method is applied to the control system design of coaxial rotor UAVs. The aerodynamic uncertainty and anti-disturbance problems are solved in the control system design. The designed controller gives the UAV excellent flight performance and control robustness. An incremental gain method (IGM) is proposed for the delay problem of the state derivative. This method has the advantages of less calculation load and simple parameter adjustment, which provides excellent convenience for applying INDI controllers to coaxial rotor UAVs. The principle of IGM is demonstrated by the stability analysis method of the discrete system, and the parameter selection strategy of the IGM is analyzed in detail by simulation. The advantages of the controller design method are verified by comparative flight tests of nonlinear dynamic inversion (NDI) and INDI. The experimental results show that the average trajectory tracking error of INDI is only 58.3% of that of NDI under the same wind speed. When the angular acceleration delay is less than 0.06 s, IGM can easily keep the system stable. In addition, INDI has better robustness under obvious model errors and strong input disturbance.      
### 11.Optimal Aggregation Strategies for Social Learning over Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2203.07065.pdf)
>  Adaptive social learning is a useful tool for studying distributed decision-making problems over graphs. This paper investigates the effect of combination policies on the performance of adaptive social learning strategies. Using large-deviation analysis, it first derives a bound on the probability of error and characterizes the optimal selection for the Perron eigenvectors of the combination policies. It subsequently studies the effect of the combination policy on the transient behavior of the learning strategy by estimating the adaptation time in the small signal-to-noise ratio regime. In the process, it is discovered that, interestingly, the influence of the combination policy on the transient behavior is insignificant, and thus it is more critical to employ policies that enhance the steady-state performance. The theoretical conclusions are illustrated by means of computer simulations.      
### 12.A novel constraint tightening approach for robust data-driven predictive control  [ :arrow_down: ](https://arxiv.org/pdf/2203.07055.pdf)
>  In this paper, we present a data-driven model predictive control (MPC) scheme that is capable of stabilizing unknown linear time-invariant systems under the influence of process disturbances. To this end, Willems' lemma is used to predict the future behavior of the system. This allows the entire scheme to be set up using only a priori measured data and knowledge of an upper bound on the system order. First, we develop a state-feedback MPC scheme, based on input-state data, which guarantees closed-loop practical exponential stability and recursive feasibility as well as closed-loop constraint satisfaction. The scheme is extended by a suitable constraint tightening, which can also be constructed using only data. In order to control a priori unstable systems, the presented scheme contains a pre-stabilizing controller and an associated input constraint tightening. We first present the proposed data-driven MPC scheme for the case of full state measurements, and also provide extensions for obtaining similar closed-loop guarantees in case of output feedback. The presented scheme is applied to a numerical example.      
### 13.Energy Efficiency Maximization of Simultaneous Transmission and Reflection RIS Assisted Full-Duplex Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.07054.pdf)
>  This work studies the effectiveness of a novel simultaneous transmission and reflection reconfigurable intelligent surface (STAR-RIS) aided Full-Duplex (FD) communication system. We aim to maximize the energy efficiency by jointly optimizing the transmit power and passive beamforming at the STAR-RIS. We propose an efficient algorithm to optimize them iteratively under the alternating optimization framework. The successive convex approximation (SCA) and Dinkelbach's method are used to solve the power optimization subproblem. The penalty-based method is used to design passive beamforming at the STAR-RIS. Numerical results verify the convergence and effectiveness of the proposed algorithm, and further reveal the benifits of the combining of the STAR-RIS and FD communication compared to benchmarks.      
### 14.Thermal circuits assembling and state-space extraction for modelling heat transfer in buildings  [ :arrow_down: ](https://arxiv.org/pdf/2203.07032.pdf)
>  State-space representation is essential in the theory of dynamic systems. This paper introduces a methodology for obtaining state-space representation from the thermal models of elementary components of a building by the conjunction of two methods: 1) assembling of thermal circuits and 2) state-space extraction from thermal circuit. These methods are fully illustrated on a very simple model and tested on a real house of about 100 m 2 on which detailed measurements were achieved for 40 days at a time step of 10 min. The errors obtained between the measurements and the simulation results are in the order of $\pm$1 {\textdegree}C for a single zone and $\pm$2 {\textdegree}C for seven thermal zones. Besides simulation, parameter identification and control, the methods for assembling thermal circuits and extraction of state-space representation may be useful in Building Information Modelling (BIM).      
### 15.A Compositional Algorithm for the Conflict-Free Electric Vehicle Routing Problem  [ :arrow_down: ](https://arxiv.org/pdf/2203.06977.pdf)
>  The Conflict-Free Electric Vehicle Routing Problem (CF-EVRP) is an extension of the Vehicle Routing Problem (VRP), a combinatorial optimization problem of designing routes for vehicles to visit customers such that a cost function, typically the number of vehicles or the total travelled distance, is minimized. The problem finds many logistics applications, particularly for highly automated logistic systems for material handling. The CF-EVRP involves constraints such as time windows on the delivery to the customers, limited operating range of the vehicles, and limited capacity on the number of vehicles that a road segment can accommodate at the same time. In this paper, the compositional algorithm ComSat for solving the CF-EVRP is presented. The algorithm iterates through the sub-problems until a globally feasible solution is found. The proposed algorithm is implemented using an optimizing SMT-solver and is evaluated against an implementation of a previously presented monolithic model. The soundness and completeness of the algorithm are proven, and it is benchmarked on a set of generated problems and found to be able to solve problems of industrial size.      
### 16.Stability of Switched Affine Systems: Arbitrary and Dwell-Time Switching  [ :arrow_down: ](https://arxiv.org/pdf/2203.06968.pdf)
>  The dynamical behavior of switched affine systems is known to be more intricate than that of the well-studied switched linear systems, essentially due to the existence of distinct equilibrium points for each subsystem. First, under arbitrary switching rules, the stability analysis must be generally carried out with respect to a compact set with non-empty interior rather than to a singleton. We provide a novel proof technique for existence and outer approximation of attractive invariant sets of a switched affine system, under the hypothesis of global uniform stability of its linearization. On the other hand, considering dwell-time switching signals, forward invariant sets need not exist for this class of switched systems, even for stable ones. Hence, more general notions of stability/boundedness are introduced and studied, highlighting the relations of these concepts to the uniform stability of the linear part of the system under the same class of dwell-time switching signals. These results reveal the main differences and specificities of switched affine systems with respect to linear ones, providing a first step for the analysis of switched systems composed by subsystems not sharing the same equilibrium. Numerical methods based on linear matrix inequalities and sum-of-squares programming are presented and illustrate the developed theory.      
### 17.Exponentially stable adaptive control. Part I. Time-invariant plants  [ :arrow_down: ](https://arxiv.org/pdf/2203.06964.pdf)
>  In this research we consider linear time-invariant plants and assume that the regressor finite excitation requirement is met. In such case, a new law to adjust the controller parameters, which ensures the exponential stability of the classical dynamic model of the tracking error under the condition that its states are not included in such a law, is proposed in this study. In addition, it also relaxes a number of classical assumptions and requirements of the adaptive control theory, i.e. the necessity to know the sign/value of the plant high-frequency gain, the need of experimentally based choice of the proposed law adaptive gain value, the requirement to the tracking error transfer function to be strictly positive real considering the output feedback control. The applicability of the proposed law to the problems of adaptive state and output feedback control is shown. The advantages of the proposed method over the well-known ones are demonstrated.      
### 18.Data-Driven Robust Control for Discrete Linear Time-Invariant Systems: A Descriptor System Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.06959.pdf)
>  Given the recent surge of interest in data-driven control, this paper proposes a two-step method to study robust data-driven control for a parameter-unknown linear time-invariant (LTI) system that is affected by energy-bounded noises. First, two data experiments are designed and corresponding data are collected, then the investigated system is equivalently written into a data-based descriptor system with structured parametric uncertainties. Second, combined with model-based control theory for descriptor systems, state feedback controllers are designed for such data-based descriptor system, which stabilize the original LTI system and guarantee the ${H_\infty}$ performance. Finally, a simulation example is provided to illustrate the effectiveness and merits of our method.      
### 19.DS3-Net: Difficulty-perceived Common-to-T1ce Semi-Supervised Multimodal MRI Synthesis Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.06920.pdf)
>  Contrast-enhanced T1 (T1ce) is one of the most essential magnetic resonance imaging (MRI) modalities for diagnosing and analyzing brain tumors, especially gliomas. In clinical practice, common MRI modalities such as T1, T2, and fluid attenuation inversion recovery are relatively easy to access while T1ce is more challenging considering the additional cost and potential risk of allergies to the contrast agent. Therefore, it is of great clinical necessity to develop a method to synthesize T1ce from other common modalities. Current paired image translation methods typically have the issue of requiring a large amount of paired data and do not focus on specific regions of interest, e.g., the tumor region, in the synthesization process. To address these issues, we propose a Difficulty-perceived common-to-T1ce Semi-Supervised multimodal MRI Synthesis network (DS3-Net), involving both paired and unpaired data together with dual-level knowledge distillation. DS3-Net predicts a difficulty map to progressively promote the synthesis task. Specifically, a pixelwise constraint and a patchwise contrastive constraint are guided by the predicted difficulty map. Through extensive experiments on the publiclyavailable BraTS2020 dataset, DS3-Net outperforms its supervised counterpart in each respect. Furthermore, with only 5% paired data, the proposed DS3-Net achieves competitive performance with state-of-theart image translation methods utilizing 100% paired data, delivering an average SSIM of 0.8947 and an average PSNR of 23.60.      
### 20.Topological EEG Nonlinear Dynamics Analysis for Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.06895.pdf)
>  Emotional recognition through exploring the electroencephalography (EEG) characteristics has been widely performed in recent studies. Nonlinear analysis and feature extraction methods for understanding the complex dynamical phenomena are associated with the EEG patterns of different emotions. The phase space reconstruction is a typical nonlinear technique to reveal the dynamics of the brain neural system. Recently, the topological data analysis (TDA) scheme has been used to explore the properties of space, which provides a powerful tool to think over the phase space. In this work, we proposed a topological EEG nonlinear dynamics analysis approach using the phase space reconstruction (PSR) technique to convert EEG time series into phase space, and the persistent homology tool explores the topological properties of the phase space. We perform the topological analysis of EEG signals in different rhythm bands to build emotion feature vectors, which shows high distinguishing ability. We evaluate the approach with two well-known benchmark datasets, the DEAP and DREAMER datasets. The recognition results achieved accuracies of 99.37% and 99.35% in arousal and valence classification tasks with DEAP, and 99.96%, 99.93%, and 99.95% in arousal, valence, and dominance classifications tasks with DREAMER, respectively. The performances are supposed to be outperformed current state-of-art approaches in DREAMER (improved by 1% to 10% depends on temporal length), while comparable to other related works evaluated in DEAP. The proposed work is the first investigation in the emotion recognition oriented EEG topological feature analysis, which brought a novel insight into the brain neural system nonlinear dynamics analysis and feature extraction.      
### 21.Robust Event Triggering Control for Lateral Dynamics of Intelligent Vehicles with Designable Inter-event Times  [ :arrow_down: ](https://arxiv.org/pdf/2203.06882.pdf)
>  In this brief, an improved event-triggered update mechanism (ETM) for the linear quadratic regulator is proposed to solve the lateral motion control problem of intelligent vehicle under bounded disturbances. Based on a novel event function using a clock-like variable to determine the triggering time, we further introduce two new design parameters to improve control performance. Distinct from existing event-based control mechanisms, the inter-event times (IETs) derived from the above control framework are designable, meaning that the proposed ETM can be deployed on practical vehicle more easily and effectively. In addition, the improved IETs-designable ETM features a global robust event-separation property that is extremely required for practical lateral motion control of vehicle subject to diverse disturbances. Theoretical analysis proves the feasibility and stability of the proposed control strategy for trajectory tracking under bounded disturbances. Finally, simulation results verify the theoretical results and show the advantages of the proposed control strategy.      
### 22.Real-Time Electric Vehicle Smart Charging at Workplaces: A Real-World Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2203.06847.pdf)
>  We study a real-time smart charging algorithm for electric vehicles (EVs) at a workplace parking lot in order to minimize electricity cost from time-of-use electricity rates and demand charges while ensuring that the owners of the EVs receive adequate levels of charge. Notably, due to real-world constraints, our algorithm is agnostic to both the state-of-charge and the departure time of the EVs and uses scenario generation to account for each EV's unknown future departure time as well as certainty equivalent control to account for the unknown EV arrivals in the future. Real-world charging data from a Google campus in California allows us to build realistic models of charging demand for each day of the week. We then compare various results from our smart charging algorithm to the status quo for a two week period at a Google parking location.      
### 23.SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2203.06823.pdf)
>  Magnetic resonance imaging (MRI) is a cornerstone of modern medical imaging. However, long image acquisition times, the need for qualitative expert analysis, and the lack of (and difficulty extracting) quantitative indicators that are sensitive to tissue health have curtailed widespread clinical and research studies. While recent machine learning methods for MRI reconstruction and analysis have shown promise for reducing this burden, these techniques are primarily validated with imperfect image quality metrics, which are discordant with clinically-relevant measures that ultimately hamper clinical deployment and clinician trust. To mitigate this challenge, we present the Stanford Knee MRI with Multi-Task Evaluation (SKM-TEA) dataset, a collection of quantitative knee MRI (qMRI) scans that enables end-to-end, clinically-relevant evaluation of MRI reconstruction and analysis tools. This 1.6TB dataset consists of raw-data measurements of ~25,000 slices (155 patients) of anonymized patient MRI scans, the corresponding scanner-generated DICOM images, manual segmentations of four tissues, and bounding box annotations for sixteen clinically relevant pathologies. We provide a framework for using qMRI parameter maps, along with image reconstructions and dense image labels, for measuring the quality of qMRI biomarker estimates extracted from MRI reconstruction, segmentation, and detection techniques. Finally, we use this framework to benchmark state-of-the-art baselines on this dataset. We hope our SKM-TEA dataset and code can enable a broad spectrum of research for modular image reconstruction and image analysis in a clinically informed manner. Dataset access, code, and benchmarks are available at <a class="link-external link-https" href="https://github.com/StanfordMIMI/skm-tea" rel="external noopener nofollow">this https URL</a>.      
### 24.Robust 2-D DOA Estimation in a Polarization Sensitive Single User Environment  [ :arrow_down: ](https://arxiv.org/pdf/2203.06792.pdf)
>  Apart from the conventional parameters (such as signal-to-noise ratio, array geometry and size, sample size), several other factors (e.g. alignment of the antenna elements, polarization parameters) influence the performance of direction of arrival (DOA) estimating algorithms. When all the antenna elements are identically aligned, the polarization parameters do not affect the steering vectors, which is the underlying assumption of all the conventional DOA algorithms. Unfortunately, in this case, for a given set of DOA angles there exists a range of polarization parameters which could result in a very low signal-to-noise ratio (SNR) across all the antenna elements in the array. To avoid this type of catastrophic event, different antenna element needs to be aligned differently. However, this fact will make almost all commonly used DOA estimation algorithms non-operable, since the steering vectors are contaminated by the polarization parameters. To the best of our knowledge, no work in the literature addresses this issue even for a single user environment. In this paper, that line of inquiry is pursued. We consider a circular array with the minimum number of antenna elements and propose an antenna alignment scheme to ensure that at any given point no more than one element will suffer from significantly low SNR due to the contribution of polarization. A low complexity algorithm that estimates the DOA angles in a closed-form manner is developed. We treat MUSIC as the baseline algorithm and demonstrate how it can reliably operate in all possible DOA and polarization environments. Finally, a thorough performance and complexity analysis are illustrated for the above two algorithms.      
### 25.The development of battery storage systems in Germany: A market review (status 2022)  [ :arrow_down: ](https://arxiv.org/pdf/2203.06762.pdf)
>  With this update of our previous publications, we publish the latest data of the market development of battery storage systems (BSS) in Germany, one of the leading storage markets worldwide. For the analyses of both stationary and mobile storage markets, we use the public registrations of the German Federal Network Agency and the Federal Motor Transport Authority, our own databases from the monitoring of subsidy programs, and bilateral exchange with large companies. In comparison to 2020, the market for home storage systems (HSS) grew by 50% in terms of battery energy in 2021 and is by far the largest stationary storage market in Germany. We estimate that about 145,000 HSS (1.27 GWh / 0.73 GW) were installed solely in 2021. The average specific price for a medium-sized HSS was about 1,000 EUR/kWh in 2021, showing a price decrease of 8% from 2020 to 2021. The emerging market for industrial storage systems (ISS) grew by 15% in 2021, with a total of 900 ISS (0.06 GWh / 0.03 GW) installed, although industrial PV installations decreased. The market growth for large-scale storage systems (LSS) remains on a relatively low level with 11 LSS (0.03 GWh / 0.04 GW) commissioned. The market for battery electric vehicles (EV) doubled in 2021 and new registrations raised to 680,000 EV (22.45 GWh / 31.18 GW). The public charging infrastructure could not follow this growth and grew linearly with about 11,700 new installations to 50,000 charging points, most of which are up to 22 kW. The number of EV per charging point grew from 10 in 2018 to 25 in 2021. In total, we estimate that over 430,000 stationary BSS with a battery energy of 4.46 GWh and a power of 2.64 GW and 1,270,000 EV with a battery energy of 39.59 GWh, a DC charging power of 51.84 GW, and an AC charging power of 7.71 GW were operated in Germany by the end of 2021.      
### 26.PMU-Driven Non-Preemptive Disconnection of Overhead Lines at the Approach or Break-Out of Forest Fires  [ :arrow_down: ](https://arxiv.org/pdf/2203.06742.pdf)
>  The number and intensity of forest fires in the United States have been steadily increasing and causing massive economic and ecological damage. Overhead transmission and distribution lines are typically disconnected preemptively near fires, a practice that causes high social cost. Deployment of Phasor Measurement Units (PMUs) and their ability for synchronized real-time measurement of voltage and current inspire the here proposed method for the just-in-time disconnection of overhead lines at the ignition or approach of fires. PMUs can detect ambient temperature changes caused by fires through the change of line resistance. An ambient temperature model at the vicinity of a fire seat and the dynamic heat exchange model of the IEEE 738 dynamic line rating standard for bare overhead conductors are used in MATLAB Simulink to assess the performance of the proposed control method. Extensive testing shows that, under various conditions, the proposed technique can detect a forest fire approaching an overhead line, while avoiding, almost completely, any false alarms.      
### 27.A Stochastic Binary Vertex-Triggering Resetting Algorithm for Global Synchronization of Pulse-Coupled Oscillators  [ :arrow_down: ](https://arxiv.org/pdf/2203.06707.pdf)
>  In this paper, we propose a novel stochastic binary resetting algorithm for networks of pulse-coupled oscillators (or, simply, agents) to reach global synchronization. The algorithm is simple to state: Every agent in a network oscillates at a common frequency. Upon completing an oscillation, an agent generates a Bernoulli random variable to decide whether it sends pulses to all of its out-neighbors or it stays quiet. Upon receiving a pulse, an agent resets its state by following a binary phase update rule. We show that such an algorithm can guarantee global synchronization of the agents almost surely as long as the underlying information flow topology is a rooted directed graph. The proof of the result relies on the use of a stochastic hybrid dynamical system approach. Toward the end of the paper, we present numerical demonstrations for the validity of the result and, also, numerical studies about the times needed to reach synchronization for various information flow topologies.      
### 28.Pilot Reuse for mMTC with Spatially Correlated MIMO Channels: A Channel Charting Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.06651.pdf)
>  Massive multiple-input multiple-output (mMIMO) technology is a way to increase the spectral efficiency of machine-type communications (MTC). To exploit the benefits from large antenna arrays, accurate channel estimation through pilot signals is needed. Massive MTC systems cannot avoid pilot reuse due to the enormous numbers of connected devices. We propose a pilot reuse algorithm based on channel charting (CC) to mitigate pilot contamination in a multi-sector single-cell massive MTC system having spatially correlated channels. We show that after creating an interference map via CC, a simple strategy to allocate the pilot sequences can be implemented. The simulation results show that the CC-based pilot reuse strategy improves channel estimation accuracy, which subsequently improves the symbol detection performance and increases the spectral efficiency compared to other existing schemes. Moreover, the performance of the CC pilot assignment method approaches that of exhaustive search pilot assignment for small network setups.      
### 29.Cluster Assignment in Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.06642.pdf)
>  We study cluster assignment in multi-agent networks. We consider homogeneous diffusive networks, and focus on design of the graph that ensures the system will converge to a prescribed cluster configuration, i.e., specifying the number of clusters and agents within each cluster. Leveraging recent results from cluster synthesis, we show that it is possible to design an oriented graph such that the action of the automorphism group of the graph has orbits of predetermined sizes, guaranteeing that the network will converge to the prescribed cluster configuration. We provide upper and lower bounds on the number of edges that are needed to construct these graphs along with a constructive approach for generating these graphs. We support our analysis with some numerical examples.      
### 30.Adaptive Bit Rate Control in Semantic Communication with Incremental Knowledge-based HARQ  [ :arrow_down: ](https://arxiv.org/pdf/2203.06634.pdf)
>  With the development of natural language processing (NLP) and deep learning (DL), great progress has been made in the field of semantic communication. Although existing semantic communication technologies can effectively reduce errors in semantic interpretation, most of these solutions still adopt a fixed bit rate structure, which is inefficient and inflexible for sentences with different meanings and signal-to-noise ratio (SNR) conditions. In this paper, we explore the impact of adaptive bit rates on semantic coding (SC) under various channel conditions. First, we propose two progressive semantic hybrid automatic repeat request (HARQ) schemes, both of which exploit the incremental knowledge (IK) obtained from the retransmission, to further reduce the semantic error in the transmission process. We then design a novel semantic encoding solution with multi-bit rate selection. In this solution, the transmitter employs a policy network to decide the appropriate coding rate, so as to ensure the correct information delivery at the cost of minimal bits. Besides, we design two specific denoisers to reduce the semantic errors encountered in the transmission process according to the semantic characteristics of context and SNR. Finally, a novel end-to-end semantic communication framework is proposed by effectively combining the aforementioned methods. Extensive simulation results have been conducted to verify the effectiveness of the proposed solution.      
### 31.A Context-Aware Readout System for Sparse Touch Sensing Array Using Ultra-low-power Always-on Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2203.06613.pdf)
>  Increasing demand for larger touch screen panels (TSPs) places more energy burden to mobile systems with conventional sensing methods. To mitigate this problem, taking advantage of the touch event sparsity, this paper proposes a novel TSP readout system that can obtain huge energy saving by turning off the readout circuits when none of the sensors are activated. To this end, a novel ultra-low-power always-on event and region of interest detection based on lightweight compressed sensing is proposed. Exploiting the proposed event detector, the context-aware TSP readout system, which can improve the energy efficiency by up to 40x, is presented.      
### 32.Spectral Modification Based Data Augmentation For Improving End-to-End ASR For Children's Speech  [ :arrow_down: ](https://arxiv.org/pdf/2203.06600.pdf)
>  Training a robust Automatic Speech Recognition (ASR) system for children's speech recognition is a challenging task due to inherent differences in acoustic attributes of adult and child speech and scarcity of publicly available children's speech dataset. In this paper, a novel segmental spectrum warping and perturbations in formant energy are introduced, to generate a children-like speech spectrum from that of an adult's speech spectrum. Then, this modified adult spectrum is used as augmented data to improve end-to-end ASR systems for children's speech recognition. The proposed data augmentation methods give 6.5% and 6.1% relative reduction in WER on children dev and test sets respectively, compared to the vocal tract length perturbation (VTLP) baseline system trained on Librispeech 100 hours adult speech dataset. When children's speech data is added in training with Librispeech set, it gives a 3.7 % and 5.1% relative reduction in WER, compared to the VTLP baseline system.      
### 33.Spectral Graph Clustering for Intentional Islanding Operations in Resilient Hybrid Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.06579.pdf)
>  Establishing cleaner energy generation therefore improving the sustainability of the power system is a crucial task in this century, and one of the key strategies being pursued is to shift the dependence on fossil fuel to renewable technologies such as wind, solar, and nuclear. However, with the increasing number of heterogeneous components included, the complexity of the hybrid energy system becomes more significant. And the complex system imposes a more stringent requirement of the contingency plan to enhance the overall system resilience. Among different strategies to ensure a reliable system, intentional islanding is commonly applied in practical applications for power systems and attracts abundant interest in the literature. In this study, we propose a hierarchical spectral clustering-based intentional islanding strategy at the transmission level with renewable generations. To incorporate the renewable generation that relies on the inverter technology, the frequency measurements are considered to represent the transient response. And it has been further used as embedded information in the clustering algorithm along with other important electrical information from the system to enrich the modeling capability of the proposed framework. To demonstrate the effectiveness of the islanding strategy, the modified IEEE-9 bus and IEEE-118 bus systems coupled with wind farms are considered as the test cases.      
### 34.Change Detection from Synthetic Aperture Radar Images via Dual Path Denoising Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.06543.pdf)
>  Benefited from the rapid and sustainable development of synthetic aperture radar (SAR) sensors, change detection from SAR images has received increasing attentions over the past few years. Existing unsupervised deep learning-based methods have made great efforts to exploit robust feature representations, but they consume much time to optimize parameters. Besides, these methods use clustering to obtain pseudo-labels for training, and the pseudo-labeled samples often involve errors, which can be considered as "label noise". To address these issues, we propose a Dual Path Denoising Network (DPDNet) for SAR image change detection. In particular, we introduce the random label propagation to clean the label noise involved in preclassification. We also propose the distinctive patch convolution for feature representation learning to reduce the time consumption. Specifically, the attention mechanism is used to select distinctive pixels in the feature maps, and patches around these pixels are selected as convolution kernels. Consequently, the DPDNet does not require a great number of training samples for parameter optimization, and its computational efficiency is greatly enhanced. Extensive experiments have been conducted on five SAR datasets to verify the proposed DPDNet. The experimental results demonstrate that our method outperforms several state-of-the-art methods in change detection results.      
### 35.Cyclone Preparedness, Rescue Operations and Damage Assessment using UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2203.06497.pdf)
>  UAV's capability to access remote and inaccessible areas within a quick time can be utilized for effective cyclone management. This paper presents the possible application of UAVs at different stages of cyclone mitigation. The overall system architecture necessary for preparedness, rescue operation, resource allocation, and damage assessment using UAVs during cyclones is described. Although general commercial UAVs are reported to be used in cyclone operations, UAV systems should be planned specifically for cyclone operations to improve efficiency. Here, the specification required for effective and safe UAV operations in the post-cyclone scenario is presented. Mission planning required for various rescue, relief, and damage assessment missions related to cyclone management is discussed. A case study of deploying UAV in Amphan cyclone operation in West Bengal is also presented. This paper can help disaster management authorities to develop UAV systems specifically to cater to cyclone operations.      
### 36.Low-Complexity Multicast Beamforming for Millimeter Wave Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.06450.pdf)
>  To develop a low-complexity multicast beamforming method for millimeter wave communications, we first propose a channel gain estimation method in this article. We use the beam sweeping to find the best codeword and its two neighboring codewords to form a composite beam. We then estimate the channel gain based on the composite beam, which is computed off-line by minimizing the variance of beam gain within beam coverage. With the estimated channel gain, we propose a multicast beamforming design method under the max-min fair (MMF) criterion. To reduce the computational complexity, we divide the large antenna array into several small-size sub-arrays, where the size of each sub-array is determined by the estimated channel gain. In particular, we introduce a phase factor for each sub-array to explore additional degree of freedom for the considered problem. Simulation results show that the proposed multicast beamforming design method can substantially reduce the computational complexity with little performance sacrifice compared to the existing methods.      
### 37.Multi-step dual control for exploration and exploitation in autonomous search with convergence guarantee  [ :arrow_down: ](https://arxiv.org/pdf/2203.06440.pdf)
>  Motivated by the recently proposed dual control for exploration and exploitation (DCEE) concept, this paper presents a Multi-Step DCEE (MS-DCEE) framework with guaranteed convergence for autonomous search of a source of airborne dispersion. Different from the existing stochastic model predictive control (SMPC) algorithm and informative path planning (IPP) approaches, the proposed MS-DCEE approach uses the current and future input to not only drive the agent towards the estimated source location (exploitation) but also reduce its estimation uncertainty (exploration) by actively learning the operational environment. Unknown source target position, together with unknown environment, impose significant challenges in establishing the recursive feasibility and the convergence of the proposed algorithm. To address them, with the help of the property of Bayesian estimation, we develop a two-step approach where the unbiasedness of the mean estimation is assumed first and then the randomness of the mean estimate under each collected information sequence is accounted. Based on that, we develop a MS-DCEE scheme with suitable terminal ingredients where recursive feasibility and convergence are guaranteed. Two simulation scenarios are conducted, which show that the proposed MS-DCEE algorithm outperforms the SMPC, the IPP and the single-step DCEE approaches in terms of searching successful rates and efficiency.      
### 38.Recurrence-in-Recurrence Networks for Video Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2203.06418.pdf)
>  State-of-the-art video deblurring methods often adopt recurrent neural networks to model the temporal dependency between the frames. While the hidden states play key role in delivering information to the next frame, abrupt motion blur tend to weaken the relevance in the neighbor frames. In this paper, we propose recurrence-in-recurrence network architecture to cope with the limitations of short-ranged memory. We employ additional recurrent units inside the RNN cell. First, we employ inner-recurrence module (IRM) to manage the long-ranged dependency in a sequence. IRM learns to keep track of the cell memory and provides complementary information to find the deblurred frames. Second, we adopt an attention-based temporal blending strategy to extract the necessary part of the information in the local neighborhood. The adpative temporal blending (ATB) can either attenuate or amplify the features by the spatial attention. Our extensive experimental results and analysis validate the effectiveness of IRM and ATB on various RNN architectures.      
### 39.SSCU-Net: Spatial-Spectral Collaborative Unmixing Network for Hyperspectral Images  [ :arrow_down: ](https://arxiv.org/pdf/2203.06375.pdf)
>  Linear spectral unmixing is an essential technique in hyperspectral image processing and interpretation. In recent years, deep learning-based approaches have shown great promise in hyperspectral unmixing, in particular, unsupervised unmixing methods based on autoencoder networks are a recent trend. The autoencoder model, which automatically learns low-dimensional representations (abundances) and reconstructs data with their corresponding bases (endmembers), has achieved superior performance in hyperspectral unmixing. In this article, we explore the effective utilization of spatial and spectral information in autoencoder-based unmixing networks. Important findings on the use of spatial and spectral information in the autoencoder framework are discussed. Inspired by these findings, we propose a spatial-spectral collaborative unmixing network, called SSCU-Net, which learns a spatial autoencoder network and a spectral autoencoder network in an end-to-end manner to more effectively improve the unmixing performance. SSCU-Net is a two-stream deep network and shares an alternating architecture, where the two autoencoder networks are efficiently trained in a collaborative way for estimation of endmembers and abundances. Meanwhile, we propose a new spatial autoencoder network by introducing a superpixel segmentation method based on abundance information, which greatly facilitates the employment of spatial information and improves the accuracy of unmixing network. Moreover, extensive ablation studies are carried out to investigate the performance gain of SSCU-Net. Experimental results on both synthetic and real hyperspectral data sets illustrate the effectiveness and competitiveness of the proposed SSCU-Net compared with several state-of-the-art hyperspectral unmixing methods.      
### 40.LesionPaste: One-Shot Anomaly Detection for Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2203.06354.pdf)
>  Due to the high cost of manually annotating medical images, especially for large-scale datasets, anomaly detection has been explored through training models with only normal data. Lacking prior knowledge of true anomalies is the main reason for the limited application of previous anomaly detection methods, especially in the medical image analysis realm. In this work, we propose a one-shot anomaly detection framework, namely LesionPaste, that utilizes true anomalies from a single annotated sample and synthesizes artificial anomalous samples for anomaly detection. First, a lesion bank is constructed by applying augmentation to randomly selected lesion patches. Then, MixUp is adopted to paste patches from the lesion bank at random positions in normal images to synthesize anomalous samples for training. Finally, a classification network is trained using the synthetic abnormal samples and the true normal data. Extensive experiments are conducted on two publicly-available medical image datasets with different types of abnormalities. On both datasets, our proposed LesionPaste largely outperforms several state-of-the-art unsupervised and semi-supervised anomaly detection methods, and is on a par with the fully-supervised counterpart. To note, LesionPaste is even better than the fully-supervised method in detecting early-stage diabetic retinopathy.      
### 41.Auto-FedRL: Federated Hyperparameter Optimization for Multi-institutional Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2203.06338.pdf)
>  Federated learning (FL) is a distributed machine learning technique that enables collaborative model training while avoiding explicit data sharing. The inherent privacy-preserving property of FL algorithms makes them especially attractive to the medical field. However, in case of heterogeneous client data distributions, standard FL methods are unstable and require intensive hyperparameter tuning to achieve optimal performance. Conventional hyperparameter optimization algorithms are impractical in real-world FL applications as they involve numerous training trials, which are often not affordable with limited compute budgets. In this work, we propose an efficient reinforcement learning~(RL)-based federated hyperparameter optimization algorithm, termed Auto-FedRL, in which an online RL agent can dynamically adjust hyperparameters of each client based on the current training progress. Extensive experiments are conducted to investigate different search strategies and RL agents. The effectiveness of the proposed method is validated on a heterogeneous data split of the CIFAR-10 dataset as well as two real-world medical image segmentation datasets for COVID-19 lesion segmentation in chest CT and pancreas segmentation in abdominal CT.      
### 42.Hybrid Beamforming for Millimeter Wave MIMO Integrated Sensing and Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.06324.pdf)
>  In this letter, we consider hybrid beamforming for millimeter wave (mmWave) MIMO integrated sensing and communications (ISAC). We design the transmit beam of a dual-functional radar-communication (DFRC) base station (BS), aiming at approaching the objective radar beam pattern, subject to the constraints of the signal to interference-plus-noise ratio (SINR) of communication users and total transmission power of the DFRC BS. To provide additional degree of freedom for the beam design problem, we introduce a phase vector to the objective beam pattern and propose an alternating minimization method to iteratively optimize the transmit beam and the phase vector, which involves second-order cone programming and constrained least squared estimation, respectively. Then based on the designed transmit beam, we determine the analog beamformer and digital beamformer subject to the constant envelop constraint of phase shifter network in mmWave MIMO, still using the alternating minimization method. Simulation results show that under the same SINR constraint of communication users, larger antenna array can achieve better radar beam quality.      
### 43.DURRNet: Deep Unfolded Single Image Reflection Removal Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.06306.pdf)
>  Single image reflection removal problem aims to divide a reflection-contaminated image into a transmission image and a reflection image. It is a canonical blind source separation problem and is highly ill-posed. In this paper, we present a novel deep architecture called deep unfolded single image reflection removal network (DURRNet) which makes an attempt to combine the best features from model-based and learning-based paradigms and therefore leads to a more interpretable deep architecture. Specifically, we first propose a model-based optimization with transform-based exclusion prior and then design an iterative algorithm with simple closed-form solutions for solving each sub-problems. With the deep unrolling technique, we build the DURRNet with ProxNets to model natural image priors and ProxInvNets which are constructed with invertible networks to impose the exclusion prior. Comprehensive experimental results on commonly used datasets demonstrate that the proposed DURRNet achieves state-of-the-art results both visually and quantitatively.      
### 44.Resilient UAV Formation for Coverage and Connectivity of Spatially Dispersed Users  [ :arrow_down: ](https://arxiv.org/pdf/2203.06287.pdf)
>  Unmanned aerial vehicles (UAVs) are a convenient choice for carrying mobile base stations to rapidly setup communication services for ground users. Unlike terrestrial networks, UAVs do not have fiber optic back-haul connectivity except when they are tethered to the ground, which restricts their mobility. In the absence of back-haul, e.g., in remote areas, emergency situations, or in battlefields, there is a need to ensure connectivity among UAVs in addition to coverage of ground users for creating local area networks. This paper provides a distributed and dynamic approach for UAV formation-based control for coverage and connectivity of spatially dispersed users. We use flocking dynamics as a guide to constructing tailored formations of UAVs on the fly. Simulation results demonstrate that if sufficient aerial base stations are available, the proposed approach results in a strongly connected network of UAVs that is able to provide both a backhaul and fronthaul network. The approach can be further extended to create multi-tier extra-terrestrial networks to cater for large-scale applications.      
### 45.Distributed Dual Quaternion Based Localization of Visual Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.06278.pdf)
>  In this paper we consider the localization problem for a visual sensor network. Inspired by the alternate attitude and position distributed optimization framework discussed in [1], we propose an estimation scheme that exploits the unit dual quaternion algebra to describe the sensors pose. This representation is beneficial in the formulation of the optimization scheme allowing to solve the localization problem without designing two interlaced position and orientation estimators, thus improving the estimation error distribution over the two pose components and the overall localization performance. Furthermore, the numerical experimentation asserts the robustness of the proposed algorithm w.r.t. the initial conditions.      
### 46.Learning cardiac activation maps from 12-lead ECG with multi-fidelity Bayesian optimization on manifolds  [ :arrow_down: ](https://arxiv.org/pdf/2203.06222.pdf)
>  We propose a method for identifying an ectopic activation in the heart non-invasively. Ectopic activity in the heart can trigger deadly arrhythmias. The localization of the ectopic foci or earliest activation sites (EASs) is therefore a critical information for cardiologists in deciding the optimal treatment. In this work, we formulate the identification problem as a global optimization problem, by minimizing the mismatch between the ECG predicted by a cardiac model, when paced at a given EAS, and the observed ECG during the ectopic activity. Our cardiac model amounts at solving an anisotropic eikonal equation for cardiac activation and the forward bidomain model in the torso with the lead field approach for computing the ECG. We build a Gaussian process surrogate model of the loss function on the heart surface to perform Bayesian optimization. In this procedure, we iteratively evaluate the loss function following the lower confidence bound criterion, which combines exploring the surface with exploitation of the minimum region. We also extend this framework to incorporate multiple levels of fidelity of the model. We show that our procedure converges to the minimum only after $11.7\pm10.4$ iterations (20 independent runs) for the single-fidelity case and $3.5\pm1.7$ iterations for the multi-fidelity case. We envision that this tool could be applied in real time in a clinical setting to identify potentially dangerous EASs.      
### 47.Medical Image Segmentation on MRI Images with Missing Modalities: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2203.06217.pdf)
>  Dealing with missing modalities in Magnetic Resonance Imaging (MRI) and overcoming their negative repercussions is considered a hurdle in biomedical imaging. The combination of a specified set of modalities, which is selected depending on the scenario and anatomical part being scanned, will provide medical practitioners with full information about the region of interest in the human body, hence the missing MRI sequences should be reimbursed. The compensation of the adverse impact of losing useful information owing to the lack of one or more modalities is a well-known challenge in the field of computer vision, particularly for medical image processing tasks including tumour segmentation, tissue classification, and image generation. Various approaches have been developed over time to mitigate this problem's negative implications and this literature review goes through a significant number of the networks that seek to do so. The approaches reviewed in this work are reviewed in detail, including earlier techniques such as synthesis methods as well as later approaches that deploy deep learning, such as common latent space models, knowledge distillation networks, mutual information maximization, and generative adversarial networks (GANs). This work discusses the most important approaches that have been offered at the time of this writing, examining the novelty, strength, and weakness of each one. Furthermore, the most commonly used MRI datasets are highlighted and described. The main goal of this research is to offer a performance evaluation of missing modality compensating networks, as well as to outline future strategies for dealing with this issue.      
### 48.Semi-supervised classification of medical ultrasound images based on generative adversarial network  [ :arrow_down: ](https://arxiv.org/pdf/2203.06184.pdf)
>  Medical ultrasound (US) is one of the most widely used imaging modalities in clinical practice. However, its use presents unique challenges such as variable imaging quality. Deep learning (DL) can be used as an advanced medical US images analysis tool, while the performance of the DL model is greatly limited by the scarcity of big datasets. Here, we develop semi-supervised classification enhancement (SSCE) structures by constructing seven convolutional neural network (CNN) models and one of the most state-of-the-art generative adversarial network (GAN) models, StyleGAN2-ADA, to address this problem. A breast cancer dataset with 780 images is used as our base dataset. The results show that our SSCE structures obtain an accuracy of up to 97.9%, showing a maximum 21.6% improvement compared with utilizing CNN models alone and outperforming the previous methods using the same dataset by up to 23.9%. We believe our proposed state-of-the-art method can be regarded as a potential auxiliary tool for on-the-fly diagnoses of medical US images.      
### 49.Gradient Methods with Memory for Minimizing Composite Functions  [ :arrow_down: ](https://arxiv.org/pdf/2203.07318.pdf)
>  The recently introduced Gradient Methods with Memory use a subset of the past oracle information to create a model of the objective function, whose accuracy enables them to surpass the traditional Gradient Methods in practical performance. The model introduces an overhead that is substantial, unless dealing with smooth unconstrained problems. In this work, we introduce several Gradient Methods with Memory that can solve composite problems efficiently, including unconstrained problems with non-smooth objectives. The auxiliary problem at each iteration still cannot be solved exactly but we show how to alter the model and how to initialize the auxiliary problem solver to ensure that this inexactness does not degrade the convergence guarantees. Moreover, we dynamically increase the convergence guarantees as to provably surpass those of their memory-less counterparts. These properties are preserved when applying acceleration and the containment of inexactness further prevents error accumulation. Our methods are able to estimate key geometry parameters to attain state-of-the art worst-case rates on many important subclasses of composite problems, where the objective smooth part satisfies a strong convexity condition or a relaxation thereof. In particular, we formulate a restart strategy applicable to optimization methods with sublinear convergence guarantees of any order. We support the theoretical results with simulations.      
### 50.Physico-chemical properties extraction from the fluorescence spectrum with 1D-convolutional neural networks: application to olive oil  [ :arrow_down: ](https://arxiv.org/pdf/2203.07229.pdf)
>  The olive oil sector produces a substantial impact in the Mediterranean's economy and lifestyle. Many studies exist which try to optimize the different steps in the olive oil's production process. One of the main challenges for olive oil producers is the ability to asses and control the quality during the production cycle. For this purpose, several parameters need to be determined, such as the acidity, the UV absorption or the ethyl esters content. To achieve this, samples must be sent to an approved laboratory for chemical analysis. This approach is expensive and cannot be performed very frequently, making quality control of olive oil a real challenge. This work explores a new approach based on fluorescence spectroscopy and artificial intelligence (namely, 1-D convolutional neural networks) to predict the five chemical quality indicators of olive oil (acidity, peroxide value, UV spectroscopic parameters $K_{270}$ and $K_{232}$, and ethyl esters) from simple fluorescence spectra. Fluorescence spectroscopy is a very attractive optical technique since it does not require sample preparation, is non destructive, and, as shown in this work, can be easily implemented in small and cost-effective sensors. The results indicate that the proposed approach gives exceptional results in the quality determination and would make the continuous quality control of olive oil during and after the production process a reality. Additionally, this novel methodology presents potential applications as a support for quality specifications of olive oil, as defined by the European regulation.      
### 51.Model predictive control and moving horizon estimation for adaptive optimal bolus feeding in high-throughput cultivation of E. coli  [ :arrow_down: ](https://arxiv.org/pdf/2203.07211.pdf)
>  We discuss the application of a nonlinear model predictive control (MPC) and a moving horizon estimation (MHE) to achieve an optimal operation of E. coli fed-batch cultivations with intermittent bolus feeding. 24 parallel experiments were considered in a high-throughput microbioreactor platform at 10 mL scale. The robotic island in question can run up to 48 fed-batch processes in parallel with an automated liquid handling and online and atline analytics. The implementation of the model-based monitoring and control framework reveals that there are mainly three challenges which need to be addressed; First, the inputs are given in an instantaneous pulsed form by bolus injections, second, online and atline measurement frequencies are severely imbalanced, and third, optimization for the distinctive multiple reactors can be either parallelized or integrated. We address these challenges by incorporating the concept of impulsive control systems, formulating multi-rate MHE with identifiability analysis, and suggesting criteria for deciding the reactor configuration. In this study, we present the key elements and background theory of the implementation with \textit{in silico} simulations for the bacterial fed-batch cultivation.      
### 52.TaylorBeamformer: Learning All-Neural Multi-Channel Speech Enhancement from Taylor's Approximation Theory  [ :arrow_down: ](https://arxiv.org/pdf/2203.07195.pdf)
>  While existing end-to-end beamformers achieve impressive performance in various front-end speech tasks, they usually encapsulate the whole process into a black box and thus lack adequate interpretability. As an attempt to fill the blank, we propose a novel neural beamformer inspired by Taylor's approximation theory called TaylorBeamformer for multi-channel speech enhancement. The core idea is that the recovery process can be formulated as the spatial filtering in the neighborhood of the input mixture. Based on that, we decompose it into the superimposition of the 0th-order non-derivative and high-order derivative terms, where the former serves as the spatial filter and the latter are viewed as the residual noise canceller to further improve the speech quality. To enable end-to-end training, we replace the derivative operations with trainable networks and thus can learn from training data. Extensive experiments are conducted on the synthesized dataset based on LibriSpeech and results show that the proposed approach performs favorably against the previous advanced baselines      
### 53.MDNet: Learning Monaural Speech Enhancement from Deep Prior Gradient  [ :arrow_down: ](https://arxiv.org/pdf/2203.07179.pdf)
>  While traditional statistical signal processing model-based methods can derive the optimal estimators relying on specific statistical assumptions, current learning-based methods further promote the performance upper bound via deep neural networks but at the expense of high encapsulation and lack adequate interpretability. Standing upon the intersection between traditional model-based methods and learning-based methods, we propose a model-driven approach based on the maximum a posteriori (MAP) framework, termed as MDNet, for single-channel speech enhancement. Specifically, the original problem is formulated into the joint posterior estimation w.r.t. speech and noise components. Different from the manual assumption toward the prior terms, we propose to model the prior distribution via networks and thus can learn from training data. The framework takes the unfolding structure and in each step, the target parameters can be progressively estimated through explicit gradient descent operations. Besides, another network serves as the fusion module to further refine the previous speech estimation. The experiments are conducted on the WSJ0-SI84 and Interspeech2020 DNS-Challenge datasets, and quantitative results show that the proposed approach outshines previous state-of-the-art baselines.      
### 54.Interpretable Dysarthric Speaker Adaptation based on Optimal-Transport  [ :arrow_down: ](https://arxiv.org/pdf/2203.07143.pdf)
>  This work addresses the mismatch problem between the distribution of training data (source) and testing data (target), in the challenging context of dysarthric speech recognition. We focus on Speaker Adaptation (SA) in command speech recognition, where data from multiple sources (i.e., multiple speakers) are available. Specifically, we propose an unsupervised Multi-Source Domain Adaptation (MSDA) algorithm based on optimal-transport, called MSDA via Weighted Joint Optimal Transport (MSDA-WJDOT). We achieve a Command Error Rate relative reduction of 16% and 7% over the speaker-independent model and the best competitor method, respectively. The strength of the proposed approach is that, differently from any other existing SA method, it offers an interpretable model that can also be exploited, in this context, to diagnose dysarthria without any specific training. Indeed, it provides a closeness measure between the target and the source speakers, reflecting their similarity in terms of speech characteristics. Based on the similarity between the target speaker and the healthy/dysarthric source speakers, we then define the healthy/dysarthric score of the target speaker that we leverage to perform dysarthria detection. This approach does not require any additional training and achieves a 95% accuracy in the dysarthria diagnosis.      
### 55.Modelling variability in vibration-based PBSHM via a generalised population form  [ :arrow_down: ](https://arxiv.org/pdf/2203.07115.pdf)
>  Structural health monitoring (SHM) has been an active research area for the last three decades, and has accumulated a number of critical advances over that period, as can be seen in the literature. However, SHM is still facing challenges because of the paucity of damage-state data, operational and environmental fluctuations, repeatability issues, and changes in boundary conditions. These issues present as inconsistencies in the captured features and can have a huge impact on the practical implementation, but more critically, on the generalisation of the technology. Population-based SHM has been designed to address some of these concerns by modelling and transferring missing information using data collected from groups of similar structures. <br>In this work, vibration data were collected from four healthy, nominally-identical, full-scale composite helicopter blades. Manufacturing differences (e.g., slight differences in geometry and/or material properties), among the blades presented as variability in their structural dynamics, which can be very problematic for SHM based on machine learning from vibration data. This work aims to address this variability by defining a general model for the frequency response functions of the blades, called a form, using mixtures of Gaussian processes.      
### 56.Human Attention Detection Using AM-FM Representations  [ :arrow_down: ](https://arxiv.org/pdf/2203.07093.pdf)
>  Human activity detection from digital videos presents many challenges to the computer vision and image processing communities. Recently, many methods have been developed to detect human activities with varying degree of success. Yet, the general human activity detection problem remains very challenging, especially when the methods need to work 'in the wild' (e.g., without having precise control over the imaging geometry). The thesis explores phase-based solutions for (i) detecting faces, (ii) back of the heads, (iii) joint detection of faces and back of the heads, and (iv) whether the head is looking to the left or the right, using standard video cameras without any control on the imaging geometry. The proposed phase-based approach is based on the development of simple and robust methods that rely on the use of Amplitude Modulation- Frequency Modulation (AM-FM) models. The approach is validated using video frames extracted from the Advancing Out-of-school Learning in Mathematics and Engineering (AOLME) project. The dataset consisted of 13,265 images from ten students looking at the camera, and 6,122 images from five students looking away from the camera. For the students facing the camera, the method was able to correctly classify 97.1% of them looking to the left and 95.9% of them looking to the right. For the students facing the back of the camera, the method was able to correctly classify 87.6% of them looking to the left and 93.3% of them looking to the right. The results indicate that AM-FM based methods hold great promise for analyzing human activity videos.      
### 57.A Robust Approach for the Decomposition of High-Energy-Consuming Industrial Loads with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.07075.pdf)
>  The knowledge of the users' electricity consumption pattern is an important coordinating mechanism between the utility company and the electricity consumers in terms of key decision makings. The load decomposition is therefore crucial to reveal the underlying relationship between the load consumption and its characteristics. However, load decomposition is conventionally performed on the residential and commercial loads, and adequate consideration has not been given to the high-energy-consuming industrial loads leading to inefficient results. This paper thus focuses on the load decomposition of the industrial park loads (IPL). The commonly used parameters in a conventional method are however inapplicable in high-energy-consuming industrial loads. Therefore, a more robust approach is developed comprising a three-algorithm model to achieve this goal on the IPL. First, the improved variational mode decomposition (IVMD) algorithm is introduced to denoise the training data of the IPL and improve its stability. Secondly, the convolutional neural network (CNN) and simple recurrent units (SRU) joint algorithms are used to achieve a non-intrusive and non-invasive decomposition process of the IPL using a double-layer deep learning network based on the IPL characteristics. Specifically, CNN is used to extract the IPL data characteristics while the improved long and short-term memory (LSTM) network, SRU, is adopted to develop the decomposition model and further train the load data. Through the robust decomposition process, the underlying relationship in the load consumption is extracted. The results obtained from the numerical examples show that this approach outperforms the state-of-the-art in the conventional decomposition process.      
### 58.Hybrid Active-Passive Reconfigurable Intelligent Surface-Assisted Multi-User MISO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.07042.pdf)
>  We consider a multi-user multiple-input single-output (MISO) communications system which is assisted by a hybrid active-passive reconfigurable intelligent surface (RIS). Unlike conventional passive RISs, hybrid RIS is equipped with a few active elements with the ability to reflect and amplify incident signals to significantly improve the system performance. Towards a fairness-oriented design, we maximize the minimum rate among all users through jointly optimizing the transmit beamforming vectors and RIS reflecting/amplifying coefficients. Combining tools from block coordinate ascent and successive convex approximation, the challenging nonconvex problem is efficiently solved by a low-complexity iterative algorithm. The numerical results show that a hybrid RIS with 4 active elements out of a total of 50 elements with a power budget of -1 dBm offers an improvement of up to 80% to the considered system, while that achieved by a fully passive RIS is only 27%.      
### 59.Compressing CNN Kernels for Videos Using Tucker Decompositions: Towards Lightweight CNN Applications  [ :arrow_down: ](https://arxiv.org/pdf/2203.07033.pdf)
>  Convolutional Neural Networks (CNN) are the state-of-the-art in the field of visual computing. However, a major problem with CNNs is the large number of floating point operations (FLOPs) required to perform convolutions for large inputs. When considering the application of CNNs to video data, convolutional filters become even more complex due to the extra temporal dimension. This leads to problems when respective applications are to be deployed on mobile devices, such as smart phones, tablets, micro-controllers or similar, indicating less computational power. <br>Kim et al. (2016) proposed using a Tucker-decomposition to compress the convolutional kernel of a pre-trained network for images in order to reduce the complexity of the network, i.e. the number of FLOPs. In this paper, we generalize the aforementioned method for application to videos (and other 3D signals) and evaluate the proposed method on a modified version of the THETIS data set, which contains videos of individuals performing tennis shots. We show that the compressed network reaches comparable accuracy, while indicating a memory compression by a factor of 51. However, the actual computational speed-up (factor 1.4) does not meet our theoretically derived expectation (factor 6).      
### 60.Modelling Non-Smooth Signals with Complex Spectral Structure  [ :arrow_down: ](https://arxiv.org/pdf/2203.06997.pdf)
>  The Gaussian Process Convolution Model (GPCM; Tobar et al., 2015a) is a model for signals with complex spectral structure. A significant limitation of the GPCM is that it assumes a rapidly decaying spectrum: it can only model smooth signals. Moreover, inference in the GPCM currently requires (1) a mean-field assumption, resulting in poorly calibrated uncertainties, and (2) a tedious variational optimisation of large covariance matrices. We redesign the GPCM model to induce a richer distribution over the spectrum with relaxed assumptions about smoothness: the Causal Gaussian Process Convolution Model (CGPCM) introduces a causality assumption into the GPCM, and the Rough Gaussian Process Convolution Model (RGPCM) can be interpreted as a Bayesian nonparametric generalisation of the fractional Ornstein-Uhlenbeck process. We also propose a more effective variational inference scheme, going beyond the mean-field assumption: we design a Gibbs sampler which directly samples from the optimal variational solution, circumventing any variational optimisation entirely. The proposed variations of the GPCM are validated in experiments on synthetic and real-world data, showing promising results.      
### 61.Lead-agnostic Self-supervised Learning for Local and Global Representations of Electrocardiogram  [ :arrow_down: ](https://arxiv.org/pdf/2203.06889.pdf)
>  In recent years, self-supervised learning methods have shown significant improvement for pre-training with unlabeled data and have proven helpful for electrocardiogram signals. However, most previous pre-training methods for electrocardiogram focused on capturing only global contextual representations. This inhibits the models from learning fruitful representation of electrocardiogram, which results in poor performance on downstream tasks. Additionally, they cannot fine-tune the model with an arbitrary set of electrocardiogram leads unless the models were pre-trained on the same set of leads. In this work, we propose an ECG pre-training method that learns both local and global contextual representations for better generalizability and performance on downstream tasks. In addition, we propose random lead masking as an ECG-specific augmentation method to make our proposed model robust to an arbitrary set of leads. Experimental results on two downstream tasks, cardiac arrhythmia classification and patient identification, show that our proposed approach outperforms other state-of-the-art methods.      
### 62.SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities  [ :arrow_down: ](https://arxiv.org/pdf/2203.06849.pdf)
>  Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years. In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks. However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models. SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks. In this paper, we introduce SUPERB-SG, a new benchmark focused on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB. We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks. It entails freezing pre-trained model parameters, only using simple task-specific trainable heads. The goal is to be inclusive of all researchers, and encourage efficient use of computational resources. We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation.      
### 63.Adaptive Model Predictive Control by Learning Classifiers  [ :arrow_down: ](https://arxiv.org/pdf/2203.06783.pdf)
>  Stochastic model predictive control has been a successful and robust control framework for many robotics tasks where the system dynamics model is slightly inaccurate or in the presence of environment disturbances. Despite the successes, it is still unclear how to best adjust control parameters to the current task in the presence of model parameter uncertainty and heteroscedastic noise. In this paper, we propose an adaptive MPC variant that automatically estimates control and model parameters by leveraging ideas from Bayesian optimization (BO) and the classical expected improvement acquisition function. We leverage recent results showing that BO can be formulated as a density ratio estimation which can be efficiently approximated by simply learning a classifier. This is then integrated into a model predictive path integral control framework yielding robust controllers for a variety of challenging robotics tasks. We demonstrate the approach on classical control problems under model uncertainty and robotics manipulation tasks.      
### 64.CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio Classification  [ :arrow_down: ](https://arxiv.org/pdf/2203.06760.pdf)
>  Audio classification is an active research area with a wide range of applications. Over the past decade, convolutional neural networks (CNNs) have been the de-facto standard building block for end-to-end audio classification models. Recently, neural networks based solely on self-attention mechanisms such as the Audio Spectrogram Transformer (AST) have been shown to outperform CNNs. In this paper, we find an intriguing interaction between the two very different models - CNN and AST models are good teachers for each other. When we use either of them as the teacher and train the other model as the student via knowledge distillation (KD), the performance of the student model noticeably improves, and in many cases, is better than the teacher model. In our experiments with this CNN/Transformer Cross-Model Knowledge Distillation (CMKD) method we achieve new state-of-the-art performance on FSD50K, AudioSet, and ESC-50.      
### 65.Bi-Sampling Approach to Classify Music Mood leveraging Raga-Rasa Association in Indian Classical Music  [ :arrow_down: ](https://arxiv.org/pdf/2203.06583.pdf)
>  The impact of Music on the mood or emotion of the listener is a well-researched area in human psychology and behavioral science. In Indian classical music, ragas are the melodic structure that defines the various styles and forms of the music. Each raga has been found to evoke a specific emotion in the listener. With the advent of advanced capabilities of audio signal processing and the application of machine learning, the demand for intelligent music classifiers and recommenders has received increased attention, especially in the 'Music as a service' cloud applications. This paper explores a novel framework to leverage the raga-rasa association in Indian classical Music to build an intelligent classifier and its application in music recommendation system based on user's current mood and the mood they aspire to be in.      
### 66.Impact of sensor placement in soil water estimation: A real-case study  [ :arrow_down: ](https://arxiv.org/pdf/2203.06548.pdf)
>  One of the essential elements in implementing a closed-loop irrigation system is soil moisture estimation based on a limited number of available sensors. One associated problem is the determination of the optimal locations to install the sensors such that good soil moisture estimation can be obtained. In our previous work, the modal degree of observability was employed to address the problem of optimal sensor placement for soil moisture estimation of agro-hydrological systems. It was demonstrated that the optimally placed sensors can improve the soil moisture estimation performance. However, it is unclear whether the optimal sensor placement can significantly improve the soil moisture estimation performance in actual applications. In this work, we investigate the impact of sensor placement in soil moisture estimation for an actual agricultural field in Lethbridge, Alberta, Canada. In an experiment on the studied field, 42 soil moisture sensors were installed at different depths to collect the soil moisture measurements for one growing season. A three-dimensional agro-hydrological model with heterogeneous soil parameters of the studied field is developed. The modal degree of observability is applied to the three-dimensional system to determine the optimal sensor locations. The extended Kalman filter (EKF) is chosen as the data assimilation tool to estimate the soil moisture content of the studied field. Soil moisture estimation results for different scenarios are obtained and analyzed to investigate the effects of sensor placement on the performance of soil moisture estimation in the actual applications.      
### 67.SA-SASV: An End-to-End Spoof-Aggregated Spoofing-Aware Speaker Verification System  [ :arrow_down: ](https://arxiv.org/pdf/2203.06517.pdf)
>  Research in the past several years has boosted the performance of automatic speaker verification systems and countermeasure systems to deliver low Equal Error Rates (EERs) on each system. However, research on joint optimization of both systems is still limited. The SASV 2022 challenge was proposed to encourage the development of integrated spoofing aware speaker verification system (SASV) with new metrics to evaluate joint model performance. This paper proposes an ensemble-free end-to-end solution, SA-SASV, to build a SASV system with multi-task classifiers, which are optimized by multiple losses. The proposed system is evaluated on the ASVSpoof 2019 evaluation dataset and improves the performance of baseline systems from 8.76% to 1.81% in SASV-EER.      
### 68.Hierarchical Codebook based Multiuser Beam Training for Millimeter Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2203.06438.pdf)
>  In this paper, multiuser beam training based on hierarchical codebook for millimeter wave massive multi-input multi-output is investigated, where the base station (BS) simultaneously performs beam training with multiple user equipments (UEs). For the UEs, an alternative minimization method with a closed-form expression (AMCF) is proposed to design the hierarchical codebook under the constant modulus constraint. To speed up the convergence of the AMCF, an initialization method based on Zadoff-Chu sequence is proposed. For the BS, a simultaneous multiuser beam training scheme based on an adaptively designed hierarchical codebook is proposed, where the codewords in the current layer of the codebook are designed according to the beam training results of the previous layer. The codewords at the BS are designed with multiple mainlobes, each covering a spatial region for one or more UEs. Simulation results verify the effectiveness of the proposed hierarchical codebook design schemes and show that the proposed multiuser beam training scheme can approach the performance of the beam sweeping but with significantly reduced beam training overhead.      
### 69.Deep learning-based conditional inpainting for restoration of artifact-affected 4D CT images  [ :arrow_down: ](https://arxiv.org/pdf/2203.06431.pdf)
>  4D CT imaging is an essential component of radiotherapy of thoracic/abdominal tumors. 4D CT images are, however, often affected by artifacts that compromise treatment planning quality. In this work, deep learning (DL)-based conditional inpainting is proposed to restore anatomically correct image information of artifact-affected areas. The restoration approach consists of a two-stage process: DL-based detection of common interpolation (INT) and double structure (DS) artifacts, followed by conditional inpainting applied to the artifact areas. In this context, conditional refers to a guidance of the inpainting process by patient-specific image data to ensure anatomically reliable results. Evaluation is based on 65 in-house 4D CT data sets of lung cancer patients (48 with only slight artifacts, 17 with pronounced artifacts) and the publicly available DIRLab 4D CT data (independent external test set). Automated artifact detection revealed a ROC-AUC of 0.99 for INT and 0.97 for DS artifacts (in-house data). The proposed inpainting method decreased the average root mean squared error (RMSE) by 60% (DS) and 42% (INT) for the in-house evaluation data (simulated artifacts for the slight artifact data; original data were considered as ground truth for RMSE computation). For the external DIR-Lab data, the RMSE decreased by 65% and 36%, respectively. Applied to the pronounced artifact data group, on average 68% of the detectable artifacts were removed. The results highlight the potential of DL-based inpainting for the restoration of artifact-affected 4D CT data. Improved performance of conditional inpainting (compared to standard inpainting) illustrates the benefits of exploiting patient-specific prior knowledge.      
### 70.One-stage Video Instance Segmentation: From Frame-in Frame-out to Clip-in Clip-out  [ :arrow_down: ](https://arxiv.org/pdf/2203.06421.pdf)
>  Many video instance segmentation (VIS) methods partition a video sequence into individual frames to detect and segment objects frame by frame. However, such a frame-in frame-out (FiFo) pipeline is ineffective to exploit the temporal information. Based on the fact that adjacent frames in a short clip are highly coherent in content, we propose to extend the one-stage FiFo framework to a clip-in clip-out (CiCo) one, which performs VIS clip by clip. Specifically, we stack FPN features of all frames in a short video clip to build a spatio-temporal feature cube, and replace the 2D conv layers in the prediction heads and the mask branch with 3D conv layers, forming clip-level prediction heads (CPH) and clip-level mask heads (CMH). Then the clip-level masks of an instance can be generated by feeding its box-level predictions from CPH and clip-level features from CMH into a small fully convolutional network. A clip-level segmentation loss is proposed to ensure that the generated instance masks are temporally coherent in the clip. The proposed CiCo strategy is free of inter-frame alignment, and can be easily embedded into existing FiFo based VIS approaches. To validate the generality and effectiveness of our CiCo strategy, we apply it to two representative FiFo methods, Yolact \cite{bolya2019yolact} and CondInst \cite{tian2020conditional}, resulting in two new one-stage VIS models, namely CiCo-Yolact and CiCo-CondInst, which achieve 37.1/37.3\%, 35.2/35.4\% and 17.2/18.0\% mask AP using the ResNet50 backbone, and 41.8/41.4\%, 38.0/38.9\% and 18.0/18.2\% mask AP using the Swin Transformer tiny backbone on YouTube-VIS 2019, 2021 and OVIS valid sets, respectively, recording new state-of-the-arts. Code and video demos of CiCo can be found at \url{<a class="link-external link-https" href="https://github.com/MinghanLi/CiCo" rel="external noopener nofollow">this https URL</a>}.      
### 71.Optimal Precoding Design for Monostatic ISAC Systems: MSE Lower Bound and DoF Completion  [ :arrow_down: ](https://arxiv.org/pdf/2203.06409.pdf)
>  In this letter, we study the parameter estimation performance for monostatic downlink integrated sensing and communications (ISAC) systems. In particular, we analyze the mean squared error (MSE) lower bound for target sensing in the downlink ISAC system that reveals the suboptimality in re-using the conventional communication waveform for sensing. To realize a practical dual-functional waveform, we propose a waveform augmentation strategy that imposes an extra signal structure, namely the degrees-of-freedom (DoF) completion method. The proposed approach is capable of improving the parameter estimation performance of the ISAC system and achieving the derived MSE lower bound. To improve the performance of the proposed strategy, we formulate an MSE minimization problem to design the ISAC precoder, subject to the communication users' signal-interference-plus-noise-ratio (SINR) constraints. Despite the non-convexity of the waveform design problem, we obtain its globally optimal solution via semi-definite relaxation (SDR) and the proposed constructive method. Simulation results validate the proposed DoF completion technology could achieve the derived MSE lower bound and the effectiveness of the MSE-based ISAC waveform design.      
### 72.Multibeam Satellite Communications with Energy Efficiency Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.06395.pdf)
>  Energy efficiency (EE) is an important aspect of satellite communications. Different with the existing algorithms that typically use the first-order Taylor lower bound approximation to convert non-convex EE maximization (EEM) problems into convex ones, in this letter a two-step quadratic transformation method is presented. In the first step, the fractional form of the achievable rate over the total power consumption is converted into a non-fractional form based on quadratic transformation. In the second step, the fractional form of the signal power over the interference-and-noise power is further converted into a non-fractional form, still based on quadratic transformation. After the two-step quadratic transformation, the original EEM problem is converted into an equivalent convex one. Then an alternating optimization algorithm is presented to solve it by iteratively performing two stages until a stop condition is satisfied. Simulation results show that the presented algorithm can fast converge and its performance is better than that of the sequential convex approximation algorithm and the multibeam interference mitigation algorithm.      
### 73.Throughput Maximization for UAV-enabled Integrated Periodic Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2203.06358.pdf)
>  Unmanned aerial vehicle (UAV) is expected to revolutionize the existing integrated sensing and communication (ISAC) system and promise a more flexible joint design. Nevertheless, the existing works on ISAC mainly focus on exploring the performance of both functionalities simultaneously during the entire considered period, which may ignore the practical asymmetric sensing and communication requirements. In particular, always forcing sensing along with communication may make it is harder to balance between these two functionalities due to shared spectrum resources and limited transmit power. To address this issue, we propose a new integrated periodic sensing and communication mechanism for the UAV-enabled ISAC system to provide a more flexible trade-off between two integrated functionalities. Specifically, the system achievable rate is maximized via jointly optimizing UAV trajectory, user association, target sensing selection, and transmit beamforming, while meeting the sensing frequency and beam pattern gain requirement for the given targets. Despite that this problem is highly non-convex and involves closely coupled integer variables, we derive the closed-form optimal beamforming vector to dramatically reduce the complexity of beamforming design, and present a tight lower bound of the achievable rate to facilitate UAV trajectory design. Based on the above results, we propose a penalty-based algorithm to efficiently solve the considered problem. The optimal achievable rate and the optimal UAV location are analyzed under a special case of infinity number of antennas. Furthermore, we prove the structural symmetry between the optimal solutions in different ISAC frames without location constraints and propose an efficient algorithm for solving the problem with location constraints.      
### 74.Channel Estimation for Wideband MmWave MIMO OFDM System Exploiting Block Sparsity  [ :arrow_down: ](https://arxiv.org/pdf/2203.06330.pdf)
>  In this letter, we investigate time-domain channel estimation for wideband millimeter wave (mmWave) MIMO OFDM system. By transmitting frequency-domain pilot symbols as well as different beamforming vectors, we observe that the time-domain mmWave MIMO channels exhibit channel delay sparsity and especially block sparsity among different spatial directions. Then we propose a time-domain channel estimation exploiting block sparsity (TDCEBS) scheme, which always aims at finding the best nonzero block achieving the largest projection of the residue at each iterations. In particular, we evaluate the system performance using the QuaDRiGa which is recommended by 5G New Radio to generate wideband mmWave MIMO channels. The effectiveness of the proposed TDCEBS scheme is verified by the simulation results, as the proposed scheme outperforms the existing schemes.      
### 75.Performance Analysis of Intelligent Reflecting Surface Assisted Opportunistic Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.06313.pdf)
>  Intelligent reflecting surfaces (IRSs) are a promising technology for enhancing coverage and spectral efficiency, especially in the millimeter wave (mmWave) bands. Existing approaches to leverage the benefits of IRS involve a resource-intensive channel estimation step followed by a computationally expensive algorithm to optimize the reflection coefficients at the IRS. In this work, we present and analyze several alternative schemes, where the phase configuration of the IRS is randomized and multi-user diversity is exploited to opportunistically select the best user at each point in time for data transmission. We show that the throughput of an IRS assisted opportunistic system asymptotically converges to the optimal beamforming-based throughput under fair allocation of resources, as the number of users gets large. Further, for all the proposed schemes, we derive the scaling law of the throughput in terms of the number of users and IRS elements, as the number of users gets large. We also introduce schemes that enhance the rate of convergence of the opportunistic rate to the beamforming rate as the number of users is increased. Following this, we extend the setup to wideband channels via an orthogonal frequency division multiplexing (OFDM) system and discuss two opportunistic schemes in an IRS assisted setting that elucidate the superior performance that IRS aided systems can offer over conventional systems at very low implementation cost and complexity.      
### 76.SOCKS: A Stochastic Optimal Control and Reachability Toolbox Using Kernel Methods  [ :arrow_down: ](https://arxiv.org/pdf/2203.06290.pdf)
>  We present SOCKS, a data-driven stochastic optimal control toolbox based in kernel methods. SOCKS is a collection of data-driven algorithms that compute approximate solutions to stochastic optimal control problems with arbitrary cost and constraint functions, including stochastic reachability, which seeks to determine the likelihood that a system will reach a desired target set while respecting a set of pre-defined safety constraints. Our approach relies upon a class of machine learning algorithms based in kernel methods, a nonparametric technique which can be used to represent probability distributions in a high-dimensional space of functions known as a reproducing kernel Hilbert space. As a nonparametric technique, kernel methods are inherently data-driven, meaning that they do not place prior assumptions on the system dynamics or the structure of the uncertainty. This makes the toolbox amenable to a wide variety of systems, including those with nonlinear dynamics, black-box elements, and poorly characterized stochastic disturbances. We present the main features of SOCKS and demonstrate its capabilities on several benchmarks.      
### 77.Parameter Inference of Time Series by Delay Embeddings and Learning Differentiable Operators  [ :arrow_down: ](https://arxiv.org/pdf/2203.06269.pdf)
>  A common issue in dealing with real-world dynamical systems is identifying system parameters responsible for its behavior. A frequent scenario is that one has time series data, along with corresponding parameter labels, but there exists new time series with unknown parameter labels, which one seeks to identify. We tackle this problem by first delay-embedding the time series into a higher dimension to obtain a proper ordinary differential equation (ODE), and then having a neural network learn to predict future time-steps of the trajectory given the present time-step. We then use the learned neural network to backpropagate prediction errors through the parameter inputs of the neural network in order to obtain a gradient in parameter space. Using this gradient, we can approximately identify parameters of time series. We demonstrate the viability of our approach on the chaotic Lorenz system, as well as real-world data with the Hall-effect Thruster (HET).      
### 78.Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task  [ :arrow_down: ](https://arxiv.org/pdf/2203.06250.pdf)
>  We develop a method to learn bio-inspired foraging policies using human data. We conduct an experiment where humans are virtually immersed in an open field foraging environment and are trained to collect the highest amount of rewards. A Markov Decision Process (MDP) framework is introduced to model the human decision dynamics. Then, Imitation Learning (IL) based on maximum likelihood estimation is used to train Neural Networks (NN) that map human decisions to observed states. The results show that passive imitation substantially underperforms humans. We further refine the human-inspired policies via Reinforcement Learning (RL), using on-policy algorithms that are more suitable to learn from pre-trained networks. We show that the combination of IL and RL can match human results and that good performance strongly depends on an egocentric representation of the environment. The developed methodology can be used to efficiently learn policies for unmanned vehicles which have to solve missions in an open field environment.      
### 79.Pressure Ulcer Categorisation using Deep Learning: A Clinical Trial to Evaluate Model Performance  [ :arrow_down: ](https://arxiv.org/pdf/2203.06248.pdf)
>  Pressure ulcers are a challenge for patients and healthcare professionals. In the UK, 700,000 people are affected by pressure ulcers each year. Treating them costs the National Health Service Â£3.8 million every day. Their etiology is complex and multifactorial. However, evidence has shown a strong link between old age, disease-related sedentary lifestyles and unhealthy eating habits. Pressure ulcers are caused by direct skin contact with a bed or chair without frequent position changes. Urinary and faecal incontinence, diabetes, and injuries that restrict body position and nutrition are also known risk factors. Guidelines and treatments exist but their implementation and success vary across different healthcare settings. This is primarily because healthcare practitioners have a) minimal experience in dealing with pressure ulcers, and b) a general lack of understanding of pressure ulcer treatments. Poorly managed, pressure ulcers lead to severe pain, poor quality of life, and significant healthcare costs. In this paper, we report the findings of a clinical trial conducted by Mersey Care NHS Foundation Trust that evaluated the performance of a faster region-based convolutional neural network and mobile platform that categorised and documented pressure ulcers. The neural network classifies category I, II, III, and IV pressure ulcers, deep tissue injuries, and unstageable pressure ulcers. Photographs of pressure ulcers taken by district nurses are transmitted over 4/5G communications to an inferencing server for classification. Classified images are stored and reviewed to assess the model's predictions and relevance as a tool for clinical decision making and standardised reporting. The results from the study generated a mean average Precision=0.6796, Recall=0.6997, F1-Score=0.6786 with 45 false positives using an @.75 confidence score threshold.      
### 80.Infrastructure-free, Deep Learned Urban Noise Monitoring at $\sim$100mW  [ :arrow_down: ](https://arxiv.org/pdf/2203.06220.pdf)
>  The Sounds of New York City (SONYC) wireless sensor network (WSN) has been fielded in Manhattan and Brooklyn over the past five years, as part of a larger human-in-the-loop cyber-physical control system for monitoring, analyzing, and mitigating urban noise pollution. We describe the evolution of the 2-tier SONYC WSN from an acoustic data collection fabric into a 3-tier in situ noise complaint monitoring WSN, and its current evaluation. The added tier consists of long-range (LoRa), multi-hop networks of a new low-power acoustic mote, MKII ("Mach 2"), that we have designed and fabricated. MKII motes are notable in three ways: First, they advance machine learning capability at mote-scale in this application domain by introducing a real-time Convolutional Neural Network (CNN) based embedding model that is competitive with alternatives while also requiring 10$\times$ lesser training data and $\sim$2 orders of magnitude fewer runtime resources. Second, they are conveniently deployed relatively far from higher-tier base station nodes without assuming power or network infrastructure support at operationally relevant sites (such as construction zones), yielding a relatively low-cost solution. And third, their networking is frequency agile, unlike conventional LoRa networks: it tolerates in a distributed, self-stabilizing way the variable external interference and link fading in the cluttered 902-928MHz ISM band urban environment by dynamically choosing good frequencies using an efficient new method that combines passive and active measurements.      
