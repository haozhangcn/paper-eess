# ArXiv eess --Thu, 24 Mar 2022
### 1.Optical Fiber Fault Detection and Localization in a Noisy OTDR Trace Based on Denoising Convolutional Autoencoder and Bidirectional Long Short-Term Memory  [ :arrow_down: ](https://arxiv.org/pdf/2203.12604.pdf)
>  Optical time-domain reflectometry (OTDR) has been widely used for characterizing fiber optical links and for detecting and locating fiber faults. OTDR traces are prone to be distorted by different kinds of noise, causing blurring of the backscattered signals, and thereby leading to a misleading interpretation and a more cumbersome event detection task. To address this problem, a novel method combining a denoising convolutional autoencoder (DCAE) and a bidirectional long short-term memory (BiLSTM) is proposed, whereby the former is used for noise removal of OTDR signals and the latter for fault detection, localization, and diagnosis with the denoised signal as input. The proposed approach is applied to noisy OTDR signals of different levels of input SNR ranging from -5 dB to 15 dB. The experimental results demonstrate that: (i) the DCAE is efficient in denoising the OTDR traces and it outperforms other deep learning techniques and the conventional denoising methods; and (ii) the BiLSTM achieves a high detection and diagnostic accuracy of 96.7% with an improvement of 13.74% compared to the performance of the same model trained with noisy OTDR signals.      
### 2.Single Carrier Frequency Domain Detectors for Internet of Underwater Things  [ :arrow_down: ](https://arxiv.org/pdf/2203.12599.pdf)
>  This paper proposes low complexity detection for internet of underwater things (IoUT)s communication. The signal is transmitted from the source to the destination using several sensors. To simplify the computational operations at the transmitter and the sensory nodes, a single carrier frequency domain equalizer (SC-FDE) is proposed and amplify-and-forward (AF) protocols are employed. Fast Fourier transform (FFT) and use of cyclic prefix (CP) are also proposed to simplify these algorithms when compared to time-domain equalization. As precise channel data is difficult to capture in underwater communications, the adaptive implementation of FDE is proposed as a solution that can be employed when the channel experiences a fast doppler shift. The two adaptive detectors are based on the least mean-square (LMS) and recursive least square (RLS) principles. Numerical simulations show that the performance of the bit error rate (BER) performance of the proposed detectors is close to that of the ideal minimum mean square error (MMSE).      
### 3.PhysioMTL: Personalizing Physiological Patterns using Optimal Transport Multi-Task Regression  [ :arrow_down: ](https://arxiv.org/pdf/2203.12595.pdf)
>  Heart rate variability (HRV) is a practical and noninvasive measure of autonomic nervous system activity, which plays an essential role in cardiovascular health. However, using HRV to assess physiology status is challenging. Even in clinical settings, HRV is sensitive to acute stressors such as physical activity, mental stress, hydration, alcohol, and sleep. Wearable devices provide convenient HRV measurements, but the irregularity of measurements and uncaptured stressors can bias conventional analytical methods. To better interpret HRV measurements for downstream healthcare applications, we learn a personalized diurnal rhythm as an accurate physiological indicator for each individual. We develop Physiological Multitask-Learning (PhysioMTL) by harnessing Optimal Transport theory within a Multitask-learning (MTL) framework. The proposed method learns an individual-specific predictive model from heterogeneous observations, and enables estimation of an optimal transport map that yields a push forward operation onto the demographic features for each task. Our model outperforms competing MTL methodologies on unobserved predictive tasks for synthetic and two real-world datasets. Specifically, our method provides remarkable prediction results on unseen held-out subjects given only $20\%$ of the subjects in real-world observational studies. Furthermore, our model enables a counterfactual engine that generates the effect of acute stressors and chronic conditions on HRV rhythms.      
### 4.Deep Learning based Intelligent Coin-tap Test for Defect Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.12594.pdf)
>  The coin-tap test is a convenient and primary method for non-destructive testing, while its manual on-site operation is tough and costly. With the help of the latest intelligent signal processing method, convolutional neural networks (CNN), we achieve an intelligent coin-tap test which exhibited superior performance in recognizing the defects. However, this success of CNNs relies on plenty of well-labeled data from the identical scenario, which could be difficult to get for many real industrial practices. This paper further develops transfer learning strategies for this issue, that is, to transfer the model trained on data of one scenario to another. In experiments, the result presents a notable improvement by using domain adaptation and pseudo label learning strategies. Hence, it becomes possible to apply the model into scenarios with none or little (less than 10\%) labeled data adopting the transfer learning strategies proposed herein. In addition, we used a benchmark dataset constructed ourselves throughout this study. This benchmark dataset for the coin-tap test containing around 100,000 sound signals is published at <a class="link-external link-https" href="https://github.com/PPhub-hy/torch-tapnet" rel="external noopener nofollow">this https URL</a>.      
### 5.Design of Customized Adaptive Radar Detectors in the CFAR Feature Plane  [ :arrow_down: ](https://arxiv.org/pdf/2203.12565.pdf)
>  The paper addresses the design of adaptive radar detectors having desired behavior, in Gaussian disturbance with unknown statistics. Specifically, given detection probability specifications for chosen signal-to-noise ratios and steering vector mismatch levels, a methodology for the optimal design of customized CFAR detectors is devised in a suitable feature plane based on maximal invariant statistics. To overcome the analytical and numerical intractability of the resulting optimization problem, a novel general reduced-complexity algorithm is developed, which is shown to be effective in providing a close approximation of the desired detector. The proposed approach solves the open problem of ensuring a prefixed false alarm probability while controlling the behavior under both matched and mismatched conditions, so enabling the design of fully customized adaptive CFAR detectors.      
### 6.Scatter Ptychography  [ :arrow_down: ](https://arxiv.org/pdf/2203.12561.pdf)
>  Coherent illumination reflected by a remote target may be secondarily scattered by intermediate objects or materials. Here we show that phase retrieval on remotely observed images of such scattered fields enables imaging of the illuminated object at resolution proportional to $\lambda R_s/A_s$, where $R_s$ is the range between the scatterer and the target and $A_s$ is the diameter of the observed scatter. This resolution may exceed the resolution of directly viewing the target by the factor $R_cA_s/R_sA_c$, where $R_c$ is the range between the observer and the target and $A_c$ is the observing aperture. Here we use this technique to demonstrate $\approx 32\times$ resolution improvement relative to direct imaging.      
### 7.A Scalable Model Specialization Framework for Training and Inference using Submodels and its Application to Speech Model Personalization  [ :arrow_down: ](https://arxiv.org/pdf/2203.12559.pdf)
>  Model fine-tuning and adaptation have become a common approach for model specialization for downstream tasks or domains. Fine-tuning the entire model or a subset of the parameters using light-weight adaptation has shown considerable success across different specialization tasks. Fine-tuning a model for a large number of domains typically requires starting a new training job for every domain posing scaling limitations. Once these models are trained, deploying them also poses significant scalability challenges for inference for real-time applications. In this paper, building upon prior light-weight adaptation techniques, we propose a modular framework that enables us to substantially improve scalability for model training and inference. We introduce Submodels that can be quickly and dynamically loaded for on-the-fly inference. We also propose multiple approaches for training those Submodels in parallel using an embedding space in the same training job. We test our framework on an extreme use-case which is speech model personalization for atypical speech, requiring a Submodel for each user. We obtain 128x Submodel throughput with a fixed computation budget without a loss of accuracy. We also show that learning a speaker-embedding space can scale further and reduce the amount of personalization training data required per speaker.      
### 8.Organic log-domain integrator synapse  [ :arrow_down: ](https://arxiv.org/pdf/2203.12552.pdf)
>  Synapses play a critical role in memory, learning, and cognition. Their main functions include converting pre-synaptic voltage spikes to post-synaptic currents, as well as scaling the input signal. Several brain-inspired architectures have been proposed to emulate the behavior of biological synapses. While these are useful to explore the properties of nervous systems, the challenge of making biocompatible and flexible circuits with biologically plausible time constants and tunable gain remains. Here, a physically flexible organic log-domain integrator synaptic circuit is shown to address this challenge. In particular, the circuit is fabricated using organic-based materials that are electrically active, offer flexibility and biocompatibility, as well as time constants (critical in learning neural codes and encoding spatiotemporal patterns) that are biologically plausible. Using a 10 nF synaptic capacitor, the time constant reached 126 ms and 221 ms before and during bending, respectively. The flexible synaptic circuit is characterized before and during bending, followed by studies on the effects of weighting voltage, synaptic capacitance, and disparity in pre-synaptic signals on the time constant.      
### 9.Geometry of finite-time thermodynamic cycles with anisotropic thermal fluctuations  [ :arrow_down: ](https://arxiv.org/pdf/2203.12483.pdf)
>  In contrast to the classical concept of a Carnot engine that alternates contact between heat baths of different temperatures, naturally occurring processes usually harvest energy from anisotropy, being exposed simultaneously to chemical and thermal fluctuations of different intensities. In these cases, the enabling mechanism responsible for transduction of energy is the presence of a non-equilibrium steady state (NESS). A suitable stochastic model for such a phenomenon is the Brownian gyrator -- a two-degree of freedom stochastically driven system that exchanges energy and heat with the environment. In this context, we present a geometric view of the energy harvesting mechanism, from a stochastic control perspective, that entails a forced periodic trajectory of the system state on the thermodynamic manifold. Dissipation and work output are expressed accordingly as path integrals of a controlled process, and fundamental limitations on power and efficiency are expressed in geometric terms via a relationship to an isoperimetric problem. The theory is presented for high-order systems far from equilibrium and beyond the linear response regime.      
### 10.The VoicePrivacy 2022 Challenge Evaluation Plan  [ :arrow_down: ](https://arxiv.org/pdf/2203.12468.pdf)
>  For new participants - Executive summary: (1) The task is to develop a voice anonymization system for speech data which conceals the speaker's voice identity while protecting linguistic content, paralinguistic attributes, intelligibility and naturalness. (2) Training, development and evaluation datasets are provided in addition to 3 different baseline anonymization systems, evaluation scripts, and metrics. Participants apply their developed anonymization systems, run evaluation scripts and submit objective evaluation results and anonymized speech data to the organizers. (3) Results will be presented at a workshop held in conjunction with INTERSPEECH 2022 to which all participants are invited to present their challenge systems and to submit additional workshop papers. <br>For readers familiar with the VoicePrivacy Challenge - Changes w.r.t. 2020: (1) A stronger, semi-informed attack model in the form of an automatic speaker verification (ASV) system trained on anonymized (per-utterance) speech data. (2) Complementary metrics comprising the equal error rate (EER) as a privacy metric, the word error rate (WER) as a primary utility metric, and the pitch correlation and gain of voice distinctiveness as secondary utility metrics. (3) A new ranking policy based upon a set of minimum target privacy requirements.      
### 11.State and parameter estimation for retinal laser treatment  [ :arrow_down: ](https://arxiv.org/pdf/2203.12452.pdf)
>  Adequate therapeutic retinal laser irradiation needs to be adapted to the local absorption. This leads to time-consuming treatments as the laser power needs to be successively adjusted to avoid under- and overtreatment caused by too low or too high temperatures. Closed-loop control can overcome this burden by means of temperature measurements. To allow for model predictive control schemes, the current state and the spot-dependent absorption need to be estimated. In this paper, we thoroughly compare moving horizon estimator (MHE) and extended Kalman filter (EKF) designs for joint state and parameter estimation. We consider two different scenarios, the estimation of one or two unknown absorption coefficients. For one unknown parameter, both estimators perform very similar. For two unknown parameters, we found that the MHE benefits from active parameter constraints at the beginning of the estimation, whereas after a settling time both estimators perform again very similar as long as the parameters are inside the considered parameter bounds.      
### 12.Verification of safety critical control policies using kernel methods  [ :arrow_down: ](https://arxiv.org/pdf/2203.12407.pdf)
>  Hamilton-Jacobi reachability methods for safety-critical control have been well studied, but the safety guarantees derived rely on the accuracy of the numerical computation. Thus, it is crucial to understand and account for any inaccuracies that occur due to uncertainty in the underlying dynamics and environment as well as the induced numerical errors. To this end, we propose a framework for modeling the error of the value function inherent in Hamilton-Jacobi reachability using a Gaussian process. The derived safety controller can be used in conjuncture with arbitrary controllers to provide a safe hybrid control law. The marginal likelihood of the Gaussian process then provides a confidence metric used to determine switches between a least restrictive controller and a safety controller. We test both the prediction as well as the correction capabilities of the presented method in a classical pursuit-evasion example.      
### 13.A Levenberg-Marquardt algorithm for sparse identification of dynamical systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.12379.pdf)
>  Low complexity of a system model is essential for its use in real-time applications. However, sparse identification methods commonly have stringent requirements that exclude them from being applied in an industrial setting. In this paper, we introduce a flexible method for the sparse identification of dynamical systems described by ordinary differential equations. Our method relieves many of the requirements imposed by other methods that relate to the structure of the model and the data set, such as fixed sampling rates, full state measurements, and linearity of the model. The Levenberg-Marquardt algorithm is used to solve the identification problem. We show that the Levenberg-Marquardt algorithm can be written in a form that enables parallel computing, which greatly diminishes the time required to solve the identification problem. An efficient backward elimination strategy is presented to construct a lean system model.      
### 14.Long hauling eco-driving: heavy-duty trucks operational modes control with integrated road slope preview  [ :arrow_down: ](https://arxiv.org/pdf/2203.12378.pdf)
>  In this paper, a complete eco-driving strategy for heavy-duty trucks (HDT) based on a finite number of driving modes with corresponding gear shifting is developed to cope with different route events and with road slope data. The problem is formulated as an optimal control problem with respect to fuel consumption and trip duration, and solved using a Pontryagin minimum principle (PMP) algorithm for a path search problem, such that computations can be carried out online, in real-time. The developed eco-driving assistance system (EDAS) provides a velocity profile and a sequence of driving modes (and gears) recommendation to the driver, without actively controlling the HDT (human in the loop) and, in practice, allows contextual feedback incorporation from the driver for safety. Simulation results show that the developed methodology is able to provide a velocity profile for a complete route based on known road events and slope information while satisfying all truck operational constraints.      
### 15.A Fast Diagnostic to Inform Screening of Discarded or Retired Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2203.12376.pdf)
>  With the increased pervasiveness of Lithium-ion batteries, there is growing concern for the amount of retired batteries that will be entering the waste stream. Although these batteries no longer meet the demands of their first application, many still have a significant portion of their initial capacity remaining for use in secondary applications. Yet, direct repurposing is generally not possible and each cell in a battery must be evaluated, increasing the cost of the repurposed packs due to the time intensive screening process. In this paper, a rapid assessment of the internal resistance of a cell is proposed. First, this method of measuring the resistance is completed on cells from twelve retired battery packs and one fresh pack using a hybrid pulse power characterization (HPPC) test as a benchmark for the analysis. Results from these tests show relatively constant resistance measurements across mid to high terminal voltages, allowing this metric to be independent of state of charge (SOC). Then, the relation between internal resistance and capacity across the various packs is discussed. Initial experimental results from this study show a correlation between internal resistance and capacity which can be approximated with a linear fit, suggesting internal resistance measurements taken above a threshold cell terminal voltage may be a suitable initial screening metric for the capacity of retired cells without knowledge of the SOC.      
### 16.PHO-LID: A Unified Model Incorporating Acoustic-Phonetic and Phonotactic Information for Language Identification  [ :arrow_down: ](https://arxiv.org/pdf/2203.12366.pdf)
>  We propose a PHO-LID model to hierarchically incorporate phoneme and phonotactic information within a convolutional neural network-transformer encoder (CNN-Trans)-based model for language identification (LID) without the use of phoneme annotations. In our proposed PHO-LID model, the LID and self-supervised phoneme segmentation tasks share a CNN module. Our model therefore encodes the language and sequential phoneme information into segments before generating phonotactic embeddings. These embeddings are then fed into transformer encoder layers for utterance-level LID. We evaluate our proposed PHO-LID model on AP17-OLR data and the MLS14 set of NIST LRE 2017. Our proposed PHO-LID model exhibits the highest LID performance than other models, and achieves over 35% relative improvement in terms of average cost on AP17-OLR data compared to the CNN-Trans model. The comparison between predicted phoneme boundaries and the corresponding audio spectrogram indicates the existence of phoneme information. In addition, we provide a viewpoint on how to utilize the phonotactic information via a contrastive loss to enhance the LID performance with an appropriate sampling.      
### 17.Values of Coordinated Residential Space Heating in Demand Response Provision  [ :arrow_down: ](https://arxiv.org/pdf/2203.12365.pdf)
>  Demand-side response from space heating in residential buildings can potentially provide a huge amount of flexibility for the power system, particularly with deep electrification of the heat sector. In this context, this paper presents a novel distributed control strategy to coordinate space heating across numerous residential households with diversified thermal parameters. By employing an iterative algorithm under the game-theoretical framework, each household adjusts its own heating schedule through demand shift and thermal comfort compensation with the purpose of achieving individual cost savings, whereas the aggregate peak demand is effectively shaved on the system level. Additionally, an innovative thermal comfort model which considers both the temporal and spatial differences in customised thermal comfort requirements is proposed. Through a series of case studies, it is demonstrated that the proposed space heating coordination strategy can facilitate effective energy arbitrage for individual buildings, driving a 13.96% reduction in system operational cost and 28.22% peak shaving. Moreover, the superiority of the proposed approach in thermal comfort maintenance is numerically analysed based on the proposed thermal comfort quantification model.      
### 18.Energy Efficient Placement of ML-Based Services in IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.12312.pdf)
>  The Internet of Things (IoT) is gaining momentum in its quest to bridge the gap between the physical and the digital world. The main goal of the IoT is the creation of smart environments and self-aware things that help to facilitate a variety of services such as smart transport, climate monitoring, e-health, etc. Huge volumes of data are expected to be collected by the connected sensors/things, which in traditional cases are processed centrally by large data centers in the core network that will inevitably lead to excessive transportation power consumption as well as added latency overheads. Instead, fog computing has been proposed by researchers from industry and academia to extend the capability of the cloud right to the point where the data is collected at the sensing layer. This way, primitive tasks that can be hosted in IoT sensors do not need to be sent all the way to the cloud for processing. In this paper we propose energy efficient embedding of machine learning (ML) models over a cloud-fog network using a Mixed Integer Linear Programming (MILP) optimization model. We exploit virtualization in our framework to provide service abstraction of Deep Neural Networks (DNN) layers that can be composed into a set of VMs interconnected by virtual links. We constrain the number of VMs that can be processed at the IoT layer and study the impact on the performance of the cloud fog approach.      
### 19.Optical Network Design for 4G LTE  [ :arrow_down: ](https://arxiv.org/pdf/2203.12309.pdf)
>  The number of mobile users is increasing rapidly, 3GPP initiated a new technology 4G Long Term Evolution (LTE). LTE is an enabling technology as a solution to the problem of network capacity and quality in areas that have a high demand like Sleman. The quality of LTE networks are supported by backbone and distribution network. This paper describes the designing of fiber optic network as the LTE backbone network in Sleman. The backbone network requires G-652 optical cable along 85 km with a ring topology and WDM-STM64 technology. The distribution network uses GPON technology and the type of G984 optical cable along 61.35 km. The minimum of power received at the end-point in the optisystem simulation is -25 dBm and -26 dBm through the calculation. This value is acceptable, since it is above the minimum of power received (Receiver Sensitivity) -28 dBm which refers to the standard parameters of G.984.2. The average value of rise time is 69 ps, this value is still below the maximum allowable value of rise time 70 ps. Average BER of backbone link is 5x10-4.      
### 20.Koopman-Based Neural Lyapunov Functions for General Attractors  [ :arrow_down: ](https://arxiv.org/pdf/2203.12303.pdf)
>  Koopman spectral theory has grown in the past decade as a powerful tool for dynamical systems analysis and control. In this paper, we show how recent data-driven techniques for estimating Koopman-Invariant subspaces with neural networks can be leveraged to extract Lyapunov certificates for the underlying system. In our work, we specifically focus on systems with a limit-cycle, beyond just an isolated equilibrium point, and use Koopman eigenfunctions to efficiently parameterize candidate Lyapunov functions to construct forward-invariant sets under some (unknown) attractor dynamics. Additionally, when the dynamics are polynomial and when neural networks are replaced by polynomials as a choice of function approximators in our approach, one can further leverage Sum-of-Squares programs and/or nonlinear programs to yield provably correct Lyapunov certificates. In such a polynomial case, our Koopman-based approach for constructing Lyapunov functions uses significantly fewer decision variables compared to directly formulating and solving a Sum-of-Squares optimization problem.      
### 21.A Multi-Characteristic Learning Method with Micro-Doppler Signatures for Pedestrian Identification  [ :arrow_down: ](https://arxiv.org/pdf/2203.12236.pdf)
>  The identification of pedestrians using radar micro-Doppler signatures has become a hot topic in recent years. In this paper, we propose a multi-characteristic learning (MCL) model with clusters to jointly learn discrepant pedestrian micro-Doppler signatures and fuse the knowledge learned from each cluster into final decisions. Time-Doppler spectrogram (TDS) and signal statistical features extracted from FMCW radar, as two categories of micro-Doppler signatures, are used in MCL to learn the micro-motion information inside pedestrians' free walking patterns. The experimental results show that our model achieves a higher accuracy rate and is more stable for pedestrian identification than other studies, which make our model more practical.      
### 22.Enhanced Contour Tracking: a Time-Varying Internal Model Principle-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.12232.pdf)
>  We propose a time-varying internal model principle-based contouring control (TV-IMCC) methodology to enhance the contour tracking performance with both axial and contour error reduction. The proposed TV-IMCC is composed of two main parts: an extended position domain framework with master-slave structures for contour regulation, and the time-varying internal model controllers for axial tracking precision improvement. The important features of the TV-IMCC lie in: 1) it is of an asymptotical stability for irregular contour tracking compared to the cross coupled control (CCC); 2) it does not lead to system nonlinearity and hence is well-suited for tracking multi-axis contours compared to the task coordinate frame (TCF) control; 3) it reduces the tracking error and extends the class of contours can be tracked compared to the position domain control (PDC). Furthermore, the stability analysis of the closed-loop system with the proposed TV-IMCC methodology is provided. And various simulation and experimental results validate the TV-IMCC with enhanced contour tracking performance. A major potential of the proposed TV-IMCC is in the field of multi-axis ultra-precision contour tracking. Moreover, the TV-IMCC does not require strict precision of the master axis, and hence it can be easily applied to macro-micro motion systems, such as galvanometer scanner-stage synchronized systems.      
### 23.Physics-Driven Deep Learning for Computational Magnetic Resonance Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2203.12215.pdf)
>  Physics-driven deep learning methods have emerged as a powerful tool for computational magnetic resonance imaging (MRI) problems, pushing reconstruction performance to new limits. This article provides an overview of the recent developments in incorporating physics information into learning-based MRI reconstruction. We consider inverse problems with both linear and non-linear forward models for computational MRI, and review the classical approaches for solving these. We then focus on physics-driven deep learning approaches, covering physics-driven loss functions, plug-and-play methods, generative models, and unrolled networks. We highlight domain-specific challenges such as real- and complex-valued building blocks of neural networks, and translational applications in MRI with linear and non-linear forward models. Finally, we discuss common issues and open challenges, and draw connections to the importance of physics-driven learning when combined with other downstream tasks in the medical imaging pipeline.      
### 24.Safe and Efficient Model Predictive Control Using Neural Networks: An Interior Point Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.12196.pdf)
>  Model predictive control (MPC) provides a useful means for controlling systems with constraints, but suffers from the computational burden of repeatedly solving an optimization problem in real time. Offline (explicit) solutions for MPC attempt to alleviate real time computational challenges using either multiparametric programming or machine learning. The multiparametric approaches are typically applied to linear or quadratic MPC problems, while learning-based approaches can be more flexible and are less memory-intensive. Existing learning-based approaches offer significant speedups, but the challenge becomes ensuring constraint satisfaction while maintaining good performance. <br>In this paper, we provide a neural network parameterization of MPC policies that explicitly encodes the constraints of the problem. Therefore, the constraints are satisfied by design. By exploring the interior of the MPC feasible set in an unsupervised learning paradigm, the neural network finds better policies faster than projection-based methods and exhibits substantially faster solve times. We use the proposed policy to solve both a robust (tube-based) and a scenario-based MPC problem, and demonstrate the performance and computational gains on two standard test systems.      
### 25.Joint Covering Congestion Rents in Multi-area Power Systems Considering Loop Flow Effects  [ :arrow_down: ](https://arxiv.org/pdf/2203.12170.pdf)
>  We consider the problem of how multiple areas should jointly cover congestion rents of internal and tie-lines in an interconnected power system. A key issue of our concern is the loop flow problem, which represents discrepancies between scheduled and actual power flow distributions because electric power does not always flow along the most direct paths of transactions. We employ generalized coordinated transaction scheduling (GCTS) for interchange scheduling, which can eliminate dispatch errors caused by loop flow effects and asymptotically converge to the joint economic dispatch (JED) under ideal assumptions. Subsequently, distributed algorithms are proposed for each area to recover multipliers of the global GCTS model, as well as quantifying and pricing its contribution to line congestions. Thereby, all areas and interface bids can jointly cover congestion rents of internal and tie-lines with their merchandise surpluses and profits. Simulations demonstrate the effectiveness of the proposed approach of LMP recovery and joint covering congestion rents.      
### 26.Precise sinusoidal signal extraction from noisy waveform in vibration calibration  [ :arrow_down: ](https://arxiv.org/pdf/2203.12144.pdf)
>  Precise extraction of sinusoidal vibration parameters is essential for the dynamic calibration of vibration sensors, such as accelerometers. However, several standard methods have not yet been optimized for large background noise. In this work, signal processing methods to extract small vibration signals from noisy data in the case of accelerometer calibration is discussed. The results show that spectral leakage degrades calibration accuracy. Three methods based on the use of a filter, window function, and numerical differentiation are investigated with theoretical calculations, simulations, and experiments. These methods can effectively reduce the contribution of the calibration system noise. The uncertainty of micro vibration calibration in the National Metrology Institute of Japan is reduced by two orders of magnitudes using the proposed methods. The theoretical analyses in this work can lay the foundation for the optimization of signal processing in vibration calibration, and can be applied to other dynamic calibration fields.      
### 27.Optimal Control of Connected Automated Vehicles with Event-Triggered Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2203.12089.pdf)
>  We address the problem of controlling Connected and Automated Vehicles (CAVs) in conflict areas of a traffic network subject to hard safety constraints. It has been shown that such problems can be solved through a combination of tractable optimal control problem formulations and the use of Control Barrier Functions (CBFs) that guarantee the satisfaction of all constraints. These solutions can be reduced to a sequence of Quadratic Programs (QPs) which are efficiently solved on line over discrete time steps. However, the feasibility of each such QP cannot be guaranteed over every time step. To overcome this limitation, we develop an event-driven approach such that the next QP is triggered by properly defined events and show that this approach can eliminate infeasible cases due to time-driven inter-sampling effects. Simulation examples show how overall infeasibilities can be significantly reduced with the proposed event-triggering scheme, while also reducing the need for communication among CAVs without compromising performance.      
### 28.Time-domain Generalization of Kron Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2203.12084.pdf)
>  Kron reduction is a network-reduction method that eliminates nodes with zero current injections from electrical networks operating in sinusoidal steady state. In the time domain, the state-of-the-art application of Kron reduction has been in networks with transmission lines that have constant R/L ratios. This paper considers RL networks without such restriction and puts forth a provably exact time-domain generalization of Kron reduction. Exemplifying empirical tests on a wye-delta network are provided to validate the analytical results.      
### 29.Modelling and Analysis of Car Following Algorithms for Fuel Economy Improvement in Connected and Autonomous Vehicles (CAVs)  [ :arrow_down: ](https://arxiv.org/pdf/2203.12078.pdf)
>  Connectivity in ground vehicles allows vehicles to share crucial vehicle data, such as vehicle acceleration, with each other. Using sensors such as cameras, radars and lidars, on the other hand, the intravehicular distance between a leader vehicle and a host vehicle can be detected, as well as the relative speed. Cooperative Adaptive Cruise Control (CACC) builds upon ground vehicle connectivity and sensor information to form convoys with automated car following. CACC can also be used to improve fuel economy and mobility performance of vehicles in the said convoy. In this paper, 3 car following algorithms for fuel economy of CAVs are presented. An Adaptive Cruise Control (ACC) algorithm was designed as the benchmark model for comparison. A Cooperative Adaptive Cruise Control (CACC) was designed, which uses lead vehicle acceleration received through V2V in car following. an Ecological Cooperative Adaptive Cruise Control (Eco-CACC) model was developed that takes the erratic lead vehicle acceleration as a disturbance to be attenuated. A High Level (HL) controller was designed for decision making when the lead vehicle was an erratic driver. Model-in-the-Loop (MIL) and Hardware-in-the-Loop (HIL) simulations were run to test these car following algorithms for fuel economy performance. The results show that the HL controller was able to attain a smooth speed profile that consumed less fuel through using CACC and Eco-CACC than its ACC counterpart when the lead vehicle was erratic.      
### 30.Distributionally Robust Model Predictive Control with Total Variation Distance  [ :arrow_down: ](https://arxiv.org/pdf/2203.12062.pdf)
>  This paper studies the problem of distributionally robust model predictive control (MPC) using total variation distance ambiguity sets. For a discrete-time linear system with additive disturbances, we provide a conditional value-at-risk reformulation of the MPC optimization problem that is distributionally robust in the expected cost and chance constraints. The distributionally robust chance constraint is over-approximated as a tightened chance constraint, wherein the tightening for each time step in the MPC can be computed offline, hence reducing the computational burden. We conclude with numerical experiments to support our results on the probabilistic guarantees and computational efficiency.      
### 31.Energy-optimal Three-dimensional Path-following Control of Autonomous Underwater Vehicles under Ocean Currents  [ :arrow_down: ](https://arxiv.org/pdf/2203.12055.pdf)
>  This paper presents a three-dimensional (3D) energy-optimal path-following control design for autonomous underwater vehicles subject to ocean currents. The proposed approach has a two-stage control architecture consisting of the setpoint computation and the setpoint tracking. In the first stage, the surge velocity, heave velocity, and pitch angle setpoints are optimized by minimizing the required vehicle propulsion energy under currents, and the line-of-sight (LOS) guidance law is used to generate the yaw angle setpoint that ensures path following. In the second stage, two model predictive controllers are designed to control the vehicle motion in the horizontal and vertical planes by tracking the optimal setpoints. The proposed controller is compared with a conventional LOS-based control that maintains zero heave velocity relative to the current (i.e., relative heave velocity) and derives pitch angle setpoint using LOS guidance to reach the desired depth. Through simulations, we show that the proposed approach can achieve more than $13\%$ energy saving on a lawnmower-type and an inspection mission under different ocean current conditions. The simulation results demonstrate that allowing motions with non-zero relative heave velocity improves energy efficiency in 3D path-following applications.      
### 32.Upmixing via style transfer: a variational autoencoder for disentangling spatial images and musical content  [ :arrow_down: ](https://arxiv.org/pdf/2203.12053.pdf)
>  In the stereo-to-multichannel upmixing problem for music, one of the main tasks is to set the directionality of the instrument sources in the multichannel rendering results. In this paper, we propose a modified variational autoencoder model that learns a latent space to describe the spatial images in multichannel music. We seek to disentangle the spatial images and music content, so the learned latent variables are invariant to the music. At test time, we use the latent variables to control the panning of sources. We propose two upmixing use cases: transferring the spatial images from one song to another and blind panning based on the generative model. We report objective and subjective evaluation results to empirically show that our model captures spatial images separately from music content and achieves transfer-based interactive panning.      
### 33.Data-driven optimal control of affine systems: A linear programming perspective  [ :arrow_down: ](https://arxiv.org/pdf/2203.12044.pdf)
>  In this letter, we discuss the problem of optimal control for affine systems in the context of data-driven linear programming. First, we introduce a unified framework for the fixed point characterization of the value function, Q-function and relaxed Bellman operators. Then, in a model-free setting, we show how to synthesize and estimate Bellman inequalities from a small but sufficiently rich dataset. To guarantee exploration richness, we complete the extension of Willem's fundamental lemma to affine systems.      
### 34.Bearing-Based Formation Control with Optimal Motion Trajectory  [ :arrow_down: ](https://arxiv.org/pdf/2203.11967.pdf)
>  Bearing-based distributed formation control is attractive because it can be implemented using vision-based measurements to achieve a desired formation. Gradient-descent-based controllers using bearing measurements have been shown to have many beneficial characteristics, such as global convergence, applicability to different graph topologies and workspaces of arbitrary dimension, and some flexibility in the choice of the cost. In practice, however, such controllers typically yield convoluted paths from their initial location to the final position in the formation. In this paper we propose a novel procedure to optimize gradient-descent-based bearing-based formation controllers to obtain shorter paths. Our approach is based on the parameterization of the cost function and, by extension, of the controller. We form and solve a nonlinear optimization problem with the sum of path lengths of the agent trajectories as the objective and subject to the original equilibria and global convergence conditions for formation control. Our simulation shows that the parameters can be optimized from a very small number of training samples (1 to 7) to straighten the trajectory by around 16% for a large number of random initial conditions for bearing-only formation. However, in the absence of any range information, the scale of the formation is not fixed and this optimization may lead to an undesired compression of the formation size. Including range measurements avoids this issue and leads to further trajectories straightening by 66%.      
### 35.A Quantitative Comparison between Shannon and Tsallis Havrda Charvat Entropies Applied to Cancer Outcome Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2203.11943.pdf)
>  In this paper, we propose to quantitatively compare loss functions based on parameterized Tsallis-Havrda-Charvat entropy and classical Shannon entropy for the training of a deep network in the case of small datasets which are usually encountered in medical applications. Shannon cross-entropy is widely used as a loss function for most neural networks applied to the segmentation, classification and detection of images. Shannon entropy is a particular case of Tsallis-Havrda-Charvat entropy. In this work, we compare these two entropies through a medical application for predicting recurrence in patients with head-neck and lung cancers after treatment. Based on both CT images and patient information, a multitask deep neural network is proposed to perform a recurrence prediction task using cross-entropy as a loss function and an image reconstruction task. Tsallis-Havrda-Charvat cross-entropy is a parameterized cross entropy with the parameter $\alpha$. Shannon entropy is a particular case of Tsallis-Havrda-Charvat entropy for $\alpha$ = 1. The influence of this parameter on the final prediction results is studied. In this paper, the experiments are conducted on two datasets including in total 580 patients, of whom 434 suffered from head-neck cancers and 146 from lung cancers. The results show that Tsallis-Havrda-Charvat entropy can achieve better performance in terms of prediction accuracy with some values of $\alpha$.      
### 36.Improving the Fairness of Chest X-ray Classifiers  [ :arrow_down: ](https://arxiv.org/pdf/2203.12609.pdf)
>  Deep learning models have reached or surpassed human-level performance in the field of medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such classifiers can exhibit biases in the form of gaps in predictive performance across protected groups. In this paper, we question whether striving to achieve zero disparities in predictive performance (i.e. group fairness) is the appropriate fairness definition in the clinical setting, over minimax fairness, which focuses on maximizing the performance of the worst-case group. We benchmark the performance of nine methods in improving classifier fairness across these two definitions. We find, consistent with prior work on non-clinical data, that methods which strive to achieve better worst-group performance do not outperform simple data balancing. We also find that methods which achieve group fairness do so by worsening performance for all groups. In light of these results, we discuss the utility of fairness definitions in the clinical setting, advocating for an investigation of the bias-inducing mechanisms in the underlying data generating process whenever possible.      
### 37.TransSleep: Transitioning-aware Attention-based Deep Neural Network for Sleep Staging  [ :arrow_down: ](https://arxiv.org/pdf/2203.12590.pdf)
>  Sleep staging is essential for sleep assessment and plays a vital role as a health indicator. Many recent studies have devised various machine learning as well as deep learning architectures for sleep staging. However, two key challenges hinder the practical use of these architectures: effectively capturing salient waveforms in sleep signals and correctly classifying confusing stages in transitioning epochs. In this study, we propose a novel deep neural network structure, TransSleep, that captures distinctive local temporal patterns and distinguishes confusing stages using two auxiliary tasks. In particular, TransSleep adopts an attention-based multi-scale feature extractor module to capture salient waveforms; a stage-confusion estimator module with a novel auxiliary task, epoch-level stage classification, to estimate confidence scores for identifying confusing stages; and a context encoder module with the other novel auxiliary task, stage-transition detection, to represent contextual relationships across neighboring epochs. Results show that TransSleep achieves promising performance in automatic sleep staging. The validity of TransSleep is demonstrated by its state-of-the-art performance on two publicly available datasets, Sleep-EDF and MASS. Furthermore, we performed ablations to analyze our results from different perspectives. Based on our overall results, we believe that TransSleep has immense potential to provide new insights into deep learning-based sleep staging.      
### 38.DSRC &amp; C-V2X Comparison for Connected and Automated Vehicles in Different Traffic Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2203.12553.pdf)
>  Researches have been devoted to making connected and automated vehicles (CAVs) faster in different traffic scenarios. By using C-V2X or DSRC communication protocol, CAVs can work more effectively. In this paper, we compare these two communication protocols on CAVs in three different traffic scenarios including ramp merging, intersection, and platoon brake. It shows there is a trade-off between communication range and interval when leveraging C-V2X or DSRC for CAVs. The result can help support further application designs for CAV autonomously choosing communication protocols in different traffic scenarios.      
### 39.Optimization-Based Safe Stabilizing Feedback with Guaranteed Region of Attraction  [ :arrow_down: ](https://arxiv.org/pdf/2203.12550.pdf)
>  This paper proposes an optimization with penalty-based feedback design framework for safe stabilization of control affine systems. Our starting point is the availability of a control Lyapunov function (CLF) and a control barrier function (CBF) defining affine-in-the-input inequalities that certify, respectively, the stability and safety objectives for the dynamics. Leveraging ideas from penalty methods for constrained optimization, the proposed design framework imposes one of the inequalities as a hard constraint and the other one as a soft constraint. We study the properties of the closed-loop system under the resulting feedback controller and identify conditions on the penalty parameter to eliminate undesired equilibria that might arise. Going beyond the local stability guarantees available in the literature, we are able to provide an inner approximation of the region of attraction of the equilibrium, and identify conditions under which the whole safe set belongs to it. Simulations illustrate our results.      
### 40.Sampling Theorems for Unsupervised Learning in Linear Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2203.12513.pdf)
>  Solving a linear inverse problem requires knowledge about the underlying signal model. In many applications, this model is a priori unknown and has to be learned from data. However, it is impossible to learn the model using observations obtained via a single incomplete measurement operator, as there is no information outside the range of the inverse operator, resulting in a chicken-and-egg problem: to learn the model we need reconstructed signals, but to reconstruct the signals we need to know the model. Two ways to overcome this limitation are using multiple measurement operators or assuming that the signal model is invariant to a certain group action. In this paper, we present necessary and sufficient sampling conditions for learning the signal model from partial measurements which only depend on the dimension of the model, and the number of operators or properties of the group action that the model is invariant to. As our results are agnostic of the learning algorithm, they shed light into the fundamental limitations of learning from incomplete data and have implications in a wide range set of practical algorithms, such as dictionary learning, matrix completion and deep neural networks.      
### 41.Block-Level Interference Exploitation Precoding without Symbol-by-Symbol Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.12502.pdf)
>  Symbol-level precoding (SLP) based on the concept of constructive interference (CI) is shown to be superior to traditional block-level precoding (BLP), however at the cost of a symbol-by-symbol optimization during the precoding design. In this paper, we propose a CI-based block-level precoding (CI-BLP) scheme for the downlink transmission of a multi-user multiple-input single-output (MU-MISO) communication system, where we design a constant precoding matrix to a block of symbol slots to exploit CI for each symbol slot simultaneously. A single optimization problem is formulated to maximize the minimum CI effect over the entire block, thus reducing the computational cost of traditional SLP as the optimization problem only needs to be solved once per block. By leveraging the Karush-Kuhn-Tucker (KKT) conditions and the dual problem formulation, the original optimization problem is finally shown to be equivalent to a quadratic programming (QP) over a simplex. Numerical results validate our derivations and exhibit superior performance for the proposed CI-BLP scheme over traditional BLP and SLP methods, thanks to the relaxed block-level power constraint.      
### 42.A Lower-bound for Variable-length Source Coding in LQG Feedback Control  [ :arrow_down: ](https://arxiv.org/pdf/2203.12467.pdf)
>  In this letter, we consider a Linear Quadratic Gaussian (LQG) control system where feedback occurs over a noiseless binary channel and derive lower bounds on the minimum communication cost (quantified via the channel bitrate) required to attain a given control performance. We assume that at every time step an encoder can convey a packet containing a variable number of bits over the channel to a decoder at the controller. Our system model provides for the possibility that the encoder and decoder have shared randomness, as is the case in systems using dithered quantizers. We define two extremal prefix-free requirements that may be imposed on the message packets; such constraints are useful in that they allow the decoder, and potentially other agents to uniquely identify the end of a transmission in an online fashion. We then derive a lower bound on the rate of prefix-free coding in terms of directed information; in particular we show that a previously known bound still holds in the case with shared randomness. We also provide a generalization of the bound that applies if prefix-free requirements are relaxed. We conclude with a rate-distortion formulation.      
### 43.Activation-Based Sampling for Pixel- to Image-Level Aggregation in Weakly-Supervised Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2203.12459.pdf)
>  Classification networks can be used to localize and segment objects in images by means of class activation maps (CAMs). However, without pixel-level annotations, they are known to (1) mainly focus on discriminative regions, and (2) to produce diffuse CAMs without well-defined prediction contours. In this work, we approach both problems with two contributions for improving CAM learning. First, we incorporate importance sampling based on the class-wise probability mass function induced by the CAMs to produce stochastic image-level class predictions. This results in CAMs which activate over a larger extent of the objects. Second, we formulate a feature similarity loss term which aims to match the prediction contours with edges in the image. As a third contribution, we conduct experiments on the PASCAL VOC and MS-COCO benchmark datasets to demonstrate that these modifications significantly increase the performance in terms of contour accuracy, while being comparable to current state-of-the-art methods in terms of region similarity.      
### 44.A Framework for Controlling Multi-Robot Systems Using Bayesian Optimization and Linear Combination of Vectors  [ :arrow_down: ](https://arxiv.org/pdf/2203.12416.pdf)
>  We propose a general framework for creating parameterized control schemes for decentralized multi-robot systems. A variety of tasks can be seen in the decentralized multi-robot literature, each with many possible control schemes. For several of them, the agents choose control velocities using algorithms that extract information from the environment and combine that information in meaningful ways. From this basic formation, a framework is proposed that classifies each robots' measurement information as sets of relevant scalars and vectors and creates a linear combination of the measured vector sets. Along with an optimizable parameter set, the scalar measurements are used to generate the coefficients for the linear combination. With this framework and Bayesian optimization, we can create effective control systems for several multi-robot tasks, including cohesion and segregation, pattern formation, and searching/foraging.      
### 45.Repulsive Clustering Based Pilot Assignment for Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.12403.pdf)
>  Thanks to its capability to provide a uniform service rate for the User Equipments (UEs), Cell-free (CF) massive Multiple-Input, Multiple-Output (mMIMO), has recently attracted considerable attention, both in academia and in industry, and so is considered as one of the potential technologies for beyond-5G and 6G. However, the reuse of the same pilot signals by multiple users can create the so-called pilot contamination problem, which can hinder the CF mMIMO from unlocking its full performance. In this paper, we address the challenge by formulating the pilot assignment as a maximally diverse clustering problem and propose an efficient yet straightforward repulsive clustering-based pilot assignment scheme to mitigate the effects of pilot contamination on CF mMIMO. The numerical results show the superiority of the proposed technique compared to some other methods with respect to the achieved uplink per-user rate.      
### 46.MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data  [ :arrow_down: ](https://arxiv.org/pdf/2203.12369.pdf)
>  Training of speech enhancement systems often does not incorporate knowledge of human perception and thus can lead to unnatural sounding results. Incorporating psychoacoustically motivated speech perception metrics as part of model training via a predictor network has recently gained interest. However, the performance of such predictors is limited by the distribution of metric scores that appear in the training <a class="link-external link-http" href="http://data.In" rel="external noopener nofollow">this http URL</a> this work, we propose MetricGAN+/- (an extension of MetricGAN+, one such metric-motivated system) which introduces an additional network - a "de-generator" which attempts to improve the robustness of the prediction network (and by extension of the generator) by ensuring observation of a wider range of metric scores in training. Experimental results on the VoiceBank-DEMAND dataset show relative improvement in PESQ score of $3.8\%$ ($3.05$ vs $3.22$ PESQ score), as well as better generalisation to unseen noise and speech.      
### 47.Learning based Channel Estimation and Phase Noise Compensation in Doubly-Selective Channels  [ :arrow_down: ](https://arxiv.org/pdf/2203.12328.pdf)
>  In this letter, we propose a learning based channel estimation scheme for orthogonal frequency division multiplexing (OFDM) systems in the presence of phase noise in doubly-selective fading channels. Two-dimensional (2D) convolutional neural networks (CNNs) are employed for effective training and tracking of channel variation in both frequency as well as time domain. The proposed network learns and estimates the channel coefficients in the entire time-frequency (TF) grid based on pilots sparsely populated in the TF grid. In order to make the network robust to phase noise (PN) impairment, a novel training scheme where the training data is rotated by random phases before being fed to the network is employed. Further, using the estimated channel coefficients, a simple and effective PN estimation and compensation scheme is devised. Numerical results demonstrate that the proposed network and PN compensation scheme achieve robust OFDM performance in the presence of phase noise.      
### 48.Wider or Deeper Neural Network Architecture for Acoustic Scene Classification with Mismatched Recording Devices  [ :arrow_down: ](https://arxiv.org/pdf/2203.12314.pdf)
>  In this paper, we present a robust and low complexity system for Acoustic Scene Classification (ASC), the task of identifying the scene of an audio recording. We first construct an ASC baseline system in which a novel inception-residual-based network architecture is proposed to deal with the mismatched recording device issue. To further improve the performance but still satisfy the low complexity model, we apply two techniques: ensemble of multiple spectrograms and channel reduction on the ASC baseline system. By conducting extensive experiments on the benchmark DCASE 2020 Task 1A Development dataset, we achieve the best model performing an accuracy of 69.9% and a low complexity of 2.4M trainable parameters, which is competitive to the state-of-the-art ASC systems and potential for real-life applications on edge devices.      
### 49.Deep Channel Prediction: A DNN Framework for Receiver Design in Time-Varying Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2203.12310.pdf)
>  In time-varying fading channels, channel coefficients are estimated using pilot symbols that are transmitted every coherence interval. For channels with high Doppler spread, the rapid channel variations over time will require considerable bandwidth for pilot transmission, leading to poor throughput. In this paper, we propose a novel receiver architecture using deep recurrent neural networks (RNNs) that learns the channel variations and thereby reduces the number of pilot symbols required for channel estimation. Specifically, we design and train an RNN to learn the correlation in the time-varying channel and predict the channel coefficients into the future with good accuracy over a wide range of Dopplers and signal-to-noise ratios (SNR). The proposed training methodology enables accurate channel prediction through the use of techniques such as teacher-force training, early-stop, and reduction of learning rate on plateau. Also, the robustness of prediction for different Dopplers and SNRs is achieved by adapting the number of predictions into the future based on the Doppler and SNR. Numerical results show that good bit error performance is achieved by the proposed receiver in time-varying fading channels. We also propose a data decision driven receiver architecture using RNNs that further reduces the pilot overhead while maintaining good bit error performance.      
### 50.A combination between VQ and covariance matrices for speaker recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.12306.pdf)
>  This paper presents a new algorithm for speaker recognition based on the combination between the classical Vector Quantization (VQ) and Covariance Matrix (CM) methods. The combined VQ-CM method improves the identification rates of each method alone, with comparable computational burden. It offers a straightforward procedure to obtain a model similar to GMM with full covariance matrices. Experimental results also show that it is more robust against noise than VQ or CM alone.      
### 51.Cell segmentation from telecentric bright-field transmitted light microscopic images using a Residual Attention U-Net: a case study on HeLa line  [ :arrow_down: ](https://arxiv.org/pdf/2203.12290.pdf)
>  Living cell segmentation from bright-field light microscopic images is challenging due to the image complexity and temporal changes in the living cells. Recently developed deep learning (DL)-based methods became popular in medical and microscopic image segmentation tasks due to their success and promising outcomes. The main objective of this paper is to develop a deep learning, UNet-based method to segment the living cells of the HeLa line in bright-field transmitted light microscopy. To find the most suitable architecture for our datasets, we have proposed a residual attention U-Net and compared it with an attention and a simple U-Net architecture. The attention mechanism highlights the remarkable features and suppresses activations in the irrelevant image regions. The residual mechanism overcomes with vanishing gradient problem. The Mean-IoU score for our datasets reaches 0.9505, 0.9524, and 0.9530 for the simple, attention, and residual attention U-Net, respectively. We achieved the most accurate semantic segmentation results in the Mean-IoU and Dice metrics by applying the residual and attention mechanisms together. The watershed method applied to this best - Residual Attention - semantic segmentation result gave the segmentation with the specific information for each cell.      
### 52.Quantitative Evaluation Approach for Translation of Perceptual Soundscape Attributes: Initial Application to the Thai Language  [ :arrow_down: ](https://arxiv.org/pdf/2203.12245.pdf)
>  Translation of perceptual soundscape attributes from one language to another remains a challenging task that requires a high degree of fidelity in both psychoacoustic and psycholinguistic senses across the target population. Due to the inherently subjective nature of human perception, translating soundscape attributes using only small focus group discussion or expert panels could lead to translations with psycholinguistic meanings that, in a non-expert setting, deviate or distort from that of the source language. In this work, we present a quantitative evaluation method based on the circumplex model of soundscape perception to assess the overall translation quality across a set of criteria. As an initial application domain, we demonstrated the use of the quantitative evaluation framework in the context of an English-to-Thai translation of soundscape attributes.      
### 53.Efficient Pairing in Unknown Environments: Minimal Observations and TSP-based Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.12214.pdf)
>  Generating paired sequences with maximal compatibility from a given set is one of the most important challenges in various applications, including information and communication technologies. However, the number of possible pairings explodes in a double factorial order as a function of the number of entities, manifesting the difficulties of finding the optimal pairing that maximizes the overall reward. In the meantime, in real-world systems, such as user pairing in non-orthogonal multiple access (NOMA), pairing often needs to be conducted at high speed in dynamically changing environments; hence, efficient recognition of the environment and finding high reward pairings are highly demanded. In this paper, we demonstrate an efficient pairing algorithm to recognize compatibilities among elements as well as to find a pairing that yields a high total compatibility. The proposed pairing strategy consists of two phases. The first is the observation phase, where compatibility information among elements is obtained by only observing the sum of rewards. We show an efficient strategy that allows obtaining all compatibility information with minimal observations. The minimum number of observations under these conditions is also discussed, along with its mathematical proof. The second is the combination phase, by which a pairing with a large total reward is determined heuristically. We transform the pairing problem into a traveling salesman problem (TSP) in a three-layer graph structure, which we call Pairing-TSP. We demonstrate heuristic algorithms in solving the Pairing-TSP efficiently. This research is expected to be utilized in real-world applications such as NOMA, social networks, among others.      
### 54.Towards Expressive Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2203.12201.pdf)
>  Previous works on expressive speech synthesis mainly focus on current sentence. The context in adjacent sentences is neglected, resulting in inflexible speaking style for the same text, which lacks speech variations. In this paper, we propose a hierarchical framework to model speaking style from context. A hierarchical context encoder is proposed to explore a wider range of contextual information considering structural relationship in context, including inter-phrase and inter-sentence relations. Moreover, to encourage this encoder to learn style representation better, we introduce a novel training strategy with knowledge distillation, which provides the target for encoder training. Both objective and subjective evaluations on a Mandarin lecture dataset demonstrate that the proposed method can significantly improve the naturalness and expressiveness of the synthesized speech.      
### 55.A density description of a bounded-confidence model of opinion dynamics on hypergraphs  [ :arrow_down: ](https://arxiv.org/pdf/2203.12189.pdf)
>  Models of opinion dynamics on graphs allow one to study how the opinions of agents change due to dyadic interactions between them. It is useful to extend such models to hypergraphs to examine how opinions change when social interactions occur between three or more agents at once. In this paper, we consider a bounded-confidence model, in which opinions take continuous values and interacting agents comprise their opinions if they are close enough to each other. We propose a density description to study the Deffuant--Weisbuch bounded-confidence model on hypergraphs. We derive a mean-field rate equation as the number of agents in a network becomes infinite, and we prove that the rate equation yields a probability density that converges to noninteracting opinion clusters. Using numerical simulations, we examine bifurcations of the density model's steady-state opinion clusters and demonstrate that the agent-based model converges to the density model as the number of agents becomes infinite.      
### 56.FullSubNet+: Channel Attention FullSubNet with Complex Spectrograms for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2203.12188.pdf)
>  Previously proposed FullSubNet has achieved outstanding performance in Deep Noise Suppression (DNS) Challenge and attracted much attention. However, it still encounters issues such as input-output mismatch and coarse processing for frequency bands. In this paper, we propose an extended single-channel real-time speech enhancement framework called FullSubNet+ with following significant improvements. First, we design a lightweight multi-scale time sensitive channel attention (MulCA) module which adopts multi-scale convolution and channel attention mechanism to help the network focus on more discriminative frequency bands for noise reduction. Then, to make full use of the phase information in noisy speech, our model takes all the magnitude, real and imaginary spectrograms as inputs. Moreover, by replacing the long short-term memory (LSTM) layers in original full-band model with stacked temporal convolutional network (TCN) blocks, we design a more efficient full-band module called full-band extractor. The experimental results in DNS Challenge dataset show the superior performance of our FullSubNet+, which reaches the state-of-the-art (SOTA) performance and outperforms other existing speech enhancement approaches.      
### 57.On Adversarial Robustness of Large-scale Audio Visual Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.12122.pdf)
>  As audio-visual systems are being deployed for safety-critical tasks such as surveillance and malicious content filtering, their robustness remains an under-studied area. Existing published work on robustness either does not scale to large-scale dataset, or does not deal with multiple modalities. This work aims to study several key questions related to multi-modal learning through the lens of robustness: 1) Are multi-modal models necessarily more robust than uni-modal models? 2) How to efficiently measure the robustness of multi-modal learning? 3) How to fuse different modalities to achieve a more robust multi-modal model? To understand the robustness of the multi-modal model in a large-scale setting, we propose a density-based metric, and a convexity metric to efficiently measure the distribution of each modality in high-dimensional latent space. Our work provides a theoretical intuition together with empirical evidence showing how multi-modal fusion affects adversarial robustness through these metrics. We further devise a mix-up strategy based on our metrics to improve the robustness of the trained model. Our experiments on AudioSet and Kinetics-Sounds verify our hypothesis that multi-modal models are not necessarily more robust than their uni-modal counterparts in the face of adversarial examples. We also observe our mix-up trained method could achieve as much protection as traditional adversarial training, offering a computationally cheap alternative. Implementation: <a class="link-external link-https" href="https://github.com/lijuncheng16/AudioSetDoneRight" rel="external noopener nofollow">this https URL</a>      
### 58.An Optical Controlling Environment and Reinforcement Learning Benchmarks  [ :arrow_down: ](https://arxiv.org/pdf/2203.12114.pdf)
>  Deep reinforcement learning has the potential to address various scientific problems. In this paper, we implement an optics simulation environment for reinforcement learning based controllers. The environment incorporates nonconvex and nonlinear optical phenomena as well as more realistic time-dependent noise. Then we provide the benchmark results of several state-of-the-art reinforcement learning algorithms on the proposed simulation environment. In the end, we discuss the difficulty of controlling the real-world optical environment with reinforcement learning algorithms.      
### 59.Music Generation Using an LSTM  [ :arrow_down: ](https://arxiv.org/pdf/2203.12105.pdf)
>  Over the past several years, deep learning for sequence modeling has grown in popularity. To achieve this goal, LSTM network structures have proven to be very useful for making predictions for the next output in a series. For instance, a smartphone predicting the next word of a text message could use an LSTM. We sought to demonstrate an approach of music generation using Recurrent Neural Networks (RNN). More specifically, a Long Short-Term Memory (LSTM) neural network. Generating music is a notoriously complicated task, whether handmade or generated, as there are a myriad of components involved. Taking this into account, we provide a brief synopsis of the intuition, theory, and application of LSTMs in music generation, develop and present the network we found to best achieve this goal, identify and address issues and challenges faced, and include potential future improvements for our network.      
### 60.A hybrid quantum image edge detector for the NISQ era  [ :arrow_down: ](https://arxiv.org/pdf/2203.12072.pdf)
>  Edges are image locations where the gray value intensity changes suddenly. They are among the most important features to understand and segment an image. Edge detection is a standard task in digital image processing, solved for example using filtering techniques. However, the amount of data to be processed grows rapidly and pushes even supercomputers to their limits. Quantum computing promises exponentially lower memory usage in terms of the number of qubits compared to the number of classical bits. In this paper, we propose a hybrid method for quantum edge detection based on the idea of a quantum artificial neuron. Our method can be practically implemented on quantum computers, especially on those of the current noisy intermediate-scale quantum era. We compare six variants of the method to reduce the number of circuits and thus the time required for the quantum edge detection. Taking advantage of the scalability of our method, we can practically detect edges in images considerably larger than reached before.      
### 61.WayFAST: Traversability Predictive Navigation for Field Robots  [ :arrow_down: ](https://arxiv.org/pdf/2203.12071.pdf)
>  We present a self-supervised approach for learning to predict traversable paths for wheeled mobile robots that require good traction to navigate. Our algorithm, termed WayFAST (Waypoint Free Autonomous Systems for Traversability), uses RGB and depth data, along with navigation experience, to autonomously generate traversable paths in outdoor unstructured environments. Our key inspiration is that traction can be estimated for rolling robots using kinodynamic models. Using traction estimates provided by an online receding horizon estimator, we are able to train a traversability prediction neural network in a self-supervised manner, without requiring heuristics utilized by previous methods. We demonstrate the effectiveness of WayFAST through extensive field testing in varying environments, ranging from sandy dry beaches to forest canopies and snow covered grass fields. Our results clearly demonstrate that WayFAST can learn to avoid geometric obstacles as well as untraversable terrain, such as snow, which would be difficult to avoid with sensors that provide only geometric data, such as LiDAR. Furthermore, we show that our training pipeline based on online traction estimates is more data-efficient than other heuristic-based methods.      
### 62.Certifying the Intersection of Reach Sets of Integrator Agents with Set-valued Input Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2203.12007.pdf)
>  We consider the problem of verifying safety for a pair of identical integrator agents in continuous time with compact set-valued input uncertainties. We encode this verification problem as that of certifying or falsifying the intersection of their reach sets. We transcribe the same into a variational problem, namely that of minimizing the support function of the difference of the two reach sets over the unit sphere. We illustrate the computational tractability of the proposed formulation by developing two cases in detail, viz. when the inputs have time-varying norm-bounded and generic hyperrectangular uncertainties. We show that the latter case allows distributed certification via second order cone programming.      
### 63.Federated Self-Supervised Learning for Acoustic Event Classification  [ :arrow_down: ](https://arxiv.org/pdf/2203.11997.pdf)
>  Standard acoustic event classification (AEC) solutions require large-scale collection of data from client devices for model optimization. Federated learning (FL) is a compelling framework that decouples data collection and model training to enhance customer privacy. In this work, we investigate the feasibility of applying FL to improve AEC performance while no customer data can be directly uploaded to the server. We assume no pseudo labels can be inferred from on-device user inputs, aligning with the typical use cases of AEC. We adapt self-supervised learning to the FL framework for on-device continual learning of representations, and it results in improved performance of the downstream AEC classifiers without labeled/pseudo-labeled data available. Compared to the baseline w/o FL, the proposed method improves precision up to 20.3\% relatively while maintaining the recall. Our work differs from prior work in FL in that our approach does not require user-generated learning targets, and the data we use is collected from our Beta program and is de-identified, to maximally simulate the production settings.      
### 64.A Factor-Based Framework for Decision-Making Competency Self-Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2203.11981.pdf)
>  We summarize our efforts to date in developing a framework for generating succinct human-understandable competency self-assessments in terms of machine self confidence, i.e. a robot's self-trust in its functional abilities to accomplish assigned tasks. Whereas early work explored machine self-confidence in ad hoc ways for niche applications, our Factorized Machine Self-Confidence framework introduces and combines several aspects of probabilistic meta reasoning for algorithmic planning and decision-making under uncertainty to arrive at a novel set of generalizable self-confidence factors, which can support competency assessment for a wide variety of problems.      
### 65.YouTube over Google's QUIC vs Internet Middleboxes: A Tug of War between Protocol Sustainability and Application QoE  [ :arrow_down: ](https://arxiv.org/pdf/2203.11977.pdf)
>  Middleboxes such as web proxies, firewalls, etc. are widely deployed in today's network infrastructure. As a result, most protocols need to adapt their behavior to co-exist. One of the most commonly used transport protocols, QUIC, adapts to such middleboxes by falling back to TCP, where they block it. In this paper, we argue that the blind fallback behavior of QUIC, i.e., not distinguishing between failures caused by middleboxes and that caused by network congestion, hugely impacts the performance of QUIC. For this, we focus on YouTube video streaming and conduct a measurement study by utilizing production endpoints of YouTube by enabling TCP and QUIC at a time. In total, we collect over 2600 streaming hours of data over various bandwidth patterns, from 5 different geographical locations and various video genres. To our surprise, we observe that the legacy setup (TCP) either outperforms or performs the same as the QUIC-enabled browser for more than 60% of cases. We see that our observation is consistent across individual QoE parameters, bandwidth patterns, locations, and videos. Next, we conduct a deep-dive analysis to discover the root cause behind such behavior. We find a good correlation (0.3-0.7) between fallback and QoE drop events, i.e., quality drop and re-buffering or stalling. We further perform Granger causal analysis and find that fallback Granger causes either quality drop or stalling for 70% of the QUIC-enabled sessions. We believe our study will help designers revisit the decision to enable fallback in QUIC and distinguish between the packet drops caused by middleboxes and network congestion.      
