# ArXiv eess --Mon, 21 Mar 2022
### 1.Symbol quantization in interstellar communications: methods and observations  [ :arrow_down: ](https://arxiv.org/pdf/2203.10065.pdf)
>  Interstellar communication transmitters, intended to be discovered and decoded to information bits, are expected to transmit signals that contain message symbols quantized in at least one of the degrees of freedom of the transmitted signal. A hypothesis is proposed that signal quantization, in the form of multiplicative values of one or more signal measurements, may be observable during the reception of hypothetical discoverable interstellar communication signals. In previous work, using single and multiple synchronized radio telescopes, candidate hypothetical interstellar communication signals comprising delta-t delta-f opposite circular polarized pulse pairs have been reported and analyzed (ref. <a class="link-https" data-arxiv-id="2105.03727" href="https://arxiv.org/abs/2105.03727">arXiv:2105.03727</a>, <a class="link-https" data-arxiv-id="2106.10168" href="https://arxiv.org/abs/2106.10168">arXiv:2106.10168</a>, <a class="link-https" data-arxiv-id="2202.12791" href="https://arxiv.org/abs/2202.12791">arXiv:2202.12791</a>). In the latter report, an apparent quantization of delta-f at multiples of 58.575 Hz was observed. In the current work, a machine process has been implemented to further examine anomalous delta-f and delta-t quantization, with results reported in this paper. As in some past work, a 26 foot diameter radio telescope with fixed azimuth and elevation pointing is used to enable a Right Ascension filter to measure signals associated with a celestial direction of interest, relative to other directions, over a 6.3 hour range of Right Ascension. The 5.25 plus or minus 0.15 hour Right Ascension, -7.6 degrees plus or minus 1 degree Declination celestial direction presents repetition and quantization anomalies, during an experiment lasting 157 days, with the first 143 days overlapping the previous experiment.      
### 2.Consonant-Vowel Transition Models Based on Deep Learning for Objective Evaluation of Articulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10054.pdf)
>  Spectro-temporal dynamics of consonant-vowel (CV) transition regions are considered to provide robust cues related to articulation. In this work, we propose an objective measure of precise articulation, dubbed the objective articulation measure (OAM), by analyzing the CV transitions segmented around vowel onsets. The OAM is derived based on the posteriors of a convolutional neural network pre-trained to classify between different consonants using CV regions as input. We demonstrate the OAM is correlated with perceptual measures in a variety of contexts including (a) adult dysarthric speech, (b) the speech of children with cleft lip/palate, and (c) a database of accented English speech from native Mandarin and Spanish speakers.      
### 3.Orientation Estimation using Wireless Device Radiation Patterns  [ :arrow_down: ](https://arxiv.org/pdf/2203.10052.pdf)
>  Wireless devices inherently have a non-uniform distribution of energy from their antenna or antennas. The shape that this forms is commonly called a radiation pattern or antenna pattern. We demonstrate that orientation can be estimated without the cooperation of the target device despite only having a small number of RSS measurements per packet. We do this by applying bounds to the amount of rotation in the time interval between packets. Using simulations, we show that this method can achieve a mean orientation error as low as 7.6Â°. We then perform a security analysis to demonstrate the method's resistance to spoofing. This paper focuses on consumer wireless devices where patterns are not deliberately highly directional and scenarios that cannot rely on contrived movement patterns of the entities involved, which is unrealistic or impractical in many settings. Our work concentrates on existing wireless systems and infrastructure common in domestic, office, and commercial.      
### 4.High-Density Coding Scheme for SWIPT Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.10047.pdf)
>  In this study, a novel coding scheme called highdensity coding based on high-density codebooks using a genetic local search algorithm is proposed. The high-density codebook maximizes the energy transfer capability by maximizing the ratio of 1 in the codebook while satisfying the conditions of a codeword with length n, a codebook with 2k codewords, and a minimum Hamming distance of the codebook of d. Furthermore, the proposed high-density codebook provides a trade-off between the throughput and harvested energy with respect to n, k, and d. The block error rate performances of the designed highdensity codebooks are derived theoretically and compared with the simulation results. The simulation results indicate that as d and k decrease, the throughput decreases by a maximum of 10% and 40%, whereas the harvested energy per time increases by a maximum of 40% and 100%, respectively. When n increases, the throughput decreases by a maximum of 30%, while the harvested energy per time increases by a maximum of 110%. With the proposed high-density coding scheme, the throughput and harvested energy at the user can be controlled adaptively according to the system requirements.      
### 5.Compositional Synthesis of Signal Temporal Logic Tasks via Assume-Guarantee Contracts  [ :arrow_down: ](https://arxiv.org/pdf/2203.10041.pdf)
>  In this paper, we focus on the problem of compositional synthesis of controllers enforcing signal temporal logic (STL) tasks over a class of continuous-time nonlinear interconnected systems. By leveraging the idea of funnel-based control, we show that a fragment of STL specifications can be formulated as assume-guarantee contracts. A new concept of contract satisfaction is then defined to establish our compositionality result, which allows us to guarantee the satisfaction of a global contract by the interconnected system when all subsystems satisfy their local contracts. Based on this compositional framework, we then design closed-form continuous-time feedback controllers to enforce local contracts over subsystems in a decentralized manner. Finally, we demonstrate the effectiveness of our results on two numerical examples.      
### 6.A constrained Shannon-Fano entropy coder for image storage in synthetic DNA  [ :arrow_down: ](https://arxiv.org/pdf/2203.09988.pdf)
>  The exponentially increasing demand for data storage has been facing more and more challenges during the past years. The energy costs that it represents are also increasing, and the availability of the storage hardware is not able to follow the storage demand's trend. The short lifespan of conventional storage media -- 10 to 20 years - forces the duplication of the hardware and worsens the situation. The majority of this storage demand concerns "cold" data, data very rarely accessed but that has to be kept for long periods of time. The coding abilities of synthetic DNA, and its long durability (several hundred years), make it a serious candidate as an alternative storage media for "cold" data. In this paper, we propose a variable-length coding algorithm adapted to DNA data storage with improved performance. The proposed algorithm is based on a modified Shannon-Fano code that respects some biochemichal constraints imposed by the synthesis chemistry. We have inserted this code in a JPEG compression algorithm adapted to DNA image storage and we highlighted an improvement of the compression ratio ranging from 0.5 up to 2 bits per nucleotide compared to the state-of-the-art solution, without affecting the reconstruction quality.      
### 7.SynthStrip: Skull-Stripping for Any Brain Image  [ :arrow_down: ](https://arxiv.org/pdf/2203.09974.pdf)
>  The removal of non-brain signal from magnetic resonance imaging (MRI) data, known as skull-stripping, is an integral component of many neuroimage analysis streams. Despite their abundance, popular classical skull-stripping methods are usually tailored to images with specific acquisition properties, namely near-isotropic resolution and T1-weighted (T1w) MRI contrast, which are prevalent in research settings. As a result, existing tools tend to adapt poorly to other image types, such as stacks of thick slices acquired with fast spin-echo (FSE) MRI that are common in the clinic. While learning-based approaches for brain extraction have gained traction in recent years, these methods face a similar burden, as they are only effective for image types seen during the training procedure. To achieve robust skull-stripping across a landscape of protocols, we introduce SynthStrip, a rapid, learning-based brain-extraction tool. By leveraging anatomical segmentations to generate an entirely synthetic training dataset with anatomies, intensity distributions, and artifacts that far exceed the realistic range of medical images, SynthStrip learns to successfully generalize to a variety of real acquired brain images, removing the need for training data with target contrasts. We demonstrate the efficacy of SynthStrip for a diverse set of image acquisitions and resolutions across subject populations, ranging from newborn to adult. We show substantial improvements in accuracy over popular skull-stripping baselines - all with a single trained model. Our method and labeled evaluation data are available at <a class="link-external link-https" href="https://w3id.org/synthstrip" rel="external noopener nofollow">this https URL</a>.      
### 8.Learning to Optimize Resource Assignment for Task Offloading in Mobile Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2203.09954.pdf)
>  In this paper, we consider a multiuser mobile edge computing (MEC) system, where a mixed-integer offloading strategy is used to assist the resource assignment for task offloading. Although the conventional branch and bound (BnB) approach can be applied to solve this problem, a huge burden of computational complexity arises which limits the application of BnB. To address this issue, we propose an intelligent BnB (IBnB) approach which applies deep learning (DL) to learn the pruning strategy of the BnB approach. By using this learning scheme, the structure of the BnB approach ensures near-optimal performance and meanwhile DL-based pruning strategy significantly reduces the complexity. Numerical results verify that the proposed IBnB approach achieves optimal performance with complexity reduced by over 80%.      
### 9.Efficient FFT Computation in IFDMA Transceivers  [ :arrow_down: ](https://arxiv.org/pdf/2203.09932.pdf)
>  Interleaved Frequency Division Multiple Access (IFDMA) has the salient advantage of lower Peak-to-Average Power Ratio (PAPR) than its competitors like Orthogonal FDMA (OFDMA). A recent research effort put forth a new IFDMA transceiver design significantly less complex than conventional IFDMA transceivers. The new IFDMA transceiver design reduces the complexity by exploiting a certain correspondence between the IFDMA signal processing and the Cooley-Tukey IFFT/FFT algorithmic structure so that IFDMA streams can be inserted/extracted at different stages of an IFFT/FFT module according to the sizes of the streams. Although the prior work has laid down the theoretical foundation for the new IFDMA transceiver's structure, the practical realization of the transceiver on specific hardware with resource constraints has not been carefully investigated. This paper is an attempt to fill the gap. Specifically, this paper puts forth a heuristic algorithm called multi-priority scheduling (MPS) to schedule the execution of the butterfly computations in the IFDMA transceiver with the constraint of a limited number of hardware processors. The resulting FFT computation, referred to as MPS-FFT, has a much lower computation time than conventional FFT computation when applied to the IFDMA signal processing. Importantly, we derive a lower bound for the optimal IFDMA FFT computation time to benchmark MPS-FFT. Our experimental results indicate that when the number of hardware processors is a power of two: 1) MPS-FFT has near-optimal computation time; 2) MPS-FFT incurs less than 44.13\% of the computation time of the conventional pipelined FFT.      
### 10.A Statistical Framework to Investigate the Optimality of Neural Networks for Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2203.09920.pdf)
>  We present a statistical framework to benchmark the performance of neural-network-based reconstruction algorithms for linear inverse problems. The underlying signals in our framework are realizations of sparse stochastic processes and are ideally matched to variational sparsity-promoting techniques, some of which can be reinterpreted as their maximum a posteriori (MAP) estimators. We derive Gibbs sampling schemes to compute the minimum mean square error (MMSE) estimators for processes with Laplace, Student's t and Bernoulli-Laplace innovations. These allow our framework to provide quantitative measures of the degree of optimality (in the mean-square-error sense) for any given reconstruction method. We showcase the use of our framework by benchmarking the performance of CNN architectures for deconvolution and Fourier sampling problems. Our experimental results suggest that while these architectures achieve near-optimal results in many settings, their performance deteriorates severely for signals associated with heavy-tailed distributions.      
### 11.Collaborative Driving: Learning- Aided Joint Topology Formulation and Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2203.09915.pdf)
>  Currently, autonomous vehicles are able to drive more naturally based on the driving policies learned from millions of driving miles in real environments. However, to further improve the automation level of vehicles is a challenging task, especially in the case of multi-vehicle cooperation. In recent heated discussions of 6G, millimeter-wave (mmWave) and terahertz (THz) bands are deemed to play important roles in new radio communication architectures and algorithms. To enable reliable autonomous driving in 6G, in this paper, we envision collaborative autonomous driving, a new framework that jointly controls driving topology and formulate vehicular networks in the mmWave/THz bands. As a swarm intelligence system, the collaborative driving scheme goes beyond existing autonomous driving patterns based on single-vehicle intelligence in terms of safety and efficiency. With efficient data sharing, the proposed framework is able to achieve cooperative sensing and load balancing so that improve sensing efficiency with saved computational resources. To deal with the new challenges in the collaborative driving framework, we further illustrate two promising approaches for mmWave/THz-based vehicle-to-vehicle (V2V) communications. Finally, we discuss several potential open research problems for the proposed collaborative driving scheme.      
### 12.Modeling R$^3$ Needle Steering in Uppaal  [ :arrow_down: ](https://arxiv.org/pdf/2203.09884.pdf)
>  Medical cyber-physical systems are safety-critical, and as such, require ongoing verification of their correct behavior, as system failure during run time may cause severe (or even fatal) personal damage. However, creating a verifiable model often conflicts with other application requirements, most notably regarding data precision and model accuracy, as efficient model checking promotes discrete data (over continuous) and abstract models to reduce the state space. In this paper, we approach the task of medical needle steering in soft tissue around potential obstacles. We design a verifiable model of needle motion (implemented in Uppaal Stratego) and a framework embedding the model for online needle steering. We mitigate the conflict by imposing boundedness on both the data types, reducing from R^3 to Z^3 when needed, and the motion and environment models, reducing the set of allowed local actions and global paths. In experiments, we successfully apply the static model alone, as well as the dynamic framework in scenarios with varying environment complexity and both a virtual and real needle setting, where up to 100% of targets were reached depending on the scenario and needle.      
### 13.Finite-sample analysis of identification of switched linear systems with arbitrary or restricted switching  [ :arrow_down: ](https://arxiv.org/pdf/2203.09862.pdf)
>  This work aims to derive a data-independent finite-sample error bound for the least-squares (LS) estimation error of switched linear systems when the state and the switching signal are measured. While the existing finite-sample bounds for linear system identification extend to the problem under consideration, the Gramian of the switched system, an essential term in the error bound, depends on the measured switching signal. Therefore, data-independent bounds on the spectrum of the Gramian are developed for globally asymptotically and marginally stable switched systems when the switching is arbitrary or subject to an average dwell time constraint. Combining the bounds on the spectrum of the Gramian and the preliminary error bound extended from linear system identification leads to the error bound for the LS estimate of the switched system.      
### 14.Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification  [ :arrow_down: ](https://arxiv.org/pdf/2203.09860.pdf)
>  Deep learning models were frequently reported to learn from shortcuts like dataset biases. As deep learning is playing an increasingly important role in the modern healthcare system, it is of great need to combat shortcut learning in medical data as well as develop unbiased and trustworthy models. In this paper, we study the problem of developing debiased chest X-ray diagnosis models from the biased training data without knowing exactly the bias labels. We start with the observations that the imbalance of bias distribution is one of the key reasons causing shortcut learning, and the dataset biases are preferred by the model if they were easier to be learned than the intended features. Based on these observations, we propose a novel algorithm, pseudo bias-balanced learning, which first captures and predicts per-sample bias labels via generalized cross entropy loss and then trains a debiased model using pseudo bias labels and bias-balanced softmax function. To our best knowledge, we are pioneered in tackling dataset biases in medical images without explicit labeling on the bias attributes. We constructed several chest X-ray datasets with various dataset bias situations and demonstrated with extensive experiments that our proposed method achieved consistent improvements over other state-of-the-art approaches.      
### 15.Sensor fusion in ptychography  [ :arrow_down: ](https://arxiv.org/pdf/2203.09794.pdf)
>  Ptychography is a lensless, computational imaging method that utilises diffraction patterns to determine the amplitude and phase of an object. In transmission ptychography, the diffraction patterns are recorded by a detector positioned along the optical axis downstream of the object. The light scattered at the highest diffraction angle carries information about the finest structures of the object. We present a setup to simultaneously capture a signal near the optical axis and a signal scattered at high diffraction angles. Moreover, we present an algorithm based on a shifted angular spectrum method and automatic differentiation that utilises this recorded signal. By jointly reconstructing the object from the resulting low and high diffraction angle images, the resolution of the reconstructed image is improved remarkably. The effective numerical aperture of the compound sensor is determined by the maximum diffraction angle captured by the off axis sensor.      
### 16.Solving Infinite-Dimensional Harmonic Lyapunov and Riccati equations  [ :arrow_down: ](https://arxiv.org/pdf/2203.09774.pdf)
>  In this paper, we address the problem of solving infinite-dimensional harmonic algebraic Lyapunov and Riccati equations up to an arbitrary small error. This question is of major practical importance for analysis and stabilization of periodic systems including tracking of periodic trajectories. We first give a closed form of a Floquet factorization in the general setting of L 2 matrix functions and study the spectral properties of infinite-dimensional harmonic matrices and their truncated version. This spectral study allows us to propose a generic and numerically efficient algorithm to solve infinite-dimensional harmonic algebraic Lyapunov equations up to an arbitrary small error. We combine this algorithm with the Kleinman algorithm to solve infinite-dimensional harmonic Riccati equations and we apply the proposed results to the design of a harmonic LQ control with periodic trajectory tracking.      
### 17.Soft Smoothness for Audio Inpainting Using a Latent Matrix Model in Delay-embedded Space  [ :arrow_down: ](https://arxiv.org/pdf/2203.09746.pdf)
>  Here, we propose a new reconstruction method of smooth time-series signals. A key concept of this study is not considering the model in signal space, but in delay-embedded space. In other words, we indirectly represent a time-series signal as an output of inverse delay-embedding of a matrix, and the matrix is constrained. Based on the model under inverse delay-embedding, we propose to constrain the matrix to be rank-1 with smooth factor vectors. The proposed model is closely related to the convolutional model, and quadratic variation (QV) regularization. Especially, the proposed method can be characterized as a generalization of QV regularization. In addition, we show that the proposed method provides the softer smoothness than QV regularization. Experiments of audio inpainting and declipping are conducted to show its advantages in comparison with several existing interpolation methods and sparse modeling.      
### 18.Rethinking the optimization process for self-supervised model-driven MRI reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2203.09724.pdf)
>  Recovering high-quality images from undersampled measurements is critical for accelerated MRI reconstruction. Recently, various supervised deep learning-based MRI reconstruction methods have been developed. Despite the achieved promising performances, these methods require fully sampled reference data, the acquisition of which is resource-intensive and time-consuming. Self-supervised learning has emerged as a promising solution to alleviate the reliance on fully sampled datasets. However, existing self-supervised methods suffer from reconstruction errors due to the insufficient constraint enforced on the non-sampled data points and the error accumulation happened alongside the iterative image reconstruction process for model-driven deep learning reconstrutions. To address these challenges, we propose K2Calibrate, a K-space adaptation strategy for self-supervised model-driven MR reconstruction optimization. By iteratively calibrating the learned measurements, K2Calibrate can reduce the network's reconstruction deterioration caused by statistically dependent noise. Extensive experiments have been conducted on the open-source dataset FastMRI, and K2Calibrate achieves better results than five state-of-the-art methods. The proposed K2Calibrate is plug-and-play and can be easily integrated with different model-driven deep learning reconstruction methods.      
### 19.Estimation of Consistent Time Delays in Subsample via Auxiliary-Function-Based Iterative Updates  [ :arrow_down: ](https://arxiv.org/pdf/2203.09723.pdf)
>  In this paper, we propose a new algorithm for the estimation of multiple time delays (TDs). Since a TD is a fundamental spatial cue for sensor array signal processing techniques, many methods for estimating it have been studied. Most of them, including generalized cross correlation (CC)-based methods, focus on how to estimate a TD between two sensors. These methods can then be easily adapted for multiple TDs by applying them to every pair of a reference sensor and another one. However, these pairwise methods can use only the partial information obtained by the selected sensors, resulting in inconsistent TD estimates and limited estimation accuracy. In contrast, we propose joint optimization of entire TD parameters, where spatial information obtained from all sensors is taken into account. We also introduce a consistent constraint regarding TD parameters to the observation model. We then consider a multidimensional CC (MCC) as the objective function, which is derived on the basis of maximum likelihood estimation. To maximize the MCC, which is a nonconvex function, we derive the auxiliary function for the MCC and design efficient update rules. We additionally estimate the amplitudes of the transfer functions for supporting the TD estimation, where we maximize the Rayleigh quotient under the non-negative constraint. We experimentally analyze essential features of the proposed method and evaluate its effectiveness in TD estimation. Code will be available at <a class="link-external link-https" href="https://github.com/onolab-tmu/AuxTDE" rel="external noopener nofollow">this https URL</a>.      
### 20.Federated Learning for Privacy Preservation in Smart Healthcare Systems: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2203.09702.pdf)
>  Recent advances in electronic devices and communication infrastructure have revolutionized the traditional healthcare system into a smart healthcare system by using IoMT devices. However, due to the centralized training approach of artificial intelligence (AI), the use of mobile and wearable IoMT devices raises privacy concerns with respect to the information that has been communicated between hospitals and end users. The information conveyed by the IoMT devices is highly confidential and can be exposed to adversaries. In this regard, federated learning (FL), a distributive AI paradigm has opened up new opportunities for privacy-preservation in IoMT without accessing the confidential data of the participants. Further, FL provides privacy to end users as only gradients are shared during training. For these specific properties of FL, in this paper we present privacy related issues in IoMT. Afterwards, we present the role of FL in IoMT networks for privacy preservation and introduce some advanced FL architectures incorporating deep reinforcement learning (DRL), digital twin, and generative adversarial networks (GANs) for detecting privacy threats. Subsequently, we present some practical opportunities of FL in smart healthcare systems. At the end, we conclude this survey by providing open research challenges for FL that can be used in future smart healthcare systems      
### 21.A workflow for segmenting soil and plant X-ray CT images with deep learning in Googles Colaboratory  [ :arrow_down: ](https://arxiv.org/pdf/2203.09674.pdf)
>  X-ray micro-computed tomography (X-ray microCT) has enabled the characterization of the properties and processes that take place in plants and soils at the micron scale. Despite the widespread use of this advanced technique, major limitations in both hardware and software limit the speed and accuracy of image processing and data analysis. Recent advances in machine learning, specifically the application of convolutional neural networks to image analysis, have enabled rapid and accurate segmentation of image data. Yet, challenges remain in applying convolutional neural networks to the analysis of environmentally and agriculturally relevant images. Specifically, there is a disconnect between the computer scientists and engineers, who build these AI/ML tools, and the potential end users in agricultural research, who may be unsure of how to apply these tools in their work. Additionally, the computing resources required for training and applying deep learning models are unique, more common to computer gaming systems or graphics design work, than to traditional computational systems. To navigate these challenges, we developed a modular workflow for applying convolutional neural networks to X-ray microCT images, using low-cost resources in Googles Colaboratory web application. Here we present the results of the workflow, illustrating how parameters can be optimized to achieve best results using example scans from walnut leaves, almond flower buds, and a soil aggregate. We expect that this framework will accelerate the adoption and use of emerging deep learning techniques within the plant and soil sciences.      
### 22.Meta Reinforcement Learning for Adaptive Control: An Offline Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.09661.pdf)
>  Meta-learning is a branch of machine learning which trains neural network models to synthesize a wide variety of data in order to rapidly solve new problems. In process control, many systems have similar and well-understood dynamics, which suggests it is feasible to create a generalizable controller through meta-learning. In this work, we formulate a meta reinforcement learning (meta-RL) control strategy that takes advantage of known, offline information for training, such as the system gain or time constant, yet efficiently controls novel systems in a completely model-free fashion. Our meta-RL agent has a recurrent structure that accumulates "context" for its current dynamics through a hidden state variable. This end-to-end architecture enables the agent to automatically adapt to changes in the process dynamics. Moreover, the same agent can be deployed on systems with previously unseen nonlinearities and timescales. In tests reported here, the meta-RL agent was trained entirely offline, yet produced excellent results in novel settings. A key design element is the ability to leverage model-based information offline during training, while maintaining a model-free policy structure for interacting with novel environments. To illustrate the approach, we take the actions proposed by the meta-RL agent to be changes to gains of a proportional-integral controller, resulting in a generalized, adaptive, closed-loop tuning strategy. Meta-learning is a promising approach for constructing sample-efficient intelligent controllers.      
### 23.Learning Nonlocal Sparse and Low-Rank Models for Image Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2203.09656.pdf)
>  The compressive sensing (CS) scheme exploits much fewer measurements than suggested by the Nyquist-Shannon sampling theorem to accurately reconstruct images, which has attracted considerable attention in the computational imaging community. While classic image CS schemes employed sparsity using analytical transforms or bases, the learning-based approaches have become increasingly popular in recent years. Such methods can effectively model the structures of image patches by optimizing their sparse representations or learning deep neural networks, while preserving the known or modeled sensing process. Beyond exploiting local image properties, advanced CS schemes adopt nonlocal image modeling, by extracting similar or highly correlated patches at different locations of an image to form a group to process jointly. More recent learning-based CS schemes apply nonlocal structured sparsity prior using group sparse representation (GSR) and/or low-rank (LR) modeling, which have demonstrated promising performance in various computational imaging and image processing applications. This article reviews some recent works in image CS tasks with a focus on the advanced GSR and LR based methods. Furthermore, we present a unified framework for incorporating various GSR and LR models and discuss the relationship between GSR and LR models. Finally, we discuss the open problems and future directions in the field.      
### 24.A Learning Framework for Bandwidth-Efficient Distributed Inference in Wireless IoT  [ :arrow_down: ](https://arxiv.org/pdf/2203.09631.pdf)
>  In wireless Internet of things (IoT), the sensors usually have limited bandwidth and power resources. Therefore, in a distributed setup, each sensor should compress and quantize the sensed observations before transmitting them to a fusion center (FC) where a global decision is inferred. Most of the existing compression techniques and entropy quantizers consider only the reconstruction fidelity as a metric, which means they decouple the compression from the sensing goal. In this work, we argue that data compression mechanisms and entropy quantizers should be co-designed with the sensing goal, specifically for machine-consumed data. To this end, we propose a novel deep learning-based framework for compressing and quantizing the observations of correlated sensors. Instead of maximizing the reconstruction fidelity, our objective is to compress the sensor observations in a way that maximizes the accuracy of the inferred decision (i.e., sensing goal) at the FC. Unlike prior work, we do not impose any assumptions about the observations distribution which emphasizes the wide applicability of our framework. We also propose a novel loss function that keeps the model focused on learning complementary features at each sensor. The results show the superior performance of our framework compared to other benchmark models.      
### 25.Transmit Precoder Design Approaches for Dual-Function Radar-Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.09571.pdf)
>  As radio-frequency (RF) antenna, component and processing capabilities increase, the ability to perform multiple RF system functions from a common aperture is being realized. Conducting both radar and communications from the same system is potentially useful in vehicular, health monitoring, and surveillance settings. This paper considers multiple-input-multiple-output (MIMO) dual-function radar-communication (DFRC) systems in which the radar and communication modes use distinct baseband waveforms. A transmit precoder provides spatial multiplexing and power allocation among the radar and communication modes. Multiple precoder design approaches are introduced for a radar detection mode in which a total search volume is divided into dwells to be searched sequentially. The approaches are designed to enforce a reliance on radar waveforms for sensing purposes, yielding improved approximation of desired ambiguity functions over prior methods found in the literature. The methods are also shown via simulation to enable design flexibility, allowing for prioritization of either subsystem and specification of a desired level of radar or communication performance.      
### 26.Distributed Estimation in Large Scale Wireless Sensor Networks via a Two Step Group-based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.09567.pdf)
>  We consider the problem of collaborative distributed estimation in a large scale sensor network with statistically dependent sensor observations. In collaborative setup, the aim is to maximize the overall estimation performance by modeling the underlying statistical dependence and efficiently utilizing the deployed sensors. To achieve greater sensor transmission and estimation efficiency, we propose a two step group-based collaborative distributed estimation scheme, where in the first step, sensors form dependence driven groups such that sensors in the same group are highly dependent, while sensors from different groups are independent, and perform a copula-based maximum a posteriori probability (MAP) estimation via intragroup collaboration. In the second step, the estimates generated in the first step are shared via inter-group collaboration to reach an average consensus. A merge based K-medoid dependence driven grouping algorithm is proposed. Moreover, we further propose a group-based sensor selection scheme using mutual information prior to the estimation. The aim is to select sensors with maximum relevance and minimum redundancy regarding the parameter of interest under certain pre-specified energy constraint. Also, the proposed group-based sensor selection scheme is shown to be equivalent to the global/non-group based selection scheme with high probability, but computationally more efficient. Numerical experiments are conducted to demonstrate the effectiveness of our approach.      
### 27.Privacy-Preserving Speech Representation Learning using Vector Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2203.09518.pdf)
>  With the popularity of virtual assistants (e.g., Siri, Alexa), the use of speech recognition is now becoming more and more widespread.However, speech signals contain a lot of sensitive information, such as the speaker's identity, which raises privacy concerns.The presented experiments show that the representations extracted by the deep layers of speech recognition networks contain speaker information.This paper aims to produce an anonymous representation while preserving speech recognition <a class="link-external link-http" href="http://performance.To" rel="external noopener nofollow">this http URL</a> this end, we propose to use vector quantization to constrain the representation space and induce the network to suppress the speaker identity.The choice of the quantization dictionary size allows to configure the trade-off between utility (speech recognition) and privacy (speaker identity concealment).      
### 28.Bayesian Inversion for Nonlinear Imaging Models using Deep Generative Priors  [ :arrow_down: ](https://arxiv.org/pdf/2203.10078.pdf)
>  Most modern imaging systems involve a computational reconstruction pipeline to infer the image of interest from acquired measurements. The Bayesian reconstruction framework relies on the characterization of the posterior distribution, which depends on a model of the imaging system and prior knowledge on the image, for solving such inverse problems. Here, the choice of the prior distribution is critical for obtaining high-quality estimates. In this work, we use deep generative models to represent the prior distribution. We develop a posterior sampling scheme for the class of nonlinear inverse problems where the forward model has a neural-network-like structure. This class includes most existing imaging modalities. We introduce the notion of augmented generative models in order to suitably handle quantitative image recovery. We illustrate the advantages of our framework by applying it to two nonlinear imaging modalities-phase retrieval and optical diffraction tomography.      
### 29.RoSS: Utilizing Robotic Rotation for Audio Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10072.pdf)
>  This paper considers the problem of audio source separation where the goal is to isolate a target audio signal (say Alice's speech) from a mixture of multiple interfering signals (e.g., when many people are talking). This problem has gained renewed interest mainly due to the significant growth in voice controlled devices, including robots in homes, offices, and other public facilities. Although a rich body of work exists on the core topic of source separation, we find that robotic motion of the microphone -- say the robot's head -- is a complementary opportunity to past approaches. Briefly, we show that rotating the microphone array to the correct orientation can produce desired aliasing between two interferers, causing the two interferers to pose as one. In other words, a mixture of K signals becomes a mixture of (K-1), a mathematically concrete gain. We show that the gain translates well to practice provided two mobility-related challenges can be mitigated. This paper is focused on mitigating these challenges and demonstrating the end-to-end performance on a fully functional prototype. We believe that our Rotational Source Separation module RoSS could be plugged into actual robot heads, or into other devices (like Amazon Show) that are also capable of rotation.      
### 30.Sampling Complexity of Path Integral Methods for Trajectory Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.10067.pdf)
>  The use of random sampling in decision-making and control has become popular with the ease of access to graphic processing units that can generate and calculate multiple random trajectories for real-time robotic applications. In contrast to sequential optimization, the sampling-based method can take advantage of parallel computing to maintain constant control loop frequencies. Inspired by its wide applicability in robotic applications, we calculate a sampling complexity result applicable to general nonlinear systems considered in the path integral method, which is a sampling-based method. The result determines the required number of samples to satisfy the given error bounds of the estimated control signal from the optimal value with the predefined risk probability. The sampling complexity result shows that the variance of the estimated control value is upper-bounded in terms of the expectation of the cost. Then we apply the result to a linear time-varying dynamical system with quadratic cost and an indicator function cost to avoid constraint sets.      
### 31.PYROBOCOP: Python-based Robotic Control &amp; Optimization Package for Manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10013.pdf)
>  PYROBOCOP is a Python-based package for control, optimization and estimation of robotic systems described by nonlinear Differential Algebraic Equations (DAEs). In particular, the package can handle systems with contacts that are described by complementarity constraints and provides a general framework for specifying obstacle avoidance constraints. The package performs direct transcription of the DAEs into a set of nonlinear equations by performing orthogonal collocation on finite elements. PYROBOCOP provides automatic reformulation of the complementarity constraints that are tractable to NLP solvers to perform optimization of robotic systems. The package is interfaced with ADOL-C[1] for obtaining sparse derivatives by automatic differentiation and IPOPT[2] for performing optimization. We evaluate PYROBOCOP on several manipulation problems for control and estimation.      
### 32.Picosecond Hyperspectral Fringe Pattern Projection for 3D Surface Measurement  [ :arrow_down: ](https://arxiv.org/pdf/2203.10008.pdf)
>  Active stereovision systems for the 3D measurement of surfaces rely on the sequential projection of different fringe patterns onto the scene to robustly and accurately generate 3D surface data. This limits the temporal resolution to the time by which a sufficiently high number of patterns can be projected and recorded. By encoding patterns spectrally and recording them with a hyperspectral imager, it is possible to record several patterns in a single image, limiting the temporal resolution to only the duration of the illumination. A picosecond 3D surface measurement was demonstrated using a high pulse energy femtosecond Ti:Sa laser, spectrally broadened in a hollow core fiber, and two hyperspectral cameras recording the patterns generated by diffraction at an Echelle grating.      
### 33.Image Storage on Synthetic DNA Using Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2203.09981.pdf)
>  Over the past years, the ever-growing trend on data storage demand, more specifically for "cold" data (rarely accessed data), has motivated research for alternative systems of data storage. Because of its biochemical characteristics, synthetic DNA molecules are now considered as serious candidates for this new kind of storage. This paper presents some results on lossy image compression methods based on convolutional autoencoders adapted to DNA data storage. <br>The model architectures presented here have been designed to efficiently compress images, encode them into a quaternary code, and finally store them into synthetic DNA molecules. This work also aims at making the compression models better fit the problematics that we encounter when storing data into DNA, namely the fact that the DNA writing, storing and reading methods are error prone processes. The main take away of this kind of compressive autoencoder is our quantization and the robustness to substitution errors thanks to the noise model that we use during training.      
### 34.Personalized filled-pause generation with group-wise prediction models  [ :arrow_down: ](https://arxiv.org/pdf/2203.09961.pdf)
>  In this paper, we propose a method to generate personalized filled pauses (FPs) with group-wise prediction models. Compared with fluent text generation, disfluent text generation has not been widely explored. To generate more human-like texts, we addressed disfluent text generation. The usage of disfluency, such as FPs, rephrases, and word fragments, differs from speaker to speaker, and thus, the generation of personalized FPs is required. However, it is difficult to predict them because of the sparsity of position and the frequency difference between more and less frequently used FPs. Moreover, it is sometimes difficult to adapt FP prediction models to each speaker because of the large variation of the tendency within each speaker. To address these issues, we propose a method to build group-dependent prediction models by grouping speakers on the basis of their tendency to use FPs. This method does not require a large amount of data and time to train each speaker model. We further introduce a loss function and a word embedding model suitable for FP prediction. Our experimental results demonstrate that group-dependent models can predict FPs with higher scores than a non-personalized one and the introduced loss function and word embedding model improve the prediction performance.      
### 35.Neural Enhanced Belief Propagation for Data Assocation in Multiobject Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2203.09948.pdf)
>  Situation-aware technologies enabled by multiobject tracking (MOT) methods will create new services and applications in fields such as autonomous navigation and applied ocean sciences. Belief propagation (BP) is a state-of-the-art method for Bayesian MOT but fully relies on a statistical model and preprocessed sensor measurements. In this paper, we establish a hybrid method for model-based and data-driven MOT. The proposed neural enhanced belief propagation (NEBP) approach complements BP by information learned from raw sensor data with the goal to improve data association and to reject false alarm measurements. We evaluate the performance of our NEBP approach for MOT on the nuScenes autonomous driving dataset and demonstrate that it can outperform state-of-the-art reference methods.      
### 36.A Lightweight Instrument-Agnostic Model for Polyphonic Note Transcription and Multipitch Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2203.09893.pdf)
>  Automatic Music Transcription (AMT) has been recognized as a key enabling technology with a wide range of applications. Given the task's complexity, best results have typically been reported for systems focusing on specific settings, e.g. instrument-specific systems tend to yield improved results over instrument-agnostic methods. Similarly, higher accuracy can be obtained when only estimating frame-wise $f_0$ values and neglecting the harder note event detection. Despite their high accuracy, such specialized systems often cannot be deployed in the real-world. Storage and network constraints prohibit the use of multiple specialized models, while memory and run-time constraints limit their complexity. In this paper, we propose a lightweight neural network for musical instrument transcription, which supports polyphonic outputs and generalizes to a wide variety of instruments (including vocals). Our model is trained to jointly predict frame-wise onsets, multipitch and note activations, and we experimentally show that this multi-output structure improves the resulting frame-level note accuracy. Despite its simplicity, benchmark results show our system's note estimation to be substantially better than a comparable baseline, and its frame-level accuracy to be only marginally below those of specialized state-of-the-art AMT systems. With this work we hope to encourage the community to further investigate low-resource, instrument-agnostic AMT systems.      
### 37.Identification of Hypokinetic Dysarthria Using Acoustic Analysis of Poem Recitation  [ :arrow_down: ](https://arxiv.org/pdf/2203.09880.pdf)
>  Up to 90 % of patients with Parkinson's disease (PD) suffer from hypokinetic dysarthria (HD). In this work, we analysed the power of conventional speech features quantifying imprecise articulation, dysprosody, speech dysfluency and speech quality deterioration extracted from a specialized poem recitation task to discriminate dysarthric and healthy speech. For this purpose, 152 speakers (53 healthy speakers, 99 PD patients) were examined. Only mildly strong correlation between speech features and clinical status of the speakers was observed. In the case of univariate classification analysis, sensitivity of 62.63% (imprecise articulation), 61.62% (dysprosody), 71.72% (speech dysfluency) and 59.60% (speech quality deterioration) was achieved. Multivariate classification analysis improved the classification performance. Sensitivity of 83.42% using only two features describing imprecise articulation and speech quality deterioration in HD was achieved. We showed the promising potential of the selected speech features and especially the use of poem recitation task to quantify and identify HD in PD.      
### 38.Automatic analysis of Categorical Verbal Fluency for Mild Cognitive Impartment detection: a non-linear language independent approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.09878.pdf)
>  Alzheimer's disease (AD) is one the main causes of dementia in the world and the patients develop severe disability and sometime full dependence. In previous stages Mild Cognitive Impairment (MCI) produces cognitive loss but not severe enough to interfere with daily life. This work, on selection of biomarkers from speech for the detection of AD, is part of a wide-ranging cross study for the diagnosis of Alzheimer. Specifically in this work a task for detection of MCI has been used. The task analyzes Categorical Verbal Fluency. The automatic classification is carried out by SVM over classical linear features, Castiglioni fractal dimension and Permutation Entropy. Finally the most relevant features are selected by ANOVA test. The promising results are over 50% for MCI      
### 39.Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.09849.pdf)
>  Recent works have revealed the vulnerability of automatic speech recognition (ASR) models to adversarial examples (AEs), i.e., small perturbations that cause an error in the transcription of the audio signal. Studying audio adversarial attacks is therefore the first step towards robust ASR. Despite the significant progress made in attacking audio examples, the black-box attack remains challenging because only the hard-label information of transcriptions is provided. Due to this limited information, existing black-box methods often require an excessive number of queries to attack a single audio example. In this paper, we introduce NP-Attack, a neural predictor-based method, which progressively evolves the search towards a small adversarial perturbation. Given a perturbation direction, our neural predictor directly estimates the smallest perturbation that causes a mistranscription. In particular, it enables NP-Attack to accurately learn promising perturbation directions via gradient-based optimization. Experimental results show that NP-Attack achieves competitive results with other state-of-the-art black-box adversarial attacks while requiring a significantly smaller number of queries. The code of NP-Attack is available online.      
### 40.Towards Representative Subset Selection for Self-Supervised Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.09829.pdf)
>  Self-supervised speech recognition models require considerable labeled training data for learning high-fidelity representations for Automatic Speech Recognition (ASR), which hinders their application to low-resource languages. We consider the task of identifying an optimal subset of training data to fine-tune self-supervised speech models for ASR. We make a surprising observation that active learning strategies for sampling harder-to-learn examples do not perform better than random subset selection for fine-tuning self-supervised ASR. We then present the COWERAGE algorithm for better subset selection in self-supervised ASR which is based on our finding that ensuring the coverage of examples based on training WER in the early training epochs leads to better generalization performance. Extensive experiments on the wav2vec 2.0 model and TIMIT dataset show the effectiveness of COWERAGE, with up to 27% absolute WER improvement over active learning methods. We also report the connection between training WER and the phonemic cover and demonstrate that our algorithm ensures inclusion of phonemically diverse examples.      
### 41.AdaVocoder: Adaptive Vocoder for Custom Voice  [ :arrow_down: ](https://arxiv.org/pdf/2203.09825.pdf)
>  Custom voice is to construct a personal speech synthesis system by adapting the source speech synthesis model to the target model through the target few recordings. The solution to constructing a custom voice is to combine an adaptive acoustic model with a robust vocoder. However, training a robust vocoder usually requires a multi-speaker dataset, which should include various age groups and various timbres, so that the trained vocoder can be used for unseen speakers. Collecting such a multi-speaker dataset is difficult, and the dataset distribution always has a mismatch with the distribution of the target speaker dataset. This paper proposes an adaptive vocoder for custom voice from another novel perspective to solve the above problems. The adaptive vocoder mainly uses a cross-domain consistency loss to solve the overfitting problem encountered by the GAN-based neural vocoder in the transfer learning of few-shot scenes. We construct two adaptive vocoders, AdaMelGAN and AdaHiFi-GAN. First, We pre-train the source vocoder model on AISHELL3 and CSMSC datasets, respectively. Then, fine-tune it on the internal dataset VXI-children with few adaptation data. The empirical results show that a high-quality custom voice system can be built by combining a adaptive acoustic model with a adaptive vocoder.      
### 42.Cross-Modal Perceptionist: Can Face Geometry be Gleaned from Voices?  [ :arrow_down: ](https://arxiv.org/pdf/2203.09824.pdf)
>  This work digs into a root question in human perception: can face geometry be gleaned from one's voices? Previous works that study this question only adopt developments in image synthesis and convert voices into face images to show correlations, but working on the image domain unavoidably involves predicting attributes that voices cannot hint, including facial textures, hairstyles, and backgrounds. We instead investigate the ability to reconstruct 3D faces to concentrate on only geometry, which is much more physiologically grounded. We propose our analysis framework, Cross-Modal Perceptionist, under both supervised and unsupervised learning. First, we construct a dataset, Voxceleb-3D, which extends Voxceleb and includes paired voices and face meshes, making supervised learning possible. Second, we use a knowledge distillation mechanism to study whether face geometry can still be gleaned from voices without paired voices and 3D face data under limited availability of 3D face scans. We break down the core question into four parts and perform visual and numerical analyses as responses to the core question. Our findings echo those in physiology and neuroscience about the correlation between voices and facial structures. The work provides future human-centric cross-modal learning with explainable foundations. See our project page: <a class="link-external link-https" href="https://choyingw.github.io/works/Voice2Mesh/index.html" rel="external noopener nofollow">this https URL</a>      
### 43.Dencentralized learning in the presence of low-rank noise  [ :arrow_down: ](https://arxiv.org/pdf/2203.09810.pdf)
>  Observations collected by agents in a network may be unreliable due to observation noise or interference. This paper proposes a distributed algorithm that allows each node to improve the reliability of its own observation by relying solely on local computations and interactions with immediate neighbors, assuming that the field (graph signal) monitored by the network lies in a low-dimensional subspace and that a low-rank noise is present in addition to the usual full-rank noise. While oblique projections can be used to project measurements onto a low-rank subspace along a direction that is oblique to the subspace, the resulting solution is not distributed. Starting from the centralized solution, we propose an algorithm that performs the oblique projection of the overall set of observations onto the signal subspace in an iterative and distributed manner. We then show how the oblique projection framework can be extended to handle distributed learning and adaptation problems over networks.      
### 44.Reinforcement-learning calibration of coherent-state receivers on variable-loss optical channels  [ :arrow_down: ](https://arxiv.org/pdf/2203.09807.pdf)
>  We study the problem of calibrating a quantum receiver for optical coherent states when transmitted on a quantum optical channel with variable transmissivity, a common model for long-distance optical-fiber and free/deep-space optical communication. We optimize the error probability of legacy adaptive receivers, such as Kennedy's and Dolinar's, on average with respect to the channel transmissivity distribution. We then compare our results with the ultimate error probability attainable by a general quantum device, computing the Helstrom bound for mixtures of coherent-state hypotheses, for the first time to our knowledge, and with homodyne measurements. With these tools, we first analyze the simplest case of two different transmissivity values; we find that the strategies adopted by adaptive receivers exhibit strikingly new features as the difference between the two transmissivities increases. Finally, we employ a recently introduced library of shallow reinforcement learning methods, demonstrating that an intelligent agent can learn the optimal receiver setup from scratch by training on repeated communication episodes on the channel with variable transmissivity and receiving rewards if the coherent-state message is correctly identified.      
### 45.Secondary complementary balancing compressive imaging with a free-space balanced amplified photodetector  [ :arrow_down: ](https://arxiv.org/pdf/2203.09802.pdf)
>  Single-pixel imaging (SPI) has attracted widespread attention because it generally uses a non-pixelated photodetector and a digital micromirror device (DMD) to acquire the object image. Since the modulated patterns seen from two reflection directions of the DMD are naturally complementary, one can apply complementary balanced measurements to greatly improve the measurement signal-to-noise ratio and reconstruction quality. However, the balance between two reflection arms significantly determines the quality of differential measurements. In this work, we propose and demonstrate a simple secondary complementary balancing mechanism to minimize the impact of the imbalance on the imaging system. In our SPI setup, we used a silicon free-space balanced amplified photodetector with 5 mm active diameter which could directly output the difference between two optical input signals in two reflection arms. Both simulation and experimental results have demonstrated that the use of secondary complementary balancing can result in a better cancellation of direct current components of measurements and a better image restoration quality.      
### 46.SWIPT-enabled NOMA in Distributed Antenna System with Imperfect Channel State Information for Max-Sum-Rate and Max-Min Fairness  [ :arrow_down: ](https://arxiv.org/pdf/2203.09769.pdf)
>  Motivated by the fact that the data rate of non-orthogonal multiple access (NOMA) can be greatly increased with the help of the distributed antenna system (DAS), we presents a framework in which the DAS contributes not only to the data rate but also the energy harvesting of simultaneous wireless information and power transfer (SWIPT) enabled NOMA. This study considers the sum-rate maximization problem and the max-min fairness problem for SWIPT-enabled NOMA in DAS and proposes two different schemes of power splitting and power allocation for SWIPT and NOMA, respectively, with imperfect channel state information (CSI). Numerical results validate the theoretical findings and demonstrate that the proposed framework of using SWIPT-enabled NOMA in DAS achieves the higher data rates than the existing SWIPT-enabled NOMA while guaranteeing the minimum harvested energy.      
### 47.Speaker Embedding-aware Neural Diarization: a Novel Framework for Overlapped Speech Diarization in the Meeting Scenario  [ :arrow_down: ](https://arxiv.org/pdf/2203.09767.pdf)
>  In this paper, we reformulate overlapped speech diarization as a single-label prediction problem, which is always treated as a multi-label classification task in previous studies. Specifically, the multiple labels of each frame are encoded into a single label with the power set, which represents the possible combinations of different speakers. Through this formulation, we propose the speaker embedding-aware neural diarization (SEND) system. In SEND, the speech encoder, speaker encoder, similarity scores, and post-processing network are optimized to predict the power set encoded labels according to the similarities between speech features and speaker embeddings. Experimental results show that our method significantly outperforms the variational Bayesian hidden Markov model-based clustering algorithm (VBx). Besides, the proposed method has two benefits compared with the target-speaker voice activity detection (TSVAD). First, SEND can achieve lower diarization error rates in the real meeting scenario. Second, when the training data has a high overlap ratio, the learning process of SEND is more stable than TSVAD.      
### 48.Fixed-Point Alignment: Incentive Bayesian Persuasion for Pipeline Stochastic Bayesian Game  [ :arrow_down: ](https://arxiv.org/pdf/2203.09725.pdf)
>  This letter studies a general-sum pipeline stochastic game where each period is composed of two pipelined stages. The first stage is a cognitive decision-making in which each agent selects one of multiple information sources (ISs) and then acquires information about the unobserved payoff-relevant state from his selected IS. In the second stage, each agent takes an action based on the information provided by his selected IS. There is a rational Bayesian persuader who controls one IS and aims to influence the agents' actions to induce her desired dynamic equilibria by solely crafting the information structure of her IS. We restrict attention to a direct Bayesian persuasion in which the persuader incentivizes the agents to select her as the IS at the first stage and consider an equilibrium concept known as pipelined perfect Markov Bayesian equilibrium (PPME) which is a nontrivial extension of Nash equilibria in general stochastic games. We propose a novel design principle termed fixed-point alignment that captures the observation that the agents' strategic interactions in the second stage induce an indirect cognitive competition (i.e., IS selection) in the first stage and formulate the direct Bayesian persuasion in PPME as a constrained non-linear optimization problem. By decomposing the optimization problem into a two-stage process known as pipelined local fixed-point alignment, we then provide a class of verifiable necessary and sufficient conditions for the implementability of the direct Bayesian persuasion in PPME.      
### 49.DGC-vector: A new speaker embedding for zero-shot voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2203.09722.pdf)
>  Recently, more and more zero-shot voice conversion algorithms have been proposed. As a fundamental part of zero-shot voice conversion, speaker embeddings are the key to improving the converted speech's speaker similarity. In this paper, we study the impact of speaker embeddings on zero-shot voice conversion performance. To better represent the characteristics of the target speaker and improve the speaker similarity in zero-shot voice conversion, we propose a novel speaker representation method in this paper. Our method combines the advantages of D-vector, global style token (GST) based speaker representation and auxiliary supervision. Objective and subjective evaluations show that the proposed method achieves a decent performance on zero-shot voice conversion and significantly improves speaker similarity over D-vector and GST-based speaker embedding.      
### 50.Learning Stabilizable Deep Dynamics Models  [ :arrow_down: ](https://arxiv.org/pdf/2203.09710.pdf)
>  When neural networks are used to model dynamics, properties such as stability of the dynamics are generally not guaranteed. In contrast, there is a recent method for learning the dynamics of autonomous systems that guarantees global exponential stability using neural networks. In this paper, we propose a new method for learning the dynamics of input-affine control systems. An important feature is that a stabilizing controller and control Lyapunov function of the learned model are obtained as well. Moreover, the proposed method can also be applied to solving Hamilton-Jacobi inequalities. The usefulness of the proposed method is examined through numerical examples.      
### 51.Improve few-shot voice cloning using multi-modal learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.09708.pdf)
>  Recently, few-shot voice cloning has achieved a significant improvement. However, most models for few-shot voice cloning are single-modal, and multi-modal few-shot voice cloning has been understudied. In this paper, we propose to use multi-modal learning to improve the few-shot voice cloning performance. Inspired by the recent works on unsupervised speech representation, the proposed multi-modal system is built by extending Tacotron2 with an unsupervised speech representation module. We evaluate our proposed system in two few-shot voice cloning scenarios, namely few-shot text-to-speech(TTS) and voice conversion(VC). Experimental results demonstrate that the proposed multi-modal learning can significantly improve the few-shot voice cloning performance over their counterpart single-modal systems.      
### 52.Latency Optimization for Blockchain-Empowered Federated Learning in Multi-Server Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2203.09670.pdf)
>  In this paper, we study a new latency optimization problem for Blockchain-based federated learning (BFL) in multi-server edge computing. In this system model, distributed mobile devices (MDs) communicate with a set of edge servers (ESs) to handle both machine learning (ML) model training and block mining simultaneously. To assist the ML model training for resource-constrained MDs, we develop an offloading strategy that enables MDs to transmit their data to one of the associated ESs. We then propose a new decentralized ML model aggregation solution at the edge layer based on a consensus mechanism to build a global ML model via peer-to-peer (P2P)-based Blockchain communications. We then formulate latency-aware BFL as an optimization aiming to minimize the system latency via joint consideration of the data offloading decisions, MDs' transmit power, channel bandwidth allocation for MDs' data offloading, MDs' computational allocation, and hash power allocation. To address the mixed action space of discrete offloading and continuous allocation variables, we propose a novel deep reinforcement learning scheme with a holistic design of a parameterized advantage actor critic (A2C) algorithm. Additionally, we theoretically characterize the convergence properties of the proposed BFL system in terms of the aggregation delay, mini-batch size, and number of P2P communication rounds. Our subsequent numerical evaluation demonstrates the superior performance of our proposed scheme over existing approaches in terms of model training efficiency, convergence rate, and system latency.      
### 53.MatchFormer: Interleaving Attention in Transformers for Feature Matching  [ :arrow_down: ](https://arxiv.org/pdf/2203.09645.pdf)
>  Local feature matching is a computationally intensive task at the subpixel level. While detector-based methods coupled with feature descriptors struggle in low-texture scenes, CNN-based methods with a sequential extract-to-match pipeline, fail to make use of the matching capacity of the encoder and tend to overburden the decoder for matching. In contrast, we propose a novel hierarchical extract-and-match transformer, termed as MatchFormer. Inside each stage of the hierarchical encoder, we interleave self-attention for feature extraction and cross-attention for feature matching, enabling a human-intuitive extract-and-match scheme. Such a match-aware encoder releases the overloaded decoder and makes the model highly efficient. Further, combining self- and cross-attention on multi-scale features in a hierarchical architecture improves matching robustness, particularly in low-texture indoor scenes or with less outdoor training data. Thanks to such a strategy, MatchFormer is a multi-win solution in efficiency, robustness, and precision. Compared to the previous best method in indoor pose estimation, our lite MatchFormer has only 45% GFLOPs, yet achieves a +1.3% precision gain and a 41% running speed boost. The large MatchFormer reaches state-of-the-art on four different benchmarks, including indoor pose estimation (ScanNet), outdoor pose estimation (MegaDepth), homography estimation and image matching (HPatch), and visual localization (InLoc). Code will be made publicly available at <a class="link-external link-https" href="https://github.com/jamycheung/MatchFormer" rel="external noopener nofollow">this https URL</a>.      
### 54.Design of Compressed Sensing Systems via Density-Evolution Framework for Structure Recovery in Graphical Models  [ :arrow_down: ](https://arxiv.org/pdf/2203.09636.pdf)
>  It has been shown that the task of learning the structure of Bayesian networks (BN) from observational data is an NP-Hard problem. Although there have been attempts made to tackle this problem, these solutions assume direct access to the observational data which may not be practical in certain applications. In this paper, we explore the feasibility of recovering the structure of Gaussian Bayesian Network (GBN) from compressed (low dimensional and indirect) measurements. We propose a novel density-evolution based framework for optimizing compressed linear measurement systems that would, by design, allow for more accurate retrieval of the covariance matrix and thereby the graph structure. In particular, under the assumption that both the covariance matrix and the graph are sparse, we show that the structure of GBN can indeed be recovered from resulting compressed measurements. The numerical simulations show that our sensing systems outperform the state of the art with respect to Maximum absolute error (MAE) and have comparable performance with respect to precision and recall, without any need for ad-hoc parameter tuning.      
### 55.Deep Semi-supervised Metric Learning with Dual Alignment for Cervical Cancer Cell Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.03265.pdf)
>  Deep learning has achieved unprecedented success in various object detection tasks with huge amounts of labeled data. However, obtaining large-scale annotations for medical images is extremely challenging due to the high demand of labour and expertise. In this paper, we propose a novel deep semi-supervised metric learning method to effectively leverage both labeled and unlabeled data for cervical cancer cell detection. Specifically, our model learns a metric space and conducts dual alignment of semantic features on both the proposal level and the prototype levels. On the proposal level, we align the unlabeled data with class proxies derived from the labeled data. We further align the prototypes of the labeled and unlabeled data to alleviate the influence of possibly noisy pseudo labels generated at the proposal alignment stage. Moreover, we adopt a memory bank to store the labeled prototypes, which significantly enrich the metric learning information from larger batches. Extensive experiments show our proposed method outperforms other state-of-the-art semi-supervised approaches consistently, demonstrating the efficacy of our proposed deep semi-supervised metric learning with dual alignment.      
### 56.Lossless Image and Intra-frame Compression with Integer-to-Integer DST  [ :arrow_down: ](https://arxiv.org/pdf/1708.07154.pdf)
>  Video coding standards are primarily designed for efficient lossy compression, but it is also desirable to support efficient lossless compression within video coding standards using small modifications to the lossy coding architecture. A simple approach is to skip transform and quantization, and simply entropy code the prediction residual. However, this approach is inefficient at compression. A more efficient and popular approach is to skip transform and quantization but also process the residual block with DPCM, along the horizontal or vertical direction, prior to entropy coding. This paper explores an alternative approach based on processing the residual block with integer-to-integer (i2i) transforms. I2i transforms can map integer pixels to integer transform coefficients without increasing the dynamic range and can be used for lossless compression. We focus on lossless intra coding and develop novel i2i approximations of the odd type-3 DST (ODST-3). Experimental results with the HEVC reference software show that the developed i2i approximations of the ODST-3 improve lossless intra-frame compression efficiency with respect to HEVC version 2, which uses the popular DPCM method, by an average 2.7% without a significant effect on computational complexity.      
