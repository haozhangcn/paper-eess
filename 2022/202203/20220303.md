# ArXiv eess --Thu, 3 Mar 2022
### 1.Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2203.01296.pdf)
>  Low-Light Image Enhancement is a computer vision task which intensifies the dark images to appropriate brightness. It can also be seen as an ill-posed problem in image restoration domain. With the success of deep neural networks, the convolutional neural networks surpass the traditional algorithm-based methods and become the mainstream in the computer vision area. To advance the performance of enhancement algorithms, we propose an image enhancement network (HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use a half wavelet attention block on M-Net+ to enrich the features from wavelet domain. Furthermore, our HWMNet has competitive performance results on two image enhancement datasets in terms of quantitative metrics and visual quality. The source code and pretrained model are available at <a class="link-external link-https" href="https://github.com/FanChiMao/HWMNet" rel="external noopener nofollow">this https URL</a>.      
### 2.Andes_gym: A Versatile Environment for Deep Reinforcement Learning in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.01292.pdf)
>  This paper presents Andes_gym, a versatile and high-performance reinforcement learning environment for power system studies. The environment leverages the modeling and simulation capability of ANDES and the reinforcement learning (RL) environment OpenAI Gym to enable the prototyping and demonstration of RL algorithms for power systems. The architecture of the proposed software tool is elaborated to provide the observation and action interfaces for RL algorithms. An example is shown to rapidly prototype a load-frequency control algorithm based on RL trained by available algorithms. The proposed environment is highly generalized by supporting all the power system dynamic models available in ANDES and numerous RL algorithms available for OpenAI Gym.      
### 3.Hybrid Model-based / Data-driven Graph Transform for Image Coding  [ :arrow_down: ](https://arxiv.org/pdf/2203.01186.pdf)
>  Transform coding to sparsify signal representations remains crucial in an image compression pipeline. While the Karhunen-LoÃ¨ve transform (KLT) computed from an empirical covariance matrix $\bar{C}$ is theoretically optimal for a stationary process, in practice, collecting sufficient statistics from a non-stationary image to reliably estimate $\bar{C}$ can be difficult. In this paper, to encode an intra-prediction residual block, we pursue a hybrid model-based / data-driven approach: the first $K$ eigenvectors of a transform matrix are derived from a statistical model, e.g., the asymmetric discrete sine transform (ADST), for stability, while the remaining $N-K$ are computed from $\bar{C}$ for performance. The transform computation is posed as a graph learning problem, where we seek a graph Laplacian matrix minimizing a graphical lasso objective inside a convex cone sharing the first $K$ eigenvectors in a Hilbert space of real symmetric matrices. We efficiently solve the problem via augmented Lagrangian relaxation and proximal gradient (PG). Using WebP as a baseline image codec, experimental results show that our hybrid graph transform achieved better energy compaction than default discrete cosine transform (DCT) and better stability than KLT.      
### 4.Omnidirectional MediA Format (OMAF): Toolbox for Virtual Reality Services  [ :arrow_down: ](https://arxiv.org/pdf/2203.01183.pdf)
>  This paper provides an overview of the Omnidirectional Media Format (OMAF) standard, second edition, which has been recently finalized. OMAF specifies the media format for coding, storage, delivery, and rendering of omnidirectional media, including video, audio, images, and timed text. Additionally, OMAF supports multiple viewpoints corresponding to omnidirectional cameras and overlay images or video rendered over the omnidirectional background image or video. Many examples of usage scenarios for multiple viewpoints and overlays are described in the paper. OMAF provides a toolbox of features, which can be selectively used in virtual reality services. Consequently, the paper presents the interoperability points specified in the OMAF standard, which enable signaling which OMAF features are in use or required to be supported in implementations. Finally, the paper summarizes which OMAF interoperability points have been taken into use in virtual reality service specifications by the 3rd Generation Partnership Project (3GPP) and the Virtual Reality Industry Forum (VRIF).      
### 5.Superiorized Adaptive Projected Subgradient Method with Application to MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2203.01116.pdf)
>  In this paper, we show that the adaptive projected subgradient method (APSM) is bounded perturbation resilient. To illustrate a potential application of this result, we propose a set-theoretic framework for MIMO detection, and we devise algorithms based on a superiorized APSM. Various low-complexity MIMO detection algorithms achieve excellent performance on i.i.d. Gaussian channels, but they typically incur high performance loss if realistic channel models are considered. Compared to existing low-complexity iterative detectors such as approximate message passing (AMP), the proposed algorithms can achieve considerably lower symbol error ratios over correlated channels. At the same time, the proposed methods do not require matrix inverses, and their complexity is similar to AMP.      
### 6.Practical Recommendations for the Design of Automatic Fault Detection Algorithms Based on Experiments with Field Monitoring Data  [ :arrow_down: ](https://arxiv.org/pdf/2203.01103.pdf)
>  Automatic fault detection (AFD) is a key technology to optimize the Operation and Maintenance of photovoltaic (PV) systems portfolios. A very common approach to detect faults in PV systems is based on the comparison between measured and simulated performance. Although this approach has been explored by many authors, due to the lack a common basis for evaluating their performance, it is still unclear what are the influencing aspects in the design of AFD algorithms. In this study, a series of AFD algorithms have been tested under real operating conditions, using monitoring data collected over 58 months on 80 rooftop-type PV systems installed in Germany. The results shown that this type of AFD algorithm have the potential to detect up to 82.8% of the energy losses with specificity above 90%. In general, the higher the simulation accuracy, the higher the specificity. The use of less accurate simulations can increase sensitivity at the cost of decreasing specificity. Analyzing the measurements individually makes the algorithm less sensitive to the simulation accuracy. The use of machine learning clustering algorithm for the statistical analysis showed exceptional ability to prevent false alerts, even in cases where the modeling accuracy is not high. If a slightly higher level of false alerts can be tolerated, the analysis of daily PR using a Shewhart chart provides the high sensitivity with an exceptionally simple solution with no need for more complex algorithms for modeling or clustering.      
### 7.Decoding-Energy-Rate-Distortion Optimization for Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2203.01099.pdf)
>  This paper presents a method for generating coded video bit streams requiring less decoding energy than conventionally coded bit streams. To this end, we propose extending the standard rate-distortion optimization approach to also consider the decoding energy. In the encoder, the decoding energy is estimated during runtime using a feature-based energy model. These energy estimates are then used to calculate decoding-energy-rate-distortion costs that are minimized by the encoder. This ultimately leads to optimal trade-offs between these three parameters. Therefore, we introduce the mathematical theory for describing decoding-energy-rate-distortion optimization and the proposed encoder algorithm is explained in detail. For rate-energy control, a new encoder parameter is introduced. Finally, measurements of the software decoding process for HEVC-coded bit streams are performed. Results show that this approach can lead to up to 30% of decoding energy reduction at a constant visual objective quality when accepting a bitrate increase at the same order of magnitude.      
### 8.Shape constrained CNN for segmentation guided prediction of myocardial shape and pose parameters in cardiac MRI  [ :arrow_down: ](https://arxiv.org/pdf/2203.01089.pdf)
>  Semantic segmentation using convolutional neural networks (CNNs) is the state-of-the-art for many medical image segmentation tasks including myocardial segmentation in cardiac MR images. However, the predicted segmentation maps obtained from such standard CNN do not allow direct quantification of regional shape properties such as regional wall thickness. Furthermore, the CNNs lack explicit shape constraints, occasionally resulting in unrealistic segmentations. In this paper, we use a CNN to predict shape parameters of an underlying statistical shape model of the myocardium learned from a training set of images. Additionally, the cardiac pose is predicted, which allows to reconstruct the myocardial contours. The integrated shape model regularizes the predicted contours and guarantees realistic shapes. We enforce robustness of shape and pose prediction by simultaneously performing pixel-wise semantic segmentation during training and define two loss functions to impose consistency between the two predicted representations: one distance-based loss and one overlap-based loss. We evaluated the proposed method in a 5-fold cross validation on an in-house clinical dataset with 75 subjects and on the ACDC and LVQuan19 public datasets. We show the benefits of simultaneous semantic segmentation and the two newly defined loss functions for the prediction of shape parameters. Our method achieved a correlation of 99% for left ventricular (LV) area on the three datasets, between 91% and 97% for myocardial area, 98-99% for LV dimensions and between 80% and 92% for regional wall thickness.      
### 9.Time-Domain Analysis for Resonant Beam Charging and Communications With Delay-Divide Demodulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.01076.pdf)
>  Laser has unique advantages such as abundant spectrum resources and low propagation divergence in wireless charging and wireless communications, compared with radio frequency. Resonant beams, as a kind of intra-cavity laser beams, have been proposed as the carrier of wireless charging and communication, as it has unique features including high power, intrinsic safety, and self-aligned mobility. However, this system has problems such as intra-cavity echo interference and power fluctuation. To study the time-domain behavior of the resonant beam system, we create a simulation algorithm by discretizing the laser rate equations which model the dynamics of the excited atom density in the gain medium and the photon density in the cavity. The simulation results are in good agreement with theoretical calculation. We also propose a delay-divide demodulation method to address the echo interference issue, and use the simulation algorithm to verify its feasibility. The results show that the resonant beam charging and communication system with the proposed demodulator is feasible and performs well. The analysis in this work also helps researchers to deeply understand the behavior of the resonant beam system.      
### 10.Recursively feasible stochastic predictive control using an interpolating initial state constraint -- extended version  [ :arrow_down: ](https://arxiv.org/pdf/2203.01073.pdf)
>  We present a stochastic model predictive control (SMPC) framework for linear systems subject to i.i.d. additive disturbances. State of the art SMPC approaches with closed-loop chance constraint satisfaction recursively initialize the nominal state based on the previously predicted nominal state or possibly the measured state under some case distinction. We improve these initialization strategies by allowing for a continuous optimization over the nominal initial state in an interpolation of these two extremes. The resulting SMPC scheme can be implemented as one standard quadratic program and is more flexible compared to state-of-the-art initialization strategies, resulting in improved performance. As the main technical contribution, we show that the proposed SMPC framework also ensures closed-loop satisfaction of chance constraints and suitable performance bounds.      
### 11.Framework for Network-Constrained Target Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2203.01003.pdf)
>  The increase in perception capabilities of connected mobile sensor platforms (e.g., self-driving vehicles, drones, and robots) leads to an extensive surge of sensed features at various temporal and spatial scales. Beyond their traditional use for safe operation, available observations could enable to see how and where people move on sidewalks and cycle paths, to eventually obtain a complete microscopic and macroscopic picture of the traffic flows in a larger area. This paper proposes a new method for advanced traffic applications, tracking an unknown and varying number of moving targets (e.g., pedestrians or cyclists) constrained by a road network, using mobile (e.g., vehicles) spatially distributed sensor platforms. The key contribution in this paper is to introduce the concept of network bound targets into the multi-target tracking problem, and hence to derive a network-constrained multi-hypotheses tracker (NC-MHT) to fully utilize the available road information. This is done by introducing a target representation, comprising a traditional target tracking representation and a discrete component placing the target on a given segment in the network. A simulation study shows that the method performs well in comparison to the standard MHT filter in free space. Results particularly highlight network-constraint effects for more efficient target predictions over extended periods of time, and in the simplification of the measurement association process, as compared to not utilizing a network structure. This theoretical work also directs attention to latent privacy concerns for potential applications.      
### 12.Modeling and Control of Smart Standalone Microgrids within Cyber Physical System Frameworks  [ :arrow_down: ](https://arxiv.org/pdf/2203.00970.pdf)
>  The ability of grid-connected microgrids (MG) to operate in islanded mode makes them an efficient solution for improving power quality and reliability. This property of MG is very much beneficial for remote and undeveloped areas in progressing countries. Moreover, ICT technology has led to the development of Smart Standalone Microgrids (SSMG), which are inundated with a plethora of sensors. This allows multiple microgrids to be controlled in a coordinated way to achieve self-sufficiency in power. In such systems, there is much interdependency between various power, control and communication parameters. Owing to these developments, the control of physical variables like voltage get affected by cyber parameters like, communication structure, delay and link loss. Moreover, due to isolation from main grid and abundance of renewable power generation units like solar PV, the inertia of these standalone grids is reduced greatly and calls for advanced control algorithms which use an abundance of sensors. Hence, the stability of these systems is greatly affected by sensor failures apart from many physical parameters like load and environmental conditions. In this thesis, a generic structure of an AC-DC hybrid microgrid is considered which is subdivided into various AC and DC counterparts. The AC and DC SSMGs are separately modeled and control solutions are proposed to improve their stability. The first two contributions propose adaptive control schemes on the primary level of control in the hybrid microgrid. Their function is to provide fast and stable parameters regulation in the DCSSMG when subjected to atmospheric changes along with faults in sensor readings. The third and fourth contributions cater to development of coordinated control cyber physical frameworks in the ACSSMG to handle the presence of simultaneous disturbances from both cyber/physical domains.      
### 13.Sketched RT3D: How to reconstruct billions of photons per second  [ :arrow_down: ](https://arxiv.org/pdf/2203.00952.pdf)
>  Single-photon light detection and ranging (lidar) captures depth and intensity information of a 3D scene. Reconstructing a scene from observed photons is a challenging task due to spurious detections associated with background illumination sources. To tackle this problem, there is a plethora of 3D reconstruction algorithms which exploit spatial regularity of natural scenes to provide stable reconstructions. However, most existing algorithms have computational and memory complexity proportional to the number of recorded photons. This complexity hinders their real-time deployment on modern lidar arrays which acquire billions of photons per second. Leveraging a recent lidar sketching framework, we show that it is possible to modify existing reconstruction algorithms such that they only require a small sketch of the photon information. In particular, we propose a sketched version of a recent state-of-the-art algorithm which uses point cloud denoisers to provide spatially regularized reconstructions. A series of experiments performed on real lidar datasets demonstrates a significant reduction of execution time and memory requirements, while achieving the same reconstruction performance than in the full data case.      
### 14.CD-GAN: a robust fusion-based generative adversarial network for unsupervised change detection between heterogeneous images  [ :arrow_down: ](https://arxiv.org/pdf/2203.00948.pdf)
>  In the context of Earth observation, the detection of changes is performed from multitemporal images acquired by sensors with possibly different characteristics and modalities. Even when restricting to the optical modality, this task has proved to be challenging as soon as the sensors provide images of different spatial and/or spectral resolutions. This paper proposes a novel unsupervised change detection method dedicated to such so-called heterogeneous optical images. This method capitalizes on recent advances which frame the change detection problem into a robust fusion framework. More precisely, we show that a deep adversarial network designed and trained beforehand to fuse a pair of multiband images can be easily complemented by a network with the same architecture to perform change detection. The resulting overall architecture itself follows an adversarial strategy where the fusion network and the additional network are interpreted as essential building blocks of a generator. A comparison with state-of-the-art change detection methods demonstrate the versatility and the effectiveness of the proposed approach.      
### 15.U-Singer: Multi-Singer Singing Voice Synthesizer that Controls Emotional Intensity  [ :arrow_down: ](https://arxiv.org/pdf/2203.00931.pdf)
>  We propose U-Singer, the first multi-singer emotional singing voice synthesizer that expresses various levels of emotional intensity. During synthesizing singing voices according to the lyrics, pitch, and duration of the music score, U-Singer reflects singer characteristics and emotional intensity by adding variances in pitch, energy, and phoneme duration according to singer ID and emotional intensity. Representing all attributes by conditional residual embeddings in a single unified embedding space, U-Singer controls mutually correlated style attributes, minimizing interference. Additionally, we apply emotion embedding interpolation and extrapolation techniques that lead the model to learn a linear embedding space and allow the model to express emotional intensity levels not included in the training data. In experiments, U-Singer synthesized high-fidelity singing voices reflecting the singer ID and emotional intensity. The visualization of the unified embedding space exhibits that U-singer estimates the correct variations in pitch and energy highly correlated with the singer ID and emotional intensity level. The audio samples are presented at <a class="link-external link-https" href="https://u-singer.github.io" rel="external noopener nofollow">this https URL</a>.      
### 16.Parameterized Image Quality Score Distribution Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2203.00926.pdf)
>  Recently, image quality has been generally describedby a mean opinion score (MOS). However, we observe that thequality scores of an image given by a group of subjects are verysubjective and diverse. Thus it is not enough to use a MOS todescribe the image quality. In this paper, we propose to describeimage quality using a parameterized distribution rather thana MOS, and an objective method is also proposed to predictthe image quality score distribution (IQSD). At first, the LIVEdatabase is re-recorded. Specifically, we have invited a largegroup of subjects to evaluate the quality of all images in theLIVE database, and each image is evaluated by a large numberof subjects (187 valid subjects), whose scores can form a reliableIQSD. By analyzing the obtained subjective quality scores, wefind that the IQSD can be well modeled by an alpha stable model,and it can reflect much more information than a single MOS, suchas the skewness of opinion score, the subject diversity and themaximum probability score for an image. Therefore, we proposeto model the IQSD using the alpha stable model. Moreover, wepropose a framework and an algorithm to predict the alphastable model based IQSD, where quality features are extractedfrom each image based on structural information and statisticalinformation, and support vector regressors are trained to predictthe alpha stable model parameters. Experimental results verifythe feasibility of using alpha stable model to describe the IQSD,and prove the effectiveness of objective alpha stable model basedIQSD prediction method.      
### 17.Smart Tracking Tray System for A Smart and Sustainable Wet Lab Community  [ :arrow_down: ](https://arxiv.org/pdf/2203.00918.pdf)
>  The laboratories and research institutes are the major places for cutting-edge scientific exploration. Hundreds of millions of research papers were formed from front-line labs. Behind this glorious achievement were unsustainable facts. More and more human investment is required in innovative experimental design and analysis of results. However, the laboratory operating environment has not been subversively transformed for centuries. This abstract proposed a smart tracking system, consisting of IoT and Data Visualization technologies, to track the chemicals in an automatic and timely approach. Positive feedback has been collected from pilot tests in several labs. The system benefits various lab users in their daily work and improves their working efficiency. In the long run, it will play an essential role in promoting the efficient use of lab resources and achieving the goal of sustainable labs.      
### 18.Machine Learning Methods for Inferring the Number of Passive Emitters via Massive MIMO Receive Array  [ :arrow_down: ](https://arxiv.org/pdf/2203.00917.pdf)
>  To improve the efficiency and accuracy of direction finding with massive MIMO receive array, it is necessary to determine the specific number of signal emitters in advance. In this paper, we present a complete DOA preprocessing system for inferring the number of passive emitters. Firstly, in order to improve the accuracy of detecting the number of signals, two high-precision signal detectors, square root of maximum eigenvalue times minimum eigenvalue (SR-MME) and geometric mean (GM), are proposed. Compared to other detectors, SR-MME and GM can achieve a high detection probability while maintaining extremely low false alarm probability. Secondly, if the existence of emitters is determined by detectors, we need to further confirm their number, that is a problem of pattern classification. Therefore, we perform feature extraction on the the eigenvalue sequence of sample covariance matrix to construct feature vector and innovatively propose a multi-layer neural network (ML-NN). Additionally, the support vector machine (SVM), and naive Bayesian classifier (NBC) are also designed. The simulation results show that the machine learning-based methods can achieve good results in signal classification, especially neural networks, which can always maintain the classification accuracy above 70\% with massive MIMO receive array. Finally, we analyze the classical signal classification methods, Akaike (AIC) and Minimum description length (MDL). It is concluded that the two methods are not suitable for scenarios with massive receive arrays, and they also have much worse performance than machine learning-based classifiers.      
### 19.Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and Cycle Idempotence  [ :arrow_down: ](https://arxiv.org/pdf/2203.00911.pdf)
>  Deep learning based single image super-resolution models have been widely studied and superb results are achieved in upscaling low-resolution images with fixed scale factor and downscaling degradation kernel. To improve real world applicability of such models, there are growing interests to develop models optimized for arbitrary upscaling factors. Our proposed method is the first to treat arbitrary rescaling, both upscaling and downscaling, as one unified process. Using joint optimization of both directions, the proposed model is able to learn upscaling and downscaling simultaneously and achieve bidirectional arbitrary image rescaling. It improves the performance of current arbitrary upscaling models by a large margin while at the same time learns to maintain visual perception quality in downscaled images. The proposed model is further shown to be robust in cycle idempotence test, free of severe degradations in reconstruction accuracy when the downscaling-to-upscaling cycle is applied repetitively. This robustness is beneficial for image rescaling in the wild when this cycle could be applied to one image for multiple times. It also performs well on tests with arbitrary large scales and asymmetric scales, even when the model is not trained with such tasks. Extensive experiments are conducted to demonstrate the superior performance of our model.      
### 20.Splitting Receiver with Joint Envelope and Coherent Detection  [ :arrow_down: ](https://arxiv.org/pdf/2203.00909.pdf)
>  This letter proposes a new splitting receiver design with joint envelope detection (ED) and coherent detection (CD). To characterize its fundamental performance limit, we conduct high signal-to-noise ratio (SNR) analysis on the proposed ED-CD splitting receiver and obtain closed-form approximations of both the achievable mutual information and the optimal splitting ratio (i.e., a key design parameter of the receiver). Our numerical results show that these high SNR approximations are accurate over a wide range of moderate SNR values, signifying the usefulness of the obtained analytical results. We also provide insights on the conditions at which the proposed splitting receiver has significant performance advantages over the traditional receivers.      
### 21.Distributed goal assignment strategy for improving leader-following formation control performance  [ :arrow_down: ](https://arxiv.org/pdf/2203.00906.pdf)
>  This paper investigates a distributed goal assignment problem in leader-following formation control of second-order multi-agent systems. It is assumed that each agent can communicate with nearby agents within the communication range and the leader information is only available to a subset of agents. Compared with existing formation control schemes addressing the goal assignment issue, the main contribution of this paper is to construct a novel distributed assignment strategy allotting appropriate goal positions of agents in the leader-following formation control framework. Based on the rigorous analysis using the Lyapunov stability theory, the enhancement of the control performance is proved via the proposed assignment strategy. To demonstrate the effectiveness of our theoretical results, two examples including multiple quadrotors are simulated.      
### 22.Machine learning based lens-free imaging technique for field-portable cytometry  [ :arrow_down: ](https://arxiv.org/pdf/2203.00899.pdf)
>  Lens-free Shadow Imaging Technique (LSIT) is a well-established technique for the characterization of microparticles and biological cells. Due to its simplicity and cost-effectiveness, various low-cost solutions have been evolved, such as automatic analysis of complete blood count (CBC), cell viability, 2D cell morphology, 3D cell tomography, etc. The developed auto characterization algorithm so far for this custom-developed LSIT cytometer was based on the hand-crafted features of the cell diffraction patterns from the LSIT cytometer, that were determined from our empirical findings on thousands of samples of individual cell types, which limit the system in terms of induction of a new cell type for auto classification or characterization. Further, its performance is suffering from poor image (cell diffraction pattern) signatures due to its small signal or background noise. In this work, we address these issues by leveraging the artificial intelligence-powered auto signal enhancing scheme such as denoising autoencoder and adaptive cell characterization technique based on the transfer of learning in deep neural networks. The performance of our proposed method shows an increase in accuracy &gt;98% along with the signal enhancement of &gt;5 dB for most of the cell types, such as Red Blood Cell (RBC) and White Blood Cell (WBC). Furthermore, the model is adaptive to learn new type of samples within a few learning iterations and able to successfully classify the newly introduced sample along with the existing other sample types.      
### 23.Joint Localization and Orientation Estimation in Millimeter-Wave MIMO OFDM Systems via Atomic Norm Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.00892.pdf)
>  Herein, an atomic norm based method for accurately estimating the location and orientation of a target from millimeter-wave multi-input-multi-output (MIMO) orthogonal frequency-division multiplexing (OFDM) signals is presented. A novel virtual channel matrix is introduced and an algorithm to extract localization-relevant channel parameters from its atomic norm decomposition is designed. Then, based on the extended invariance principle, a weighted least squares problem is proposed to accurately recover the location and orientation using both line-of-sight and non-line-of-sight channel information. The conditions for the optimality and uniqueness of the estimate and theoretical guarantees for the estimation error are characterized for the noiseless and the noisy scenarios. Theoretical results are confirmed via simulation. Numerical results investigate the robustness of the proposed algorithm to incorrect model order selection or synchronization error, and highlight performance improvements over a prior method. The resultant performance nearly achieves the Cramer-Rao lower bound on the estimation error.      
### 24.Can No-reference features help in Full-reference image quality estimation?  [ :arrow_down: ](https://arxiv.org/pdf/2203.00845.pdf)
>  Development of perceptual image quality assessment (IQA) metrics has been of significant interest to computer vision community. The aim of these metrics is to model quality of an image as perceived by humans. Recent works in Full-reference IQA research perform pixelwise comparison between deep features corresponding to query and reference images for quality prediction. However, pixelwise feature comparison may not be meaningful if distortion present in query image is severe. In this context, we explore utilization of no-reference features in Full-reference IQA task. Our model consists of both full-reference and no-reference branches. Full-reference branches use both distorted and reference images, whereas No-reference branch only uses distorted image. Our experiments show that use of no-reference features boosts performance of image quality assessment. Our model achieves higher SRCC and KRCC scores than a number of state-of-the-art algorithms on KADID-10K and PIPAL datasets.      
### 25.To further understand graph signals  [ :arrow_down: ](https://arxiv.org/pdf/2203.00832.pdf)
>  Graph signal processing (GSP) is a framework to analyze and process graph structured data. Many research works focus on developing tools such as Graph Fourier transforms (GFT), filters and neural network models to handle graph signals. Such approaches have successfully taken care of "signal processing" in many circumstances. In this paper, we want to put emphasis on "graph signals" themselves. Although there are characterizations of graph signals using the notion of bandwidth derived from GFT, we want to argue here that graph signals may contain hidden geometric information of the network, independent of (graph) Fourier theories. We shall provide a framework to understand such information, and demonstrate how new knowledge on "graph signals" can help with "signal processing".      
### 26.Using Geographic Load Shifting to Reduce Carbon Emissions  [ :arrow_down: ](https://arxiv.org/pdf/2203.00826.pdf)
>  An increasing focus on the electricity use and carbon emissions associated with computing has lead to pledges by major cloud computing companies to lower their carbon footprint. Data centers have a unique ability to shift computing load between different geographical locations, giving rise to geographic load flexibility that can be employed to reduce carbon emissions. In this paper, we present a model where data centers shift load independently of the ISOs. We first consider the impact of load shifting guided by locational marginal carbon emissions, denoted by $\lambda_{\text{CO}_2}$, a sensitivity metric that measures the impact of incremental load shifts. Relative to previous models for data center load shifting, the presented model improves accuracy and include more realistic assumptions regarding the operation of both data centers and the electricity market. Further, we introduce a new benchmark model in which data centers have access to the full information about the power system and can identify optimal shifts for the current time period. We demonstrate the efficacy of our model on the IEEE RTS GMLC system using 5 minute load and generation data for an entire year. Our results show that the proposed accuracy improvements for the shifting model based on $\lambda_{\text{CO}_2}$ are highly effective, leading to results that outperform the benchmark model.      
### 27.Distributed and Localized Model Predictive Control. Part II: Theoretical Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2203.00780.pdf)
>  Engineered cyberphysical systems are growing increasingly large and complex. These systems require scalable controllers that robustly satisfy state and input constraints in the presence of additive noise -- such controllers should also be accompanied by theoretical guarantees on feasibility and stability. In our companion paper, we introduced Distributed and Localized Model Predictive Control (DLMPC) for large-scale linear systems; DLMPC is a scalable closed-loop MPC scheme in which subsystems need only exchange local information in order to synthesize and implement local controllers. In this paper, we provide recursive feasibility and asymptotic stability guarantees for DLMPC. We leverage the System Level Synthesis framework to express the maximal positive robust invariant set for the closed-loop system and its corresponding Lyapunov function, both in terms of the closed-loop system responses. We use the invariant set as the terminal set for DLMPC, and show that this guarantees feasibility with minimal conservatism. We use the Lyapunov function as the terminal cost, and show that this guarantees stability. We provide fully distributed and localized algorithms to compute the terminal set offline, and also provide necessary additions to the online DLMPC algorithm to accommodate coupled terminal constraint and cost. In all algorithms, only local information exchanges are necessary, and computational complexity is independent of the global system size -- we demonstrate this analytically and experimentally. This is the first distributed MPC approach that provides minimally conservative yet fully distributed guarantees for recursive feasibility and asymptotic stability, for both nominal and robust settings.      
### 28.Real time spectrogram inversion on mobile phone  [ :arrow_down: ](https://arxiv.org/pdf/2203.00756.pdf)
>  With the growth of computing power on mobile phones and privacy concerns over user's data, on-device real time speech processing has become an important research topic. In this paper, we focus on methods for real time spectrogram inversion, where an algorithm receives a portion of the input signal (e.g., one frame) and processes it incrementally, i.e., operating in streaming mode. We present a real time Griffin Lim(GL) algorithm using a sliding window approach in STFT domain. The proposed algorithm is 2.4x faster than real time on the ARM CPU of a Pixel4. In addition we explore a neural vocoder operating in streaming mode and demonstrate the impact of looking ahead on perceptual quality. As little as one hop size (12.5ms) of lookahead is able to significantly improve perceptual quality in comparison to a causal model. We compare GL with the neural vocoder and show different trade-offs in terms of perceptual quality, on-device latency, algorithmic delay, memory footprint and noise sensitivity. For fair quality assessment of the GL approach, we use input log magnitude spectrogram without mel transformation. We evaluate presented real time spectrogram inversion approaches on clean, noisy and atypical speech.      
### 29.Computing Bounds on $L_{\infty}$-induced Norm for Linear Time-Invariant Systems Using Homogeneous Lyapunov Functions  [ :arrow_down: ](https://arxiv.org/pdf/2203.00716.pdf)
>  Quadratic Lyapunov function has been widely used in the analysis of linear time invariant (LTI) systems ever since it has shown that the existence of such quadratic Lyapunov function certifies the stability of the LTI system. In this work, the problem of finding upper and lower bounds for the $L_{\infty}$-induced norm of the LTI system is considered. Quadratic Lyapunov functions are used to find the star norm, the best upper on the $L_{\infty}$-induced norm, by bounding the unit peak input reachable sets by inescapable ellipsoids. Instead, a more general class of homogeneous Lyapunov functions is used to get less conservative upper bounds on the $L_{\infty}$-induced norm and better conservative approximations for the reachable sets than those obtained using standard quadratic Lyapunov functions. The homogeneous Lyapunov function for the LTI system is considered to be a quadratic Lyapunov function for a higher-order system obtained by Lifting the LTI system via Kronecker product. Different examples are provided to show the significant improvements on the bounds obtained by using Homogeneous Lyapunov functions.      
### 30.ONIX: an X-ray deep-learning tool for 3D reconstructions from sparse views  [ :arrow_down: ](https://arxiv.org/pdf/2203.00682.pdf)
>  Three-dimensional (3D) X-ray imaging techniques like tomography and confocal microscopy are crucial for academic and industrial applications. These approaches access 3D information by scanning the sample with respect to the X-ray source. However, the scanning process limits the temporal resolution when studying dynamics and is not feasible for some applications, such as surgical guidance in medical applications. Alternatives to obtaining 3D information when scanning is not possible are X-ray stereoscopy and multi-projection imaging. However, these approaches suffer from limited volumetric information as they only acquire a small number of views or projections compared to traditional 3D scanning techniques. Here, we present ONIX (Optimized Neural Implicit X-ray imaging), a deep-learning algorithm capable of retrieving 3D objects with arbitrary large resolution from only a set of sparse projections. ONIX, although it does not have access to any volumetric information, outperforms current 3D reconstruction approaches because it includes the physics of image formation with X-rays, and it generalizes across different experiments over similar samples to overcome the limited volumetric information provided by sparse views. We demonstrate the capabilities of ONIX compared to state-of-the-art tomographic reconstruction algorithms by applying it to simulated and experimental datasets, where a maximum of eight projections are acquired. We anticipate that ONIX will become a crucial tool for the X-ray community by i) enabling the study of fast dynamics not possible today when implemented together with X-ray multi-projection imaging, and ii) enhancing the volumetric information and capabilities of X-ray stereoscopic imaging in medical applications.      
### 31.End-to-End Simulation of 5G Networks Assisted by IRS and AF Relays  [ :arrow_down: ](https://arxiv.org/pdf/2203.01209.pdf)
>  The high propagation and penetration loss experienced at millimeter wave (mmWave) frequencies requires ultra-dense deployments of 5th generation (5G) base stations, which may be infeasible and costly for network operators. Integrated Access and Backhaul (IAB) has been proposed to partially address this issue, even though raising concerns in terms of power consumption and scalability. Recently, the research community has been investigating Intelligent Reflective Surfaces (IRSs) and Amplify-and-Forward (AF) relays as more energy-efficient alternatives to solve coverage issues in 5G scenarios. Along these lines, this paper relies on a new simulation framework, based on ns-3, to simulate IRS/AF systems with a full-stack, end-to-end perspective, with considerations on to the impact of the channel model and the protocol stack of 5G NR networks. Our goal is to demonstrate whether these technologies can be used to relay 5G traffic requests and, if so, how to dimension IRS/AF nodes as a function of the number of end users.      
### 32.Container Localisation and Mass Estimation with an RGB-D Camera  [ :arrow_down: ](https://arxiv.org/pdf/2203.01207.pdf)
>  In the research area of human-robot interactions, the automatic estimation of the mass of a container manipulated by a person leveraging only visual information is a challenging task. The main challenges consist of occlusions, different filling materials and lighting conditions. The mass of an object constitutes key information for the robot to correctly regulate the force required to grasp the container. We propose a single RGB-D camera-based method to locate a manipulated container and estimate its empty mass i.e., independently of the presence of the content. The method first automatically selects a number of candidate containers based on the distance with the fixed frontal view, then averages the mass predictions of a lightweight model to provide the final estimation. Results on the CORSMAL Containers Manipulation dataset show that the proposed method estimates empty container mass obtaining a score of 71.08% under different lighting or filling conditions.      
### 33.Audio Self-supervised Learning: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2203.01205.pdf)
>  Inspired by the humans' cognitive ability to generalise knowledge and skills, Self-Supervised Learning (SSL) targets at discovering general representations from large-scale data without requiring human annotations, which is an expensive and time consuming task. Its success in the fields of computer vision and natural language processing have prompted its recent adoption into the field of audio and speech processing. Comprehensive reviews summarising the knowledge in audio SSL are currently missing. To fill this gap, in the present work, we provide an overview of the SSL methods used for audio and speech processing applications. Herein, we also summarise the empirical works that exploit the audio modality in multi-modal SSL frameworks, and the existing suitable benchmarks to evaluate the power of SSL in the computer audition domain. Finally, we discuss some open problems and point out the future directions on the development of audio SSL.      
### 34.Linear Stochastic Bandits over a Bit-Constrained Channel  [ :arrow_down: ](https://arxiv.org/pdf/2203.01198.pdf)
>  One of the primary challenges in large-scale distributed learning stems from stringent communication constraints. While several recent works address this challenge for static optimization problems, sequential decision-making under uncertainty has remained much less explored in this regard. Motivated by this gap, we introduce a new linear stochastic bandit formulation over a bit-constrained channel. Specifically, in our setup, an agent interacting with an environment transmits encoded estimates of an unknown model parameter to a server over a communication channel of finite capacity. The goal of the server is to take actions based on these estimates to minimize cumulative regret. To this end, we develop a novel and general algorithmic framework that hinges on two main components: (i) an adaptive encoding mechanism that exploits statistical concentration bounds, and (ii) a decision-making principle based on confidence sets that account for encoding errors. As our main result, we prove that when the unknown model is $d$-dimensional, a channel capacity of $O(d)$ bits suffices to achieve order-optimal regret. To demonstrate the generality of our approach, we then show that the same result continues to hold for non-linear observation models satisfying standard regularity conditions. Finally, we establish that for the simpler unstructured multi-armed bandit problem, $1$ bit channel-capacity is sufficient for achieving optimal regret bounds. Overall, our work takes a significant first step towards paving the way for statistical decision-making over finite-capacity channels.      
### 35.DCT-Former: Efficient Self-Attention with Discrete Cosine Transform  [ :arrow_down: ](https://arxiv.org/pdf/2203.01178.pdf)
>  Since their introduction the Trasformer architectures emerged as the dominating architectures for both natural language processing and, more recently, computer vision applications. An intrinsic limitation of this family of "fully-attentive" architectures arises from the computation of the dot-product attention, which grows both in memory consumption and number of operations as $O(n^2)$ where $n$ stands for the input sequence length, thus limiting the applications that require modeling very long sequences. Several approaches have been proposed so far in the literature to mitigate this issue, with varying degrees of success. Our idea takes inspiration from the world of lossy data compression (such as the JPEG algorithm) to derive an approximation of the attention module by leveraging the properties of the Discrete Cosine Transform. An extensive section of experiments shows that our method takes up less memory for the same performance, while also drastically reducing inference time. This makes it particularly suitable in real-time contexts on embedded platforms. Moreover, we assume that the results of our research might serve as a starting point for a broader family of deep neural models with reduced memory footprint. The implementation will be made publicly available at <a class="link-external link-https" href="https://github.com/cscribano/DCT-Former-Public" rel="external noopener nofollow">this https URL</a>      
### 36.Speaker recognition improvement using blind inversion of distortions  [ :arrow_down: ](https://arxiv.org/pdf/2203.01164.pdf)
>  In this paper we propose the inversion of nonlinear distortions in order to improve the recognition rates of a speaker recognizer system. We study the effect of saturations on the test signals, trying to take into account real situations where the training material has been recorded in a controlled situation but the testing signals present some mismatch with the input signal level (saturations). The experimental results shows that a combination of data fusion with and without nonlinear distortion compensation can improve the recognition rates with saturated test sentences from 80% to 88.57%, while the results with clean speech (without saturation) is 87.76% for one microphone.      
### 37.A multi-task learning for cavitation detection and cavitation intensity recognition of valve acoustic signals  [ :arrow_down: ](https://arxiv.org/pdf/2203.01118.pdf)
>  With the rapid development of smart manufacturing, data-driven machinery health management has received a growing attention. As one of the most popular methods in machinery health management, deep learning (DL) has achieved remarkable successes. However, due to the issues of limited samples and poor separability of different cavitation states of acoustic signals, which greatly hinder the eventual performance of DL modes for cavitation intensity recognition and cavitation detection. In this work, a novel multi-task learning framework for simultaneous cavitation detection and cavitation intensity recognition framework using 1-D double hierarchical residual networks (1-D DHRN) is proposed for analyzing valves acoustic signals. Firstly, a data augmentation method based on sliding window with fast Fourier transform (Swin-FFT) is developed to alleviate the small-sample issue confronted in this study. Secondly, a 1-D double hierarchical residual block (1-D DHRB) is constructed to capture sensitive features from the frequency domain acoustic signals of valve. Then, a new structure of 1-D DHRN is proposed. Finally, the devised 1-D DHRN is evaluated on two datasets of valve acoustic signals without noise (Dataset 1 and Dataset 2) and one dataset of valve acoustic signals with realistic surrounding noise (Dataset 3) provided by SAMSON AG (Frankfurt). Our method has achieved state-of-the-art results. The prediction accurcies of 1-D DHRN for cavitation intensitys recognition are as high as 93.75%, 94.31% and 100%, which indicates that 1-D DHRN outperforms other DL models and conventional methods. At the same time, the testing accuracies of 1-D DHRN for cavitation detection are as high as 97.02%, 97.64% and 100%. In addition, 1-D DHRN has also been tested for different frequencies of samples and shows excellent results for frequency of samples that mobile phones can accommodate.      
### 38.A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based Non-Autoregressive TTS  [ :arrow_down: ](https://arxiv.org/pdf/2203.01080.pdf)
>  The generative adversarial network (GAN) has shown its outstanding capability in improving Non-Autoregressive TTS (NAR-TTS) by adversarially training it with an extra model that discriminates between the real and the generated speech. To maximize the benefits of GAN, it is crucial to find a powerful discriminator that can capture rich distinguishable information. In this paper, we propose a multi-scale time-frequency spectrogram discriminator to help NAR-TTS generate high-fidelity Mel-spectrograms. It treats the spectrogram as a 2D image to exploit the correlation among different components in the time-frequency domain. And a U-Net-based model structure is employed to discriminate at different scales to capture both coarse-grained and fine-grained information. We conduct subjective tests to evaluate the proposed approach. Both multi-scale and time-frequency discriminating bring significant improvement in the naturalness and fidelity. When combining the neural vocoder, it is shown more effective and concise than fine-tuning the vocoder. Finally, we visualize the discriminating maps to compare their difference to verify the effectiveness of multi-scale discriminating.      
### 39.Unfreezing Social Navigation: Dynamical Systems based Compliance for Contact Control in Robot Navigation  [ :arrow_down: ](https://arxiv.org/pdf/2203.01053.pdf)
>  Large efforts have focused on ensuring that the controllers for mobile service robots follow proxemics and other social rules to ensure both safe and socially acceptable distance to pedestrians. Nonetheless, involuntary contact may be unavoidable when the robot travels in crowded areas or when encountering adversarial pedestrians. Freezing the robot in response to contact might be detrimental to bystanders' safety and prevents it from achieving its task. Unavoidable contacts must hence be controlled to ensure the safe and smooth travelling of robots in pedestrian alleys. We present a force-limited and obstacle avoidance controller integrated into a time-invariant dynamical system (DS) in a closed-loop force controller that let the robot react instantaneously to contact or to the sudden appearance of pedestrians. Mitigating the risk of collision is done by modulating the velocity commands upon detecting a contact and by absorbing part of the contact force through active compliant control when the robot bumps inadvertently against a pedestrian. We evaluated our method with a personal mobility robot -- Qolo -- showing contact mitigation with passive and active compliance. We showed the robot able to overcome an adversarial pedestrian within 9 N of the set limit contact force for speeds under 1 m/s. Moreover, we evaluated integrated obstacle avoidance proving the ability to advance without incurring any other collision.      
### 40.Structural Gaussian Priors for Bayesian CT reconstruction of Subsea Pipes  [ :arrow_down: ](https://arxiv.org/pdf/2203.01030.pdf)
>  A non-destructive testing (NDT) application of X-ray computed tomography (CT) is inspection of subsea pipes in operation via 2D cross-sectional scans. Data acquisition is time-consuming and costly due to the challenging subsea environment. Reducing the number of projections in a scan can yield time and cost savings, but compromises the reconstruction quality, if conventional reconstruction methods are used. In this work we take a Bayesian approach to CT reconstruction and focus on designing an effective prior to make use of available structural information about the pipe geometry. We propose a new class of structural Gaussian priors to enforce expected material properties in different regions of the reconstructed image based on independent Gaussian priors in combination with global regularity through a Gaussian Markov Random Field (GMRF) prior. Numerical experiments with synthetic and real data show that the proposed structural Gaussian prior can reduce artifacts and enhance contrast in the reconstruction compared to using only a global GMRF prior or no prior at all. We show how the resulting posterior distribution can be efficiently sampled even for large-scale images, which is essential for practical NDT applications.      
### 41.UAV-Aided Decentralized Learning over Mesh Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.01008.pdf)
>  Decentralized learning empowers wireless network devices to collaboratively train a machine learning (ML) model relying solely on device-to-device (D2D) communication. It is known that the convergence speed of decentralized optimization algorithms severely depends on the degree of the network connectivity, with denser network topologies leading to shorter convergence time. Consequently, local connectivity of real world mesh networks, due to the limited communication range of its wireless nodes, undermines the efficiency of decentralized learning protocols, rendering them potentially impracticable. In this work we investigate the role of an unmanned aerial vehicle (UAV), used as flying relay, in facilitating decentralized learning procedures in such challenging conditions. We propose an optimized UAV trajectory, that is defined as a sequence of waypoints that the UAV visits sequentially in order to transfer intelligence across sparsely connected group of users. We then provide a series of experiments highlighting the essential role of UAVs in the context of decentralized learning over mesh networks.      
### 42.Sequential Offloading for Distributed DNN Computation in Multiuser MEC Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.01005.pdf)
>  This paper studies a sequential task offloading problem for a multiuser mobile edge computing (MEC) system. We consider a dynamic optimization approach, which embraces wireless channel fluctuations and random deep neural network (DNN) task arrivals over an infinite horizon. Specifically, we introduce a local CPU workload queue (WD-QSI) and an MEC server workload queue (MEC-QSI) to model the dynamic workload of DNN tasks at each WD and the MEC server, respectively. The transmit power and the partitioning of the local DNN task at each WD are dynamically determined based on the instantaneous channel conditions (to capture the transmission opportunities) and the instantaneous WD-QSI and MEC-QSI (to capture the dynamic urgency of the tasks) to minimize the average latency of the DNN tasks. The joint optimization can be formulated as an ergodic Markov decision process (MDP), in which the optimality condition is characterized by a centralized Bellman equation. However, the brute force solution of the MDP is not viable due to the curse of dimensionality as well as the requirement for knowledge of the global state information. To overcome these issues, we first decompose the MDP into multiple lower dimensional sub-MDPs, each of which can be associated with a WD or the MEC server. Next, we further develop a parametric online Q-learning algorithm, so that each sub-MDP is solved locally at its associated WD or the MEC server. The proposed solution is completely decentralized in the sense that the transmit power for sequential offloading and the DNN task partitioning can be determined based on the local channel state information (CSI) and the local WD-QSI at the WD only. Additionally, no prior knowledge of the distribution of the DNN task arrivals or the channel statistics will be needed for the MEC server.      
### 43.Speaker Adaption with Intuitive Prosodic Features for Statistical Parametric Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2203.00951.pdf)
>  In this paper, we propose a method of speaker adaption with intuitive prosodic features for statistical parametric speech synthesis. The intuitive prosodic features employed in this method include pitch, pitch range, speech rate and energy considering that they are directly related with the overall prosodic characteristics of different speakers. The intuitive prosodic features are extracted at utterance-level or speaker-level, and are further integrated into the existing speaker-encoding-based and speaker-embedding-based adaptation frameworks respectively. The acoustic models are sequence-to-sequence ones based on Tacotron2. Intuitive prosodic features are concatenated with text encoder outputs and speaker vectors for decoding acoustic features.Experimental results have demonstrated that our proposed methods can achieve better objective and subjective performance than the baseline methods without intuitive prosodic features. Besides, the proposed speaker adaption method with utterance-level prosodic features has achieved the best similarity of synthetic speech among all compared methods.      
### 44.TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration  [ :arrow_down: ](https://arxiv.org/pdf/2203.00927.pdf)
>  Traditional video-based human activity recognition has experienced remarkable progress linked to the rise of deep learning, but this effect was slower as it comes to the downstream task of driver behavior understanding. Understanding the situation inside the vehicle cabin is essential for Advanced Driving Assistant System (ADAS) as it enables identifying distraction, predicting driver's intent and leads to more convenient human-vehicle interaction. At the same time, driver observation systems face substantial obstacles as they need to capture different granularities of driver states, while the complexity of such secondary activities grows with the rising automation and increased driver freedom. Furthermore, a model is rarely deployed under conditions identical to the ones in the training set, as sensor placements and types vary from vehicle to vehicle, constituting a substantial obstacle for real-life deployment of data-driven models. In this work, we present a novel vision-based framework for recognizing secondary driver behaviours based on visual transformers and an additional augmented feature distribution calibration module. This module operates in the latent feature-space enriching and diversifying the training set at feature-level in order to improve generalization to novel data appearances, (e.g., sensor changes) and general feature quality. Our framework consistently leads to better recognition rates, surpassing previous state-of-the-art results of the public Drive&amp;Act benchmark on all granularity levels. Our code will be made publicly available at <a class="link-external link-https" href="https://github.com/KPeng9510/TransDARC" rel="external noopener nofollow">this https URL</a>.      
### 45.PUFA-GAN: A Frequency-Aware Generative Adversarial Network for 3D Point Cloud Upsampling  [ :arrow_down: ](https://arxiv.org/pdf/2203.00914.pdf)
>  We propose a generative adversarial network for point cloud upsampling, which can not only make the upsampled points evenly distributed on the underlying surface but also efficiently generate clean high frequency regions. The generator of our network includes a dynamic graph hierarchical residual aggregation unit and a hierarchical residual aggregation unit for point feature extraction and upsampling, respectively. The former extracts multiscale point-wise descriptive features, while the latter captures rich feature details with hierarchical residuals. To generate neat edges, our discriminator uses a graph filter to extract and retain high frequency points. The generated high resolution point cloud and corresponding high frequency points help the discriminator learn the global and high frequency properties of the point cloud. We also propose an identity distribution loss function to make sure that the upsampled points remain on the underlying surface of the input low resolution point cloud. To assess the regularity of the upsampled points in high frequency regions, we introduce two evaluation metrics. Objective and subjective results demonstrate that the visual quality of the upsampled point clouds generated by our method is better than that of the state-of-the-art methods.      
### 46.Cell-Free Massive MIMO-OFDM for High-Speed Train Communications  [ :arrow_down: ](https://arxiv.org/pdf/2203.00900.pdf)
>  Cell-free (CF) massive multiple-input multiple-output (MIMO) systems show great potentials in low-mobility scenarios, due to cell boundary disappearance and strong macro diversity. However, the great Doppler frequency offset (DFO) leads to serious inter-carrier interference in orthogonal frequency division multiplexing (OFDM) technology, which makes it difficult to provide high-quality transmissions for both high-speed train (HST) operation control systems and passengers. In this paper, we focus on the performance of CF massive MIMO-OFDM systems with both fully centralized and local minimum mean square error (MMSE) combining in HST communications. Considering the local maximum ratio (MR) combining, the large-scale fading decoding (LSFD) cooperation and the practical effect of DFO on system performance, exact closed-form expressions for uplink spectral efficiency (SE) expressions are derived. We observe that cooperative MMSE combining achieves better SE performance than uncooperative MR combining. In addition, HST communications with small cell and cellular massive MIMO-OFDM systems are compared in terms of SE. Numerical results reveal that the CF massive MIMO-OFDM system achieves a larger and more uniform SE than the other systems. Finally, the train antenna centric (TA-centric) CF massive MIMO-OFDM system is designed for practical implementation in HST communications, and three power control schemes are adopted to optimize the propagation of TAs for reducing the impact of the DFO.      
### 47.Towards Contextual Spelling Correction for Customization of End-to-end Speech Recognition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.00888.pdf)
>  Contextual biasing is an important and challenging task for end-to-end automatic speech recognition (ASR) systems, which aims to achieve better recognition performance by biasing the ASR system to particular context phrases such as person names, music list, proper nouns, etc. Existing methods mainly include contextual LM biasing and adding bias encoder into end-to-end ASR models. In this work, we introduce a novel approach to do contextual biasing by adding a contextual spelling correction model on top of the end-to-end ASR system. We incorporate contextual information into a sequence-to-sequence spelling correction model with a shared context encoder. Our proposed model includes two different mechanisms: autoregressive (AR) and non-autoregressive (NAR). We propose filtering algorithms to handle large-size context lists, and performance balancing mechanisms to control the biasing degree of the model. We demonstrate the proposed model is a general biasing solution which is domain-insensitive and can be adopted in different scenarios. Experiments show that the proposed method achieves as much as 51% relative word error rate (WER) reduction over ASR system and outperforms traditional biasing methods. Compared to the AR solution, the proposed NAR model reduces model size by 43.2% and speeds up inference by 2.1 times.      
### 48.Towards Effective Resource Procurement in MEC: a Resource Re-selling Framework  [ :arrow_down: ](https://arxiv.org/pdf/2203.00825.pdf)
>  On-demand and resource reservation pricing models have been widely used in cloud computing, catering to different user requirements. Nevertheless, in Multi-Access Edge Computing (MEC), as the edge has limited resources compared to the cloud, on-demand users may not get their jobs served on time, or at all, if too many resources were reserved by reservation plan users. Concurrently, reservation plan users may possess excess un-utilized quota. To optimize this resource mismatch scenario, we propose a Sharing Quota Model (SQM) where reservation plan users can re-sell unused resource quota to on-demand users, with the mobile network operator (MNO) taking a commission. To analyze the user's aggregate behavior at equilibrium and investigate the MNO's incentive of allowing re-selling, we formulate a 3-stage non-cooperative Stackelberg Game. Solving this game, we characterize the optimal strategies of buyers and re-sellers. We show that on aggregate, users' optimal strategies give rise to 4 disjoint regions, dependent on the MNO's prices and supply levels. Based on this, we characterise the MNO's optimal prices for on-demand users. Numerical results show that having both the sharing and on-demand pool gives the MNO an optimal revenue when the on-demand pool's supply is low, and when the MNO's commission is low.      
### 49.Stable, accurate and efficient deep neural networks for inverse problems with analysis-sparse models  [ :arrow_down: ](https://arxiv.org/pdf/2203.00804.pdf)
>  Solving inverse problems is a fundamental component of science, engineering and mathematics. With the advent of deep learning, deep neural networks have significant potential to outperform existing state-of-the-art, model-based methods for solving inverse problems. However, it is known that current data-driven approaches face several key issues, notably instabilities and hallucinations, with potential impact in critical tasks such as medical imaging. This raises the key question of whether or not one can construct stable and accurate deep neural networks for inverse problems. In this work, we present a novel construction of an accurate, stable and efficient neural network for inverse problems with general analysis-sparse models. To construct the network, we unroll NESTA, an accelerated first-order method for convex optimization. Combined with a compressed sensing analysis, we prove accuracy and stability. Finally, a restart scheme is employed to enable exponential decay of the required network depth, yielding a shallower, and consequently more efficient, network. We showcase this approach in the case of Fourier imaging, and verify its stability and performance via a series of numerical experiments. The key impact of this work is to provide theoretical guarantees for computing and developing stable neural networks in practice.      
### 50.Unified Physical Threat Monitoring System Aided by Virtual Building Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.00789.pdf)
>  With increasing physical threats in recent years targeted at critical infrastructures, it is crucial to establish a reliable threat monitoring system integrating video surveillance and digital sensors based on cutting-edge technologies. A physical threat monitoring solution unifying the floorplan, cameras, and sensors for smart buildings has been set up in our study. Computer vision and deep learning models are used for video streams analysis. When a threat is detected by a rule engine based on the real-time analysis results combining with feedback from related digital sensors, an alert is sent to the Video Management System so that human operators can take further action. A physical threat monitoring system typically needs to address complex and even destructive incidents, such as fire, which is unrealistic to simulate in real life. Restrictions imposed during the Covid-19 pandemic and privacy concerns have added to the challenges. Our study utilises the Unreal Engine to simulate some typical suspicious and intrusion scenes with photorealistic qualities in the context of a virtual building. Add-on programs are implemented to transfer the video stream from virtual PTZ cameras to the Milestone Video Management System and enable users to control those cameras from the graphic client application. Virtual sensors such as fire alarms, temperature sensors and door access controls are implemented similarly, fulfilling the same programmatic VMS interface as real-life sensors. Thanks to this simulation system's extensibility and repeatability, we have consolidated this unified physical threat monitoring system and verified its effectiveness and user-friendliness. Both the simulated Unreal scenes and the software add-ons developed during this study are highly modulated and thereby are ready for reuse in future projects in this area.      
### 51.Connecting Gaits in Energetically Conservative Legged Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.00782.pdf)
>  In this work, we present a nonlinear dynamics perspective on generating and connecting gaits for energetically conservative models of legged systems. In particular, we show that the set of conservative gaits constitutes a connected space of locally defined 1D submanifolds in the gait space. These manifolds are coordinate-free parameterized by energy level. We present algorithms for identifying such families of gaits through the use of numerical continuation methods, generating sets and bifurcation points. To this end, we also introduce several details for the numerical implementation. Most importantly, we establish the necessary condition for the Delassus' matrix to preserve energy across impacts. An important application of our work is with simple models of legged locomotion that are often able to capture the complexity of legged locomotion with just a few degrees of freedom and a small number of physical parameters. We demonstrate the efficacy of our framework on a one-legged hopper with four degrees of freedom.      
### 52.Short-Packet Interleaver against Impulse Interference in Practical Industrial Environments  [ :arrow_down: ](https://arxiv.org/pdf/2203.00770.pdf)
>  The most common cause of transmission failure in Wireless High Performance (WirelessHP) target industry environments is impulse interference. As interleavers are commonly used to improve the reliability on the Orthogonal Frequency Division Multiplexing (OFDM) symbol level for long packet transmission, this paper considers the feasibility of applying short-packet bit interleaving to enhance the impulse/burst interference resisting capability on both OFDM symbol and frame level. Using the Universal Software Radio Peripherals (USRP) and PC hardware platform, the Packet Error Rate (PER) performance of interleaved coded short-packet transmission with Convolutional Codes (CC), Reed-Solomon codes (RS) and RS+CC concatenated codes are tested and analyzed. Applying the IEEE 1613 standard for impulse interference generation, extensive PER tests of CC(1=2) and RS(31; 21)+CC(1=2) concatenated codes are performed. With practical experiments, we prove the effectiveness of bit in terleaved coded short-packet transmission in real factory environments. We also investigate how PER performance depends on the interleavers, codes and impulse interference power and frequency.      
### 53.A Conformer Based Acoustic Model for Robust Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.00725.pdf)
>  This study addresses robust automatic speech recognition (ASR) by introducing a Conformer-based acoustic model. The proposed model builds on a state-of-the-art recognition system using a bi-directional long short-term memory (BLSTM) model with utterance-wise dropout and iterative speaker adaptation, but employs a Conformer encoder instead of the BLSTM network. The Conformer encoder uses a convolution-augmented attention mechanism for acoustic modeling. The proposed system is evaluated on the monaural ASR task of the CHiME-4 corpus. Coupled with utterance-wise normalization and speaker adaptation, our model achieves $6.25\%$ word error rate, which outperforms the previous best system by $8.4\%$ relatively. In addition, the proposed Conformer-based model is $18.3\%$ smaller in model size and reduces training time by $88.5\%$.      
### 54.Subspace-Based Pilot Decontamination in User-Centric Scalable Cell-Free Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.00714.pdf)
>  We consider a cell-free wireless system operated in Time Division Duplex (TDD) mode with localized user-centric clusters of remote radio units (RUs). Since the uplink pilot dimensions per channel coherence slot is limited, co-pilot users might incur mutual pilot contamination. In the current literature, it is assumed that the long-term statistical knowledge of all user channels is available. This enables MMSE channel estimation or simplified dominant subspace projection, which achieves significant pilot decontamination under certain assumptions on the channel covariance matrices. However, estimating the channel covariance matrix or even just its dominant subspace at all RUs forming a user cluster is not an easy task. In fact, if not properly designed, a piloting scheme for such long-term statistics estimation will also be subject to the contamination problem. In this paper, we propose a new channel subspace estimation scheme explicitly designed for cell-free wireless networks. Our scheme is based on 1) a sounding reference signal (SRS) using latin squares wideband frequency hopping, and 2) a subspace estimation method based on robust Principal Component Analysis (R-PCA). The SRS hopping scheme ensures that for any user and any RU participating in its cluster, only a few pilot measurements will contain strong co-pilot interference. These few heavily contaminated measurements are (implicitly) eliminated by R-PCA, which is designed to regularize the estimation and discount the "outlier" measurements. Our simulation results show that the proposed scheme achieves almost perfect subspace knowledge, which in turns yields system performance very close to that with ideal channel state information, thus essentially solving the problem of pilot contamination in cell-free user-centric TDD wireless networks.      
