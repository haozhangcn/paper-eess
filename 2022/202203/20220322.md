# ArXiv eess --Tue, 22 Mar 2022
### 1.A Comprehensive Survey of Spectrum Sharing Schemes from a Standardization and Implementation Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2203.11125.pdf)
>  As the services and requirements of next-generation wireless networks become increasingly diversified, it is estimated that the current frequency bands of mobile network operators (MNOs) will be unable to cope with the immensity of anticipated demands. Due to spectrum scarcity, there has been a growing trend among stakeholders toward identifying practical solutions to make the most productive use of the exclusively allocated bands on a shared basis through spectrum sharing mechanisms. However, due to the technical complexities of these mechanisms, their design presents challenges, as it requires coordination among multiple entities. To address this challenge, in this paper, we begin with a detailed review of the recent literature on spectrum sharing methods, classifying them on the basis of their operational frequency regime that is, whether they are implemented to operate in licensed bands (e.g., licensed shared access (LSA), spectrum access system (SAS), and dynamic spectrum sharing (DSS)) or unlicensed bands (e.g., LTE-unlicensed (LTE-U), licensed assisted access (LAA), MulteFire, and new radio-unlicensed (NR-U)). Then, in order to narrow the gap between the standardization and vendor-specific implementations, we provide a detailed review of the potential implementation scenarios and necessary amendments to legacy cellular networks from the perspective of telecom vendors and regulatory bodies. Next, we analyze applications of artificial intelligence (AI) and machine learning (ML) techniques for facilitating spectrum sharing mechanisms and leveraging the full potential of autonomous sharing scenarios. Finally, we conclude the paper by presenting open research challenges, which aim to provide insights into prospective research endeavors.      
### 2.Collective Decision Making using Attractive and Repulsive Forces in Markovian Opinion Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2203.11116.pdf)
>  In this paper, we model a decision making process in a network of interacting agents using Markovian opinion dynamics, where each agent switches between decisions according to a continuous time Markov chain. We are inspired by the problem of modeling how interaction among road users in a traffic intersection affects the choice that each agent makes concerning where to exit and whether or not to give way. We introduce attractive/repulsive forces that act within and between groups of agents, with the objective of resembling the behaviors emerging in networks where agents make decisions that depend both on their own preferences and the decisions of the surrounding agents. Our model extends the possibility of using Markovian opinion dynamics to describe a wider scope of practical scenarios, in which groups of stochastic agents make collective decisions. In traffic applications, our method could be used in autonomous vehicles to predict the decisions of human road users.      
### 3.Learning Resilient Radio Resource Management Policies with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.11012.pdf)
>  We consider the problems of downlink user selection and power control in wireless networks, comprising multiple transmitters and receivers communicating with each other over a shared wireless medium. To achieve a high aggregate rate, while ensuring fairness across all the receivers, we formulate a resilient radio resource management (RRM) policy optimization problem with per-user minimum-capacity constraints that adapt to the underlying network conditions via learnable slack variables. We reformulate the problem in the Lagrangian dual domain, and show that we can parameterize the user selection and power control policies using a finite set of parameters, which can be trained alongside the slack and dual variables via an unsupervised primal-dual approach thanks to a provably small duality gap. We use a scalable and permutation-equivariant graph neural network (GNN) architecture to parameterize the RRM policies based on a graph topology derived from the instantaneous channel conditions. Through experimental results, we verify that the minimum-capacity constraints adapt to the underlying network configurations and channel conditions. We further demonstrate that, thanks to such adaptation, our proposed method achieves a superior tradeoff between the average rate and the 5th percentile rate -- a metric that quantifies the level of fairness in the resource allocation decisions -- as compared to baseline algorithms.      
### 4.Reconfigurable Optical Networks with Self-Tunable Transceivers: Implementation Options and Control  [ :arrow_down: ](https://arxiv.org/pdf/2203.10978.pdf)
>  This paper reviews methods for autonomous tuning of optical transceivers, based on an overhead management channel between the modules on both sides of the link. Different implementation options for the tuning principle, as well as for the tunable laser are introduced.      
### 5.Controllable energy angular spectrum method  [ :arrow_down: ](https://arxiv.org/pdf/2203.10966.pdf)
>  A controllable energy method, which considers the undersampling issue of the transfer function and valid spectral energy of a source signal, is proposed to implement angular spectrum diffraction calculation in near and far fields. The proposed method provides an optimized frequency boundary $f_{CE}$ within which it always keeps controllable energy to be diffracted. The controllable energy angular spectrum method significantly reduces the number of samples while having the same accuracy as previous angular spectrum methods, implying a higher calculation efficiency. The new perspective of analyzing spectral energy is shown to improve the performance of relevant diffraction calculations.      
### 6.On the energy efficiency of Laser-based Optical Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.10904.pdf)
>  Optical wireless Communication (OWC) is a strong candidate in the next generation (6G) of cellular networks. In this paper, a laser-based optical wireless network is deployed in an indoor environment using Vertical Cavity Surface Emitting Lasers (VCSELS) as transmitters serving multiple users. Specifically, a commercially available low-cost VCSEL operating at 850nm wavelength is used. Considering the confined coverage area of each VCSEL, an array of VCSELs is designed to transmit data to multiple users through narrow beams taking into account eye safety regulations. To manage multi-user interference (MUI), Zero Forcing (ZF) is implemented to maximize the multiplexing gain of the network. The energy efficiency of the network is studied under different laser beam waists to find the effective laser beam size that results in throughput enhancement. The results show that the energy efficiency increases with the laser beam waist. Moreover, using micro lenses placed in front of the VCSELs leads to significant increase in the energy efficiency.      
### 7.Identification of Friction Models for MPC-based Control of a PowerCube Serial Robot  [ :arrow_down: ](https://arxiv.org/pdf/2203.10896.pdf)
>  For model-based control, an accurate and in its complexity suitable representation of the real system is a decisive prerequisite for high and robust control quality. In a structured step-by-step procedure, a model predictive control (MPC) scheme for a Schunk PowerCube robot is derived. Neweul-M$^2$ provides the necessary nonlinear model in symbolical and numerical form. To handle the heavy online computational burden involved with the derived nonlinear model, a linear time-varying MPC scheme is developed based on linearizing the nonlinear system concerning the desired trajectory and the a priori known corresponding feed-forward controller. To improve the identification of the nonlinear friction models of the joints, a nonlinear regression method and the Sparse Identification of Nonlinear Dynamics (SINDy) are compared with each other concerning robustness, online adaptivity, and necessary preprocessing of the input data. Everything is implemented on a slim, low-cost control system with a standard laptop PC.      
### 8.Partially adaptive filtering using randomized projections  [ :arrow_down: ](https://arxiv.org/pdf/2203.10873.pdf)
>  This short note addresses the design of a partially adaptive filter to retrieve a signal of interest in the presence of strong low-rank interference and thermal noise. We consider a generalized sidelobe canceler implementation where the dimension-reducing transformation is build resorting to ideas borrowed from randomized matrix approximations. More precisely, the main subspace of the auxiliary data $Z$ is approximated by $Z\Omega$ where $\Omega$ is a random matrix or a matrix that picks at random columns of $Z$. These transformations do not require eigenvalue decomposition, yet they provide performance similar to those of a principal component filter.      
### 9.The role of regularization in data-driven predictive control  [ :arrow_down: ](https://arxiv.org/pdf/2203.10846.pdf)
>  Data-driven predictive control (DDPC) has been recently proposed as an effective alternative to traditional model-predictive control (MPC) for its unique features of being time-efficient and unbiased with respect to the oracle solution. Nonetheless, it has also been observed in many examples that the noise on the output data may strongly jeopardize the final closed-loop performance, since it affects both the data-based system representation and the control update computed from the online measurements. Recent studies have empirically shown that regularization is potentially a successful tool to counteract the effect of noise. In this paper, the link between the stochastic data matrices and the predictive control problem is studied in detail. Then, leveraging on these results, we delve deep into the role of regularization for data-driven control, discussing when and how it should be applied. A benchmark numerical case study illustrates how control design is simplified when a method inspired to the proposed perspective, called $\gamma$-DDPC, is adopted. Specifically, when regularization can be avoided, no closed-loop experiments are required to tune the regularization weights via cross-validation.      
### 10.Separating Content from Speaker Identity in Speech for the Assessment of Cognitive Impairments  [ :arrow_down: ](https://arxiv.org/pdf/2203.10827.pdf)
>  Deep speaker embeddings have been shown effective for assessing cognitive impairments aside from their original purpose of speaker verification. However, the research found that speaker embeddings encode speaker identity and an array of information, including speaker demographics, such as sex and age, and speech contents to an extent, which are known confounders in the assessment of cognitive impairments. In this paper, we hypothesize that content information separated from speaker identity using a framework for voice conversion is more effective for assessing cognitive impairments and train simple classifiers for the comparative analysis on the DementiaBank Pitt Corpus. Our results show that while content embeddings have an advantage over speaker embeddings for the defined problem, further experiments show their effectiveness depends on information encoded in speaker embeddings due to the inherent design of the architecture used for extracting contents.      
### 11.Longitudinal Self-Supervision for COVID-19 Pathology Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2203.10804.pdf)
>  Quantifying COVID-19 infection over time is an important task to manage the hospitalization of patients during a global pandemic. Recently, deep learning-based approaches have been proposed to help radiologists automatically quantify COVID-19 pathologies on longitudinal CT scans. However, the learning process of deep learning methods demands extensive training data to learn the complex characteristics of infected regions over longitudinal scans. It is challenging to collect a large-scale dataset, especially for longitudinal training. In this study, we want to address this problem by proposing a new self-supervised learning method to effectively train longitudinal networks for the quantification of COVID-19 infections. For this purpose, longitudinal self-supervision schemes are explored on clinical longitudinal COVID-19 CT scans. Experimental results show that the proposed method is effective, helping the model better exploit the semantics of longitudinal data and improve two COVID-19 quantification tasks.      
### 12.A Stochastic Planning Method for Low-carbon Building-level Integrated Energy System Considering Electric-Heat-V2G Coupling  [ :arrow_down: ](https://arxiv.org/pdf/2203.10799.pdf)
>  The concept of low-carbon building is proposed to ameliorate the climate change caused by environmental problems and realize carbon neutrality at the building level in urban areas. In addition, renewable energy curtailment in the power distribution system, as well as low efficiency due to independent operation of traditional energy systems, has been addressed by the application of integrated energy system (IES) to some extent. In this paper, we propose a planning method for low-carbon building-level IES, in which electric vehicles (EV) and the mode of Vehicle to Grid (V2G) are considered and further increase the flexibility of low-carbon buildings. The proposed planning model optimize the investment, operation costs and CO2 emission for building-level IES, so as to achieve the maximum benefit of the construction of the low-carbon building and help the realization of carbon neutrality. Moreover, we consider the uncertainty of distributed renewable energy, multi-energy load fluctuation and the random behavior of EV users, then formulating a two-stage stochastic programming model with chance constraints, in which heuristic moment matching scenario generation (HMMSG) and sample average approximation (SAA) method are applied. In case study, a real IES commercial building in Shanghai, where photovoltaic (PV), energy storage system (ESS), fuel cell (FC), EV, etc. are included as planning options, is used as numerical example to verify the effectiveness of the proposed planning method, with functions of ESS and EV in IES are analyzed in detail in different operation scenarios.      
### 13.Classifications of Skull Fractures using CT Scan Images via CNN with Lazy Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2203.10786.pdf)
>  Classification of skull fracture is a challenging task for both radiologists and researchers. Skull fractures result in broken pieces of bone, which can cut into the brain and cause bleeding and other injury types. So it is vital to detect and classify the fracture very early. In real world, often fractures occur at multiple sites. This makes it harder to detect the fracture type where many fracture types might summarize a skull fracture. Unfortunately, manual detection of skull fracture and the classification process is time-consuming, threatening a patient's life. Because of the emergence of deep learning, this process could be automated. Convolutional Neural Networks (CNNs) are the most widely used deep learning models for image categorization because they deliver high accuracy and outstanding outcomes compared to other models. We propose a new model called SkullNetV1 comprising a novel CNN by taking advantage of CNN for feature extraction and lazy learning approach which acts as a classifier for classification of skull fractures from brain CT images to classify five fracture types. Our suggested model achieved a subset accuracy of 88%, an F1 score of 93%, the Area Under the Curve (AUC) of 0.89 to 0.98, a Hamming score of 92% and a Hamming loss of 0.04 for this seven-class multi-labeled classification.      
### 14.Simple and Efficient LoRa Receiver Scheme for Multi-Path Channel  [ :arrow_down: ](https://arxiv.org/pdf/2203.10783.pdf)
>  This paper presents a novel LoRa (Long Range) receiver operating in frequency selective Multi-Path Channel (MPC). The dechirped received LoRa wave-forms under MPC allows us to derive a simple and efficient LoRa receiver scheme by using a MF (Matched Filter) approach that aims to maximize the SNR (Signal-to-Noise Ratio) at the symbol index frequency of the DFT output. We show that the MF receiver can be seen as RAKE structure where interference peaks related to multipath, exhibited at DFT output, are recombined in a constructive way. Detection performance is driven by channel energy and the benefit of this novel MF/RAKE receiver over original coherent and non-coherent receiver appears only for MPC that exhibits significant paths energy. These two MF and RAKE receivers have however different implementation complexities that are studied in details. We provide in that sense recommendations on which receiver variant to use for real operations, depending on complexity constraints. Finally, the proposed MF/RAKE receiver outperforms previous results on TDEL (Time Delay Estimation LoRa) receiver over MPC, especially at low SNR and higher LoRa Spreading Factor (SF) parameter, at the cost of higher but reasonable complexity.      
### 15.Performance-Robustness Tradeoffs in Adversarially Robust Linear-Quadratic Control  [ :arrow_down: ](https://arxiv.org/pdf/2203.10763.pdf)
>  While $\mathcal{H}_\infty$ methods can introduce robustness against worst-case perturbations, their nominal performance under conventional stochastic disturbances is often drastically reduced. Though this fundamental tradeoff between nominal performance and robustness is known to exist, it is not well-characterized in quantitative terms. Toward addressing this issue, we borrow from the increasingly ubiquitous notion of adversarial training from machine learning to construct a class of controllers which are optimized for disturbances consisting of mixed stochastic and worst-case components. We find that this problem admits a stationary optimal controller that has a simple analytic form closely related to suboptimal $\mathcal{H}_\infty$ solutions. We then provide a quantitative performance-robustness tradeoff analysis, in which system-theoretic properties such as controllability and stability explicitly manifest in an interpretable manner. This provides practitioners with general guidance for determining how much robustness to incorporate based on a priori system knowledge. We empirically validate our results by comparing the performance of our controller against standard baselines, and plotting tradeoff curves.      
### 16.SweiNet: Deep Learning Based Uncertainty Quantification for Ultrasound Shear Wave Elasticity Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2203.10678.pdf)
>  In ultrasound shear wave elasticity (SWE) imaging, a number of algorithms exist for estimating the shear wave speed (SWS) from spatiotemporal displacement data. However, no method provides a well-calibrated and practical uncertainty metric, hindering SWE's clinical adoption and utility in downstream decision-making. Here, we designed a deep learning SWS estimator that simultaneously outputs a quantitative and well-calibrated uncertainty value for each estimate. Our deep neural network (DNN) takes as input a single 2D spatiotemporal plane of tracked displacement data and outputs the two parameters $m$ and $\sigma$ of a log-normal probability distribution. For training and testing, we used in vivo 2D-SWE data of the cervix collected from 30 pregnant subjects, totaling 551 acquisitions and &gt;2 million space-time plots. Points were grouped by uncertainty into bins to assess uncertainty calibration: the predicted uncertainty closely matched the root-mean-square estimation error, with an average absolute percent deviation of 3.84%. We created a leave-one-out ensemble model that estimated uncertainty with better calibration (1.45%) than any individual ensemble member on a held-out patient's data. Lastly, we applied the DNN to an external dataset to evaluate its generalizability. We have made the trained model, SweiNet, openly available to provide the research community with a fast SWS estimator that also outputs a well-calibrated estimate of the predictive uncertainty.      
### 17.A direct geometry processing cartilage generation method using segmented bone models from datasets with poor cartilage visibility  [ :arrow_down: ](https://arxiv.org/pdf/2203.10667.pdf)
>  We present a method to generate subject-specific cartilage for the hip joint. Given bone geometry, our approach is agnostic to image modality, creates conforming interfaces, and is well suited for finite element analysis. We demonstrate our method on ten hip joints showing anatomical shape consistency and well-behaved stress patterns. Our method is fast and may assist in large-scale biomechanical population studies of the hip joint when manual segmentation or training data is not feasible.      
### 18.DeeP-LCC: Data-EnablEd Predictive Leading Cruise Control in Mixed Traffic Flow  [ :arrow_down: ](https://arxiv.org/pdf/2203.10639.pdf)
>  For the control of connected and autonomous vehicles (CAVs), most existing methods focus on model-based strategies. They require explicit knowledge of car-following dynamics of human-driven vehicles that are non-trivial to identify accurately. In this paper, instead of relying on a parametric car-following model, we introduce a data-driven non-parametric strategy, called DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control), to achieve safe and optimal control of CAVs in mixed traffic. We first utilize Willems' fundamental lemma to obtain a data-centric representation of mixed traffic behavior. This is justified by rigorous analysis on controllability and observability properties of mixed traffic. We then employ a receding horizon strategy to solve a finite-horizon optimal control problem at each time step, in which input/output constraints are incorporated for collision-free guarantees. Numerical experiments validate the performance of DeeP-LCC compared to a standard predictive controller that requires an accurate model. Extensive nonlinear traffic simulations further confirm its great potential on improving traffic efficiency, driving safety, and fuel economy.      
### 19.Vocal effort modeling in neural TTS for improving the intelligibility of synthetic speech in noise  [ :arrow_down: ](https://arxiv.org/pdf/2203.10637.pdf)
>  We present a neural text-to-speech (TTS) method that models natural vocal effort variation to improve the intelligibility of synthetic speech in the presence of noise. The method consists of first measuring the spectral tilt of unlabeled conventional speech data, and then conditioning a neural TTS model with normalized spectral tilt among other prosodic factors. Changing spectral tilt and keeping other prosodic factors unchanged enables effective vocal effort control at synthesis time independent of other prosodic factors. By extrapolation of the spectral tilt values beyond what has been seen in the original data, we can generate speech with high vocal effort levels, thus improving the intelligibility of speech in the presence of masking noise. We evaluate the intelligibility and quality of normal speech and speech with increased vocal effort in the presence of various masking noise conditions, and compare these to well-known speech intelligibility-enhancing algorithms. The evaluations show that the proposed method can improve the intelligibility of synthetic speech with little loss in speech quality.      
### 20.ICTs and Forced Migration: A Critical Discourse Review  [ :arrow_down: ](https://arxiv.org/pdf/2203.10633.pdf)
>  The role of information and communication technologies (ICTs) in relation to issues of forced migration has come to the attention of the Information Systems (IS) literature. In this paper we review the interdisciplinary research on the topic, seeking to identify the main discourses in it.      
### 21.Multi-Modal Learning Using Physicians Diagnostics for Optical Coherence Tomography Classification  [ :arrow_down: ](https://arxiv.org/pdf/2203.10622.pdf)
>  In this paper, we propose a framework that incorporates experts diagnostics and insights into the analysis of Optical Coherence Tomography (OCT) using multi-modal learning. To demonstrate the effectiveness of this approach, we create a medical diagnostic attribute dataset to improve disease classification using OCT. Although there have been successful attempts to deploy machine learning for disease classification in OCT, such methodologies lack the experts insights. We argue that injecting ophthalmological assessments as another supervision in a learning framework is of great importance for the machine learning process to perform accurate and interpretable classification. We demonstrate the proposed framework through comprehensive experiments that compare the effectiveness of combining diagnostic attribute features with latent visual representations and show that they surpass the state-of-the-art approach. Finally, we analyze the proposed dual-stream architecture and provide an insight that determine the components that contribute most to classification performance.      
### 22.Interval Dominance based Structural Results for Markov Decision Process  [ :arrow_down: ](https://arxiv.org/pdf/2203.10618.pdf)
>  The textbook proof for monotone optimal policies of a Markov decision process (MDP) requires supermodularity of the rewards and transition probabilities.This paper uses a sufficient condition for interval dominance (called I)to obtain structural results for MDPs under more general conditions. We present several MDP examples where supermodularity does not hold, yet I holds, and so the optimal policy is monotone; these include sigmoidal rewards and perturbed bi-diagonal transition matrices. We also consider MDPs with TP3 transition matrices and concave value functions.      
### 23.Towards Clinical Practice: Design and Implementation of Convolutional Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection from Chest X-Ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2203.10596.pdf)
>  One of the critical tools for early detection and subsequent evaluation of the incidence of lung diseases is chest radiography. This study presents a real-world implementation of a convolutional neural network (CNN) based Carebot Covid app to detect COVID-19 from chest X-ray (CXR) images. Our proposed model takes the form of a simple and intuitive application. Used CNN can be deployed as a STOW-RS prediction endpoint for direct implementation into DICOM viewers. The results of this study show that the deep learning model based on DenseNet and ResNet architecture can detect SARS-CoV-2 from CXR images with precision of 0.981, recall of 0.962 and AP of 0.993.      
### 24.Exascale Grid Optimization (ExaGO) toolkit: An open-source high-performance package for solving large-scale grid optimization problems  [ :arrow_down: ](https://arxiv.org/pdf/2203.10587.pdf)
>  This paper introduces the Exascale Grid Optimization (ExaGO) toolkit, a library for solving large-scale alternating current optimal power flow (ACOPF) problems including stochastic effects, security constraints and multi-period constraints. ExaGO can run on parallel distributed memory platforms, including massively parallel hardware accelerators such as graphical processing units (GPUs). We present the details of the ExaGO library including its architecture, formulations, modeling details, and its performance for several optimization applications.      
### 25.Neuro-physical dynamic load modeling using differentiable parametric optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.10582.pdf)
>  In this work, we investigate a data-driven approach for obtaining a reduced equivalent load model of distribution systems for electromechanical transient stability analysis. The proposed reduced equivalent is a neuro-physical model comprising of a traditional ZIP load model augmented with a neural network. This neuro-physical model is trained through differentiable programming. We discuss the formulation, modeling details, and training of the proposed model set up as a differential parametric program. The performance and accuracy of this neurophysical ZIP load model is presented on a medium-scale 350-bus transmission-distribution network.      
### 26.A Learning Convolutional Neural Network Approach for Network Robustness Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2203.10552.pdf)
>  Network robustness is critical for various societal and industrial networks again malicious attacks. In particular, connectivity robustness and controllability robustness reflect how well a networked system can maintain its connectedness and controllability against destructive attacks, which can be quantified by a sequence of values that record the remaining connectivity and controllability of the network after a sequence of node- or edge-removal attacks. Traditionally, robustness is determined by attack simulations, which are computationally very time-consuming or even practically infeasible. In this paper, an improved method for network robustness prediction is developed based on learning feature representation using convolutional neural network (LFR-CNN). In this scheme, higher-dimensional network data are compressed to lower-dimensional representations, and then passed to a CNN to perform robustness prediction. Extensive experimental studies on both synthetic and real-world networks, both directed and undirected, demonstrate that 1) the proposed LFR-CNN performs better than other two state-of-the-art prediction methods, with significantly lower prediction errors; 2) LFR-CNN is insensitive to the variation of the network size, which significantly extends its applicability; 3) although LFR-CNN needs more time to perform feature learning, it can achieve accurate prediction faster than attack simulations; 4) LFR-CNN not only can accurately predict network robustness, but also provides a good indicator for connectivity robustness, better than the classical spectral measures.      
### 27.Learning Whole Heart Mesh Generation From Patient Images For Computational Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2203.10517.pdf)
>  Patient-specific cardiac modeling combines geometries of the heart derived from medical images and biophysical simulations to predict various aspects of cardiac function. However, generating simulation-suitable models of the heart from patient image data often requires complicated procedures and significant human effort. We present a fast and automated deep-learning method to construct simulation-suitable models of the heart from medical images. The approach constructs meshes from 3D patient images by learning to deform a small set of deformation handles on a whole heart template. For both 3D CT and MR data, this method achieves promising accuracy for whole heart reconstruction, consistently outperforming prior methods in constructing simulation-suitable meshes of the heart. When evaluated on time-series CT data, this method produced more anatomically and temporally consistent geometries than prior methods, and was able to produce geometries that better satisfy modeling requirements for cardiac flow simulations. Our source code will be available on GitHub.      
### 28.Attention Aided CSI Wireless Localization  [ :arrow_down: ](https://arxiv.org/pdf/2203.10506.pdf)
>  Deep neural networks (DNNs) have become a popular approach for wireless localization based on channel state information (CSI). A common practice is to use the raw CSI in the input and allow the network to learn relevant channel representations for mapping to location information. However, various works show that raw CSI can be very sensitive to system impairments and small changes in the environment. On the contrary, hand-designing features may hinder the limits of channel representation learning of the DNN. In this work, we propose attention-based CSI for robust feature learning. We evaluate the performance of attended features in centralized and distributed massive MIMO systems for ray-tracing channels in two non-stationary railway track environments. By comparison to a base DNN, our approach provides exceptional performance.      
### 29.Fundamental Trackability Problems for Iterative Learning Control  [ :arrow_down: ](https://arxiv.org/pdf/2203.10497.pdf)
>  Generally, the classic iterative learning control (ILC) methods focus on finding design conditions for repetitive systems to achieve the perfect tracking of any specified trajectory, whereas they ignore a fundamental problem of ILC: whether the specified trajectory is trackable, or equivalently, whether there exist some inputs for the repetitive systems under consideration to generate the specified trajectory? The current paper contributes to dealing with this problem. Not only is a concept of trackability introduced formally for any specified trajectory in ILC, but also some related trackability criteria are established. Further, the relation between the trackability and the perfect tracking tasks for ILC is bridged, based on which a new convergence analysis approach is developed for ILC by leveraging properties of a functional Cauchy sequence (FCS). Simulation examples are given to verify the effectiveness of the presented trackability criteria and FCS-induced convergence analysis method for ILC.      
### 30.Direct Participation of Dynamic Virtual Power Plants in Secondary Frequency Control  [ :arrow_down: ](https://arxiv.org/pdf/2203.10406.pdf)
>  This paper proposes a novel control strategy in which Renewable Energy Sources (RES) considered in a new Dynamic Virtual Power Plant (DVPP) concept directly participate to Secondary Frequency Control (SFC). This allows full participation of these generators to SFC, i.e., in the same manner as classic synchronous generators by fulfilling identical specifications from both control and contractual points of view. An internal real-time redispatch has been proposed to account in DVPP in order to determine the amount of active power injection by each RES unit for provision of frequency support in secondary level. The whole control scheme is designed to take into account both rapid and slow dynamics of modern power systems which contain both classic synchronous generators and rapid power electronics for renawable energy sources in which DVPP is supposed to be inserted. The performance of secondary frequency control strategy has been validated through simulation studies on a two-area benchmark with mixed wind power plants and classic synchronous generators. This work is part of the H2020 POSYTYF project (<a class="link-external link-https" href="https://posytyf-h2020.eu/" rel="external noopener nofollow">this https URL</a>).      
### 31.Status Updating with an Energy Harvesting Sensor under Partial Battery Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2203.10400.pdf)
>  We consider status updating under inexact knowledge of the battery level of an energy harvesting (EH) sensor that sends status updates about a random process to users via a cache-enabled edge node. More precisely, the control decisions are performed by relying only on the battery level knowledge captured from the last received status update packet. Upon receiving on-demand requests for fresh information from the users, the edge node uses the available information to decide whether to command the sensor to send a status update or to retrieve the most recently received measurement from the cache. We seek for the best actions of the edge node to minimize the average AoI of the served measurements, i.e., average on-demand AoI. Accounting for the partial battery knowledge, we model the problem as a partially observable Markov decision process (POMDP), and, through characterizing its key structures, develop a dynamic programming algorithm to obtain an optimal policy. Simulation results illustrate the threshold-based structure of an optimal policy and show the gains obtained by the proposed optimal POMDP-based policy compared to a request-aware greedy (myopic) policy.      
### 32.Analyzing speaker verification embedding extractors and back-ends under language and channel mismatch  [ :arrow_down: ](https://arxiv.org/pdf/2203.10300.pdf)
>  In this paper, we analyze the behavior and performance of speaker embeddings and the back-end scoring model under domain and language mismatch. We present our findings regarding ResNet-based speaker embedding architectures and show that reduced temporal stride yields improved performance. We then consider a PLDA back-end and show how a combination of small speaker subspace, language-dependent PLDA mixture, and nuisance-attribute projection can have a drastic impact on the performance of the system. Besides, we present an efficient way of scoring and fusing class posterior logit vectors recently shown to perform well for speaker verification task. The experiments are performed using the NIST SRE 2021 setup.      
### 33.Min-Max Latency Optimization Based on Sensed Position State Information in Internet of Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2203.10281.pdf)
>  The dual-function radar communication (DFRC) is an essential technology in Internet of Vehicles (IoV). Consider that the road-side unit (RSU) employs the DFRC signals to sense the vehicles' position state information (PSI), and communicates with the vehicles based on PSI. The objective of this paper is to minimize the maximum communication delay among all vehicles by considering the estimation accuracy constraint of the vehicles' PSI and the transmit power constraint of RSU. By leveraging convex optimization theory, two iterative power allocation algorithms are proposed with different complexities and applicable scenarios. Simulation results indicate that the proposed power allocation algorithm converges and can significantly reduce the maximum transmit delay among vehicles compared with other schemes.      
### 34.Epidemic Propagation under Evolutionary Behavioral Dynamics: Stability and Bifurcation Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2203.10276.pdf)
>  We consider the class of SIS epidemic models in which a large population of individuals chooses whether to adopt protection or to remain unprotected as the epidemic evolves. For a susceptible individual, adopting protection reduces the probability of becoming infected but it comes with a cost that is weighed with the instantaneous risk of becoming infected. An infected individual adopting protection transmits a new infection with a smaller probability compared to an unprotected infected individual. We focus on the replicator evolutionary dynamics to model the evolution of protection decisions by susceptible and infected subpopulations. We completely characterize the existence and local stability of the equilibria of the resulting coupled epidemic and replicator dynamics. We further show how the stability of different equilibrium points gets exchanged as certain parameters change. Finally, we investigate the system behavior under timescale separation between the epidemic and the evolutionary dynamics.      
### 35.Exploiting Cross Domain Acoustic-to-articulatory Inverted Features For Disordered Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.10274.pdf)
>  Articulatory features are inherently invariant to acoustic signal distortion and have been successfully incorporated into automatic speech recognition (ASR) systems for normal speech. Their practical application to disordered speech recognition is often limited by the difficulty in collecting such specialist data from impaired speakers. This paper presents a cross-domain acoustic-to-articulatory (A2A) inversion approach that utilizes the parallel acoustic-articulatory data of the 15-hour TORGO corpus in model training before being cross-domain adapted to the 102.7-hour UASpeech corpus and to produce articulatory features. Mixture density networks based neural A2A inversion models were used. A cross-domain feature adaptation network was also used to reduce the acoustic mismatch between the TORGO and UASpeech data. On both tasks, incorporating the A2A generated articulatory features consistently outperformed the baseline hybrid DNN/TDNN, CTC and Conformer based end-to-end systems constructed using acoustic features only. The best multi-modal system incorporating video modality and the cross-domain articulatory features as well as data augmentation and learning hidden unit contributions (LHUC) speaker adaptation produced the lowest published word error rate (WER) of 24.82% on the 16 dysarthric speakers of the benchmark UASpeech task.      
### 36.SDOAnet: An Efficient Deep Learning-Based DOA Estimation Network for Imperfect Array  [ :arrow_down: ](https://arxiv.org/pdf/2203.10231.pdf)
>  Direction of arrival (DOA) estimation is a fundamental problem in both conventional radar and wireless communication applications and emerging integrated sensing and communication (ISAC) systems. Due to many imperfect factors in the low-cost systems, including the antenna position perturbations, the inconsistent gains/phases, the mutual coupling effect, the nonlinear amplifier effect, etc., the performance of the DOA estimation often degrades significantly. To characterize the realistic array more accurately, a novel deep learning (DL)-based DOA estimation method named super-resolution DOA network (SDOAnet) is proposed in this paper. Different from the existing DL-based DOA methods, our proposed SDOAnet employs the sampled received signals, instead of the covariance matrices of the received signals, as the input of the convolution layers for extracting data features. Moreover, the output of SDOAnet is a vector that is independent of the DOA of targets but can be used to estimate their spatial spectrum. As a result, the same training network can be applied with any number of targets, which significantly reduce the implementation complexity. At last, the convergence speed of our SDOAnet with a low-dimension network structure is much faster than existing DL-based methods. Simulation results show that the proposed SDOAnet outperforms the existing DOA estimation methods with the effect of the imperfect array. The code about the SDOAnet is available online <a class="link-external link-https" href="https://github.com/chenpengseu/SDOAnet.git" rel="external noopener nofollow">this https URL</a>.      
### 37.Reconfigurable Intelligent Surface Aided Sparse DOA Estimation Method With Non-ULA  [ :arrow_down: ](https://arxiv.org/pdf/2203.10222.pdf)
>  The direction of arrival (DOA) estimation problem is addressed in this letter. A reconfigurable intelligent surface (RIS) aided system for the DOA estimation is proposed. Unlike traditional DOA estimation systems, a low-cost system with only one complete functional receiver is given by changing the phases of the reflected signals at the RIS elements to realize the multiple measurements. Moreover, an atomic norm-based method is proposed for the DOA estimation by exploiting the target sparsity in the spatial domain and solved by a semi-definite programming (SDP) method. Furthermore, the RIS elements can be any geometry array for practical consideration, so a transformation matrix is formulated and different from the conventional SDP method. Simulation results show that the proposed method can estimate the DOA more accurately than the existing methods in the non-uniform linear RIS array.      
### 38.Efficient DOA Estimation Method for Reconfigurable Intelligent Surfaces Aided UAV Swarm  [ :arrow_down: ](https://arxiv.org/pdf/2203.10219.pdf)
>  The conventional direction of arrival (DOA) estimation methods are performed with multiple receiving channels. In this paper, a changeling DOA estimation problem is addressed in a different scenario with only one full-functional receiving channel. A new unmanned aerial vehicle (UAV) swarm system using multiple lifted reconfigurable intelligent surface (RIS) is proposed for the DOA estimation. The UAV movement degrades the DOA estimation performance significantly, and the existing atomic norm minimization (ANM) methods cannot be used in the scenario with array perturbation. Specifically, considering the position perturbation of UAVs, a new atomic norm-based DOA estimation method is proposed, where an atomic norm is defined with the parameter of the position perturbation. Then, a customized semi-definite programming (SDP) method is derived to solve the atomic norm-based method, where different from the traditional SDP method, an additional transforming matrix is formulated. Moreover, a gradient descent method is applied to refine the estimated DOA and the position perturbation further. Simulation results show that the proposed method achieves much better DOA estimation performance in the RIS-aided UAV swarm system with only one receiving channel than various benchmark schemes.      
### 39.Optimizing Transmission Infrastructure Investments to Support Line De-energization for Mitigating Wildfire Ignition Risk  [ :arrow_down: ](https://arxiv.org/pdf/2203.10176.pdf)
>  Wildfires pose a growing risk to public safety in regions like the western United States, and, historically, electric power systems have ignited some of the most destructive wildfires. To reduce wildfire ignition risks, power system operators preemptively de-energize high-risk power lines during extreme wildfire conditions as part of "Public Safety Power Shutoff" (PSPS) events. While capable of substantially reducing acute wildfire risks, PSPS events can also result in significant amounts of load shedding as the partially de-energized system may not be able to supply all customer demands. We investigate the extent to which infrastructure investments can support system operations during PSPS events by enabling reduced load shedding and wildfire ignition risk. We consider the installation of grid-scale batteries, solar PV, and line hardening or maintenance measures (e.g., undergrounding or increased vegetation management). Optimally selecting the locations, types, and sizes of these infrastructure investments requires considering the line de-energizations associated with PSPS events. Accordingly, this paper proposes a multi-period optimization formulation that locates and sizes infrastructure investments while simultaneously choosing line de-energizations to minimize wildfire ignition risk and load shedding. The proposed formulation is evaluated using two geolocated test cases along with realistic infrastructure investment parameters and actual wildfire risk data from the US Geological Survey. We evaluate the performance of investment choices by simulating de-energization decisions for the entire 2021 wildfire season with optimized infrastructure placements. With investment decisions varying significantly for different test cases, budgets, and operator priorities, the numerical results demonstrate the proposed formulation's value in tailoring investment choices to different settings.      
### 40.Infinite-Horizon Reach-Avoid Zero-Sum Games via Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.10142.pdf)
>  In this paper, we consider the infinite-horizon reach-avoid zero-sum game problem, where the goal is to find a set in the state space, referred to as the reach-avoid set, such that the system starting at a state therein could be controlled to reach a given target set without violating constraints under the worst-case disturbance. We address this problem by designing a new value function with a contracting Bellman backup, where the super-zero level set, i.e., the set of states where the value function is evaluated to be non-negative, recovers the reach-avoid set. Building upon this, we prove that the proposed method can be adapted to compute the viability kernel, or the set of states which could be controlled to satisfy given constraints, and the backward reachable set, or the set of states that could be driven towards a given target set. Finally, we propose to alleviate the curse of dimensionality issue in high-dimensional problems by extending Conservative Q-Learning, a deep reinforcement learning technique, to learn a value function such that the super-zero level set of the learned value function serves as a (conservative) approximation to the reach-avoid set. Our theoretical and empirical results suggest that the proposed method could learn reliably the reach-avoid set and the optimal control policy even with neural network approximation.      
### 41.AlignTransformer: Hierarchical Alignment of Visual Regions and Disease Tags for Medical Report Generation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10095.pdf)
>  Recently, medical report generation, which aims to automatically generate a long and coherent descriptive paragraph of a given medical image, has received growing research interests. Different from the general image captioning tasks, medical report generation is more challenging for data-driven neural models. This is mainly due to 1) the serious data bias: the normal visual regions dominate the dataset over the abnormal visual regions, and 2) the very long sequence. To alleviate above two problems, we propose an AlignTransformer framework, which includes the Align Hierarchical Attention (AHA) and the Multi-Grained Transformer (MGT) modules: 1) AHA module first predicts the disease tags from the input image and then learns the multi-grained visual features by hierarchically aligning the visual regions and disease tags. The acquired disease-grounded visual features can better represent the abnormal regions of the input image, which could alleviate data bias problem; 2) MGT module effectively uses the multi-grained features and Transformer framework to generate the long medical report. The experiments on the public IU-Xray and MIMIC-CXR datasets show that the AlignTransformer can achieve results competitive with state-of-the-art methods on the two datasets. Moreover, the human evaluation conducted by professional radiologists further proves the effectiveness of our approach.      
### 42.Label conditioned segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10091.pdf)
>  Semantic segmentation is an important task in computer vision that is often tackled with convolutional neural networks (CNNs). A CNN learns to produce pixel-level predictions through training on pairs of images and their corresponding ground-truth segmentation labels. For segmentation tasks with multiple classes, the standard approach is to use a network that computes a multi-channel probabilistic segmentation map, with each channel representing one class. In applications where the image grid size (e.g., when it is a 3D volume) and/or the number of labels is relatively large, the standard (baseline) approach can become prohibitively expensive for our computational resources. In this paper, we propose a simple yet effective method to address this challenge. In our approach, the segmentation network produces a single-channel output, while being conditioned on a single class label, which determines the output class of the network. Our method, called label conditioned segmentation (LCS), can be used to segment images with a very large number of classes, which might be infeasible for the baseline approach. We also demonstrate in the experiments that label conditioning can improve the accuracy of a given backbone architecture, likely, thanks to its parameter efficiency. Finally, as we show in our results, an LCS model can produce previously unseen fine-grained labels during inference time, when only coarse labels were available during training. We provide all of our code here: <a class="link-external link-https" href="https://github.com/tym002/Label-conditioned-segmentation" rel="external noopener nofollow">this https URL</a>      
### 43.Physics-driven Synthetic Data Learning for Biomedical Magnetic Resonance  [ :arrow_down: ](https://arxiv.org/pdf/2203.11178.pdf)
>  Deep learning has innovated the field of computational imaging. One of its bottlenecks is unavailable or insufficient training data. This article reviews an emerging paradigm, imaging physics-based data synthesis (IPADS), that can provide huge training data in biomedical magnetic resonance without or with few real data. Following the physical law of magnetic resonance, IPADS generates signals from differential equations or analytical solution models, making the learning more scalable, explainable, and better protecting privacy. Key components of IPADS learning, including signal generation models, basic deep learning network structures, enhanced data generation, and learning methods are discussed. Great potentials of IPADS have been demonstrated by representative applications in fast imaging, ultrafast signal reconstruction and accurate parameter quantification. Finally, open questions and future work have been discussed.      
### 44.Operator Sketching for Deep Unrolling Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.11156.pdf)
>  In this work we propose a new paradigm for designing efficient deep unrolling networks using operator sketching. The deep unrolling networks are currently the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, especially the 3D cone-beam X-ray CT and 4D MRI imaging, the deep unrolling schemes typically become inefficient both in terms of memory and computation, due to the need of computing multiple times the high-dimensional forward and adjoint operators. Recently researchers have found that such limitations can be partially addressed by stochastic unrolling with subsets of operators, inspired by the success of stochastic first-order optimization. In this work, we propose a further acceleration upon stochastic unrolling, using sketching techniques to approximate products in the high-dimensional image space. The operator sketching can be jointly applied with stochastic unrolling for the best acceleration and compression performance. Our numerical experiments on X-ray CT image reconstruction demonstrate the remarkable effectiveness of our sketched unrolling schemes.      
### 45.Individualizing Head-Related Transfer Functions for Binaural Acoustic Applications  [ :arrow_down: ](https://arxiv.org/pdf/2203.11138.pdf)
>  A Head Related Transfer Function (HRTF) characterizes how a human ear receives sounds from a point in space, and depends on the shapes of one's head, pinna, and torso. Accurate estimations of HRTFs for human subjects are crucial in enabling binaural acoustic applications such as sound localization and 3D sound spatialization. Unfortunately, conventional approaches for HRTF estimation rely on specialized devices or lengthy measurement processes. This work proposes a novel lightweight method for HRTF individualization that can be implemented using commercial-off-the-shelf components and performed by average users in home settings. The proposed method has two key components: a generative neural network model that can be individualized to predict HRTFs of new subjects from sparse measurements, and a lightweight measurement procedure that collects HRTF data from spatial locations. Extensive experiments using a public dataset and in house measurement data from 10 subjects of different ages and genders, show that the individualized models significantly outperform a baseline model in the accuracy of predicted HRTFs. To further demonstrate the advantages of individualized HRTFs, we implement two prototype applications for binaural localization and acoustic spatialization. We find that the performance of a localization model is improved by 15 degree after trained with individualized HRTFs. Furthermore, in hearing tests, the success rate of correctly identifying the azimuth direction of incoming sounds increases by 183% after individualization.      
### 46.Differentiable Duration Modeling for End-to-End Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2203.11049.pdf)
>  Parallel text-to-speech (TTS) models have recently enabled fast and highly-natural speech synthesis. However, such models typically require external alignment models, which are not necessarily optimized for the decoder as they are not jointly trained. In this paper, we propose a differentiable duration method for learning monotonic alignments between input and output sequences. Our method is based on a soft-duration mechanism that optimizes a stochastic process in expectation. Using this differentiable duration method, a direct text to waveform TTS model is introduced to produce raw audio as output instead of performing neural vocoding. Our model learns to perform high-fidelity speech synthesis through a combination of adversarial training and matching the total ground-truth duration. Experimental results show that our model obtains competitive results while enjoying a much simpler training pipeline. Audio samples are available online.      
### 47.Multi-View Dreaming: Multi-View World Model with Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.11024.pdf)
>  In this paper, we propose Multi-View Dreaming, a novel reinforcement learning agent for integrated recognition and control from multi-view observations by extending Dreaming. Most current reinforcement learning method assumes a single-view observation space, and this imposes limitations on the observed data, such as lack of spatial information and occlusions. This makes obtaining ideal observational information from the environment difficult and is a bottleneck for real-world robotics applications. In this paper, we use contrastive learning to train a shared latent space between different viewpoints, and show how the Products of Experts approach can be used to integrate and control the probability distributions of latent states for multiple viewpoints. We also propose Multi-View DreamingV2, a variant of Multi-View Dreaming that uses a categorical distribution to model the latent state instead of the Gaussian distribution. Experiments show that the proposed method outperforms simple extensions of existing methods in a realistic robot control task.      
### 48.Spoofing-Aware Speaker Verification with Unsupervised Domain Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10992.pdf)
>  In this paper, we initiate the concern of enhancing the spoofing robustness of the automatic speaker verification (ASV) system, without the primary presence of a separate countermeasure module. We start from the standard ASV framework of the ASVspoof 2019 baseline and approach the problem from the back-end classifier based on probabilistic linear discriminant analysis. We employ three unsupervised domain adaptation techniques to optimize the back-end using the audio data in the training partition of the ASVspoof 2019 dataset. We demonstrate notable improvements on both logical and physical access scenarios, especially on the latter where the system is attacked by replayed audios, with a maximum of 36.1% and 5.3% relative improvement on bonafide and spoofed cases, respectively. We perform additional studies such as per-attack breakdown analysis, data composition, and integration with a countermeasure system at score-level with Gaussian back-end.      
### 49.SOLIS: Autonomous Solubility Screening using Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.10970.pdf)
>  Accelerating material discovery has tremendous societal and industrial impact, particularly for pharmaceuticals and clean energy production. Many experimental instruments have some degree of automation, facilitating continuous running and higher throughput. However, it is common that sample preparation is still carried out manually. This can result in researchers spending a significant amount of their time on repetitive tasks, which introduces errors and can prohibit production of statistically relevant data. Crystallisation experiments are common in many chemical fields, both for purification and in polymorph screening experiments. The initial step often involves a solubility screen of the molecule; that is, understanding whether molecular compounds have dissolved in a particular solvent. This usually can be time consuming and work intensive. Moreover, accurate knowledge of the precise solubility limit of the molecule is often not required, and simply measuring a threshold of solubility in each solvent would be sufficient. To address this, we propose a novel cascaded deep model that is inspired by how a human chemist would visually assess a sample to determine whether the solid has completely dissolved in the solution. In this paper, we design, develop, and evaluate the first fully autonomous solubility screening framework, which leverages state-of-the-art methods for image segmentation and convolutional neural networks for image classification. To realise that, we first create a dataset comprising different molecules and solvents, which is collected in a real-world chemistry laboratory. We then evaluated our method on the data recorded through an eye-in-hand camera mounted on a seven degree-of-freedom robotic manipulator, and show that our model can achieve 99.13% test accuracy across various setups.      
### 50.Active Meta-Learner for Log Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2203.10960.pdf)
>  The analysis of logs is a vital activity undertaken for cyber investigation, digital forensics and fault detection to enhance system and cyber resilience. However, performing log analysis is a complex task. It requires extensive knowledge of how the logs are generated and the format of the log entries used. Also, it requires extensive knowledge or expertise in the identifying anomalous log entries from normal or benign log entries. This is especially complex when the forms of anomalous entries are constrained by what are the known forms of internal or external attacks techniques or the varied forms of disruptions that may exists. New or evasive forms of such disruptions are difficult to define. The challenge of log analysis is further complicated by the volume of log entries. Even with the availability of such log data, labelling such log entries would be a massive undertaking. Hence this research seeks to address these challenges with its novel Deep Learning model that learns and improves itself progressively with inputs or corrections provided when available. The practical application of such model construct facilitates log analysis or review with abilities to learn or incorporate new patterns to spot anomalies or ignore false positives.      
### 51.Dynamic Certification for Autonomous Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.10950.pdf)
>  Autonomous systems are often deployed in complex sociotechnical environments, such as public roads, where they must behave safely and securely. Unlike many traditionally engineered systems, autonomous systems are expected to behave predictably in varying "open world" environmental contexts that cannot be fully specified formally. As a result, assurance about autonomous systems requires us to develop new certification methods and mathematical tools that can bound the uncertainty engendered by these diverse deployment scenarios, rather than relying on static tools.      
### 52.OWC-enabled Spine and Leaf Architecture Towards Energy Efficient Data Center Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.10892.pdf)
>  Due to the emergence of new paradigms and services such as 5G/6G, IoT, and more, current deployed wired Data Center Networks (DCNs) are not meeting the required performance metrics due to their limited reconfigurability, scalability, and throughput. To that end, wireless DCNs using technologies such as Optical Wireless Communication (OWC) have become viable and costeffective solutions as they offer higher capacity, better energy efficiency, and better scalability. This paper proposes an OWC-based spine and leaf DCNs where the leaf switches are enabled with OWC transceivers, and the spine switches are replaced by Access Points (APs) in the ceiling connected to a backbone network. The APs are interconnected through a Passive Optical Network (PON) that also connects the architecture with upper network layers. An Infrared (IR) OWC system that employs Wavelength Division Multiplexing (WDM) is proposed to enhance the DCN downlink communication. The simulation (i.e., channel modeling) results show that our proposed data center links achieve good data rates in the data center up to 15 Gbps. For the PON, Arrayed Waveguide Grating Routers (AWGRs) that enable WDM are proposed to connect the APs. We evaluate the performance of the considered architecture in term of its power efficiency compared to traditional spine and leaf data centers. The results show that the OWC-enabled DCN reduces the power consumption by 42% compared to traditional the spine and leaf architecture.      
### 53.Multi-class versus One-class classifier in spontaneous speech analysis oriented to Alzheimer Disease diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2203.10837.pdf)
>  Most of medical developments require the ability to identify samples that are anomalous with respect to a target group or control group, in the sense they could belong to a new, previously unseen class or are not class data. In this case when there are not enough data to train two-class One-class classification appear like an available solution. On the other hand non-linear approaches could give very useful information. The aim of our project is to contribute to earlier diagnosis of AD and better estimates of its severity by using automatic analysis performed through new biomarkers extracted from speech signal. The methods selected in this case are speech biomarkers oriented to Spontaneous Speech and Emotional Response Analysis. In this approach One-class classifiers and two-class classifiers are analyzed. The use of information about outlier and Fractal Dimension features improves the system performance.      
### 54.Perceptual Features as Markers of Parkinson's Disease: The Issue of Clinical Interpretability  [ :arrow_down: ](https://arxiv.org/pdf/2203.10830.pdf)
>  Up to 90% of patients with Parkinson's disease (PD) suffer from hypokinetic dysathria (HD) which is also manifested in the field of phonation. Clinical signs of HD like monoloudness, monopitch or hoarse voice are usually quantified by conventional clinical interpretable features (jitter, shimmer, harmonic-to-noise ratio, etc.). This paper provides large and robust insight into perceptual analysis of 5 Czech vowels of 84 PD patients and proves that despite the clinical inexplicability the perceptual features outperform the conventional ones, especially in terms of discrimination power (classification accuracy ACC = 92 %, sensitivity SEN = 93 %, specificity SPE = 92 %) and partial correlation with clinical scores like UPDRS (Unified Parkinson's disease rating scale), MMSE (Mini-mental state examination) or FOG (Freezing of gait questionnaire), where p &lt; 0.0001.      
### 55.Graph Neural Networks for Wireless Communications: From Theory to Practice  [ :arrow_down: ](https://arxiv.org/pdf/2203.10800.pdf)
>  Deep learning-based approaches have been developed to solve challenging problems in wireless communications, leading to promising results. Early attempts adopted neural network architectures inherited from applications such as computer vision. They often require huge amounts of training samples (i.e., poor generalization), and yield poor performance in large-scale networks (i.e., poor scalability). To resolve these issues, graph neural networks (GNNs) have been recently adopted, as they can effectively exploit the domain knowledge, i.e., the graph topology in wireless communication problems. GNN-based methods can achieve near-optimal performance in large-scale networks and generalize well under different system settings, but the theoretical underpinnings and design guidelines remain elusive, which may hinder their practical implementations. This paper endeavors to fill both the theoretical and practical gaps. For theoretical guarantees, we prove that GNNs achieve near-optimal performance in wireless networks with much fewer training samples than traditional neural architectures. Specifically, to solve an optimization problem on an $n$-node graph (where the nodes may represent users, base stations, or antennas), GNNs' generalization error and required number of training samples are $\mathcal{O}(n)$ and $\mathcal{O}(n^2)$ times lower than the unstructured multi-layer perceptrons. For design guidelines, we propose a unified framework that is applicable to general design problems in wireless networks, which includes graph modeling, neural architecture design, and theory-guided performance enhancement. Extensive simulations, which cover a variety of important problems and network settings, verify our theory and effectiveness of the proposed design framework.      
### 56.Phase-Aware Spoof Speech Detection Based on Res2Net with Phase Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.10793.pdf)
>  The spoof speech detection (SSD) is the essential countermeasure for automatic speaker verification systems. Although SSD with magnitude features in the frequency domain has shown promising results, the phase information also can be important to capture the artefacts of certain types of spoofing attacks. Thus, both magnitude and phase features must be considered to ensure the generalization ability to diverse types of spoofing attacks. In this paper, we investigate the failure reason of feature-level fusion of the previous works through the entropy analysis from which we found that the randomness difference between magnitude and phase features is large, which can interrupt the feature-level fusion via backend neural network; thus, we propose a phase network to reduce that difference. Our SSD system: phase network equipped Res2Net achieved significant performance improvement, specifically in the spoofing attack for which the phase information is considered to be important. Also, we demonstrate our SSD system in both known- and unknown-kind SSD scenarios for practical applications.      
### 57.Intelligent control of a single-link flexible manipulator using sliding modes and artificial neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.10771.pdf)
>  This letter presents a new intelligent control scheme for the accurate trajectory tracking of flexible link manipulators. The proposed approach is mainly based on a sliding mode controller for underactuated systems with an embedded artificial neural network to deal with modeling inaccuracies. The adopted neural network only needs a single input and one hidden layer, which drastically reduces the computational complexity of the control law and allows its implementation in low-power microcontrollers. Online learning, rather than supervised offline training, is chosen to allow the weights of the neural network to be adjusted in real time during the tracking. Therefore, the resulting controller is able to cope with the underactuating issues and to adapt itself by learning from experience, which grants the capacity to deal with plant dynamics properly. The boundedness and convergence properties of the tracking error are proved by evoking Barbalat's lemma in a Lyapunov-like stability analysis. Experimental results obtained with a small single-link flexible manipulator show the efficacy of the proposed control scheme, even in the presence of a high level of uncertainty and noisy signals.      
### 58.WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses  [ :arrow_down: ](https://arxiv.org/pdf/2203.10750.pdf)
>  In this paper, we develop a new multi-singer Chinese neural singing voice synthesis (SVS) system named WeSinger. To improve the accuracy and naturalness of synthesized singing voice, we design several specifical modules and techniques: 1) A deep bi-directional LSTM based duration model with multi-scale rhythm loss and post-processing step; 2) A Transformer-alike acoustic model with progressive pitch-weighted decoder loss; 3) a 24 kHz pitch-aware LPCNet neural vocoder to produce high-quality singing waveforms; 4) A novel data augmentation method with multi-singer pre-training for stronger robustness and naturalness. Both quantitative and qualitative evaluation results demonstrate the effectiveness of WeSinger in terms of accuracy and naturalness, and WeSinger achieves state-of-the-art performance on the public corpus Opencpop. Some synthesized singing samples are available online\footnote{<a class="link-external link-https" href="https://zzw922cn.github.io/wesinger" rel="external noopener nofollow">this https URL</a>}      
### 59.RareGAN: Generating Samples for Rare Classes  [ :arrow_down: ](https://arxiv.org/pdf/2203.10674.pdf)
>  We study the problem of learning generative adversarial networks (GANs) for a rare class of an unlabeled dataset subject to a labeling budget. This problem is motivated from practical applications in domains including security (e.g., synthesizing packets for DNS amplification attacks), systems and networking (e.g., synthesizing workloads that trigger high resource usage), and machine learning (e.g., generating images from a rare class). Existing approaches are unsuitable, either requiring fully-labeled datasets or sacrificing the fidelity of the rare class for that of the common classes. We propose RareGAN, a novel synthesis of three key ideas: (1) extending conditional GANs to use labelled and unlabelled data for better generalization; (2) an active learning approach that requests the most useful labels; and (3) a weighted loss function to favor learning the rare class. We show that RareGAN achieves a better fidelity-diversity tradeoff on the rare class than prior work across different applications, budgets, rare class fractions, GAN losses, and architectures.      
### 60.Multimodal learning-based inversion models for the space-time reconstruction of satellite-derived geophysical fields  [ :arrow_down: ](https://arxiv.org/pdf/2203.10640.pdf)
>  For numerous earth observation applications, one may benefit from various satellite sensors to address the reconstruction of some process or information of interest. A variety of satellite sensors deliver observation data with different sampling patterns due satellite orbits and/or their sensitivity to atmospheric conditions (e.g., clour cover, heavy rains,...). Beyond the ability to account for irregularly-sampled observations, the definition of model-driven inversion methods is often limited to specific case-studies where one can explicitly derive a physical model to relate the different observation sources. Here, we investigate how end-to-end learning schemes provide new means to address multimodal inversion problems. The proposed scheme combines a variational formulation with trainable observation operators, {\em a priori} terms and solvers. Through an application to space oceanography, we show how this scheme can successfully extract relevant information from satellite-derived sea surface temperature images and enhance the reconstruction of sea surface currents issued from satellite altimetry data.      
### 61.The Dark Side: Security Concerns in Machine Learning for EDA  [ :arrow_down: ](https://arxiv.org/pdf/2203.10597.pdf)
>  The growing IC complexity has led to a compelling need for design efficiency improvement through new electronic design automation (EDA) methodologies. In recent years, many unprecedented efficient EDA methods have been enabled by machine learning (ML) techniques. While ML demonstrates its great potential in circuit design, however, the dark side about security problems, is seldomly discussed. This paper gives a comprehensive and impartial summary of all security concerns we have observed in ML for EDA. Many of them are hidden or neglected by practitioners in this field. In this paper, we first provide our taxonomy to define four major types of security concerns, then we analyze different application scenarios and special properties in ML for EDA. After that, we present our detailed analysis of each security concern with experiments.      
### 62.Synergy between 6G and AI: Open Future Horizons and Impending Security Risks  [ :arrow_down: ](https://arxiv.org/pdf/2203.10534.pdf)
>  This paper investigates the synergy between 6G and AI. It argues that they can unlock future horizons, by discussing how they can address future challenges in healthcare, transportation, virtual reality, education, resource management, robotics, in addition to public safety and warfare. However, these great opportunities come also with greater risk. Therefore, the paper provides an overview of the security risks and challenges, along with possible mitigation techniques.      
### 63.ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2203.10473.pdf)
>  In recent years, the neural network-based model for multi-speaker text-to-speech synthesis (TTS) has made significant progress. However, the current speaker encoder models used in these methods cannot capture enough speaker information. In this paper, we propose an end-to-end method that is able to generate high-quality speech and better similarity for both seen and unseen speakers by introducing a more powerful speaker encoder. The method consists of three separately trained components: a speaker encoder based on the state-of-the-art TDNN-based ECAPA-TDNN derived from speaker verification task, a FastSpeech2 based synthesizer, and a HiFi-GAN vocoder. By comparing different speaker encoder models, our proposed method can achieve better naturalness and similarity in seen and unseen test sets. To efficiently evaluate our synthesized speech, we are the first to adopt deep-learning-based automatic MOS evaluation methods to assess our results, and these methods show great potential in automatic speech quality assessment.      
### 64.A Study on Robustness to Perturbations for Representations of Environmental Sound  [ :arrow_down: ](https://arxiv.org/pdf/2203.10425.pdf)
>  Audio applications involving environmental sound analysis increasingly use general-purpose audio representations, also known as embeddings, for transfer learning. Recently, Holistic Evaluation of Audio Representations (HEAR) evaluated twenty-nine embedding models on nineteen diverse tasks. However, the evaluation's effectiveness depends on the variation already captured within a given dataset. Therefore, for a given data domain, it is unclear how the representations would be affected by the variations caused by myriad microphones' range and acoustic conditions -- commonly known as channel effects. We aim to extend HEAR to evaluate invariance to channel effects in this work. To accomplish this, we imitate channel effects by injecting perturbations to the audio signal and measure the shift in the new (perturbed) embeddings with three distance measures, making the evaluation domain-dependent but not task-dependent. Combined with the downstream performance, it helps us make a more informed prediction of how robust the embeddings are to the channel effects. We evaluate two embeddings -- YAMNet, and OpenL$^3$ on monophonic (UrbanSound8K) and polyphonic (SONYC UST) datasets. We show that one distance measure does not suffice in such task-independent evaluation. Although Frchet Audio Distance (FAD) correlates with the trend of the performance drop in the downstream task most accurately, we show that we need to study this in conjunction with the other distances to get a clear understanding of the overall effect of the perturbation. In terms of the embedding performance, we find OpenL$^3$ to be more robust to YAMNet, which aligns with the HEAR evaluation.      
### 65.Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source Mixed Sampling and Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.10395.pdf)
>  Autonomous vehicles utilize urban scene segmentation to understand the real world like a human and react accordingly. Semantic segmentation of normal scenes has experienced a remarkable rise in accuracy on conventional benchmarks. However, a significant portion of real-life accidents features abnormal scenes, such as those with object deformations, overturns, and unexpected traffic behaviors. Since even small mis-segmentation of driving scenes can lead to serious threats to human lives, the robustness of such models in accident scenarios is an extremely important factor in ensuring safety of intelligent transportation systems. <br>In this paper, we propose a Multi-source Meta-learning Unsupervised Domain Adaptation (MMUDA) framework, to improve the generalization of segmentation transformers to extreme accident scenes. In MMUDA, we make use of Multi-Domain Mixed Sampling to augment the images of multiple-source domains (normal scenes) with the target data appearances (abnormal scenes). To train our model, we intertwine and study a meta-learning strategy in the multi-source setting for robustifying the segmentation results. We further enhance the segmentation backbone (SegFormer) with a HybridASPP decoder design, featuring large window attention spatial pyramid pooling and strip pooling, to efficiently aggregate long-range contextual dependencies. Our approach achieves a mIoU score of 46.97% on the DADA-seg benchmark, surpassing the previous state-of-the-art model by more than 7.50%. Code will be made publicly available at <a class="link-external link-https" href="https://github.com/xinyu-laura/MMUDA" rel="external noopener nofollow">this https URL</a>.      
### 66.Differential Private Discrete Noise Adding Mechanism: Conditions, Properties and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2203.10323.pdf)
>  Differential privacy is a standard framework to quantify the privacy loss in the data anonymization process. To preserve differential privacy, a random noise adding mechanism is widely adopted, where the trade-off between data privacy level and data utility is of great concern. The privacy and utility properties for the continuous noise adding mechanism have been well studied. However, the related works are insufficient for the discrete random mechanism on discretely distributed data, e.g., traffic data, health records. This paper focuses on the discrete random noise adding mechanisms. We study the basic differential privacy conditions and properties for the general discrete random mechanisms, as well as the trade-off between data privacy and data utility. Specifically, we derive a sufficient and necessary condition for discrete epsilon-differential privacy and a sufficient condition for discrete (epsilon, delta)-differential privacy, with the numerical estimation of differential privacy parameters. These conditions can be applied to analyze the differential privacy properties for the discrete noise adding mechanisms with various kinds of noises. Then, with the differential privacy guarantees, we propose an optimal discrete epsilon-differential private noise adding mechanism under the utility-maximization framework, where the utility is characterized by the similarity of the statistical properties between the mechanism's input and output. For this setup, we find that the class of the discrete noise probability distributions in the optimal mechanism is Staircase-shaped.      
### 67.Hybrid Active and Passive Sensing for SLAM in Wireless Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.10267.pdf)
>  Integrating sensing functions into future mobile equipment has become an important trend. Realizing different types of sensing and achieving mutual enhancement under the existing communication hardware architecture is a crucial challenge in realizing the deep integration of sensing and communication. In the 5G New Radio context, active sensing can be performed through uplink beam sweeping on the user equipment (UE) side to observe the surrounding environment. In addition, the UE can perform passive sensing through downlink channel estimation to measure the multipath component (MPC) information. This study is the first to develop a hybrid simultaneous localization and mapping (SLAM) mechanism that combines active and passive sensing, in which mutual enhancement between the two sensing modes is realized in communication systems. Specifically, we first establish a common feature associated with the reflective surface to bridge active and passive sensing, thus enabling information fusion. Based on the common feature, we can attain physical anchor initialization through MPC with the assistance of active sensing. Then, we extend the classic probabilistic data association SLAM mechanism to achieve UE localization and continuously refine the physical anchor and target reflections through the subsequent passive sensing. Numerical results show that the proposed hybrid active and passive sensing-based SLAM mechanism can work successfully in tricky scenarios without any prior information on the floor plan, anchors, or agents. Moreover, the proposed algorithm demonstrates significant performance gains compared with active or passive sensing only mechanisms.      
### 68.Similarity and Content-based Phonetic Self Attention for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.10252.pdf)
>  Transformer-based speech recognition models have achieved great success due to the self-attention (SA) mechanism that utilizes every frame in the feature extraction process. Especially, SA heads in lower layers capture various phonetic characteristics by the query-key dot product, which is designed to compute the pairwise relationship between frames. In this paper, we propose a variant of SA to extract more representative phonetic features. The proposed phonetic self-attention (phSA) is composed of two different types of phonetic attention; one is similarity-based and the other is content-based. In short, similarity-based attention utilizes the correlation between frames while content-based attention only considers each frame without being affected by others. We identify which parts of the original dot product are related to two different attention patterns and improve each part by simple modifications. Our experiments on phoneme classification and speech recognition show that replacing SA with phSA for lower layers improves the recognition performance without increasing the latency and the parameter size.      
### 69.A Track-Wise Ensemble Event Independent Network for Polyphonic Sound Event Localization and Detection  [ :arrow_down: ](https://arxiv.org/pdf/2203.10228.pdf)
>  Polyphonic sound event localization and detection (SELD) aims at detecting types of sound events with corresponding temporal activities and spatial locations. In this paper, a track-wise ensemble event independent network with a novel data augmentation method is proposed. The proposed model is based on our previous proposed Event-Independent Network V2 and is extended by conformer blocks and dense blocks. The track-wise ensemble model with track-wise output format is proposed to solve an ensemble model problem for track-wise output format that track permutation may occur among different models. The data augmentation approach contains several data augmentation chains, which are composed of random combinations of several data augmentation operations. The method also utilizes log-mel spectrograms, intensity vectors, and Spatial Cues-Augmented Log-Spectrogram (SALSA) for different models. We evaluate our proposed method in the Task of the L3DAS22 challenge and obtain the top ranking solution with a location-dependent F-score to be 0.699. Source code is released.      
### 70.Local Partial Zero-Forcing Combining for Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.10224.pdf)
>  Cell-free massive multiple-input multiple-output (MIMO) provides more uniform spectral efficiency (SE) for users (UEs) than cellular technology. The main challenge to achieve the benefits of cell-free massive MIMO is to realize signal processing in a scalable way. In this paper, we consider scalable fullpilot zero-forcing (FZF), partial FZF (PFZF), protective weak PFZF (PWPFZF), and local regularized ZF (LRZF) combining by exploiting channel statistics. We derive closed-form expressions of the uplink SE for FZF, PFZF, and PWPFZF combining with large-scale fading decoding over independent Rayleigh fading channels, taking channel estimation errors and pilot contamination into account. Moreover, we investigate the impact of the number of pilot sequences, antennas per AP, and APs on the performance. Numerical results show that LRZF provides the highest SE. However, PWPFZF is preferable when the number of pilot sequences is large and the number of antennas per AP is small. The reason is that PWPFZF has lower computational complexity and the SE expression can be computed in closed-form. Furthermore, we investigate the performance of PWPFZF combining with fractional power control and the numerical results show that it improves the performance of weak UEs and realizes uniformly good service for all UEs in a scalable fashion.      
### 71.UAV Trajectory and Beamforming Optimization for Integrated Periodic Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2203.10223.pdf)
>  Unmanned aerial vehicle (UAV) is expected to bring transformative improvement to the integrated sensing and communication (ISAC) system. However, due to shared spectrum resources, it is challenging to achieve a critical trade-off between these two integrated functionalities. To address this issue, we propose in this paper a new integrated \emph{periodic} sensing and communication mechanism for the UAV-enable ISAC system. Specifically, the user achievable rate is maximized via jointly optimizing UAV trajectory, transmit precoder, and sensing start instant, subject to the sensing frequency and beam pattern gain constraints. Despite that this problem is highly non-convex and involves an infinite number of variables, we obtain the optimal transmit precoder and derive the optimal achievable rate in closed-form for any given UAV location to facilitate the UAV trajectory design. Furthermore, we first prove the structural symmetry between optimal solutions in different ISAC frames without location constraints and then propose a high-quality UAV trajectory and sensing optimization algorithm for the general location-constrained case. Simulation results corroborate the effectiveness of the proposed design and also unveil a more flexible trade-off in ISAC systems over benchmark schemes.      
### 72.Online Guaranteed Reachable Set Approximation for Systems with Changed Dynamics and Control Authority  [ :arrow_down: ](https://arxiv.org/pdf/2203.10220.pdf)
>  This work presents a method of efficiently computing inner and outer approximations of forward reachable sets for nonlinear control systems with changed dynamics and diminished control authority, given an a priori computed reachable set for the nominal system. The method functions by shrinking or inflating a precomputed reachable set based on prior knowledge of the system's trajectory deviation growth dynamics, depending on whether an inner approximation or outer approximation is desired. These dynamics determine an upper bound on the minimal deviation between two trajectories emanating from the same point that are generated on the nominal system using nominal control inputs, and by the impaired system based on the diminished set of control inputs, respectively. The dynamics depend on the given Hausdorff distance bound between the nominal set of admissible controls and the possibly unknown impaired space of admissible controls, as well as a bound on the rate change between the nominal and off-nominal dynamics. Because of its computational efficiency compared to direct computation of the off-nominal reachable set, this procedure can be applied to on-board fault-tolerant path planning and failure recovery. In addition, the proposed algorithm does not require convexity of the reachable sets unlike our previous work, thereby making it suitable for general use. We raise a number of implementational considerations for our algorithm, and we present three illustrative examples, namely an application to the heading dynamics of a ship, a lower triangular dynamical system, and a system of coupled linear subsystems.      
### 73.Coordinated Pose Control of Mobile Manipulation with an Unstable Bikebot Platform  [ :arrow_down: ](https://arxiv.org/pdf/2203.10210.pdf)
>  Bikebot manipulation has advantages of the single-track robot mobility and manipulation dexterity. We present a coordinated pose control of mobile manipulation with the stationary bikebot. The challenges of the bikebot manipulation include the limited steering balance capability of the unstable bikebot and kinematic redundancy of the manipulator. We first present the steering balance model to analyze and explore the maximum steering capability to balance the stationary platform. A balancing equilibrium manifold is then proposed to describe the necessary condition to fulfill the simultaneous platform balance and posture control of the end-effector. A coordinated planning and control design is presented to determine the balance-prioritized posture control under kinematic and dynamic constraints. Extensive experiments are conducted to demonstrate the mechatronic design for autonomous plant inspection in agricultural applications. The results confirm the feasibility to use the bikebot manipulation for a plant inspection with end-effector position and orientation errors about 5 mm and 0.3 degs, respectively.      
### 74.Privacy-Preserving Reinforcement Learning Beyond Expectation  [ :arrow_down: ](https://arxiv.org/pdf/2203.10165.pdf)
>  Cyber and cyber-physical systems equipped with machine learning algorithms such as autonomous cars share environments with humans. In such a setting, it is important to align system (or agent) behaviors with the preferences of one or more human users. We consider the case when an agent has to learn behaviors in an unknown environment. Our goal is to capture two defining characteristics of humans: i) a tendency to assess and quantify risk, and ii) a desire to keep decision making hidden from external parties. We incorporate cumulative prospect theory (CPT) into the objective of a reinforcement learning (RL) problem for the former. For the latter, we use differential privacy. We design an algorithm to enable an RL agent to learn policies to maximize a CPT-based objective in a privacy-preserving manner and establish guarantees on the privacy of value functions learned by the algorithm when rewards are sufficiently close. This is accomplished through adding a calibrated noise using a Gaussian process mechanism at each step. Through empirical evaluations, we highlight a privacy-utility tradeoff and demonstrate that the RL agent is able to learn behaviors that are aligned with that of a human user in the same environment in a privacy-preserving manner      
### 75.AI system for fetal ultrasound in low-resource settings  [ :arrow_down: ](https://arxiv.org/pdf/2203.10139.pdf)
>  Despite considerable progress in maternal healthcare, maternal and perinatal deaths remain high in low-to-middle income countries. Fetal ultrasound is an important component of antenatal care, but shortage of adequately trained healthcare workers has limited its adoption. We developed and validated an artificial intelligence (AI) system that uses novice-acquired "blind sweep" ultrasound videos to estimate gestational age (GA) and fetal malpresentation. We further addressed obstacles that may be encountered in low-resourced settings. Using a simplified sweep protocol with real-time AI feedback on sweep quality, we have demonstrated the generalization of model performance to minimally trained novice ultrasound operators using low cost ultrasound devices with on-device AI integration. The GA model was non-inferior to standard fetal biometry estimates with as few as two sweeps, and the fetal malpresentation model had high AUC-ROCs across operators and devices. Our AI models have the potential to assist in upleveling the capabilities of lightly trained ultrasound operators in low resource settings.      
### 76.Towards a Perceptual Model for Estimating the Quality of Visual Speech  [ :arrow_down: ](https://arxiv.org/pdf/2203.10117.pdf)
>  Generating realistic lip motions to simulate speech production is key for driving natural character animations from audio. Previous research has shown that traditional metrics used to optimize and assess models for generating lip motions from speech are not a good indicator of subjective opinion of animation quality. Yet, running repetitive subjective studies for assessing the quality of animations can be time-consuming and difficult to replicate. In this work, we seek to understand the relationship between perturbed lip motion and subjective opinion of lip motion quality. Specifically, we adjust the degree of articulation for lip motion sequences and run a user-study to examine how this adjustment impacts the perceived quality of lip motion. We then train a model using the scores collected from our user-study to automatically predict the subjective quality of an animated sequence. Our results show that (1) users score lip motions with slight over-articulation the highest in terms of perceptual quality; (2) under-articulation had a more detrimental effect on perceived quality of lip motion compared to the effect of over-articulation; and (3) we can automatically estimate the subjective perceptual score for a given lip motion sequences with low error rates.      
### 77.Selection of entropy based features for the analysis of the Archimedes' spiral applied to essential tremor  [ :arrow_down: ](https://arxiv.org/pdf/2203.10094.pdf)
>  Biomedical systems are regulated by interacting mechanisms that operate across multiple spatial and temporal scales and produce biosignals with linear and non-linear information inside. In this sense entropy could provide a useful measure about disorder in the system, lack of information in time-series and/or irregularity of the signals. Essential tremor (ET) is the most common movement disorder, being 20 times more common than Parkinson's disease, and 50-70% of this disease cases are estimated to be genetic in origin. Archimedes spiral drawing is one of the most used standard tests for clinical diagnosis. This work, on selection of nonlinear biomarkers from drawings and handwriting, is part of a wide-ranging cross study for the diagnosis of essential tremor in BioDonostia Health Institute. Several entropy algorithms are used to generate nonlinear feayures. The automatic analysis system consists of several Machine Learning paradigms.      
