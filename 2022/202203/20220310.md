# ArXiv eess --Thu, 10 Mar 2022
### 1.A novel method for adaptive control of deformable mirrors  [ :arrow_down: ](https://arxiv.org/pdf/2203.04915.pdf)
>  For sufficiently wide ranges of applied control signals (control voltages), MEMS and piezoelectric Deformable Mirrors (DMs), exhibit nonlinear behavior. The nonlinear behavior manifests itself in nonlinear actuator couplings, nonlinear actuator deformation characteristics, and in the case of piezoelectric DMs, hysteresis. Furthermore, in a number of situations, DM behavior can change over time, and this requires a procedure for updating the DM models on the basis of the observed data. If not properly modeled and if not taken into account when designing control algorithms, nonlinearities, and time-varying DM behavior, can significantly degrade the achievable closed-loop performance of Adaptive Optics (AO) systems. Widely used approaches for DM control are based on pre-estimated linear time-invariant DM models in the form of influence matrices. Often, these models are not being updated during system operation. Consequently, when the nonlinear DM behavior is excited by control signals with wide operating ranges, or when the DM behavior changes over time, the state-of-the-art DM control approaches relying upon linear control methods, might not be able to produce a satisfactory closed-loop performance of an AO system. Motivated by these key facts, we present a novel method for data-driven DM control. Our approach combines a simple open-loop control method with a recursive least squares method for dynamically updating the DM model. The DM model is constantly being updated on the basis of the dynamically changing DM operating points. That is, the proposed method updates both the control actions and the DM model during the system operation. We experimentally verify this approach on a Boston Micromachines MEMS DM with 140 actuators. Preliminary experimental results reported in this manuscript demonstrate good potential for using the developed method for DM control.      
### 2.Low-profile Button Sensor Antenna Design for Wireless Medical Body Area Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.04884.pdf)
>  A button sensor antenna for wireless medical body area networks (WMBAN) is presented, which works through the IEEE 802.11b/g/n standard. Due to strong interaction between the sensor antenna and the body, an innovative robust system is designed with a small footprint that can serve on- and off-body healthcare applications. The measured and simulated results are in good agreement. The design offers a wide range of omnidirectional radiation patterns in free space, with a reflection coefficient (S11) of -29.30 (-30.97) dB in the lower (upper) bands. S11 reaches up to -23.07 (-27.07) dB and -30.76 (-31.12) dB, respectively, on the human body chest and arm. The Specific Absorption Rate (SAR) values are below the regulatory limitations for both 1-gram (1.6 W/Kg) and 10-gram tissues (2.0 W/Kg). Experimental tests of the read range validate the results of a maximum coverage range of 40 meters.      
### 3.Structural &amp; Granger CAUSALITY for IoT Digital Twin  [ :arrow_down: ](https://arxiv.org/pdf/2203.04876.pdf)
>  In this foundational expository article on the application of Causality Analysis in IoT, we establish the basic theory and algorithms for estimating Structural and Granger causality factors from measured multichannel sensor data (vector timeseries). Vector timeseries is modeled as a Structural Vector Autoregressive (SVAR) model; utilizing Kalman Filter and Independent Component Analysis (ICA) methods, Structural and generalized Granger causality factors are estimated. The estimated causal factors are presented as a Fence graph which we call Causal Digital Twin. Practical applications of Causal Digital Twin are demonstrated on NASA Prognostic Data Repository Bearing data collection. Use of Causal Digital Twin for counterfactual experiments are indicated. <br>Causal Digital Twin is a horizontal solution that applies to diverse use cases in multiple industries such as Industrial, Manufacturing, Automotive, Consumer, Building and Smart City.      
### 4.Joint-optimization of Node placement and UAV's Trajectory for Self-sustaining Air-Ground IoT system  [ :arrow_down: ](https://arxiv.org/pdf/2203.04866.pdf)
>  Due to the sustainable power supply and environment-friendly features, self-powered IoT devices have been increasingly employed in various fields such as providing observation data in remote areas, especially in rural areas or post-disaster scenarios. Generally, through multi-hop relay, the sensed data of those self-powered IoT devices are collected by the sink node which connects to the IoT backbones. However, due to the remoteness, the sink needs to be located at the border of the monitoring area where both the backbone of IoT and electrical infrastructures are accessible. Under such deployment, significant data flow and relay overhead will incur considering the large scale of the monitoring area. Motivated by this issue, this paper aims to design a UAV-assisted self-powered heterogeneous system to provide comprehensive monitoring data. In this system, because of the superiority of the unmanned aerial vehicle (UAV) in the easy deployment, We dispatch UAV collects data from self-powered IoT devices, periodically so as to alleviate the data overflow. Moreover, based on that the self-powered IoT devices are expected to have a more considerable capability in the heavy data flow area, we also developed a placement upgrade strategy to upgrade the general homogeneous self-powered IoT system to the heterogeneous self-powered IoT system. Simulation results indicated the developed UAV-assisted self-powered heterogeneous system can achieve around $1.28\times$ the amount of data delivery to sink compared with the homogeneous self-powered IoT system.      
### 5.A Unified Network Equilibrium for E-Hailing Platform Operation and Customer Mode Choice  [ :arrow_down: ](https://arxiv.org/pdf/2203.04865.pdf)
>  This paper aims to combine both economic and network user equilibrium for ride-sourcing and ride-pooling services, while endogenously optimizing the pooling sequence of two origin-destination (OD) pairs. With the growing popularity of ride-sourcing and ride-pooling services provided by transportation network companies (TNC), there lacks a theoretical network equilibrium model that accounts for the emerging ride-pooling service, due to the challenge in enumerating all possible combinations of OD pairs pooling and sequencing. This paper proposes a unified network equilibrium framework that integrates three modules, including travelers' modal choice between e-pooling and e-solo services, e-platforms' decision on vehicle dispatching and driver-passenger matching, and network congestion. To facilitate the representation of vehicle and passenger OD flows and pooling options, a layered OD hypergraph is created encompassing ride-sourcing and ride-pooling services over origins and destination nodes. Numerical examples are performed on both small and large road networks to demonstrate the efficiency of our model. The proposed equilibrium framework can efficiently assist policymakers and urban planners to evaluate the impact of TNCs on traffic congestion, and also help TNCs with pricing and fleet sizing optimization.      
### 6.Re-ordering of Hadamard matrix using Fourier transform and gray-level co-occurrence matrix for compressive single-pixel imaging  [ :arrow_down: ](https://arxiv.org/pdf/2203.04858.pdf)
>  One of the most active research fields in single-pixel imaging is the influence of the sampling basis and its order in the quality of the reconstructed images. This paper presents two new orders, ascending scale (AS) and ascending inertia (AI), of the Hadamard basis and test their performance, using simulation and experimental methods, for low sampling ratios (0.5 to 0.01). These orders were compared with two state-of-the-art orders, cake-cutting (CC) and total gradient (TG), using TVAL3 as the reconstruction algorithm and three noise levels. These newly proposed orders have better reconstructed image quality on the simulation data set (110 images) and achieved structure similarity index values higher than CC order. The experimental data set (2 images) showed that the AS and AI orders performed better with a sampling ratio of 0.5, while for lower sampling ratio the performance of AS, AI and CC was similar. The TG order performed worst in the majority of the cases. Finally, the simulation results present clear evidence that peak signal-to-noise ratio (PSNR) is not a reliable image quality assessment (IQA) metric to assess image reconstruction quality in the context of single pixel imaging.      
### 7.'Beach' to 'Bitch': Inadvertent Unsafe Transcription of Kids' Content on YouTube  [ :arrow_down: ](https://arxiv.org/pdf/2203.04837.pdf)
>  Over the last few years, YouTube Kids has emerged as one of the highly competitive alternatives to television for children's entertainment. Consequently, YouTube Kids' content should receive an additional level of scrutiny to ensure children's safety. While research on detecting offensive or inappropriate content for kids is gaining momentum, little or no current work exists that investigates to what extent AI applications can (accidentally) introduce content that is inappropriate for kids. <br>In this paper, we present a novel (and troubling) finding that well-known automatic speech recognition (ASR) systems may produce text content highly inappropriate for kids while transcribing YouTube Kids' videos. We dub this phenomenon as \emph{inappropriate content hallucination}. Our analyses suggest that such hallucinations are far from occasional, and the ASR systems often produce them with high confidence. We release a first-of-its-kind data set of audios for which the existing state-of-the-art ASR systems hallucinate inappropriate content for kids. In addition, we demonstrate that some of these errors can be fixed using language models.      
### 8.Neural Network Training on In-memory-computing Hardware with Radix-4 Gradients  [ :arrow_down: ](https://arxiv.org/pdf/2203.04821.pdf)
>  Deep learning training involves a large number of operations, which are dominated by high dimensionality Matrix-Vector Multiplies (MVMs). This has motivated hardware accelerators to enhance compute efficiency, but where data movement and accessing are proving to be key bottlenecks. In-Memory Computing (IMC) is an approach with the potential to overcome this, whereby computations are performed in-place within dense 2-D memory. However, IMC fundamentally trades efficiency and throughput gains for dynamic-range limitations, raising distinct challenges for training, where compute precision requirements are seen to be substantially higher than for inferencing. This paper explores training on IMC hardware by leveraging two recent developments: (1) a training algorithm enabling aggressive quantization through a radix-4 number representation; (2) IMC leveraging compute based on precision capacitors, whereby analog noise effects can be made well below quantization effects. Energy modeling calibrated to a measured silicon prototype implemented in 16nm CMOS shows that energy savings of over 400x can be achieved with full quantizer adaptability, where all training MVMs can be mapped to IMC, and 3x can be achieved for two-level quantizer adaptability, where two of the three training MVMs can be mapped to IMC.      
### 9.Machine Learning based Optimal Feedback Control for Microgrid Stabilization  [ :arrow_down: ](https://arxiv.org/pdf/2203.04815.pdf)
>  Microgrids have more operational flexibilities as well as uncertainties than conventional power grids, especially when renewable energy resources are utilized. An energy storage based feedback controller can compensate undesired dynamics of a microgrid to improve its stability. However, the optimal feedback control of a microgrid subject to a large disturbance needs to solve a Hamilton-Jacobi-Bellman problem. This paper proposes a machine learning-based optimal feedback control scheme. Its training dataset is generated from a linear-quadratic regulator and a brute-force method respectively addressing small and large disturbances. Then, a three-layer neural network is constructed from the data for the purpose of optimal feedback control. A case study is carried out for a microgrid model based on a modified Kundur two-area system to test the real-time performance of the proposed control scheme.      
### 10.Intelligent resonance tracking of a microwave plasmonic resonator for compact wireless sensors  [ :arrow_down: ](https://arxiv.org/pdf/2203.04780.pdf)
>  Plasmonic sensing has been in the spotlight for decades, the concept and applications of which have been generalized to spoof surface plasmons (SSPs) in the microwave band. Here, we report a compact and wireless sensor within a printed circuit board size of 18 mm * 12 mm, tracking the resonance frequency shift of a microwave plasmonic resonator via a software-defined scheme. The microwave plasmonic resonator yields a deep-subwavelength size, enhanced sensitivity, and a good electromagnetic compatibility performance. The software-defined resonance tracking scheme minimalizes the hardware circuit and the consumed spectrum resources, and makes the detection intelligently adaptive to the target resonance, with a signal-to-noise ratio of 69 dB and a data rate of 2272 measuring points per second. The sensor has been validated via acetone vapor concentration sensing, while its applications can be widely extended by replacing the transducer materials. This approach provides compact, sensitive, accurate and intelligent solutions for resonant sensors in the Internet of things (IoT).      
### 11.A practical framework for multi-domain speech recognition and an instance sampling method to neural language modeling  [ :arrow_down: ](https://arxiv.org/pdf/2203.04767.pdf)
>  Automatic speech recognition (ASR) systems used on smart phones or vehicles are usually required to process speech queries from very different domains. In such situations, a vanilla ASR system usually fails to perform well on every domain. This paper proposes a multi-domain ASR framework for Tencent Map, a navigation app used on smart phones and in-vehicle infotainment systems. The proposed framework consists of three core parts: a basic ASR module to generate n-best lists of a speech query, a text classification module to determine which domain the speech query belongs to, and a reranking module to rescore n-best lists using domain-specific language models. In addition, an instance sampling based method to training neural network language models (NNLMs) is proposed to address the data imbalance problem in multi-domain ASR. In experiments, the proposed framework was evaluated on navigation domain and music domain, since navigating and playing music are two main features of Tencent Map. Compared to a general ASR system, the proposed framework achieves a relative 13% $\sim$ 22% character error rate reduction on several test sets collected from Tencent Map and our in-car voice assistant.      
### 12.Using Human Gaze For Surgical Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.04752.pdf)
>  Automatically recognizing surgical activities plays an important role in providing feedback to surgeons, and is a fundamental step towards computer-aided surgical systems. Human gaze and visual saliency carry important information about visual attention, and can be used in computer vision systems. Although state-of-the-art surgical activity recognition models learn spatial temporal features, none of these models make use of human gaze and visual saliency. In this study, we propose to use human gaze with a spatial temporal attention mechanism for activity recognition in surgical videos. Our model consists of an I3D-based architecture, learns spatio-temporal features using 3D convolutions, as well as learning an attention map using human gaze. We evaluated our model on the Suturing task of JIGSAWS which is a publicly available surgical video understanding dataset. Our evaluations on a subset of random video segments in this task suggest that our approach achieves promising results with an accuracy of 86.2%.      
### 13.Predicting conversion of mild cognitive impairment to Alzheimer's disease  [ :arrow_down: ](https://arxiv.org/pdf/2203.04725.pdf)
>  Alzheimer's disease (AD) is the most common age-related dementia. Mild cognitive impairment (MCI) is the early stage of cognitive decline before AD. It is crucial to predict the MCI-to-AD conversion for precise management, which remains challenging due to the diversity of patients. Previous evidence shows that the brain network generated from diffusion MRI promises to classify dementia using deep learning. However, the limited availability of diffusion MRI challenges the model training. In this study, we develop a self-supervised contrastive learning approach to generate structural brain networks from routine anatomical MRI under the guidance of diffusion MRI. The generated brain networks are applied to train a learning framework for predicting the MCI-to-AD conversion. Instead of directly modelling the AD brain networks, we train a graph encoder and a variational autoencoder to model the healthy ageing trajectories from brain networks of healthy controls. To predict the MCI-to-AD conversion, we further design a recurrent neural networks based approach to model the longitudinal deviation of patients' brain networks from the healthy ageing trajectory. Numerical results show that the proposed methods outperform the benchmarks in the prediction task. We also visualize the model interpretation to explain the prediction and identify abnormal changes of white matter tracts.      
### 14.Deep learning-based reconstruction of highly accelerated 3D MRI  [ :arrow_down: ](https://arxiv.org/pdf/2203.04674.pdf)
>  Purpose: To accelerate brain 3D MRI scans by using a deep learning method for reconstructing images from highly-undersampled multi-coil k-space data <br>Methods: DL-Speed, an unrolled optimization architecture with dense skip-layer connections, was trained on 3D T1-weighted brain scan data to reconstruct complex-valued images from highly-undersampled k-space data. The trained model was evaluated on 3D MPRAGE brain scan data retrospectively-undersampled with a 10-fold acceleration, compared to a conventional parallel imaging method with a 2-fold acceleration. Scores of SNR, artifacts, gray/white matter contrast, resolution/sharpness, deep gray-matter, cerebellar vermis, anterior commissure, and overall quality, on a 5-point Likert scale, were assessed by experienced radiologists. In addition, the trained model was tested on retrospectively-undersampled 3D T1-weighted LAVA (Liver Acquisition with Volume Acceleration) abdominal scan data, and prospectively-undersampled 3D MPRAGE and LAVA scans in three healthy volunteers and one, respectively. <br>Results: The qualitative scores for DL-Speed with a 10-fold acceleration were higher than or equal to those for the parallel imaging with 2-fold acceleration. DL-Speed outperformed a compressed sensing method in quantitative metrics on retrospectively-undersampled LAVA data. DL-Speed was demonstrated to perform reasonably well on prospectively-undersampled scan data, realizing a 2-5 times reduction in scan time. <br>Conclusion: DL-Speed was shown to accelerate 3D MPRAGE and LAVA with up to a net 10-fold acceleration, achieving 2-5 times faster scans compared to conventional parallel imaging and acceleration, while maintaining diagnostic image quality and real-time reconstruction. The brain scan data-trained DL-Speed also performed well when reconstructing abdominal LAVA scan data, demonstrating versatility of the network.      
### 15.Single-pixel imaging based on weight sort of the Hadamard basis  [ :arrow_down: ](https://arxiv.org/pdf/2203.04659.pdf)
>  Single-pixel imaging (SPI) is very popular in subsampling applications, but the random measurement matrices it typically uses will lead to measurement blindness as well as difficulties in calculation and storage, and will also limit the further reduction in sampling rate. The deterministic Hadamard basis has become an alternative choice due to its orthogonality and structural characteristics. There is evidence that sorting the Hadamard basis is beneficial to further reduce the sampling rate, thus many orderings have emerged, but their relations remain unclear and lack a unified theory. Given this, here we specially propose a concept named selection history, which can record the Hadamard spatial folding process, and build a model based on it to reveal the formation mechanisms of different orderings and to deduce the mutual conversion relationship among them. Then, a weight ordering of the Hadamard basis is proposed. Both numerical simulation and experimental results have demonstrated that with this weight sort technique, the sampling rate, reconstruction time and matrix memory consumption are greatly reduced in comparison to traditional sorting methods. Therefore, we believe that this method may pave the way for real-time single-pixel imaging.      
### 16.PRINCE: A Pruned AMP Integrated Deep CNN Method for Efficient Channel Estimation of Millimeter-wave and Terahertz Ultra-Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.04635.pdf)
>  Millimeter-wave (mmWave) and Terahertz (THz)-band communications exploit the abundant bandwidth to fulfill the increasing data rate demands of 6G wireless communications. To compensate for the high propagation loss with reduced hardware costs, ultra-massive multiple-input multiple-output (UM-MIMO) with a hybrid beamforming structure is a promising technology in the mmWave and THz bands. However, channel estimation (CE) is challenging for hybrid UM-MIMO systems, which requires recovering the high-dimensional channels from severely few channel observations. In this paper, a Pruned Approximate Message Passing (AMP) Integrated Deep Convolutional-neural-network (DCNN) CE (PRINCE) method is firstly proposed, which enhances the estimation accuracy of the AMP method by appending a DCNN network. Moreover, by truncating the insignificant feature maps in the convolutional layers of the DCNN network, a pruning method including training with regularization, pruning and refining procedures is developed to reduce the network scale. Simulation results show that the PRINCE achieves a good trade-off between the CE accuracy and significantly low complexity, with normalized-mean-square-error (NMSE) of $-10$ dB at signal-to-noise-ratio (SNR) as $10$ dB after eliminating $80\%$ feature maps.      
### 17.Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2203.04614.pdf)
>  A large-scale labeled dataset is a key factor for the success of supervised deep learning in computer vision. However, a limited number of annotated data is very common, especially in ophthalmic image analysis, since manual annotation is time-consuming and labor-intensive. Self-supervised learning (SSL) methods bring huge opportunities for better utilizing unlabeled data, as they do not need massive annotations. With an attempt to use as many as possible unlabeled ophthalmic images, it is necessary to break the dimension barrier, simultaneously making use of both 2D and 3D images. In this paper, we propose a universal self-supervised Transformer framework, named Uni4Eye, to discover the inherent image property and capture domain-specific feature embedding in ophthalmic images. Uni4Eye can serve as a global feature extractor, which builds its basis on a Masked Image Modeling task with a Vision Transformer (ViT) architecture. We employ a Unified Patch Embedding module to replace the origin patch embedding module in ViT for jointly processing both 2D and 3D input images. Besides, we design a dual-branch multitask decoder module to simultaneously perform two reconstruction tasks on the input image and its gradient map, delivering discriminative representations for better convergence. We evaluate the performance of our pre-trained Uni4Eye encoder by fine-tuning it on six downstream ophthalmic image classification tasks. The superiority of Uni4Eye is successfully established through comparisons to other state-of-the-art SSL pre-training methods.      
### 18.Differential Chaos Shift Keying-based Wireless Power Transfer over a Frequency Selective Channel  [ :arrow_down: ](https://arxiv.org/pdf/2203.04612.pdf)
>  This paper studies the performance of a differential chaos shift keying (DCSK)-based wireless power transfer (WPT) setup in a frequency selective scenario. Particularly, by taking into account the nonlinearities of the energy harvesting (EH) process and a generalized frequency selective Nakagami-m fading channel, we derive closed-form analytical expressions for the harvested energy in terms of the transmitted waveform and channel parameters. A simplified closed-form expression for the harvested energy is also obtained for a scenario, where the delay spread is negligible in comparison to the transmit symbol duration. Nontrivial design insights are provided, where it is shown how the power delay profile of the channel as well as the parameters of the transmitted waveform affect the EH performance. Our results show that a frequency selective channel is comparatively more beneficial for WPT compared to a flat fading scenario. However, a significant delay spread negatively impacts the energy transfer.      
### 19.Attention-effective multiple instance learning on weakly stem cell colony segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04606.pdf)
>  The detection of induced pluripotent stem cell (iPSC) colonies often needs the precise extraction of the colony features. However, existing computerized systems relied on segmentation of contours by preprocessing for classifying the colony conditions were task-extensive. To maximize the efficiency in categorizing colony conditions, we propose a multiple instance learning (MIL) in weakly supervised settings. It is designed in a single model to produce weak segmentation and classification of colonies without using finely labeled samples. As a single model, we employ a U-net-like convolution neural network (CNN) to train on binary image-level labels for MIL colonies classification. Furthermore, to specify the object of interest we used a simple post-processing method. The proposed approach is compared over conventional methods using five-fold cross-validation and receiver operating characteristic (ROC) curve. The maximum accuracy of the MIL-net is 95%, which is 15 % higher than the conventional methods. Furthermore, the ability to interpret the location of the iPSC colonies based on the image level label without using a pixel-wise ground truth image is more appealing and cost-effective in colony condition recognition.      
### 20.Unsupervised Domain Adaptation across FMCW Radar Configurations Using Margin Disparity Discrepancy  [ :arrow_down: ](https://arxiv.org/pdf/2203.04588.pdf)
>  Commercial radar sensing is gaining relevance and machine learning algorithms constitute one of the key components that are enabling the spread of this radio technology into areas like surveillance or healthcare. However, radar datasets are still scarce and generalization cannot be yet achieved for all radar systems, environment conditions or design parameters. A certain degree of fine tuning is, therefore, usually required to deploy machine-learning-enabled radar applications. In this work, we consider the problem of unsupervised domain adaptation across radar configurations in the context of deep-learning human activity classification using frequency-modulated continuous-wave. For that, we focus on the theory-inspired technique of Margin Disparity Discrepancy, which has already been proved successful in the area of computer vision. Our experiments extend this technique to radar data, achieving a comparable accuracy to fewshot supervised approaches for the same classification problem.      
### 21.Multi-Material Blind Beam Hardening Correction Based on Non-Linearity Adjustment of Projections  [ :arrow_down: ](https://arxiv.org/pdf/2203.04587.pdf)
>  Beam hardening (BH) is one of the major artifacts that severely reduces the quality of Computed Tomography (CT) imaging. In a polychromatic X-ray beam, since low-energy photons are more preferentially absorbed, the attenuation of the beam is no longer a linear function of the absorber thickness. The existing BH correction methods either require a given material, which might be unfeasible in reality, or they require a long computation time. This work aims to propose a fast and accurate BH correction method that requires no prior knowledge of the materials and corrects first and higher-order BH artifacts. In the first step, a wide sweep of the material is performed based on an experimentally measured look-up table to obtain the closest estimate of the material. Then the non-linearity effect of the BH is corrected by adding the difference between the estimated monochromatic and the polychromatic simulated projections of the segmented image. The estimated monochromatic projection is simulated by selecting the energy from the polychromatic spectrum which produces the lowest mean square error (MSE) with the acquired projection from the scanner. The polychromatic projection is estimated by minimizing the difference between the acquired projection and the weighted sum of the simulated polychromatic projections using different spectra of different filtration. To evaluate the proposed BH correction method, we have conducted extensive experiments on the real-world CT data. Compared to the state-of-the-art empirical BH correction method, the experiments show that the proposed method can highly reduce the BH artifacts without prior knowledge of the materials.      
### 22.Multi-modal Brain Tumor Segmentation via Missing Modality Synthesis and Modality-level Attention Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2203.04586.pdf)
>  Multi-modal magnetic resonance (MR) imaging provides great potential for diagnosing and analyzing brain gliomas. In clinical scenarios, common MR sequences such as T1, T2 and FLAIR can be obtained simultaneously in a single scanning process. However, acquiring contrast enhanced modalities such as T1ce requires additional time, cost, and injection of contrast agent. As such, it is clinically meaningful to develop a method to synthesize unavailable modalities which can also be used as additional inputs to downstream tasks (e.g., brain tumor segmentation) for performance enhancing. In this work, we propose an end-to-end framework named Modality-Level Attention Fusion Network (MAF-Net), wherein we innovatively conduct patchwise contrastive learning for extracting multi-modal latent features and dynamically assigning attention weights to fuse different modalities. Through extensive experiments on BraTS2020, our proposed MAF-Net is found to yield superior T1ce synthesis performance (SSIM of 0.8879 and PSNR of 22.78) and accurate brain tumor segmentation (mean Dice scores of 67.9%, 41.8% and 88.0% on segmenting the tumor core, enhancing tumor and whole tumor).      
### 23.Language Adaptive Cross-lingual Speech Representation Learning with Sparse Sharing Sub-networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.04583.pdf)
>  Unsupervised cross-lingual speech representation learning (XLSR) has recently shown promising results in speech recognition by leveraging vast amounts of unlabeled data across multiple languages. However, standard XLSR model suffers from language interference problem due to the lack of language specific modeling ability. In this work, we investigate language adaptive training on XLSR models. More importantly, we propose a novel language adaptive pre-training approach based on sparse sharing sub-networks. It makes room for language specific modeling by pruning out unimportant parameters for each language, without requiring any manually designed language specific component. After pruning, each language only maintains a sparse sub-network, while the sub-networks are partially shared with each other. Experimental results on a downstream multilingual speech recognition task show that our proposed method significantly outperforms baseline XLSR models on both high resource and low resource languages. Besides, our proposed method consistently outperforms other adaptation methods and requires fewer parameters.      
### 24.Equilibrium-Independent Stability Analysis for Distribution Systems with Lossy Transmission Lines  [ :arrow_down: ](https://arxiv.org/pdf/2203.04580.pdf)
>  Power distribution systems are becoming much more active with increased penetration of distributed energy resources (DERs). Because of the intermittent outputs from DERs, the stability of distribution systems under large disturbances and time-varying conditions is becoming a key concern for practical operations. However, the transmission lines in distribution systems are called "lossy" in the sense that the resistances are comparable to reactances., There is a lack of a good Lyapunov function to be used for systems with lossy lines, making the transient stability a much harder problem that remains open even for simplified models. <br>This paper proposes a novel equilibrium-independent transient stability analysis of distribution systems with lossy lines. We certify network-level stability by breaking the network into subsystems, where a tunable model for lossy transmission lines is designed to explicitly tradeoff between the control effort and the stability region. By looking at the equilibrium-independent passivity of each subsystem, the network stability is certified through a diagonal stability property of the interconnection matrix. This allows the analysis scale to large networked systems with time-varying equilibriums. The proposed method gracefully extrapolates between lossless and lossy systems, and provides a simple yet effective approach to optimize control efforts with guaranteed stability regions. Cased studies verify that the proposed method is much less conservative than existing approaches and also scale to large systems.      
### 25.PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04568.pdf)
>  The success of Transformer in computer vision has attracted increasing attention in the medical imaging community. Especially for medical image segmentation, many excellent hybrid architectures based on convolutional neural networks (CNNs) and Transformer have been presented and achieve impressive performance. However, most of these methods, which embed modular Transformer into CNNs, struggle to reach their full potential. In this paper, we propose a novel hybrid architecture for medical image segmentation called PHTrans, which parallelly hybridizes Transformer and CNN in main building blocks to produce hierarchical representations from global and local features and adaptively aggregate them, aiming to fully exploit their strengths to obtain better segmentation performance. Specifically, PHTrans follows the U-shaped encoder-decoder design and introduces the parallel hybird module in deep stages, where convolution blocks and the modified 3D Swin Transformer learn local features and global dependencies separately, then a sequence-to-volume operation unifies the dimensions of the outputs to achieve feature aggregation. Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its effectiveness, consistently outperforming state-of-the-art methods.      
### 26.Weighted Sum Age of Information Minimization in Wireless Networks with Aerial IRS  [ :arrow_down: ](https://arxiv.org/pdf/2203.04525.pdf)
>  In this letter, we analyze a terrestrial wireless communication network assisted by an aerial intelligent reflecting surface (IRS). We consider a packet scheduling problem at the ground base station (BS) aimed at improving the information freshness by selecting packets based on their AoI. To further improve the communication quality, the trajectory of the unmanned aerial vehicle (UAV) which carries the IRS is optimized with joint active and passive beamforming design. To solve the formulated non-convex problem, we propose an iterative alternating optimization problem based on a successive convex approximation (SCA) algorithm. The simulation results shows significant performance improvement in terms of weighted sum AoI, and the SCA solution converges quickly with low computational complexity.      
### 27.Recovery Time Metric Demonstrated on Real-world Electric Grid for Hurricane Impacted Outages  [ :arrow_down: ](https://arxiv.org/pdf/2203.04517.pdf)
>  This work proposes a methodology for estimating recovery times for transmission lines and substations, and is demonstrated on a real-world 1269-bus power system model of Puerto Rico under 20 hurricane scenarios, or stochastic realizations of asset failure under the meteorological conditions of Hurricane Maria. The method defines base recovery times for system components and identifies factors that impact these base values by means of multipliers. While the method is tested on transmission lines and substation failures due to hurricanes, it is based on a generic process that could be applied to any system component or event as a general recovery time estimation framework. The results show that given the two failure modes under study (transmission towers and substations), transmission towers appear to have a greater impact on recovery time estimates despite substations being given longer base outage times. Additionally, average recovery times for the simulated hurricanes across 20 scenarios is ~28,000 work crew days.      
### 28.Learning Invariant Stabilizing Controllers for Frequency Regulation under Variable Inertia  [ :arrow_down: ](https://arxiv.org/pdf/2203.04502.pdf)
>  Declines in cost and concerns about the environmental impact of traditional generation have boosted the penetration of renewables and non-conventional distributed energy resources into the power grid. The intermittent availability of these resources causes the inertia of the power system to vary over time. As a result, there is a need to go beyond traditional controllers designed to regulate frequency under the assumption of invariant dynamics. This paper presents a learning-based framework for the design of stable controllers based on imitating datasets obtained from linear-quadratic regulator (LQR) formulations for different switching sequences of inertia modes. The proposed controller is linear and invariant, thereby interpretable, does not require the knowledge of the current operating mode, and is guaranteed to stabilize the switching power dynamics. We also show that it is always possible to stabilize the switched system using a communication-free local controller, whose implementation only requires each node to use its own state. Simulations on a 12-bus 3-region network illustrate our results.      
### 29.Millimeter-Scale Ultra-Low-Power Imaging System for Intelligent Edge Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2203.04496.pdf)
>  Millimeter-scale embedded sensing systems have unique advantages over larger devices as they are able to capture, analyze, store, and transmit data at the source while being unobtrusive and covert. However, area-constrained systems pose several challenges, including a tight energy budget and peak power, limited data storage, costly wireless communication, and physical integration at a miniature scale. This paper proposes a novel 6.7$\times$7$\times$5mm imaging system with deep-learning and image processing capabilities for intelligent edge applications, and is demonstrated in a home-surveillance scenario. The system is implemented by vertically stacking custom ultra-low-power (ULP) ICs and uses techniques such as dynamic behavior-specific power management, hierarchical event detection, and a combination of data compression methods. It demonstrates a new image-correcting neural network that compensates for non-idealities caused by a mm-scale lens and ULP front-end. The system can store 74 frames or offload data wirelessly, consuming 49.6$\mu$W on average for an expected battery lifetime of 7 days.      
### 30.Intelligent Feedback Overhead Reduction (iFOR) in Wi-Fi 7 and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2203.04493.pdf)
>  The IEEE 802.11 standard based wireless local area networks (WLANs) or Wi-Fi networks are critical to provide internet access in today's world. The increasing demand for high data rate in Wi-Fi networks has led to several advancements in the 802.11 standard. Supporting MIMO transmissions with higher number of transmit antennas operating on wider bandwidths is one of the key capabilities for reaching higher throughput. However, the increase in sounding feedback overhead due to higher number of transmit antennas may significantly curb the throughput gain. In this paper, we develop an unsupervised learning-based method to reduce the sounding duration in a Wi-Fi MIMO link. Simulation results show that our method uses approximately only 8% of the number of bits required by the existing feedback mechanism and it can boost the system throughput by up to 52%.      
### 31.The Impact of Heavy-Duty Vehicle Electrification on Large Power Grids: a Synthetic Texas Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2203.04430.pdf)
>  The electrification of heavy-duty vehicles (HDEVs) is a nascent and rapidly emerging avenue for decarbonization of the transportation sector. In this paper, we examine the impacts of increased vehicle electrification on the power grid infrastructure, with particular focus on HDEVs. We utilize a synthetic representation of the 2000-bus Texas transmission grid, and realistic representations of multiple distribution grids in Travis county, Texas, as well as transit data pertaining to HDEVs, to uncover the consequences of HDEV electrification, and expose the limitations imposed by existing electric grid infrastructure. Our analysis reveals that grid-wide voltage problems that are spatiotemporally correlated with the mobility of HDEVs may occur even at modest penetration levels. In fact, we find that as little as 11% of heavy duty vehicles in Texas charging simultaneously can lead to significant voltage violations on the transmission network that compromise grid reliability. Furthermore, we find that just a few dozen EVs charging simultaneously can lead to voltage violations at the distribution level.      
### 32.Harmonicity Plays a Critical Role in DNN Based Versus in Biologically-Inspired Monaural Speech Segregation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.04420.pdf)
>  Recent advancements in deep learning have led to drastic improvements in speech segregation models. Despite their success and growing applicability, few efforts have been made to analyze the underlying principles that these networks learn to perform segregation. Here we analyze the role of harmonicity on two state-of-the-art Deep Neural Networks (DNN)-based models- Conv-TasNet and DPT-Net. We evaluate their performance with mixtures of natural speech versus slightly manipulated inharmonic speech, where harmonics are slightly frequency jittered. We find that performance deteriorates significantly if one source is even slightly harmonically jittered, e.g., an imperceptible 3% harmonic jitter degrades performance of Conv-TasNet from 15.4 dB to 0.70 dB. Training the model on inharmonic speech does not remedy this sensitivity, instead resulting in worse performance on natural speech mixtures, making inharmonicity a powerful adversarial factor in DNN models. Furthermore, additional analyses reveal that DNN algorithms deviate markedly from biologically inspired algorithms that rely primarily on timing cues and not harmonicity to segregate speech.      
### 33.Grid Value Analysis of Medium Voltage Back-to-Back Converter on DER Hosting Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2203.04417.pdf)
>  This paper presents an analysis of the value that can be realized by medium-voltage back-to-back (MVB2B) converters in terms of increased utilization rate of distributed energy resource (DER) and the improvement in operational conditions. A systematic, transferrable, and scalable methodology has been designed to analyze and quantify the increased DER value from three perspectives: 1) curtailment reduction of the DER generation, 2) size reduction of the energy storage needed to otherwise realize DER hosting levels, and 3) hosting capacity improvement of DER compared to base distribution circuit capability. In the case study, the proposed methodology is applied to two utility distribution systems for analysis and quantification of the grid value of the MVB2B converter, installed in the distribution circuit, and provided to the solar photovoltaic (PV) DERs. The analysis results demonstrate that the MVB2B converter can deliver significant value to PV hosting enhancement of two adjacent distribution systems when they are connected by the MVB2B converter. Based on this case study, this paper analyzes and summarizes the approximate realized grid value of the MVB2B converter for distribution systems dominated by different shares of customer classes.      
### 34.Practical cognitive speech compression  [ :arrow_down: ](https://arxiv.org/pdf/2203.04415.pdf)
>  This paper presents a new neural speech compression method that is practical in the sense that it operates at low bitrate, introduces a low latency, is compatible in computational complexity with current mobile devices, and provides a subjective quality that is comparable to that of standard mobile-telephony codecs. Other recently proposed neural vocoders also have the ability to operate at low bitrate. However, they do not produce the same level of subjective quality as standard codecs. On the other hand, standard codecs rely on objective and short-term metrics such as the segmental signal-to-noise ratio that correlate only weakly with perception. Furthermore, standard codecs are less efficient than unsupervised neural networks at capturing speech attributes, especially long-term ones. The proposed method combines a cognitive-coding encoder that extracts an interpretable unsupervised hierarchical representation with a multi stage decoder that has a GAN-based architecture. We observe that this method is very robust to the quantization of representation features. An AB test was conducted on a subset of the Harvard sentences that are commonly used to evaluate standard mobile-telephony codecs. The results show that the proposed method outperforms the standard AMR-WB codec in terms of delay, bitrate and subjective quality.      
### 35.A machine learning accelerated inverse design of underwater acoustic polyurethane coatings with cylindrical voids  [ :arrow_down: ](https://arxiv.org/pdf/2203.04409.pdf)
>  Here, we report the development of a detailed "Materials Informatics" framework for the design of acoustic coatings for underwater sound attenuation through integrating Machine Learning (ML) and statistical optimization algorithms with a Finite Element Model (FEM). The finite element models were developed to simulate the realistic performance of the acoustic coatings based on polyurethane (PU) elastomers with embedded cylindrical voids. The FEM results revealed that the frequency-dependent viscoelastic behavior of the polyurethane matrix has a significant impact on the magnitude and frequency of the absorption peak associated with the cylinders at low frequencies, which has been commonly ignored in previous studies on similar systems. The data generated from the FEM was used to train a Deep Neural Network (DNN) to accelerate the design process, and subsequently, was integrated with a Genetic Algorithm (GA) to determine the optimal geometric parameters of the cylinders to achieve maximized, broadband, low-frequency waterborne sound attenuation. A significant, broadband, low-frequency attenuation is achieved by optimally configuring the layers of cylindrical voids and using attenuation mechanisms, including Fabry-PÃ©rot resonance and Bragg scattering of the layers of voids. Integration of the machine learning technique into the optimization algorithm further accelerated the exploration of the high dimensional design space for the targeted performance. The developed DNN exhibited significantly increased speed (by a factor of $4.5\times 10^3$ ) in predicting the absorption coefficient compared to the conventional FEM(s). Therefore, the acceleration brought by the materials informatics framework brings a paradigm shift to the design and development of acoustic coatings compared to the conventional trial-and-error practices.      
### 36.Sub-THz Channel Measurements at 158 GHz and 300 GHz in a Street Canyon Environment  [ :arrow_down: ](https://arxiv.org/pdf/2203.04404.pdf)
>  This paper presents first results of a channel measurement campaign performed in an urban micro (UMi) street canyon scenario at 158 GHz and 300 GHz.      
### 37.High Noise Immune Time-domain Inversion via Cascade Network (TICaN) for Complex Scatterers  [ :arrow_down: ](https://arxiv.org/pdf/2203.04402.pdf)
>  In this paper, a high noise immune time-domain inversion cascade network (TICaN) is proposed to reconstruct scatterers from the measured electromagnetic fields. The TICaN is comprised of a denoising block aiming at improving the signal-to-noise ratio, and an inversion block to reconstruct the electromagnetic properties from the raw time-domain measurements. The scatterers investigated in this study include complicated geometry shapes and high contrast, which cover the stratum layer, lossy medium and hyperfine structure, etc. After being well trained, the performance of the TICaN is evaluated from the perspective of accuracy, noise-immunity, computational acceleration, and generalizability. It can be proven that the proposed framework can realize high-precision inversion under high-intensity noise environments. Compared with traditional reconstruction methods, TICaN avoids the tedious iterative calculation by utilizing the parallel computing ability of GPU and thus significantly reduce the computing time. Besides, the proposed TICaN has certain generalization ability in reconstructing the unknown scatterers such as the famous Austria rings. Herein, it is confident that the proposed TICaN will serve as a new path for real-time quantitative microwave imaging for various practical scenarios.      
### 38.KPF-AE-LSTM: A Deep Probabilistic Model for Net-Load Forecasting in High Solar Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2203.04401.pdf)
>  With the expected rise in behind-the-meter solar penetration within the distribution networks, there is a need to develop time-series forecasting methods that can reliably predict the net-load, accurately quantifying its uncertainty and variability. This paper presents a deep learning method to generate probabilistic forecasts of day-ahead net-load at 15-min resolution, at various solar penetration levels. Our proposed deep-learning based architecture utilizes the dimensional reduction, from a higher-dimensional input to a lower-dimensional latent space, via a convolutional Autoencoder (AE). The extracted features from AE are then utilized to generate probability distributions across the latent space, by passing the features through a kernel-embedded Perron-Frobenius (kPF) operator. Finally, long short-term memory (LSTM) layers are used to synthesize time-series probability distributions of the forecasted net-load, from the latent space distributions. The models are shown to deliver superior forecast performance (as per several metrics), as well as maintain superior training efficiency, in comparison to existing benchmark models. Detailed analysis is carried out to evaluate the model performance across various solar penetration levels (up to 50\%), prediction horizons (e.g., 15\,min and 24\,hr ahead), and aggregation level of houses, as well as its robustness against missing measurements.      
### 39.Multi-Objective System-by-Design for mm-Wave Automotive Radar Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2203.04400.pdf)
>  The computationally-efficient solution of multi-objective optimization problems (MOPs) arising in the design of modern electromagnetic (EM) microwave devices is addressed. Towards this end, a novel System-by-Design (SbD) method is developed to effectively explore the solution space and to provide the decision maker with a set of optimal trade-off solutions minimizing multiple and (generally) contrasting objectives. The proposed MO-SbD method proves a high computational efficiency, with a remarkable time saving with respect to a competitive state-of-the-art MOP solution strategy, thanks to the "smart" integration of evolutionary-inspired concepts and operators with artificial intelligence (AI) and machine learning (ML) techniques. Representative numerical results are reported to provide the interested users with useful insights and guidelines on the proposed optimization method as well as to assess its effectiveness in designing mm-wave automotive radar antennas.      
### 40.Multi-Scale Single-Bit RP-EMS Synthesis for Advanced Propagation Manipulation through System-by-Design  [ :arrow_down: ](https://arxiv.org/pdf/2203.04399.pdf)
>  A new method for synthesizing Single-Bit Reconfigurable Passive Electromagnetic Skins (1RP-EMSs) featuring advanced beam shaping capabilities is proposed. By using single-bit unit cells, the multi-scale problem of controlling 1RP-EMSs is formulated as a two-phase process. First, the macro-scale synthesis of the discrete surface current that radiates the electromagnetic (EM) field fitting user-designed requirements is performed by means of an innovative quantized version of the iterative projection method (QIPM). Successively, the meta-atom states of the 1RP-EMS are optimized with a customized implementation of the System-by-Design paradigm to yield a 1RP-EMS that supports such a feasible reference current. A representative set of numerical results is reported to assess the effectiveness of the proposed approach in designing and controlling single-bit meta-atom RP-EMSs that enable complex wave manipulations.      
### 41.Window Filtering Algorithm for Pulsed Light Coherent Combining of Low Repetition Frequency  [ :arrow_down: ](https://arxiv.org/pdf/2203.04398.pdf)
>  The multi-dithering method has been well verified in phase locking of polarization coherent combination experiment. However, it is hard to apply to low repetition frequency pulsed lasers, since there exists an overlap frequency domain between pulse laser and the amplitude phase noise and traditional filters cannot effectively separate phase noise. Aiming to solve the problem in this paper, we propose a novel method of pulse noise detection, identification, and filtering based on the autocorrelation characteristics between noise signals. In the proposed algorithm, a self-designed window algorithm is used to identify the pulse, and then the pulse signal group in the window is replaced by interpolation, which effectively filter the pulse signal doped in the phase noise within 0.1 ms. After filtering the pulses in the phase noise, the phase difference of two pulsed beams (10 kHz) is successfully compensated to zero in 1 ms, and the coherent combination of closed-loop phase lock is realized. At the same time, the phase correction times are few, the phase lock effect is stable, and the final light intensity increases to the ideal value (0.9 Imax).      
### 42.Observations on the Angular Statistics of the Indoor Sub-THz Radio Channel at 158 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2203.04397.pdf)
>  This paper presents selected results from a channel measurement campaign conducted in a shopping mall scenario at 158 GHz. The focus is on the statistical analysis of the collected measurement data in terms of directional channel gain. Although most power is received from the line-of-sight (LOS) direction, significant multipaths arrive from all measured azimuth directions. The median of the sorted directional channel gain can be approximated by a linear curve showing an offset of about 10 dB with respect to the LOS direction.      
### 43.Embedding Temporal Convolutional Networks for Energy-Efficient PPG-Based Heart Rate Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2203.04396.pdf)
>  Photoplethysmography (PPG) sensors allow for non-invasive and comfortable heart-rate (HR) monitoring, suitable for compact wrist-worn devices. Unfortunately, Motion Artifacts (MAs) severely impact the monitoring accuracy, causing high variability in the skin-to-sensor interface. Several data fusion techniques have been introduced to cope with this problem, based on combining PPG signals with inertial sensor data. Until know, both commercial and reasearch solutions are computationally efficient but not very robust, or strongly dependent on hand-tuned parameters, which leads to poor generalization performance. % In this work, we tackle these limitations by proposing a computationally lightweight yet robust deep learning-based approach for PPG-based HR estimation. Specifically, we derive a diverse set of Temporal Convolutional Networks (TCN) for HR estimation, leveraging Neural Architecture Search (NAS). Moreover, we also introduce ActPPG, an adaptive algorithm that selects among multiple HR estimators depending on the amount of MAs, to improve energy efficiency. We validate our approaches on two benchmark datasets, achieving as low as 3.84 Beats per Minute (BPM) of Mean Absolute Error (MAE) on PPGDalia, which outperforms the previous state-of-the-art. Moreover, we deploy our models on a low-power commercial microcontroller (STM32L4), obtaining a rich set of Pareto optimal solutions in the complexity vs. accuracy space.      
### 44.A Study of Multihop mmW Aerial Backhaul Links  [ :arrow_down: ](https://arxiv.org/pdf/2203.04387.pdf)
>  The main contribution of this paper is to analyze a long networked flying platform (NFP)-based millimeter wave (mmWave) backhaul link that is offered as a cost effective and easy to deploy solution to connect a disaster or remote area to the nearest core network. For this aim, we characterize the backhaul channel as a function of realistic physical parameters such as heights and distances of obstacles along the route, flight altitude and the intensity of NFPs' vibrations, the real 3D antenna pattern provided by 3GPP, etc. For the characterized channel, we derive an analytical closed-form expression for the outage probability. Finally, using the obtained results, we provide a fast algorithm for the optimal parameter design of the considered system that minimizes the cost.      
### 45.Formation Control of Nonlinear Multi-Agent Systems Using Three-Layer Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2203.04381.pdf)
>  This paper considers a leader-following formation control problem for heterogeneous, second-order, uncertain, input-affine, nonlinear multi-agent systems modeled by a directed graph. A tunable, three-layer neural network (NN) is proposed with an input layer, two hidden layers, and an output layer to approximate an unknown nonlinearity. Unlike commonly used trial and error efforts to select the number of neurons in a conventional NN, in this case an \textit{a priori} knowledge allows one to set up the number of neurons in each layer. The NN weights tuning laws are derived using the Lyapunov theory. The leader-following and formation control problems are addressed by a robust integral of the sign of the error (RISE) feedback and a NN-based control. The RISE feedback term compensates for unknown leader dynamics and the unknown, bounded disturbance in the agent error dynamics. The NN-based term compensates for the unknown nonlinearity in the dynamics of multi-agent systems, and semi-global asymptotic tracking results are rigorously proven using the Lyapunov stability theory. The results of the paper are compared with two previous results to evaluate the efficiency and performance of the proposed method.      
### 46.Long mmWave Backhaul Connectivity Using Fixed-Wing UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2203.04377.pdf)
>  This paper discusses the analysis of a fixed-wing unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) backhaul link, that is offered as a cost-effective and easy deploy the solution to connect a disaster or remote area to the nearest core network. We present the optimal design of a relay system based on fixed-wing UAV, taking into account the actual channel parameters such as the UAV vibrations, tracking error, real 3GPP antenna pattern, UAV's height, flight path, and the effect of physical obstacles. The performance of the considered system is evaluated in terms of outage probability and the channel capacity while taking into account the impact of the system parameters such as optimal selection of UAV flight path and antenna patterns.      
### 47.Deep Learning for Sleep Stages Classification: Modified Rectified Linear Unit Activation Function and Modified Orthogonal Weight Initialisation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04371.pdf)
>  Background and Aim: Each stage of sleep can affect human health, and not getting enough sleep at any stage may lead to sleep disorder like parasomnia, apnea, insomnia, etc. Sleep-related diseases could be diagnosed using Convolutional Neural Network Classifier. However, this classifier has not been successfully implemented into sleep stage classification systems due to high complexity and low accuracy of classification. The aim of this research is to increase the accuracy and reduce the learning time of Convolutional Neural Network Classifier. Methodology: The proposed system used a modified Orthogonal Convolutional Neural Network and a modified Adam optimisation technique to improve the sleep stage classification accuracy and reduce the gradient saturation problem that occurs due to sigmoid activation function. The proposed system uses Leaky Rectified Linear Unit (ReLU) instead of sigmoid activation function as an activation function. Results: The proposed system called Enhanced Sleep Stage Classification system (ESSC) used six different databases for training and testing the proposed model on the different sleep stages. These databases are University College Dublin database (UCD), Beth Israel Deaconess Medical Center MIT database (MIT-BIH), Sleep European Data Format (EDF), Sleep EDF Extended, Montreal Archive of Sleep Studies (MASS), and Sleep Heart Health Study (SHHS). Our results show that the gradient saturation problem does not exist anymore. The modified Adam optimiser helps to reduce the noise which in turn result in faster convergence time. Conclusion: The convergence speed of ESSC is increased along with better classification accuracy compared to the state of art solution.      
### 48.Feasibility Guaranteed Traffic Merging Control Using Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2203.04348.pdf)
>  We consider the merging control problem for Connected and Automated Vehicles (CAVs) aiming to jointly minimize travel time and energy consumption while providing speed-dependent safety guarantees and satisfying velocity and acceleration constraints. Applying the joint optimal control and control barrier function (OCBF) method, a controller that optimally tracks the unconstrained optimal control solution while guaranteeing the satisfaction of all constraints is efficiently obtained by transforming the optimal tracking problem into a sequence of quadratic programs (QPs). However, these QPs can become infeasible, especially under tight control bounds, thus failing to guarantee safety constraints. We solve this problem by deriving a control-dependent feasibility constraint corresponding to each CBF constraint which is added to each QP and we show that each such modified QP is guaranteed to be feasible. Extensive simulations of the merging control problem illustrate the effectiveness of this feasibility guaranteed controller.      
### 49.MICDIR: Multi-scale Inverse-consistent Deformable Image Registration using UNetMSS with Self-Constructing Graph Latent  [ :arrow_down: ](https://arxiv.org/pdf/2203.04317.pdf)
>  Image registration is the process of bringing different images into a common coordinate system - a technique widely used in various applications of computer vision, such as remote sensing, image retrieval, and most commonly in medical imaging. Deep Learning based techniques have been applied successfully to tackle various complex medical image processing problems, including medical image registration. Over the years, several image registration techniques have been proposed using deep learning. Deformable image registration techniques such as Voxelmorph have been successful in capturing finer changes and providing smoother deformations. However, Voxelmorph, as well as ICNet and FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical view of the supplied image) and therefore can not track large deformations. In order to tackle the aforementioned problems, this paper extends the Voxelmorph approach in three different ways. To improve the performance in case of small as well as large deformations, supervision of the model at different resolutions have been integrated using a multi-scale UNet. To support the network to learn and encode the minute structural co-relations of the given image-pairs, a self-constructing graph network (SCGNet) has been used as the latent of the multi-scale UNet - which can improve the learning process of the model and help the model to generalise better. And finally, to make the deformations inverse-consistent, cycle consistency loss has been employed. On the task of registration of brain MRIs, the proposed method achieved significant improvements over ANTs and VoxelMorph, obtaining a Dice score of 0.8013$\pm$0.0243 for intramodal and 0.6211$\pm$0.0309 for intermodal, while VoxelMorph achieved 0.7747$\pm$0.0260 and 0.6071$\pm$0.0510, respectively.      
### 50.A Note on Probability Quantification for Protective System Efficacy Analysis: Stochastic Dynamics, Information Flow, and Initiating Event Arrival Times  [ :arrow_down: ](https://arxiv.org/pdf/2203.04315.pdf)
>  Probability Quantification (PQ) predictions of the efficacy of safety-critical protective systems is challenging. Yet, the popularity of PQ methodologies (e.g., Probabilistic Risk Assessment (PRA), Quantitative Risk Analysis (QRA) and Probabilistic Safety Analysis (PSA)) is growing and can now be found written into regulatory rules. PQ in predictive modeling is attractive because of its grounding in probability theory. But, certain important safety related events are not probability-measurable which is problematic for risk-analytic methodologies that rely on PQ computations. Herein, we identify why the dynamics of available information play an essential role in governing the fidelity of PQ, and why PQ in the analysis of safety-critical protective systems is limited by the un-measurability of certain critical events. We provide an historical example that provides a practical context for our observations. Finally we discuss the implications of measurability for regulatory decision-making governed by recent nuclear industry legislation advocating increased use of risk informed, performance-based regulation for advanced reactor licensing.      
### 51.PyNET-QxQ: A Distilled PyNET for QxQ Bayer Pattern Demosaicing in CMOS Image Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2203.04314.pdf)
>  The deep learning-based ISP models for mobile cameras produce high-quality images comparable to the professional DSLR camera. However, many of them are computationally expensive, which may not be appropriate for mobile environments. Also, the recent mobile cameras adopt non-Bayer CFAs (e.g., Quad Bayer, Nona Bayer, and QxQ Bayer) to improve image quality; however, most deep learning-based ISP models mainly focus on standard Bayer CFA. In this work, we propose PyNET-QxQ based on PyNET, a light-weighted ISP explicitly designed for the QxQ CFA pattern. The number of parameters of PyNET-QxQ is less than 2.5% of PyNET. We also introduce a novel knowledge distillation technique, progressive distillation, to train the compressed network effectively. Finally, experiments with QxQ images (obtained by an actual QxQ camera sensor, under development) demonstrate the outstanding performance of PyNET-QxQ despite significant parameter reductions.      
### 52.Multi-Scale Adaptive Network for Single Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2203.04313.pdf)
>  Multi-scale architectures have shown effectiveness in a variety of tasks including single image denoising, thanks to appealing cross-scale complementarity. However, existing methods treat different scale features equally without considering their scale-specific characteristics, i.e., the within-scale characteristics are ignored. In this paper, we reveal this missing piece for multi-scale architecture design and accordingly propose a novel Multi-Scale Adaptive Network (MSANet) for single image denoising. To be specific, MSANet simultaneously embraces the within-scale characteristics and the cross-scale complementarity thanks to three novel neural blocks, i.e., adaptive feature block (AFeB), adaptive multi-scale block (AMB), and adaptive fusion block (AFuB). In brief, AFeB is designed to adaptively select details and filter noises, which is highly expected for fine-grained features. AMB could enlarge the receptive field and aggregate the multi-scale information, which is designed to satisfy the demands of both fine- and coarse-grained features. AFuB devotes to adaptively sampling and transferring the features from one scale to another scale, which is used to fuse the features with varying characteristics from coarse to fine. Extensive experiments on both three real and six synthetic noisy image datasets show the superiority of MSANet compared with 12 methods.      
### 53.Breast cancer detection using artificial intelligence techniques: A systematic literature review  [ :arrow_down: ](https://arxiv.org/pdf/2203.04308.pdf)
>  Cancer is one of the most dangerous diseases to humans, and yet no permanent cure has been developed for it. Breast cancer is one of the most common cancer types. According to the National Breast Cancer foundation, in 2020 alone, more than 276,000 new cases of invasive breast cancer and more than 48,000 non-invasive cases were diagnosed in the US. To put these figures in perspective, 64% of these cases are diagnosed early in the disease's cycle, giving patients a 99% chance of survival. Artificial intelligence and machine learning have been used effectively in detection and treatment of several dangerous diseases, helping in early diagnosis and treatment, and thus increasing the patient's chance of survival. Deep learning has been designed to analyze the most important features affecting detection and treatment of serious diseases. For example, breast cancer can be detected using genes or histopathological imaging. Analysis at the genetic level is very expensive, so histopathological imaging is the most common approach used to detect breast cancer. In this research work, we systematically reviewed previous work done on detection and treatment of breast cancer using genetic sequencing or histopathological imaging with the help of deep learning and machine learning. We also provide recommendations to researchers who will work in this field      
### 54.Diffusion Models for Medical Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2203.04306.pdf)
>  In medical applications, weakly supervised anomaly detection methods are of great interest, as only image-level annotations are required for training. Current anomaly detection methods mainly rely on generative adversarial networks or autoencoder models. Those models are often complicated to train or have difficulties to preserve fine details in the image. We present a novel weakly supervised anomaly detection method based on denoising diffusion implicit models. We combine the deterministic iterative noising and denoising scheme with classifier guidance for image-to-image translation between diseased and healthy subjects. Our method generates very detailed anomaly maps without the need for a complex training procedure. We evaluate our method on the BRATS2020 dataset for brain tumor detection and the CheXpert dataset for detecting pleural effusions.      
### 55.Dynamic Dual-Output Diffusion Models  [ :arrow_down: ](https://arxiv.org/pdf/2203.04304.pdf)
>  Iterative denoising-based generation, also known as denoising diffusion models, has recently been shown to be comparable in quality to other classes of generative models, and even surpass them. Including, in particular, Generative Adversarial Networks, which are currently the state of the art in many sub-tasks of image generation. However, a major drawback of this method is that it requires hundreds of iterations to produce a competitive result. Recent works have proposed solutions that allow for faster generation with fewer iterations, but the image quality gradually deteriorates with increasingly fewer iterations being applied during generation. In this paper, we reveal some of the causes that affect the generation quality of diffusion models, especially when sampling with few iterations, and come up with a simple, yet effective, solution to mitigate them. We consider two opposite equations for the iterative denoising, the first predicts the applied noise, and the second predicts the image directly. Our solution takes the two options and learns to dynamically alternate between them through the denoising process. Our proposed solution is general and can be applied to any existing diffusion model. As we show, when applied to various SOTA architectures, our solution immediately improves their generation quality, with negligible added complexity and parameters. We experiment on multiple datasets and configurations and run an extensive ablation study to support these findings.      
### 56.SuperPoint features in endoscopy  [ :arrow_down: ](https://arxiv.org/pdf/2203.04302.pdf)
>  There is often a significant gap between research results and applicability in routine medical practice. This work studies the performance of well-known local features on a medical dataset captured during routine colonoscopy procedures. Local feature extraction and matching is a key step for many computer vision applications, specially regarding 3D modelling. In the medical domain, handcrafted local features such as SIFT, with public pipelines such as COLMAP, are still a predominant tool for this kind of tasks. We explore the potential of the well known self-supervised approach SuperPoint, present an adapted variation for the endoscopic domain and propose a challenging evaluation framework. SuperPoint based models achieve significantly higher matching quality than commonly used local features in this domain. Our adapted model avoids features within specularity regions, a frequent and problematic artifact in endoscopic images, with consequent benefits for matching and reconstruction results.      
### 57.Live Laparoscopic Video Retrieval with Compressed Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2203.04301.pdf)
>  Searching through large volumes of medical data to retrieve relevant information is a challenging yet crucial task for clinical care. However the primitive and most common approach to retrieval, involving text in the form of keywords, is severely limited when dealing with complex media formats. Content-based retrieval offers a way to overcome this limitation, by using rich media as the query itself. Surgical video-to-video retrieval in particular is a new and largely unexplored research problem with high clinical value, especially in the real-time case: using real-time video hashing, search can be achieved directly inside of the operating room. Indeed, the process of hashing converts large data entries into compact binary arrays or hashes, enabling large-scale search operations at a very fast rate. However, due to fluctuations over the course of a video, not all bits in a given hash are equally reliable. In this work, we propose a method capable of mitigating this uncertainty while maintaining a light computational footprint. We present superior retrieval results (3-4 % top 10 mean average precision) on a multi-task evaluation protocol for surgery, using cholecystectomy phases, bypass phases, and coming from an entirely new dataset introduced here, critical events across six different surgery types. Success on this multi-task benchmark shows the generalizability of our approach for surgical video retrieval.      
### 58.Source-free Domain Adaptation for Multi-site and Lifespan Brain Skull Stripping  [ :arrow_down: ](https://arxiv.org/pdf/2203.04299.pdf)
>  Skull stripping is a crucial prerequisite step in the analysis of brain magnetic resonance (MR) images. Although many excellent works or tools have been proposed, they suffer from low generalization capability. For instance, the model trained on a dataset with specific imaging parameters (source domain) cannot be well applied to other datasets with different imaging parameters (target domain). Especially, for the lifespan datasets, the model trained on an adult dataset is not applicable to an infant dataset due to the large domain difference. To address this issue, numerous domain adaptation (DA) methods have been proposed to align the extracted features between the source and target domains, requiring concurrent access to the input images of both domains. Unfortunately, it is problematic to share the images due to privacy. In this paper, we design a source-free domain adaptation framework (SDAF) for multi-site and lifespan skull stripping that can accomplish domain adaptation without access to source domain images. Our method only needs to share the source labels as shape dictionaries and the weights trained on the source data, without disclosing private information from source domain subjects. To deal with the domain shift between multi-site lifespan datasets, we take advantage of the brain shape prior which is invariant to imaging parameters and ages. Experiments demonstrate that our framework can significantly outperform the state-of-the-art methods on multi-site lifespan datasets.      
### 59.Region Specific Optimization (RSO)-based Deep Interactive Registration  [ :arrow_down: ](https://arxiv.org/pdf/2203.04295.pdf)
>  Medical image registration is a fundamental and vital task which will affect the efficacy of many downstream clinical tasks. Deep learning (DL)-based deformable image registration (DIR) methods have been investigated, showing state-of-the-art performance. A test time optimization (TTO) technique was proposed to further improve the DL models' performance. Despite the substantial accuracy improvement with this TTO technique, there still remained some regions that exhibited large registration errors even after many TTO iterations. To mitigate this challenge, we firstly identified the reason why the TTO technique was slow, or even failed, to improve those regions' registration results. We then proposed a two-levels TTO technique, i.e., image-specific optimization (ISO) and region-specific optimization (RSO), where the region can be interactively indicated by the clinician during the registration result reviewing process. For both efficiency and accuracy, we further envisioned a three-step DL-based image registration workflow. Experimental results showed that our proposed method outperformed the conventional method qualitatively and quantitatively.      
### 60.NaviAirway: a bronchiole-sensitive deep learning-based airway segmentation pipeline for planning of navigation bronchoscopy  [ :arrow_down: ](https://arxiv.org/pdf/2203.04294.pdf)
>  Navigation bronchoscopy is a minimally invasive procedure in which doctors pass a bronchoscope into a subject's airways to sample the target pulmonary lesion. A three-dimensional (3D) airway roadmap reconstructed from Computer Tomography (CT) scans is a prerequisite for this procedure, especially when the target is distally located. Therefore, an accurate and efficient airway segmentation algorithm is essential to reduce bronchoscopists' burden of pre-procedural airway identification as well as patients' discomfort during the prolonged procedure. However, airway segmentation remains a challenging task because of the intrinsic complex tree-like structure, imbalanced sizes of airway branches, potential domain shifts of CT scans, and few available labeled images. To address these problems, we present a deep learning-based pipeline, denoted as NaviAirway, which finds finer bronchioles through four major novel components - feature extractor modules in model architecture design, a bronchiole-sensitive loss function, a human-vision-inspired iterative training strategy, and a semi-supervised learning framework to utilize unlabeled CT images. Experimental results showed that NaviAirway outperformed existing methods, particularly in identification of higher generation bronchioles and robustness to new CT scans. On average, NaviAirway takes five minutes to segment the CT scans of one patient on a GPU-embedded computer. Moreover, we propose two new metrics to complement conventional ones for a more comprehensive and fairer evaluation of deep learning-based airway segmentation approaches. The code is publicly available on <a class="link-external link-https" href="https://github.com/AntonotnaWang/NaviAirway" rel="external noopener nofollow">this https URL</a>.      
### 61.Towards performant and reliable undersampled MR reconstruction via diffusion model sampling  [ :arrow_down: ](https://arxiv.org/pdf/2203.04292.pdf)
>  Magnetic Resonance (MR) image reconstruction from under-sampled acquisition promises faster scanning time. To this end, current State-of-The-Art (SoTA) approaches leverage deep neural networks and supervised training to learn a recovery model. While these approaches achieve impressive performances, the learned model can be fragile on unseen degradation, e.g. when given a different acceleration factor. These methods are also generally deterministic and provide a single solution to an ill-posed problem; as such, it can be difficult for practitioners to understand the reliability of the reconstruction. We introduce DiffuseRecon, a novel diffusion model-based MR reconstruction method. DiffuseRecon guides the generation process based on the observed signals and a pre-trained diffusion model, and does not require additional training on specific acceleration factors. DiffuseRecon is stochastic in nature and generates results from a distribution of fully-sampled MR images; as such, it allows us to explicitly visualize different potential reconstruction solutions. Lastly, DiffuseRecon proposes an accelerated, coarse-to-fine Monte-Carlo sampling scheme to approximate the most likely reconstruction candidate. The proposed DiffuseRecon achieves SoTA performances reconstructing from raw acquisition signals in fastMRI and SKM-TEA.      
### 62.Residual Aligner Network  [ :arrow_down: ](https://arxiv.org/pdf/2203.04290.pdf)
>  Image registration is important for medical imaging, the estimation of the spatial transformation between different images. Many previous studies have used learning-based methods for coarse-to-fine registration to efficiently perform 3D image registration. The coarse-to-fine approach, however, is limited when dealing with the different motions of nearby objects. Here we propose a novel Motion-Aware (MA) structure that captures the different motions in a region. The MA structure incorporates a novel Residual Aligner (RA) module which predicts the multi-head displacement field used to disentangle the different motions of multiple neighbouring objects. Compared with other deep learning methods, the network based on the MA structure and RA module achieve one of the most accurate unsupervised inter-subject registration on the 9 organs of assorted sizes in abdominal CT scans, with the highest-ranked registration of the veins (Dice Similarity Coefficient / Average surface distance: 62\%/4.9mm for the vena cava and 34\%/7.9mm for the portal and splenic vein), with a half-sized structure and more efficient computation. Applied to the segmentation of lungs in chest CT scans, the new network achieves results which were indistinguishable from the best-ranked networks (94\%/3.0mm). Additionally, the theorem on predicted motion pattern and the design of MA structure are validated by further analysis.      
### 63.DUAL: Textless Spoken Question Answering with Speech Discrete Unit Adaptive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.04911.pdf)
>  Spoken Question Answering (SQA) has gained research attention and made remarkable progress in recent years. However, existing SQA methods rely on Automatic Speech Recognition (ASR) transcripts, which are time and cost-prohibitive to collect. This work proposes an ASR transcript-free SQA framework named Discrete Unit Adaptive Learning (DUAL), which leverages unlabeled data for pre-training and is fine-tuned by the SQA downstream task. DAUL can directly predict the time interval of the spoken answer from the spoken document. We also release a new SQA benchmark corpus Natural Multi-speaker Spoken Question Answering (NMSQA) for testing SQA in realistic scenarios. The experimental results show that DUAL performs competitively with the cascade approach (ASR + text QA), and DUAL is robust to real-world speech. We will open-source our code and model to inspire more SQA innovations from the community      
### 64.An Environmental Feature Representation in I-vector Space for Room Verification and Metadata Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04880.pdf)
>  This paper investigates the application of environmental feature representations for room verification tasks and acoustic meta-data estimation. Audio recordings contain both speaker and non-speaker information. We refer to the non-speaker-related information, including channel and other environmental factors, as e-vectors. I-vectors, commonly used in speaker identification, are extracted in the total variability space and capture both speaker and channel-environment information without discrimination. Accordingly, e-vectors can be extracted from i-vectors using methods such as linear discriminant analysis. In this paper, we first demonstrate that e-vectors can be successfully applied to room verification tasks with a low equal error rate. Second, we propose two methods for estimating metadata information -- signal-to-noise (SNR) and reverberation (T60) -- from these e-vectors. When comparing our system to contemporary global SNR estimation methods, in terms of accuracy, we perform favorably even with low dimensional i-vectors. Lastly, we show that room verification tasks can be improved if e-vectors are augmented with the extracted metadata information.      
### 65.Fair Coordination of Distributed Energy Resources with Volt-Var Control and PV Curtailment  [ :arrow_down: ](https://arxiv.org/pdf/2203.04842.pdf)
>  This paper presents a novel distributed optimal power flow (DOPF) method for fair distributed energy resource (DER) coordination in the context of mandated rooftop PV inverter control modes. In practice, inverter reactive power control is increasingly required by grid connection codes, which often unfairly curtail PV generation of prosumers towards the end of low-voltage feeders. Similarly, optimization-based DER coordination methods that aim solely for technically-efficient DER coordination do not consider the distribution of PV curtailment across customers. To address these concerns, we develop a tractable multi-objective DOPF method for optimal DER coordination that (i) curtails PV generation fairly across prosumers, and (ii) incorporates a standard piecewise-linear volt-var control reactive power control function without using integer variables. Three equity principles representing different interpretations of fairness are implemented in our coordination method; namely, egalitarian, proportional and uniform dynamic PV curtailment redistribution. The performance of our approach is demonstrated on low-voltage distribution feeders of different sizes (5, 10, 25, 50 and 100 prosumers) using two network topologies: line topology without lateral spurs and tree topology with lateral spurs. Each network considers three levels of PV penetration, giving 30 test systems in total. The results demonstrate the effectiveness of the proposed DOPF method for fair DER coordination: PV curtailment is equitably distributed among prosumers with a computational burden on par with conventional DOPF approaches. Moreover, different fairness methods result in different patterns of curtailment, which a regulator may choose between.      
### 66.CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2203.04838.pdf)
>  The performance of semantic segmentation of RGB images can be advanced by exploiting informative features from supplementary modalities. In this work, we propose CMX, a vision-transformer-based cross-modal fusion framework for RGB-X semantic segmentation. To generalize to different sensing modalities encompassing various uncertainties, we consider that comprehensive cross-modal interactions should be provided. CMX is built with two streams to extract features from RGB images and the complementary modality (X-modality). In each feature extraction stage, we design a Cross-Modal Feature Rectification Module (CM-FRM) to calibrate the feature of the current modality by combining the feature from the other modality, in spatial- and channel-wise dimensions. With rectified feature pairs, we deploy a Feature Fusion Module (FFM) to mix them for the final semantic prediction. FFM is constructed with a cross-attention mechanism, which enables exchange of long-range contexts, enhancing both modalities' features at a global level. Extensive experiments show that CMX generalizes to diverse multi-modal combinations, achieving state-of-the-art performances on four RGB-Depth benchmarks, as well as RGB-Thermal and RGB-Polarization datasets. Besides, to investigate the generalizability to dense-sparse data fusion, we establish a RGB-Event semantic segmentation benchmark based on the EventScape dataset, on which CMX sets the new state-of-the-art. Code is available at <a class="link-external link-https" href="https://github.com/huaaaliu/RGBX_Semantic_Segmentation" rel="external noopener nofollow">this https URL</a>      
### 67.Participation Factor-Based Adaptive Model Reduction for Fast Power System Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04820.pdf)
>  This paper describes an adaptive method to reduce a nonlinear power system model for fast and accurate transient stability simulation. It presents an approach to analyze and rank participation factors of each system state variable into dominant system modes excited by a disturbance so as to determine which regions or generators can be reduced without impacting the accuracy of simulation for a study area. In this approach, the generator models located in an external area with large participation factors are nonlinearly reduced and the rest of the generators will be linearized. The simulation results confirm that the assessment of the level of interaction between generators and system modes by participation factors is effective in enhancing the accuracy and speed of power system models. The proposed method is applied to the Northeastern Power Coordinating Council region system with 48-machine, 140-bus power system model and the results are compared with two cases including fully linearized model reduction and model reduction using the rotor angle deviation criteria.      
### 68.Practical Considerations of DER Coordination with Distributed Optimal Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2203.04819.pdf)
>  The coordination of prosumer-owned, behind-the-meter distributed energy resources (DER) can be achieved using a multiperiod, distributed optimal power flow (DOPF), which satisfies network constraints and preserves the privacy of prosumers. To solve the problem in a distributed fashion, it is decomposed and solved using the alternating direction method of multipliers (ADMM), which may require many iterations between prosumers and the central entity (i.e., an aggregator). Furthermore, the computational burden is shared among the agents with different processing capacities. Therefore, computational constraints and communication requirements may make the DOPF infeasible or impractical. In this paper, part of the DOPF (some of the prosumer subproblems) is executed on a Raspberry Pi-based hardware prototype, which emulates a low processing power, edge computing device. Four important aspects are analyzed using test cases of different complexities. The first is the computation cost of executing the subproblems in the edge computing device. The second is the algorithm operation on congested electrical networks, which impacts the convergence speed of DOPF solutions. Third, the precision of the computed solution, including the trade-off between solution quality and the number of iterations, is examined. Fourth, the communication requirements for implementation across different communication networks are investigated. The above metrics are analyzed in four scenarios involving 26-bus and 51-bus networks.      
### 69.Time-variant Nonlinear Participation Factors Considering Resonances in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.04808.pdf)
>  The participation factor (PF), as an important modal property for small-signal stability, evaluates the linkage between a state variable and a mode. Applying the normal form theory, a nonlinear PF can be defined to evaluate the participation of a state variable into modal dynamics following a large disturbance, that gives considerations to resonances and nonlinearities up to a desired order. However, existing nonlinear PFs are inconsistent with the conventional linear PF when nonlinear dynamics following a large disturbance attenuate and linear modal dynamics become dominating. This paper proposes a time-variant nonlinear PF by introducing a time decaying factor and the definition of a nonlinear mode. The new PFs consider modes of resonances and their values naturally transition to a linear PF when the system state becomes close to its equilibrium. The case study on a two-area four-generator system shows that the new PF can correctly rank generators by their participations in natural and resonance modes of nonlinear oscillation subject to a large disturbance.      
### 70.Sum Rate Maximization in STAR-RIS Assisted Full-Duplex Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.04709.pdf)
>  The sum-rate performance of simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted full-duplex (FD) communication systems is investigated. The reflection and transmission coefficients of STAR-RIS elements are optimized for the energy splitting and mode switching protocols to maximize the weighted sum rate of the system. The underlying optimization problems are non-convex, and hence, the successive convex approximation technique has been employed to develop efficient algorithms to obtain sub-optimal solutions. Thereby, the maximum average weighted sum rate and corresponding coefficients at the STAR-RIS subject to predefined threshold rates and unit-modulus constraints are quantified. The performance of the proposed system design is compared with the conventional reflecting/transmitting-only RISs and half-duplex counterparts via simulations where it is observed that STAR-RIS can boost the performance of FD systems.      
### 71.Multi-robot Cooperative Pursuit via Potential Field-Enhanced Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.04700.pdf)
>  It is of great challenge, though promising, to coordinate collective robots for hunting an evader in a decentralized manner purely in light of local observations. In this paper, this challenge is addressed by a novel hybrid cooperative pursuit algorithm that combines reinforcement learning with the artificial potential field method. In the proposed algorithm, decentralized deep reinforcement learning is employed to learn cooperative pursuit policies that are adaptive to dynamic environments. The artificial potential field method is integrated into the learning process as predefined rules to improve the data efficiency and generalization ability. It is shown by numerical simulations that the proposed hybrid design outperforms the pursuit policies either learned from vanilla reinforcement learning or designed by the potential field method. Furthermore, experiments are conducted by transferring the learned pursuit policies into real-world mobile robots. Experimental results demonstrate the feasibility and potential of the proposed algorithm in learning multiple cooperative pursuit strategies.      
### 72.Robust Federated Learning Against Adversarial Attacks for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2203.04696.pdf)
>  Due to the development of machine learning and speech processing, speech emotion recognition has been a popular research topic in recent years. However, the speech data cannot be protected when it is uploaded and processed on servers in the internet-of-things applications of speech emotion recognition. Furthermore, deep neural networks have proven to be vulnerable to human-indistinguishable adversarial perturbations. The adversarial attacks generated from the perturbations may result in deep neural networks wrongly predicting the emotional states. We propose a novel federated adversarial learning framework for protecting both data and deep neural networks. The proposed framework consists of i) federated learning for data privacy, and ii) adversarial training at the training stage and randomisation at the testing stage for model robustness. The experiments show that our proposed framework can effectively protect the speech data locally and improve the model robustness against a series of adversarial attacks.      
### 73.Electrical Vehicle Fleet Routing Accounting for Dynamic Battery Degradation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04642.pdf)
>  The increasing uptake of electrical vehicles (EVs) has increased the awareness of battery degradation costs and how they can be minimized. However, from a planning perspective it is difficult to integrate battery degradation models into existing route planning models and to assess how policies that aim at reducing battery degradation affect route planning costs and degradation across the fleet. In this paper, a simple transportation vehicle routing problem (VRP) is formulated as a mixed-integer nonlinear problem (MINLP), with a modification that allows monitoring the maximum and minimum depth-of-discharge (DoD) of the entire fleet. This allows us to measure the battery health degradation during the online optimization process. The results show that accounting for the impact of different route characteristics on battery degradation can have an impact on the route planning of the entire fleet as well as the battery degradation for all vehicles. The latter is achieved by forcing vehicles to adapt to certain DoD boundaries in the long term.      
### 74.Speaker Identification Experiments Under Gender De-Identification  [ :arrow_down: ](https://arxiv.org/pdf/2203.04638.pdf)
>  The present work is based on the COST Action IC1206 for De-identification in multimedia content. It was performed to test four algorithms of voice modifications on a speech gender recognizer to find the degree of modification of pitch when the speech recognizer have the probability of success equal to the probability of failure. The purpose of this analysis is to assess the intensity of the speech tone modification, the quality, the reversibility and not-reversibility of the changes made. Keywords DeIdentification; Speech Algorithms      
### 75.Pruning Graph Convolutional Networks to select meaningful graph frequencies for fMRI decoding  [ :arrow_down: ](https://arxiv.org/pdf/2203.04455.pdf)
>  Graph Signal Processing is a promising framework to manipulate brain signals as it allows to encompass the spatial dependencies between the activity in regions of interest in the brain. In this work, we are interested in better understanding what are the graph frequencies that are the most useful to decode fMRI signals. To this end, we introduce a deep learning architecture and adapt a pruning methodology to automatically identify such frequencies. We experiment with various datasets, architectures and graphs, and show that low graph frequencies are consistently identified as the most important for fMRI decoding, with a stronger contribution for the functional graph over the structural one. We believe that this work provides novel insights on how graph-based methods can be deployed to increase fMRI decoding accuracy and interpretability.      
### 76.OpenGridGym: An Open-Source AI-Friendly Toolkit for Distribution Market Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2203.04410.pdf)
>  This paper presents OpenGridGym, an open-source Python-based package that allows for seamless integration of distribution market simulation with state-of-the-art artificial intelligence (AI) decision-making algorithms. We present the architecture and design choice for the proposed framework, elaborate on how users interact with OpenGridGym, and highlight its value by providing multiple cases to demonstrate its use. Four modules are used in any simulation: (1) the physical grid, (2) market mechanisms, (3) a set of trainable agents which interact with the former two modules, and (4) environment module that connects and coordinates the above three. We provide templates for each of those four, but they are easily interchangeable with custom alternatives. Several case studies are presented to illustrate the capability and potential of this toolkit in helping researchers address key design and operational questions in distribution electricity markets.      
### 77.Routing with Privacy for Drone Package Delivery Systems  [ :arrow_down: ](https://arxiv.org/pdf/2203.04406.pdf)
>  Unmanned aerial vehicles (UAVs), or drones, are increasingly being used to deliver goods from vendors to customers. To safely conduct these operations at scale, drones are required to broadcast position information as codified in remote identification (remote ID) regulations. However, location broadcast of package delivery drones introduces a privacy risk for customers using these delivery services: Third-party observers may leverage broadcast drone trajectories to link customers with their purchases, potentially resulting in a wide range of privacy risks. We propose a probabilistic definition of privacy risk based on the likelihood of associating a customer to a vendor given a package delivery route. Next, we quantify these risks, enabling drone operators to assess privacy risks when planning delivery routes. We then evaluate the impacts of various factors (e.g., drone capacity) on privacy and consider the trade-offs between privacy and delivery wait times. Finally, we propose heuristics for generating routes with privacy guarantees to avoid exhaustive enumeration of all possible routes and evaluate their performance on several realistic delivery scenarios.      
### 78.Model-free feature selection to facilitate automatic discovery of divergent subgroups in tabular data  [ :arrow_down: ](https://arxiv.org/pdf/2203.04386.pdf)
>  Data-centric AI encourages the need of cleaning and understanding of data in order to achieve trustworthy AI. Existing technologies, such as AutoML, make it easier to design and train models automatically, but there is a lack of a similar level of capabilities to extract data-centric insights. Manual stratification of tabular data per a feature (e.g., gender) is limited to scale up for higher feature dimension, which could be addressed using automatic discovery of divergent subgroups. Nonetheless, these automatic discovery techniques often search across potentially exponential combinations of features that could be simplified using a preceding feature selection step. Existing feature selection techniques for tabular data often involve fitting a particular model in order to select important features. However, such model-based selection is prone to model-bias and spurious correlations in addition to requiring extra resource to design, fine-tune and train a model. In this paper, we propose a model-free and sparsity-based automatic feature selection (SAFS) framework to facilitate automatic discovery of divergent subgroups. Different from filter-based selection techniques, we exploit the sparsity of objective measures among feature values to rank and select features. We validated SAFS across two publicly available datasets (MIMIC-III and Allstate Claims) and compared it with six existing feature selection methods. SAFS achieves a reduction of feature selection time by a factor of 81x and 104x, averaged cross the existing methods in the MIMIC-III and Claims datasets respectively. SAFS-selected features are also shown to achieve competitive detection performance, e.g., 18.3% of features selected by SAFS in the Claims dataset detected divergent samples similar to those detected by using the whole features with a Jaccard similarity of 0.95 but with a 16x reduction in detection time.      
### 79.On generative models as the basis for digital twins  [ :arrow_down: ](https://arxiv.org/pdf/2203.04384.pdf)
>  A framework is proposed for generative models as a basis for digital twins or mirrors of structures. The proposal is based on the premise that deterministic models cannot account for the uncertainty present in most structural modelling applications. Two different types of generative models are considered here. The first is a physics-based model based on the stochastic finite element (SFE) method, which is widely used when modelling structures that have material and loading uncertainties imposed. Such models can be calibrated according to data from the structure and would be expected to outperform any other model if the modelling accurately captures the true underlying physics of the structure. The potential use of SFE models as digital mirrors is illustrated via application to a linear structure with stochastic material properties. For situations where the physical formulation of such models does not suffice, a data-driven framework is proposed, using machine learning and conditional generative adversarial networks (cGANs). The latter algorithm is used to learn the distribution of the quantity of interest in a structure with material nonlinearities and uncertainties. For the examples considered in this work, the data-driven cGANs model outperform the physics-based approach. Finally, an example is shown where the two methods are coupled such that a hybrid model approach is demonstrated.      
### 80.Cluster Head Detection for Hierarchical UAV Swarm With Graph Self-supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2203.04311.pdf)
>  In this paper, we study the cluster head detection problem of a two-level unmanned aerial vehicle (UAV) swarm network (USNET) with multiple UAV clusters, where the inherent follow strategy (IFS) of low-level follower UAVs (FUAVs) with respect to high-level cluster head UAVs (HUAVs) is unknown. We first propose a graph attention self-supervised learning algorithm (GASSL) to detect the HUAVs of a single UAV cluster, where the GASSL can fit the IFS at the same time. Then, to detect the HUAVs in the USNET with multiple UAV clusters, we develop a multi-cluster graph attention self-supervised learning algorithm (MC-GASSL) based on the GASSL. The MC-GASSL clusters the USNET with a gated recurrent unit (GRU)-based metric learning scheme and finds the HUAVs in each cluster with GASSL. Numerical results show that the GASSL can detect the HUAVs in single UAV clusters obeying various kinds of IFSs with over 98% average accuracy. The simulation results also show that the clustering purity of the USNET with MC-GASSL exceeds that with traditional clustering algorithms by at least 10% average. Furthermore, the MC-GASSL can efficiently detect all the HUAVs in USNETs with various IFSs and cluster numbers with low detection redundancies.      
### 81.A Machine Learning Approach to Digital Contact Tracing: TC4TL Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2203.04307.pdf)
>  Contact tracing is a method used by public health organisations to try prevent the spread of infectious diseases in the community. Traditionally performed by manual contact tracers, more recently the use of apps have been considered utilising phone sensor data to determine the distance between two phones. In this paper, we investigate the development of machine learning approaches to determine the distance between two mobile phone devices using Bluetooth Low Energy, sensory data and meta data. We use TableNet architecture and feature engineering to improve on the existing state of the art (total nDCF 0.21 vs 2.08), significantly outperforming existing models.      
### 82.Self-supervised learning for analysis of temporal and morphological drug effects in cancer cell imaging data  [ :arrow_down: ](https://arxiv.org/pdf/2203.04289.pdf)
>  In this work, we propose two novel methodologies to study temporal and morphological phenotypic effects caused by different experimental conditions using imaging data. As a proof of concept, we apply them to analyze drug effects in 2D cancer cell cultures. We train a convolutional autoencoder on 1M images dataset with random augmentations and multi-crops to use as feature extractor. We systematically compare it to the pretrained state-of-the-art models. We further use the feature extractor in two ways. First, we apply distance-based analysis and dynamic time warping to cluster temporal patterns of 31 drugs. We identify clusters allowing annotation of drugs as having cytotoxic, cytostatic, mixed or no effect. Second, we implement an adversarial/regularized learning setup to improve classification of 31 drugs and visualize image regions that contribute to the improvement. We increase top-3 classification accuracy by 8% on average and mine examples of morphological feature importance maps. We provide the feature extractor and the weights to foster transfer learning applications in biology. We also discuss utility of other pretrained models and applicability of our methods to other types of biomedical data.      
### 83.OmniWheg: An Omnidirectional Wheel-Leg Transformable Robot  [ :arrow_down: ](https://arxiv.org/pdf/2203.02118.pdf)
>  This paper presents the design, analysis, and performance evaluation of an omnidirectional transformable wheel-leg robot called OmniWheg. We design a novel mechanism consisting of a separable Omni-wheel and 4-bar linkages, allowing the robot to transform between Omni-wheeled and legged modes smoothly. On wheeled mode, the robot can move in all directions and efficiently adjust the relative position of its wheels, while it can overcome common obstacles in legged mode, such as stairs and steps. Unlike other articles studying whegs, this implementation with omnidirectional wheels allows the correction of misalignments between right and left wheels before traversing obstacles, which effectively improves the success rate and simplifies the preparation process before the wheel-leg transformation. We describe the design concept, mechanism, and the dynamic characteristic of the wheel-leg structure. We then evaluate its performance in various scenarios, including passing obstacles, climbing steps of different heights, and turning/moving omnidirectionally. Our results confirm that this mobile platform can overcome common indoor obstacles and move flexibly on the flat ground with the new transformable wheel-leg mechanism, while keeping a high degree of stability.      
