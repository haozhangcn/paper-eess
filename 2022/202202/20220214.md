# ArXiv eess --Mon, 14 Feb 2022
### 1.Nonprehensile Manipulation of a Stick Using Impulsive Forces  [ :arrow_down: ](https://arxiv.org/pdf/2202.05819.pdf)
>  The problem of nonprehensile manipulation of a stick in three-dimensional space using intermittent impulsive forces is considered. The objective is to juggle the stick between a sequence of configurations that are rotationally symmetric about the vertical axis. The dynamics of the stick is described by five generalized coordinates and three control inputs. Between two consecutive rotationally symmetric configurations, the dynamics is conveniently represented by a Poincaré map in the reference frame of the juggler. Stabilization of the orbit associated with a desired juggling motion is accomplished by stabilizing a fixed point on the Poincaré map. The Impulse Controlled Poincaré Map approach is used to stabilize the orbit, and numerical simulations are used demonstrate convergence to the desired juggling motion from an arbitrary initial configuration. In the limiting case, where consecutive rotationally symmetric configurations are chosen arbitrarily close, it is shown that the dynamics reduces to that of steady precession of the stick on a hoop.      
### 2.The xmuspeech system for multi-channel multi-party meeting transcription challenge  [ :arrow_down: ](https://arxiv.org/pdf/2202.05744.pdf)
>  This paper describes the system developed by the XMUSPEECH team for the Multi-channel Multi-party Meeting Transcription Challenge (M2MeT). For the speaker diarization task, we propose a multi-channel speaker diarization system that obtains spatial information of speaker by Difference of Arrival (DOA) technology. Speaker-spatial embedding is generated by x-vector and s-vector derived from Filter-and-Sum Beamforming (FSB) which makes the embedding more robust. Specifically, we propose a novel multi-channel sequence-to-sequence neural network architecture named Discriminative Multi-stream Neural Network (DMSNet) which consists of Attention Filter-and-Sum block (AFSB) and Conformer encoder. We explore DMSNet to address overlapped speech problem on multi-channel audio. Compared with LSTM based OSD module, we achieve a decreases of 10.1% in Detection Error Rate(DetER). By performing DMSNet based OSD module, the DER of cluster-based diarization system decrease significantly form 13.44% to 7.63%. Our best fusion system achieves 7.09% and 9.80% of the diarization error rate (DER) on evaluation set and test set.      
### 3.Cross-Block Difference Guided Fast CU Partition for VVC Intra Coding  [ :arrow_down: ](https://arxiv.org/pdf/2202.05677.pdf)
>  In this paper, we propose a new fast CU partition algorithm for VVC intra coding based on cross-block difference. This difference is measured by the gradient and the content of sub-blocks obtained from partition and is employed to guide the skipping of unnecessary horizontal and vertical partition modes. With this guidance, a fast determination of block partitions is accordingly achieved. Compared with VVC, our proposed method can save 41.64% (on average) encoding time with only 0.97% (on average) increase of BD-rate.      
### 4.Deep artificial neural network for prediction of atrial fibrillation through the analysis of 12-leads standard ECG  [ :arrow_down: ](https://arxiv.org/pdf/2202.05676.pdf)
>  Atrial Fibrillation (AF) is a heart's arrhythmia which, despite being often asymptomatic, represents an important risk factor for stroke, therefore being able to predict AF at the electrocardiogram exam, would be of great impact on actively targeting patients at high risk. In the present work we use Convolution Neural Networks to analyze ECG and predict Atrial Fibrillation starting from realistic datasets, i.e. considering fewer ECG than other studies and extending the maximal distance between ECG and AF diagnosis. We achieved 75.5% (0.75) AUC firstly increasing our dataset size by a shifting technique and secondarily using the dilation parameter of the convolution neural network. In addition we find that, contrarily to what is commonly used by clinicians reporting AF at the exam, the most informative leads for the task of predicting AF are D1 and avR. Similarly, we find that the most important frequencies to check are in the range of 5-20 Hz. Finally, we develop a net able to manage at the same time the electrocardiographic signal together with the electronic health record, showing that integration between different sources of data is a profitable path. In fact, the 2.8% gain of such net brings us to a 78.6% (std 0.77) AUC. In future works we will deepen both the integration of sources and the reason why we claim avR is the most informative lead.      
### 5.Channel Estimation with Simultaneous Reflecting and Sensing Reconfigurable Intelligent Metasurfaces  [ :arrow_down: ](https://arxiv.org/pdf/2202.05673.pdf)
>  Reconfigurable Intelligent Surfaces (RISs) are envisioned to play a key role in future wireless communications, enabling programmable radio propagation environments. They are usually considered as nearly passive planar structures that operate as adjustable reflectors, giving rise to a multitude of implementation challenges, including an inherent difficulty in estimating the underlying wireless channels. In this paper, we propose the concept of Hybrid RISs (HRISs), which do not solely reflect the impinging waveform in a controllable fashion, but are also capable of sensing and processing a portion of it via some active reception elements. We first present implementation details for this novel metasurface architecture and propose a simple model for its operation, when considered for wireless communications. As an indicative application of HRISs, we formulate and solve the individual channels identification problem for the uplink of multi-user HRIS-empowered systems. Our numerical results showcase that, in the high signal-to-noise regime, HRISs enable individual channel estimation with notably reduced amounts of pilots, compared to those needed when using a purely reflective RIS that can only estimate the cascaded channel.      
### 6.High Fidelity RF Clutter Modeling and Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2202.05666.pdf)
>  In this paper, we present a tutorial overview of state-of-the-art radio frequency (RF) clutter modeling and simulation (M&amp;S) techniques. Traditional statistical approximation based methods will be reviewed followed by more accurate physics-based stochastic transfer function clutter models that facilitate site-specific simulations anywhere on earth. The various factors that go into the computation of these transfer functions will be presented, followed by several examples across multiple RF applications. Finally, we introduce a radar challenge dataset generated using these tools that can enable testing and benchmarking of all cognitive radar algorithms and techniques.      
### 7.Spatial Reuse in Dense Wireless Areas: A Cross-layer Optimization Approach via ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2202.05655.pdf)
>  This paper introduces an efficient method for communication resource use in dense wireless areas where all nodes must communicate with a common destination node. The proposed method groups nodes based on their \newt{distance from the destination} and creates a structured multi-hop configuration in which each group can relay its neighbor's data. \newt{The large number of active radio nodes and the common direction of communication toward a single destination are exploited to reuse the limited spectrum resources in spatially separated groups}. Spectrum allocation constraints among groups are then embedded in a joint routing and resource allocation framework to optimize the route and amount of resources allocated to each node. \newt{The solution to this problem uses coordination among the lower-layers of the wireless-network protocol stack to outperform conventional approaches where these layers are decoupled. Furthermore, the structure of this problem is exploited to obtain} a semi-distributed optimization algorithm based on the alternating direction method of multipliers (ADMM) where each node can optimize its resources independently based on local channel information.      
### 8.Vehicle and License Plate Recognition with Novel Dataset for Toll Collection  [ :arrow_down: ](https://arxiv.org/pdf/2202.05631.pdf)
>  We propose an automatic framework for toll collection, consisting of three steps: vehicle type recognition, license plate localization, and reading. However, each of the three steps becomes non-trivial due to image variations caused by several factors. The traditional vehicle decorations on the front cause variations among vehicles of the same type. These decorations make license plate localization and recognition difficult due to severe background clutter and partial occlusions. Likewise, on most vehicles, specifically trucks, the position of the license plate is not consistent. Lastly, for license plate reading, the variations are induced by non-uniform font styles, sizes, and partially occluded letters and numbers. Our proposed framework takes advantage of both data availability and performance evaluation of the backbone deep learning architectures. We gather a novel dataset, \emph{Diverse Vehicle and License Plates Dataset (DVLPD)}, consisting of 10k images belonging to six vehicle types. Each image is then manually annotated for vehicle type, license plate, and its characters and digits. For each of the three tasks, we evaluate You Only Look Once (YOLO)v2, YOLOv3, YOLOv4, and FasterRCNN. For real-time implementation on a Raspberry Pi, we evaluate the lighter versions of YOLO named Tiny YOLOv3 and Tiny YOLOv4. The best Mean Average Precision (mAP@0.5) of 98.8% for vehicle type recognition, 98.5% for license plate detection, and 98.3% for license plate reading is achieved by YOLOv4, while its lighter version, i.e., Tiny YOLOv4 obtained a mAP of 97.1%, 97.4%, and 93.7% on vehicle type recognition, license plate detection, and license plate reading, respectively. The dataset and the training codes are available at <a class="link-external link-https" href="https://github.com/usama-x930/VT-LPR" rel="external noopener nofollow">this https URL</a>      
### 9.A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation  [ :arrow_down: ](https://arxiv.org/pdf/2202.05623.pdf)
>  Classic image inpainting is a restoration method that reconstructs missing image parts. However, a carefully selected mask of known pixels that yield a high quality inpainting can also act as a sparse image representation. This challenging spatial optimisation problem is essential for practical applications such as compression. So far, it has been almost exclusively addressed by model-based approaches. First attempts with neural networks seem promising, but are tailored towards specific inpainting operators or require postprocessing. To address this issue, we propose the first generative adversarial network for spatial inpainting data optimisation. In contrast to previous approaches, it allows joint training of an inpainting generator and a corresponding mask optimisation network. With a Wasserstein distance, we ensure that our inpainting results accurately reflect the statistics of natural images. This yields significant improvements in visual quality and speed over conventional stochastic models and also outperforms current spatial optimisation networks.      
### 10.Dilated convolutional neural network-based deep reference picture generation for video compression  [ :arrow_down: ](https://arxiv.org/pdf/2202.05514.pdf)
>  Motion estimation and motion compensation are indispensable parts of inter prediction in video coding. Since the motion vector of objects is mostly in fractional pixel units, original reference pictures may not accurately provide a suitable reference for motion compensation. In this paper, we propose a deep reference picture generator which can create a picture that is more relevant to the current encoding frame, thereby further reducing temporal redundancy and improving video compression efficiency. Inspired by the recent progress of Convolutional Neural Network(CNN), this paper proposes to use a dilated CNN to build the generator. Moreover, we insert the generated deep picture into Versatile Video Coding(VVC) as a reference picture and perform a comprehensive set of experiments to evaluate the effectiveness of our network on the latest VVC Test Model VTM. The experimental results demonstrate that our proposed method achieves on average 9.7% bit saving compared with VVC under low-delay P configuration.      
### 11.Entroformer: A Transformer-based Entropy Model for Learned Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2202.05492.pdf)
>  One critical component in lossy deep image compression is the entropy model, which predicts the probability distribution of the quantized latent representation in the encoding and decoding modules. Previous works build entropy models upon convolutional neural networks which are inefficient in capturing global dependencies. In this work, we propose a novel transformer-based entropy model, termed Entroformer, to capture long-range dependencies in probability distribution estimation effectively and efficiently. Different from vision transformers in image classification, the Entroformer is highly optimized for image compression, including a top-k self-attention and a diamond relative position encoding. Meanwhile, we further expand this architecture with a parallel bidirectional context model to speed up the decoding process. The experiments show that the Entroformer achieves state-of-the-art performance on image compression while being time-efficient.      
### 12.Infrastructure-enabled GPS Spoofing Detection and Correction  [ :arrow_down: ](https://arxiv.org/pdf/2202.05463.pdf)
>  Accurate and robust localization is crucial for supporting high-level driving automation and safety. Modern localization solutions rely on various sensors, among which GPS has been and will continue to be essential. However, GPS can be vulnerable to malicious attacks and GPS spoofing has been identified as a high threat. GPS spoofing injects false information into true GPS measurements, aiming to deviate a vehicle from its true trajectory, endangering the safety of road users. With various types of vehicle-based sensors emerging, recent studies propose to detect GPS spoofing by fusing data from multiple sensors and identifying inconsistencies among them. Yet, these methods often require sophisticated algorithms and cannot handle stealthy or coordinated attacks targeting multiple sensors. With infrastructure becoming increasingly important in supporting emerging vehicle technologies and systems (e.g., automated vehicles), this study explores the potential of applying infrastructure data in defending against GPS spoofing. We propose an infrastructure-enabled method by deploying roadside infrastructure as an independent, secured data source. A real-time detector, based on the Isolation Forest, is constructed to detect GPS spoofing. Once spoofing is detected, GPS measurements are isolated, and the potentially compromised location estimator is corrected using the infrastructure data. The proposed method relies less on vehicular onboard data than existing solutions. Enabled by the secure infrastructure data, we can design a simpler yet more effective solution against GPS spoofing, compared with state-of-the-art defense methods. We test the proposed method using both simulation data and real-world GPS data, and show its effectiveness in defending various types of GPS spoofing attacks, including a type of stealthy attacks that are proposed to fail the production-grade autonomous driving systems.      
### 13.Wind power ramp prediction algorithm based on wavelet deep belief network  [ :arrow_down: ](https://arxiv.org/pdf/2202.05430.pdf)
>  The wind power ramp events threaten the power grid safety significantly. To improve the ramp prediction accuracy, a hybrid wavelet deep belief network algorithm with adaptive feature selection (WDBNAFS) is proposed. First, the wind power characteristic is analyzed. Then, wavelet decomposition is addressed to the time series, and an adaptive feature selection algorithm is proposed to select the inputs of the prediction model. Finally, a deep belief network is employed to predict the wind power ramp event, and the proposed WDBNAFS was testified with the experiments based on the practical data. The simulation results demonstrate that the prediction accuracy of the proposed algorithm is more than 90%.      
### 14.Neural Architecture Search for Energy Efficient Always-on Audio Models  [ :arrow_down: ](https://arxiv.org/pdf/2202.05397.pdf)
>  Mobile and edge computing devices for always-on audio classification require energy-efficient neural network architectures. We present a neural architecture search (NAS) that optimizes accuracy, energy efficiency and memory usage. The search is run on Vizier, a black-box optimization service. We present a search strategy that uses both Bayesian and regularized evolutionary search with particle swarms, and employs early-stopping to reduce the computational burden. The search returns architectures for a sound-event classification dataset based upon AudioSet with similar accuracy to MobileNetV1/V2 implementations but with an order of magnitude less energy per inference and a much smaller memory footprint.      
### 15.Enhancing ASR for Stuttered Speech with Limited Data Using Detect and Pass  [ :arrow_down: ](https://arxiv.org/pdf/2202.05396.pdf)
>  It is estimated that around 70 million people worldwide are affected by a speech disorder called stuttering. With recent advances in Automatic Speech Recognition (ASR), voice assistants are increasingly useful in our everyday lives. Many technologies in education, retail, telecommunication and healthcare can now be operated through voice. Unfortunately, these benefits are not accessible for People Who Stutter (PWS). We propose a simple but effective method called 'Detect and Pass' to make modern ASR systems accessible for People Who Stutter in a limited data setting. The algorithm uses a context aware classifier trained on a limited amount of data, to detect acoustic frames that contain stutter. To improve robustness on stuttered speech, this extra information is passed on to the ASR model to be utilized during inference. Our experiments show a reduction of 12.18% to 71.24% in Word Error Rate (WER) across various state of the art ASR systems. Upon varying the threshold of the associated posterior probability of stutter for each stacked frame used in determining low frame rate (LFR) acoustic features, we were able to determine an optimal setting that reduced the WER by 23.93% to 71.67% across different ASR systems.      
### 16.Give me a knee radiograph, I will tell you where the knee joint area is: a deep convolutional neural network adventure  [ :arrow_down: ](https://arxiv.org/pdf/2202.05382.pdf)
>  Knee pain is undoubtedly the most common musculoskeletal symptom that impairs quality of life, confines mobility and functionality across all ages. Knee pain is clinically evaluated by routine radiographs, where the widespread adoption of radiographic images and their availability at low cost, make them the principle component in the assessment of knee pain and knee pathologies, such as arthritis, trauma, and sport injuries. However, interpretation of the knee radiographs is still highly subjective, and overlapping structures within the radiographs and the large volume of images needing to be analyzed on a daily basis, make interpretation challenging for both naive and experienced practitioners. There is thus a need to implement an artificial intelligence strategy to objectively and automatically interpret knee radiographs, facilitating triage of abnormal radiographs in a timely fashion. The current work proposes an accurate and effective pipeline for autonomous detection, localization, and classification of knee joint area in plain radiographs combining the You Only Look Once (YOLO v3) deep convolutional neural network with a large and fully-annotated knee radiographs dataset. The present work is expected to stimulate more interest from the deep learning computer vision community to this pragmatic and clinical application.      
### 17.Adaptive Control of Distributed Energy Resources for Distribution Grid Voltage Stability  [ :arrow_down: ](https://arxiv.org/pdf/2202.05373.pdf)
>  Volt-VAR and Volt-Watt functionality in photovoltaic (PV) smart inverters provide mechanisms to ensure system voltage magnitudes and power factors remain within acceptable limits. However, these control functions can become unstable, introducing oscillations in system voltages when not appropriately configured or maliciously altered during a cyberattack. In the event that Volt-VAR and Volt-Watt control functions in a portion of PV smart inverters in a distribution grid are unstable, the proposed adaptation scheme utilizes the remaining and stably-behaving PV smart inverters and other Distributed Energy Resources to mitigate the effect of the instability. The adaptation mechanism is entirely decentralized, model-free, communication-free, and requires virtually no external configuration. We provide a derivation of the adaptive control approach and validate the algorithm in experiments on the IEEE 37 and 8500 node test feeders.      
### 18.Structured light dark-field microscope  [ :arrow_down: ](https://arxiv.org/pdf/2202.05357.pdf)
>  A resolution-enhanced dark-field microscope by structured light illumination is proposed to improve resolution and contrast. A set of phase-shifted fringes are projected to the sample plane at large angle to capture modulated dark-field images, from which resolution- and contrast-enhanced dark-field image, as well as sectioned dark-field image, can be obtained. Human tissue samples are tested to demonstrate the resolution and contrast enhancement. The system can be implemented in transmission-mode and reflectance-mode, with potential applications ranging from defect detection to biomedical imaging.      
### 19.Optimal Transport for Super Resolution Applied to Astronomy Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2202.05354.pdf)
>  Super resolution is an essential tool in optics, especially on interstellar scales, due to physical laws restricting possible imaging resolution. We propose using optimal transport and entropy for super resolution applications. We prove that the reconstruction is accurate when sparsity is known and noise or distortion is small enough. We prove that the optimizer is stable and robust to noise and perturbations. We compare this method to a state of the art convolutional neural network and get similar results for much less computational cost and greater methodological flexibility.      
### 20.Neural Network Training Using Closed-Loop Data: Hazards and an Instrumental Variable (IVNN) Solution  [ :arrow_down: ](https://arxiv.org/pdf/2202.05337.pdf)
>  An increasing trend in the use of neural networks in control systems is being observed. The aim of this paper is to reveal that the straightforward application of learning neural network feedforward controllers with closed-loop data may introduce parameter inconsistency that degrades control performance, and to provide a solution. The proposed method employs instrumental variables to ensure consistent parameter estimates. A nonlinear system example reveals that the developed instrumental variable neural network (IVNN) approach asymptotically recovers the optimal solution, while pre-existing approaches are shown to lead to inconsistent estimates.      
### 21.Dynamic Background Subtraction by Generative Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.05336.pdf)
>  Background subtraction is a significant task in computer vision and an essential step for many real world applications. One of the challenges for background subtraction methods is dynamic background, which constitute stochastic movements in some parts of the background. In this paper, we have proposed a new background subtraction method, called DBSGen, which uses two generative neural networks, one for dynamic motion removal and another for background generation. At the end, the foreground moving objects are obtained by a pixel-wise distance threshold based on a dynamic entropy map. The proposed method has a unified framework that can be optimized in an end-to-end and unsupervised fashion. The performance of the method is evaluated over dynamic background sequences and it outperforms most of state-of-the-art methods. Our code is publicly available at <a class="link-external link-https" href="https://github.com/FatemeBahri/DBSGen" rel="external noopener nofollow">this https URL</a>.      
### 22.Mining the manifolds of deep generative models for multiple data-consistent solutions of ill-posed tomographic imaging problems  [ :arrow_down: ](https://arxiv.org/pdf/2202.05311.pdf)
>  Tomographic imaging is in general an ill-posed inverse problem. Typically, a single regularized image estimate of the sought-after object is obtained from tomographic measurements. However, there may be multiple objects that are all consistent with the same measurement data. The ability to generate such alternate solutions is important because it may enable new assessments of imaging systems. In principle, this can be achieved by means of posterior sampling methods. In recent years, deep neural networks have been employed for posterior sampling with promising results. However, such methods are not yet for use with large-scale tomographic imaging applications. On the other hand, empirical sampling methods may be computationally feasible for large-scale imaging systems and enable uncertainty quantification for practical applications. Empirical sampling involves solving a regularized inverse problem within a stochastic optimization framework in order to obtain alternate data-consistent solutions. In this work, we propose a new empirical sampling method that computes multiple solutions of a tomographic inverse problem that are consistent with the same acquired measurement data. The method operates by repeatedly solving an optimization problem in the latent space of a style-based generative adversarial network (StyleGAN), and was inspired by the Photo Upsampling via Latent Space Exploration (PULSE) method that was developed for super-resolution tasks. The proposed method is demonstrated and analyzed via numerical studies that involve two stylized tomographic imaging modalities. These studies establish the ability of the method to perform efficient empirical sampling and uncertainty quantification.      
### 23.Towards a Guideline for Evaluation Metrics in Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2202.05273.pdf)
>  In the last decade, research on artificial intelligence has seen rapid growth with deep learning models, especially in the field of medical image segmentation. Various studies demonstrated that these models have powerful prediction capabilities and achieved similar results as clinicians. However, recent studies revealed that the evaluation in image segmentation studies lacks reliable model performance assessment and showed statistical bias by incorrect metric implementation or usage. Thus, this work provides an overview and interpretation guide on the following metrics for medical image segmentation evaluation in binary as well as multi-class problems: Dice similarity coefficient, Jaccard, Sensitivity, Specificity, Rand index, ROC curves, Cohen's Kappa, and Hausdorff distance. As a summary, we propose a guideline for standardized medical image segmentation evaluation to improve evaluation quality, reproducibility, and comparability in the research field.      
### 24.A Deep Learning Approach for Digital ColorReconstruction of Lenticular Films  [ :arrow_down: ](https://arxiv.org/pdf/2202.05270.pdf)
>  We propose the first accurate digitization and color reconstruction process for historical lenticular film that is robust to artifacts. Lenticular films emerged in the 1920s and were one of the first technologies that permitted to capture full color information in motion. The technology leverages an RGB filter and cylindrical lenticules embossed on the film surface to encode the color in the horizontal spatial dimension of the image. To project the pictures the encoding process was reversed using an appropriate analog device. In this work, we introduce an automated, fully digital pipeline to process the scan of lenticular films and colorize the image. Our method merges deep learning with a model-based approach in order to maximize the performance while making sure that the reconstructed colored images truthfully match the encoded color information. Our model employs different strategies to achieve an effective color reconstruction, in particular (i) we use data augmentation to create a robust lenticule segmentation network, (ii) we fit the lenticules raster prediction to obtain a precise vectorial lenticule localization, and (iii) we train a colorization network that predicts interpolation coefficients in order to obtain a truthful colorization. We validate the proposed method on a lenticular film dataset and compare it to other approaches. Since no colored groundtruth is available as reference, we conduct a user study to validate our method in a subjective manner. The results of the study show that the proposed method is largely preferred with respect to other existing and baseline methods.      
### 25.A Plug-and-Play Approach to Multiparametric Quantitative MRI: Image Reconstruction using Pre-Trained Deep Denoisers  [ :arrow_down: ](https://arxiv.org/pdf/2202.05269.pdf)
>  Current spatiotemporal deep learning approaches to Magnetic Resonance Fingerprinting (MRF) build artefact-removal models customised to a particular k-space subsampling pattern which is used for fast (compressed) acquisition. This may not be useful when the acquisition process is unknown during training of the deep learning model and/or changes during testing time. This paper proposes an iterative deep learning plug-and-play reconstruction approach to MRF which is adaptive to the forward acquisition process. Spatiotemporal image priors are learned by an image denoiser i.e. a Convolutional Neural Network (CNN), trained to remove generic white gaussian noise (not a particular subsampling artefact) from data. This CNN denoiser is then used as a data-driven shrinkage operator within the iterative reconstruction algorithm. This algorithm with the same denoiser model is then tested on two simulated acquisition processes with distinct subsampling patterns. The results show consistent de-aliasing performance against both acquisition schemes and accurate mapping of tissues' quantitative bio-properties. Software available: <a class="link-external link-https" href="https://github.com/ketanfatania/QMRI-PnP-Recon-POC" rel="external noopener nofollow">this https URL</a>      
### 26.HNF-Netv2 for Brain Tumor Segmentation using multi-modal MR Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2202.05268.pdf)
>  In our previous work, $i.e.$, HNF-Net, high-resolution feature representation and light-weight non-local self-attention mechanism are exploited for brain tumor segmentation using multi-modal MR imaging. In this paper, we extend our HNF-Net to HNF-Netv2 by adding inter-scale and intra-scale semantic discrimination enhancing blocks to further exploit global semantic discrimination for the obtained high-resolution features. We trained and evaluated our HNF-Netv2 on the multi-modal Brain Tumor Segmentation Challenge (BraTS) 2021 dataset. The result on the test set shows that our HNF-Netv2 achieved the average Dice scores of 0.878514, 0.872985, and 0.924919, as well as the Hausdorff distances ($95\%$) of 8.9184, 16.2530, and 4.4895 for the enhancing tumor, tumor core, and whole tumor, respectively. Our method won the RSNA 2021 Brain Tumor AI Challenge Prize (Segmentation Task), which ranks 8th out of all 1250 submitted results.      
### 27.The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2202.05817.pdf)
>  The use of Semantic Technologies - in particular the Semantic Web - has revealed to be a great tool for describing the cultural heritage domain and artistic practices. However, the panorama of ontologies for musicological applications seems to be limited and restricted to specific applications. In this research, we propose HaMSE, an ontology capable of describing musical features that can assist musicological research. More specifically, HaMSE proposes to address sues that have been affecting musicological research for decades: the representation of music and the relationship between quantitative and qualitative data. To do this, HaMSE allows the alignment between different music representation systems and describes a set of musicological features that can allow the music analysis at different granularity levels.      
### 28.Rate-matching the regret lower-bound in the linear quadratic regulator with unknown dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2202.05799.pdf)
>  The theory of reinforcement learning currently suffers from a mismatch between its empirical performance and the theoretical characterization of its performance, with consequences for, e.g., the understanding of sample efficiency, safety, and robustness. The linear quadratic regulator with unknown dynamics is a fundamental reinforcement learning setting with significant structure in its dynamics and cost function, yet even in this setting there is a gap between the best known regret lower-bound of $\Omega_p(\sqrt{T})$ and the best known upper-bound of $O_p(\sqrt{T}\,\text{polylog}(T))$. The contribution of this paper is to close that gap by establishing a novel regret upper-bound of $O_p(\sqrt{T})$. Our proof is constructive in that it analyzes the regret of a concrete algorithm, and simultaneously establishes an estimation error bound on the dynamics of $O_p(T^{-1/4})$ which is also the first to match the rate of a known lower-bound. The two keys to our improved proof technique are (1) a more precise upper- and lower-bound on the system Gram matrix and (2) a self-bounding argument for the expected estimation error of the optimal controller.      
### 29.A Novel Speech Intelligibility Enhancement Model based on CanonicalCorrelation and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.05756.pdf)
>  Current deep learning (DL) based approaches to speech intelligibility enhancement in noisy environments are often trained to minimise the feature distance between noise-free speech and enhanced speech signals. Despite improving the speech quality, such approaches do not deliver required levels of speech intelligibility in everyday noisy environments . Intelligibility-oriented (I-O) loss functions have recently been developed to train DL approaches for robust speech enhancement. Here, we formulate, for the first time, a novel canonical correlation based I-O loss function to more effectively train DL algorithms. Specifically, we present a canonical-correlation based short-time objective intelligibility (CC-STOI) cost function to train a fully convolutional neural network (FCN) model. We carry out comparative simulation experiments to show that our CC-STOI based speech enhancement framework outperforms state-of-the-art DL models trained with conventional distance-based and STOI-based loss functions, using objective and subjective evaluation measures for case of both unseen speakers and noises. Ongoing future work is evaluating the proposed approach for design of robust hearing-assistive technology.      
### 30.Estimating flow fields with Reduced Order Models of Centrifugal Pumps  [ :arrow_down: ](https://arxiv.org/pdf/2202.05736.pdf)
>  The estimation of fluid flows inside a centrifugal pump in realtime is a challenging task that cannot be achieved with long-established methods like CFD due to their computational demands. We use a projection-based reduced order model (ROM) instead. Based on this ROM, a realtime observer can be devised that estimates the temporally and spatially resolved velocity and pressure fields inside the pump. The entire fluid-solid domain is treated as a fluid in order to be able to consider moving rigid bodies in the reduction method. A greedy algorithm is introduced for finding suitable and as few measurement locations as possible. Robust observability is ensured with an extended Kalman filter, which is based on a time-variant observability matrix obtained from the nonlinear velocity ROM. We present the results of the velocity and pressure ROMs based on a unsteady Reynolds-averaged Navier-Stokes CFD simulation of a 2D centrifugal model pump, as well as the results for the extended Kalman filter.      
### 31.SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography  [ :arrow_down: ](https://arxiv.org/pdf/2202.05735.pdf)
>  Introduction: Sleep staging is an essential component in the diagnosis of sleep disorders and management of sleep health. It is traditionally measured in a clinical setting and requires a labor-intensive labeling process. We hypothesize that it is possible to perform robust 4-class sleep staging using the raw photoplethysmography (PPG) time series and modern advances in deep learning (DL). Methods: We used two publicly available sleep databases that included raw PPG recordings, totalling 2,374 patients and 23,055 hours. We developed SleepPPG-Net, a DL model for 4-class sleep staging from the raw PPG time series. SleepPPG-Net was trained end-to-end and consists of a residual convolutional network for automatic feature extraction and a temporal convolutional network to capture long-range contextual information. We benchmarked the performance of SleepPPG-Net against models based on the best-reported state-of-the-art (SOTA) algorithms. Results: When benchmarked on a held-out test set, SleepPPG-Net obtained a median Cohen's Kappa ($\kappa$) score of 0.75 against 0.69 for the best SOTA approach. SleepPPG-Net showed good generalization performance to an external database, obtaining a $\kappa$ score of 0.74 after transfer learning. Perspective: Overall, SleepPPG-Net provides new SOTA performance. In addition, performance is high enough to open the path to the development of wearables that meet the requirements for usage in clinical applications such as the diagnosis and monitoring of obstructive sleep apnea.      
### 32.On the Detection of Adaptive Adversarial Attacks in Speaker Verification Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.05725.pdf)
>  Speaker verification systems have been widely used in smart phones and Internet of things devices to identify a legitimate user. In recent work, it has been shown that adversarial attacks, such as FAKEBOB, can work effectively against speaker verification systems. The goal of this paper is to design a detector that can distinguish an original audio from an audio contaminated by adversarial attacks. Specifically, our designed detector, called MEH-FEST, calculates the minimum energy in high frequencies from the short-time Fourier transform of an audio and uses it as a detection metric. Through both analysis and experiments, we show that our proposed detector is easy to implement, fast to process an input audio, and effective in determining whether an audio is corrupted by FAKEBOB attacks. The experimental results indicate that the detector is extremely effective: with near zero false positive and false negative rates for detecting FAKEBOB attacks in Gaussian mixture model (GMM) and i-vector speaker verification systems. Moreover, adaptive adversarial attacks against our proposed detector and their countermeasures are discussed and studied, showing the game between attackers and defenders.      
### 33.Audio Defect Detection in Music with Deep Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.05718.pdf)
>  With increasing amounts of music being digitally transferred from production to distribution, automatic means of determining media quality are needed. Protection mechanisms in digital audio processing tools have not eliminated the need of production entities located downstream the distribution chain to assess audio quality and detect defects inserted further upstream. Such analysis often relies on the received audio and scarce meta-data alone. Deliberate use of artefacts such as clicks in popular music as well as more recent defects stemming from corruption in modern audio encodings call for data-centric and context sensitive solutions for detection. We present a convolutional network architecture following end-to-end encoder decoder configuration to develop detectors for two exemplary audio defects. A click detector is trained and compared to a traditional signal processing method, with a discussion on context sensitivity. Additional post-processing is used for data augmentation and workflow simulation. The ability of our models to capture variance is explored in a detector for artefacts from decompression of corrupted MP3 compressed audio. For both tasks we describe the synthetic generation of artefacts for controlled detector training and evaluation. We evaluate our detectors on the large open-source Free Music Archive (FMA) and genre-specific datasets.      
### 34.Modeling Reservoir Release Using Pseudo-Prospective Learning and Physical Simulations to Predict Water Temperature  [ :arrow_down: ](https://arxiv.org/pdf/2202.05714.pdf)
>  This paper proposes a new data-driven method for predicting water temperature in stream networks with reservoirs. The water flows released from reservoirs greatly affect the water temperature of downstream river segments. However, the information of released water flow is often not available for many reservoirs, which makes it difficult for data-driven models to capture the impact to downstream river segments. In this paper, we first build a state-aware graph model to represent the interactions amongst streams and reservoirs, and then propose a parallel learning structure to extract the reservoir release information and use it to improve the prediction. In particular, for reservoirs with no available release information, we mimic the water managers' release decision process through a pseudo-prospective learning method, which infers the release information from anticipated water temperature dynamics. For reservoirs with the release information, we leverage a physics-based model to simulate the water release temperature and transfer such information to guide the learning process for other reservoirs. The evaluation for the Delaware River Basin shows that the proposed method brings over 10\% accuracy improvement over existing data-driven models for stream temperature prediction when the release data is not available for any reservoirs. The performance is further improved after we incorporate the release data and physical simulations for a subset of reservoirs.      
### 35.Graphon-aided Joint Estimation of Multiple Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2202.05686.pdf)
>  We consider the problem of estimating the topology of multiple networks from nodal observations, where these networks are assumed to be drawn from the same (unknown) random graph model. We adopt a graphon as our random graph model, which is a nonparametric model from which graphs of potentially different sizes can be drawn. The versatility of graphons allows us to tackle the joint inference problem even for the cases where the graphs to be recovered contain different number of nodes and lack precise alignment across the graphs. Our solution is based on combining a maximum likelihood penalty with graphon estimation schemes and can be used to augment existing network inference methods. We validate our proposed approach by comparing its performance against competing methods in synthetic and real-world datasets.      
### 36.A Novel Chaos-based Light-weight Image Encryption Scheme for Multi-modal Hearing Aids  [ :arrow_down: ](https://arxiv.org/pdf/2202.05662.pdf)
>  Multimodal hearing aids (HAs) aim to deliver more intelligible audio in noisy environments by contextually sensing and processing data in the form of not only audio but also visual information (e.g. lip reading). Machine learning techniques can play a pivotal role for the contextually processing of multimodal data. However, since the computational power of HA devices is low, therefore this data must be processed either on the edge or cloud which, in turn, poses privacy concerns for sensitive user data. Existing literature proposes several techniques for data encryption but their computational complexity is a major bottleneck to meet strict latency requirements for development of future multi-modal hearing aids. To overcome this problem, this paper proposes a novel real-time audio/visual data encryption scheme based on chaos-based encryption using the Tangent-Delay Ellipse Reflecting Cavity-Map System (TD-ERCS) map and Non-linear Chaotic (NCA) Algorithm. The results achieved against different security parameters, including Correlation Coefficient, Unified Averaged Changed Intensity (UACI), Key Sensitivity Analysis, Number of Changing Pixel Rate (NPCR), Mean-Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Entropy test, and Chi-test, indicate that the newly proposed scheme is more lightweight due to its lower execution time as compared to existing schemes and more secure due to increased key-space against modern brute-force attacks.      
### 37.Performance and limitations of dual-comb based ranging systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.05644.pdf)
>  Dual-comb LiDARs have the potential to perform high-resolution ranging at high speed. Here, through an implementation involving electro-optic modulators and heterodyne detection, we quantify the ranging systems trade-off between precision and non-ambiguity range (NAR) using a unique performance factor. We highlight the influence of the comb amplitude envelope on the precision with a distance measurement limited by the repetition rate of the optical comb. The influence of the combs repetition rate on the NAR and on the precision is illustrated through a setup allowing distance measurement with a tunable NAR. Finally, we demonstrate the impossibility to resolve different targets, quantify the impact on the measured distance and develop on the conditions in which non-linear effects of the interference make the measurement impossible.      
### 38.Audio-Based Deep Learning Frameworks for Detecting COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2202.05626.pdf)
>  This paper evaluates a wide range of audio-based deep learning frameworks applied to the breathing, cough, and speech sounds for detecting COVID-19. In general, the audio recording inputs are transformed into low-level spectrogram features, then they are fed into pre-trained deep learning models to extract high-level embedding features. Next, the dimension of these high-level embedding features are reduced before finetuning using Light Gradient Boosting Machine (LightGBM) as a back-end classification. Our experiments on the Second DiCOVA Challenge achieved the highest Area Under the Curve (AUC), F1 score, sensitivity score, and specificity score of 89.03%, 64.41%, 63.33%, and 95.13%, respectively. Based on these scores, our method outperforms the state-of-the-art systems, and improves the challenge baseline by 4.33%, 6.00% and 8.33% in terms of AUC, F1 score and sensitivity score, respectively.      
### 39.RIS-Aided Wireless Communications: Extra Degrees of Freedom via Rotation and Location Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2202.05569.pdf)
>  We consider the extra degree of freedom offered by the rotation of the reconfigurable intelligent surface (RIS) plane and investigate its potential in improving the performance of RIS-assisted wireless communication systems. By considering radiation pattern modeling at all involved nodes, we first derive the composite channel gain and present a closed-form upper bound for the system ergodic capacity over cascade Rician fading channels. Then, we reconstruct the composite channel gain by taking the rotations at the RIS plane, transmit antenna, and receive antenna into account, and extract the optimal rotation angles after investigating their impacts on the capacity. Moreover, we present a location-dependent expression of the ergodic capacity and investigate the RIS deployment strategy, i.e. the joint rotation adjustment and location selection. Finally, simulation results verify the accuracy of the theoretical analyses and deployment strategy. Although the RIS location has a big impact on the performance, our results showcase that the RIS rotation plays a more important role. In other words, we can obtain a considerable improvement by properly rotating the RIS rather than moving it over a wide area. For instance, we can achieve more than 200\% performance improvement through rotating the RIS by 42.14$^{\circ}$, while an 150\% improvement is obtained by shifting the RIS over 400 meters.      
### 40.A Partial Reciprocity-based Channel Prediction Framework for FDD massive MIMO with High Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2202.05564.pdf)
>  Massive multiple-input multiple-output (MIMO) is believed to deliver unrepresented spectral efficiency gains for 5G and beyond. However, a practical challenge arises during its commercial deployment, which is known as the "curse of mobility". The performance of massive MIMO drops alarmingly when the velocity level of user increases. In this paper, we tackle the problem in frequency division duplex (FDD) massive MIMO with a novel Channel State Information (CSI) acquisition framework. A joint angle-delay-Doppler (JADD) wideband beamformer is proposed for channel training. Our idea consists in the exploitation of the partial channel reciprocity of FDD and the angle-delay-Doppler channel structure. More precisely, the base station (BS) estimates the angle-delay-Doppler information of the UL channel based on UL pilots using Matrix Pencil method. It then computes the wideband JADD beamformers according to the extracted parameters. Afterwards, the user estimates and feeds back some scalar coefficients for the BS to reconstruct the predicted DL channel. Asymptotic analysis shows that the CSI prediction error converges to zero when the number of BS antennas and the bandwidth increases. Numerical results with industrial channel model demonstrate that our framework can well adapt to high speed (350 km/h), large CSI delay (10 ms) and channel sample noise.      
### 41.A Sonification of the zCOSMOS Galaxy Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2202.05539.pdf)
>  Sonification is the transformation of data into acoustic signals, achievable through different techniques. Sonification can be defined as a way to represent data values and relations as perceivable sounds, aiming at facilitating their communication and interpretation. Like data visualization provides meaning via images, sonification conveys meaning via sound. Sonification approaches are useful in a number of scenario. A first case is the possibility to receive information while keeping other sensory channels free, like in medical environment, in driving experience, etc. Another scenario addresses an easier recognition of patterns when data present high dimensionality and cardinality. Finally, sonification can be applied to presentation and dissemination initiatives, also with artistic goals. The zCOSMOS dataset contains detailed data about almost 20000 galaxies, describing the evolution of a relatively small portion of the universe in the last 10 million years in terms of galaxy mass, absolute luminosity, redshift, distance, age, and star formation rate. The present paper proposes a sonification for the mentioned dataset, with the following goals: i) providing a general description of the dataset, accessible via sound, which could also make unnoticed patterns emerge; ii) realizing an artistic but scientifically accurate sonic portrait of a portion of the universe, thus filling the gap between art and science in the context of scientific dissemination and so-called "edutainment"; iii) adding value to the dataset, since also scientific data and achievements must be considered as a cultural heritage that needs to be preserved and enhanced. Both scientific and technological aspects of the sonification are addressed.      
### 42.Unsupervised HDR Imaging: What Can Be Learned from a Single 8-bit Video?  [ :arrow_down: ](https://arxiv.org/pdf/2202.05522.pdf)
>  Recently, Deep Learning-based methods for inverse tone-mapping standard dynamic range (SDR) images to obtain high dynamic range (HDR) images have become very popular. These methods manage to fill over-exposed areas convincingly both in terms of details and dynamic range. Typically, these methods, to be effective, need to learn from large datasets and to transfer this knowledge to the network weights. In this work, we tackle this problem from a completely different perspective. What can we learn from a single SDR video? With the presented zero-shot approach, we show that, in many cases, a single SDR video is sufficient to be able to generate an HDR video of the same quality or better than other state-of-the-art methods.      
### 43.Concurrent Training of a Control Policy and a State Estimator for Dynamic and Robust Legged Locomotion  [ :arrow_down: ](https://arxiv.org/pdf/2202.05481.pdf)
>  In this paper, we propose a locomotion training framework where a control policy and a state estimator are trained concurrently. The framework consists of a policy network which outputs the desired joint positions and a state estimation network which outputs estimates of the robot's states such as the base linear velocity, foot height, and contact probability. We exploit a fast simulation environment to train the networks and the trained networks are transferred to the real robot. The trained policy and state estimator are capable of traversing diverse terrains such as a hill, slippery plate, and bumpy road. We also demonstrate that the learned policy can run at up to 3.75 m/s on normal flat ground and 3.54 m/s on a slippery plate with the coefficient of friction of 0.22.      
### 44.FAAG: Fast Adversarial Audio Generation through Interactive Attack Optimisation  [ :arrow_down: ](https://arxiv.org/pdf/2202.05416.pdf)
>  Automatic Speech Recognition services (ASRs) inherit deep neural networks' vulnerabilities like crafted adversarial examples. Existing methods often suffer from low efficiency because the target phases are added to the entire audio sample, resulting in high demand for computational resources. This paper proposes a novel scheme named FAAG as an iterative optimization-based method to generate targeted adversarial examples quickly. By injecting the noise over the beginning part of the audio, FAAG generates adversarial audio in high quality with a high success rate timely. Specifically, we use audio's logits output to map each character in the transcription to an approximate position of the audio's frame. Thus, an adversarial example can be generated by FAAG in approximately two minutes using CPUs only and around ten seconds with one GPU while maintaining an average success rate over 85%. Specifically, the FAAG method can speed up around 60% compared with the baseline method during the adversarial example generation process. Furthermore, we found that appending benign audio to any suspicious examples can effectively defend against the targeted adversarial attack. We hope that this work paves the way for inventing new adversarial attacks against speech recognition with computational constraints.      
### 45.DDoS-UNet: Incorporating temporal information using Dynamic Dual-channel UNet for enhancing super-resolution of dynamic MRI  [ :arrow_down: ](https://arxiv.org/pdf/2202.05355.pdf)
>  Magnetic resonance imaging (MRI) provides high spatial resolution and excellent soft-tissue contrast without using harmful ionising radiation. Dynamic MRI is an essential tool for interventions to visualise movements or changes of the target organ. However, such MRI acquisition with high temporal resolution suffers from limited spatial resolution - also known as the spatio-temporal trade-off of dynamic MRI. Several approaches, including deep learning based super-resolution approaches, have been proposed to mitigate this trade-off. Nevertheless, such an approach typically aims to super-resolve each time-point separately, treating them as individual volumes. This research addresses the problem by creating a deep learning model which attempts to learn both spatial and temporal relationships. A modified 3D UNet model, DDoS-UNet, is proposed - which takes the low-resolution volume of the current time-point along with a prior image volume. Initially, the network is supplied with a static high-resolution planning scan as the prior image along with the low-resolution input to super-resolve the first time-point. Then it continues step-wise by using the super-resolved time-points as the prior image while super-resolving the subsequent time-points. The model performance was tested with 3D dynamic data that was undersampled to different in-plane levels. The proposed network achieved an average SSIM value of 0.951$\pm$0.017 while reconstructing the lowest resolution data (i.e. only 4\% of the k-space acquired) - which could result in a theoretical acceleration factor of 25. The proposed approach can be used to reduce the required scan-time while achieving high spatial resolution.      
### 46.An Initial Description of Capabilities and Constraints for a Computational Auditory System (an Artificial Ear) for Cognitive Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2202.05332.pdf)
>  We present an initial set of factors, features, and constraints for developing a Computational Auditory System (CAS, aka less formally an artificial ear, AE) for use by cognitive architectures. We start to define a CAS and what tasks it should be able to perform. We then outline the features of a CAS for use by a cognitive architecture and factors that influence its performance. We conclude with an update on what has been created so far and insights on how to create and use a CAS in a cognitive architecture and include a set of functionalities for an artificial ear.      
### 47.Universal Learning Waveform Selection Strategies for Adaptive Target Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2202.05294.pdf)
>  Online selection of optimal waveforms for target tracking with active sensors has long been a problem of interest. Many conventional solutions utilize an estimation-theoretic interpretation, in which a waveform-specific Cramér-Rao lower bound on measurement error is used to select the optimal waveform for each tracking step. However, this approach is only valid in the high SNR regime, and requires a rather restrictive set of assumptions regarding the target motion and measurement models. Further, due to computational concerns, many traditional approaches are limited to near-term, or myopic, optimization, even though radar scenes exhibit strong temporal correlation. More recently, reinforcement learning has been proposed for waveform selection, in which the problem is framed as a Markov decision process (MDP), allowing for long-term planning. However, a major limitation of reinforcement learning is that the memory length of the underlying Markov process is often unknown for realistic target and channel dynamics, and a more general framework is desirable. This work develops a universal sequential waveform selection scheme which asymptotically achieves Bellman optimality in any radar scene which can be modeled as a $U^{\text{th}}$ order Markov process for a finite, but unknown, integer $U$. Our approach is based on well-established tools from the field of universal source coding, where a stationary source is parsed into variable length phrases in order to build a context-tree, which is used as a probabalistic model for the scene's behavior. We show that an algorithm based on a multi-alphabet version of the Context-Tree Weighting (CTW) method can be used to optimally solve a broad class of waveform-agile tracking problems while making minimal assumptions about the environment's behavior.      
### 48.Single-channel speech enhancement by using psychoacoustical model inspired fusion framework  [ :arrow_down: ](https://arxiv.org/pdf/2202.05272.pdf)
>  When the parameters of Bayesian Short-time Spectral Amplitude (STSA) estimator for speech enhancement are selected based on the characteristics of the human auditory system, the gain function of the estimator becomes more flexible. Although this type of estimator in acoustic domain is quite effective in reducing the back-ground noise at high frequencies, it produces more speech distortions, which make the high-frequency contents of the speech such as friciatives less perceptible in heavy noise conditions, resulting in intelligibility reduction. On the other hand, the speech enhancement scheme, which exploits the psychoacoustic evidence of frequency selectivity in the modulation domain, is found to be able to increase the intelligibility of noisy speech by a substantial amount, but also suffers from the temporal slurring problem due to its essential design constraint. In order to achieve the joint improvements in both the perceived speech quality and intelligibility, we proposed and investigated a fusion framework by combining the merits of acoustic and modulation domain approaches while avoiding their respective weaknesses. Objective measure evaluation shows that the proposed speech enhancement fusion framework can provide consistent improvements in the perceived speech quality and intelligibility across different SNR levels in various noise conditions, while compared to the other baseline techniques.      
### 49.A Field of Experts Prior for Adapting Neural Networks at Test Time  [ :arrow_down: ](https://arxiv.org/pdf/2202.05271.pdf)
>  Performance of convolutional neural networks (CNNs) in image analysis tasks is often marred in the presence of acquisition-related distribution shifts between training and test images. Recently, it has been proposed to tackle this problem by fine-tuning trained CNNs for each test image. Such test-time-adaptation (TTA) is a promising and practical strategy for improving robustness to distribution shifts as it requires neither data sharing between institutions nor annotating additional data. Previous TTA methods use a helper model to increase similarity between outputs and/or features extracted from a test image with those of the training images. Such helpers, which are typically modeled using CNNs, can be task-specific and themselves vulnerable to distribution shifts in their inputs. To overcome these problems, we propose to carry out TTA by matching the feature distributions of test and training images, as modelled by a field-of-experts (FoE) prior. FoEs model complicated probability distributions as products of many simpler expert distributions. We use 1D marginal distributions of a trained task CNN's features as experts in the FoE model. Further, we compute principal components of patches of the task CNN's features, and consider the distributions of PCA loadings as additional experts. We validate the method on 5 MRI segmentation tasks (healthy tissues in 4 anatomical regions and lesions in 1 one anatomy), using data from 17 clinics, and on a MRI registration task, using data from 3 clinics. We find that the proposed FoE-based TTA is generically applicable in multiple tasks, and outperforms all previous TTA methods for lesion segmentation. For healthy tissue segmentation, the proposed method outperforms other task-agnostic methods, but a previous TTA method which is specifically designed for segmentation performs the best for most of the tested datasets. Our code is publicly available.      
### 50.On Real-time Image Reconstruction with Neural Networks for MRI-guided Radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2202.05267.pdf)
>  MRI-guidance techniques that dynamically adapt radiation beams to follow tumor motion in real-time will lead to more accurate cancer treatments and reduced collateral healthy tissue damage. The gold-standard for reconstruction of undersampled MR data is compressed sensing (CS) which is computationally slow and limits the rate that images can be available for real-time adaptation. Here, we demonstrate the use of automated transform by manifold approximation (AUTOMAP), a generalized framework that maps raw MR signal to the target image domain, to rapidly reconstruct images from undersampled radial k-space data. The AUTOMAP neural network was trained to reconstruct images from a golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on lung cancer patient data and generic images from ImageNet. Model training was subsequently augmented with motion-encoded k-space data derived from videos in the YouTube-8M dataset to encourage motion robust reconstruction. We find that AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with much shorter processing times after initial fine-tuning on retrospectively acquired lung cancer patient data. Validation of motion-trained models with a virtual dynamic lung tumor phantom showed that the generalized motion properties learned from YouTube lead to improved target tracking accuracy. Our work shows that AUTOMAP can achieve real-time, accurate reconstruction of radial data. These findings imply that neural-network-based reconstruction is potentially superior to existing approaches for real-time image guidance applications.      
