# ArXiv eess --Tue, 22 Feb 2022
### 1.A Pricing Rule for Third-Party Platoon Coordination Service Provider  [ :arrow_down: ](https://arxiv.org/pdf/2202.10444.pdf)
>  We model a platooning system including trucks and a third-party service provider that performs platoon coordination, distributes the platooning profit within platoons, and charges the trucks in exchange for its services. This paper studies one class of pricing rules, where the third-party service provider keeps part of the platooning profit each time a platoon is formed. Furthermore, we propose a platoon coordination solution based on distributed model predictive control in which the pricing rule is integrated. To evaluate the effect of the pricing on the platooning system, we perform a simulation over the Swedish road network. The simulation shows that the platooning rate and profit highly depend on the pricing. This suggests that pricing needs to be set carefully to obtain a satisfactory platooning system in the future.      
### 2.Wireless Connectivity and Localization for Advanced Air Mobility Services  [ :arrow_down: ](https://arxiv.org/pdf/2202.10438.pdf)
>  By serving as an analog to traffic signal lights, communication signaling for drone to drone communications holds the key to the success of advanced air mobility (AAM) in both urban and rural settings. Deployment of AAM applications such as air taxis and air ambulances, especially at large-scale, requires a reliable channel for a point-to-point and broadcast communication between two or more aircraft. Achieving such high reliability, in a highly mobile environment, requires communication systems designed for agility and efficiency. This paper presents the foundations for establishing and maintaining a reliable communication channel among multiple aircraft in unique AAM settings. Subsequently, it presents concepts and results on wireless coverage and mobility for AAM services using cellular networks as a ground network infrastructure. Finally, we analyze the wireless localization performance at 3D AAM corridors when cellular networks are utilized, considering different corridor heights and base station densities. We highlight future research directions and open problems to improve wireless coverage and localization throughout the manuscript.      
### 3.Malaria detection in Segmented Blood Cell using Convolutional Neural Networks and Canny Edge Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.10426.pdf)
>  We apply convolutional neural networks to identify between malaria infected and non-infected segmented cells from the thin blood smear slide images. We optimize our model to find over 95% accuracy in malaria cell detection. We also apply Canny image processing to reduce training file size while maintaining comparable accuracy (~ 94%).      
### 4.MIST GAN: Modality Imputation Using Style Transfer for MRI  [ :arrow_down: ](https://arxiv.org/pdf/2202.10396.pdf)
>  MRI entails a great amount of cost, time and effort for the generation of all the modalities that are recommended for efficient diagnosis and treatment planning. Recent advancements in deep learning research show that generative models have achieved substantial improvement in the aspects of style transfer and image synthesis. In this work, we formulate generating the missing MR modality from existing MR modalities as an imputation problem using style transfer. With a multiple-to-one mapping, we model a network that accommodates domain specific styles in generating the target image. We analyse the style diversity both within and across MR modalities. Our model is tested on the BraTS'18 dataset and the results obtained are observed to be on par with the state-of-the-art in terms of visual metrics, SSIM and PSNR. After being evaluated by two expert radiologists, we show that our model is efficient, extendable, and suitable for clinical applications.      
### 5.L3DAS22 Challenge: Learning 3D Audio Sources in a Real Office Environment  [ :arrow_down: ](https://arxiv.org/pdf/2202.10372.pdf)
>  The L3DAS22 Challenge is aimed at encouraging the development of machine learning strategies for 3D speech enhancement and 3D sound localization and detection in office-like environments. This challenge improves and extends the tasks of the L3DAS21 edition. We generated a new dataset, which maintains the same general characteristics of L3DAS21 datasets, but with an extended number of data points and adding constrains that improve the baseline model's efficiency and overcome the major difficulties encountered by the participants of the previous challenge. We updated the baseline model of Task 1, using the architecture that ranked first in the previous challenge edition. We wrote a new supporting API, improving its clarity and ease-of-use. In the end, we present and discuss the results submitted by all participants. L3DAS22 Challenge website: <a class="link-external link-http" href="http://www.l3das.com/icassp2022" rel="external noopener nofollow">this http URL</a>.      
### 6.Coordinated Sum-Rate Maximization in Multicell MU-MIMO with Deep Unrolling  [ :arrow_down: ](https://arxiv.org/pdf/2202.10371.pdf)
>  Coordinated weighted sum-rate maximization in multicell MIMO networks with intra- and intercell interference and local channel state at the base stations is recognized as an important yet difficult problem. A classical, locally optimal solution is obtained by the weighted minimum mean squared error (WMMSE) algorithm which facilitates a distributed implementation in multicell networks. However, it often suffers from slow convergence and therefore large communication overhead. To obtain more practical solutions, the unrolling/unfolding of traditional iterative algorithms gained significant attention. In this work, we demonstrate a complete unfolding of the WMMSE algorithm for transceiver design in multicell MU-MIMO interference channels with local channel state information. The resulting architecture termed GCN-WMMSE applies ideas from graph signal processing and is agnostic to different wireless network topologies, while exhibiting a low number of trainable parameters and high efficiency w.r.t. training data. It significantly reduces the number of required iterations while achieving performance similar to the WMMSE algorithm, alleviating the overhead in a distributed deployment. Additionally, we review previous architectures based on unrolling the WMMSE algorithm and compare them to GCN-WMMSE in their specific applicable domains.      
### 7.Estimation of Evaporator Valve Sizes in Supermarket Refrigeration Cabinets  [ :arrow_down: ](https://arxiv.org/pdf/2202.10348.pdf)
>  In many applications, e.g. fault diagnostics and optimized control of supermarket refrigeration systems, it is important to determine the heat demand of the cabinets. This can easily be achieved by measuring the mass flow through each cabinet, however, that is expensive and not feasible in large-scale deployments. Therefore it is important to be able to estimate the valve sizes from the monitoring data, which is typically measured. The valve size is measured by an area, which can be used to calculate mass flow through the valve -- this estimated value is referred to as the valve constant. A novel method for estimating the cabinet evaporator valve constants is proposed in the present paper. It is demonstrated using monitoring data from a refrigeration system in a supermarket consisting of data sampled at a one-minute sampling rate, however it is shown that a sampling time of around 10-20 minutes is adequate for the method. Through thermodynamic analysis of a two-stage CO2 refrigeration system, a linear regression model for estimating valve constants was developed using time series data. The linear regression requires that transient dynamics are not present in the data, which depends on multiple factors e.g. the sampling time. If dynamics are not modeled it can be detected by a significant auto-correlation of the residuals. In order to include the dynamics in the model, an Auto-Regressive Moving Average model with eXogenous variables (ARMAX) was applied, and it is shown how it effectively eliminates the auto-correlation and provides more unbiased estimates, as well as improved the accuracy estimates. Furthermore, it is shown that the sample time has a huge impact on the valve estimates. Thus, a method for selecting the optimal sampling time is introduced. It works individually for each of the evaporators, by exploring their respective frequency spectrum.      
### 8.Speaker Adaptation Using Spectro-Temporal Deep Features for Dysarthric and Elderly Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2202.10290.pdf)
>  Despite the rapid progress of automatic speech recognition (ASR) technologies targeting normal speech in recent decades, accurate recognition of dysarthric and elderly speech remains highly challenging tasks to date. Sources of heterogeneity commonly found in normal speech including accent or gender, when further compounded with the variability over age and speech pathology severity level, create large diversity among speakers. To this end, speaker adaptation techniques play a key role in personalization of ASR systems for such users. Motivated by the spectro-temporal level differences between dysarthric, elderly and normal speech that systematically manifest in articulatory imprecision, decreased volume and clarity, slower speaking rates and increased dysfluencies, novel spectrotemporal subspace basis deep embedding features derived using SVD speech spectrum decomposition are proposed in this paper to facilitate auxiliary feature based speaker adaptation of state-of-the-art hybrid DNN/TDNN and end-to-end Conformer speech recognition systems. Experiments were conducted on four tasks: the English UASpeech and TORGO dysarthric speech corpora; the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets. The proposed spectro-temporal deep feature adapted systems outperformed baseline i-Vector and xVector adaptation by up to 2.63% absolute (8.63% relative) reduction in word error rate (WER). Consistent performance improvements were retained after model based speaker adaptation using learning hidden unit contributions (LHUC) was further applied. The best speaker adapted system using the proposed spectral basis embedding features produced the lowest published WER of 25.05% on the UASpeech test set of 16 dysarthric speakers.      
### 9.On the Distributed Estimation from Relative Measurements: a Graph-Based Convergence Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2202.10202.pdf)
>  For a multi-agent system state estimation resting upon noisy measurements constitutes a problem related to several application scenarios. Adopting the standard least-squares approach, in this work we derive both the (centralized) analytic solution to this issue and two distributed iterative schemes, which allow to establish a connection between the convergence behavior of consensus algorithm toward the optimal estimate and the theory of the stochastic matrices that describe the network system dynamics. This study on the one hand highlights the role of the topological links that define the neighborhood of agent nodes, while on the other allows to optimize the convergence rate by easy parameter tuning. The theoretical findings are validated considering different network topologies by means of numerical simulations.      
### 10.Optimal Time-Invariant Formation Tracking for a Second-Order Multi-Agent System  [ :arrow_down: ](https://arxiv.org/pdf/2202.10196.pdf)
>  Given a multi-agent linear system, we formalize and solve a trajectory optimization problem that encapsulates trajectory tracking, distance-based formation control and input energy minimization. To this end, a numerical projection operator Newton's method is developed to find a solution by the minimization of a cost functional able to capture all these different tasks. To stabilize the formation, a particular potential function has been designed, allowing to obtain specified geometrical configurations while the barycenter position and velocity of the system follows a desired trajectory.      
### 11.OSegNet: Operational Segmentation Network for COVID-19 Detection using Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2202.10185.pdf)
>  Coronavirus disease 2019 (COVID-19) has been diagnosed automatically using Machine Learning algorithms over chest X-ray (CXR) images. However, most of the earlier studies used Deep Learning models over scarce datasets bearing the risk of overfitting. Additionally, previous studies have revealed the fact that deep networks are not reliable for classification since their decisions may originate from irrelevant areas on the CXRs. Therefore, in this study, we propose Operational Segmentation Network (OSegNet) that performs detection by segmenting COVID-19 pneumonia for a reliable diagnosis. To address the data scarcity encountered in training and especially in evaluation, this study extends the largest COVID-19 CXR dataset: QaTa-COV19 with 121,378 CXRs including 9258 COVID-19 samples with their corresponding ground-truth segmentation masks that are publicly shared with the research community. Consequently, OSegNet has achieved a detection performance with the highest accuracy of 99.65% among the state-of-the-art deep models with 98.09% precision.      
### 12.MILP-based optimal day-ahead scheduling for system-centric CEMS supporting different types of homes and energy trading  [ :arrow_down: ](https://arxiv.org/pdf/2202.10181.pdf)
>  Optimal day-ahead scheduling for a system-centric community energy management system (CEMS) is proposed to provide economic benefits and user comfort of energy management at the community level. Our proposed community includes different types of homes and allows prosumers to trade energy locally using mid-market rate pricing. A mathematical model of the community is constructed and the optimization problem of this model is transformed into an MILP problem that can be solved in a short time. By solving this MILP problem, the optimization of the overall energy cost of the community and satisfaction of the thermal comfort at every home are achieved. For comparison, we also establish two different scenarios for the same community: a prosumer-centric CEMS and no CEMS. The simulation results demonstrate that the overall energy cost of the community with the system-centric CEMS is the smallest among the three scenarios and is only half that of the community with the prosumer-centric CEMS. Moreover, by using linear transformation, the computational time of the optimization problem of the proposed system-centric CEMS is only 118.2 s for a 500-home community, which is a short time for day-ahead scheduling of a community.      
### 13.Formal Analysis of the Sampling Behaviour of Stochastic Event-Triggered Control  [ :arrow_down: ](https://arxiv.org/pdf/2202.10178.pdf)
>  Analyzing Event-Triggered Control's (ETC) sampling behaviour is of paramount importance, as it enables formal assessment of its sampling performance and prediction of its sampling patterns. In this work, we formally analyze the sampling behaviour of stochastic linear periodic ETC (PETC) systems by computing bounds on associated metrics. Specifically, we consider functions over sequences of state measurements and intersampling times that can be expressed as average, multiplicative or cumulative rewards, and introduce their expectations as metrics on PETC's sampling behaviour. We compute bounds on these expectations, by constructing appropriate Interval Markov Chains equipped with suitable reward structures, that abstract stochastic PETC's sampling behaviour. Our results are illustrated on a numerical example, for which we compute bounds on the expected average intersampling time and on the probability of triggering with the maximum possible intersampling time in a finite horizon.      
### 14.A Lifting Approach to Learning-Based Self-Triggered Control with Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2202.10174.pdf)
>  This paper investigates the design of self-triggered control for networked control systems (NCS), where the dynamics of the plant is unknown apriori. To deal with the nature of the self-triggered control, in which state measurements are transmitted to the controller a-periodically, we propose to lift the continuous-time dynamics to a novel dynamical model by taking an inter-event time as an additional input, and then, the lifted model is learned by the Gaussian processes (GP) regression. Moreover, we propose a learning-based approach, in which a self-triggered controller is learned by minimizing a cost function, such that it can take inter-sample behavior into account. By employing the lifting approach, we can utilize a gradient-based policy update as an efficient method to optimize both control and communication policies. Finally, we summarize the overall algorithm and provide a numerical simulation to illustrate the effectiveness of the proposed approach.      
### 15.Entropy of Generating Series for Nonlinear Input-Output Systems and Their Interconnections  [ :arrow_down: ](https://arxiv.org/pdf/2202.10170.pdf)
>  This paper has two main objectives. The first is to introduce a notion of entropy that is well suited for the analysis of nonlinear input-output systems that have a Chen-Fliess series representation. The latter is defined in terms of its generating series over a noncommutative alphabet. The idea is to assign an entropy to a generating series as an element of a graded vector space. The second objective is to describe the entropy of generating series originating from interconnected systems of Chen-Fliess series that arise in the context of control theory. It is shown that one set of interconnections can never increase entropy as defined here, while a second set has the potential to do so. The paper concludes with a brief introduction of an entropy ultrametric space.      
### 16.Distributed Strategies for Dynamic Coverage with Limited Sensing Capabilities  [ :arrow_down: ](https://arxiv.org/pdf/2202.10164.pdf)
>  In this work, it is presented the development of a novel distributed algorithm performing robotic coverage, clustering and dispatch around an event in static-obstacle structured environments without relying on metric information. Specifically, the aim is to account for the trade-off between local communication given by bearing visibility sensors installed on each agent involved, optimal deployment in closed unknown scenarios and focus of a group of agents on one point of interest. The particular targets of this study can be summarized as 1. the computation, under certain topological assumptions, of a lower bound for the number of required agents, which are provided by a realistic geometric model (e.g. a round shape) to emphasize physical limitations; 2. the minimization of the number of nodes and links maintaining a distributed approach over a connected communication graph; 3. the identification of an activation cluster around an event with a radial decreasing intensity, sensed by each agent; 4. the attempt to send the agents belonging to the cluster towards the most intense point in the scenario by minimizing a weighted isoperimetric functional.      
### 17.Tuning of passivity-based controllers for mechanical systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.10161.pdf)
>  This manuscript describes several approaches to tune the parameters of a class of passivity-based controllers for standard nonlinear mechanical systems. In particular, we are interested in controllers that preserve the mechanical system structure in closed-loop. To this end, first, we provide tuning rules for stabilization, i.e., the rate of convergence (exponential stability) and stability margin (input-to-state stability). Then, we provide guidelines to remove the overshoot while prescribing the rise time. Additionally, we propose a methodology to tune the gyroscopic-related parameters. We also provide remarks on the damping phenomena to facilitate the practical implementation of our approaches. We conclude this paper with experimental results obtained from applying our tuning rules to an underactuated and a fully-actuated mechanical configuration.      
### 18.Two-snapshot DOA Estimation via Hankel-structured Matrix Completion  [ :arrow_down: ](https://arxiv.org/pdf/2202.10148.pdf)
>  In this paper, we study the problem of estimating the direction of arrival (DOA) using a sparsely sampled uniform linear array (ULA). Based on an initial incomplete ULA measurement, our strategy is to choose a sparse subset of array elements for measuring the next snapshot. Then, we use a Hankel-structured matrix completion to interpolate for the missing ULA measurements. Finally, the source DOAs are estimated using a subspace method such as Prony on the fully recovered ULA. We theoretically provide a sufficient bound for the number of required samples (array elements) for perfect recovery. The numerical comparisons of the proposed method with existing techniques such as atomic-norm minimization and off-the-grid approaches confirm the superiority of the proposed method.      
### 19.S3T: Self-Supervised Pre-training with Swin Transformer for Music Classification  [ :arrow_down: ](https://arxiv.org/pdf/2202.10139.pdf)
>  In this paper, we propose S3T, a self-supervised pre-training method with Swin Transformer for music classification, aiming to learn meaningful music representations from massive easily accessible unlabeled music data. S3T introduces a momentum-based paradigm, MoCo, with Swin Transformer as its feature extractor to music time-frequency domain. For better music representations learning, S3T contributes a music data augmentation pipeline and two specially designed pre-processors. To our knowledge, S3T is the first method combining the Swin Transformer with a self-supervised learning method for music classification. We evaluate S3T on music genre classification and music tagging tasks with linear classifiers trained on learned representations. Experimental results show that S3T outperforms the previous self-supervised method (CLMR) by 12.5 percents top-1 accuracy and 4.8 percents PR-AUC on two tasks respectively, and also surpasses the task-specific state-of-the-art supervised methods. Besides, S3T shows advances in label efficiency using only 10% labeled data exceeding CLMR on both tasks with 100% labeled data.      
### 20.Counterfactual Regret Minimization for Anti-jamming Game of Frequency Agile Radar  [ :arrow_down: ](https://arxiv.org/pdf/2202.10049.pdf)
>  The competition between radar and jammer is one emerging issue in modern electronic warfare, which in principle can be viewed as a non-cooperative game with two players. In this work, the competition between a frequency agile (FA) radar and a noise-modulated jammer is considered. As modern FA radar adopts coherent processing with several pulses, the competition is hence in a multiple-round way where each pulse can be modeled as one round interaction between the radar and jammer. To capture such multiple-round property as well as imperfect information inside the game, i.e., radar and jammer are unable to know the upcoming signal, we propose an extensive-form game formulation for such competition. Since the number of game information states grows exponentially with respect to number of pulses, finding Nash Equilibrium (NE) strategies may be a computationally intractable task. To effectively solve the game, a learning-based algorithm called deep Counterfactual Regret Minimization (CFR) is utilized. Numerical simulations demonstrates the effectiveness of deep CFR algorithm for approximately finding NE and obtaining the best response strategy.      
### 21.DFT-Spread Orthogonal Time Frequency Space System with Superimposed Pilots for Terahertz Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2202.10035.pdf)
>  Terahertz (THz) integrated sensing and communication (ISAC) is a promising interdisciplinary technology that realizes simultaneously transmitting Terabit-per-second (Tbps) and millimeter-level accurate environment or human activity sensing. However, both communication performance and sensing accuracy are influenced by the Doppler effects, which are especially severe in the THz band. Moreover, peak-to-average power ratio (PAPR) degrades the THz power amplifier (PA) efficiency. In this paper, a discrete Fourier transform spread orthogonal time frequency space (DFT-s-OTFS) system is proposed to improve the robustness to Doppler effects and reduce PAPR for THz ISAC. Then, a two-phase sensing parameter estimation algorithm is developed to integrate sensing functionality into the DFT-s-OTFS waveform. Meanwhile, a scheme of superimposed pilots is designed, which reduces the pilot overhead and improves the spectral efficiency. Based on the superimposed pilots, a low-complexity iterative channel estimation and data detection method is proposed to recover the data symbols of DFT-s-OTFS. The proposed DFT-s-OTFS waveform can improve the PA efficiency by 10% on average compared to OTFS. Simulation results demonstrate that the proposed two-phase sensing estimation algorithm for THz DFT-s-OTFS systems is able to realize millimeter-level range estimation accuracy and decimeter-per-second-level velocity estimation accuracy. Moreover, the effectiveness of the iterative method for data detection aided by superimposed pilots in DFT-s-OTFS systems is validated by the simulations and the bit error rate performance is not degraded by the Doppler effects.      
### 22.The PCG-AIID System for L3DAS22 Challenge: MIMO and MISO convolutional recurrent Network for Multi Channel Speech Enhancement and Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2202.10017.pdf)
>  This paper described the PCG-AIID system for L3DAS22 challenge in Task 1: 3D speech enhancement in office reverberant environment. We proposed a two-stage framework to address multi-channel speech denoising and dereverberation. In the first stage, a multiple input and multiple output (MIMO) network is applied to remove background noise while maintaining the spatial characteristics of multi-channel signals. In the second stage, a multiple input and single output (MISO) network is applied to enhance the speech from desired direction and post-filtering. As a result, our system ranked 3rd place in ICASSP2022 L3DAS22 challenge and significantly outperforms the baseline system, while achieving 3.2% WER and 0.972 STOI on the blind test-set.      
### 23.Controller Manipulation Attack on Reconfigurable Intelligent Surface Aided Wireless Communication  [ :arrow_down: ](https://arxiv.org/pdf/2202.10012.pdf)
>  In this paper, we introduce a new attack called controller manipulation attack (CMA) on a Reconfigurable Intelligent Surface (RIS) assisted communication system between a transmitter and a receiver. An attacker has the potential to manipulate the RIS controller and modify the phase shift induced by the RIS elements. The goal of the attacker is to minimize the data rate at the receiver, subject to a constraint on the attack detection probability at the receiver. We consider two different attack detection models: (i) composite hypothesis testing based attack detection in a given fading block for known channel gains, and (ii) SNR moment based detection over possibly multiple fading blocks. In the first case, a simple energy detector turns out to be uniformly most powerful (UMP) and the attack against this energy detector is designed via a novel optimization formulation and a semidefinite relaxation based solution. In the second case, we consider threshold detection using moments of SNR; various SNR moments under no attack are obtained analytically for large RIS and then used to formulate the attack design problem as a linear program. Finally, numerical results illustrate the performance and trade-offs associated with the attack schemes, and also demonstrate their efficacy.      
### 24.Integrated Fault Diagnosis and Control Design for DER Inverters using Machine Learning Methods  [ :arrow_down: ](https://arxiv.org/pdf/2202.09996.pdf)
>  This paper employs a supervised machine learning (ML) algorithm to propose an integrated fault detection and diagnosis (FDD) and fault-tolerant control (FTC) strategy to detect, diagnose, and classify the grid faults and correct the input voltage before affecting the grid-connected distributed energy resources (DER) inverters. This controller can mitigate the impact of grid faults on inverters by predicting and modifying the time series of their input voltage. Simulation results show the effectiveness of the proposed controller and evaluate its operating performance.      
### 25.L-SpEx: Localized Target Speaker Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2202.09995.pdf)
>  Speaker extraction aims to extract the target speaker's voice from a multi-talker speech mixture given an auxiliary reference utterance. Recent studies show that speaker extraction benefits from the location or direction of the target speaker. However, these studies assume that the target speaker's location is known in advance or detected by an extra visual cue, e.g., face image or video. In this paper, we propose an end-to-end localized target speaker extraction on pure speech cues, that is called L-SpEx. Specifically, we design a speaker localizer driven by the target speaker's embedding to extract the spatial features, including direction-of-arrival (DOA) of the target speaker and beamforming output. Then, the spatial cues and target speaker's embedding are both used to form a top-down auditory attention to the target speaker. Experiments on the multi-channel reverberant dataset called MC-Libri2Mix show that our L-SpEx approach significantly outperforms the baseline system.      
### 26.Outlier-based Autism Detection using Longitudinal Structural MRI  [ :arrow_down: ](https://arxiv.org/pdf/2202.09988.pdf)
>  Diagnosis of Autism Spectrum Disorder (ASD) using clinical evaluation (cognitive tests) is challenging due to wide variations amongst individuals. Since no effective treatment exists, prompt and reliable ASD diagnosis can enable the effective preparation of treatment regimens. This paper proposes structural Magnetic Resonance Imaging (sMRI)-based ASD diagnosis via an outlier detection approach. To learn Spatio-temporal patterns in structural brain connectivity, a Generative Adversarial Network (GAN) is trained exclusively with sMRI scans of healthy subjects. Given a stack of three adjacent slices as input, the GAN generator reconstructs the next three adjacent slices; the GAN discriminator then identifies ASD sMRI scan reconstructions as outliers. This model is compared against two other baselines -- a simpler UNet and a sophisticated Self-Attention GAN. Axial, Coronal, and Sagittal sMRI slices from the multi-site ABIDE II dataset are used for evaluation. Extensive experiments reveal that our ASD detection framework performs comparably with the state-of-the-art with far fewer training data. Furthermore, longitudinal data (two scans per subject over time) achieve 17-28% higher accuracy than cross-sectional data (one scan per subject). Among other findings, metrics employed for model training as well as reconstruction loss computation impact detection performance, and the coronal modality is found to best encode structural information for ASD detection.      
### 27.Sensing as A Service in 6G Perceptive Networks: A Unified Framework for ISAC Resource Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2202.09969.pdf)
>  In the upcoming next-generation (5G-Advanced and 6G) wireless networks, sensing as a service will play a more important role than ever before. Recently, the concept of perceptive network is proposed as a paradigm shift that provides sensing and communication (S&amp;C) services simultaneously. This type of technology is typically referred to as Integrated Sensing and Communications (ISAC). In this paper, we propose the concept of sensing quality of service (QoS) in terms of diverse applications. Specifically, the probability of detection, the Cramer-Rao bound (CRB) for parameter estimation and the posterior CRB for moving target indication are employed to measure the sensing QoS for detection, localization, and tracking, respectively. Then, we establish a unified framework for ISAC resource allocation, where the fairness and the comprehensiveness optimization criteria are considered for the aforementioned sensing services. The proposed schemes can flexibly allocate the limited power and bandwidth resources according to both S&amp;C QoSs. Finally, we study the performance trade-off between S&amp;C services in different resource allocation schemes by numerical simulations.      
### 28.Theoretical Analysis of Deep Neural Networks in Physical Layer Communication  [ :arrow_down: ](https://arxiv.org/pdf/2202.09954.pdf)
>  Recently, deep neural network (DNN)-based physical layer communication techniques have attracted considerable interest. Although their potential to enhance communication systems and superb performance have been validated by simulation experiments, little attention has been paid to the theoretical analysis. Specifically, most studies in the physical layer have tended to focus on the application of DNN models to wireless communication problems but not to theoretically understand how does a DNN work in a communication system. In this paper, we aim to quantitatively analyze why DNNs can achieve comparable performance in the physical layer comparing with traditional techniques, and also drive their cost in terms of computational complexity. To achieve this goal, we first analyze the encoding performance of a DNN-based transmitter and compare it to a traditional one. And then, we theoretically analyze the performance of DNN-based estimator and compare it with traditional estimators. Third, we investigate and validate how information is flown in a DNN-based communication system under the information theoretic concepts. Our analysis develops a concise way to open the "black box" of DNNs in physical layer communication, which can be applied to support the design of DNN-based intelligent communication techniques and help to provide explainable performance assessment.      
### 29.Deep learning-guided weighted averaging for signal dropout compensation in diffusion-weighted imaging of the liver  [ :arrow_down: ](https://arxiv.org/pdf/2202.09912.pdf)
>  Purpose: To develop an algorithm for the retrospective correction of signal dropout artifacts in abdominal diffusion-weighted imaging (DWI) resulting from cardiac motion. <br>Methods: Given a set of image repetitions for a slice, a locally adaptive weighted averaging is proposed which aims to suppress the contribution of image regions affected by signal dropouts. Corresponding weight maps were estimated by a sliding-window algorithm which analyzed signal deviations from a patch-wise reference. In order to ensure the computation of a robust reference, repetitions were filtered by a classifier that was trained to detect images corrupted by signal dropouts. The proposed method, termed Deep Learning-guided Adaptive Weighted Averaging (DLAWA), was evaluated in terms of dropout suppression capability, bias reduction in the Apparent Diffusion Coefficient (ADC) and noise characteristics. <br>Results: In the case of uniform averaging, motion-related dropouts caused signal attenuation and ADC overestimation in parts of the liver with the left lobe being affected particularly. Both effects could be substantially mitigated by DLAWA while preventing global penalties with respect to signal-to-noise ratio (SNR) due to local signal suppression. Performing evaluations on patient data, the capability to recover lesions concealed by signal dropouts was demonstrated as well. Further, DLAWA allowed for transparent control of the trade-off between SNR and signal dropout suppression by means of a few hyperparameters. <br>Conclusion: This work presents an effective and flexible method for the local compensation of signal dropouts resulting from motion and pulsation. Since DLAWA follows a retrospective approach, no changes to the acquisition are required.      
### 30.Performance Analysis of Optimally Coordinated Connected and Automated Vehicles in a Mixed Traffic Environment  [ :arrow_down: ](https://arxiv.org/pdf/2202.09876.pdf)
>  Trajectory planning of connected and automated vehicles (CAVs) poses significant challenges in a mixed traffic environment due to the presence of human-driven vehicles (HDVs). In this paper, we apply a framework that allows optimal coordination of CAVs and HDVs traveling through a traffic corridor consisting of an on-ramp merging, a speed reduction zone, and a roundabout. We study the impact of different penetration rates of CAVs and traffic volumes on the efficiency of the corridor. We provide extensive simulation results and report on the benefits in terms of total travel time and fuel economy.      
### 31.A Novel Framework for Brain Tumor Detection Based on Convolutional Variational Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2202.09850.pdf)
>  Brain tumor detection can make the difference between life and death. Recently, deep learning-based brain tumor detection techniques have gained attention due to their higher performance. However, obtaining the expected performance of such deep learning-based systems requires large amounts of classified images to train the deep models. Obtaining such data is usually boring, time-consuming, and can easily be exposed to human mistakes which hinder the utilization of such deep learning approaches. This paper introduces a novel framework for brain tumor detection and classification. The basic idea is to generate a large synthetic MRI images dataset that reflects the typical pattern of the brain MRI images from a small class-unbalanced collected dataset. The resulted dataset is then used for training a deep model for detection and classification. Specifically, we employ two types of deep models. The first model is a generative model to capture the distribution of the important features in a set of small class-unbalanced brain MRI images. Then by using this distribution, the generative model can synthesize any number of brain MRI images for each class. Hence, the system can automatically convert a small unbalanced dataset to a larger balanced one. The second model is the classifier that is trained using the large balanced dataset to detect brain tumors in MRI images. The proposed framework acquires an overall detection accuracy of 96.88% which highlights the promise of the proposed framework as an accurate low-overhead brain tumor detection system.      
### 32.RFTacho: Non-intrusive RF monitoring of rotating machines  [ :arrow_down: ](https://arxiv.org/pdf/2202.09841.pdf)
>  Measuring rotation speed is essential to many engineering applications; it elicits faults undetectable by vibration monitoring alone and enhances the vibration signal analysis of rotating machines. Optical, magnetic or mechanical Tachometers are currently state-of-art. Their limitations are they require line-of-sight, direct access to the rotating object. This paper proposes RFTacho, a rotation speed measurement \emph{system} that leverages novel hardware and signal processing algorithms to produce highly accurate readings conveniently. RFTacho uses RF Orbital Angular Momentum (OAM) waves to measure rotation speed of multiple machines simultaneously with no requirements from the machine's properties. OAM antennas allow it to operate in high-scattering environments, commonly found in industries, as they are resilient to de-polarization compared to linearly polarized antennas. RFTacho achieves this by using two novel signal processing algorithms to extract the rotation speed of several rotating objects simultaneously amidst noise arising from high-scattering environments, non-line-of-sight scenarios and dynamic environmental conditions with a resolution of $1 rpm$. We test RFTacho on several real-world machines like fans, motors, air conditioners. Results show that RFTacho has avg. error of $&lt;0.5\%$ compared to ground truth. We demonstrate RFTacho's simultaneous multiple-object measurement capability that other tachometers do not have. Initial experiments show that RFTacho can measure speeds as high as 7000 rpm (theoretically 60000 rpm) with high resiliency at different coverage distances and orientation angles, requiring only 150 mW transmit power while operating in the 5 GHz license-exempt band. RFTacho is the first RF-based sensing system that combines OAM waves and novel processing approaches to measure the rotation speed of multiple machines simultaneously in a non-intrusive way.      
### 33.Behind Closed Doors: Process-Level Rootkit Attacks in Cyber-Physical Microgrid Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.09831.pdf)
>  Embedded controllers, sensors, actuators, advanced metering infrastructure, etc. are cornerstone components of cyber-physical energy systems such as microgrids (MGs). Harnessing their monitoring and control functionalities, sophisticated schemes enhancing MG stability can be deployed. However, the deployment of `smart' assets increases the threat surface. Power systems possess mechanisms capable of detecting abnormal operations. Furthermore, the lack of sophistication in attack strategies can render them detectable since they blindly violate power system semantics. On the other hand, the recent increase of process-aware rootkits that can attain persistence and compromise operations in undetectable ways requires special attention. In this work, we investigate the steps followed by stealthy rootkits at the process level of control systems pre- and post-compromise. We investigate the rootkits' precompromise stage involving the deployment to multiple system locations and aggregation of system-specific information to build a neural network-based virtual data-driven model (VDDM) of the system. Then, during the weaponization phase, we demonstrate how the VDDM measurement predictions are paramount, first to orchestrate crippling attacks from multiple system standpoints, maximizing the impact, and second, impede detection blinding system operator situational awareness.      
### 34.Alternative design of DeepPDNet in the context of image restoration  [ :arrow_down: ](https://arxiv.org/pdf/2202.09810.pdf)
>  This work designs an image restoration deep network relying on unfolded Chambolle-Pock primal-dual iterations. Each layer of our network is built from Chambolle-Pock iterations when specified for minimizing a sum of a $\ell_2$-norm data-term and an analysis sparse prior. The parameters of our network are the step-sizes of the Chambolle-Pock scheme and the linear operator involved in sparsity-based penalization, including implicitly the regularization parameter. A backpropagation procedure is fully described. Preliminary experiments illustrate the good behavior of such a deep primal-dual network in the context of image restoration on BSD68 database.      
### 35.Image quality assessment by overlapping task-specific and task-agnostic measures: application to prostate multiparametric MR images for cancer segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2202.09798.pdf)
>  Image quality assessment (IQA) in medical imaging can be used to ensure that downstream clinical tasks can be reliably performed. Quantifying the impact of an image on the specific target tasks, also named as task amenability, is needed. A task-specific IQA has recently been proposed to learn an image-amenability-predicting controller simultaneously with a target task predictor. This allows for the trained IQA controller to measure the impact an image has on the target task performance, when this task is performed using the predictor, e.g. segmentation and classification neural networks in modern clinical applications. In this work, we propose an extension to this task-specific IQA approach, by adding a task-agnostic IQA based on auto-encoding as the target task. Analysing the intersection between low-quality images, deemed by both the task-specific and task-agnostic IQA, may help to differentiate the underpinning factors that caused the poor target task performance. For example, common imaging artefacts may not adversely affect the target task, which would lead to a low task-agnostic quality and a high task-specific quality, whilst individual cases considered clinically challenging, which can not be improved by better imaging equipment or protocols, is likely to result in a high task-agnostic quality but a low task-specific quality. We first describe a flexible reward shaping strategy which allows for the adjustment of weighting between task-agnostic and task-specific quality scoring. Furthermore, we evaluate the proposed algorithm using a clinically challenging target task of prostate tumour segmentation on multiparametric magnetic resonance (mpMR) images, from 850 patients. The proposed reward shaping strategy, with appropriately weighted task-specific and task-agnostic qualities, successfully identified samples that need re-acquisition due to defected imaging process.      
### 36.Microwave Sensing of Elemental Sulfur Deposition in Gas Pipelines  [ :arrow_down: ](https://arxiv.org/pdf/2202.09796.pdf)
>  A non-intrusive conformal electromagnetic-based monitoring of elemental sulfur deposition within a natural gas-carrying pipeline is presented. The deposited sulfur behaves as a superstrate layer above a sensing microstrip patch antenna that is optimally placed on the inner wall of the gas pipeline. Increasing the superstrate thickness by the sulfur deposition alters the antenna resonance behavior, which can be monitored externally. The effect of uneven or bumpy sulfur deposition is studied. Sensing antennas positioned outside a plexiglass pipeline are also investigated to observe the change in the antenna impedance matching with accumulating sulfur superstrate. Lab-based measured results agreed well with the simulated responses using commercial electromagnetic software. The proposed low-cost and easy-to-implement detection technique exhibits an accurate estimation of the deposited sulfur thickness inside the natural gas-carrying pipelines.      
### 37.Analysis and optimization of a novel energy storage flywheel for improved energy capacity  [ :arrow_down: ](https://arxiv.org/pdf/2202.09783.pdf)
>  Kinetic/Flywheel energy storage systems (FESS) have re-emerged as a vital technology in many areas such as smart grid, renewable energy, electric vehicle, and high-power applications. FESSs are designed and optimized to have higher energy per mass (specific energy) and volume (energy density). Prior research, such as the use of high-strength materials and the reduction of stress concentration, primarily focused on designing and optimizing the rotor itself. However, a modern FESS includes other indispensable components such as magnetic bearings and a motor/generator that requires a shaft. The shaft significantly impacts the flywheel design. This paper investigates several typical flywheel designs and their stress analysis. A simplified analysis method is given for designing rotor-shaft assembly. It is found that the shaftless flywheel design approach can double the energy density level when compared to typical designs. The shaftless flywheel is further optimized using finite element analysis with the magnetic bearing and motor/generators' design considerations.      
### 38.Multi-objective Distributed Optimization for Zonal Distribution System with Multi-Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2202.09762.pdf)
>  The issue of voltage variations caused by integration of renewables has been addressed in this paper through distributed management of Microgrids (MGs). The distribution network (DN) takes the network losses and voltage quality as objectives, an alternating direction method of multipliers (ADMM) with adaptive penalty modulation has been proposed to realize distributed optimization with improved convergence. On the basis of satisfying the optimization target on the system level, the individual MG manages the controllable resources inside the MG to minimize the operating cost on the lower level. The feasibility and effectiveness of the proposed method has been demonstrated on a modified IEEE 33-bus system.      
### 39.Optimal configuration of cooperative stationary and mobile energy storage considering ambient temperature: A case for Winter Olympic Game  [ :arrow_down: ](https://arxiv.org/pdf/2202.09761.pdf)
>  The international mega-event, such as the Winter Olympic Game, has been considered as one of the most carbon intensive activities worldwide. The commitment of fully renewable energy accommodation and utilization while ensuring the extreme high reliability has brought significant challenges on system operation due to the stochastic nature of the renewables. The battery energy storage system (BESS) composed of stationary energy storage system (SESS) and shared mobile energy storage system (MESS) can be utilized to meet the requirements of short-term load surges, renewable accommodation and emergency power supply for important loads during the mega-event. The BESS can continue to serve the venues electricity consumption to satisfy the carbon neutrality after the event. On the other hand, the low ambient temperature of Winter Olympic game has significant impact on BESSs degradation and performance which need to be integrated to the charging and discharging model of BESS. To this end, a joint two-stage optimal configuration method considering the ambient temperature of SESS and MESS has been developed to support the mega-event carbon neutrality, to reduce redundant BESS capacity allocation and improve the system life cycle cost-benefit. Simulation results have demonstrated the rationality and effectiveness of the collaborative operation of SESS and the MESS under various scenarios.      
### 40.RDP-Net: Region Detail Preserving Network for Change Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.09745.pdf)
>  Change detection (CD) is an essential earth observation technique. It captures the dynamic information of land objects. With the rise of deep learning, neural networks (NN) have shown great potential in CD. However, current NN models introduce backbone architectures that lose the detail information during learning. Moreover, current NN models are heavy in parameters, which prevents their deployment on edge devices such as drones. In this work, we tackle this issue by proposing RDP-Net: a region detail preserving network for CD. We propose an efficient training strategy that quantifies the importance of individual samples during the warmup period of NN training. Then, we perform non-uniform sampling based on the importance score so that the NN could learn detail information from easy to hard. Next, we propose an effective edge loss that improves the network's attention on details such as boundaries and small regions. As a result, we provide a NN model that achieves the state-of-the-art empirical performance in CD with only 1.70M parameters. We hope our RDP-Net would benefit the practical CD applications on compact devices and could inspire more people to bring change detection to a new level with the efficient training strategy.      
### 41.A Foundation for Wireless Channel Prediction and Full Ray Makeup Estimation Using an Unmanned Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2202.09740.pdf)
>  In this paper, we consider the problem of wireless channel prediction, where we are interested in predicting the channel quality at unvisited locations in an area of interest, based on a small number of prior received power measurements collected by an unmanned vehicle in the area. We propose a new framework for channel prediction that can not only predict the detailed variations of the received power, but can also predict the detailed makeup of the wireless rays (i.e., amplitude, angle-of-arrival, and phase of all the incoming paths). More specifically, we show how an enclosure-based robotic route design ensures that the received power measurements at the prior measurement locations can be utilized to fully predict detailed ray parameters at unvisited locations. We then show how to first estimate the detailed ray parameters at the prior measurement route and then fully extend them to predict the detailed ray makeup at unvisited locations in the workspace. We experimentally validate our proposed framework through extensive real-world experiments in three different areas, and show that our approach can accurately predict the received channel power and the detailed makeup of the rays at unvisited locations in an area, considerably outperforming the state-of-the-art in wireless channel prediction.      
### 42.The Loop Game: Quality Assessment and Optimization for Low-Light Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2202.09738.pdf)
>  There is an increasing consensus that the design and optimization of low light image enhancement methods need to be fully driven by perceptual quality. With numerous approaches proposed to enhance low-light images, much less work has been dedicated to quality assessment and quality optimization of low-light enhancement. In this paper, to close the gap between enhancement and assessment, we propose a loop enhancement framework that produces a clear picture of how the enhancement of low-light images could be optimized towards better visual quality. In particular, we create a large-scale database for QUality assessment Of The Enhanced LOw-Light Image (QUOTE-LOL), which serves as the foundation in studying and developing objective quality assessment measures. The objective quality assessment measure plays a critical bridging role between visual quality and enhancement and is further incorporated in the optimization in learning the enhancement model towards perceptual optimally. Finally, we iteratively perform the enhancement and optimization tasks, enhancing the low-light images continuously. The superiority of the proposed scheme is validated based on various low-light scenes. The database as well as the code will be available.      
### 43.Runtime-Assured, Real-Time Neural Control of Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2202.09710.pdf)
>  We present SimpleMG, a new, provably correct design methodology for runtime assurance of microgrids (MGs) with neural controllers. Our approach is centered around the Neural Simplex Architecture, which in turn is based on Sha et al.'s Simplex Control Architecture. Reinforcement Learning is used to synthesize high-performance neural controllers for MGs. Barrier Certificates are used to establish SimpleMG's runtime-assurance guarantees. We present a novel method to derive the condition for switching from the unverified neural controller to the verified-safe baseline controller, and we prove that the method is correct. We conduct an extensive experimental evaluation of SimpleMG using RTDS, a high-fidelity, real-time simulation environment for power systems, on a realistic model of a microgrid comprising three distributed energy resources (battery, photovoltaic, and diesel generator). Our experiments confirm that SimpleMG can be used to develop high-performance neural controllers for complex microgrids while assuring runtime safety, even in the presence of adversarial input attacks on the neural controller. Our experiments also demonstrate the benefits of online retraining of the neural controller while the baseline controller is in control      
### 44.Model-Based Reconstruction for Collimated Beam Ultrasound Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.09703.pdf)
>  Collimated beam ultrasound systems are a novel technology for imaging inside multi-layered structures such as geothermal wells. Such systems include a transmitter and multiple receivers to capture reflected signals. Common algorithms for ultrasound reconstruction use delay-and-sum (DAS) approaches; these have low computational complexity but produce inaccurate images in the presence of complex structures and specialized geometries such as collimated beams. <br>In this paper, we propose a multi-layer, ultrasonic, model-based iterative reconstruction algorithm designed for collimated beam systems. We introduce a physics-based forward model to accurately account for the propagation of a collimated ultrasonic beam in multi-layer media and describe an efficient implementation using binary search. We model direct arrival signals, detector noise, and a spatially varying image prior, then cast the reconstruction as a maximum a posteriori estimation problem. Using simulated and experimental data we obtain significantly fewer artifacts relative to DAS while running in near real time using commodity compute resources.      
### 45.Evaluation of voltage magnitude based unbalance metric for low voltage distribution networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09669.pdf)
>  Voltage unbalance in distribution networks (DN) is expected to grow with increasing penetration of single-phase distributed generation and single-phase loads such as electric vehicle chargers. Unbalance mitigation will be a significant concern as voltage unbalance leads to increased losses, reduced motor and inverter efficiency, and becomes a limiting factor for DN operation. The true definition of the unbalance metric needs phasor measurements of network voltage and current. However, such phasor measurements are generally not available in real life and as such approximate definitions are widely used due to their simplicity. This work aims to compare the true voltage unbalance definition and approximate unbalance metrics derived from phase voltage magnitude, as phase voltage magnitudes are commonly measured by digital metering infrastructure. For the comparison, multi-period power flow simulations are performed for 161 Spanish distribution feeders with R/X ratios varying from 2.87 to 14.68. We observe that phase magnitude-based unbalance metrics reasonably approximate the true unbalance for higher R/X ratios with a varying load power factor in a DN. Furthermore, the approximate unbalance metrics slightly improve for a low DN power factor due to the increase in DN unbalance. Therefore, the phase magnitude-based unbalance metric can be utilized for approximating DN unbalance.      
### 46.Detection of Stealthy Adversaries for Networked Unmanned Aerial Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2202.09661.pdf)
>  A network of unmanned aerial vehicles (UAVs) provides distributed coverage, reconfigurability, and maneuverability in performing complex cooperative tasks. However, it relies on wireless communications that can be susceptible to cyber adversaries and intrusions, disrupting the entire network's operation. This paper develops model-based centralized and decentralized observer techniques for detecting a class of stealthy intrusions, namely zero-dynamics and covert attacks, on networked UAVs in formation control settings. The centralized observer that runs in a control center leverages switching in the UAVs' communication topology for attack detection, and the decentralized observers, implemented onboard each UAV in the network, use the model of networked UAVs and locally available measurements. Experimental results are provided to show the effectiveness of the proposed detection schemes in different case studies.      
### 47.Multi-Channel FFT Architectures Designed via Folding and Interleaving  [ :arrow_down: ](https://arxiv.org/pdf/2202.09623.pdf)
>  Computing the FFT of a single channel is well understood in the literature. However, computing the FFT of multiple channels in a systematic manner has not been fully addressed. This paper presents a framework to design a family of multi-channel FFT architectures using {\em folding} and {\em interleaving}. Three distinct multi-channel FFT architectures are presented in this paper. These architectures differ in the input and output preprocessing steps and are based on different folding sets, i.e., different orders of execution.      
### 48.A Lightweight Dual-Domain Attention Framework for Sparse-View CT Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2202.09609.pdf)
>  Computed Tomography (CT) plays an essential role in clinical diagnosis. Due to the adverse effects of radiation on patients, the radiation dose is expected to be reduced as low as possible. Sparse sampling is an effective way, but it will lead to severe artifacts on the reconstructed CT image, thus sparse-view CT image reconstruction has been a prevailing and challenging research area. With the popularity of mobile devices, the requirements for lightweight and real-time networks are increasing rapidly. In this paper, we design a novel lightweight network called CAGAN, and propose a dual-domain reconstruction pipeline for parallel beam sparse-view CT. CAGAN is an adversarial auto-encoder, combining the Coordinate Attention unit, which preserves the spatial information of features. Also, the application of Shuffle Blocks reduces the parameters by a quarter without sacrificing its performance. In the Radon domain, the CAGAN learns the mapping between the interpolated data and fringe-free projection data. After the restored Radon data is reconstructed to an image, the image is sent into the second CAGAN trained for recovering the details, so that a high-quality image is obtained. Experiments indicate that the CAGAN strikes an excellent balance between model complexity and performance, and our pipeline outperforms the DD-Net and the DuDoNet.      
### 49.Innovative semantic communication system  [ :arrow_down: ](https://arxiv.org/pdf/2202.09595.pdf)
>  Traditional communication systems focus on the transmission process, and the context-dependent meaning has been ignored. The fact that 5G system has approached Shannon limit and the increasing amount of data will cause communication bottleneck, such as the increased delay problems. Inspired by the ability of artificial intelligence to understand semantics, we propose a new communication paradigm, which integrates artificial intelligence and communication, the semantic communication system. Semantic communication is at the second level of communication based on Shannon and Weaver\cite{6197583}, which retains the semantic features of the transmitted information and recovers the signal at the receiver, thus compressing the communication traffic without losing important information. Different from other semantic communication systems, the proposed system not only transmits semantic information but also transmits semantic decoder. In addition, a general semantic metrics is proposed to measure the quality of semantic communication system. In particular, the semantic communication system for image, namely AESC-I, is designed to verify the feasibility of the new paradigm. Simulations are conducted on our system with the additive white Gaussian noise (AWGN) and the multipath fading channel using MNIST and Cifar10 datasets. The experimental results show that DeepSC-I can effectively extract semantic information and reconstruct images at a relatively low SNR.      
### 50.Data-driven approximation and reduction from noisy data in matrix pencil frameworks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09568.pdf)
>  This work aims at tackling the problem of learning surrogate models from noisy time-domain data by means of matrix pencil-based techniques, namely the Hankel and Loewner frameworks. A data-driven approach to obtain reduced order state-space models from time-domain input-output measurements for linear time-invariant (LTI) systems is proposed. This is accomplished by combining the aforementioned model order reduction (MOR) techniques with the signal matrix model (SMM) approach. The proposed method is illustrated by a numerical benchmark example consisting of a building model.      
### 51.Can Social Robots Effectively Elicit Curiosity in STEM Topics from K-1 Students During Oral Assessments?  [ :arrow_down: ](https://arxiv.org/pdf/2202.09531.pdf)
>  This paper presents the results of a pilot study that introduces social robots into kindergarten and first-grade classroom tasks. This study aims to understand 1) how effective social robots are in administering educational activities and assessments, and 2) if these interactions with social robots can serve as a gateway into learning about robotics and STEM for young children. We administered a commonly-used assessment (GFTA3) of speech production using a social robot and compared the quality of recorded responses to those obtained with a human assessor. In a comparison done between 40 children, we found no significant differences in the student responses between the two conditions over the three metrics used: word repetition accuracy, number of times additional help was needed, and similarity of prosody to the assessor. We also found that interactions with the robot were successfully able to stimulate curiosity in robotics, and therefore STEM, from a large number of the 164 student participants.      
### 52.LPC Augment: An LPC-Based ASR Data Augmentation Algorithm for Low and Zero-Resource Children's Dialects  [ :arrow_down: ](https://arxiv.org/pdf/2202.09529.pdf)
>  This paper proposes a novel linear prediction coding-based data aug-mentation method for children's low and zero resource dialect ASR. The data augmentation procedure consists of perturbing the formant peaks of the LPC spectrum during LPC analysis and reconstruction. The method is evaluated on two novel children's speech datasets with one containing California English from the Southern CaliforniaArea and the other containing a mix of Southern American English and African American English from the Atlanta, Georgia area. We test the proposed method in training both an HMM-DNN system and an end-to-end system to show model-robustness and demonstrate that the algorithm improves ASR performance, especially for zero resource dialect children's task, as compared to common data augmentation methods such as VTLP, Speed Perturbation, and SpecAugment.      
### 53.Assisting Living by Wireless Sensing: The Role of Integrated Sensing and Communications in 6G Era  [ :arrow_down: ](https://arxiv.org/pdf/2202.09522.pdf)
>  Advance in wireless communication and signal processing facilitates integrated sensing and communication (ISAC) -- a technology that combines sensing and communication functionalities to efficiently utilize congested wireless/hardware resources, and to pursue mutual benefits. Consequently, the future communications network will be perceptive. In this article, we provide a review of human-related sensing in the context of ISAC. We first present a general ISAC receiver signal processing framework, with a focus on human activity recognition (HAR). Based on geographical deployments, we then categorize current ISAC HAR into three classical configurations, namely monostatic, bi-static and distributed deployments, and discuss their properties, critical research problems and solutions. In order to facilitate system realization and improve the recognition performance, we further explore inherent connections between physical-layer system parameters and HAR performance metrics. Finally, we review major technical challenges and identify key open research problems.      
### 54.SPNet: A novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss  [ :arrow_down: ](https://arxiv.org/pdf/2202.09515.pdf)
>  Segmentation of retinal vessel images is critical to the diagnosis of retinopathy. Recently, convolutional neural networks have shown significant ability to extract the blood vessel structure. However, it remains challenging to refined segmentation for the capillaries and the edges of retinal vessels due to thickness inconsistencies and blurry boundaries. In this paper, we propose a novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss (SPNet) to address the above problems. Specifically, we introduce a decoder-sharing mechanism to capture multi-scale semantic information, where feature maps at diverse scales are decoded through a sequence of weight-sharing decoder modules. Also, to strengthen characterization on the capillaries and the edges of blood vessels, we define a residual pyramid architecture which decomposes the spatial information in the decoding phase. A pyramid-like loss function is designed to compensate possible segmentation errors progressively. Experimental results on public benchmarks show that the proposed method outperforms the backbone network and the state-of-the-art methods, especially in the regions of the capillaries and the vessel contours. In addition, performances on cross-datasets verify that SPNet shows stronger generalization ability.      
### 55.Exact Instability Margin Analysis and Minimum Norm Strong Stabilization -- phase change rate maximization --  [ :arrow_down: ](https://arxiv.org/pdf/2202.09500.pdf)
>  This paper is concerned with a new control related optimization problem named "phase change rate maximization" for single-input-single-output (SISO) linear time-invariant (LTI) systems. The problem relates to two control problems, namely robust instability analysis against stable perturbations and minimum norm strong stabilization. We define an index of the instability margin called "robust instability radius (RIR)" as the smallest $H_\infty$ norm of a stable perturbation that stabilizes a given unstable system. This paper has two main contributions. It is first shown that the problem of finding the exact RIR can be transformed into a problem of maximizing the phase change rate at the peak frequency with a phase constraint. Then, we show that the maximum is attained by a first-order all-pass function and derive conditions, under which the RIR can be exactly characterized, in terms of the phase change rate. Two extensions with illustrative examples are also provided.      
### 56.A Soft-Switching Single-Stage AC-DC Converter  [ :arrow_down: ](https://arxiv.org/pdf/2202.09462.pdf)
>  Partial resonance high frequency AC link converters are recognized to provide soft-switching, single-stage power conversion. They are highly reliable due to elimination of DC capacitors. Previous work has focused on proof of concept topologies and design requirements. In this work, a current regulated AC-DC converter from this family of converters is presented. The control design and grid integration requirements are discussed. An active damping method using grid current feedback is implemented to mitigate the filter resonance oscillations. The current control is implemented in the synchronous frame using voltage oriented control which enable power factor and power flow control. The result of converter operation and its control loops performances are presented      
### 57.Merging Control Strategies of Connected and Autonomous Vehicles at Freeway On-Ramps: A Comprehensive Review  [ :arrow_down: ](https://arxiv.org/pdf/2202.09457.pdf)
>  On-ramp merging areas are typical bottlenecks in the freeway network, since merging on-ramp vehicles may cause intensive disturbances on the mainline traffic flow and lead to various negative impacts on traffic efficiency and safety. The connected and autonomous vehicles (CAVs), with their capabilities of real-time communication and precise motion control, hold a great potential to facilitate ramp merging operation through enhanced coordination strategies. This paper presents a comprehensive review of the existing ramp merging strategies leveraging CAVs, focusing on the latest trends and developments in the research field. The review comprehensively covers 44 papers recently published in leading transportation journals. Based on the application context, control strategies are categorized into three categories: merging into sing-lane freeways with total CAVs, merging into sing-lane freeways with mixed traffic flows, and merging into multilane freeways. Relevant literature is reviewed regarding the required technologies, control decision level, applied methods, and impacts on traffic performance. More importantly, we identify the existing research gaps and provide insightful discussions on the potential and promising directions for future research based on the review, which facilitates further advancement in this research topic.      
### 58.Flow-level Coordination of Connected and Autonomous Vehicles in Multilane Freeway Ramp Merging Areas  [ :arrow_down: ](https://arxiv.org/pdf/2202.09454.pdf)
>  On-ramp merging areas are deemed to be typical bottlenecks for freeway networks due to the intensive disturbances induced by the frequent merging, weaving, and lane-changing behaviors. The Connected and Autonomous Vehicles (CAVs), benefited from their capabilities of real-time communication and precise motion control, hold an opportunity to promote ramp merging operation through enhanced cooperation. The existing CAV cooperation strategies are mainly designed for single-lane freeways, although multilane configurations are more prevailing in the real-world. In this paper, we present a flow-level CAV coordination strategy to facilitate merging operation in multilane freeways. The coordination integrates lane-change rules between mainstream lanes, proactive creation of large merging gaps, and platooning of ramp vehicles for enhanced benefits in traffic flow stability and efficiency. The strategy is formulated under an optimization framework, where the optimal control plan is determined based on real-time traffic conditions. The impacts of tunable model parameters on the produced control plan are discussed in detail. The efficiency of the proposed multilane strategy is demonstrated in a micro-simulation environment. The results show that the coordination can substantially improve the overall ramp merging efficiency and prevent recurrent traffic congestions, especially under high traffic volume conditions.      
### 59.Multiple Ancillary Services Provision by Distributed Energy Resources in Active Distribution Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09403.pdf)
>  The electric power system is currently experiencing radical changes stemming from the increasing share of renewable energy resources and the consequent decommissioning of conventional power plants based on synchronous generators. Since the principal providers of ancillary services are being phased out, new flexibility and reserve providers are needed. The proliferation of Distributed Energy Resources (DERs) in modern distribution networks has opened new possibilities for distribution system operators, enabling them to fill the market gap by harnessing the DER flexibility. This paper introduces a novel centralized MPC-based controller that enables the concurrent provision of voltage support, primary and secondary frequency control by adjusting the setpoints of a heterogeneous group of DERs in active distribution grids. The input-multirate control framework is used to accommodate the distinct timescales and provision requirements of each ancillary service and to ensure that the available resources are properly allocated. Furthermore, an efficient way for incorporating network constraints in the formulation is proposed, where network decomposition is applied to a linear power flow formulation together with network reduction. In addition, different timescale dynamics of the employed DERs and their capability curves are included. The performance of the proposed controller is evaluated on several case studies via dynamic simulations of the IEEE 33-bus system.      
### 60.Towards Digital Twin Oriented Modelling of Complex Networked Systems and Their Dynamics: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2202.09363.pdf)
>  This paper aims to provide a comprehensive critical overview on how entities and their interactions in Complex Networked Systems (CNS) are modelled across disciplines as they approach their ultimate goal of creating a Digital Twin (DT) that perfectly matches the reality. We propose a new framework to conceptually compare diverse existing modelling paradigms from different perspectives and create unified assessment criteria to assess their respective capabilities of reaching such an ultimate goal. Using the proposed criteria, we also appraise how far the reviewed current state-of-the-art approaches are from the idealised DTs. We also identify and propose potential directions and ways of building a DT-orientated CNS based on the convergence and integration of CNS and DT utilising a variety of cross-disciplinary techniques.      
### 61.Parameter Identification of a PN-Guided Incoming Missile Using an Improved Multiple-Model Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2202.09361.pdf)
>  An active defense against an incoming missile requires information of it, including a guidance law parameter and a first-order lateral time constant. To this end, assuming that a missile with a proportional navigation (PN) guidance law attempts to attack an aerial target with bang-bang evasive maneuvers, a parameter identification model based on the gated recurrent unit (GRU) neural network is built in this paper. The analytic identification solutions for the guidance law parameter and the first-order lateral time constant are derived. The inputs of the identification model are available kinematic information between the aircraft and the missile, while the outputs contain the regression results of missile parameters. To increase the training speed and the identification accuracy of the Model, an output processing method called improved multiplemodel mechanism (IMMM) is proposed in this paper. The effectiveness of IMMM and the performance of the established model are demonstrated through numerical simulations under various engagement scenarios.      
### 62.Analytic Method for Estimating Aircraft Fix Displacement from Gyroscope's Allan-Deviation Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2202.09360.pdf)
>  The noise and drift requirements for a navigation-grade gyroscope are widely known, yet there is no simple analytic model of how the noise and drift of a gyroscope influence the fix displacement error (FDE) of an inertial navigation system (INS). This work derives simple analytical expressions for the cross-track and along-track errors of an aircraft whose INS consists solely of a three-axis gyroscope system with perfect knowledge of the vertical direction. The error signal of each gyroscope is Gaussian white noise and drift modeled as a first-order Markov random walk. These expressions provide a straightforward mean of calculating the FDE of an aircraft as a function of the flight duration, velocity, noise amplitude, drift amplitude, and drift's time constant. These expressions are validated with Monte-Carlo simulations of long flights. This model quantifies the noise-versus-drift trade-off for a gyroscope in an inertial navigation system. It can save time when estimating the noise and drift that a gyroscope must exhibit to satisfy a given position-error requirement, or vice versa. They are used in particular to confirm the values, often cited without demonstration, of the noise and drift required to meet the maximum position error of an aircraft imposed by the Federal Aviation Administration's required navigation performance 10 specification. Finally, it demonstrates that using the minimum in the measured Allan deviation of a gyroscope as a metric of the drift is incorrect, because it fails to capture the drift's time constant. The proper metric is the maximum in the Allan deviation.      
### 63.The Role of Heterogeneity in Autonomous Perimeter Defense Problems  [ :arrow_down: ](https://arxiv.org/pdf/2202.10433.pdf)
>  When is heterogeneity in the composition of an autonomous robotic team beneficial and when is it detrimental? We investigate and answer this question in the context of a minimally viable model that examines the role of heterogeneous speeds in perimeter defense problems, where defenders share a total allocated speed budget. We consider two distinct problem settings and develop strategies based on dynamic programming and on local interaction rules. We present a theoretical analysis of both approaches and our results are extensively validated using simulations. Interestingly, our results demonstrate that the viability of heterogeneous teams depends on the amount of information available to the defenders. Moreover, our results suggest a universality property: across a wide range of problem parameters the optimal ratio of the speeds of the defenders remains nearly constant.      
### 64.Fast and Scalable Memristive In-Memory Sorting with Column-Skipping Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2202.10424.pdf)
>  Memristive in-memory sorting has been proposed recently to improve hardware sorting efficiency. Using iterative in-memory min computations, data movements between memory and external processing units can be eliminated for improved latency and energy efficiency. However, the bit-traversal algorithm to search the min requires a large number of column reads on memristive memory. In this work, we propose a column-skipping algorithm with help of a near-memory circuit. Redundant column reads can be skipped based on recorded states for improved latency and hardware efficiency. To enhance the scalability, we develop a multi-bank management that enables column-skipping for dataset stored in different memristive memory banks. Prototype column-skipping sorters are implemented with a 1T1R memristive memory in 40nm CMOS technology. Experimented on a variety of sorting datasets, the length-1024 32-bit column-skipping sorter with state recording of 2 demonstrates up to 4.08x speedup, 3.14x area efficiency and 3.39x energy efficiency, respectively, over the latest memristive in-memory sorting.      
### 65.Composite Anomaly Detection via Hierarchical Dynamic Search  [ :arrow_down: ](https://arxiv.org/pdf/2202.10418.pdf)
>  Anomaly detection among a large number of processes arises in many applications ranging from dynamic spectrum access to \textcolor{NewColor}{cybersecurity}. In such problems one can often obtain noisy observations aggregated from a chosen subset of processes \textcolor{NewColor}{that} {conforms} to a tree structure. The distribution of these observation\textcolor{NewColor}{s}, based on which the presence of anomalies is detected, may be only partially known. This gives rise to the need for a search strategy designed to account for both the sample complexity and the detection accuracy, as well as cope with statistical models that are known only up to some missing parameters. In this work we propose \textcolor{NewColor}{a} sequential search strategy using two variations of the \acl{gllr} \textcolor{NewColor}{statistic}. Our proposed \ac{hds} strategy is shown to be order-optimal with respect to the size of the search space and asymptotically optimal with respect to the detection accuracy. An explicit upper bound on the error probability of \ac{hds} is established for the finite sample regime. Extensive experiments are conducted, demonstrating the \textcolor{NewColor}{performance} gains of \ac{hds} over existing methods.      
### 66.Unified approach for computing sum of sources over CQ-MAC  [ :arrow_down: ](https://arxiv.org/pdf/2202.10403.pdf)
>  We consider the task of communicating a generic bivariate function of two classical sources over a Classical-Quantum Multiple Access Channel (CQ-MAC). The two sources are observed at the encoders of the CQ-MAC, and the decoder aims at reconstructing a bivariate function from the received quantum state. Inspired by the techniques developed for the analogous classical setting, and employing the technique of simultaneous (joint) decoding developed for the classical-quantum setting, we propose and analyze a coding scheme based on a fusion of algebraic structured and unstructured codes. This coding scheme allows exploiting both the symmetric structure common amongst the sources and the asymmetries. We derive a new set of sufficient conditions that strictly enlarges the largest known set of sources (capable of communicating the bivariate function) for any given CQ-MAC. We provide these conditions in terms of single-letter quantum information-theoretic quantities.      
### 67.Performance of dense wireless networks in 5G and beyond using stochastic geometry  [ :arrow_down: ](https://arxiv.org/pdf/2202.10363.pdf)
>  Device density in cellular networks is expected to increase considerably in the next future. Accordingly, the access point (AP) will equip massive multiple-input multiple-output (mMIMO) antennas, using collimated millimeter-wave (mmW) and sub-THz communications, and increase the bandwidth to accommodate the growing data rate demands. In this scenario, interference plays a critical role and, if not characterized and mitigated properly, might limit the performances of the network. In this context, this paper derives the statistical properties of the aggregated interference power for a cellular network equipping a mMIMO cylindrical array. The proposed statistical model considers the link blockage and other network parameters such as antenna configuration and device density. The findings show that the characteristic function (CF) of the aggregated interference power can be regarded as a weighted mixture of two alpha-stable distributions. Furthermore, by analyzing the service probability, it is found that there is an optimal configuration of the array depending on the AP height and device density. The proposed statistical model can be part of the design of dense networks providing valuable insights for optimal network deployment      
### 68.A self-adaptive RIS that estimates and shapes fading rich-scattering wireless channels  [ :arrow_down: ](https://arxiv.org/pdf/2202.10248.pdf)
>  We present a framework for operating a self-adaptive RIS inside a fading rich-scattering wireless environment. We model the rich-scattering wireless channel as being double-parametrized by (i) the RIS, and (ii) dynamic perturbers (moving objects, etc.). Within each coherence time, first, the self-adaptive RIS estimates the status of the dynamic perturbers (e.g., the perturbers' orientations and locations) based on measurements with an auxiliary wireless channel. Then, second, using a learned surrogate forward model of the mapping from RIS configuration and perturber status to wireless channel, an optimized RIS configuration to achieve a desired functionality is obtained. We demonstrate our technique using a physics-based end-to-end model of RIS-parametrized communication with adjustable fading (PhysFad) for the example objective of maximizing the received signal strength indicator. Our results present a route toward convergence of RIS-empowered localization and sensing with RIS-empowered channel shaping beyond the simple case of operation in free space without fading.      
### 69.Fourier ptychography multi-parameter neural network with composite physical priori optimization  [ :arrow_down: ](https://arxiv.org/pdf/2202.10239.pdf)
>  Fourier ptychography microscopy(FP) is a recently developed computational imaging approach for microscopic super-resolution imaging. By turning on each light-emitting-diode (LED) located on different position on the LED array sequentially and acquiring the corresponding images that contain different spatial frequency components, high spatial resolution and quantitative phase imaging can be achieved in the case of large field-of-view. Nevertheless, FPM has high requirements for the system construction and data acquisition processes, such as precise LEDs position, accurate focusing and appropriate exposure time, which brings many limitations to its practical applications. In this paper, inspired by artificial neural network, we propose a Fourier ptychography multi-parameter neural network (FPMN) with composite physical prior optimization. A hybrid parameter determination strategy combining physical imaging model and data-driven network training is proposed to recover the multi layers of the network corresponding to different physical parameters, including sample complex function, system pupil function, defocus distance, LED array position deviation and illumination intensity fluctuation, etc. Among these parameters, LED array position deviation is recovered based on the features of brightfield to darkfield transition low-resolution images while the others are recovered in the process of training of the neural network. The feasibility and effectiveness of FPMN are verified through simulations and actual experiments. Therefore FPMN can evidently reduce the requirement for practical applications of FPM.      
### 70.A Dynamic Model of a Skydiver With Validation in Wind Tunnel and Free Fall  [ :arrow_down: ](https://arxiv.org/pdf/2202.10233.pdf)
>  An innovative approach of gaining insight into motor skills involved in human body flight is proposed. The key idea is the creation of a model autonomous system capable of virtually performing skydiving maneuvers. A dynamic skydiver model and simulator is developed, comprising biomechanical, aerodynamic, and kinematic models, dynamic equations of motion, and a virtual reality environment. Limb relative orientations, and resulting inertial body angular position and velocity are measured in skydiving experiments in a vertical wind tunnel and in free fall. These experimental data are compared with corresponding simulation data to tune and verify the model for basic skydiving maneuvers. The model is further extended to reconstruct advanced aerial maneuvers, such as transitions between stable equilibria. The experimental data are used to estimate skydiver's conscious inputs as a function of time, via an Unscented Kalman Filter modified for this purpose.      
### 71.Information Revelation Through Signalling  [ :arrow_down: ](https://arxiv.org/pdf/2202.10145.pdf)
>  This paper studies a Stackelberg game wherein a sender (leader) attempts to shape the information of a less informed receiver (follower) who in turn takes an action that determines the payoff of both players. The sender chooses signals to maximize its own utility function while the receiver aims to ascertain the value of a source that is privately known to the sender. It is well known that such sender-receiver games admit a vast number of equilibria and not all signals from the sender can be relied on as truthful. Our main contribution is an exact characterization of the minimum number of distinct source symbols that can be correctly recovered by a receiver in \textit{any} equilibrium of this game; we call this quantity the \textit{informativeness} of the sender. We show that the informativeness is given by the \textit{vertex clique cover number} of a certain graph induced by the utility function, whereby it can be computed based on the utility function alone without the need to enumerate all equilibria. We find that informativeness characterizes the existence of well-known classes of separating, pooling and semi-separating equilibria. We also compare informativeness with the amount of information obtained by the receiver when it is the leader and show that the informativeness is always greater than the latter, implying that the receiver is better off being a follower.      
### 72.Inferring Network Structure with Unobservable Nodes from Time Series Data  [ :arrow_down: ](https://arxiv.org/pdf/2202.10144.pdf)
>  Network structures play important roles in social, technological and biological systems. However, the observable nodes and connections in real cases are often incomplete or unavailable due to measurement errors, private protection issues, or other problems. Therefore, inferring the complete network structure is useful for understanding human interactions and complex dynamics. The existing studies have not fully solved the problem of inferring network structure with partial information about connections or nodes. In this paper, we tackle the problem by utilizing time-series data generated by network dynamics. We regard the network inference problem based on dynamical time series data as a problem of minimizing errors for predicting states of observable nodes and proposed a novel data-driven deep learning model called Gumbel-softmax Inference for Network (GIN) to solve the problem under incomplete information. The GIN framework includes three modules: a dynamics learner, a network generator, and an initial state generator to infer the unobservable parts of the network. We implement experiments on artificial and empirical social networks with discrete and continuous dynamics. The experiments show that our method can infer the unknown parts of the structure and the initial states of the observable nodes with up to 90\% accuracy. The accuracy declines linearly with the increase of the fractions of unobservable nodes. Our framework may have wide applications where the network structure is hard to obtain and the time series data is rich.      
### 73.A new data augmentation method for intent classification enhancement and its application on spoken conversation datasets  [ :arrow_down: ](https://arxiv.org/pdf/2202.10137.pdf)
>  Intent classifiers are vital to the successful operation of virtual agent systems. This is especially so in voice activated systems where the data can be noisy with many ambiguous directions for user intents. Before operation begins, these classifiers are generally lacking in real-world training data. Active learning is a common approach used to help label large amounts of collected user input. However, this approach requires many hours of manual labeling work. We present the Nearest Neighbors Scores Improvement (NNSI) algorithm for automatic data selection and labeling. The NNSI reduces the need for manual labeling by automatically selecting highly-ambiguous samples and labeling them with high accuracy. This is done by integrating the classifier's output from a semantically similar group of text samples. The labeled samples can then be added to the training set to improve the accuracy of the classifier. We demonstrated the use of NNSI on two large-scale, real-life voice conversation systems. Evaluation of our results showed that our method was able to select and label useful samples with high accuracy. Adding these new samples to the training data significantly improved the classifiers and reduced error rates by up to 10%.      
### 74.Accurate Single-Ended Measurement of Propagation Delay in Fiber Using Correlation Optical Time Domain Reflectometry  [ :arrow_down: ](https://arxiv.org/pdf/2202.10112.pdf)
>  A correlation optical time-domain reflectometry (COTDR) method is presented, which measures the propagation delay with an accuracy of a few picoseconds. This accuracy is achieved using a test signal data rate of 10 Gbit/s and employing cross-correlation and pulse fitting techniques. In this paper we introduce and evaluate the basic signal processing steps, investigate the measurement accuracy, and discuss applications for monitoring link delay and chromatic dispersion of long fiber spans as well as temperature sensing applications.      
### 75.Simplified Learning of CAD Features Leveraging a Deep Residual Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2202.10099.pdf)
>  In the domain of computer vision, deep residual neural networks like EfficientNet have set new standards in terms of robustness and accuracy. One key problem underlying the training of deep neural networks is the immanent lack of a sufficient amount of training data. The problem worsens especially if labels cannot be generated automatically, but have to be annotated manually. This challenge occurs for instance if expert knowledge related to 3D parts should be externalized based on example models. One way to reduce the necessary amount of labeled data may be the use of autoencoders, which can be learned in an unsupervised fashion without labeled data. In this work, we present a deep residual 3D autoencoder based on the EfficientNet architecture, intended for transfer learning tasks related to 3D CAD model assessment. For this purpose, we adopted EfficientNet to 3D problems like voxel models derived from a STEP file. Striving to reduce the amount of labeled 3D data required, the networks encoder can be utilized for transfer training.      
### 76.Massive MIMO with Dual-Polarized Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2202.10084.pdf)
>  This paper considers a single-cell massive MIMO (multiple-input multiple-output) system with dual-polarized antennas at both the base station and users. We study a channel model that takes into account several practical aspects that arise when utilizing dual-polarization, such as channel cross-polar discrimination (XPD) and cross-polar correlations (XPC) at the transmitter and receiver. We analyze uplink and downlink achievable spectral efficiencies (SE) with and without successive interference cancellation (SIC) for the linear minimum mean squared error (MMSE), zero-forcing (ZF), and maximum ratio (MR) combining/precoding schemes. In addition, we derive the statistical properties of the MMSE channel estimator for the dual-polarized channel model. These estimates are used to implement different precoding and combining schemes when the uplink and downlink SE expressions are calculated for the case. Closed-form uplink and downlink SE expressions for MR combining/precoding are derived. Based on these results, we also provide power control algorithms to maximize the uplink and downlink sum SEs. Moreover, we compare the SEs achieved in dual-polarized and uni-polarized setups numerically and evaluate the impact of XPD and XPC.      
### 77.ICSML: Industrial Control Systems Machine Learning inference framework natively executing on IEC 61131-3 languages  [ :arrow_down: ](https://arxiv.org/pdf/2202.10075.pdf)
>  Industrial Control Systems (ICS) have played a catalytic role in enabling the 4th Industrial Revolution. ICS devices like Programmable Logic Controllers (PLCs), automate, monitor and control critical processes in industrial, energy and commercial environments. The convergence of traditional Operational Technology (OT) with Information Technology (IT) has opened a new and unique threat landscape. This has inspired defense research that focuses heavily on Machine Learning (ML) based anomaly detection methods that run on external IT hardware which means an increase in costs and the further expansion of the threat landscape. To remove this requirement, we introduce the ICS Machine Learning inference framework (ICSML) which enables the execution of ML models natively on the PLC. ICSML is implemented in IEC 61131-3 code and works around the limitations imposed by the domain-specific languages, providing a complete set of components for the creation of fully fledged ML models in a way similar to established ML frameworks. We then demonstrate a complete end-to-end methodology for creating ICS ML models using an external framework for training and ICSML for the PLC implementation. To evaluate our contributions we run a series of benchmarks studying memory and performance and compare our solution to the TFLite inference framework. Finally, to demonstrate the abilities of ICSML and to verify its non-intrusive nature, we develop and evaluate a case study of a real defense for process aware attacks against a Multi Stage Flash (MSF) desalination plant.      
### 78.Channel Estimation and Projection for RIS-assisted MIMO Using Zadoff-Chu Sequences  [ :arrow_down: ](https://arxiv.org/pdf/2202.10038.pdf)
>  The reconfigurable intelligent surface (RIS) technology is a promising enabler for millimeter wave (mmWave) wireless communications, as it can potentially provide spectral efficiency comparable to the conventional massive multiple-input multiple-output (MIMO) but with significantly lower hardware complexity. In this paper, we focus on the estimation and projection of the uplink RIS-aided massive MIMO channel, which can be time-varying. We propose to let the user equipments (UE) transmit Zadoff-Chu (ZC) sequences and let the base station (BS) conduct maximum likelihood (ML) estimation of the uplink channel. The proposed scheme is computationally efficient: it uses ZC sequences to decouple the estimation of the frequency and time offsets; it uses the space-alternating generalized expectation-maximization (SAGE) method to reduce the high-dimensional problem due to the multipaths to multiple lower-dimensional ones per path. Owing to the estimation of the Doppler frequency offsets, the time-varying channel state can be projected, which can significantly lower the overhead of the pilots for channel estimation. The numerical simulations verify the effectiveness of the proposed scheme.      
### 79.Hardware Obfuscation of Digital FIR Filters  [ :arrow_down: ](https://arxiv.org/pdf/2202.10022.pdf)
>  A finite impulse response (FIR) filter is a ubiquitous block in digital signal processing applications. Its characteristics are determined by its coefficients, which are the intellectual property (IP) for its designer. However, in a hardware efficient realization, its coefficients become vulnerable to reverse engineering. This paper presents a filter design technique that can protect this IP, taking into account hardware complexity and ensuring that the filter behaves as specified only when a secret key is provided. To do so, coefficients are hidden among decoys, which are selected beyond possible values of coefficients using three alternative methods. As an attack scenario, an adversary at an untrusted foundry is considered. A reverse engineering technique is developed to find the chosen decoy selection method and explore the potential leakage of coefficients through decoys. An oracle-less attack is also used to find the secret key. Experimental results show that the proposed technique can lead to filter designs with competitive hardware complexity and higher resiliency to attacks with respect to previously proposed methods.      
### 80.AVQVC: One-shot Voice Conversion by Vector Quantization with applying contrastive learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.10020.pdf)
>  Voice Conversion(VC) refers to changing the timbre of a speech while retaining the discourse content. Recently, many works have focused on disentangle-based learning techniques to separate the timbre and the linguistic content information from a speech signal. Once successful, voice conversion will be feasible and straightforward. This paper proposed a novel one-shot voice conversion framework based on vector quantization voice conversion (VQVC) and AutoVC, called AVQVC. A new training method is applied to VQVC to separate content and timbre information from speech more effectively. The result shows that this approach has better performance than VQVC in separating content and timbre to improve the sound quality of generated speech.      
### 81.Deep Feature based Cross-slide Registration  [ :arrow_down: ](https://arxiv.org/pdf/2202.09971.pdf)
>  Cross-slide image analysis provides additional information by analysing the expression of different biomarkers as compared to a single slide analysis. Slides stained with different biomarkers are analysed side by side which may reveal unknown relations between the different biomarkers. During the slide preparation, a tissue section may be placed at an arbitrary orientation as compared to other sections of the same tissue block. The problem is compounded by the fact that tissue contents are likely to change from one section to the next and there may be unique artefacts on some of the slides. This makes registration of each section to a reference section of the same tissue block an important pre-requisite task before any cross-slide analysis. We propose a deep feature based registration (DFBR) method which utilises data-driven features to estimate the rigid transformation. We adopted a multi-stage strategy for improving the quality of registration. We also developed a visualisation tool to view registered pairs of WSIs at different magnifications. With the help of this tool, one can apply a transformation on the fly without the need to generate transformed source WSI in a pyramidal form. We compared the performance of data-driven features with that of hand-crafted features on the COMET dataset. Our approach can align the images with low registration errors. Generally, the success of non-rigid registration is dependent on the quality of rigid registration. To evaluate the efficacy of the DFBR method, the first two steps of the ANHIR winner's framework are replaced with our DFBR to register challenge provided image pairs. The modified framework produce comparable results to that of challenge winning team.      
### 82.LiDAR-guided Stereo Matching with a Spatial Consistency Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2202.09953.pdf)
>  The complementary fusion of light detection and ranging (LiDAR) data and image data is a promising but challenging task for generating high-precision and high-density point clouds. This study proposes an innovative LiDAR-guided stereo matching approach called LiDAR-guided stereo matching (LGSM), which considers the spatial consistency represented by continuous disparity or depth changes in the homogeneous region of an image. The LGSM first detects the homogeneous pixels of each LiDAR projection point based on their color or intensity similarity. Next, we propose a riverbed enhancement function to optimize the cost volume of the LiDAR projection points and their homogeneous pixels to improve the matching robustness. Our formulation expands the constraint scopes of sparse LiDAR projection points with the guidance of image information to optimize the cost volume of pixels as much as possible. We applied LGSM to semi-global matching and AD-Census on both simulated and real datasets. When the percentage of LiDAR points in the simulated datasets was 0.16%, the matching accuracy of our method achieved a subpixel level, while that of the original stereo matching algorithm was 3.4 pixels. The experimental results show that LGSM is suitable for indoor, street, aerial, and satellite image datasets and provides good transferability across semi-global matching and AD-Census. Furthermore, the qualitative and quantitative evaluations demonstrate that LGSM is superior to two state-of-the-art optimizing cost volume methods, especially in reducing mismatches in difficult matching areas and refining the boundaries of objects.      
### 83.CampNet: Context-Aware Mask Prediction for End-to-End Text-Based Speech Editing  [ :arrow_down: ](https://arxiv.org/pdf/2202.09950.pdf)
>  The text-based speech editor allows the editing of speech through intuitive cutting, copying, and pasting operations to speed up the process of editing speech. However, the major drawback of current systems is that edited speech often sounds unnatural due to cut-copy-paste operation. In addition, it is not obvious how to synthesize records according to a new word not appearing in the transcript. This paper proposes a novel end-to-end text-based speech editing method called context-aware mask prediction network (CampNet). The model can simulate the text-based speech editing process by randomly masking part of speech and then predicting the masked region by sensing the speech context. It can solve unnatural prosody in the edited region and synthesize the speech corresponding to the unseen words in the transcript. Secondly, for the possible operation of text-based speech editing, we design three text-based operations based on CampNet: deletion, insertion, and replacement. These operations can cover various situations of speech editing. Thirdly, to synthesize the speech corresponding to long text in insertion and replacement operations, a word-level autoregressive generation method is proposed. Fourthly, we propose a speaker adaptation method using only one sentence for CampNet and explore the ability of few-shot learning based on CampNet, which provides a new idea for speech forgery tasks. The subjective and objective experiments on VCTK and LibriTTS datasets show that the speech editing results based on CampNet are better than TTS technology, manual editing, and VoCo method. We also conduct detailed ablation experiments to explore the effect of the CampNet structure on its performance. Finally, the experiment shows that speaker adaptation with only one sentence can further improve the naturalness of speech. Examples of generated speech can be found at <a class="link-external link-https" href="https://hairuo55.github.io/CampNet" rel="external noopener nofollow">this https URL</a>.      
### 84.Extending Flat Motion Planning to Non-flat Systems. Experiments on Aircraft Models Using Maple  [ :arrow_down: ](https://arxiv.org/pdf/2202.09921.pdf)
>  Aircraft models may be considered as flat if one neglects some terms associated to aerodynamics. But some maneuvers may be hard to achieve with this flat approximation. Computational experiments in Maple show that in some cases a suitably designed feed-back allows to follow such trajectories, when applied to the non-flat model. We propose an iterated process to compute a more achievable trajectory, starting from the flat reference trajectory. More precisely, the unknown neglected terms in the flat model are iteratively re-evaluated using the values obtained at the previous step. This process may be interpreted as a new trajectory parametrization using an infinite number of derivatives, a property that may be called generalized flatness. We illustrate the pertinence of this approach in flight conditions of increasing difficulties, from power-off gliding flight to aerobatics.      
### 85.Transmission-Aware Bandwidth Variable Transceiver Allocation in DWDM Optical Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09913.pdf)
>  This paper addresses the transmission-aware transceiver allocation problem of flexible optical networks for a multi-period planning. The proposed approach aims at assigning the best configuration of bandwidth variable transceivers (BVTRX) considering the amplifier noise and nonlinear channel interferences using the incoherent Extended Gaussian Noise (EGN) model. The proposed solution improves the network throughput and spectrum utilization in the early planning periods and allocates lower number of BV-TRXs in later periods in comparison to algorithms presented recently. A heuristic approach to regenerator placement has also been applied achieving up to 25% transceiver and 50% spectrum utilization savings in comparison to configurations without regenerators.      
### 86.towards automatic transcription of polyphonic electric guitar music:a new dataset and a multi-loss transformer model  [ :arrow_down: ](https://arxiv.org/pdf/2202.09907.pdf)
>  In this paper, we propose a new dataset named EGDB, that con-tains transcriptions of the electric guitar performance of 240 tab-latures rendered with different tones. Moreover, we benchmark theperformance of two well-known transcription models proposed orig-inally for the piano on this dataset, along with a multi-loss Trans-former model that we newly propose. Our evaluation on this datasetand a separate set of real-world recordings demonstrate the influenceof timbre on the accuracy of guitar sheet transcription, the potentialof using multiple losses for Transformers, as well as the room forfurther improvement for this task.      
### 87.Quasi-Orthogonal Foliations of the Configuration Space -- A Redundancy Resolution Approach at Position Level  [ :arrow_down: ](https://arxiv.org/pdf/2202.09869.pdf)
>  High versatility and flexibility of robotic systems require kinematic structures with many degrees of freedom. This usually renders the system kinematically redundant, i.e., its maneuvers are not fully determined by the main manipulation or interaction task. Additional constraints or objectives are required to solve the under-determined control and planning problems. The state-of-the-art approaches involve arranging tasks in a hierarchy and decoupling lower from higher priority tasks on velocity or torque level. Velocities and torques are elements of vector and covector spaces, respectively, and thus the approaches are inherently based on linear algebra tools. In this paper, we develop an approach to redundancy resolution and decoupling on position level. That requires moving from vector spaces and linear algebra to manifolds and differential geometry. We propose to determine, in addition to the task forward kinematics, another set of coordinate functions. The Jacobian of those functions shall resemble the conditions known from the linear algebra-based velocity- and torque-level decoupling to the best extent possible. The approach provides a better insight into the topological properties of robot kinematics and control problems, allowing a more global geometrical view. Quasi-decoupled coordinates can help to avoid or diminish some practical and theoretical difficulties related to the classical projection approaches at the cost of higher offline computational efforts. A condition for the existence of these coordinates is derived. If the condition is not satisfied, one can still find approximate solutions by numerical optimization. Finally, we show simulation results for both, trajectory tracking and classical impedance control.      
### 88.Practical Interference Exploitation Precoding without Symbol-by-Symbol Optimization: A Block-Level Approach  [ :arrow_down: ](https://arxiv.org/pdf/2202.09830.pdf)
>  In this paper, we propose a constructive interference (CI)-based block-level precoding (CI-BLP) approach for the downlink of a multi-user multiple-input single-output (MU-MISO) communication system. Contrary to existing CI precoding approaches which have to be designed on a symbol-by-symbol level, here a constant precoding matrix is applied to a block of symbol slots within a channel coherence interval, thus significantly reducing the computational costs over traditional CI-based symbol-level precoding (CI-SLP) as the CI-BLP optimization problem only needs to be solved once per block. For both PSK and QAM modulation, we formulate an optimization problem to maximize the minimum CI effect over the block subject to a block- rather than symbol-level power budget. We mathematically derive the optimal precoding matrix for CI-BLP as a function of the Lagrange multipliers in closed form. By formulating the dual problem, the original CI-BLP optimization problem is further shown to be equivalent to a quadratic programming (QP) optimization. Numerical results validate our derivations, and show that the proposed CI-BLP scheme achieves improved performance over the traditional CI-SLP method, thanks to the relaxed power constraint over the considered block of symbol slots.      
### 89.Gradient Tracking: A Unified Approach to Smooth Distributed Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2202.09804.pdf)
>  In this work, we study the classical distributed optimization problem over digraphs, where the objective function is a sum of smooth local functions. Inspired by the implicit tracking mechanism proposed in our earlier work, we develop a unified algorithmic framework from a pure primal perspective, i.e., UGT, which is essentially a generalized gradient tracking method and can unify most existing distributed optimization algorithms with constant step-sizes. It is proved that two variants of UGT can both achieve linear convergence if the global objective function is strongly convex. Finally, the performance of UGT is evaluated by numerical experiments.      
### 90.Distortion-Aware Loop Filtering of Intra 360^o Video Coding with Equirectangular Projection  [ :arrow_down: ](https://arxiv.org/pdf/2202.09802.pdf)
>  In this paper, we propose a distortion-aware loop filtering model to improve the performance of intra coding for 360$^o$ videos projected via equirectangular projection (ERP) format. To enable the awareness of distortion, our proposed module analyzes content characteristics based on a coding unit (CU) partition mask and processes them through partial convolution to activate the specified area. The feature recalibration module, which leverages cascaded residual channel-wise attention blocks (RCABs) to adjust the inter-channel and intra-channel features automatically, is capable of adapting with different quality levels. The perceptual geometry optimization combining with weighted mean squared error (WMSE) and the perceptual loss guarantees both the local field of view (FoV) and global image reconstruction with high quality. Extensive experimental results show that our proposed scheme achieves significant bitrate savings compared with the anchor (HM + 360Lib), leading to 8.9%, 9.0%, 7.1% and 7.4% on average bit rate reductions in terms of PSNR, WPSNR, and PSNR of two viewports for luminance component of 360^o videos, respectively.      
### 91.An Analysis of Complex-Valued CNNs for RF Data-Driven Wireless Device Classification  [ :arrow_down: ](https://arxiv.org/pdf/2202.09777.pdf)
>  Recent deep neural network-based device classification studies show that complex-valued neural networks (CVNNs) yield higher classification accuracy than real-valued neural networks (RVNNs). Although this improvement is (intuitively) attributed to the complex nature of the input RF data (i.e., IQ symbols), no prior work has taken a closer look into analyzing such a trend in the context of wireless device identification. Our study provides a deeper understanding of this trend using real LoRa and WiFi RF datasets. We perform a deep dive into understanding the impact of (i) the input representation/type and (ii) the architectural layer of the neural network. For the input representation, we considered the IQ as well as the polar coordinates both partially and fully. For the architectural layer, we considered a series of ablation experiments that eliminate parts of the CVNN components. Our results show that CVNNs consistently outperform RVNNs counterpart in the various scenarios mentioned above, indicating that CVNNs are able to make better use of the joint information provided via the in-phase (I) and quadrature (Q) components of the signal.      
### 92.Enhancing Affective Representations of Music-Induced EEG through Multimodal Supervision and latent Domain Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2202.09750.pdf)
>  The study of Music Cognition and neural responses to music has been invaluable in understanding human emotions. Brain signals, though, manifest a highly complex structure that makes processing and retrieving meaningful features challenging, particularly of abstract constructs like affect. Moreover, the performance of learning models is undermined by the limited amount of available neuronal data and their severe inter-subject variability. In this paper we extract efficient, personalized affective representations from EEG signals during music listening. To this end, we employ music signals as a supervisory modality to EEG, aiming to project their semantic correspondence onto a common representation space. We utilize a bi-modal framework by combining an LSTM-based attention model to process EEG and a pre-trained model for music tagging, along with a reverse domain discriminator to align the distributions of the two modalities, further constraining the learning process with emotion tags. The resulting framework can be utilized for emotion recognition both directly, by performing supervised predictions from either modality, and indirectly, by providing relevant music samples to EEG input queries. The experimental findings show the potential of enhancing neuronal data through stimulus information for recognition purposes and yield insights into the distribution and temporal variance of music-induced affective features.      
### 93.Schrdinger Meets Kuramoto via Feynman-Kac: Minimum Effort Distribution Steering for Noisy Nonuniform Kuramoto Oscillators  [ :arrow_down: ](https://arxiv.org/pdf/2202.09734.pdf)
>  We formulate and solve the problem of finite horizon minimum control effort steering of the state probability distribution between prescribed endpoint joints for a finite population of networked noisy nonuniform Kuramoto oscillators. We consider both the first and second order stochastic Kuramoto models. For numerical solution of the associated stochastic optimal control, we propose combining certain measure-valued proximal recursions and the Feynman-Kac path integral computation. We illustrate the proposed framework via numerical examples.      
### 94.It's Raw! Audio Generation with State-Space Models  [ :arrow_down: ](https://arxiv.org/pdf/2202.09729.pdf)
>  Developing architectures suitable for modeling raw audio is a challenging problem due to the high sampling rates of audio waveforms. Standard sequence modeling approaches like RNNs and CNNs have previously been tailored to fit the demands of audio, but the resultant architectures make undesirable computational tradeoffs and struggle to model waveforms effectively. We propose SaShiMi, a new multi-scale architecture for waveform modeling built around the recently introduced S4 model for long sequence modeling. We identify that S4 can be unstable during autoregressive generation, and provide a simple improvement to its parameterization by drawing connections to Hurwitz matrices. SaShiMi yields state-of-the-art performance for unconditional waveform generation in the autoregressive setting. Additionally, SaShiMi improves non-autoregressive generation performance when used as the backbone architecture for a diffusion model. Compared to prior architectures in the autoregressive generation setting, SaShiMi generates piano and speech waveforms which humans find more musical and coherent respectively, e.g. 2x better mean opinion scores than WaveNet on an unconditional speech generation task. On a music generation task, SaShiMi outperforms WaveNet on density estimation and speed at both training and inference even when using 3x fewer parameters. Code can be found at <a class="link-external link-https" href="https://github.com/HazyResearch/state-spaces" rel="external noopener nofollow">this https URL</a> and samples at <a class="link-external link-https" href="https://hazyresearch.stanford.edu/sashimi-examples" rel="external noopener nofollow">this https URL</a>.      
### 95.Echofilter: A Deep Learning Segmentation Model Improves the Automation, Standardization, and Timeliness for Post-Processing Echosounder Data in Tidal Energy Streams  [ :arrow_down: ](https://arxiv.org/pdf/2202.09648.pdf)
>  Understanding the abundance and distribution of fish in tidal energy streams is important for assessing the risk presented by the introduction of tidal energy devices into the habitat. However, the impressive tidal currents that make sites favorable for tidal energy development are often highly turbulent and entrain air into the water, complicating the interpretation of echosounder data. The portion of the water column contaminated by returns from entrained air must be excluded from data used for biological analyses. Application of a single algorithm to identify the depth-of-penetration of entrained-air is insufficient for a boundary that is discontinuous, depth-dynamic, porous, and widely variable across the tidal flow speeds which can range from 0 to 5m/s. Using a case study at a tidal energy demonstration site in the Bay of Fundy, we describe the development and application of deep learning models that produce a pronounced, consistent, substantial, and measurable improvement of the automated detection of the extent to which entrained-air has penetrated the water column. <br>Our model, Echofilter, was highly responsive to the dynamic range of turbulence conditions and sensitive to the fine-scale nuances in the boundary position, producing an entrained-air boundary line with an average error of 0.32m on mobile downfacing and 0.5-1.0m on stationary upfacing data. The model's annotations had a high level of agreement with the human segmentation (mobile downfacing Jaccard index: 98.8%; stationary upfacing: 93-95%). This resulted in a 50% reduction in the time required for manual edits compared to the time required to manually edit the line placed by currently available algorithms. Because of the improved initial automated placement, the implementation of the models generated a marked increase in the standardization and repeatability of line placement.      
### 96.Navigating Conceptual Space; A new take on Artificial General Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2202.09646.pdf)
>  Edward C. Tolman found reinforcement learning unsatisfactory for explaining intelligence and proposed a clear distinction between learning and behavior. Tolman's ideas on latent learning and cognitive maps eventually led to what is now known as conceptual space, a geometric representation where concepts and ideas can form points or shapes.Active navigation between ideas - reasoning - can be expressed directly as purposive navigation in conceptual space. Assimilating the theory of conceptual space from modern neuroscience, we propose autonomous navigation as a valid approach for emulated cognition. However, achieving autonomous navigation in high-dimensional Euclidean spaces is not trivial in technology. In this work, we explore whether neoRL navigation is up for the task; adopting Kaelbling's concerns for efficient robot navigation, we test whether the neoRL approach is general across navigational modalities, compositional across considerations of experience, and effective when learning in multiple Euclidean dimensions. We find neoRL learning to be more resemblant of biological learning than of RL in AI, and propose neoRL navigation of conceptual space as a plausible new path toward emulated cognition.      
### 97.Polytopic Matrix Factorization: Determinant Maximization Based Criterion and Identifiability  [ :arrow_down: ](https://arxiv.org/pdf/2202.09638.pdf)
>  We introduce Polytopic Matrix Factorization (PMF) as a novel data decomposition approach. In this new framework, we model input data as unknown linear transformations of some latent vectors drawn from a polytope. In this sense, the article considers a semi-structured data model, in which the input matrix is modeled as the product of a full column rank matrix and a matrix containing samples from a polytope as its column vectors. The choice of polytope reflects the presumed features of the latent components and their mutual relationships. As the factorization criterion, we propose the determinant maximization (Det-Max) for the sample autocorrelation matrix of the latent vectors. We introduce a sufficient condition for identifiability, which requires that the convex hull of the latent vectors contains the maximum volume inscribed ellipsoid of the polytope with a particular tightness constraint. Based on the Det-Max criterion and the proposed identifiability condition, we show that all polytopes that satisfy a particular symmetry restriction qualify for the PMF framework. Having infinitely many polytope choices provides a form of flexibility in characterizing latent vectors. In particular, it is possible to define latent vectors with heterogeneous features, enabling the assignment of attributes such as nonnegativity and sparsity at the subvector level. The article offers examples illustrating the connection between polytope choices and the corresponding feature representations.      
### 98.An Unsupervised Attentive-Adversarial Learning Framework for Single Image Deraining  [ :arrow_down: ](https://arxiv.org/pdf/2202.09635.pdf)
>  Single image deraining has been an important topic in low-level computer vision tasks. The atmospheric veiling effect (which is generated by rain accumulation, similar to fog) usually appears with the rain. Most deep learning-based single image deraining methods mainly focus on rain streak removal by disregarding this effect, which leads to low-quality deraining performance. In addition, these methods are trained only on synthetic data, hence they do not take into account real-world rainy images. To address the above issues, we propose a novel unsupervised attentive-adversarial learning framework (UALF) for single image deraining that trains on both synthetic and real rainy images while simultaneously capturing both rain streaks and rain accumulation features. UALF consists of a Rain-fog2Clean (R2C) transformation block and a Clean2Rain-fog (C2R) transformation block. In R2C, to better characterize the rain-fog fusion feature and to achieve high-quality deraining performance, we employ an attention rain-fog feature extraction network (ARFE) to exploit the self-similarity of global and local rain-fog information by learning the spatial feature correlations. Moreover, to improve the transformation ability of C2R, we design a rain-fog feature decoupling and reorganization network (RFDR) by embedding a rainy image degradation model and a mixed discriminator to preserve richer texture details. Extensive experiments on benchmark rain-fog and rain datasets show that UALF outperforms state-of-the-art deraining methods. We also conduct defogging performance evaluation experiments to further demonstrate the effectiveness of UALF      
### 99.Evaluation of Neuromorphic Spike Encoding of Sound Using Information Theory  [ :arrow_down: ](https://arxiv.org/pdf/2202.09619.pdf)
>  The problem of spike encoding of sound consists in transforming a sound waveform into spikes. It is of interest in many domains, including the development of audio-based spiking neural networks, where it is the first and most crucial stage of processing. Many algorithms have been proposed to perform spike encoding of sound. However, a systematic approach to quantitatively evaluate their performance is currently lacking. We propose the use of an information-theoretic framework to solve this problem. Specifically, we evaluate the coding efficiency of four spike encoding algorithms on two coding tasks that consist of coding the fundamental characteristics of sound: frequency and amplitude. The algorithms investigated are: Independent Spike Coding, Send-on-Delta coding, Ben's Spiker Algorithm, and Leaky Integrate-and-Fire coding. Using the tools of information theory, we estimate the information that the spikes carry on relevant aspects of an input stimulus. We find disparities in the coding efficiencies of the algorithms, where Leaky Integrate-and-Fire coding performs best. The information-theoretic analysis of their performance on these coding tasks provides insight on the encoding of richer and more complex sound stimuli.      
### 100.STAR-RIS-NOMA Networks: An Error Performance Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2202.09597.pdf)
>  This letter investigates the bit error rate (BER) performance of simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) in non-orthogonal multiple access (NOMA) networks. In the investigated network, a STAR-RIS serves two non-orthogonal users located on either side of the surface by utilizing the mode switching protocol. We derive the closed-form and upper bound BER expressions in perfect and imperfect successive interference cancellation cases. Furthermore, asymptotic analyses are also conducted to provide further insights into the BER behavior in the high signal-to-noise ratio region. Finally, the accuracy of our theoretical analysis is validated through Monte Carlo simulations. The obtained results reveal that the BER performance of STAR-RIS-NOMA outperforms that of the classical NOMA system, and STAR-RIS might be a promising NOMA 2.0 solution.      
### 101.C2N: Practical Generative Noise Modeling for Real-World Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2202.09533.pdf)
>  Learning-based image denoising methods have been bounded to situations where well-aligned noisy and clean images are given, or samples are synthesized from predetermined noise models, e.g., Gaussian. While recent generative noise modeling methods aim to simulate the unknown distribution of real-world noise, several limitations still exist. In a practical scenario, a noise generator should learn to simulate the general and complex noise distribution without using paired noisy and clean images. However, since existing methods are constructed on the unrealistic assumption of real-world noise, they tend to generate implausible patterns and cannot express complicated noise maps. Therefore, we introduce a Clean-to-Noisy image generation framework, namely C2N, to imitate complex real-world noise without using any paired examples. We construct the noise generator in C2N accordingly with each component of real-world noise characteristics to express a wide range of noise accurately. Combined with our C2N, conventional denoising CNNs can be trained to outperform existing unsupervised methods on challenging real-world benchmarks by a large margin.      
### 102.DRL-based Joint Beamforming and BS-RIS-UE Association Design for RIS-Assisted mmWave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09524.pdf)
>  Reconfigurable intelligent surface (RIS) is considered as an extraordinarily promising technology to solve the blockage problem of millimeter wave (mmWave) communications owing to its capable of establishing a reconfigurable wireless propagation. In this paper, we focus on a RIS-assisted mmWave communication network consisting of multiple base stations (BSs) serving a set of user equipments (UEs). Considering the BS-RIS-UE association problem which determines that the RIS should assist which BS and UEs, we joint optimize BS-RIS-UE association and passive beamforming at RIS to maximize the sum-rate of the system. To solve this intractable non-convex problem, we propose a soft actor-critic (SAC) deep reinforcement learning (DRL)-based joint beamforming and BS-RIS-UE association design algorithm, which can learn the best policy by interacting with the environment using less prior information and avoid falling into the local optimal solution by incorporating with the maximization of policy information entropy. The simulation results demonstrate that the proposed SAC-DRL algorithm can achieve significant performance gains compared with benchmark schemes.      
### 103.Energy-Efficient Throughput Maximization in mmWave MU-Massive-MIMO-OFDM: Genetic Algorithm based Resource Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2202.09438.pdf)
>  This paper develops a new genetic algorithm based resource allocation (GA-RA) technique for energy-efficient throughout maximization in multi-user massive multiple-input multiple-output (MU-mMIMO) systems using orthogonal frequency division multiplexing (OFDM) based transmission. We employ a hybrid precoding (HP) architecture with three stages: (i) radio frequency (RF) beamformer, (ii) baseband (BB) precoder, (iii) resource allocation (RA) block. First, a single RF beamformer block is built for all subcarriers via the slow time-varying angle-of-departure (AoD) information. For enhancing the energy efficiency, the RF beamformer aims to reduce the hardware cost/complexity and total power consumption via a low number of RF chains. Afterwards, the reduced-size effective channel state information (CSI) is utilized in the design of a distinct BB precoder and RA block for each subcarrier. The BB precoder is developed via regularized zero-forcing technique. Finally, the RA block is built via the proposed GA-RA technique for throughput maximization by allocating the power and subcarrier resources. The illustrative results show that the throughput performance in the MU-mMIMO-OFDM systems is greatly enhanced via the proposed GA-RA technique compared to both equal RA (EQ-RA) and particle swarm optimization based RA (PSO-RA). Moreover, the performance gain ratio increases with the increasing number of subcarriers, particularly for low transmission powers.      
### 104.Route Discovery and Capacity of Ad hoc Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.09423.pdf)
>  Throughput capacity of large ad hoc networks has been shown to scale adversely with the size of network $n$. However the need for the nodes to find or repair routes has not been analyzed in this context. In this paper, we explicitly take route discovery into account and obtain the scaling law for the throughput capacity under general assumptions on the network environment, node behavior, and the quality of route discovery algorithms. We also discuss a number of possible scenarios and show that the need for route discovery may change the scaling for the throughput capacity dramatically.      
### 105.Functional Optical Coherence Tomography for Intrinsic Signal Optoretinography: Recent Developments and Deployment Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2202.09414.pdf)
>  Intrinsic optical signal (IOS) imaging of the retina, also termed as optoretinography (ORG), promises a noninvasive method for objective assessment of retinal function. By providing unparalleled capability to differentiate individual layers of the retina, functional optical coherence tomography (OCT) has been actively investigated for intrinsic signal ORG measurements. However, clinical deployment of functional OCT for quantitative ORG is still challenging due to the lack of a standardized imaging protocol and the complication of IOS sources and mechanisms. This article aims to summarize recent developments of functional OCT for ORG measurement, OCT intensity- and phase-based IOS processing. Technical challenges and perspectives of quantitative IOS analysis and ORG interpretations are discussed.      
