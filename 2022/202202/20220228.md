# ArXiv eess --Mon, 28 Feb 2022
### 1.Model predictive control for retinal laser treatment at 1 kHz  [ :arrow_down: ](https://arxiv.org/pdf/2202.12879.pdf)
>  Laser photocoagulation is a technique applied in the treatment of retinal diseases. While this is often done manually or using simple control schemes, we pursue an optimization-based approach, namely Model Predictive Control (MPC), to enforce bounds on the peak temperature and, thus, safety during the medical treatment procedure - despite the spot-dependent absorption of the tissue. To this end, a repetition rate of 1 kHz is desirable rendering the real-time requirements a major challenge. We present a tailored MPC scheme using parametric model reduction, an extended Kalman filter for the parameter and state estimation, and suitably constructed stage costs and verify its applicability both in simulation and experiments with porcine eyes. Moreover, we give some insight on the implementation specifically tailored for fast numerical computations.      
### 2.A CNN-based Post-Processor for Perceptually-Optimized Immersive Media Compression  [ :arrow_down: ](https://arxiv.org/pdf/2202.12852.pdf)
>  In recent years, resolution adaptation based on deep neural networks has enabled significant performance gains for conventional (2D) video codecs. This paper investigates the effectiveness of spatial resolution resampling in the context of immersive content. The proposed approach reduces the spatial resolution of input multi-view videos before encoding, and reconstructs their original resolution after decoding. During the up-sampling process, an advanced CNN model is used to reduce potential re-sampling, compression, and synthesis artifacts. This work has been fully tested with the TMIV coding standard using a Versatile Video Coding (VVC) codec. The results demonstrate that the proposed method achieves a significant rate-quality performance improvement for the majority of the test sequences, with an average BD-VMAF improvement of 3.07 overall sequences.      
### 3.On Digital Subcarrier Multiplexing under A Bandwidth Limitation and ASE Noise  [ :arrow_down: ](https://arxiv.org/pdf/2202.12827.pdf)
>  We show that digital subcarrier multiplexing (DSM) systems require much greater complexity for Nyquist pulse shaping than single-carrier (SC) systems, and it is a misconception that both systems use the same bandwidth when using the same pulse shaping. Through back-to-back (B2B) experiments with realistic transmitter (TX) modules and amplified spontaneous emission (ASE) noise loading, we show that even with optimized waterfilling and entropy loading, DSM does not achieve a larger net data rate (NDR) compared to SC when only ASE noise exists in the channel in long-haul transmission scenarios.      
### 4.High-Dimensional Sparse Bayesian Learning without Covariance Matrices  [ :arrow_down: ](https://arxiv.org/pdf/2202.12808.pdf)
>  Sparse Bayesian learning (SBL) is a powerful framework for tackling the sparse coding problem. However, the most popular inference algorithms for SBL become too expensive for high-dimensional settings, due to the need to store and compute a large covariance matrix. We introduce a new inference scheme that avoids explicit construction of the covariance matrix by solving multiple linear systems in parallel to obtain the posterior moments for SBL. Our approach couples a little-known diagonal estimation result from numerical linear algebra with the conjugate gradient algorithm. On several simulations, our method scales better than existing approaches in computation time and memory, especially for structured dictionaries capable of fast matrix-vector multiplication.      
### 5.Development of a Model Predictive Airpath Controller for a Diesel Engine on a High-Fidelity Engine Model with Transient Thermal Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2202.12803.pdf)
>  This paper presents the results of a model predictive controller (MPC) development for diesel engine air-path regulation. The control objective is to track the intake manifold pressure and exhaust gas recirculation (EGR) rate targets by manipulating the EGR valve and variable geometry turbine (VGT) while satisfying state and control constraints. The MPC controller is designed and verified using a high-fidelity engine model in GT-Power. The controller exploits a low-order rate-based linear parameter-varying (LPV) model for prediction which is identified from transient response data generated by the GT-Power model. It is shown that transient engine thermal dynamics influence the airpath dynamics, specifically the intake manifold pressure response, however, MPC demonstrates robustness against inaccuracies in modeling these thermal dynamics. In particular, we show that MPC can be successfully implemented using a rate-based prediction model with two inputs (EGR and VGT positions) identified from data with steady-state wall temperature dynamics, however, closed-loop performance can be improved if a prediction model (i) is identified from data with transient thermal dynamics, and (ii) has the fuel injection rate as extra model input. Further, the MPC calibration process across the engine operating range to achieve improved performance is addressed. As the MPC calibration is shown to be sensitive to the operating conditions, a fast calibration process is proposed.      
### 6.Symbol repetition in interstellar communications: methods and observations  [ :arrow_down: ](https://arxiv.org/pdf/2202.12791.pdf)
>  Discoverable interstellar communication signals are expected to exhibit al least one signal characteristic clearly distinct from random noise. A hypothesis is proposed that radio telescope received signals may contain transmitted delta-t delta-f opposite circular polarized pulse pairs, conveying a combination of information content and discovery methods, including symbol repetition. Hypothetical signals are experimentally measured using a 26 foot diameter radio telescope, a chosen matched filter receiver, and machine post processing system. Measurements are expected to present likelihoods explained by an Additive White Gaussian Noise model, augmented to reduce radio frequency interference. In addition, measurements are expected to present no significant differences across a population of Right Ascension ranges, during long duration experiments. The hypothesis and experimental methods described in this paper are based on multiple radio telescope delta-t delta-f polarized pulse pair experiments previously reported. (ref. <a class="link-https" data-arxiv-id="2105.03727" href="https://arxiv.org/abs/2105.03727">arXiv:2105.03727</a>, <a class="link-https" data-arxiv-id="2106.10168" href="https://arxiv.org/abs/2106.10168">arXiv:2106.10168</a>). In the current work, a Right Ascension filter spans twenty-one 0.3 hour Right Ascension bins over a 0 to 6.3 hr range, during a 143 day experiment. Apparent symbol repetition is measured and analyzed. The 5.25 plus or minus 0.15 hr Right Ascension, -7.6 degree plus or minus 1 degree Declination celestial direction has been associated with anomalous observations in previous work, and continues to present anomalies, having unknown cause.      
### 7.Data-driven distributed MPC of dynamically coupled linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.12764.pdf)
>  In this paper, we present a data-driven distributed model predictive control (MPC) scheme to stabilise the origin of dynamically coupled discrete-time linear systems subject to decoupled input constraints. The local optimisation problems solved by the subsystems rely on a distributed adaptation of the Fundamental Lemma by Willems et al., allowing to parametrise system trajectories using only measured input-output data without explicit model knowledge. For the local predictions, the subsystems rely on communicated assumed trajectories of neighbours. Each subsystem guarantees a small deviation from these trajectories via a consistency constraint. We provide a theoretical analysis of the resulting non-iterative distributed MPC scheme, including proofs of recursive feasibility and (practical) stability. Finally, the approach is successfully applied to a numerical example.      
### 8.A Lyapunov function for robust stability of moving horizon estimation  [ :arrow_down: ](https://arxiv.org/pdf/2202.12744.pdf)
>  We provide a novel robust stability analysis for moving horizon estimation (MHE) using a Lyapunov function. Additionally, we introduce linear matrix inequalities (LMIs) to verify the necessary incremental input/output-to-state stability ($\delta$-IOSS) detectability condition. We consider an MHE formulation with time-discounted quadratic objective for nonlinear systems admitting an exponential $\delta$-IOSS Lyapunov function. We show that with a suitable parameterization of the MHE objective, the $\delta$-IOSS Lyapunov function serves as an $M$-step Lyapunov function for MHE. Provided that the estimation horizon is chosen large enough, this directly implies exponential stability of MHE. The stability analysis is also applicable to full information estimation, where the restriction to exponential $\delta$-IOSS can be relaxed. Moreover, we provide simple LMI conditions to systematically derive $\delta$-IOSS Lyapunov functions, which allows us to easily verify $\delta$-IOSS for a large class of nonlinear detectable systems. This is useful in the context of MHE in general, since most of the existing nonlinear (robust) stability results for MHE depend on the system being $\delta$-IOSS (detectable). In combination, we thus provide sufficient conditions that directly provide a framework to design MHE schemes with guaranteed robust exponential stability. The applicability of the overall MHE design is demonstrated with a nonlinear chemical reactor process.      
### 9.Learning-Based Fault-Tolerant Control for an Hexarotor with Model Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2202.12736.pdf)
>  In this paper we present a learning-based tracking controller based on Gaussian processes (GP) for a fault-tolerant hexarotor in a recovery maneuver. In particular, to estimate certain uncertainties that appear in a hexacopter vehicle with the ability to reconfigure its rotors to compensate for failures. The rotors reconfiguration introduces disturbances that make the dynamic model of the vehicle differ from the nominal model. The control algorithm is designed to learn and compensate the amount of modeling uncertainties after a failure in the control allocation reconfiguration by using GP as a learning-based model for the predictions. In particular the presented approach guarantees a probabilistic bounded tracking error with high probability. The performance of the learning-based fault-tolerant controller is evaluated through experimental tests with an hexarotor UAV.      
### 10.Benchmarking Generative Latent Variable Models for Speech  [ :arrow_down: ](https://arxiv.org/pdf/2202.12707.pdf)
>  Stochastic latent variable models (LVMs) achieve state-of-the-art performance on natural image generation but are still inferior to deterministic models on speech. In this paper, we develop a speech benchmark of popular temporal LVMs and compare them against state-of-the-art deterministic models. We report the likelihood, which is a much used metric in the image domain, but rarely, and often incomparably, reported for speech models. To assess the quality of the learned representations, we also compare their usefulness for phoneme recognition. Finally, we adapt the Clockwork VAE, a state-of-the-art temporal LVM for video generation, to the speech domain. Despite being autoregressive only in latent space, we find that the Clockwork VAE can outperform previous LVMs and reduce the gap to deterministic models by using a hierarchy of latent variables.      
### 11.State-of-the-art in speaker recognition  [ :arrow_down: ](https://arxiv.org/pdf/2202.12705.pdf)
>  Recent advances in speech technologies have produced new tools that can be used to improve the performance and flexibility of speaker recognition While there are few degrees of freedom or alternative methods when using fingerprint or iris identification techniques, speech offers much more flexibility and different levels for performing recognition: the system can force the user to speak in a particular manner, different for each attempt to enter. Also with voice input the system has other degrees of freedom, such as the use of knowledge/codes that only the user knows, or dialectical/semantical traits that are difficult to forge. This paper offers and overview of the state of the art in speaker recognition, with special emphasis on the pros and contras, and the current research lines. The current research lines include improved classification systems, and the use of high level information by means of probabilistic grammars. In conclusion, speaker recognition is far away from being a technology where all the possibilities have already been explored.      
### 12.Domain Adaptation: the Key Enabler of Neural Network Equalizers in Coherent Optical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.12689.pdf)
>  We introduce the domain adaptation and randomization approach for calibrating neural network-based equalizers for real transmissions, using synthetic data. The approach renders up to 99\% training process reduction, which we demonstrate in three experimental setups.      
### 13.A deep learning approach for direction of arrival estimation using automotive-grade ultrasonic sensors  [ :arrow_down: ](https://arxiv.org/pdf/2202.12684.pdf)
>  In this paper, a deep learning approach is presented for direction of arrival estimation using automotive-grade ultrasonic sensors which are used for driving assistance systems such as automatic parking. A study and implementation of the state of the art deterministic direction of arrival estimation algorithms is used as a benchmark for the performance of the proposed approach. Analysis of the performance of the proposed algorithms against the existing algorithms is carried out over simulation data as well as data from a measurement campaign done using automotive-grade ultrasonic sensors. Both sets of results clearly show the superiority of the proposed approach under realistic conditions such as noise from the environment as well as eventual errors in measurements. It is demonstrated as well how the proposed approach can overcome some of the known limitations of the existing algorithms such as precision dilution of triangulation and aliasing.      
### 14.Harmonic gated compensation network plus for ICASSP 2022 DNS CHALLENGE  [ :arrow_down: ](https://arxiv.org/pdf/2202.12643.pdf)
>  The harmonic structure of speech is resistant to noise, but the harmonics may still be partially masked by noise. Therefore, we previously proposed a harmonic gated compensation network (HGCN) to predict the full harmonic locations based on the unmasked harmonics and process the result of a coarse enhancement module to recover the masked harmonics. In addition, the auditory loudness loss function is used to train the network. For the DNS Challenge, we update HGCN with the following aspects, resulting in HGCN+. First, a high-band module is employed to help the model handle full-band signals. Second, cosine is used to model the harmonic structure more accurately. Then, the dual-path encoder and dual-path rnn (DPRNN) are introduced to take full advantage of the features. Finally, a gated residual linear structure replaces the gated convolution in the compensation module to increase the receptive field of frequency. The experimental results show that each updated module brings performance improvement to the model. HGCN+ also outperforms the referenced models on both wide-band and full-band test sets.      
### 15.Goal-Oriented Communication for Edge Learning based on the Information Bottleneck  [ :arrow_down: ](https://arxiv.org/pdf/2202.12639.pdf)
>  Whenever communication takes place to fulfil a goal, an effective way to encode the source data to be transmitted is to use an encoding rule that allows the receiver to meet the requirements of the goal. A formal way to identify the relevant information with respect to a goal can be obtained exploiting the information bottleneck (IB) principle. In this paper, we propose a goal-oriented communication system, based on the combination of IB and stochastic optimization. The IB principle is used to design the encoder in order to find an optimal balance between representation complexity and relevance of the encoded data with respect to the goal. Stochastic optimization is then used to adapt the parameters of the IB to find an efficient resource allocation of communication and computation resources. Our goal is to minimize the average energy consumption under constraints on average service delay and accuracy of the learning task applied to the received data in a dynamic scenario. Numerical results assess the performance of the proposed strategy in two cases: regression from Gaussian random variables, where we can exploit closed-form solutions, and image classification using deep neural networks, with adaptive network splitting between transmit and receive sides.      
### 16.Predicting 4D Liver MRI for MR-guided Interventions  [ :arrow_down: ](https://arxiv.org/pdf/2202.12628.pdf)
>  Organ motion poses an unresolved challenge in image-guided interventions. In the pursuit of solving this problem, the research field of time-resolved volumetric magnetic resonance imaging (4D MRI) has evolved. However, current techniques are unsuitable for most interventional settings because they lack sufficient temporal and/or spatial resolution or have long acquisition times. In this work, we propose a novel approach for real-time, high-resolution 4D MRI with large fields of view for MR-guided interventions. To this end, we trained a convolutional neural network (CNN) end-to-end to predict a 3D liver MRI that correctly predicts the liver's respiratory state from a live 2D navigator MRI of a subject. Our method can be used in two ways: First, it can reconstruct near real-time 4D MRI with high quality and high resolution (209x128x128 matrix size with isotropic 1.8mm voxel size and 0.6s/volume) given a dynamic interventional 2D navigator slice for guidance during an intervention. Second, it can be used for retrospective 4D reconstruction with a temporal resolution of below 0.2s/volume for motion analysis and use in radiation therapy. We report a mean target registration error (TRE) of 1.19 $\pm$0.74mm, which is below voxel size. We compare our results with a state-of-the-art retrospective 4D MRI reconstruction. Visual evaluation shows comparable quality. We show that small training sizes with short acquisition times down to 2min can already achieve promising results and 24min are sufficient for high quality results. Because our method can be readily combined with earlier methods, acquisition time can be further decreased while also limiting quality loss. We show that an end-to-end, deep learning formulation is highly promising for 4D MRI reconstruction.      
### 17.Local Intensity Order Transformation for Robust Curvilinear Object Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2202.12587.pdf)
>  Segmentation of curvilinear structures is important in many applications, such as retinal blood vessel segmentation for early detection of vessel diseases and pavement crack segmentation for road condition evaluation and maintenance. Currently, deep learning-based methods have achieved impressive performance on these tasks. Yet, most of them mainly focus on finding powerful deep architectures but ignore capturing the inherent curvilinear structure feature (e.g., the curvilinear structure is darker than the context) for a more robust representation. In consequence, the performance usually drops a lot on cross-datasets, which poses great challenges in practice. In this paper, we aim to improve the generalizability by introducing a novel local intensity order transformation (LIOT). Specifically, we transfer a gray-scale image into a contrast-invariant four-channel image based on the intensity order between each pixel and its nearby pixels along with the four (horizontal and vertical) directions. This results in a representation that preserves the inherent characteristic of the curvilinear structure while being robust to contrast changes. Cross-dataset evaluation on three retinal blood vessel segmentation datasets demonstrates that LIOT improves the generalizability of some state-of-the-art methods. Additionally, the cross-dataset evaluation between retinal blood vessel segmentation and pavement crack segmentation shows that LIOT is able to preserve the inherent characteristic of curvilinear structure with large appearance gaps. An implementation of the proposed method is available at <a class="link-external link-https" href="https://github.com/TY-Shi/LIOT" rel="external noopener nofollow">this https URL</a>.      
### 18.Model Predictive Control with Preview: Recursive Feasibility and Stability  [ :arrow_down: ](https://arxiv.org/pdf/2202.12585.pdf)
>  This paper proposes a stabilising model predictive control (MPC) scheme with preview information of disturbance for nonlinear systems. The proposed MPC algorithm is able to not only reject disturbance by making use of disturbance preview information as necessary, but also take advantage of the disturbance if it is good for a control task. This is realised by taking into account both the task (e.g. reference trajectory) and disturbance preview in the prediction horizon when performing online optimisation. Conditions are established to ensure recursive feasibility and stability under the disturbance. First the disturbance within the horizon is augmented with the state to form a new composite system and then the stage cost function is modified accordingly. With the help of input-to-state stability theory, a terminal cost and a terminal constraint are constructed and added to the MPC algorithm with preview to guarantee its recursive feasibility and stability under a pre-bounded disturbance. Numerical simulation results demonstrate the effectiveness of the proposed MPC algorithm.      
### 19.Beyond Bjøntegaard: Limits of Video Compression Performance Comparisons  [ :arrow_down: ](https://arxiv.org/pdf/2202.12565.pdf)
>  For 20 years, the gold standard to evaluate the performance of video codecs is to calculate average differences between ratedistortion curves, also called the "Bjøntegaard Delta". With the help of this tool, the compression performance of codecs can be compared. In the past years, we could observe that the calculus was also deployed for other metrics than bitrate and distortion in terms of peak signal-to-noise ratio, for example other quality metrics such as video multi-method assessment fusion or hardware-dependent metrics such as the decoding energy. However, it is unclear whether the Bjøntegaard Delta is a valid way to evaluate these metrics. To this end, this paper reviews several interpolation methods and evaluates their accuracy using different performancemetrics. As a result, we propose to use a novel approach based on Akima interpolation, which returns the most accurate results for a large variety of performance metrics. The approximation accuracy of this new method is determined to be below a bound of 1.5%.      
### 20.An Ensemble Approach for Patient Prognosis of Head and Neck Tumor Using Multimodal Data  [ :arrow_down: ](https://arxiv.org/pdf/2202.12537.pdf)
>  Accurate prognosis of a tumor can help doctors provide a proper course of treatment and, therefore, save the lives of many. Traditional machine learning algorithms have been eminently useful in crafting prognostic models in the last few decades. Recently, deep learning algorithms have shown significant improvement when developing diagnosis and prognosis solutions to different healthcare problems. However, most of these solutions rely solely on either imaging or clinical data. Utilizing patient tabular data such as demographics and patient medical history alongside imaging data in a multimodal approach to solve a prognosis task has started to gain more interest recently and has the potential to create more accurate solutions. The main issue when using clinical and imaging data to train a deep learning model is to decide on how to combine the information from these sources. We propose a multimodal network that ensembles deep multi-task logistic regression (MTLR), Cox proportional hazard (CoxPH) and CNN models to predict prognostic outcomes for patients with head and neck tumors using patients' clinical and imaging (CT and PET) data. Features from CT and PET scans are fused and then combined with patients' electronic health records for the prediction. The proposed model is trained and tested on 224 and 101 patient records respectively. Experimental results show that our proposed ensemble solution achieves a C-index of 0.72 on The HECKTOR test set that saved us the first place in prognosis task of the HECKTOR challenge. The full implementation based on PyTorch is available on \url{<a class="link-external link-https" href="https://github.com/numanai/BioMedIA-Hecktor2021" rel="external noopener nofollow">this https URL</a>}.      
### 21.Faithful learning with sure data for lung nodule diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2202.12515.pdf)
>  Recent evolution in deep learning has proven its value for CT-based lung nodule classification. Most current techniques are intrinsically black-box systems, suffering from two generalizability issues in clinical practice. First, benign-malignant discrimination is often assessed by human observers without pathologic diagnoses at the nodule level. We termed these data as "unsure data". Second, a classifier does not necessarily acquire reliable nodule features for stable learning and robust prediction with patch-level labels during learning. In this study, we construct a sure dataset with pathologically-confirmed labels and propose a collaborative learning framework to facilitate sure nodule classification by integrating unsure data knowledge through nodule segmentation and malignancy score regression. A loss function is designed to learn reliable features by introducing interpretability constraints regulated with nodule segmentation maps. Furthermore, based on model inference results that reflect the understanding from both machine and experts, we explore a new nodule analysis method for similar historical nodule retrieval and interpretable diagnosis. Detailed experimental results demonstrate that our approach is beneficial for achieving improved performance coupled with faithful model reasoning for lung cancer prediction. Extensive cross-evaluation results further illustrate the effect of unsure data for deep-learning-based methods in lung nodule classification.      
### 22.NOMA Channel Estimation and Signal Detection using Rotational Invariant Codes and Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.12514.pdf)
>  This paper studies the joint channel estimation and signal detection for the uplink power domain non-orthogonal multiple access. The proposed technique performs both detection and estimation without the need of pilot symbols by using a clustering technique. To remove the effect of channel fading, we apply rotational invariant coding to assist signal detection at receiver without sending pilots. We utilize Gaussian mixture model (GMM) to cluster received signals without supervision and optimize decision boundaries to enhance the bit error rate (BER) performance.      
### 23.Monogenic Wavelet Scattering Network for Texture Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2202.12491.pdf)
>  The scattering transform network (STN), which has a similar structure as that of a popular convolutional neural network except its use of predefined convolution filters and a small number of layers, can generates a robust representation of an input signal relative to small deformations. We propose a novel Monogenic Wavelet Scattering Network (MWSN) for 2D texture image classification through a cascade of monogenic wavelet filtering with nonlinear modulus and averaging operators by replacing the 2D Morlet wavelet filtering in the standard STN. Our MWSN can extract useful hierarchical and directional features with interpretable coefficients, which can be further compressed by PCA and fed into a classifier. Using the CUReT texture image database, we demonstrate the superior performance of our MWSN over the standard STN. This performance improvement can be explained by the natural extension of 1D analyticity to 2D monogenicity.      
### 24.Structure-aware Unsupervised Tagged-to-Cine MRI Synthesis with Self Disentanglement  [ :arrow_down: ](https://arxiv.org/pdf/2202.12474.pdf)
>  Cycle reconstruction regularized adversarial training -- e.g., CycleGAN, DiscoGAN, and DualGAN -- has been widely used for image style transfer with unpaired training data. Several recent works, however, have shown that local distortions are frequent, and structural consistency cannot be guaranteed. Targeting this issue, prior works usually relied on additional segmentation or consistent feature extraction steps that are task-specific. To counter this, this work aims to learn a general add-on structural feature extractor, by explicitly enforcing the structural alignment between an input and its synthesized image. Specifically, we propose a novel input-output image patches self-training scheme to achieve a disentanglement of underlying anatomical structures and imaging modalities. The translator and structure encoder are updated, following an alternating training protocol. In addition, the information w.r.t. imaging modality can be eliminated with an asymmetric adversarial game. We train, validate, and test our network on 1,768, 416, and 1,560 unpaired subject-independent slices of tagged and cine magnetic resonance imaging from a total of twenty healthy subjects, respectively, demonstrating superior performance over competing methods.      
### 25.MetaRadar: Multi-target Detection for Reconfigurable Intelligent Surface Aided Radar Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.12473.pdf)
>  As a widely used localization and sensing technique, radars will play an important role in future wireless networks. However, the wireless channels between the radar and the targets are passively adopted by traditional radars, which limits the performance of target detection. To address this issue, we propose to use the reconfigurable intelligent surface (RIS) to improve the detection accuracy of radar systems due to its capability to customize channel conditions by adjusting its phase shifts, which is referred to as MetaRadar. In such a system, it is challenging to jointly optimize both radar waveforms and RIS phase shifts in order to improve the multi-target detection performance. To tackle this challenge, we design a waveform and phase shift optimization (WPSO) algorithm to effectively solve the multi-target detection problem, and also analyze the performance of the proposed MetaRadar scheme theoretically. Simulation results show that the detection performance of the MetaRadar scheme is significantly better than that of the traditional radar schemes.      
### 26.Koopman Spectral Analysis of Intermittent Dynamics in Complex Systems: A Case Study in Pathophysiological Processes of Obstructive Sleep Apnea  [ :arrow_down: ](https://arxiv.org/pdf/2202.12430.pdf)
>  Complex systems, such as pathophysiological processes, commonly exhibit chaotic, nonlinear, and intermittent phenomena. Koopman operator theory and Hankel alternative view of Koopman (HAVOK) model have been widely used to decompose the chaos of the complex system dynamics into an intermittent forced linear system. Although the statistics of the intermittent forcing have been proposed to characterize intermittencies in the HAVOK model, they were not adequate to attribute for the mode switching of nonlinear dynamics and the fat-tailed non-Gaussian distribution originated from high-frequency bursts and rarely-observed intermittent forcing. The paper proposed a new intermittency dynamics analysis approach to characterize the intermittent phases, chaotic bursts, and local spectral-temporal properties of various intermittent dynamics modes using spectral decomposition and wavelet analysis. To validate our methods, the intermittency behavior of apneic events in obstructive sleep apnea disorder was selected as the case, in which heart rate variability (HRV) features were extracted. Next, we constructed the Hankel matrix from the HRV features and obtained the last eigen time-delay coordinate by singular value decomposition of the Hankel matrix, which was modeled as an intermittent forcing input. The statistics of the forcing in OSA demonstrated the fat-tailed distribution of the intermittent forcing, which correspond to the intermittency of the underlying OSA pathophysiological process. The pooled means and standard deviations of the burst duration and the inter-burst duration across OSA patients were also calculated to be minutes and minutes. Scalogram amplitude and spectral decomposition of the wavelet transform exhibited various predominant frequencies and dynamics modes associated with apneic events.      
### 27.Applying Polynomial Decoupling Methods to the Polynomial NARX Model  [ :arrow_down: ](https://arxiv.org/pdf/2202.12423.pdf)
>  System identification uses measurements of a dynamic system's input and output to reconstruct a mathematical model for that system. These can be mechanical, electrical, physiological, among others. Since most of the systems around us exhibit some form of nonlinear behavior, nonlinear system identification techniques are the tools that will help us gain a better understanding of our surroundings and potentially let us improve their performance. One model that is often used to represent nonlinear systems is the polynomial NARX model, an equation error model where the output is a polynomial function of the past inputs and outputs. That said, a major disadvantage with the polynomial NARX model is that the number of parameters increases rapidly with increasing polynomial order. Furthermore, the polynomial NARX model is a black-box model, and is therefore difficult to interpret. This paper discusses a decoupling algorithm for the polynomial NARX model that substitutes the multivariate polynomial with a transformation matrix followed by a bank of univariate polynomials. This decreases the number of model parameters significantly and also imposes structure on the black-box NARX model. Since a non-convex optimization is required for this identification technique, initialization is an important factor to consider. In this paper the decoupling algorithm is developed in conjunction with several different initialization techniques. The resulting algorithms are applied to two nonlinear benchmark problems: measurement data from the Silver-Box and simulation data from the Bouc-Wen friction model, and the performance is evaluated for different validation signals in both simulation and prediction.      
### 28.Microgrid Day-Ahead Scheduling Considering Neural Network based Battery Degradation Model  [ :arrow_down: ](https://arxiv.org/pdf/2202.12416.pdf)
>  Battery energy storage system (BESS) can effectively mitigate the uncertainty of variable renewable generation. Degradation is un-preventable for batteries such as the most popular Lithium-ion battery (LiB). The main causes of LiB degradation are loss of Li-ions, loss of electrolyte, and increase of internal resistance which are hard to model and predict. In this paper, we propose a data driven method to predict the battery degradation per a given scheduled battery operational profile. Particularly, a neural net-work based battery degradation (NNBD) model is proposed to quantify the battery degradation with inputs of major battery degradation factors. When incorporating the proposed NNBD model into microgrid day-ahead scheduling (MDS), we can estab-lish a battery degradation based MDS (BDMDS) model that can consider the equivalent battery degradation cost precisely. Since the proposed NNBD model is highly non-linear and non-convex, BDMDS would be very hard to solve. To address this issue, a neural network and optimization decoupled heuristic (NNODH) algorithm is proposed in this paper to effectively solve this neural network embedded optimization problem. Simulation results demonstrate that the proposed NNODH algorithm is able to ob-tain the optimal solution with lowest total cost including normal operation cost and battery degradation cost.      
### 29.PRNU Emphasis: a Generalization of the Multiplicative Model  [ :arrow_down: ](https://arxiv.org/pdf/2202.12357.pdf)
>  The photoresponse non-uniformity (PRNU) is a camera-specific pattern, widely adopted to solve multimedia forensics problems such as device identification or forgery detection. The theoretical analysis of this fingerprint customarily relies on a multiplicative model for the denoising residuals. This setup assumes that the nonlinear mapping from the scene irradiance to the preprocessed luminance, that is, the composition of the Camera Response Function (CRF) with the optical and digital preprocessing pipelines, is a gamma correction. Yet, this assumption seldom holds in practice. In this letter, we improve the multiplicative model by including the influence of this nonlinear mapping on the denoising residuals. We also propose a method to estimate this effect. Results evidence that the response of typical cameras deviates from a gamma correction. Experimental device identification with our model increases the TPR by a $4.93\, \%$ on average for a fixed FPR of $0.01$.      
### 30.openFEAT: Improving Speaker Identification by Open-set Few-shot Embedding Adaptation with Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2202.12349.pdf)
>  Household speaker identification with few enrollment utterances is an important yet challenging problem, especially when household members share similar voice characteristics and room acoustics. A common embedding space learned from a large number of speakers is not universally applicable for the optimal identification of every speaker in a household. In this work, we first formulate household speaker identification as a few-shot open-set recognition task and then propose a novel embedding adaptation framework to adapt speaker representations from the given universal embedding space to a household-specific embedding space using a set-to-set function, yielding better household speaker identification performance. With our algorithm, Open-set Few-shot Embedding Adaptation with Transformer (openFEAT), we observe that the speaker identification equal error rate (IEER) on simulated households with 2 to 7 hard-to-discriminate speakers is reduced by 23% to 31% relative.      
### 31.Time Efficient Training of Progressive Generative Adversarial Network using Depthwise Separable Convolution and Super Resolution Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2202.12337.pdf)
>  Generative Adversarial Networks have been employed successfully to generate high-resolution augmented images of size 1024^2. Although the augmented images generated are unprecedented, the training time of the model is exceptionally high. Conventional GAN requires training of both Discriminator as well as the Generator. In Progressive GAN, which is the current state-of-the-art GAN for image augmentation, instead of training the GAN all at once, a new concept of progressing growing of Discriminator and Generator simultaneously, was proposed. Although the lower stages such as 4x4 and 8x8 train rather quickly, the later stages consume a tremendous amount of time which could take days to finish the model training. In our paper, we propose a novel pipeline that combines Progressive GAN with slight modifications and Super Resolution GAN. Super Resolution GAN up samples low-resolution images to high-resolution images which can prove to be a useful resource to reduce the training time exponentially.      
### 32.Towards Better Meta-Initialization with Task Augmentation for Kindergarten-aged Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2202.12326.pdf)
>  Children's automatic speech recognition (ASR) is always difficult due to, in part, the data scarcity problem, especially for kindergarten-aged kids. When data are scarce, the model might overfit to the training data, and hence good starting points for training are essential. Recently, meta-learning was proposed to learn model initialization (MI) for ASR tasks of different languages. This method leads to good performance when the model is adapted to an unseen language. However, MI is vulnerable to overfitting on training tasks (learner overfitting). It is also unknown whether MI generalizes to other low-resource tasks. In this paper, we validate the effectiveness of MI in children's ASR and attempt to alleviate the problem of learner overfitting. To achieve model-agnostic meta-learning (MAML), we regard children's speech at each age as a different task. In terms of learner overfitting, we propose a task-level augmentation method by simulating new ages using frequency warping techniques. Detailed experiments are conducted to show the impact of task augmentation on each age for kindergarten-aged speech. As a result, our approach achieves a relative word error rate (WER) improvement of 51% over the baseline system with no augmentation or initialization.      
### 33.From Low to High Order Motion Planners: Safe Robot Navigation using Motion Prediction and Reference Governor  [ :arrow_down: ](https://arxiv.org/pdf/2202.12816.pdf)
>  Safe navigation around obstacles is a fundamental challenge for highly dynamic robots. The state-of-the-art approach for adapting simple reference path planners to complex robot dynamics using trajectory optimization and tracking control is brittle and requires significant replanning cycles. In this paper, we introduce a novel feedback motion planning framework that extends the applicability of low-order (e.g. position-/velocity-controlled) reference motion planners to high-order (e.g., acceleration-/jerk-controlled) robot models using motion prediction and reference governors. We use predicted robot motion range for safety assessment and establish a bidirectional interface between high-level planning and low-level control via a reference governor. We describe the generic fundamental building blocks of our feedback motion planning framework and give specific example constructions for motion control, prediction, and reference planning. We prove the correctness of our planning framework and demonstrate its performance in numerical simulations. We conclude that accurate motion prediction is crucial for closing the gap between high-level planning and low-level control.      
### 34.Deep learning-assisted imaging through stationary scattering media  [ :arrow_down: ](https://arxiv.org/pdf/2202.12806.pdf)
>  Imaging through scattering media is a challenging problem owing to speckle decorrelations from perturbations in the media itself. For in-line imaging modalities, which are appealing because they are compact, require no moving parts, and are robust, negating the effects of such scattering becomes particularly challenging. Here we explore the effect of stationary scattering media on light scattering in in-line geometries, including digital holographic microscopy. We consider various object-scatterer scenarios where the object is distorted or obscured by additional stationary scatterers, and use an advanced deep learning (DL) generative methodology, generative adversarial networks (GANs), to mitigate the effects of the additional scatterers. Using light scattering simulations and experiments on objects of interest with and without additional scatterers, we find that conditional GANs can be quickly trained with minuscule datasets and can also efficiently learn the one-to-one statistical mapping between the cross-domain input-output image pairs. Training such a network yields a standalone model, that can be used later to inverse or negate the effect of scattering, yielding clear object reconstructions for object retrieval and downstream processing. Moreover, it is well-known that the coherent point spread function (c-PSF) of a stationary scattering optical system is a speckle pattern which is spatially shift variant. We show that with rapid training using only 20 image pairs, it is possible to negate this undesired scattering to accurately localize diffraction-limited impulses with high spatial accuracy, therefore transforming the earlier shift variant system to a linear shift invariant (LSI) system.      
### 35.Probabilistic Data Association for Semantic SLAM at Scale  [ :arrow_down: ](https://arxiv.org/pdf/2202.12802.pdf)
>  With advances in image processing and machine learning, it is now feasible to incorporate semantic information into the problem of simultaneous localisation and mapping (SLAM). Previously, SLAM was carried out using lower level geometric features (points, lines, and planes) which are often view-point dependent and error prone in visually repetitive environments. Semantic information can improve the ability to recognise previously visited locations, as well as maintain sparser maps for long term SLAM applications. However, SLAM in repetitive environments has the critical problem of assigning measurements to the landmarks which generated them. In this paper, we use k-best assignment enumeration to compute marginal assignment probabilities for each measurement landmark pair, in real time. We present numerical studies on the KITTI dataset to demonstrate the effectiveness and speed of the proposed framework.      
### 36.Behaviorally Grounded Model-Based and Model Free Cost Reduction in a Simulated Multi-Echelon Supply Chain  [ :arrow_down: ](https://arxiv.org/pdf/2202.12786.pdf)
>  Amplification and phase shift in ordering signals, commonly referred to as bullwhip, are responsible for both excessive strain on real world inventory management systems, stock outs, and unnecessary capital reservation though safety stock building. Bullwhip is a classic, yet persisting, problem with reverberating consequences in inventory management. Research on bullwhip has consistently emphasized behavioral influences for this phenomenon and leveraged behavioral ordering models to suggest interventions. However more recent model-free approaches have also seen success. In this work, the author develops algorithmic approaches towards mitigating bullwhip using both behaviorally grounded model-based approaches alongside a model-free dual deep Q-network reinforcement learning approach. In addition to exploring the utility of this specific model-free architecture to multi-echelon supply chains with imperfect information sharing and information delays, the author directly compares the performance of these model-based and model-free approaches. In doing so, this work highlights both the insights gained from exploring model-based approaches in the context of prior behavioral operations management literature and emphasizes the complementary nature of model-based and model-free approaches in approaching behaviorally grounded supply chain management problems.      
### 37.Ask2Mask: Guided Data Selection for Masked Speech Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2202.12719.pdf)
>  Masked speech modeling (MSM) methods such as wav2vec2 or w2v-BERT learn representations over speech frames which are randomly masked within an utterance. While these methods improve performance of Automatic Speech Recognition (ASR) systems, they have one major limitation. They treat all unsupervised speech samples with equal weight, which hinders learning as not all samples have relevant information to learn meaningful representations. In this work, we address this limitation. We propose ask2mask (ATM), a novel approach to focus on specific samples during MSM pre-training. ATM employs an external ASR model or \textit{scorer} to weight unsupervised input samples in two different ways: 1) A fine-grained data selection is performed by masking over the highly confident input frames as chosen by the scorer. This allows the model to learn meaningful representations. 2) ATM is further extended to focus at utterance-level by weighting the final MSM loss with the utterance-level confidence score. We conduct fine-tuning experiments on two well-benchmarked corpora: LibriSpeech (matching the pre-training data) and Commonvoice, TED-LIUM, AMI and CHiME-6 (not matching the pre-training data). The results substantiate the efficacy of ATM on significantly improving the recognition performance under mismatched conditions (up to 11.6\% relative over published results and upto 4.46\% relative over our internal baseline) while still yielding modest improvements under matched conditions.      
### 38.Early Disease Stage Characterization in Parkinson's Disease from Resting-state fMRI Data Using a Long Short-term Memory Network  [ :arrow_down: ](https://arxiv.org/pdf/2202.12715.pdf)
>  Parkinson's disease (PD) is a common and complex neurodegenerative disorder with 5 stages in the Hoehn and Yahr scaling. Given the heterogeneity of PD, it is challenging to classify early stages 1 and 2 and detect brain function alterations. Functional magnetic resonance imaging (fMRI) is a promising tool in revealing functional connectivity (FC) differences and developing biomarkers in PD. Some machine learning approaches like support vector machine and logistic regression have been successfully applied in the early diagnosis of PD using fMRI data, which outperform classifiers based on manually selected morphological features. However, the early-stage characterization in FC changes has not been fully investigated. Given the complexity and non-linearity of fMRI data, we propose the use of a long short-term memory (LSTM) network to characterize the early stages of PD. The study included 84 subjects (56 in stage 2 and 28 in stage 1) from the Parkinson's Progression Markers Initiative (PPMI), the largest available public PD dataset. Under a repeated 10-fold stratified cross-validation, the LSTM model reached an accuracy of 71.63%, 13.52% higher than the best traditional machine learning method, indicating significantly better robustness and accuracy compared with other machine learning classifiers. We used the learned LSTM model weights to select the top brain regions that contributed to model prediction and performed FC analyses to characterize functional changes with disease stage and motor impairment to gain better insight into the brain mechanisms of PD.      
### 39.Reconstruction of Perceived Images from fMRI Patterns and Semantic Brain Exploration using Instance-Conditioned GANs  [ :arrow_down: ](https://arxiv.org/pdf/2202.12692.pdf)
>  Reconstructing perceived natural images from fMRI signals is one of the most engaging topics of neural decoding research. Prior studies had success in reconstructing either the low-level image features or the semantic/high-level aspects, but rarely both. In this study, we utilized an Instance-Conditioned GAN (IC-GAN) model to reconstruct images from fMRI patterns with both accurate semantic attributes and preserved low-level details. The IC-GAN model takes as input a 119-dim noise vector and a 2048-dim instance feature vector extracted from a target image via a self-supervised learning model (SwAV ResNet-50); these instance features act as a conditioning for IC-GAN image generation, while the noise vector introduces variability between samples. We trained ridge regression models to predict instance features, noise vectors, and dense vectors (the output of the first dense layer of the IC-GAN generator) of stimuli from corresponding fMRI patterns. Then, we used the IC-GAN generator to reconstruct novel test images based on these fMRI-predicted variables. The generated images presented state-of-the-art results in terms of capturing the semantic attributes of the original test images while remaining relatively faithful to low-level image details. Finally, we use the learned regression model and the IC-GAN generator to systematically explore and visualize the semantic features that maximally drive each of several regions-of-interest in the human brain.      
### 40.Bridging the Urban-Rural Connectivity Gap through Intelligent Space, Air, and Ground Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.12683.pdf)
>  Connectivity in rural areas is one of the main challenges of communication networks. To overcome this challenge, a variety of solutions for different situations are required. Optimizing the current networking paradigms is therefore mandatory. The high costs of infrastructure and the low revenue of cell sites in rural areas compared with urban areas are especially unattractive for telecommunication operators. Therefore, space, air, and ground networks should all be optimized for achieving connectivity in rural areas. We highlight the latest works on rural connectivity, discuss the solutions for terrestrial networks, and study the potential benefits of nonterrestrial networks. Furthermore, we present an overview of artificial intelligence (AI) techniques for improving space, air, and ground networks, hence improving connectivity in rural areas. AI enables intelligent communications and can integrate space, air, and ground networks for rural connectivity. We discuss the rural connectivity challenges and highlight the latest projects and research and the empowerment of networks using AI. Finally, we discuss the potential positive impacts of providing connectivity to rural communities.      
### 41.Time-coded Spiking Fourier Transform in Neuromorphic Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2202.12650.pdf)
>  After several decades of continuously optimizing computing systems, the Moore's law is reaching itsend. However, there is an increasing demand for fast and efficient processing systems that can handlelarge streams of data while decreasing system footprints. Neuromorphic computing answers thisneed by creating decentralized architectures that communicate with binary events over time. Despiteits rapid growth in the last few years, novel algorithms are needed that can leverage the potential ofthis emerging computing paradigm and can stimulate the design of advanced neuromorphic <a class="link-external link-http" href="http://chips.In" rel="external noopener nofollow">this http URL</a> this work, we propose a time-based spiking neural network that is mathematically equivalent tothe Fourier transform. We implemented the network in the neuromorphic chip Loihi and conductedexperiments on five different real scenarios with an automotive frequency modulated continuouswave radar. Experimental results validate the algorithm, and we hope they prompt the design of adhoc neuromorphic chips that can improve the efficiency of state-of-the-art digital signal processorsand encourage research on neuromorphic computing for signal processing.      
### 42.LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras with Negative Plane  [ :arrow_down: ](https://arxiv.org/pdf/2202.12613.pdf)
>  Visual-inertial-odometry has attracted extensive attention in the field of autonomous driving and robotics. The size of Field of View (FoV) plays an important role in Visual-Odometry (VO) and Visual-Inertial-Odometry (VIO), as a large FoV enables to perceive a wide range of surrounding scene elements and features. However, when the field of the camera reaches the negative half plane, one cannot simply use [u,v,1]^T to represent the image feature points anymore. To tackle this issue, we propose LF-VIO, a real-time VIO framework for cameras with extremely large FoV. We leverage a three-dimensional vector with unit length to represent feature points, and design a series of algorithms to overcome this challenge. To address the scarcity of panoramic visual odometry datasets with ground-truth location and pose, we present the PALVIO dataset, collected with a Panoramic Annular Lens (PAL) system with an entire FoV of 360x(40-120) degrees and an IMU sensor. With a comprehensive variety of experiments, the proposed LF-VIO is verified on both the established PALVIO benchmark and a public fisheye camera dataset with a FoV of 360x(0-93.5) degrees. LF-VIO outperforms state-of-the-art visual-inertial-odometry methods. Our dataset and code are made publicly available at <a class="link-external link-https" href="https://github.com/flysoaryun/LF-VIO" rel="external noopener nofollow">this https URL</a>      
### 43.Phase Object Reconstruction for 4D-STEM using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.12611.pdf)
>  In this study we explore the possibility to use deep learning for the reconstruction of phase images from 4D scanning transmission electron microscopy (4D-STEM) data. The process can be divided into two main steps. First, the complex electron wave function is recovered for a convergent beam electron diffraction pattern (CBED) using a convolutional neural network (CNN). Subsequently a corresponding patch of the phase object is recovered using the phase object approximation (POA). Repeating this for each scan position in a 4D-STEM dataset and combining the patches by complex summation yields the full phase object. Each patch is recovered from a kernel of 3x3 adjacent CBEDs only, which eliminates common, large memory requirements and enables live processing during an experiment. The machine learning pipeline, data generation and the reconstruction algorithm are presented. We demonstrate that the CNN can retrieve phase information beyond the aperture angle, enabling super-resolution imaging. The image contrast formation is evaluated showing a dependence on thickness and atomic column type. Columns containing light and heavy elements can be imaged simultaneously and are distinguishable. The combination of super-resolution, good noise robustness and intuitive image contrast characteristics makes the approach unique among live imaging methods in 4D-STEM.      
### 44.Bridging the Gap Between Patient-specific and Patient-independent Seizure Prediction via Knowledge Distillation  [ :arrow_down: ](https://arxiv.org/pdf/2202.12598.pdf)
>  Objective. Deep neural networks (DNN) have shown unprecedented success in various brain-machine interface (BCI) applications such as epileptic seizure prediction. However, existing approaches typically train models in a patient-specific fashion due to the highly personalized characteristics of epileptic signals. Therefore, only a limited number of labeled recordings from each subject can be used for training. As a consequence, current DNN based methods demonstrate poor generalization ability to some extent due to the insufficiency of training data. On the other hand, patient-independent models attempt to utilize more patient data to train a universal model for all patients by pooling patient data together. Despite different techniques applied, results show that patient-independent models perform worse than patient-specific models due to high individual variation across patients. A substantial gap thus exists between patient-specific and patient-independent models. In this paper, we propose a novel training scheme based on knowledge distillation which makes use of a large amount of data from multiple subjects. It first distills informative features from signals of all available subjects with a pre-trained general model. A patient-specific model can then be obtained with the help of distilled knowledge and additional personalized data. Significance. The proposed training scheme significantly improves the performance of patient-specific seizure predictors and bridges the gap between patient-specific and patient-independent predictors. Five state-of-the-art seizure prediction methods are trained on the CHB-MIT sEEG database with our proposed scheme. The resulting accuracy, sensitivity, and false prediction rate show that our proposed training scheme consistently improves the prediction performance of state-of-the-art methods by a large margin.      
### 45.A Blockchain-Based Consent Mechanism for Access to Fitness Data in the Healthcare Context  [ :arrow_down: ](https://arxiv.org/pdf/2202.12582.pdf)
>  Wearable fitness devices are widely used to track an individual's health and physical activities to improve the quality of health services. These devices sense a considerable amount of sensitive data processed by a centralized third party. While many researchers have thoroughly evaluated privacy issues surrounding wearable fitness trackers, no study has addressed privacy issues in trackers by giving control of the data to the user. Blockchain is an emerging technology with outstanding advantages in resolving consent management privacy concerns. As there are no fully transparent, legally compliant solutions for sharing personal fitness data, this study introduces an architecture for a human-centric, legally compliant, decentralized and dynamic consent system based on blockchain and smart contracts. Algorithms and sequence diagrams of the proposed system's activities show consent-related data flow among various agents, which are used later to prove the system's trustworthiness by formalizing the security requirements. The security properties of the proposed system were evaluated using the formal security modeling framework SeMF, which demonstrates the feasibility of the solution at an abstract level based on formal language theory. As a result, we have empirically proven that blockchain technology is suitable for mitigating the privacy issues of fitness providers by recording individuals' consent using blockchain and smart contracts.      
### 46.A Survey of Multilingual Models for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2202.12576.pdf)
>  Although Automatic Speech Recognition (ASR) systems have achieved human-like performance for a few languages, the majority of the world's languages do not have usable systems due to the lack of large speech datasets to train these models. Cross-lingual transfer is an attractive solution to this problem, because low-resource languages can potentially benefit from higher-resource languages either through transfer learning, or being jointly trained in the same multilingual model. The problem of cross-lingual transfer has been well studied in ASR, however, recent advances in Self Supervised Learning are opening up avenues for unlabeled speech data to be used in multilingual ASR models, which can pave the way for improved performance on low-resource languages. In this paper, we survey the state of the art in multilingual ASR models that are built with cross-lingual transfer in mind. We present best practices for building multilingual models from research across diverse languages and techniques, discuss open questions and provide recommendations for future work.      
### 47.Oscillatory Neural Network as Hetero-Associative Memory for Image Edge Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.12541.pdf)
>  The increasing amount of data to be processed on edge devices, such as cameras, has motivated Artificial Intelligence (AI) integration at the edge. Typical image processing methods performed at the edge, such as feature extraction or edge detection, use convolutional filters that are energy, computation, and memory hungry algorithms. But edge devices and cameras have scarce computational resources, bandwidth, and power and are limited due to privacy constraints to send data over to the cloud. Thus, there is a need to process image data at the edge. Over the years, this need has incited a lot of interest in implementing neuromorphic computing at the edge. Neuromorphic systems aim to emulate the biological neural functions to achieve energy-efficient computing. Recently, Oscillatory Neural Networks (ONN) present a novel brain-inspired computing approach by emulating brain oscillations to perform autoassociative memory types of applications. To speed up image edge detection and reduce its power consumption, we perform an in-depth investigation with ONNs. We propose a novel image processing method by using ONNs as a hetero-associative memory (HAM) for image edge detection. We simulate our ONN-HAM solution using first, a Matlab emulator, and then a fully digital ONN design. We show results on gray scale square evaluation maps, also on black and white and gray scale 28x28 MNIST images and finally on black and white 512x512 standard test images. We compare our solution with standard edge detection filters such as Sobel and Canny. Finally, using the fully digital design simulation results, we report on timing and resource characteristics, and evaluate its feasibility for real-time image processing applications. Our digital ONN-HAM solution can process images with up to 120x120 pixels (166 MHz system frequency) respecting real-time camera constraints. This work is the first to explore ONNs as hetero-associative memory for image processing applications.      
### 48.Embedded Soft Sensing in Soft Ring Actuator for Aiding with theSelf-Organisation of the In-Hand Rotational Manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2202.12525.pdf)
>  This paper proposes a soft sensor embedded in a soft ring actuator with five fingers as a soft hand to identify the bifurcation of manipulated objects during the in-hand manipulation process. The manipulation is performed by breaking the symmetry method with an underactuated control system by bifurcating the object to clockwise or counter-clockwise rotations. Two soft sensors are embedded in parallel over a single soft finger, and the difference in the resistance measurements is compared when the finger is displaced or bent in a particular direction, which can identify the bifurcation direction and aid in the break of symmetry approach without the need of external tracking devices. The sensors performance is also characterised by extending and bending the finger without an object interaction. During an experiment that performs a break of symmetry, manipulated objects turn clockwise and counter-clockwise depending on the perturbation and actuation frequency, sensors can track the direction of rotation. The embedded sensors provide a self-sensing capability for implementing a closed-loop control in future work. The soft ring actuator performance presents a self-organisation behaviour with soft fingers rotating an object without a required control for rotating the object. Therefore, the soft fingers are an underactuated system with complex behaviour when interacting with objects that serve in-hand manipulation field.      
### 49.Learning ECG Representations based on Manipulated Temporal-Spatial Reverse Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.12458.pdf)
>  Learning representations from electrocardiogram (ECG) serves as a fundamental step for many downstream machine learning-based ECG analysis tasks. However, the learning process is always restricted by lack of high-quality labeled data in reality. Existing methods addressing data deficiency either cannot provide satisfied representations for downstream tasks or require too much effort to construct similar and dissimilar pairs to learn informative representations. In this paper, we propose a straightforward but effective approach to learn ECG representations. Inspired by the temporal and spatial characteristics of ECG, we flip the original signals horizontally, vertically, and both horizontally and vertically. The learning is then done by classifying the four types of signals including the original one. To verify the effectiveness of the proposed temporal-spatial (T-S) reverse detection method, we conduct a downstream task to detect atrial fibrillation (AF) which is one of the most common ECG tasks. The results show that the ECG representations learned with our method lead to remarkable performances on the downstream task. In addition, after exploring the representational feature space and investigating which parts of the ECG signal contribute to the representations, we conclude that the temporal reverse is more effective than the spatial reverse for learning ECG representations.      
### 50.Stacked Residuals of Dynamic Layers for Time Series Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.12457.pdf)
>  We present an end-to-end differentiable neural network architecture to perform anomaly detection in multivariate time series by incorporating a Sequential Probability Ratio Test on the prediction residual. The architecture is a cascade of dynamical systems designed to separate linearly predictable components of the signal such as trends and seasonality, from the non-linear ones. The former are modeled by local Linear Dynamic Layers, and their residual is fed to a generic Temporal Convolutional Network that also aggregates global statistics from different time series as context for the local predictions of each one. The last layer implements the anomaly detector, which exploits the temporal structure of the prediction residuals to detect both isolated point anomalies and set-point changes. It is based on a novel application of the classic CUMSUM algorithm, adapted through the use of a variational approximation of f-divergences. The model automatically adapts to the time scales of the observed signals. It approximates a SARIMA model at the get-go, and auto-tunes to the statistics of the signal and its covariates, without the need for supervision, as more data is observed. The resulting system, which we call STRIC, outperforms both state-of-the-art robust statistical methods and deep neural network architectures on multiple anomaly detection benchmarks.      
### 51.Gaussian Belief Trees for Chance Constrained Asymptotically Optimal Motion Planning  [ :arrow_down: ](https://arxiv.org/pdf/2202.12407.pdf)
>  In this paper, we address the problem of sampling-based motion planning under motion and measurement uncertainty with probabilistic guarantees. We generalize traditional sampling-based tree-based motion planning algorithms for deterministic systems and propose belief-$\mathcal{A}$, a framework that extends any kinodynamical tree-based planner to the belief space for linear (or linearizable) systems. We introduce appropriate sampling techniques and distance metrics for the belief space that preserve the probabilistic completeness and asymptotic optimality properties of the underlying planner. We demonstrate the efficacy of our approach for finding safe low-cost paths efficiently and asymptotically optimally in simulation, for both holonomic and non-holonomic systems.      
### 52.Fast Matching Pursuit with Multi-Gabor Dictionaries  [ :arrow_down: ](https://arxiv.org/pdf/2202.12380.pdf)
>  Finding the best K-sparse approximation of a signal in a redundant dictionary is an NP-hard problem. Suboptimal greedy matching pursuit (MP) algorithms are generally used for this task. In this work, we present an acceleration technique and an implementation of the matching pursuit algorithm acting on a multi-Gabor dictionary, i.e., a concatenation of several Gabor-type time-frequency dictionaries, each of which consisting of translations and modulations of a possibly different window and time and frequency shift parameters. The technique is based on pre-computing and thresholding inner products between atoms and on updating the residual directly in the coefficient domain, i.e., without the round-trip to the signal domain. Since the proposed acceleration technique involves an approximate update step, we provide theoretical and experimental results illustrating the convergence of the resulting algorithm. The implementation is written in C (compatible with C99 and C++11) and we also provide Matlab and GNU Octave interfaces. For some settings, the implementation is up to 70 times faster than the standard Matching Pursuit Toolkit (MPTK).      
### 53.Calderón Preconditioners for the TD-EFIE discretized with Convolution Quadratures  [ :arrow_down: ](https://arxiv.org/pdf/2202.12377.pdf)
>  This work focuses on the preconditioning and DC stabilization of the time domain electric field integral equation discretized in time with the convolution quadrature method. The standard formulation of the equation suffers from severe ill-conditioning for large time steps and refined meshes, in addition to DC instabilities plaguing standard solutions for late time steps. This work addresses all these issues by preconditioning the TD-EFIE operator matrices with a Calderón approach. Numerical results will corroborate the theory, showing the practical relevance of the proposed advancements.      
### 54.Queue-Aware STAR-RIS Assisted NOMA Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.12333.pdf)
>  In this paper, the queue-aware simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) assisted non-orthogonal multiple access (NOMA) communication system is investigated to ensure the system stability, where the long-term stability-oriented problem is reformulated to maximize the per-slot queue-weighted sum rate (QWSR) of users based on the Lyapunov drift theory. By jointly optimizing the NOMA decoding order, the active beamforming coefficients at the BS, and the passive transmission and reflection coefficients at the STAR-RIS, three STAR-RIS operating protocols are considered, namely energy splitting (ES), mode switching (MS), and time switching (TS). For ES, the blocked coordinate descent and the successive convex approximation methods are invoked to handle the highly-coupled and non-convex problem. For MS, the proposed algorithm is further extended to a penalty-based two-loop algorithm to solve the binary amplitude constrained problem. For TS, the formulated problem is decomposed into two subproblems, each of which can be solved in a similar manner to ES. Simulation results show that: i) our proposed STAR-RIS assisted NOMA communication achieves better performance than the conventional schemes; ii) the reformulated QWSR maximization problem confirms the system stability; and iii) TS achieves superior performance with respect to both the QWSR and the average queue length.      
### 55.Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph  [ :arrow_down: ](https://arxiv.org/pdf/2202.12307.pdf)
>  This paper addresses the unsupervised learning of content-style decomposed representation. We first give a definition of style and then model the content-style representation as a token-level bipartite graph. An unsupervised framework, named Retriever, is proposed to learn such representations. First, a cross-attention module is employed to retrieve permutation invariant (P.I.) information, defined as style, from the input data. Second, a vector quantization (VQ) module is used, together with man-induced constraints, to produce interpretable content tokens. Last, an innovative link attention module serves as the decoder to reconstruct data from the decomposed content and style, with the help of the linking keys. Being modal-agnostic, the proposed Retriever is evaluated in both speech and image domains. The state-of-the-art zero-shot voice conversion performance confirms the disentangling ability of our framework. Top performance is also achieved in the part discovery task for images, verifying the interpretability of our representation. In addition, the vivid part-based style transfer quality demonstrates the potential of Retriever to support various fascinating generative tasks. Project page at <a class="link-external link-https" href="https://ydcustc.github.io/retriever-demo/" rel="external noopener nofollow">this https URL</a>.      
