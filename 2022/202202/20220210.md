# ArXiv eess --Thu, 10 Feb 2022
### 1.An Experimental Proof of Concept for Integrated Sensing and Communications Waveform Design  [ :arrow_down: ](https://arxiv.org/pdf/2202.04602.pdf)
>  The integration of sensing and communication (ISAC) functionalities have recently gained significant research interest as a hardware-, power-, spectrum- and cost- efficient solution. This experimental work focuses on a dual-functional radar sensing and communication framework where a single radiation waveform, either omnidirectional or directional, can realize both radar sensing and communication functions. We study a trade-off approach that can balance the performance of communications and radar sensing. We design an orthogonal frequency division multiplexing (OFDM) based multi-user multiple input multiple output (MIMO) software-defined radio (SDR) testbed to validate the dual-functional model. We carry out over-the-air experiments to investigate the optimal trade-off factor to balance the performance for both functions. On the radar performance, we measure the output beampatterns of our transmission to examine their similarity to simulation based beampatterns. On the communication side, we obtain bit error rate (BER) results from the testbed to show the communication performance using the dual-functional waveform. Our experiment reveals that the dual-functional approach can achieve comparable BER performance with pure communication-based solutions while maintaining fine radar beampatterns simultaneously.      
### 2.Exploring Structural Sparsity in Neural Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2202.04595.pdf)
>  Neural image compression have reached or out-performed traditional methods (such as JPEG, BPG, WebP). However,their sophisticated network structures with cascaded convolution layers bring heavy computational burden for practical deployment. In this paper, we explore the structural sparsity in neural image compression network to obtain real-time acceleration without any specialized hardware design or algorithm. We propose a simple plug-in adaptive binary channel masking(ABCM) to judge the importance of each convolution channel and introduce sparsity during training. During inference, the unimportant channels are pruned to obtain slimmer network and less computation. We implement our method into three neural image compression networks with different entropy models to verify its effectiveness and generalization, the experiment results show that up to 7x computation reduction and 3x acceleration can be achieved with negligible performance drop.      
### 3.A Nonlinear Proportional Integral Disturbance Observer and Motion Control Technique for Permanent Magnet Synchronous Motors  [ :arrow_down: ](https://arxiv.org/pdf/2202.04594.pdf)
>  In this paper, we present a Nonlinear-Proportional Integrator (N-PI) disturbance observer (DOB) to enhance the motion tracking of the performance of a surface-mounted Permanent Magnet Synchronous Motor (SPMSM) in rapidly speed varying regions. By presenting an N-PI-DOB for load torque estimation with torque modulation technique, we show that the tracking error dynamics of angular position/velocity are coupled with tracking errors of currents loop and estimation errors. After analyzing disturbances of currents tracking error dynamics, we design the N-PI-DOB and Lyapunov-based nonlinear currents controller to enhance the motion tracking performances. With these N-PI-DOBs and motion controllers, we analyze the stability of motion tracking error dynamics and estimation error dynamics. We experimentally perform a comparative study with/without the N-PI-DOB to verify the effectiveness of the proposed method in the condition of the unknown load torque and rapidly speed-varying.      
### 4.Real-time decision-making for autonomous vehicles under faults  [ :arrow_down: ](https://arxiv.org/pdf/2202.04554.pdf)
>  This paper addresses the challenges of decision-making for autonomous vehicles under faults during a transport mission. A real-time decision-making problem of vehicle routing planning considering maintenance management is formulated as an optimization problem. The goal is to minimize the total time to finish the transport mission by selecting the optimal workshop to conduct the maintenance and the corresponding routes. Two methods are proposed to solve the optimization problem based on two methods of fundamental solutions: (1) Mixed Integer Programming; (2) Dijkstra's algorithm. We adapt these methods to solve the optimization problem and consider improving the computation efficiency. Numerical studies of test cases of highway and urban scenarios are presented to demonstrate the proposed methods, which show the feasibility and high computational efficiency of both methods.      
### 5.Integrated routing for a vehicle-robot pickup and delivery system with time constraints  [ :arrow_down: ](https://arxiv.org/pdf/2202.04550.pdf)
>  This paper considers an unmanned vehicle-robot pickup and delivery system, in which a self-driving vehicle carrying multiple unmanned robots in the form of the mother ship travels from a depot to a number of stations distributed in a neighborhood to perform multiple pickup and delivery services. First of all, we present it as a Multi-modal Vehicle Routing Problem (MMVRP) with time constraints, which are typical service requirements for grocery and food delivery in practice. We then formulate it as a Mixed Integer Quadratically Con-strained Program (MIQCP) model to determine the optimal integrated routing plan (vehicle routing and robot routing) to minimize the total weighted tardiness of all services. Finally, a small-size and a medium-size problem instance are solved using the Gurobi solver in Python to demonstrate the validity and the performance of the proposed MIQCP model.      
### 6.Self-Sensing Hysteresis-Type Bearingless Motor  [ :arrow_down: ](https://arxiv.org/pdf/2202.04547.pdf)
>  Bearingless motors use a single stator assembly to apply torque and magnetic suspension forces on the rotor, making these machines compact with frictionless operation and thus well suited to high-speed applications. One major challenge that prevents wide usage of bearingless motors is the need for air-gap position sensors, which are typically expensive. Here we present a method to estimate the radial position of a hysteresis-type bearingless motor using the inductance variation of the stator coils amplified by an injected high-frequency signal. We have carried out finite element (FE) simulations to demonstrate its feasibility, and have constructed a prototype self-sensing bearingless motor for experimental validations.      
### 7.Spectrally Adaptive Common Spatial Patterns  [ :arrow_down: ](https://arxiv.org/pdf/2202.04542.pdf)
>  The method of Common Spatial Patterns (CSP) is widely used for feature extraction of electroencephalography (EEG) data, such as in motor imagery brain-computer interface (BCI) systems. It is a data-driven method estimating a set of spatial filters so that the power of the filtered EEG signal is maximized for one motor imagery class and minimized for the other. This method, however, is prone to overfitting and is known to suffer from poor generalization especially with limited calibration data. Additionally, due to the high heterogeneity in brain data and the non-stationarity of brain activity, CSP is usually trained for each user separately resulting in long calibration sessions or frequent re-calibrations that are tiring for the user. In this work, we propose a novel algorithm called Spectrally Adaptive Common Spatial Patterns (SACSP) that improves CSP by learning a temporal/spectral filter for each spatial filter so that the spatial filters are concentrated on the most relevant temporal frequencies for each user. We show the efficacy of SACSP in providing better generalizability and higher classification accuracy from calibration to online control compared to existing methods. Furthermore, we show that SACSP provides neurophysiologically relevant information about the temporal frequencies of the filtered signals. Our results highlight the differences in the motor imagery signal among BCI users as well as spectral differences in the signals generated for each class, and show the importance of learning robust user-specific features in a data-driven manner.      
### 8.Dynamic self-triggered control for nonlinear systems with delays  [ :arrow_down: ](https://arxiv.org/pdf/2202.04539.pdf)
>  Self-triggered control (STC) is a resource efficient approach to determine sampling instants for Networked Control Systems (NCS). Recently, a dynamic STC strategy based on hybrid Lyapunov functions for nonlinear NCS has been proposed in Hertneck and AllgÃ¶wer (2021b), however with the limitation to NCS without transmission delays. In this paper, we extend this strategy for nonlinear NCS with transmission delays. The capability to handle systems with delays makes it possible to use the resulting dynamic STC mechanism in many practical scenarios where instant transmissions without delays cannot be guaranteed. The proposed dynamic STC mechanism guarantees stability despite bounded transmission delays. The effectiveness of the mechanism is illustrated with a numerical example and compared to state-of-the art literature.      
### 9.Techtile -- Open 6G R&amp;D Testbed for Communication, Positioning, Sensing, WPT and Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.04524.pdf)
>  New concepts for next-generation wireless systems are being developed. It is expected that these 6G and beyond systems will incorporate more than only communication, but also sensing, positioning, (deep) edge computing, and other services. The discussed measurement facility and approach, named Techtile, is an open, both in design and operation, and unique testbed to evaluate these newly envisioned systems. Techtile is a multi-functional and versatile testbed, providing fine-grained distributed resources for new communication, positioning and sensing technologies. The facility enables experimental research on hyper-connected interactive environments and validation of new algorithms and topologies. The backbone connects 140~resource units equipped with edge computing devices, software-defined radios, sensors, and LED sources. By doing so, different network topologies and local-versus-central computing can be assessed. The introduced diversity of i) the technologies (e.g., RF, acoustics and light), ii) the distributed resources and iii) the interconnectivity allows exploring more degrees and new types of diversity, which can be investigated in this testbed.      
### 10.End-to-End Blind Quality Assessment for Laparoscopic Videos using Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.04517.pdf)
>  Video quality assessment is a challenging problem having a critical significance in the context of medical imaging. For instance, in laparoscopic surgery, the acquired video data suffers from different kinds of distortion that not only hinder surgery performance but also affect the execution of subsequent tasks in surgical navigation and robotic surgeries. For this reason, we propose in this paper neural network-based approaches for distortion classification as well as quality prediction. More precisely, a Residual Network (ResNet) based approach is firstly developed for simultaneous ranking and classification task. Then, this architecture is extended to make it appropriate for the quality prediction task by using an additional Fully Connected Neural Network (FCNN). To train the overall architecture (ResNet and FCNN models), transfer learning and end-to-end learning approaches are investigated. Experimental results, carried out on a new laparoscopic video quality database, have shown the efficiency of the proposed methods compared to recent conventional and deep learning based approaches.      
### 11.Data-driven Safe Control of Linear Systems Under Epistemic and Aleatory Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2202.04495.pdf)
>  Safe control of constrained linear systems under both epistemic and aleatory uncertainties is considered. The aleatory uncertainty characterizes random noises and is modeled by a probability distribution function (PDF) and the epistemic uncertainty characterizes the lack of knowledge on the system dynamics. Data-based probabilistic safe controllers are designed for the cases where the noise PDF is 1) zero-mean Gaussian with a known covariance, 2) zero-mean Gaussian with an uncertain covariance, and 3) zero-mean non-Gaussian with an unknown distribution. Easy-to-check model-based conditions for guaranteeing probabilistic safety are provided for the first case by introducing probabilistic contractive sets. These results are then extended to the second and third cases by leveraging distributionally-robust probabilistic safe control and conditional value-at-risk (CVaR) based probabilistic safe control, respectively. Data-based implementations of these probabilistic safe controllers are then considered. It is shown that data-richness requirements for directly learning a safe controller is considerably weaker than data-richness requirements for model-based safe control approaches that undertake a model identification. Moreover, an upper bound on the minimal risk level, under which the existence of a safe controller is guaranteed, is learned using collected data. A simulation example is provided to show the effectiveness of the proposed approach.      
### 12.AC-Feasible Power Transfer Regions of Virtual Power Plants: Characterization and Application  [ :arrow_down: ](https://arxiv.org/pdf/2202.04456.pdf)
>  Distributed energy resources (DERs) in distribution networks can participate in the transmission-level operation when they are aggregated as a virtual power plant (VPP). A critical challenge for such participation is the complexity of the feasible power transfer region between a VPP and the transmission system at their point of common coupling. To overcome this challenge, this paper develops a method to characterize the AC-feasible power transfer regions for VPPs. The developed method constructed several convex polytopes in the domain of power transfers by solving a series of optimization problems. These optimization problems are established by combing the Brouwer fixed point theorem with the second-order Taylor expansion of the nonlinear Dist-Flow equations, which can theoretically guarantee the AC feasibility of the convex polytopes, whose union serves as an inner approximation to the feasible region. Furthermore, a big-M formulation is developed to linearize the transmission-level operation problem with VPP participation. The proposed method is verified by numerical experiments in the IEEE 33-bus and IEEE 136-bus test systems.      
### 13.Time-Frequency Mask Aware Bi-directional LSTM: A Deep Learning Approach for Underwater Acoustic Signal Separation  [ :arrow_down: ](https://arxiv.org/pdf/2202.04405.pdf)
>  The underwater acoustic signals separation is a key technique for the underwater communications. The existing methods are mostly model-based, and could not accurately characterise the practical underwater acoustic communication environment. They are only suitable for binary signal separation, but cannot handle multivariate signal separation. On the other hand, the recurrent neural network (RNN) shows powerful capability in extracting the features of the temporal sequences. Inspired by this, in this paper, we present a data-driven approach for underwater acoustic signals separation using deep learning technology. We use the Bi-directional Long Short-Term Memory (Bi-LSTM) to explore the features of Time-Frequency (T-F) mask, and propose a T-F mask aware Bi-LSTM for signal separation. Taking advantage of the sparseness of the T-F image, the designed Bi-LSTM network is able to extract the discriminative features for separation, which further improves the separation performance. In particular, this method breaks through the limitations of the existing methods, not only achieves good results in multivariate separation, but also effectively separates signals when mixed with 40dB Gaussian noise signals. The experimental results show that this method can achieve a $97\%$ guarantee ratio (PSR), and the average similarity coefficient of the multivariate signal separation is stable above 0.8 under high noise conditions.      
### 14.Data-Driven Chance Constrained Control using Kernel Distribution Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2202.04193.pdf)
>  We present a data-driven algorithm for efficiently computing stochastic control policies for general joint chance constrained optimal control problems. Our approach leverages the theory of kernel distribution embeddings, which allows representing expectation operators as inner products in a reproducing kernel Hilbert space. This framework enables approximately reformulating the original problem using a dataset of observed trajectories from the system without imposing prior assumptions on the parameterization of the system dynamics or the structure of the uncertainty. By optimizing over a finite subset of stochastic open-loop control trajectories, we relax the original problem to a linear program over the control parameters that can be efficiently solved using standard convex optimization techniques. We demonstrate our proposed approach in simulation on a system with nonlinear non-Markovian dynamics navigating in a cluttered environment.      
### 15.Federated Learning of Generative Image Priors for MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2202.04175.pdf)
>  Multi-institutional efforts can facilitate training of deep MRI reconstruction models, albeit privacy risks arise during cross-site sharing of imaging data. Federated learning (FL) has recently been introduced to address privacy concerns by enabling distributed training without transfer of imaging data. Existing FL methods for MRI reconstruction employ conditional models to map from undersampled to fully-sampled acquisitions via explicit knowledge of the imaging operator. Since conditional models generalize poorly across different acceleration rates or sampling densities, imaging operators must be fixed between training and testing, and they are typically matched across sites. To improve generalization and flexibility in multi-institutional collaborations, here we introduce a novel method for MRI reconstruction based on Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a two-stage approach: cross-site learning of a generative MRI prior, and subject-specific injection of the imaging operator. The global MRI prior is learned via an unconditional adversarial model that synthesizes high-quality MR images based on latent variables. Specificity in the prior is preserved via a mapper subnetwork that produces site-specific latents. During inference, the prior is combined with subject-specific imaging operators to enable reconstruction, and further adapted to individual test samples by minimizing data-consistency loss. Comprehensive experiments on multi-institutional datasets clearly demonstrate enhanced generalization performance of FedGIMP against site-specific and federated methods based on conditional models, as well as traditional reconstruction methods.      
### 16.A Speech Intelligibility Enhancement Model based on Canonical Correlation and Deep Learning for Hearing-Assistive Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2202.04172.pdf)
>  Current deep learning (DL) based approaches to speech intelligibility enhancement in noisy environments are generally trained to minimise the distance between clean and enhanced speech features. These often result in improved speech quality however they suffer from a lack of generalisation and may not deliver the required speech intelligibility in everyday noisy situations. In an attempt to address these challenges, researchers have explored intelligibility-oriented (I-O) loss functions to train DL approaches for robust speech enhancement (SE). In this paper, we formulate a novel canonical correlation-based I-O loss function to more effectively train DL algorithms. Specifically, we present a fully convolutional SE model that uses a modified canonical-correlation based short-time objective intelligibility (CC-STOI) metric as a training cost function. To the best of our knowledge, this is the first work that exploits the integration of canonical correlation in an I-O based loss function for SE. Comparative experimental results demonstrate that our proposed CC-STOI based SE framework outperforms DL models trained with conventional STOI and distance-based loss functions, in terms of both standard objective and subjective evaluation measures when dealing with unseen speakers and noises.      
### 17.A Policy Gradient Algorithm for the Risk-Sensitive Exponential Cost MDP  [ :arrow_down: ](https://arxiv.org/pdf/2202.04157.pdf)
>  We study the risk-sensitive exponential cost MDP formulation and develop a trajectory-based gradient algorithm to find the stationary point of the cost associated with a set of parameterized policies. We derive a formula that can be used to compute the policy gradient from (state, action, cost) information collected from sample paths of the MDP for each fixed parameterized policy. Unlike the traditional average-cost problem, standard stochastic approximation theory cannot be used to exploit this formula. To address the issue, we introduce a truncated and smooth version of the risk-sensitive cost and show that this new cost criterion can be used to approximate the risk-sensitive cost and its gradient uniformly under some mild assumptions. We then develop a trajectory-based gradient algorithm to minimize the smooth truncated estimation of the risk-sensitive cost and derive conditions under which a sequence of truncations can be used to solve the original, untruncated cost problem.      
### 18.Time-varying harmonic models for voice signal analysis  [ :arrow_down: ](https://arxiv.org/pdf/2202.04150.pdf)
>  Assessment of voice signals has long been performed with the assumption of periodicity as this facilitates analysis. Near periodicity of normal voice signals makes short-time harmonic modeling an appealing choice to extract vocal feature parameters. For dysphonic voice, however, a fixed harmonic structure could be too constrained as it strictly enforces periodicity in the model. Slight variation in amplitude or frequency in the signal may cause the model to misrepresent the observed signal. To address these issues, this paper presents a time-varying harmonic model, which allows its fundamental frequency and harmonic amplitudes to be polynomial functions of time. The model decouples the slow deviations of frequency and amplitude from fast irregular vocal fold vibratory behaviors such as subharmonics and diplophonia. The time-varying model is shown to track the frequency and amplitude modulations present in voice with severe tremor. This reduces the sensitivity of the model-based harmonics-to-noise ratio measures to slow frequency and amplitude variations while maintaining its sensitivity to increase in turbulent noise or the presence of irregular vibration. Other uses of the model include the vocal tract filter estimation and the rates of frequency and intensity changes. These use cases are experimentally demonstrated along with the modeling accuracy.      
### 19.Cross-level Contrastive Learning and Consistency Constraint for Semi-supervised Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2202.04074.pdf)
>  Semi-supervised learning (SSL), which aims at leveraging a few labeled images and a large number of unlabeled images for network training, is beneficial for relieving the burden of data annotation in medical image segmentation. According to the experience of medical imaging experts, local attributes such as texture, luster and smoothness are very important factors for identifying target objects like lesions and polyps in medical images. Motivated by this, we propose a cross-level constrastive learning scheme to enhance representation capacity for local features in semi-supervised medical image segmentation. Compared to existing image-wise, patch-wise and point-wise constrastive learning algorithms, our devised method is capable of exploring more complex similarity cues, namely the relational characteristics between global point-wise and local patch-wise representations. Additionally, for fully making use of cross-level semantic relations, we devise a novel consistency constraint that compares the predictions of patches against those of the full image. With the help of the cross-level contrastive learning and consistency constraint, the unlabelled data can be effectively explored to improve segmentation performance on two medical image datasets for polyp and skin lesion segmentation respectively. Code of our approach is available.      
### 20.The EMory BrEast imaging Dataset (EMBED): A Racially Diverse, Granular Dataset of 3.5M Screening and Diagnostic Mammograms  [ :arrow_down: ](https://arxiv.org/pdf/2202.04073.pdf)
>  Developing and validating artificial intelligence models in medical imaging requires datasets that are large, granular, and diverse. To date, the majority of publicly available breast imaging datasets lack in one or more of these areas. Models trained on these data may therefore underperform on patient populations or pathologies that have not previously been encountered. The EMory BrEast imaging Dataset (EMBED) addresses these gaps by providing 3650,000 2D and DBT screening and diagnostic mammograms for 116,000 women divided equally between White and African American patients. The dataset also contains 40,000 annotated lesions linked to structured imaging descriptors and 61 ground truth pathologic outcomes grouped into six severity classes. Our goal is to share this dataset with research partners to aid in development and validation of breast AI models that will serve all patients fairly and help decrease bias in medical AI.      
### 21.Reducing Redundancy in the Bottleneck Representation of the Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2202.04629.pdf)
>  Autoencoders are a type of unsupervised neural networks, which can be used to solve various tasks, e.g., dimensionality reduction, image compression, and image denoising. An AE has two goals: (i) compress the original input to a low-dimensional space at the bottleneck of the network topology using an encoder, (ii) reconstruct the input from the representation at the bottleneck using a decoder. Both encoder and decoder are optimized jointly by minimizing a distortion-based loss which implicitly forces the model to keep only those variations of input data that are required to reconstruct the and to reduce redundancies. In this paper, we propose a scheme to explicitly penalize feature redundancies in the bottleneck representation. To this end, we propose an additional loss term, based on the pair-wise correlation of the neurons, which complements the standard reconstruction loss forcing the encoder to learn a more diverse and richer representation of the input. We tested our approach across different tasks: dimensionality reduction using three different dataset, image compression using the MNIST dataset, and image denoising using fashion MNIST. The experimental results show that the proposed loss leads consistently to superior performance compared to the standard AE loss.      
### 22.Anti-windup-like Compensator Synthesis for Discrete-Time Quantized Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2202.04610.pdf)
>  This paper addresses the problem of designing an anti-windup like compensator for discrete-time linear control systems with quantized input. The proposed compensator provides a correction signal proportional to the quantization error that fed to the controller. The compensator is designed to ensure that solutions to the closed-loop systems converge in finite time into a compact set containing the origin that can be tuned by the designer. A numerically tractable algorithm with feasibility guarantees is provided for the design of the compensator. The proposed results are illustrated on an academic example and an open-loop unstable aircraft system.      
### 23.Optimal Hyperparameters and Structure Setting of Multi-Objective Robust CNN Systems via Generalized Taguchi Method and Objective Vector Norm  [ :arrow_down: ](https://arxiv.org/pdf/2202.04567.pdf)
>  Recently, Machine Learning (ML), Artificial Intelligence (AI), and Convolutional Neural Network (CNN) have made huge progress with broad applications, where their systems have deep learning structures and a large number of hyperparameters that determine the quality and performance of the CNNs and AI systems. These systems may have multi-objective ML and AI performance needs. There is a key requirement to find the optimal hyperparameters and structures for multi-objective robust optimal CNN systems. This paper proposes a generalized Taguchi approach to effectively determine the optimal hyperparameters and structure for the multi-objective robust optimal CNN systems via their objective performance vector norm. The proposed approach and methods are applied to a CNN classification system with the original ResNet for CIFAR-10 dataset as a demonstration and validation, which shows the proposed methods are highly effective to achieve an optimal accuracy rate of the original ResNet on CIFAR-10.      
### 24.A Multimodal Canonical-Correlated Graph Neural Network for Energy-Efficient Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2202.04528.pdf)
>  This paper proposes a novel multimodal self-supervised architecture for energy-efficient AV speech enhancement by integrating graph neural networks with canonical correlation analysis (CCA-GNN). This builds on a state-of-the-art CCA-GNN that aims to learn representative embeddings by maximizing the correlation between pairs of augmented views of the same input while decorrelating disconnected features. The key idea of the conventional CCA-GNN involves discarding augmentation-variant information and preserving augmentation-invariant information whilst preventing capturing of redundant information. Our proposed AV CCA-GNN model is designed to deal with the challenging multimodal representation learning context. Specifically, our model improves contextual AV speech processing by maximizing canonical correlation from augmented views of the same channel, as well as canonical correlation from audio and visual embeddings. In addition, we propose a positional encoding of the nodes that considers a prior-frame sequence distance instead of a feature-space representation while computing the node's nearest neighbors. This serves to introduce temporal information in the embeddings through the neighborhood's connectivity. Experiments conducted with the benchmark ChiME3 dataset show that our proposed prior frame-based AV CCA-GNN reinforces better feature learning in the temporal context, leading to more energy-efficient speech reconstruction compared to state-of-the-art CCA-GNN and multi-layer perceptron models. The results demonstrate the potential of our proposed approach for exploitation in future assistive technology and energy-efficient multimodal devices.      
### 25.MapiFi: Using Wi-Fi Signals to Map Home Devices  [ :arrow_down: ](https://arxiv.org/pdf/2202.04473.pdf)
>  Imagine a map of your home with all of your connected devices (computers, TVs, voice control devices, printers, security cameras, etc.), in their location. You could then easily group devices into user-profiles, monitor Wi-Fi quality and activity in different areas of your home, and even locate a lost tablet in your home. MapiFi is a method to generate that map of the devices in a home. The first part of MapiFi involves the user (either a technician or the resident) walking around the home with a mobile device that listens to Wi-Fi radio channels. The mobile device detects Wi-Fi packets that come from all of the home's devices that connect to the gateway and measures their signal strengths (ignoring the content of the packets). The second part is an algorithm that uses all the signal-strength measurements to estimate the locations of all the devices in the home. Then, MapiFi visualizes the home's space as a coordinate system with devices marked as points in this space. A patent has been filed based on this technology. This paper was published in SCTE Technical Journal (see published paper at <a class="link-external link-https" href="https://wagtail-prod-storage.s3.amazonaws.com/documents/SCTE_Technical_Journal_V1N3.pdf" rel="external noopener nofollow">this https URL</a>).      
### 26.Conditional Drums Generation using Compound Word Representations  [ :arrow_down: ](https://arxiv.org/pdf/2202.04464.pdf)
>  The field of automatic music composition has seen great progress in recent years, specifically with the invention of transformer-based architectures. When using any deep learning model which considers music as a sequence of events with multiple complex dependencies, the selection of a proper data representation is crucial. In this paper, we tackle the task of conditional drums generation using a novel data encoding scheme inspired by the Compound Word representation, a tokenization process of sequential data. Therefore, we present a sequence-to-sequence architecture where a Bidirectional Long short-term memory (BiLSTM) Encoder receives information about the conditioning parameters (i.e., accompanying tracks and musical attributes), while a Transformer-based Decoder with relative global attention produces the generated drum sequences. We conducted experiments to thoroughly compare the effectiveness of our method to several baselines. Quantitative evaluation shows that our model is able to generate drums sequences that have similar statistical distributions and characteristics to the training corpus. These features include syncopation, compression ratio, and symmetry among others. We also verified, through a listening test, that generated drum sequences sound pleasant, natural and coherent while they "groove" with the given accompaniment.      
### 27.A hypothesis-driven method based on machine learning for neuroimaging data analysis  [ :arrow_down: ](https://arxiv.org/pdf/2202.04397.pdf)
>  There remains an open question about the usefulness and the interpretation of Machine learning (MLE) approaches for discrimination of spatial patterns of brain images between samples or activation states. In the last few decades, these approaches have limited their operation to feature extraction and linear classification tasks for between-group inference. In this context, statistical inference is assessed by randomly permuting image labels or by the use of random effect models that consider between-subject variability. These multivariate MLE-based statistical pipelines, whilst potentially more effective for detecting activations than hypotheses-driven methods, have lost their mathematical elegance, ease of interpretation, and spatial localization of the ubiquitous General linear Model (GLM). Recently, the estimation of the conventional GLM has been demonstrated to be connected to an univariate classification task when the design matrix is expressed as a binary indicator matrix. In this paper we explore the complete connection between the univariate GLM and MLE \emph{regressions}. To this purpose we derive a refined statistical test with the GLM based on the parameters obtained by a linear Support Vector Regression (SVR) in the \emph{inverse} problem (SVR-iGLM). Subsequently, random field theory (RFT) is employed for assessing statistical significance following a conventional GLM benchmark. Experimental results demonstrate how parameter estimations derived from each model (mainly GLM and SVR) result in different experimental design estimates that are significantly related to the predefined functional task. Moreover, using real data from a multisite initiative the proposed MLE-based inference demonstrates statistical power and the control of false positives, outperforming the regular GLM.      
### 28.Binaural Audio Rendering in the Spherical Harmonic Domain: A Summary of the Mathematics and its Pitfalls  [ :arrow_down: ](https://arxiv.org/pdf/2202.04393.pdf)
>  The present document reviews the mathematics behind binaural rendering of sound fields that are available as spherical harmonic expansion coefficients. This process is also known as binaural ambisonic decoding. We highlight that the details entail some amount peculiarity so that one has to be well aware of the precise definitions that are chosen for some of the involved quantities to obtain a consistent formulation.      
### 29.Dual field structure-preserving discretization of port-Hamiltonian systems using finite element exterior calculus  [ :arrow_down: ](https://arxiv.org/pdf/2202.04390.pdf)
>  In this paper we propose a novel approach to discretize linear port-Hamiltonian systems while preserving the underlying structure. We present a finite element exterior calculus formulation that is able to mimetically represent conservation laws and cope with mixed open boundary conditions using a single computational mesh. The possibility of including open boundary conditions allows for modular composition of complex multi-physical systems whereas the exterior calculus formulation provides a coordinate-free treatment. Our approach relies on a dual-field representation of the physical system that is redundant at the continuous level but eliminates the need of mimicking the Hodge star operator at the discrete level. By considering the Stokes-Dirac structure representing the system together with its adjoint, which embeds the metric information directly in the codifferential, the need for an explicit discrete Hodge star is avoided altogether. By imposing the boundary conditions in a strong manner, the power balance characterizing the Stokes-Dirac structure is then retrieved at the discrete level via symplectic Runge-Kutta integrators based on Gauss-Legendre collocation points. Numerical experiments validate the convergence of the method and the conservation properties in terms of energy balance both for the wave and Maxwell equations in a three dimensional domain. For the latter example, the magnetic and electric fields preserve their divergence free nature at the discrete level.      
### 30.A Measurement-Based Robust Non-Gaussian Process Emulator Applied to Data-Driven Stochastic Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2202.04378.pdf)
>  In this paper, we propose a robust non-Gaussian process emulator based on the Schweppe-type generalized maximum likelihood estimator, which is trained on metered time series of voltage phasors and power injections to perform stochastic power flow. Power system data are often corrupted with outliers caused by fault conditions, power outages, and extreme weather, to name a few. The proposed emulator bounds the influence of the outliers using weights calculated based on projection statistics, which are robust distances of the data points associated with the rows vectors of the factor space. Specifically, the developed estimator is robust to vertical outliers and bad leverage points while retaining good leverage points in the measurements of the training dataset. The proposed method is demonstrated on an unbalanced radial IEEE 33-Bus system heavily integrated with renewable energy sources.      
### 31.Simultaneous Transmit Diversity and Passive Beamforming with Large-Scale Intelligent Reflecting Surface  [ :arrow_down: ](https://arxiv.org/pdf/2202.04370.pdf)
>  Intelligent reflecting surface (IRS) has emerged as a cost-effective solution to enhance wireless communication performance via passive signal reflection. Existing works on IRS have mainly focused on investigating IRS's passive beamforming/reflection design to boost the communication rate for users assuming that their channel state information (CSI) is fully or partially known. However, how to exploit IRS to improve the wireless transmission reliability without any CSI, which is typical in high-mobility/delay-sensitive communication scenarios, remains largely open. In this paper, we study a new IRS-aided communication system with the IRS integrated to its aided access point (AP) to achieve both functions of transmit diversity and passive beamforming simultaneously. Specifically, we first show an interesting result that the IRS's passive beamforming gain in any direction is invariant to the common phase-shift applied to all of its reflecting elements. Accordingly, we design the common phase-shift of IRS elements to achieve transmit diversity at the AP side without the need of any CSI of the users. In addition, we propose a practical method for the users to estimate the CSI at the receiver side for information decoding. Meanwhile, we show that the conventional passive beamforming gain of IRS can be retained for the other users with their CSI known at the AP. Furthermore, we derive the asymptotic performance of both IRS-aided transmit diversity and passive beamforming in closed-form, by considering the large-scale IRS with an infinite number of elements. Numerical results validate our analysis and show the performance gains of the proposed IRS-aided simultaneous transmit diversity and passive beamforming scheme over other benchmark schemes.      
### 32.AIVC: Artificial Intelligence based Video Codec  [ :arrow_down: ](https://arxiv.org/pdf/2202.04365.pdf)
>  This paper introduces AIVC, an end-to-end neural video codec. It is based on two conditional autoencoders MNet and CNet, for motion compensation and coding. AIVC learns to compress videos using any coding configurations through a single end-to-end rate-distortion optimization. Furthermore, it offers performance competitive with the recent video coder HEVC under several established test conditions. A comprehensive ablation study is performed to evaluate the benefits of the different modules composing AIVC. The implementation is made available at <a class="link-external link-https" href="https://orange-opensource.github.io/AIVC/" rel="external noopener nofollow">this https URL</a>.      
### 33.Scenario-Assisted Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2202.04337.pdf)
>  Deep reinforcement learning has proven remarkably useful in training agents from unstructured data. However, the opacity of the produced agents makes it difficult to ensure that they adhere to various requirements posed by human engineers. In this work-in-progress report, we propose a technique for enhancing the reinforcement learning training process (specifically, its reward calculation), in a way that allows human engineers to directly contribute their expert knowledge, making the agent under training more likely to comply with various relevant constraints. Moreover, our proposed approach allows formulating these constraints using advanced model engineering techniques, such as scenario-based modeling. This mix of black-box learning-based tools with classical modeling approaches could produce systems that are effective and efficient, but are also more transparent and maintainable. We evaluated our technique using a case-study from the domain of internet congestion control, obtaining promising results.      
### 34.CAU_KU team's submission to ADD 2022 Challenge task 1: Low-quality fake audio detection through frequency feature masking  [ :arrow_down: ](https://arxiv.org/pdf/2202.04328.pdf)
>  This technical report describes Chung-Ang University and Korea University (CAU_KU) team's model participating in the Audio Deep Synthesis Detection (ADD) 2022 Challenge, track 1: Low-quality fake audio detection. For track 1, we propose a frequency feature masking (FFM) augmentation technique to deal with a low-quality audio environment. %detection that spectrogram-based models can be applied. We applied FFM and mixup augmentation on five spectrogram-based deep neural network architectures that performed well for spoofing detection using mel-spectrogram and constant Q transform (CQT) features. Our best submission achieved 23.8% of EER ranked 3rd on track 1.      
### 35.Using 5G in Smart Cities: A Systematic Mapping Study  [ :arrow_down: ](https://arxiv.org/pdf/2202.04312.pdf)
>  5G is the fifth generation wireless network, with a set of characteristics, e.g., high bandwidth and data rates. The scenarios of using 5G include enhanced Mobile Broadband (eMBB), massive Machine Type Communications (mMTC), and ultra-Reliable and Low-Latency Communications (uRLLC). 5G is expected to support a wide variety of applications. We conducted a systematic mapping study that covers the literature published between Jan 2012 and Dec 2019 regarding using 5G in smart cities. The scenarios, architecture, technologies, challenges, and lessons learned of using 5G in smart cities are summarized and further analyzed based on 32 selected studies, and the results are that: (1) The studies are distributed over 27 publication venues. 17 studies report results based on academic studies and 13 studies use demonstration or toy examples. Only 2 studies report using 5G in smart cities based on industrial studies. 16 studies include assumptions of 5G network design or smart city scenarios. (2) The most discussed smart city scenario is transportation, followed by public safety, healthcare, city tourism, entertainment, and education. (3) 28 studies propose and/or discuss the architecture of 5G-enabled smart cities, containing smart city architecture (treating 5G as a component), 5G network architecture in smart cities, and business architecture of using 5G in smart cities. (4) The most mentioned 5G-related technologies are radio access technologies, network slicing, and edge computing. (5) Challenges are mainly about complex context, challenging requirements, and network development of using 5G in smart cities. (6) Most of the lessons learned identified are benefits regarding 5G itself or the proposed 5G-related methods in smart cities. This work provides a reflection of the past eight years of the state of the art on using 5G in smart cities, which can benefit both researchers and practitioners.      
### 36.TinyM$^2$Net: A Flexible System Algorithm Co-designed Multimodal Learning Framework for Tiny Devices  [ :arrow_down: ](https://arxiv.org/pdf/2202.04303.pdf)
>  With the emergence of Artificial Intelligence (AI), new attention has been given to implement AI algorithms on resource constrained tiny devices to expand the application domain of IoT. Multimodal Learning has recently become very popular with the classification task due to its impressive performance for both image and audio event classification. This paper presents TinyM$^2$Net -- a flexible system algorithm co-designed multimodal learning framework for resource constrained tiny devices. The framework was designed to be evaluated on two different case-studies: COVID-19 detection from multimodal audio recordings and battle field object detection from multimodal images and audios. In order to compress the model to implement on tiny devices, substantial network architecture optimization and mixed precision quantization were performed (mixed 8-bit and 4-bit). TinyM$^2$Net shows that even a tiny multimodal learning model can improve the classification performance than that of any unimodal frameworks. The most compressed TinyM$^2$Net achieves 88.4% COVID-19 detection accuracy (14.5% improvement from unimodal base model) and 96.8\% battle field object detection accuracy (3.9% improvement from unimodal base model). Finally, we test our TinyM$^2$Net models on a Raspberry Pi 4 to see how they perform when deployed to a resource constrained tiny device.      
### 37.The Volcspeech system for the ICASSP 2022 multi-channel multi-party meeting transcription challenge  [ :arrow_down: ](https://arxiv.org/pdf/2202.04261.pdf)
>  This paper describes our submission to ICASSP 2022 Multi-channel Multi-party Meeting Transcription (M2MeT) Challenge. For Track 1, we propose several approaches to empower the clustering-based speaker diarization system to handle overlapped speech. Front-end dereverberation and the direction-of-arrival (DOA) estimation are used to improve the accuracy of speaker diarization. Multi-channel combination and overlap detection are applied to reduce the missed speaker error. A modified DOVER-Lap is also proposed to fuse the results of different systems. We achieve the final DER of 5.79% on the Eval set and 7.23% on the Test set. For Track 2, we develop our system using the Conformer model in a joint CTC-attention architecture. Serialized output training is adopted to multi-speaker overlapped speech recognition. We propose a neural front-end module to model multi-channel audio and train the model end-to-end. Various data augmentation methods are utilized to mitigate over-fitting in the multi-channel multi-speaker E2E system. Transformer language model fusion is developed to achieve better performance. The final CER is 19.2% on the Eval set and 20.8% on the Test set.      
### 38.GenAD: General Representations of Multivariate Time Seriesfor Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2202.04250.pdf)
>  The reliability of wireless base stations in China Mobile is of vital importance, because the cell phone users are connected to the stations and the behaviors of the stations are directly related to user experience. Although the monitoring of the station behaviors can be realized by anomaly detection on multivariate time series, due to complex correlations and various temporal patterns of multivariate series in large-scale stations, building a general unsupervised anomaly detection model with a higher F1-score remains a challenging task. In this paper, we propose a General representation of multivariate time series for Anomaly Detection(GenAD). First, we pre-train a general model on large-scale wireless base stations with self-supervision, which can be easily transferred to a specific station anomaly detection with a small amount of training data. Second, we employ Multi-Correlation Attention and Time-Series Attention to represent the correlations and temporal patterns of the stations. With the above innovations, GenAD increases F1-score by total 9% on real-world datasets in China Mobile, while the performance does not significantly degrade on public datasets with only 10% of the training data.      
### 39.Real-Time Event-Based Tracking and Detection for Maritime Environments  [ :arrow_down: ](https://arxiv.org/pdf/2202.04231.pdf)
>  Event cameras are ideal for object tracking applications due to their ability to capture fast-moving objects while mitigating latency and data redundancy. Existing event-based clustering and feature tracking approaches for surveillance and object detection work well in the majority of cases, but fall short in a maritime environment. Our application of maritime vessel detection and tracking requires a process that can identify features and output a confidence score representing the likelihood that the feature was produced by a vessel, which may trigger a subsequent alert or activate a classification system. However, the maritime environment presents unique challenges such as the tendency of waves to produce the majority of events, demanding the majority of computational processing and producing false positive detections. By filtering redundant events and analyzing the movement of each event cluster, we can identify and track vessels while ignoring shorter lived and erratic features such as those produced by waves.      
### 40.QAC: Quantum-computing Aided Composition  [ :arrow_down: ](https://arxiv.org/pdf/2202.04215.pdf)
>  In this chapter I will discuss the role of quantum computing in computer music and how it can be integrated to better serve the creative artists. I will start by considering different approaches in current computer music and quantum computing tools, as well as reviewing some previous attempts to integrate them. Then, I will reflect on the meaning of this integration and present what I coined as QAC (Quantum-computing Aided Composition) as well as an early attempt at realizing it. This chapter will also introduce The QAC Toolkit Max package, analyze its performance, and explore some examples of what it can offer to realtime creative practice. Lastly, I will present a real case scenario of QAC in the creative work Disklavier Prelude #3.      
### 41.Unified Characterization and Precoding for Non-Stationary Channels  [ :arrow_down: ](https://arxiv.org/pdf/2202.04148.pdf)
>  Modern wireless channels are increasingly dense and mobile making the channel highly non-stationary. The time-varying distribution and the existence of joint interference across multiple degrees of freedom (e.g., users, antennas, frequency and symbols) in such channels render conventional precoding sub-optimal in practice, and have led to historically poor characterization of their statistics. The core of our work is the derivation of a high-order generalization of Mercer's Theorem to decompose the non-stationary channel into constituent fading sub-channels (2-D eigenfunctions) that are jointly orthogonal across its degrees of freedom. Consequently, transmitting these eigenfunctions with optimally derived coefficients eventually mitigates any interference across these dimensions and forms the foundation of the proposed joint spatio-temporal precoding. The precoded symbols directly reconstruct the data symbols at the receiver upon demodulation, thereby significantly reducing its computational burden, by alleviating the need for any complementary decoding. These eigenfunctions are paramount to extracting the second-order channel statistics, and therefore completely characterize the underlying channel. Theory and simulations show that such precoding leads to ${&gt;}10^4{\times}$ BER improvement (at 20dB) over existing methods for non-stationary channels.      
### 42.The Rate-Distortion-Perception Tradeoff: The Role of Common Randomness  [ :arrow_down: ](https://arxiv.org/pdf/2202.04147.pdf)
>  A rate-distortion-perception (RDP) tradeoff has recently been proposed by Blau and Michaeli and also Matsumoto. Focusing on the case of perfect realism, which coincides with the problem of distribution-preserving lossy compression studied by Li et al., a coding theorem for the RDP tradeoff that allows for a specified amount of common randomness between the encoder and decoder is provided. The existing RDP tradeoff is recovered by allowing for the amount of common randomness to be infinite. The quadratic Gaussian case is examined in detail.      
### 43.ns-3 and 5G-LENA extensions to support MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2202.04135.pdf)
>  MIMO spatial multiplexing is an essential feature to increase the communication data rates in current and future cellular systems. Currently, the ns-3 lte module leverages an abstraction model for 2x2 MIMO with spatial multiplexing of 2 streams; while mmwave and nr modules were lacking the spatial multiplexing option until this work, since the ns-3 models were not supporting the usage of multiple antennas for spatial multiplexing and an abstraction model such as the one used in the lte module is not suitable for the mmWave frequencies. In this paper, we propose, implement and evaluate 2-stream MIMO spatial multiplexing models for ns-3 and the nr module. The proposed extension for the ns-3 supports multiple antennas for MIMO spatial multiplexing and can be used by any ns-3 module that is compatible with the ns-3 antenna array based models, such as nr and mmwave modules. We leverage this ns-3 extension to model 2-stream MIMO by exploiting dual-polarized antennas and their orthogonality under line-of-sight conditions, as it happens at high frequency bands, to send the two data streams. The proposed model does not rely on abstraction, as the MIMO model in the ns-3 lte module, and can thus model more realistically the propagation differences of the two streams, correlation, inter-stream interference, and allows design and evaluation of the rank adaptation algorithms. Additionally, we propose and evaluate an adaptive rank adaptation scheme and compare it with a fixed scheme. The developed MIMO spatial multiplexing models for the ns-3 simulator and the nr module are openly available.      
### 44.Random Linear Network Coding in NOMA Optical Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2202.04123.pdf)
>  Optical wireless communication (OWC) has the potential to provide high communication speeds that support the massive use of the Internet that is expected in the near future. In OWC, optical access points (APs) are deployed on the celling to serve multiple users. In this context, efficient multiple access schemes are required to share the resources among the users and align multi-user interference. Recently, non-orthogonal multiple access (NOMA) has been studied to serve multiple users simultaneously using the same resources, while a different power level is allocated to each user. Despite the acceptable performance of NOMA, users might experience a high packet loss due to high noise, which results from the use of successive interference cancelation (SIC). In this work, random linear network coding (RLNC) is proposed to enhance the performance of NOMA in an optical wireless network where users are divided into multicast groups, and each group contains users that slightly differ in their channel gains. Moreover, a fixed power allocation (FPA) strategy is considered among these groups to avoid complexity. The performance of the proposed scheme is evaluated in terms of total packet success probability. The results show that the proposed scheme is more suitable for the network considered compared to other benchmark schemes such as traditional NOMA and orthogonal transmission schemes. Moreover, the total packet success probability is highly affected by the level of power allocated to each group in all the scenarios.      
### 45.Detecting and Localizing Copy-Move and Image-Splicing Forgery  [ :arrow_down: ](https://arxiv.org/pdf/2202.04069.pdf)
>  In the world of fake news and deepfakes, there have been an alarmingly large number of cases of images being tampered with and published in newspapers, used in court, and posted on social media for defamation purposes. Detecting these tampered images is an important task and one we try to tackle. In this paper, we focus on the methods to detect if an image has been tampered with using both Deep Learning and Image transformation methods and comparing the performances and robustness of each method. We then attempt to identify the tampered area of the image and predict the corresponding mask. Based on the results, suggestions and approaches are provided to achieve a more robust framework to detect and identify the forgeries.      
