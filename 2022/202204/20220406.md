# ArXiv eess --Wed, 6 Apr 2022
### 1.Learning Speech Emotion Representations in the Quaternion Domain  [ :arrow_down: ](https://arxiv.org/pdf/2204.02385.pdf)
>  The modeling of human emotion expression in speech signals is an important, yet challenging task. The high resource demand of speech emotion recognition models, combined with the the general scarcity of emotion-labelled data are obstacles to the development and application of effective solutions in this field. In this paper, we present an approach to jointly circumvent these difficulties. Our method, named RH-emo, is a novel semi-supervised architecture aimed at extracting quaternion embeddings from real-valued monoaural spectrograms, enabling the use of quaternion-valued networks for speech emotion recognition tasks. RH-emo is a hybrid real/quaternion autoencoder network that consists of a real-valued encoder in parallel to a real-valued emotion classifier and a quaternion-valued decoder. On the one hand, the classifier permits to optimize each latent axis of the embeddings for the classification of a specific emotion-related characteristic: valence, arousal, dominance and overall emotion. On the other hand, the quaternion reconstruction enables the latent dimension to develop intra-channel correlations that are required for an effective representation as a quaternion entity. We test our approach on speech emotion recognition tasks using four popular datasets: Iemocap, Ravdess, EmoDb and Tess, comparing the performance of three well-established real-valued CNN architectures (AlexNet, ResNet-50, VGG) and their quaternion-valued equivalent fed with the embeddings created with RH-emo. We obtain a consistent improvement in the test accuracy for all datasets, while drastically reducing the resources' demand of models. Moreover, we performed additional experiments and ablation studies that confirm the effectiveness of our approach. The RH-emo repository is available at: <a class="link-external link-https" href="https://github.com/ispamm/rhemo" rel="external noopener nofollow">this https URL</a>.      
### 2.Hear No Evil: Towards Adversarial Robustness of Automatic Speech Recognition via Multi-Task Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.02381.pdf)
>  As automatic speech recognition (ASR) systems are now being widely deployed in the wild, the increasing threat of adversarial attacks raises serious questions about the security and reliability of using such systems. On the other hand, multi-task learning (MTL) has shown success in training models that can resist adversarial attacks in the computer vision domain. In this work, we investigate the impact of performing such multi-task learning on the adversarial robustness of ASR models in the speech domain. We conduct extensive MTL experimentation by combining semantically diverse tasks such as accent classification and ASR, and evaluate a wide range of adversarial settings. Our thorough analysis reveals that performing MTL with semantically diverse tasks consistently makes it harder for an adversarial attack to succeed. We also discuss in detail the serious pitfalls and their related remedies that have a significant impact on the robustness of MTL models. Our proposed MTL approach shows considerable absolute improvements in adversarially targeted WER ranging from 17.25 up to 59.90 compared to single-task learning baselines (attention decoder and CTC respectively). Ours is the first in-depth study that uncovers adversarial robustness gains from multi-task learning for ASR.      
### 3.Data-driven Influence Based Clustering of Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.02373.pdf)
>  Community detection is a challenging and relevant problem in various disciplines of science and engineering like power systems, gene-regulatory networks, social networks, financial networks, astronomy etc. Furthermore, in many of these applications the underlying system is dynamical in nature and because of the complexity of the systems involved, deriving a mathematical model which can be used for clustering and community detection, is often impossible. Moreover, while clustering dynamical systems, it is imperative that the dynamical nature of the underlying system is taken into account. In this paper, we propose a novel approach for clustering dynamical systems purely from time-series data which inherently takes into account the dynamical evolution of the underlying system. In particular, we define a \emph{distance/similarity} measure between the states of the system which is a function of the influence that the states have on each other, and use the proposed measure for clustering of the dynamical system. For data-driven computation we leverage the Koopman operator framework which takes into account the nonlinearities (if present) of the underlying system, thus making the proposed framework applicable to a wide range of application areas. We illustrate the efficacy of the proposed approach by clustering three different dynamical systems, namely, a linear system, which acts like a proof of concept, the highly non-linear IEEE 39 bus transmission network and dynamic variables obtained from atmospheric data over the Amazon rain forest.      
### 4.Information-Theoretic Policy Extraction from Partial Observations  [ :arrow_down: ](https://arxiv.org/pdf/2204.02350.pdf)
>  We investigate the problem of extracting a control policy from a single or multiple partial observation sequences. Therefore we cast the problem as a Controlled Hidden Markov Model. We then sketch two information-theoretic approaches to extract a policy which we refer to as A Posterior Control Distributions. The performance of both methods is investigated and compared empirically on a linear tracking problem.      
### 5.digHolo : High-speed library for off-axis digital holography and Hermite-Gaussian decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2204.02348.pdf)
>  'digHolo' is a numerical library for processing batches of input off-axis digital holography interferograms and outputting the corresponding reconstructed fields. Optionally the library can perform a modal decomposition of the reconstructed fields and is particularly efficient at Hermite-Gaussian and Laguerre-Gaussian decomposition. <br>The library is written in C++11 for the x86-64 (AVX2) architecture and is intended for use primarily as a dynamic linked library (Windows) or shared object (Linux) which the user can integrate into their own software. The library can be compiled as an executable for processing interferograms from disk using the command line. The library has dependencies on two external libraries; FFTW and BLAS/LAPACK (functions cgemv, cgemm, cgesvd, sgels), but a precompiled statically linked DLL is provided for Windows. <br>A video tutorial is provided explaining usage of the software in addition to this user guide. Coding examples for use in Matlab, Python and C++ are supplied.      
### 6.Leveraging Speech Separation for Conversational Telephone Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2204.02306.pdf)
>  Speech separation and speaker diarization have strong similarities. In particular with respect to end-to-end neural diarization (EEND) methods. Separation aims at extracting each speaker from overlapped speech, while diarization identifies time boundaries of speech segments produced by the same speaker. In this paper, we carry out an analysis of the use of speech separation guided diarization (SSGD) where diarization is performed simply by separating the speakers signals and applying voice activity detection. In particular we compare two speech separation (SSep) models, both in offline and online settings. In the online setting we consider both the use of continuous source separation (CSS) and causal SSep models architectures. As an additional contribution, we show a simple post-processing algorithm which reduces significantly the false alarm errors of a SSGD pipeline. We perform our experiments on Fisher Corpus Part 1 and CALLHOME datasets evaluating both separation and diarization metrics. Notably, without fine-tuning, our SSGD DPRNN-based online model achieves 12.7% DER on CALLHOME, comparable with state-of-the-art EEND models despite having considerably lower latency, i.e., 50 ms vs 1 s.      
### 7.Design Guidelines for Inclusive Speaker Verification Evaluation Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2204.02281.pdf)
>  Speaker verification (SV) provides billions of voice-enabled devices with access control, and ensures the security of voice-driven technologies. As a type of biometrics, it is necessary that SV is unbiased, with consistent and reliable performance across speakers irrespective of their demographic, social and economic attributes. Current SV evaluation practices are insufficient for evaluating bias: they are over-simplified and aggregate users, not representative of real-life usage scenarios, and consequences of errors are not accounted for. This paper proposes design guidelines for constructing SV evaluation datasets that address these short-comings. We propose a schema for grading the difficulty of utterance pairs, and present an algorithm for generating inclusive SV datasets. We empirically validate our proposed method in a set of experiments on the VoxCeleb1 dataset. Our results confirm that the count of utterance pairs/speaker, and the difficulty grading of utterance pairs have a significant effect on evaluation performance and variability. Our work contributes to the development of SV evaluation practices that are inclusive and fair.      
### 8.Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2204.02275.pdf)
>  Melanoma is a fatal skin cancer that is curable and has dramatically increasing survival rate when diagnosed at early stages. Learning-based methods hold significant promise for the detection of melanoma from dermoscopic images. However, since melanoma is a rare disease, existing databases of skin lesions predominantly contain highly imbalanced numbers of benign versus malignant samples. In turn, this imbalance introduces substantial bias in classification models due to the statistical dominance of the majority class. To address this issue, we introduce a deep clustering approach based on the latent-space embedding of dermoscopic images. Clustering is achieved using a novel center-oriented margin-free triplet loss (COM-Triplet) enforced on image embeddings from a convolutional neural network backbone. The proposed method aims to form maximally-separated cluster centers as opposed to minimizing classification error, so it is less sensitive to class imbalance. To avoid the need for labeled data, we further propose to implement COM-Triplet based on pseudo-labels generated by a Gaussian mixture model. Comprehensive experiments show that deep clustering with COM-Triplet loss outperforms clustering with triplet loss, and competing classifiers in both supervised and unsupervised settings.      
### 9.Multilingual and Multimodal Abuse Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.02263.pdf)
>  The presence of abusive content on social media platforms is undesirable as it severely impedes healthy and safe social media interactions. While automatic abuse detection has been widely explored in textual domain, audio abuse detection still remains unexplored. In this paper, we attempt abuse detection in conversational audio from a multimodal perspective in a multilingual social media setting. Our key hypothesis is that along with the modelling of audio, incorporating discriminative information from other modalities can be highly beneficial for this task. Our proposed method, MADA, explicitly focuses on two modalities other than the audio itself, namely, the underlying emotions expressed in the abusive audio and the semantic information encapsulated in the corresponding textual form. Observations prove that MADA demonstrates gains over audio-only approaches on the ADIMA dataset. We test the proposed approach on 10 different languages and observe consistent gains in the range 0.6%-5.2% by leveraging multiple modalities. We also perform extensive ablation experiments for studying the contributions of every modality and observe the best results while leveraging all the modalities together. Additionally, we perform experiments to empirically confirm that there is a strong correlation between underlying emotions and abusive behaviour.      
### 10.A Comparison of Deep Learning MOS Predictors for Speech Synthesis Quality  [ :arrow_down: ](https://arxiv.org/pdf/2204.02249.pdf)
>  This paper introduces a comparison of deep learning-based techniques for the MOS prediction task of synthesised speech in the Interspeech VoiceMOS challenge. Using the data from the main track of the VoiceMOS challenge we explore both existing predictors and propose new ones. We evaluate two groups of models: NISQA-based models and techniques based on fine-tuning the self-supervised learning (SSL) model wav2vec2_base. Our findings show that a simplified version of NISQA with 40% fewer parameters achieves results close to the original NISQA architecture on both utterance-level and system-level performances. Pre-training NISQA with the NISQA corpus improves utterance-level performance but shows no benefit on the system-level performance. Also, the NISQA-based models perform close to LDNet and MOSANet, 2 out of 3 baselines of the challenge. Fine-tuning wav2vec2_base shows superior performance than the NISQA-based models. We explore the mismatch between natural and synthetic speech and discovered that the performance of the SSL model drops consistently when fine-tuned on natural speech samples. We show that adding CNN features with the SSL model does not improve the baseline performance. Finally, we show that the system type has an impact on the predictions of the non-SSL models.      
### 11.Complex Recurrent Variational Autoencoder for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2204.02195.pdf)
>  Commonly-used methods in speech enhancement are based on short-time fourier transform (STFT) representation, in particular on the magnitude of the STFT. This is because phase is naturally unstructured and intractable, and magnitude has shown more importance in speech enhancement. Nevertheless, phase has shown its significance in some research and cannot be ignored. Complex neural networks, with their inherent advantage, provide a solution for complex spectrogram processing. Complex variational autoencoder (VAE), as an extension of vanilla \acrshort{vae}, has shown positive results in complex spectrogram representation. However, the existing work on complex \acrshort{vae} only uses linear layers and merely applies the model on direct spectra representation. This paper extends the linear complex \acrshort{vae} to a non-linear one. Furthermore, on account of the temporal property of speech signals, a complex recurrent \acrshort{vae} is proposed. The proposed model has been applied on speech enhancement. As far as we know, it is the first time that a complex generative model is applied to speech enhancement. Experiments are based on the TIMIT dataset, while speech intelligibility and speech quality have been evaluated. The results show that, for speech enhancement, the proposed method has better performance on speech intelligibility and comparable performance on speech quality.      
### 12.Overall Complexity Certification of a Standard Branch and Bound Method for Mixed-Integer Quadratic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2204.02171.pdf)
>  This paper presents a method to certify the computational complexity of a standard Branch and Bound method for solving Mixed-Integer Quadratic Programming (MIQP) problems defined as instances of a multi-parametric MIQP. Beyond previous work, not only the size of the binary search tree is considered, but also the exact complexity of solving the relaxations in the nodes by using recent result from exact complexity certification of active-set QP methods. With the algorithm proposed in this paper, a total worst-case number of QP iterations to be performed in order to solve the MIQP problem can be determined as a function of the parameter in the problem. An important application of the proposed method is Model Predictive Control for hybrid systems, that can be formulated as an MIQP that has to be solved in real-time. The usefulness of the proposed method is successfully illustrated in numerical examples.      
### 13.Disentangled Speech Representation Learning Based on Factorized Hierarchical Variational Autoencoder with Self-Supervised Objective  [ :arrow_down: ](https://arxiv.org/pdf/2204.02166.pdf)
>  Disentangled representation learning aims to extract explanatory features or factors and retain salient information. Factorized hierarchical variational autoencoder (FHVAE) presents a way to disentangle a speech signal into sequential-level and segmental-level features, which represent speaker identity and speech content information, respectively. As a self-supervised objective, autoregressive predictive coding (APC), on the other hand, has been used in extracting meaningful and transferable speech features for multiple downstream tasks. Inspired by the success of these two representation learning methods, this paper proposes to integrate the APC objective into the FHVAE framework aiming at benefiting from the additional self-supervision target. The main proposed method requires neither more training data nor more computational cost at test time, but obtains improved meaningful representations while maintaining disentanglement. The experiments were conducted on the TIMIT dataset. Results demonstrate that FHVAE equipped with the additional self-supervised objective is able to learn features providing superior performance for tasks including speech recognition and speaker recognition. Furthermore, voice conversion, as one application of disentangled representation learning, has been applied and evaluated. The results show performance similar to baseline of the new framework on voice conversion.      
### 14.Computationally efficient robust MPC using optimized constraint tightening  [ :arrow_down: ](https://arxiv.org/pdf/2204.02142.pdf)
>  A robust model predictive control (MPC) method is presented for linear, time-invariant systems affected by bounded additive disturbances. The main contribution is the offline design of a disturbance-affine feedback gain whereby the resulting constraint tightening is minimized. This is achieved by formulating the constraint tightening problem as a convex optimization problem with the feedback term as a variable. The resulting MPC controller has the computational complexity of nominal MPC, and guarantees recursive feasibility, stability and constraint satisfaction. The advantages of the proposed approach compared to existing robust MPC methods are demonstrated using numerical examples.      
### 15.Exploring the influence of fine-tuning data on wav2vec 2.0 model for blind speech quality prediction  [ :arrow_down: ](https://arxiv.org/pdf/2204.02135.pdf)
>  Recent studies have shown how self-supervised models can produce accurate speech quality predictions. Speech representations generated by the pre-trained wav2vec 2.0 model allows constructing robust predicting models using small amounts of annotated data. This opens the possibility of developing strong models in scenarios where labelled data is scarce. It is known that fine-tuning improves the model's performance; however, it is unclear how the data (e.g., language, amount of samples) used for fine-tuning is influencing that performance. In this paper, we explore how using different speech corpus to fine-tune the wav2vec 2.0 can influence its performance. We took four speech datasets containing degradations found in common conferencing applications and fine-tuned wav2vec 2.0 targeting different languages and data size scenarios. The fine-tuned models were tested across all four conferencing datasets plus an additional dataset containing synthetic speech and they were compared against three external baseline models. Results showed that fine-tuned models were able to compete with baseline models. Larger fine-tune data guarantee better performance; meanwhile, diversity in language helped the models deal with specific languages. Further research is needed to evaluate other wav2vec 2.0 models pre-trained with multi-lingual datasets and to develop prediction models that are more resilient to language diversity.      
### 16.Scalable tube model predictive control of uncertain linear systems using ellipsoidal sets  [ :arrow_down: ](https://arxiv.org/pdf/2204.02134.pdf)
>  This work proposes a novel robust model predictive control (MPC) algorithm for linear systems affected by dynamic model uncertainty and exogenous disturbances. The uncertainty is modeled using a linear fractional perturbation structure with a time-varying perturbation matrix, enabling the algorithm to be applied to a large model class. The MPC controller constructs a state tube as a sequence of parameterized ellipsoidal sets to bound the state trajectories of the system. The proposed approach results in a semidefinite program to be solved online, whose size scales linearly with the order of the system. The design of the state tube is formulated as an offline optimization problem, which offers flexibility to impose desirable features such as robust invariance on the terminal set. This contrasts with most existing tube MPC strategies using polytopic sets in the state tube, which are difficult to design and whose complexity grows combinatorially with the system order. The algorithm guarantees constraint satisfaction, recursive feasibility, and stability of the closed loop. The advantages of the algorithm are demonstrated using two simulation studies.      
### 17.Scalable global state synchronization of discrete-time double integrator multi-agent systems with input saturation via linear protocol  [ :arrow_down: ](https://arxiv.org/pdf/2204.02129.pdf)
>  This paper studies scalable global state synchronization of discrete-time double integrator multi-agent systems in presence of input saturation based on localized information exchange. A scale-free collaborative linear dynamic protocols design methodology is developed for discrete-time multi-agent systems with both full and partial-state couplings. And the protocol design methodology does not need any knowledge of the directed network topology and the spectrum of the associated Laplacian matrix. Meanwhile, the protocols are parametric based on a parameter set in which the designed protocols can guarantee the global synchronization result. Furthermore, the proposed protocol is scalable and achieves synchronization for any arbitrary number of agents.      
### 18.Split Hierarchical Variational Compression  [ :arrow_down: ](https://arxiv.org/pdf/2204.02071.pdf)
>  Variational autoencoders (VAEs) have witnessed great success in performing the compression of image datasets. This success, made possible by the bits-back coding framework, has produced competitive compression performance across many benchmarks. However, despite this, VAE architectures are currently limited by a combination of coding practicalities and compression ratios. That is, not only do state-of-the-art methods, such as normalizing flows, often demonstrate out-performance, but the initial bits required in coding makes single and parallel image compression challenging. To remedy this, we introduce Split Hierarchical Variational Compression (SHVC). SHVC introduces two novelties. Firstly, we propose an efficient autoregressive prior, the autoregressive sub-pixel convolution, that allows a generalisation between per-pixel autoregressions and fully factorised probability models. Secondly, we define our coding framework, the autoregressive initial bits, that flexibly supports parallel coding and avoids -- for the first time -- many of the practicalities commonly associated with bits-back coding. In our experiments, we demonstrate SHVC is able to achieve state-of-the-art compression performance across full-resolution lossless image compression tasks, with up to 100x fewer model parameters than competing VAE approaches.      
### 19.Inverse Problems Are Solvable on Real Number Signal Processing Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2204.02066.pdf)
>  Inverse problems are used to model numerous tasks in imaging sciences, in particular, they encompass any task to reconstruct data from measurements. Thus, the algorithmic solvability of inverse problems is of significant importance. The study of this question is inherently related to the underlying computing model and hardware, since the admissible operations of any implemented algorithm are defined by the computing model and the hardware. Turing machines provide the fundamental model of today's digital computers. However, it has been shown that Turing machines are incapable of solving finite dimensional inverse problems for any given accuracy. This stimulates the question of how powerful the computing model must be to enable the general solution of finite dimensional inverse problems. This paper investigates the general computation framework of Blum-Shub-Smale (BSS) machines which allows the processing and storage of arbitrary real values. Although a corresponding real world computing device does not exist at the moment, research and development towards real number computing hardware, usually referred to by the term "neuromorphic computing", has increased in recent years. In this work, we show that real number computing in the framework of BSS machines does enable the algorithmic solvability of finite dimensional inverse problems. Our results emphasize the influence of the considered computing model in questions of algorithmic solvability of inverse problems.      
### 20.Parameter Filter-based Event-triggered Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.02059.pdf)
>  Model-based algorithms are deeply rooted in modern control and systems theory. However, they usually come with a critical assumption - access to an accurate model of the system. In practice, models are far from perfect. Even precisely tuned estimates of unknown parameters will deteriorate over time. Therefore, it is essential to detect the change to avoid suboptimal or even dangerous behavior of a control system. We propose to combine statistical tests with dedicated parameter filters that track unknown system parameters from state data. These filters yield point estimates of the unknown parameters and, further, an inherent notion of uncertainty. When the point estimate leaves the confidence region, we trigger active learning experiments. We update models only after enforcing a sufficiently small uncertainty in the filter. Thus, models are only updated when necessary and statistically significant while ensuring guaranteed improvement, which we call event-triggered learning. We validate the proposed method in numerical simulations of a DC motor in combination with model predictive control.      
### 21.On the Computational Consequences of Cost Function Design in Nonlinear Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2204.01986.pdf)
>  Optimal control is an essential tool for stabilizing complex nonlinear system. However, despite the extensive impacts of methods such as receding horizon control, dynamic programming and reinforcement learning, the design of cost functions for a particular system often remains a heuristic-driven process of trial and error. In this paper we seek to gain insights into how the choice of cost function interacts with the underlying structure of the control system and impacts the amount of computation required to obtain a stabilizing controller. We treat the cost design problem as a two-step process where the designer specifies outputs for the system that are to be penalized and then modulates the relative weighting of the inputs and the outputs in the cost. We then bound the length of the prediction horizon $T&gt;0$ that is required for receding horizon control methods to stabilize the system as a concrete way of characterizing the computational difficulty of stabilizing the system using the chosen cost function. Drawing on insights from the `cheap control' literature, we investigate cases where the chosen outputs lead to minimumphase and non-minimumphase input-output dynamics. When the system is minimumphase, the prediction horizon needed to ensure stability can be made arbitrarily small by making the penalty on the control small enough. This indicates that choices of cost function which implicitly induce minimumphase behavior lead to an optimal control problem from which it is `easy' to obtain a stabilizing controller. Using these insights, we investigate empirically how the choice of cost function affects the ability of modern reinforcement learning algorithms to learn a stabilizing controller. Taken together, the results in this paper indicate that cost functions which induce non-minimum phase behavior lead to inherent computational difficulties.      
### 22.Unsupervised Data Selection via Discrete Speech Representation for ASR  [ :arrow_down: ](https://arxiv.org/pdf/2204.01981.pdf)
>  Self-supervised learning of speech representations has achieved impressive results in improving automatic speech recognition (ASR). In this paper, we show that data selection is important for self-supervised learning. We propose a simple and effective unsupervised data selection method which selects acoustically similar speech to a target domain. It takes the discrete speech representation available in common self-supervised learning frameworks as input, and applies a contrastive data selection method on the discrete tokens. Through extensive empirical studies we show that our proposed method reduces the amount of required pre-training data and improves the downstream ASR performance. Pre-training on a selected subset of 6% of the general data pool results in 11.8% relative improvements in LibriSpeech test-other compared to pre-training on the full set. On Multilingual LibriSpeech French, German, and Spanish test sets, selecting 6% data for pre-training reduces word error rate by more than 15% relatively compared to the full set, and achieves competitive results compared to current state-of-the-art performances.      
### 23.Multi-Weight Respecification of Scan-specific Learning for Parallel Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2204.01979.pdf)
>  Parallel imaging is widely used in magnetic resonance imaging as an acceleration technology. Traditional linear reconstruction methods in parallel imaging often suffer from noise amplification. Recently, a non-linear robust artificial-neural-network for k-space interpolation (RAKI) exhibits superior noise resilience over other linear methods. However, RAKI performs poorly at high acceleration rates, and needs a large amount of autocalibration signals as the training samples. In order to tackle these issues, we propose a multi-weight method that implements multiple weighting matrices on the undersampled data, named as MW-RAKI. Enforcing multiple weighted matrices on the measurements can effectively reduce the influence of noise and increase the data constraints. Furthermore, we incorporate the strategy of multiple weighting matrixes into a residual version of RAKI, and form MW-rRAKI.Experimental compari-sons with the alternative methods demonstrated noticeably better reconstruction performances, particularly at high acceleration rates.      
### 24.Dual Quaternion Ambisonics Array for Six-Degree-of-Freedom Acoustic Representation  [ :arrow_down: ](https://arxiv.org/pdf/2204.01851.pdf)
>  Spatial audio methods are gaining a growing interest due to the spread of immersive audio experiences and applications, such as virtual and augmented reality. For these purposes, 3D audio signals are often acquired through arrays of Ambisonics microphones, each comprising four capsules that decompose the sound field in spherical harmonics. In this paper, we propose a dual quaternion representation of the spatial sound field acquired through an array of two First Order Ambisonics (FOA) microphones. The audio signals are encapsulated in a dual quaternion that leverages quaternion algebra properties to exploit correlations among them. This augmented representation with 6 degrees of freedom (6DOF) involves a more accurate coverage of the sound field, resulting in a more precise sound localization and a more immersive audio experience. We evaluate our approach on a sound event localization and detection (SELD) benchmark. We show that our dual quaternion SELD model with temporal convolution blocks (DualQSELD-TCN) achieves better results with respect to real and quaternion-valued baselines thanks to our augmented representation of the sound field. Full code is available at: <a class="link-external link-https" href="https://github.com/ispamm/DualQSELD-TCN" rel="external noopener nofollow">this https URL</a>.      
### 25.Free Energy Principle for the Noise Smoothness Estimation of Linear Systems with Colored Noise  [ :arrow_down: ](https://arxiv.org/pdf/2204.01796.pdf)
>  The free energy principle (FEP) from neuroscience provides a framework called active inference for the joint estimation and control of state space systems, subjected to colored noise. However, the active inference community has been challenged with the critical task of manually tuning the noise smoothness parameter. To solve this problem, we introduce a novel online noise smoothness estimator based on the idea of free energy principle. We mathematically show that our estimator can converge to the free energy optimum during smoothness estimation. Using this formulation, we introduce a joint state and noise smoothness observer design called DEMs. Through rigorous simulations, we show that DEMs outperforms state-of-the-art state observers with least state estimation error. Finally, we provide a proof of concept for DEMs by applying it on a real life robotics problem - state estimation of a quadrotor hovering in wind, demonstrating its practical use.      
### 26.The First Principles of Deep Learning and Compression  [ :arrow_down: ](https://arxiv.org/pdf/2204.01782.pdf)
>  The deep learning revolution incited by the 2012 Alexnet paper has been transformative for the field of computer vision. Many problems which were severely limited using classical solutions are now seeing unprecedented success. The rapid proliferation of deep learning methods has led to a sharp increase in their use in consumer and embedded applications. One consequence of consumer and embedded applications is lossy multimedia compression which is required to engineer the efficient storage and transmission of data in these real-world scenarios. As such, there has been increased interest in a deep learning solution for multimedia compression which would allow for higher compression ratios and increased visual quality. <br>The deep learning approach to multimedia compression, so called Learned Multimedia Compression, involves computing a compressed representation of an image or video using a deep network for the encoder and the decoder. While these techniques have enjoyed impressive academic success, their industry adoption has been essentially non-existent. Classical compression techniques like JPEG and MPEG are too entrenched in modern computing to be easily replaced. This dissertation takes an orthogonal approach and leverages deep learning to improve the compression fidelity of these classical algorithms. This allows the incredible advances in deep learning to be used for multimedia compression without threatening the ubiquity of the classical methods. <br>The key insight of this work is that methods which are motivated by first principles, i.e., the underlying engineering decisions that were made when the compression algorithms were developed, are more effective than general methods. By encoding prior knowledge into the design of the algorithm, the flexibility, performance, and/or accuracy are improved at the cost of generality...      
### 27.Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.01737.pdf)
>  Convolutional neural networks have enabled significant improvements in medical image-based disease classification. It has, however, become increasingly clear that these models are susceptible to performance degradation due to spurious correlations and dataset shifts, which may lead to underperformance on underrepresented patient groups, among other problems. In this paper, we compare two classification schemes on the ADNI MRI dataset: a very simple logistic regression model that uses manually selected volumetric features as inputs, and a convolutional neural network trained on 3D MRI data. We assess the robustness of the trained models in the face of varying dataset splits, training set sex composition, and stage of disease. In contrast to earlier work on diagnosing lung diseases based on chest x-ray data, we do not find a strong dependence of model performance for male and female test subjects on the sex composition of the training dataset. Moreover, in our analysis, the low-dimensional model with manually selected features outperforms the 3D CNN, thus emphasizing the need for automatic robust feature extraction methods and the value of manual feature specification (based on prior knowledge) for robustness.      
### 28.Tracking Urbanization in Developing Regions with Remote Sensing Spatial-Temporal Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2204.01736.pdf)
>  Automated tracking of urban development in areas where construction information is not available became possible with recent advancements in machine learning and remote sensing. Unfortunately, these solutions perform best on high-resolution imagery, which is expensive to acquire and infrequently available, making it difficult to scale over long time spans and across large geographies. In this work, we propose a pipeline that leverages a single high-resolution image and a time series of publicly available low-resolution images to generate accurate high-resolution time series for object tracking in urban construction. Our method achieves significant improvement in comparison to baselines using single image super-resolution, and can assist in extending the accessibility and scalability of building construction tracking across the developing world.      
### 29.Robust Stuttering Detection via Multi-task and Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.01735.pdf)
>  By automatic detection and identification of stuttering, speech pathologists can track the progression of disfluencies of persons who stutter (PWS). In this paper, we investigate the impact of multi-task (MTL) and adversarial learning (ADV) to learn robust stutter features. This is the first-ever preliminary study where MTL and ADV have been employed in stuttering identification (SI). We evaluate our system on the SEP-28k stuttering dataset consisting of 20 hours (approx) of data from 385 podcasts. Our methods show promising results and outperform the baseline in various disfluency classes. We achieve up to 10%, 6.78%, and 2% improvement in repetitions, blocks, and interjections respectively over the baseline.      
### 30.Transient motion classification through turbid volumes via parallelized single-photon detection and deep contrastive embedding  [ :arrow_down: ](https://arxiv.org/pdf/2204.01733.pdf)
>  Fast noninvasive probing of spatially varying decorrelating events, such as cerebral blood flow beneath the human skull, is an essential task in various scientific and clinical settings. One of the primary optical techniques used is diffuse correlation spectroscopy (DCS), whose classical implementation uses a single or few single-photon detectors, resulting in poor spatial localization accuracy and relatively low temporal resolution. Here, we propose a technique termed Classifying Rapid decorrelation Events via Parallelized single photon dEtection (CREPE)}, a new form of DCS that can probe and classify different decorrelating movements hidden underneath turbid volume with high sensitivity using parallelized speckle detection from a $32\times32$ pixel SPAD array. We evaluate our setup by classifying different spatiotemporal-decorrelating patterns hidden beneath a 5mm tissue-like phantom made with rapidly decorrelating dynamic scattering media. Twelve multi-mode fibers are used to collect scattered light from different positions on the surface of the tissue phantom. To validate our setup, we generate perturbed decorrelation patterns by both a digital micromirror device (DMD) modulated at multi-kilo-hertz rates, as well as a vessel phantom containing flowing fluid. Along with a deep contrastive learning algorithm that outperforms classic unsupervised learning methods, we demonstrate our approach can accurately detect and classify different transient decorrelation events (happening in 0.1-0.4s) underneath turbid scattering media, without any data labeling. This has the potential to be applied to noninvasively monitor deep tissue motion patterns, for example identifying normal or abnormal cerebral blood flow events, at multi-Hertz rates within a compact and static detection probe.      
### 31.Analyzing the Effects of Handling Data Imbalance on Learned Features from Medical Images by Looking Into the Models  [ :arrow_down: ](https://arxiv.org/pdf/2204.01729.pdf)
>  One challenging property lurking in medical datasets is the imbalanced data distribution, where the frequency of the samples between the different classes is not balanced. Training a model on an imbalanced dataset can introduce unique challenges to the learning problem where a model is biased towards the highly frequent class. Many methods are proposed to tackle the distributional differences and the imbalanced problem. However, the impact of these approaches on the learned features is not well studied. In this paper, we look deeper into the internal units of neural networks to observe how handling data imbalance affects the learned features. We study several popular cost-sensitive approaches for handling data imbalance and analyze the feature maps of the convolutional neural networks from multiple perspectives: analyzing the alignment of salient features with pathologies and analyzing the pathology-related concepts encoded by the networks. Our study reveals differences and insights regarding the trained models that are not reflected by quantitative metrics such as AUROC and AP and show up only by looking at the models through a lens.      
### 32.Generalized Zero Shot Learning For Medical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2204.01728.pdf)
>  In many real world medical image classification settings we do not have access to samples of all possible disease classes, while a robust system is expected to give high performance in recognizing novel test data. We propose a generalized zero shot learning (GZSL) method that uses self supervised learning (SSL) for: 1) selecting anchor vectors of different disease classes; and 2) training a feature generator. Our approach does not require class attribute vectors which are available for natural images but not for medical images. SSL ensures that the anchor vectors are representative of each class. SSL is also used to generate synthetic features of unseen classes. Using a simpler architecture, our method matches a state of the art SSL based GZSL method for natural images and outperforms all methods for medical images. Our method is adaptable enough to accommodate class attribute vectors when they are available for natural images.      
### 33.RestoreX-AI: A Contrastive Approach towards Guiding Image Restoration via Explainable AI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.01719.pdf)
>  Modern applications such as self-driving cars and drones rely heavily upon robust object detection techniques. However, weather corruptions can hinder the object detectability and pose a serious threat to their navigation and reliability. Thus, there is a need for efficient denoising, deraining, and restoration techniques. Generative adversarial networks and transformers have been widely adopted for image restoration. However, the training of these methods is often unstable and time-consuming. Furthermore, when used for object detection (OD), the output images generated by these methods may provide unsatisfactory results despite image clarity. In this work, we propose a contrastive approach towards mitigating this problem, by evaluating images generated by restoration models during and post training. This approach leverages OD scores combined with attention maps for predicting the usefulness of restored images for the OD task. We conduct experiments using two novel use-cases of conditional GANs and two transformer methods that probe the robustness of the proposed approach on multi-weather corruptions in the OD task. Our approach achieves an averaged 178 percent increase in mAP between the input and restored images under adverse weather conditions like dust tornadoes and snowfall. We report unique cases where greater denoising does not improve OD performance and conversely where noisy generated images demonstrate good results. We conclude the need for explainability frameworks to bridge the gap between human and machine perception, especially in the context of robust object detection for autonomous vehicles.      
### 34.Estimating Fine-Grained Noise Model via Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.01716.pdf)
>  Image denoising has achieved unprecedented progress as great efforts have been made to exploit effective deep denoisers. To improve the denoising performance in realworld, two typical solutions are used in recent trends: devising better noise models for the synthesis of more realistic training data, and estimating noise level function to guide non-blind denoisers. In this work, we combine both noise modeling and estimation, and propose an innovative noise model estimation and noise synthesis pipeline for realistic noisy image generation. Specifically, our model learns a noise estimation model with fine-grained statistical noise model in a contrastive manner. Then, we use the estimated noise parameters to model camera-specific noise distribution, and synthesize realistic noisy training data. The most striking thing for our work is that by calibrating noise models of several sensors, our model can be extended to predict other cameras. In other words, we can estimate cameraspecific noise models for unknown sensors with only testing images, without laborious calibration frames or paired noisy/clean data. The proposed pipeline endows deep denoisers with competitive performances with state-of-the-art real noise modeling methods.      
### 35.Exemplar Learning for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.01713.pdf)
>  Medical image annotation typically requires expert knowledge and hence incurs time-consuming and expensive data annotation costs. To reduce this burden, we propose a novel learning scenario, Exemplar Learning (EL), to explore automated learning processes for medical image segmentation from a single annotated image example. This innovative learning task is particularly suitable for medical image segmentation, where all categories of organs can be presented in one single image for annotation all at once. To address this challenging EL task, we propose an Exemplar Learning-based Synthesis Net (ELSNet) framework for medical image segmentation that enables innovative exemplar-based data synthesis, pixel-prototype based contrastive embedding learning, and pseudo-label based exploitation of the unlabeled data. Specifically, ELSNet introduces two new modules for image segmentation: an exemplar-guided synthesis module, which enriches and diversifies the training set by synthesizing annotated samples from the given exemplar, and a pixel-prototype based contrastive embedding module, which enhances the discriminative capacity of the base segmentation model via contrastive self-supervised learning. Moreover, we deploy a two-stage process for segmentation model training, which exploits the unlabeled data with predicted pseudo segmentation labels. To evaluate this new learning framework, we conduct extensive experiments on several organ segmentation datasets and present an in-depth analysis. The empirical results show that the proposed exemplar learning framework produces effective segmentation results.      
### 36.Histogram of Oriented Gradients Meet Deep Learning: A Novel Multi-task Deep Network for Medical Image Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.01712.pdf)
>  We present our novel deep multi-task learning method for medical image segmentation. Existing multi-task methods demand ground truth annotations for both the primary and auxiliary tasks. Contrary to it, we propose to generate the pseudo-labels of an auxiliary task in an unsupervised manner. To generate the pseudo-labels, we leverage Histogram of Oriented Gradients (HOGs), one of the most widely used and powerful hand-crafted features for detection. Together with the ground truth semantic segmentation masks for the primary task and pseudo-labels for the auxiliary task, we learn the parameters of the deep network to minimise the loss of both the primary task and the auxiliary task jointly. We employed our method on two powerful and widely used semantic segmentation networks: UNet and U2Net to train in a multi-task setup. To validate our hypothesis, we performed experiments on two different medical image segmentation data sets. From the extensive quantitative and qualitative results, we observe that our method consistently improves the performance compared to the counter-part method. Moreover, our method is the winner of FetReg Endovis Sub-challenge on Semantic Segmentation organised in conjunction with MICCAI 2021.      
### 37.Single Image Internal Distribution Measurement Using Non-Local Variational Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2204.01711.pdf)
>  Deep learning-based super-resolution methods have shown great promise, especially for single image super-resolution (SISR) tasks. Despite the performance gain, these methods are limited due to their reliance on copious data for model training. In addition, supervised SISR solutions rely on local neighbourhood information focusing only on the feature learning processes for the reconstruction of low-dimensional images. Moreover, they fail to capitalize on global context due to their constrained receptive field. To combat these challenges, this paper proposes a novel image-specific solution, namely non-local variational autoencoder (\texttt{NLVAE}), to reconstruct a high-resolution (HR) image from a single low-resolution (LR) image without the need for any prior training. To harvest maximum details for various receptive regions and high-quality synthetic images, \texttt{NLVAE} is introduced as a self-supervised strategy that reconstructs high-resolution images using disentangled information from the non-local neighbourhood. Experimental results from seven benchmark datasets demonstrate the effectiveness of the \texttt{NLVAE} model. Moreover, our proposed model outperforms a number of baseline and state-of-the-art methods as confirmed through extensive qualitative and quantitative evaluations.      
### 38.MRI-based Multi-task Decoupling Learning for Alzheimer's Disease Detection and MMSE Score Prediction: A Multi-site Validation  [ :arrow_down: ](https://arxiv.org/pdf/2204.01708.pdf)
>  Accurately detecting Alzheimer's disease (AD) and predicting mini-mental state examination (MMSE) score are important tasks in elderly health by magnetic resonance imaging (MRI). Most of the previous methods on these two tasks are based on single-task learning and rarely consider the correlation between them. Since the MMSE score, which is an important basis for AD diagnosis, can also reflect the progress of cognitive impairment, some studies have begun to apply multi-task learning methods to these two tasks. However, how to exploit feature correlation remains a challenging problem for these methods. To comprehensively address this challenge, we propose a MRI-based multi-task decoupled learning method for AD detection and MMSE score prediction. First, a multi-task learning network is proposed to implement AD detection and MMSE score prediction, which exploits feature correlation by adding three multi-task interaction layers between the backbones of the two tasks. Each multi-task interaction layer contains two feature decoupling modules and one feature interaction module. Furthermore, to enhance the generalization between tasks of the features selected by the feature decoupling module, we propose the feature consistency loss constrained feature decoupling module. Finally, in order to exploit the specific distribution information of MMSE score in different groups, a distribution loss is proposed to further enhance the model performance. We evaluate our proposed method on multi-site datasets. Experimental results show that our proposed multi-task decoupled representation learning method achieves good performance, outperforming single-task learning and other existing state-of-the-art methods.      
### 39.Data and Physics Driven Learning Models for Fast MRI -- Fundamentals and Methodologies from CNN, GAN to Attention and Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2204.01706.pdf)
>  Research studies have shown no qualms about using data driven deep learning models for downstream tasks in medical image analysis, e.g., anatomy segmentation and lesion detection, disease diagnosis and prognosis, and treatment planning. However, deep learning models are not the sovereign remedy for medical image analysis when the upstream imaging is not being conducted properly (with artefacts). This has been manifested in MRI studies, where the scanning is typically slow, prone to motion artefacts, with a relatively low signal to noise ratio, and poor spatial and/or temporal resolution. Recent studies have witnessed substantial growth in the development of deep learning techniques for propelling fast MRI. This article aims to (1) introduce the deep learning based data driven techniques for fast MRI including convolutional neural network and generative adversarial network based methods, (2) survey the attention and transformer based models for speeding up MRI reconstruction, and (3) detail the research in coupling physics and data driven models for MRI acceleration. Finally, we will demonstrate through a few clinical applications, explain the importance of data harmonisation and explainable models for such fast MRI techniques in multicentre and multi-scanner studies, and discuss common pitfalls in current research and recommendations for future research directions.      
### 40.Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI  [ :arrow_down: ](https://arxiv.org/pdf/2204.01702.pdf)
>  Precision medicine for chronic diseases such as multiple sclerosis (MS) involves choosing a treatment which best balances efficacy and side effects/preferences for individual patients. Making this choice as early as possible is important, as delays in finding an effective therapy can lead to irreversible disability accrual. To this end, we present the first deep neural network model for individualized treatment decisions from baseline magnetic resonance imaging (MRI) (with clinical information if available) for MS patients. Our model (a) predicts future new and enlarging T2 weighted (NE-T2) lesion counts on follow-up MRI on multiple treatments and (b) estimates the conditional average treatment effect (CATE), as defined by the predicted future suppression of NE-T2 lesions, between different treatment options relative to placebo. Our model is validated on a proprietary federated dataset of 1817 multi-sequence MRIs acquired from MS patients during four multi-centre randomized clinical trials. Our framework achieves high average precision in the binarized regression of future NE-T2 lesions on five different treatments, identifies heterogeneous treatment effects, and provides a personalized treatment recommendation that accounts for treatment-associated risk (e.g. side effects, patient preference, administration difficulties).      
### 41.ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2204.02389.pdf)
>  Objects play a crucial role in our everyday activities. Though multisensory object-centric learning has shown great potential lately, the modeling of objects in prior work is rather unrealistic. ObjectFolder 1.0 is a recent dataset that introduces 100 virtualized objects with visual, acoustic, and tactile sensory data. However, the dataset is small in scale and the multisensory data is of limited quality, hampering generalization to real-world scenarios. We present ObjectFolder 2.0, a large-scale, multisensory dataset of common household objects in the form of implicit neural representations that significantly enhances ObjectFolder 1.0 in three aspects. First, our dataset is 10 times larger in the amount of objects and orders of magnitude faster in rendering time. Second, we significantly improve the multisensory rendering quality for all three modalities. Third, we show that models learned from virtual objects in our dataset successfully transfer to their real-world counterparts in three challenging tasks: object scale estimation, contact localization, and shape reconstruction. ObjectFolder 2.0 offers a new path and testbed for multisensory learning in computer vision and robotics. The dataset is available at <a class="link-external link-https" href="https://github.com/rhgao/ObjectFolder" rel="external noopener nofollow">this https URL</a>.      
### 42.Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs  [ :arrow_down: ](https://arxiv.org/pdf/2204.02362.pdf)
>  Neuroscience and neurotechnology are currently being revolutionized by artificial intelligence (AI) and machine learning. AI is widely used to study and interpret neural signals (analytical applications), assist people with disabilities (prosthetic applications), and treat underlying neurological symptoms (therapeutic applications). In this brief, we will review the emerging opportunities of on-chip AI for the next-generation implantable brain-machine interfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major technological challenges for the effectiveness of AI models will be discussed. Finally, we will present algorithmic and IC design solutions to enable a new generation of AI-enhanced and high-channel-count BMIs.      
### 43.How Information on Acoustic Scenes and Sound Events Mutually Benefits Event Detection and Scene Classification Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2204.02279.pdf)
>  Acoustic scene classification (ASC) and sound event detection (SED) are fundamental tasks in environmental sound analysis, and many methods based on deep learning have been proposed. Considering that information on acoustic scenes and sound events helps SED and ASC mutually, some researchers have proposed a joint analysis of acoustic scenes and sound events by multitask learning (MTL). However, conventional works have not investigated in detail how acoustic scenes and sound events mutually benefit SED and ASC. We, therefore, investigate the impact of information on acoustic scenes and sound events on the performance of SED and ASC by using domain adversarial training based on a gradient reversal layer (GRL) or model training with fake labels. Experimental results obtained using the TUT Acoustic Scenes 2016/2017 and TUT Sound Events 2016/2017 show that pieces of information on acoustic scenes and sound events are effectively used to detect sound events and classify acoustic scenes, respectively. Moreover, upon comparing GRL- and fake-label-based methods with single-task-based ASC and SED methods, single-task-based methods are found to achieve better performance. This result implies that even when using single-task-based ASC and SED methods, information on acoustic scenes may be implicitly utilized for SED and vice versa.      
### 44.Repeat after me: Self-supervised learning of acoustic-to-articulatory mapping by vocal imitation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02269.pdf)
>  We propose a computational model of speech production combining a pre-trained neural articulatory synthesizer able to reproduce complex speech stimuli from a limited set of interpretable articulatory parameters, a DNN-based internal forward model predicting the sensory consequences of articulatory commands, and an internal inverse model based on a recurrent neural network recovering articulatory commands from the acoustic speech input. Both forward and inverse models are jointly trained in a self-supervised way from raw acoustic-only speech data from different speakers. The imitation simulations are evaluated objectively and subjectively and display quite encouraging performances.      
### 45.Designing Interference-Immune Doppler-TolerantWaveforms for Automotive Radar Applications  [ :arrow_down: ](https://arxiv.org/pdf/2204.02236.pdf)
>  Dynamic target detection using FMCW waveform is challenging in the presence of interference for different radar applications. Degradation in SNR is irreparable and interference is difficult to mitigate in time and frequency domain. In this paper, a waveform design problem is addressed using the Majorization-Minimization (MM) framework by considering PSL/ISL cost functions, resulting in a code sequence with Doppler-tolerance characteristics of an FMCW waveform and interference immune characteristics of a tailored PMCW waveform (unique phase code + minimal ISL/PSL). The optimal design sequences possess polynomial phase behavior of degree Q amongst its sub-sequences and obtain optimal ISL and PSL solutions with guaranteed convergence. By tuning the optimization parameters such as degree Q of the polynomial phase behavior, sub-sequence length M and the total number of sub-sequences L, the optimized sequences can be as Doppler tolerant as FMCW waveform in one end, and they can possess small cross-correlation values similar to random-phase sequences in PMCW waveform on the other end. If required in the event of acute interference, new codes can be generated in the runtime which have low cross-correlation with the interferers. The performance analysis indicates that the proposed method outperforms the state-of-the-art counterparts.      
### 46.A New Correction to the Rytov Approximation for Strongly Scattering Lossy Media  [ :arrow_down: ](https://arxiv.org/pdf/2204.02180.pdf)
>  We propose a correction to the conventional Rytov approximation (RA) and investigate its performance for predicting wave scattering under strong scattering conditions. An important motivation for the correction and investigation is to help in the development of better models for inverse scattering. The correction is based upon incorporating the high frequency theory of inhomogeneous wave propagation for lossy media into the RA formulation. We denote the technique as the extended Rytov approximation for lossy media (xRA-LM). xRA-LM significantly improves upon existing non-iterative linear scattering approximations such as RA and the Born approximation (BA) by providing a validity range for the permittivity of the objects of up to 50 times greater than RA. We demonstrate the technique by providing results for predicting wave scattering from piece-wise homogeneous scatterers in a two-dimensional (2D) region. Numerical investigation of the performance of xRA-LM for solving direct problem show that xRA-LM can accurately predict wave scattering by electrically large, low-loss scatterers with high complex permittivity ($\epsilon_r&gt; 50+5j$). To the best of our knowledge, this is the first non-iterative, linear approximate wave scattering model which has a large validity range in terms of both permittivity and electrical size.      
### 47.AILTTS: Adversarial Learning of Intermediate Acoustic Feature for End-to-End Lightweight Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2204.02172.pdf)
>  The quality of end-to-end neural text-to-speech (TTS) systems highly depends on the reliable estimation of intermediate acoustic features from text inputs. To reduce the complexity of the speech generation process, several non-autoregressive TTS systems directly find a mapping relationship between text and waveforms. However, the generation quality of these system is unsatisfactory due to the difficulty in modeling the dynamic nature of prosodic information. In this paper, we propose an effective prosody predictor that successfully replicates the characteristics of prosodic features extracted from mel-spectrograms. Specifically, we introduce a generative model-based conditional discriminator to enable the estimated embeddings have highly informative prosodic features, which significantly enhances the expressiveness of generated speech. Since the estimated embeddings obtained by the proposed method are highly correlated with acoustic features, the time-alignment of input texts and intermediate features is greatly simplified, which results in faster convergence. Our proposed model outperforms several publicly available models based on various objective and subjective evaluation metrics, even using a relatively small number of parameters.      
### 48.Systematic Unsupervised Recycled Field-Programmable Gate Array Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.02159.pdf)
>  With the expansion of the semiconductor supply chain, the use of recycled field-programmable gate arrays (FPGAs) has become a serious concern. Several methods for detecting recycled FPGAs by analyzing the ring oscillator (RO) frequencies have been proposed; however, most assume the known fresh FPGAs (KFFs) as the training data in machine-learning-based classification. In this study, we propose a novel recycled FPGA detection method based on an unsupervised anomaly detection scheme when there are few or no KFFs available. As the RO frequencies in the neighboring logic blocks on an FPGA are similar because of systematic process variation, our method compares the RO frequencies and does not require KFFs. The proposed method efficiently identifies recycled FPGAs through outlier detection using direct density ratio estimation. Experiments using Xilinx Artix-7 FPGAs demonstrate that the proposed method successfully distinguishes recycled FPGAs from 35 fresh FPGAs. In contrast, a conventional recycled FPGA detection method results in certain misclassification.      
### 49.UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022  [ :arrow_down: ](https://arxiv.org/pdf/2204.02152.pdf)
>  We present the UTokyo-SaruLab mean opinion score (MOS) prediction system submitted to VoiceMOS Challenge 2022. The challenge is to predict the MOS values of speech samples collected from previous Blizzard Challenges and Voice Conversion Challenges for two tracks: a main track for in-domain prediction and an out-of-domain (OOD) track for which there is less labeled data from different listening tests. Our system is based on ensemble learning of strong and weak learners. Strong learners incorporate several improvements to the previous fine-tuning models of self-supervised learning (SSL) models, while weak learners use basic machine-learning methods to predict scores from SSL features. In the Challenge, our system had the highest score on several metrics for both the main and OOD tracks. In addition, we conducted ablation studies to investigate the effectiveness of our proposed methods.      
### 50.RaDur: A Reference-aware and Duration-robust Network for Target Sound Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.02143.pdf)
>  Target sound detection (TSD) aims to detect the target sound from a mixture audio given the reference information. Previous methods use a conditional network to extract a sound-discriminative embedding from the reference audio, and then use it to detect the target sound from the mixture audio. However, the network performs much differently when using different reference audios (e.g. performs poorly for noisy and short-duration reference audios), and tends to make wrong decisions for transient events (i.e. shorter than $1$ second). To overcome these problems, in this paper, we present a reference-aware and duration-robust network (RaDur) for TSD. More specifically, in order to make the network more aware of the reference information, we propose an embedding enhancement module to take into account the mixture audio while generating the embedding, and apply the attention pooling to enhance the features of target sound-related frames and weaken the features of noisy frames. In addition, a duration-robust focal loss is proposed to help model different-duration events. To evaluate our method, we build two TSD datasets based on UrbanSound and Audioset. Extensive experiments show the effectiveness of our methods.      
### 51.MetaAudio: A Few-Shot Audio Classification Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2204.02121.pdf)
>  Currently available benchmarks for few-shot learning (machine learning with few training examples) are limited in the domains they cover, primarily focusing on image classification. This work aims to alleviate this reliance on image-based benchmarks by offering the first comprehensive, public and fully reproducible audio based alternative, covering a variety of sound domains and experimental settings. We compare the few-shot classification performance of a variety of techniques on seven audio datasets (spanning environmental sounds to human-speech). Extending this, we carry out in-depth analyses of joint training (where all datasets are used during training) and cross-dataset adaptation protocols, establishing the possibility of a generalised audio few-shot classification algorithm. Our experimentation shows gradient-based meta-learning methods such as MAML and Meta-Curvature consistently outperform both metric and baseline methods. We also demonstrate that the joint training routine helps overall generalisation for the environmental sound databases included, as well as being a somewhat-effective method of tackling the cross-dataset/domain setting.      
### 52.Dynamic Federations for 6G Cell-Free Networking: Concepts and Terminology  [ :arrow_down: ](https://arxiv.org/pdf/2204.02102.pdf)
>  Cell-Free networking is one of the prime candidates for 6G networks. Despite being capable of providing the 6G needs, practical limitations and considerations are often neglected in current research. In this work, we introduce the concept of federations to dynamically scale and select the best set of resources, e.g., antennas, computing and data resources, to serve a given application. Next to communication, 6G systems are expected to provide also wireless powering, positioning and sensing, further increasing the complexity of such systems. Therefore, each federation is self-managing and is distributed over the area in a cell-free manner. Next to the dynamic federations, new accompanying terminology is proposed to design cell-free systems taking into account practical limitations such as time synchronization and distributed processing. We conclude with an illustration with four federations, serving distinct applications, and introduce two new testbeds to study these architectures and concepts.      
### 53.Non-Linear Speech coding with MLP, RBF and Elman based prediction  [ :arrow_down: ](https://arxiv.org/pdf/2204.02101.pdf)
>  In this paper we propose a nonlinear scalar predictor based on a combination of Multi Layer Perceptron, Radial Basis Functions and Elman networks. This system is applied to speech coding in an ADPCM backward scheme. The combination of this predictors improves the results of one predictor alone. A comparative study of this three neural networks for speech prediction is also presented.      
### 54.VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices  [ :arrow_down: ](https://arxiv.org/pdf/2204.02090.pdf)
>  In this paper, we address the problem of lip-voice synchronisation in videos containing human face and voice. Our approach is based on determining if the lips motion and the voice in a video are synchronised or not, depending on their audio-visual correspondence score. We propose an audio-visual cross-modal transformer-based model that outperforms several baseline models in the audio-visual synchronisation task on the standard lip-reading speech benchmark dataset LRS2. While the existing methods focus mainly on the lip synchronisation in speech videos, we also consider the special case of singing voice. Singing voice is a more challenging use case for synchronisation due to sustained vowel sounds. We also investigate the relevance of lip synchronisation models trained on speech datasets in the context of singing voice. Finally, we use the frozen visual features learned by our lip synchronisation model in the singing voice separation task to outperform a baseline audio-visual model which was trained end-to-end. The demos, source code, and the pre-trained model will be made available on <a class="link-external link-https" href="https://ipcv.github.io/VocaLiST/" rel="external noopener nofollow">this https URL</a>      
### 55.A Two-student Learning Framework for Mixed Supervised Target Sound Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.02088.pdf)
>  Target sound detection (TSD) aims to detect the target sound from mixture audio given the reference information. Previous work shows that a good detection performance relies on fully-annotated data. However, collecting fully-annotated data is labor-extensive. Therefore, we consider TSD with mixed supervision, which learns novel categories (target domain) using weak annotations with the help of full annotations of existing base categories (source domain). We propose a novel two-student learning framework, which contains two mutual helping student models ($\mathit{s\_student}$ and $\mathit{w\_student}$) that learn from fully- and weakly-annotated datasets, respectively. Specifically, we first propose a frame-level knowledge distillation strategy to transfer the class-agnostic knowledge from $\mathit{s\_student}$ to $\mathit{w\_student}$. After that, a pseudo supervised (PS) training is designed to transfer the knowledge from $\mathit{w\_student}$ to $\mathit{s\_student}$. Lastly, an adversarial training strategy is proposed, which aims to align the data distribution between source and target domains. To evaluate our method, we build three TSD datasets based on UrbanSound and Audioset. Experimental results show that our methods offer about 8\% improvement in event-based F score.      
### 56.Real-time Hyperspectral Imaging in Hardware via Trained Metasurface Encoders  [ :arrow_down: ](https://arxiv.org/pdf/2204.02084.pdf)
>  Hyperspectral imaging has attracted significant attention to identify spectral signatures for image classification and automated pattern recognition in computer vision. State-of-the-art implementations of snapshot hyperspectral imaging rely on bulky, non-integrated, and expensive optical elements, including lenses, spectrometers, and filters. These macroscopic components do not allow fast data processing for, e.g real-time and high-resolution videos. This work introduces Hyplex, a new integrated architecture addressing the limitations discussed above. Hyplex is a CMOS-compatible, fast hyperspectral camera that replaces bulk optics with nanoscale metasurfaces inversely designed through artificial intelligence. Hyplex does not require spectrometers but makes use of conventional monochrome cameras, opening up the possibility for real-time and high-resolution hyperspectral imaging at inexpensive costs. Hyplex exploits a model-driven optimization, which connects the physical metasurfaces layer with modern visual computing approaches based on end-to-end training. We design and implement a prototype version of Hyplex and compare its performance against the state-of-the-art for typical imaging tasks such as spectral reconstruction and semantic segmentation. In all benchmarks, Hyplex reports the smallest reconstruction error. We additionally present what is, to the best of our knowledge, the largest publicly available labeled hyperspectral dataset for semantic segmentation.      
### 57.Real-time Online Multi-Object Tracking in Compressed Domain  [ :arrow_down: ](https://arxiv.org/pdf/2204.02081.pdf)
>  Recent online Multi-Object Tracking (MOT) methods have achieved desirable tracking performance. However, the tracking speed of most existing methods is rather slow. Inspired from the fact that the adjacent frames are highly relevant and redundant, we divide the frames into key and non-key frames respectively and track objects in the compressed domain. For the key frames, the RGB images are restored for detection and data association. To make data association more reliable, an appearance Convolutional Neural Network (CNN) which can be jointly trained with the detector is proposed. For the non-key frames, the objects are directly propagated by a tracking CNN based on the motion information provided in the compressed domain. Compared with the state-of-the-art online MOT methods,our tracker is about 6x faster while maintaining a comparable tracking performance.      
### 58.On representation formulas for optimal control: A Lagrangian perspective  [ :arrow_down: ](https://arxiv.org/pdf/2204.02050.pdf)
>  In this paper, we study representation formulas for finite-horizon optimal control problems with or without state constraints, unifying two different viewpoints: the Lagrangian and dynamic programming (DP) frameworks. In a recent work [1], the generalized Lax formula is obtained via DP for optimal control problems with state constraints and nonlinear systems. We revisit the formula from the Lagrangian perspective to provide a unified framework for understanding and implementing the nontrivial representation of the value function. Our simple derivation makes direct use of the Lagrangian formula from the theory of Hamilton-Jacobi (HJ) equations. We also discuss a rigorous way to construct an optimal control using a $\delta$-net, as well as a numerical scheme for controller synthesis via convex optimization.      
### 59.On the Relevance of Bandwidth Extension for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02040.pdf)
>  In this paper, we consider the effect of a bandwidth extension of narrow-band speech signals (0.3-3.4 kHz) to 0.3-8 kHz on speaker verification. Using covariance matrix based verification systems together with detection error trade-off curves, we compare the performance between systems operating on narrow-band, wide-band (0-8 kHz), and bandwidth-extended speech. The experiments were conducted using different short-time spectral parameterizations derived from microphone and ISDN speech databases. The studied bandwidth-extension algorithm did not introduce artifacts that affected the speaker verification task, and we achieved improvements between 1 and 10 percent (depending on the model order) over the verification system designed for narrow-band speech when mel-frequency cepstral coefficients for the short-time spectral parameterization were used.      
### 60.A Complementary Joint Training Approach Using Unpaired Speech and Text for Low-Resource Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.02023.pdf)
>  Unpaired data has shown to be beneficial for low-resource automatic speech recognition~(ASR), which can be involved in the design of hybrid models with multi-task training or language model dependent pre-training. In this work, we leverage unpaired data to train a general sequence-to-sequence model. Unpaired speech and text are used in the form of data pairs by generating the corresponding missing parts in prior to model training. Inspired by the complementarity of speech-PseudoLabel pair and SynthesizedAudio-text pair in both acoustic features and linguistic features, we propose a complementary joint training~(CJT) method that trains a model alternatively with two data pairs. Furthermore, label masking for pseudo-labels and gradient restriction for synthesized audio are proposed to further cope with the deviations from real data, termed as CJT++. Experimental results show that compared to speech-only training, the proposed basic CJT achieves great performance improvements on clean/other test sets, and the CJT++ re-training yields further performance enhancements. It is also apparent that the proposed method outperforms the wav2vec2.0 model with the same model size and beam size, particularly in extreme low-resource cases.      
### 61.Compute- and Data-Intensive Networks: The Key to the Metaverse  [ :arrow_down: ](https://arxiv.org/pdf/2204.02001.pdf)
>  The worlds of computing, communication, and storage have for a long time been treated separately, and even the recent trends of cloud computing, distributed computing, and mobile edge computing have not fundamentally changed the role of networks, still designed to move data between end users and pre-determined computation nodes, without true optimization of the end-to-end compute-communication process. However, the emergence of Metaverse applications, where users consume multimedia experiences that result from the real-time combination of distributed live sources and stored digital assets, has changed the requirements for, and possibilities of, systems that provide distributed caching, computation, and communication. We argue that the real-time interactive nature and high demands on data storage, streaming rates, and processing power of Metaverse applications will accelerate the merging of the cloud into the network, leading to highly-distributed tightly-integrated compute- and data-intensive networks becoming universal compute platforms for next-generation digital experiences. In this paper, we first describe the requirements of Metaverse applications and associated supporting infrastructure, including relevant use cases. We then outline a comprehensive cloud network flow mathematical framework, designed for the end-to-end optimization and control of such systems, and show numerical results illustrating its promising role for the efficient operation of Metaverse-ready networks.      
### 62.Audio-visual multi-channel speech separation, dereverberation and recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.01977.pdf)
>  Despite the rapid advance of automatic speech recognition (ASR) technologies, accurate recognition of cocktail party speech characterised by the interference from overlapping speakers, background noise and room reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, audio-visual speech enhancement techniques have been developed, although predominantly targeting overlapping speech separation and recognition tasks. In this paper, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all three stages of the system is proposed. The advantage of the additional visual modality over using audio only is demonstrated on two neural dereverberation approaches based on DNN-WPE and spectral mapping respectively. The learning cost function mismatch between the separation and dereverberation models and their integration with the back-end recognition system is minimised using fine-tuning on the MSE and LF-MMI criteria. Experiments conducted on the LRS2 dataset suggest that the proposed audio-visual multi-channel speech separation, dereverberation and recognition system outperforms the baseline audio-visual multi-channel speech separation and recognition system containing no dereverberation module by a statistically significant word error rate (WER) reduction of 2.06% absolute (8.77% relative).      
### 63.Time Efficient Joint UAV-BS Deployment and User Association based on Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.01966.pdf)
>  This paper proposes a time-efficient mechanism to decrease the on-line computing time of solving the joint unmanned aerial vehicle base station (UAV-BS) deployment and user/sensor association (UDUA) problem aiming at maximizing the downlink sum transmission throughput. The joint UDUA problem is decoupled into two sub-problems: one is the user association sub-problem, which gets the optimal matching strategy between aerial and ground nodes for certain UAV-BS positions; and the other is the UAV-BS deployment sub-problem trying to find the best position combination of the UAV-BSs that make the solution of the first sub-problem optimal among all the possible position combinations of the UAV-BSs. In the proposed mechanism, we transform the user association sub-problem into an equivalent bipartite matching problem and solve it using the Kuhn-Munkres algorithm. For the UAV-BS deployment sub-problem, we theoretically prove that adopting the best UAV-BS deployment strategy of a previous user distribution for each new user distribution will introduce little performance decline compared with the new user distribution's ground true best strategy if the two user distributions are similar enough. Based on our mathematical analyses, the similarity level between user distributions is well defined and becomes the key to solve the second sub-problem. Numerical results indicate that the proposed UDUA mechanism can achieve near-optimal system performance in terms of average downlink sum transmission throughput and failure rate with enormously reduced computing time compared with benchmark approaches.      
### 64.Application of a Spectral Method to Simulate Quasi-Three-Dimensional Underwater Acoustic Fields  [ :arrow_down: ](https://arxiv.org/pdf/2204.01954.pdf)
>  The solution and synthesis of quasi-three-dimensional sound fields have always been core issues in computational ocean acoustics. Traditionally, finite difference algorithms have been employed to solve these problems. In this paper, a novel numerical algorithm based on the spectral method is devised. The quasi-three-dimensional problem is transformed into a problem resembling a two-dimensional line source using an integral transformation strategy. Then, a stair-step approximation is adopted to address the range dependence of the two-dimensional problem; because this approximation is essentially a discretization, the range-dependent two-dimensional problem is further simplified into a one-dimensional problem. Finally, we apply the Chebyshev--Tau spectral method to accurately solve the one-dimensional problem. We present the corresponding numerical program for the proposed algorithm and describe some representative numerical examples. The simulation results ultimately verify the reliability and capability of the proposed algorithm.      
### 65.Control Barrier Function Based Design of Gradient Flows for Constrained Nonlinear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2204.01930.pdf)
>  This paper considers the problem of designing a continuous time dynamical system to solve constrained nonlinear optimization problems such that the feasible set is forward invariant and asymptotically stable. The invariance of the feasible set makes the dynamics anytime, when viewed as an algorithm, meaning that it is guaranteed to return a feasible solution regardless of when it is terminated. The system is obtained by augmenting the gradient flow of the objective function with inputs, then designing a feedback controller to keep the state evolution within the feasible set using techniques from the theory of control barrier functions. The equilibria of the system correspond exactly to critical points of the optimization problem. Since the state of the system corresponds to the primal optimizer, and the steady-state input at equilibria corresponds to the dual optimizer, the method can be interpreted as a primal-dual approach. The resulting closed-loop system is locally Lipschitz continuous, so classical solutions to the system exist. We characterize conditions under which local minimizers are Lyapunov stable, drawing connections between various constraint qualification conditions and the stability of the local minimizer. The algorithm is compared to other continuous time methods for optimization.      
### 66.Learning to Adapt to Domain Shifts with Few-shot Samples in Anomalous Sound Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.01905.pdf)
>  Anomaly detection has many important applications, such as monitoring industrial equipment. Despite recent advances in anomaly detection with deep-learning methods, it is unclear how existing solutions would perform under out-of-distribution scenarios, e.g., due to shifts in machine load or environmental noise. Grounded in the application of machine health monitoring, we propose a framework that adapts to new conditions with few-shot samples. Building upon prior work, we adopt a classification-based approach for anomaly detection and show its equivalence to mixture density estimation of the normal samples. We incorporate an episodic training procedure to match the few-shot setting during inference. We define multiple auxiliary classification tasks based on meta-information and leverage gradient-based meta-learning to improve generalization to different shifts. We evaluate our proposed method on a recently-released dataset of audio measurements from different machine types. It improved upon two baselines by around 10% and is on par with best-performing model reported on the dataset.      
### 67.Outage Performance of RIS-aided Cooperative FD-SWIPT-NOMA in Nakagami-m Channels  [ :arrow_down: ](https://arxiv.org/pdf/2204.01900.pdf)
>  In this work we {derive new} analytical expressions for the outage probability (OP) of the downlink (DL) cooperative full-duplex (FD) simultaneous wireless information power transfer (SWIPT) non-orthogonal multiple access (NOMA) system aided by reconfigurable intelligent surfaces (RIS). The expressions for both the strongest and weakest NOMA users are devised assuming Nakagami-$m$ channel fading. The derived analytical OP expressions are simple to compute yet accurate for a wide range of RIS passive elements configurations, energy harvesting (EH) coefficient, and residual self-interference (SI) levels, being extensively validated by numerical simulations, demonstrating the correctness and accuracy of the proposed analytical method. The OP expressions reveal how paramount is to mitigate the SI in the FD relay mode, since for reasonable values of residual SI coefficient ($\bar{\omega}\geq -13$dB), it is notable its detrimental effect over the system performance; hence, new SI reduction methods for FD relays are useful for low number of passive elements. Also, applying the proposed OP expressions to predict the behaviour of the RIS-NOMA system equipped with a higher number of passive elements ($N\geq 30$) reveals a substantial reduction of the SI effect, motivating the implementation of the cooperative FD communications. Furthermore, we found the asymptotic behavior of outage probability of both clustered users, as well as the equal diversity order for both users, given by $\frac{N\mu^2}{2-2\mu^2}$ if the fraction of the harvest energy $\rho =0$ or $0$ if $\rho\neq0$, indicating the influence of channel parameters and number of RIS elements in the performance.      
### 68.Deliberation Model for On-Device Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2204.01893.pdf)
>  We propose a novel deliberation-based approach to end-to-end (E2E) spoken language understanding (SLU), where a streaming automatic speech recognition (ASR) model produces the first-pass hypothesis and a second-pass natural language understanding (NLU) component generates the semantic parse by conditioning on both ASR's text and audio embeddings. By formulating E2E SLU as a generalized decoder, our system is able to support complex compositional semantic structures. Furthermore, the sharing of parameters between ASR and NLU makes the system especially suitable for resource-constrained (on-device) environments; our proposed approach consistently outperforms strong pipeline NLU baselines by 0.82% to 1.34% across various operating points on the spoken version of the TOPv2 dataset. We demonstrate that the fusion of text and audio features, coupled with the system's ability to rewrite the first-pass hypothesis, makes our approach more robust to ASR errors. Finally, we show that our approach can significantly reduce the degradation when moving from natural speech to synthetic speech training, but more work is required to make text-to-speech (TTS) a viable solution for scaling up E2E SLU.      
### 69.Non-Euclidean Monotone Operator Theory with Applications to Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.01877.pdf)
>  We provide a novel transcription of monotone operator theory to the non-Euclidean finite-dimensional spaces $\ell_1$ and $\ell_{\infty}$. We first establish properties of mappings which are monotone with respect to the non-Euclidean norms $\ell_1$ or $\ell_{\infty}$. In analogy with their Euclidean counterparts, mappings which are monotone with respect to a non-Euclidean norm are amenable to numerous algorithms for computing their zeros. We demonstrate that several classic iterative methods for computing zeros of monotone operators are directly applicable in the non-Euclidean framework. We present a case-study in the equilibrium computation of recurrent neural networks and demonstrate that casting the computation as a suitable operator splitting problem improves convergence rates.      
### 70.WiFiEye -- Seeing over WiFi Made Accessible  [ :arrow_down: ](https://arxiv.org/pdf/2204.01830.pdf)
>  While commonly used for communication purposes, an increasing number of recent studies consider WiFi for sensing. In particular, wireless signals are altered (e.g., reflected and attenuated) by the human body and objects in the environment. This can be perceived by an observer to infer information on human activities or changes in the environment and, hence, to "see" over WiFi. Until now, works on WiFi-based sensing have resulted in a set of custom software tools - each designed for a specific purpose. Moreover, given how scattered the literature is, it is difficult to even identify all steps/functions necessary to build a basic system for WiFi-based sensing. This has led to a high entry barrier, hindering further research in this area. There has been no effort to integrate these tools or to build a general software framework that can serve as the basis for further research, e.g., on using machine learning to interpret the altered WiFi signals. To address this issue, in this paper, we propose WiFiEye - a generic software framework that makes all necessary steps/functions available "out of the box". This way, WiFiEye allows researchers to easily bootstrap new WiFi-based sensing applications, thereby, focusing on research rather than on implementation aspects. To illustrate WiFiEye's workflow, we present a case study on WiFi-based human activity recognition.      
### 71.Lightweight HDR Camera ISP for Robust Perception in Dynamic Illumination Conditions via Fourier Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.01795.pdf)
>  The limited dynamic range of commercial compact camera sensors results in an inaccurate representation of scenes with varying illumination conditions, adversely affecting image quality and subsequently limiting the performance of underlying image processing algorithms. Current state-of-the-art (SoTA) convolutional neural networks (CNN) are developed as post-processing techniques to independently recover under-/over-exposed images. However, when applied to images containing real-world degradations such as glare, high-beam, color bleeding with varying noise intensity, these algorithms amplify the degradations, further degrading image quality. We propose a lightweight two-stage image enhancement algorithm sequentially balancing illumination and noise removal using frequency priors for structural guidance to overcome these limitations. Furthermore, to ensure realistic image quality, we leverage the relationship between frequency and spatial domain properties of an image and propose a Fourier spectrum-based adversarial framework (AFNet) for consistent image enhancement under varying illumination conditions. While current formulations of image enhancement are envisioned as post-processing techniques, we examine if such an algorithm could be extended to integrate the functionality of the Image Signal Processing (ISP) pipeline within the camera sensor benefiting from RAW sensor data and lightweight CNN architecture. Based on quantitative and qualitative evaluations, we also examine the practicality and effects of image enhancement techniques on the performance of common perception tasks such as object detection and semantic segmentation in varying illumination conditions.      
### 72.GWA: A Large High-Quality Acoustic Dataset for Audio Processing  [ :arrow_down: ](https://arxiv.org/pdf/2204.01787.pdf)
>  We present the Geometric-Wave Acoustic (GWA) dataset, a large-scale audio dataset of over 2 million synthetic room impulse responses (IRs) and their corresponding detailed geometric and simulation configurations. Our dataset samples acoustic environments from over 6.8K high-quality diverse and professionally designed houses represented as semantically labeled 3D meshes. We also present a novel real-world acoustic materials assignment scheme based on semantic matching that uses a sentence transformer model. We compute high-quality impulse responses corresponding to accurate low-frequency and high-frequency wave effects by automatically calibrating geometric acoustic ray-tracing with a finite-difference time-domain wave solver. We demonstrate the higher accuracy of our IRs by comparing with recorded IRs from complex real-world environments. The code and the full dataset will be released at the time of publication. Moreover, we highlight the benefits of GWA on audio deep learning tasks such as automated speech recognition, speech enhancement, and speech separation. We observe significant improvement over prior synthetic IR datasets in all tasks due to using our dataset.      
### 73.Face Recognition In Children: A Longitudinal Study  [ :arrow_down: ](https://arxiv.org/pdf/2204.01760.pdf)
>  The lack of high fidelity and publicly available longitudinal children face datasets is one of the main limiting factors in the development of face recognition systems for children. In this work, we introduce the Young Face Aging (YFA) dataset for analyzing the performance of face recognition systems over short age-gaps in children. We expand previous work by comparing YFA with several publicly available cross-age adult datasets to quantify the effects of short age-gap in adults and children. Our analysis confirms a statistically significant and matcher independent decaying relationship between the match scores of ArcFace-Focal, MagFace, and Facenet matchers and the age-gap between the gallery and probe images in children, even at the short age-gap of 6 months. However, our result indicates that the low verification performance reported in previous work might be due to the intra-class structure of the matcher and the lower quality of the samples. Our experiment using YFA and a state-of-the-art, quality-aware face matcher (MagFace) indicates 98.3% and 94.9% TAR at 0.1% FAR over 6 and 36 Months age-gaps, respectively, suggesting that face recognition may be feasible for children for age-gaps of up to three years.      
### 74.Gan-Based Joint Activity Detection and Channel Estimation For Grant-free Random Access  [ :arrow_down: ](https://arxiv.org/pdf/2204.01731.pdf)
>  Joint activity detection and channel estimation (JADCE) for grant-free random access is a critical issue that needs to be addressed to support massive connectivity in IoT networks. However, the existing model-free learning method can only achieve either activity detection or channel estimation, but not both. In this paper, we propose a novel model-free learning method based on generative adversarial network (GAN) to tackle the JADCE problem. We adopt the U-net architecture to build the generator rather than the standard GAN architecture, where a pre-estimated value that contains the activity information is adopted as input to the generator. By leveraging the properties of the pseudoinverse, the generator is refined by using an affine projection and a skip connection to ensure the output of the generator is consistent with the measurement. Moreover, we build a two-layer fully-connected neural network to design pilot matrix for reducing the impact of receiver noise. Simulation results show that the proposed method outperforms the existing methods in high SNR regimes, as both data consistency projection and pilot matrix optimization improve the learning ability.      
### 75.Lip to Speech Synthesis with Visual Context Attentional GAN  [ :arrow_down: ](https://arxiv.org/pdf/2204.01726.pdf)
>  In this paper, we propose a novel lip-to-speech generative adversarial network, Visual Context Attentional GAN (VCA-GAN), which can jointly model local and global lip movements during speech synthesis. Specifically, the proposed VCA-GAN synthesizes the speech from local lip visual features by finding a mapping function of viseme-to-phoneme, while global visual context is embedded into the intermediate layers of the generator to clarify the ambiguity in the mapping induced by homophene. To achieve this, a visual context attention module is proposed where it encodes global representations from the local visual features, and provides the desired global visual context corresponding to the given coarse speech representation to the generator through audio-visual attention. In addition to the explicit modelling of local and global visual representations, synchronization learning is introduced as a form of contrastive learning that guides the generator to synthesize a speech in sync with the given input lip movements. Extensive experiments demonstrate that the proposed VCA-GAN outperforms existing state-of-the-art and is able to effectively synthesize the speech from multi-speaker that has been barely handled in the previous works.      
