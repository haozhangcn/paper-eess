# ArXiv eess --Thu, 7 Apr 2022
### 1.Data-driven Robust LQR with Multiplicative Noise via System Level Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.02883.pdf)
>  This paper aims to develop a data-driven method for solving the closed-loop state-feedback control of a discrete-time LQR problem for systems affected by multiplicative norm bounded model uncertainty. To synthesize a tractable robust state feedback policy, first, we adopt the recently developed system-level synthesis (SLS) framework to reformulate the LQR control design closed-loop system responses rather than the control gain. In many situations, however, the solution to this worst-case optimization problem may be too conservative since it sets out to enforce the design constraints for every possible value of the uncertainty. To deal with this issue, we reformulate this optimization problem as a chance-constrained program (CCP), where the guarantees are not expressed as deterministic satisfaction against all possible uncertainty outcomes but rather expressed as guarantees against uncertainty outcomes. To approximately solve the CCP without requiring prior knowledge of how the uncertainties in the system matrices are described, we employ the so-called scenario approach, which provides probabilistic guarantees based on a finite number of samples and results in a convex optimization program with moderate computational complexity. Finally, numerical simulations are presented to illustrate the theoretical findings.      
### 2.Primal-dual Estimator Learning: an Offline Constrained Moving Horizon Estimation Method with Feasibility and Near-optimality Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2204.02857.pdf)
>  This paper proposes a primal-dual framework to learn a stable estimator for linear constrained estimation problems leveraging the moving horizon approach. To avoid the online computational burden in most existing methods, we learn a parameterized function offline to approximate the primal estimate. Meanwhile, a dual estimator is trained to check the suboptimality of the primal estimator during execution time. Both the primal and dual estimators are learned from data using supervised learning techniques, and the explicit sample size is provided, which enables us to guarantee the quality of each learned estimator in terms of feasibility and optimality. This in turn allows us to bound the probability of the learned estimator being infeasible or suboptimal. Furthermore, we analyze the stability of the resulting estimator with a bounded error in the minimization of the cost function. Since our algorithm does not require the solution of an optimization problem during runtime, state estimates can be generated online almost instantly. Simulation results are presented to show the accuracy and time efficiency of the proposed framework compared to online optimization of moving horizon estimation and Kalman filter. To the best of our knowledge, this is the first learning-based state estimator with feasibility and near-optimality guarantees for linear constrained systems.      
### 3.Spectral Denoising for Microphone Classification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02841.pdf)
>  In this paper, we propose the application of denoising to microphone classification, to enable its usage on content with unfavorable noisy conditions. We first describe the proposed integrated approach; afterwards we discuss the baseline algorithm for microphone classification, and the various denoising procedures which can be combined with it in the time or spectral domain; lastly, we determine the best performing denoising procedure, and evaluate the performance of the integrated approach with several SNR levels of additive input noise. In comparison to the reference baseline, the proposed method achieves an average accuracy increase of about 25% on denoised content.      
### 4.CCAT-NET: A Novel Transformer Based Semi-supervised Framework for Covid-19 Lung Lesion Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02839.pdf)
>  The spread of the novel coronavirus disease 2019 (COVID-19) has claimed millions of lives. Automatic segmentation of lesions from CT images can assist doctors with screening, treatment, and monitoring. However, accurate segmentation of lesions from CT images can be very challenging due to data and model limitations. Recently, Transformer-based networks have attracted a lot of attention in the area of computer vision, as Transformer outperforms CNN at a bunch of tasks. In this work, we propose a novel network structure that combines CNN and Transformer for the segmentation of COVID-19 lesions. We further propose an efficient semi-supervised learning framework to address the shortage of labeled data. Extensive experiments showed that our proposed network outperforms most existing networks and the semi-supervised learning framework can outperform the base network by 3.0% and 8.2% in terms of Dice coefficient and sensitivity.      
### 5.Online Feedback Droop Scheduling in Distribution Grids for Frequency and Local Voltage Control  [ :arrow_down: ](https://arxiv.org/pdf/2204.02837.pdf)
>  This paper presents a novel framework for collective control of Distributed Energy Resources (DERs) in active Distribution Networks (DNs). The proposed approach unifies the commonly employed local (i.e., decentralized) voltage and frequency droop control schemes into a transfer matrix relating frequency and voltage magnitude measurements to active and reactive power injection adjustments. Furthermore, the transfer matrices of individual DER units are adaptively tuned in real-time via slow communication links using an online gain scheduling approach, with the objective to enable frequency support provision to the transmission system and ensure that the DN voltages are kept within the allowable limits. A global asymptomatic stability condition of the analyzed droop-controlled DN is analytically established. The considered gain scheduling problem is solved by leveraging an online primal-dual gradient-based method and a suitable linearized power flow model. Additional ancillary service providers can be trivially incorporated into the proposed framework in a plug-and-play fashion. Numerical simulations of the 37-bus IEEE test system confirm the validity of the approach and demonstrate numerous advantages of the proposed scheme over the state-of-the-art.      
### 6.A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02779.pdf)
>  Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and for images acquired at different centers than those used for training, with labeling errors that violate expert knowledge about the anatomy and the intensity distribution of the regions to be segmented. Such errors undermine the trustworthiness of deep learning models developed for medical image segmentation. Mechanisms with a fallback method for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). Here, we propose a principled trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that are likely to violate expert knowledge and relies on a fallback atlas-based segmentation method for those voxels. We demonstrate the effectiveness of the proposed trustworthy AI approach on the largest reported annotated dataset of fetal T2w MRI consisting of 540 manually annotated fetal brain 3D MRIs with neurotypical or abnormal brain development and acquired from 13 sources of data across 6 countries. We show that our trustworthy AI method improves the robustness of a state-of-the-art backbone AI for fetal brain MRI segmentation on MRIs acquired across various centers and for fetuses with various brain abnormalities.      
### 7.Neural Network-augmented Kalman Filtering for Robust Online Speech Dereverberation in Noisy Reverberant Environments  [ :arrow_down: ](https://arxiv.org/pdf/2204.02741.pdf)
>  In this paper, a neural network-augmented algorithm for noise-robust online dereverberation with a Kalman filtering variant of the weighted prediction error (WPE) method is proposed. The filter stochastic variations are predicted by a deep neural network (DNN) trained end-to-end using the filter residual error and signal characteristics. The presented framework allows for robust dereverberation on a single-channel noisy reverberant dataset similar to WHAMR!. The Kalman filtering WPE introduces distortions in the enhanced signal when predicting the filter variations from the residual error only, if the target speech power spectral density is not perfectly known and the observation is noisy. The proposed approach avoids these distortions by correcting the filter variations estimation in a data-driven way, increasing the robustness of the method to noisy scenarios. Furthermore, it yields a strong dereverberation and denoising performance compared to a DNN-supported recursive least squares variant of WPE, especially for highly noisy inputs.      
### 8.Customizable End-to-end Optimization of Online Neural Network-supported Dereverberation for Hearing Devices  [ :arrow_down: ](https://arxiv.org/pdf/2204.02694.pdf)
>  This work focuses on online dereverberation for hearing devices using the weighted prediction error (WPE) algorithm. WPE filtering requires an estimate of the target speech power spectral density (PSD). Recently deep neural networks (DNNs) have been used for this task. However, these approaches optimize the PSD estimate which only indirectly affects the WPE output, thus potentially resulting in limited dereverberation. In this paper, we propose an end-to-end approach specialized for online processing, that directly optimizes the dereverberated output signal. In addition, we propose to adapt it to the needs of different types of hearing-device users by modifying the optimization target as well as the WPE algorithm characteristics used in training. We show that the proposed end-to-end approach outperforms the traditional and conventional DNN-supported WPEs on a noise-free version of the WHAMR! dataset.      
### 9.Towards An End-to-End Framework for Flow-Guided Video Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2204.02663.pdf)
>  Optical flow, which captures motion information across frames, is exploited in recent video inpainting methods through propagating pixels along its trajectories. However, the hand-crafted flow-based processes in these methods are applied separately to form the whole inpainting pipeline. Thus, these methods are less efficient and rely heavily on the intermediate results from earlier stages. In this paper, we propose an End-to-End framework for Flow-Guided Video Inpainting (E$^2$FGVI) through elaborately designed three trainable modules, namely, flow completion, feature propagation, and content hallucination modules. The three modules correspond with the three stages of previous flow-based methods but can be jointly optimized, leading to a more efficient and effective inpainting process. Experimental results demonstrate that the proposed method outperforms state-of-the-art methods both qualitatively and quantitatively and shows promising efficiency. The code is available at <a class="link-external link-https" href="https://github.com/MCG-NKU/E2FGVI" rel="external noopener nofollow">this https URL</a>.      
### 10.Representation Selective Self-distillation and wav2vec 2.0 Feature Exploration for Spoof-aware Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02639.pdf)
>  Text-to-speech and voice conversion studies are constantly improving to the extent where they can produce synthetic speech almost indistinguishable from bona fide human speech. In this regrad, the importance of countermeasures (CM) against synthetic voice attacks of the automatic speaker verification (ASV) systems emerges. Nonetheless, most end-to-end spoofing detection networks are black box systems, and the answer to what is an effective representation for finding artifacts still remains veiled. In this paper, we examine which feature space can effectively represent synthetic artifacts using wav2vec 2.0, and study which architecture can effectively utilize the space. Our study allows us to analyze which attribute of speech signals is advantageous for the CM systems. The proposed CM system achieved 0.31% equal error rate (EER) on ASVspoof 2019 LA evaluation set for the spoof detection task. We further propose a simple yet effective spoofing aware speaker verification (SASV) methodology, which takes advantage of the disentangled representations from our countermeasure system. Evaluation performed with the SASV Challenge 2022 database show 1.08% of SASV EER. Quantitative analysis shows that using the explored feature space of wav2vec 2.0 advantages both spoofing CM and SASV.      
### 11.Global HRTF Interpolation via Learned Affine Transformation of Hyper-conditioned Features  [ :arrow_down: ](https://arxiv.org/pdf/2204.02637.pdf)
>  Estimating Head-Related Transfer Functions (HRTFs) of arbitrary source points is essential in immersive binaural audio rendering. Computing each individual's HRTFs is challenging, as traditional approaches require expensive time and computational resources, while modern data-driven approaches are data-hungry. Especially for the data-driven approaches, existing HRTF datasets differ in spatial sampling distributions of source positions, posing a major problem when generalizing the method across multiple datasets. To alleviate this, we propose a deep learning method based on a novel conditioning architecture. The proposed method can predict an HRTF of any position by interpolating the HRTFs of known distributions. Experimental results show that the proposed architecture improves the model's generalizability across datasets with various coordinate systems. Additional demonstrations using coarsened HRTFs demonstrate that the model robustly reconstructs the target HRTFs from the coarsened data.      
### 12.Super-resolved multi-temporal segmentation with deep permutation-invariant networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.02631.pdf)
>  Multi-image super-resolution from multi-temporal satellite acquisitions of a scene has recently enjoyed great success thanks to new deep learning models. In this paper, we go beyond classic image reconstruction at a higher resolution by studying a super-resolved inference problem, namely semantic segmentation at a spatial resolution higher than the one of sensing platform. We expand upon recently proposed models exploiting temporal permutation invariance with a multi-resolution fusion module able to infer the rich semantic information needed by the segmentation task. The model presented in this paper has recently won the AI4EO challenge on Enhanced Sentinel 2 Agriculture.      
### 13.Cluster Synchronization of Kuramoto Oscillators and Brain Functional Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2204.02627.pdf)
>  The recent progress of functional magnetic resonance imaging techniques has unveiled that human brains exhibit clustered correlation patterns of their spontaneous activities. It is important to understand the mechanism of cluster synchronization phenomena since it may reflect the underlying brain functions and brain diseases. In this paper, we investigate cluster synchronization conditions for networks of Kuramoto oscillators. The key analytical tool that we use is the method of averaging, and we provide a unified framework of stability analysis for cluster synchronization. The main results show that cluster synchronization is achieved if (i) the inter-cluster coupling strengths are sufficiently weak and/or (ii) the natural frequencies are largely different among clusters. Moreover, we apply our theoretical findings to empirical brain networks. Discussions on how to understand brain functional connectivity and further directions to investigate neuroscientific questions are provided.      
### 14.Fault Diagnosis of Discrete-Event Systems under Non-Deterministic Observations with Output Fairness  [ :arrow_down: ](https://arxiv.org/pdf/2204.02617.pdf)
>  In this paper, we revisit the fault diagnosis problem of discrete-event systems (DES) under non-deterministic observations. Non-deterministic observation is a general observation model that includes the case of intermittent loss of observations. In this setting, upon the occurrence of an event, the sensor reading may be non-deterministic such that a set of output symbols are all possible. Existing works on fault diagnosis under non-deterministic observations require to consider all possible observation realizations. However, this approach includes the case where some possible outputs are permanently disabled. In this work, we introduce the concept of output fairness by requiring that, for any output symbols, if it has infinite chances to be generated, then it will indeed be generated infinite number of times. We use an assume-guarantee type of linear temporal logic formulas to formally describe this assumption. A new notion called output-fair diagnosability (OF-diagnosability) is proposed. An effective approach is provided for the verification of OF-diagnosability. We show that the proposed notion of OF-diagnosability is weaker than the standard definition of diagnosability under non-deterministic observations, and it better captures the physical scenario of observation non-determinism or intermittent loss of observations.      
### 15.SFCW GPR tree roots detection enhancement by time frequency analysis in tropical areas  [ :arrow_down: ](https://arxiv.org/pdf/2204.02594.pdf)
>  Accurate monitoring of tree roots using ground penetrating radar (GPR) is very useful in assessing the trees health. In high moisture tropical areas such as Singapore, tree fall due to root rot can cause loss of lives and properties. The tropical complex soil characteristics due to the high moisture content tends to affect penetration depth of the signal. This limits the depth range of the GPR. Typically, a wide band signal is used to increase the penetration depth and to improve the resolution of the GPR. However, this broad band frequency tends to be noisy and selective frequency filtering is required for noise reduction. Therefore, in this paper, we adapt the stepped frequency continuous wave (SFCW) GPR and propose the use of a Joint time frequency analysis (JTFA) method called short time Fourier transform (STFT), to reduce noise and enhance tree root detection. The proposed methodology is illustrated and tested with controlled experiments and real tree roots testing. The results show promising prospects of the method for tree roots detection in tropical areas.      
### 16.A Novel 3D Non-Stationary Channel Model for 6G Indoor Visible Light Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.02560.pdf)
>  The visible light communication (VLC) technology has attracted much attention in the research of the sixth generation (6G) communication systems. In this paper, a novel three dimensional (3D) space-time-frequency non-stationary geometry-based stochastic model (GBSM) is proposed for indoor VLC channels. The proposed VLC GBSM can capture unique indoor VLC channel characteristics such as the space-time-frequency non-stationarity caused by large light-emitting diode (LED) arrays in indoor scenarios, long travelling paths, and large bandwidths of visible light waves, respectively. In addition, the proposed model can support special radiation patterns of LEDs, 3D translational and rotational motions of the optical receiver (Rx), and can be applied to angle diversity receivers (ADRs). Key channel properties are simulated and analyzed, including the space-time-frequency correlation function (STFCF), received power, root mean square (RMS) delay spread, and path loss (PL). Simulation results verify the space-time-frequency non-stationarity in indoor VLC channels. Finally, the accuracy and practicality of the proposed model are validated by comparing the simulation result of channel 3dB bandwidth with the existing measurement data. The proposed channel model will play a supporting role in the design of future 6G VLC systems.      
### 17.Towards Better Test Coverage: Merging Unit Tests for Autonomous Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.02541.pdf)
>  We present a framework for merging unit tests for autonomous systems. Typically, it is intractable to test an autonomous system for every scenario in its operating environment. The question of whether it is possible to design a single test for multiple requirements of the system motivates this work. First, we formally define three attributes of a test: a test specification that characterizes behaviors observed in a test execution, a test environment, and a test policy. Using the merge operator from contract-based design theory, we provide a formalism to construct a merged test specification from two unit test specifications. Temporal constraints on the merged test specification guarantee that non-trivial satisfaction of both unit test specifications is necessary for a successful merged test execution. We assume that the test environment remains the same across the unit tests and the merged test. Given a test specification and a test environment, we synthesize a test policy filter using a receding horizon approach, and use the test policy filter to guide a search procedure (e.g. Monte-Carlo Tree Search) to find a test policy that is guaranteed to satisfy the test specification. This search procedure finds a test policy that maximizes a pre-defined robustness metric for the test while the filter guarantees a test policy for satisfying the test specification. We prove that our algorithm is sound. Furthermore, the receding horizon approach to synthesizing the filter ensures that our algorithm is scalable. Finally, we show that merging unit tests is impactful for designing efficient test campaigns to achieve similar levels of coverage in fewer test executions. We illustrate our framework on two self-driving examples in a discrete-state setting.      
### 18.IoT-Scan: Network Reconnaissance for the Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2204.02538.pdf)
>  Network reconnaissance is a core networking and security procedure aimed at discovering devices and their properties. For IP-based networks, several network reconnaissance tools are available, such as Nmap. For the Internet of Things (IoT), there is currently no similar tool capable of discovering devices across multiple protocols. In this paper, we present IoT-Scan, a universal IoT network reconnaissance tool. <br>IoT-Scan is based on software defined radio (SDR) technology, which allows for a flexible software-based implementation of radio protocols. We present a series of passive, active, multi-channel, and multi-protocol scanning algorithms to speed up the discovery of devices with IoT-Scan. We benchmark the passive scanning algorithms against a theoretical traffic model based on the non-uniform coupon collector problem. We implement the scanning algorithms and compare their performance for four popular IoT protocols: Zigbee, Bluetooth LE, Z-Wave, and LoRa. Through extensive experiments with dozens of IoT devices, we demonstrate that our implementation experiences minimal packet losses and achieves performance near the theoretical benchmark. Using multi-protocol scanning, we further demonstrate a reduction of 70\% in the discovery times of Bluetooth and Zigbee devices in the 2.4\,GHz band and of LoRa and Z-Wave devices in the 900\,MHz band, compared to sequential passive scanning. We make our implementation and data available to the research community to allow independent replication of our results and facilitate further development of the tool.      
### 19.Co-optimization of power line shutoff and restoration for electric grids under high wildfire ignition risk  [ :arrow_down: ](https://arxiv.org/pdf/2204.02507.pdf)
>  Electric power infrastructure has ignited several of the most destructive wildfires in recent history. Preemptive power shut-offs are an effective tool to mitigate the risk of ignitions from power lines, but at the same time can cause widespread power outages. Electric utilities are thus faced with the challenging trade-off of where and when to implement these shut-offs, as well as how to most efficiently restore power once the wildfire risk is reduced. This work proposes a mathematical optimization problem to help utilities make these decisions. Our model co-optimizes the power shut-off (considering both wildfire risk reduction and power outages) as well as the post-event inspection and energization of lines. It is implemented as a rolling horizon optimization problem that is resolved whenever new forecasts of load and wildfire risk become available. We demonstrate our method on the IEEE RTS-GMLC test case using real wildfire risk data US Geological Survey, and investigate the sensitivity of the results to the forecast quality, decision horizon and system restoration budget. The software implementation is available in the open source software package PowerModelsWildfire.jl.      
### 20.Recursive Restoration Refinement: A Fast Heuristic for Near-Optimal Restoration Prioritization in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.02504.pdf)
>  The prioritization of restoration actions after large power system outages plays a key role in how quickly power can be restored. It has been shown that fast and intuitive heuristics for restoration prioritization most often result in low-quality restoration plans. Meanwhile, mathematical optimization tools that find high-quality restoration plans are too slow to be applied to restoration planning problems of practical interest. This work makes a significant step in closing this quality vs compute time gap by proposing the Recursive Restoration Refinement heuristic for power system restoration. This heuristic is shown to produce near-optimal restoration plans up to 1,000 times faster than other state-of-the-art solution methods on a range of test cases with up to 500 buses and 700 damaged components. The potential impact of this new heuristic is demonstrated by a preliminary analysis of the key features of high-quality restoration plans. The recursive restoration refinement algorithm and other methods explored in this work have been made available as part of the open-source software package, PowerModelsRestoration, to support ongoing research in power restoration algorithms.      
### 21.Learning Optimal K-space Acquisition and Reconstruction using Physics-Informed Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.02480.pdf)
>  The inherent slow imaging speed of Magnetic Resonance Image (MRI) has spurred the development of various acceleration methods, typically through heuristically undersampling the MRI measurement domain known as k-space. Recently, deep neural networks have been applied to reconstruct undersampled k-space data and have shown improved reconstruction performance. While most of these methods focus on designing novel reconstruction networks or new training strategies for a given undersampling pattern, \textit{e.g.}, Cartesian undersampling or Non-Cartesian sampling, to date, there is limited research aiming to learn and optimize k-space sampling strategies using deep neural networks. This work proposes a novel optimization framework to learn k-space sampling trajectories by considering it as an Ordinary Differential Equation (ODE) problem that can be solved using neural ODE. In particular, the sampling of k-space data is framed as a dynamic system, in which neural ODE is formulated to approximate the system with additional constraints on MRI physics. In addition, we have also demonstrated that trajectory optimization and image reconstruction can be learned collaboratively for improved imaging efficiency and reconstruction performance. Experiments were conducted on different in-vivo datasets (\textit{e.g.}, brain and knee images) acquired with different sequences. Initial results have shown that our proposed method can generate better image quality in accelerated MRI than conventional undersampling schemes in Cartesian and Non-Cartesian acquisitions.      
### 22.Parametric Channel Model Estimation for Large Intelligent Surface-Based Transceiver-assisted Communication System  [ :arrow_down: ](https://arxiv.org/pdf/2204.02479.pdf)
>  The number of connected mobile devices and the amount of data traffic through these devices are expected to grow many-fold in future communication networks. To support the scale of this huge data traffic, more and more base stations and wireless terminals are required to be deployed in existing networks. Nevertheless, practically deploying a large number of base stations having massive antenna arrays will substantially increase the hardware cost and power consumption of the network. A promising approach for enhancing the coverage and rate of wireless communication systems is the large intelligent surface-based transceiver (LISBT), which uses a spatially continuous surface for signal transmission and receiving. A typical LIS consists of a planar array having a large number of reflecting metamaterial elements (e.g., low-cost printed dipoles), each of which could act as a phase shift. It is also considered to be a cost effective and energy efficient solution. Accurate channel state information (CSI) in LISBT-assisted wireless communication systems is critical for achieving these goals. In this paper, we propose a channel estimation scheme based on the physical parameters of the system. that requires only five pilot signals to perfectly estimate the channel parameters assuming there is no noise at the receiver. In the presence of noise, we propose an iterative estimation algorithm that decreases the channel estimation error due to noise. The proposed scheme's training overhead and computational cost do not grow with the number of antennas, unlike previous work on enormous multiple-input multiple-output (MIMO). The channel estimate scheme based on the physical properties of the Large intelligent surface-based transceiver (LISBT)-assisted wireless communication systems is the subject of our future study.      
### 23.A Comprehensive Framework based on Dynamic and Steady State Analysis to Evaluate Power System Resiliency to Extreme Weather Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2204.02453.pdf)
>  Power system robustness against high impact low probability events is becoming a major concern. To depict distinct phases of a system response during these disturbances, an irregular polygon model is derived from the conventional trapezoid model and the model is analytically investigated for transmission system performance, based on which resiliency metrics are developed for the same. Furthermore, the system resiliency to windstorm is evaluated on the IEEE reliability test system (RTS) by performing steady state and dynamic security assessment incorporating protection modelling and corrective action schemes using the software Power System Simulator for Engineering (PSS/E). Based on the results of steady state and dynamic analysis, modified resiliency metrics are quantified. Finally, this paper quantifies the interdependency of operational and infrastructure resiliency as they cannot be considered as discrete characteristics of the system.      
### 24.Federated Cross Learning for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02450.pdf)
>  Federated learning (FL) can collaboratively train deep learning models using isolated patient data owned by different hospitals for various clinical applications, including medical image segmentation. However, a major problem of FL is its performance degradation when dealing with the data that are not independently and identically distributed (non-iid), which is often the case in medical images. In this paper, we first conduct a theoretical analysis on the FL algorithm to reveal the problem of model aggregation during training on non-iid data. With the insights gained through the analysis, we propose a simple and yet effective method, federated cross learning (FedCross), to tackle this challenging problem. Unlike the conventional FL methods that combine multiple individually trained local models on a server node, our FedCross sequentially trains the global model across different clients in a round-robin manner, and thus the entire training procedure does not involve any model aggregation steps. To further improve its performance to be comparable with the centralized learning method, we combine the FedCross with an ensemble learning mechanism to compose a federated cross ensemble learning (FedCrossEns) method. Finally, we conduct extensive experiments using a set of public datasets. The experimental results show that the proposed FedCross training strategy outperforms the mainstream FL methods on non-iid data. In addition to improving the segmentation performance, our FedCrossEns can further provide a quantitative estimation of the model uncertainty, demonstrating the effectiveness and clinical significance of our designs. Source code will be made publicly available after paper publication.      
### 25.A deep learning framework for the detection and quantification of drusen and reticular pseudodrusen on optical coherence tomography  [ :arrow_down: ](https://arxiv.org/pdf/2204.02406.pdf)
>  Purpose - To develop and validate a deep learning (DL) framework for the detection and quantification of drusen and reticular pseudodrusen (RPD) on optical coherence tomography scans. <br>Design - Development and validation of deep learning models for classification and feature segmentation. <br>Methods - A DL framework was developed consisting of a classification model and an out-of-distribution (OOD) detection model for the identification of ungradable scans; a classification model to identify scans with drusen or RPD; and an image segmentation model to independently segment lesions as RPD or drusen. Data were obtained from 1284 participants in the UK Biobank (UKBB) with a self-reported diagnosis of age-related macular degeneration (AMD) and 250 UKBB controls. Drusen and RPD were manually delineated by five retina specialists. The main outcome measures were sensitivity, specificity, area under the ROC curve (AUC), kappa, accuracy and intraclass correlation coefficient (ICC). <br>Results - The classification models performed strongly at their respective tasks (0.95, 0.93, and 0.99 AUC, respectively, for the ungradable scans classifier, the OOD model, and the drusen and RPD classification model). The mean ICC for drusen and RPD area vs. graders was 0.74 and 0.61, respectively, compared with 0.69 and 0.68 for intergrader agreement. FROC curves showed that the model's sensitivity was close to human performance. <br>Conclusions - The models achieved high classification and segmentation performance, similar to human performance. Application of this robust framework will further our understanding of RPD as a separate entity from drusen in both research and clinical settings.      
### 26.Zero-shot Blind Image Denoising via Implicit Neural Representations  [ :arrow_down: ](https://arxiv.org/pdf/2204.02405.pdf)
>  Recent denoising algorithms based on the "blind-spot" strategy show impressive blind image denoising performances, without utilizing any external dataset. While the methods excel in recovering highly contaminated images, we observe that such algorithms are often less effective under a low-noise or real noise regime. To address this gap, we propose an alternative denoising strategy that leverages the architectural inductive bias of implicit neural representations (INRs), based on our two findings: (1) INR tends to fit the low-frequency clean image signal faster than the high-frequency noise, and (2) INR layers that are closer to the output play more critical roles in fitting higher-frequency parts. Building on these observations, we propose a denoising algorithm that maximizes the innate denoising capability of INRs by penalizing the growth of deeper layer weights. We show that our method outperforms existing zero-shot denoising methods under an extensive set of low-noise or real-noise scenarios.      
### 27.Hospital-Agnostic Image Representation Learning in Digital Pathology  [ :arrow_down: ](https://arxiv.org/pdf/2204.02404.pdf)
>  Whole Slide Images (WSIs) in digital pathology are used to diagnose cancer subtypes. The difference in procedures to acquire WSIs at various trial sites gives rise to variability in the histopathology images, thus making consistent diagnosis challenging. These differences may stem from variability in image acquisition through multi-vendor scanners, variable acquisition parameters, and differences in staining procedure; as well, patient demographics may bias the glass slide batches before image acquisition. These variabilities are assumed to cause a domain shift in the images of different hospitals. It is crucial to overcome this domain shift because an ideal machine-learning model must be able to work on the diverse sources of images, independent of the acquisition center. A domain generalization technique is leveraged in this study to improve the generalization capability of a Deep Neural Network (DNN), to an unseen histopathology image set (i.e., from an unseen hospital/trial site) in the presence of domain shift. According to experimental results, the conventional supervised-learning regime generalizes poorly to data collected from different hospitals. However, the proposed hospital-agnostic learning can improve the generalization considering the low-dimensional latent space representation visualization, and classification accuracy results.      
### 28.Explainable Deep Learning Algorithm for Distinguishing Incomplete Kawasaki Disease by Coronary Artery Lesions on Echocardiographic Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2204.02403.pdf)
>  Background and Objective: Incomplete Kawasaki disease (KD) has often been misdiagnosed due to a lack of the clinical manifestations of classic KD. However, it is associated with a markedly higher prevalence of coronary artery lesions. Identifying coronary artery lesions by echocardiography is important for the timely diagnosis of and favorable outcomes in KD. Moreover, similar to KD, coronavirus disease 2019, currently causing a worldwide pandemic, also manifests with fever; therefore, it is crucial at this moment that KD should be distinguished clearly among the febrile diseases in children. In this study, we aimed to validate a deep learning algorithm for classification of KD and other acute febrile diseases. <br>Methods: We obtained coronary artery images by echocardiography of children (n = 88 for KD; n = 65 for pneumonia). We trained six deep learning networks (VGG19, Xception, ResNet50, ResNext50, SE-ResNet50, and SE-ResNext50) using the collected data. <br>Results: SE-ResNext50 showed the best performance in terms of accuracy, specificity, and precision in the classification. SE-ResNext50 offered a precision of 76.35%, a sensitivity of 82.64%, and a specificity of 58.12%. <br>Conclusions: The results of our study suggested that deep learning algorithms have similar performance to an experienced cardiologist in detecting coronary artery lesions to facilitate the diagnosis of KD.      
### 29.Enhanced Direct Speech-to-Speech Translation Using Self-supervised Pre-training and Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02967.pdf)
>  Direct speech-to-speech translation (S2ST) models suffer from data scarcity issues as there exists little parallel S2ST data, compared to the amount of data available for conventional cascaded systems that consist of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS) synthesis. In this work, we explore self-supervised pre-training with unlabeled speech data and data augmentation to tackle this issue. We take advantage of a recently proposed speech-to-unit translation (S2UT) framework that encodes target speech into discrete representations, and transfer pre-training and efficient partial finetuning techniques that work well for speech-to-text translation (S2T) to the S2UT domain by studying both speech encoder and discrete unit decoder pre-training. Our experiments show that self-supervised pre-training consistently improves model performance compared with multitask learning with a BLEU gain of 4.3-12.0 under various data setups, and it can be further combined with data augmentation techniques that apply MT to create weakly supervised training data. Audio samples are available at: <a class="link-external link-https" href="https://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html" rel="external noopener nofollow">this https URL</a> .      
### 30.ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound  [ :arrow_down: ](https://arxiv.org/pdf/2204.02874.pdf)
>  We introduce an audiovisual method for long-range text-to-video retrieval. Unlike previous approaches designed for short video retrieval (e.g., 5-15 seconds in duration), our approach aims to retrieve minute-long videos that capture complex human actions. One challenge of standard video-only approaches is the large computational cost associated with processing hundreds of densely extracted frames from such long videos. To address this issue, we propose to replace parts of the video with compact audio cues that succinctly summarize dynamic audio events and are cheap to process. Our method, named ECLIPSE (Efficient CLIP with Sound Encoding), adapts the popular CLIP model to an audiovisual video setting, by adding a unified audiovisual transformer block that captures complementary cues from the video and audio streams. In addition to being 2.92x faster and 2.34x memory-efficient than long-range video-only approaches, our method also achieves better text-to-video retrieval accuracy on several diverse long-range video datasets such as ActivityNet, QVHighlights, YouCook2, DiDeMo and Charades.      
### 31.Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware Adversarial Training  [ :arrow_down: ](https://arxiv.org/pdf/2204.02844.pdf)
>  Existing deep learning real denoising methods require a large amount of noisy-clean image pairs for supervision. Nonetheless, capturing a real noisy-clean dataset is an unacceptable expensive and cumbersome procedure. To alleviate this problem, this work investigates how to generate realistic noisy images. Firstly, we formulate a simple yet reasonable noise model that treats each real noisy pixel as a random variable. This model splits the noisy image generation problem into two sub-problems: image domain alignment and noise domain alignment. Subsequently, we propose a novel framework, namely Pixel-level Noise-aware Generative Adversarial Network (PNGAN). PNGAN employs a pre-trained real denoiser to map the fake and real noisy images into a nearly noise-free solution space to perform image domain alignment. Simultaneously, PNGAN establishes a pixel-level adversarial training to conduct noise domain alignment. Additionally, for better noise fitting, we present an efficient architecture Simple Multi-scale Network (SMNet) as the generator. Qualitative validation shows that noise generated by PNGAN is highly similar to real noise in terms of intensity and distribution. Quantitative experiments demonstrate that a series of denoisers trained with the generated noisy images achieve state-of-the-art (SOTA) results on four real denoising benchmarks.      
### 32.Aggression in Hindi and English Speech: Acoustic Correlates and Automatic Identification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02814.pdf)
>  In the present paper, we will present the results of an acoustic analysis of political discourse in Hindi and discuss some of the conventionalised acoustic features of aggressive speech regularly employed by the speakers of Hindi and English. The study is based on a corpus of slightly over 10 hours of political discourse and includes debates on news channel and political speeches. Using this study, we develop two automatic classification systems for identifying aggression in English and Hindi speech, based solely on an acoustic model. The Hindi classifier, trained using 50 hours of annotated speech, and English classifier, trained using 40 hours of annotated speech, achieve a respectable accuracy of over 73% and 66% respectively. In this paper, we discuss the development of this annotated dataset, the experiments for developing the classifier and discuss the errors that it makes.      
### 33.Expression-preserving face frontalization improves visually assisted speech processing  [ :arrow_down: ](https://arxiv.org/pdf/2204.02810.pdf)
>  Face frontalization consists of synthesizing a frontally-viewed face from an arbitrarily-viewed one. The main contribution of this paper is a frontalization methodology that preserves non-rigid facial deformations in order to boost the performance of visually assisted speech communication. The method alternates between the estimation of (i)~the rigid transformation (scale, rotation, and translation) and (ii)~the non-rigid deformation between an arbitrarily-viewed face and a face model. The method has two important merits: it can deal with non-Gaussian errors in the data and it incorporates a dynamical face deformation model. For that purpose, we use the generalized Student t-distribution in combination with a linear dynamic system in order to account for both rigid head motions and time-varying facial deformations caused by speech production. We propose to use the zero-mean normalized cross-correlation (ZNCC) score to evaluate the ability of the method to preserve facial expressions. The method is thoroughly evaluated and compared with several state of the art methods, either based on traditional geometric models or on deep learning. Moreover, we show that the method, when incorporated into deep learning pipelines, namely lip reading and speech enhancement, improves word recognition and speech intelligibilty scores by a considerable margin. Supplemental material is accessible at <a class="link-external link-https" href="https://team.inria.fr/robotlearn/research/facefrontalization-benchmark/" rel="external noopener nofollow">this https URL</a>      
### 34.Federated Self-supervised Speech Representations: Are We There Yet?  [ :arrow_down: ](https://arxiv.org/pdf/2204.02804.pdf)
>  The ubiquity of microphone-enabled devices has lead to large amounts of unlabelled audio data being produced at the edge. The integration of self-supervised learning (SSL) and federated learning (FL) into one coherent system can potentially offer data privacy guarantees while also advancing the quality and robustness of speech representations. In this paper, we provide a first-of-its-kind systematic study of the feasibility and complexities for training speech SSL models under FL scenarios from the perspective of algorithms, hardware, and systems limits. Despite the high potential of their combination, we find existing system constraints and algorithmic behaviour make SSL and FL systems nearly impossible to build today. Yet critically, our results indicate specific performance bottlenecks and research opportunities that would allow this situation to be reversed. While our analysis suggests that, given existing trends in hardware, hybrid SSL and FL speech systems will not be viable until 2027. We believe this study can act as a roadmap to accelerate work towards reaching this milestone much earlier.      
### 35.Dimensionality Expansion and Transfer Learning for Next Generation Energy Management Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.02802.pdf)
>  Electrical management systems (EMS) are playing a central role in enabling energy savings. They can be deployed within an everyday household where they monitor and manage appliances and help residents be more energy efficient and subsequently also more economical. One of they key functionalities of EMS is to automatically detect and identify appliances within a household through the process of load monitoring. In this paper, we propose a new transfer learning approach for building EMS (BEMS) and study the trade-offs in terms of numbers of samples and target classes in adapting a backbone model during the transfer process. We also perform a first time analysis of feature expansion through video-like transformation of time series data for device classification in non intrusive load monitoring (NILM) and propose a deep learning architecture enabling accurate appliance identification. We examine the relative performance of our method on 5 different representative low-frequency datasets and show that our method performs with an average F1 score of 0.88 on these datasets.      
### 36.BFRnet: A deep learning-based MR background field removal method for QSM of the brain containing significant pathological susceptibility sources  [ :arrow_down: ](https://arxiv.org/pdf/2204.02760.pdf)
>  Introduction: Background field removal (BFR) is a critical step required for successful quantitative susceptibility mapping (QSM). However, eliminating the background field in brains containing significant susceptibility sources, such as intracranial hemorrhages, is challenging due to the relatively large scale of the field induced by these pathological susceptibility sources. Method: This study proposes a new deep learning-based method, BFRnet, to remove background field in healthy and hemorrhagic subjects. The network is built with the dual-frequency octave convolutions on the U-net architecture, trained with synthetic field maps containing significant susceptibility sources. The BFRnet method is compared with three conventional BFR methods and one previous deep learning method using simulated and in vivo brains from 4 healthy and 2 hemorrhagic subjects. Robustness against acquisition field-of-view (FOV) orientation and brain masking are also investigated. Results: For both simulation and in vivo experiments, BFRnet led to the best visually appealing results in the local field and QSM results with the minimum contrast loss and the most accurate hemorrhage susceptibility measurements among all five methods. In addition, BFRnet produced the most consistent local field and susceptibility maps between different sizes of brain masks, while conventional methods depend drastically on precise brain extraction and further brain edge erosions. It is also observed that BFRnet performed the best among all BFR methods for acquisition FOVs oblique to the main magnetic field. Conclusion: The proposed BFRnet improved the accuracy of local field reconstruction in the hemorrhagic subjects compared with conventional BFR algorithms. The BFRnet method was effective for acquisitions of titled orientations and retained whole brains without edge erosion as often required by traditional BFR methods.      
### 37.Towards Multi-Scale Speaking Style Modelling with Hierarchical Context Information for Mandarin Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.02743.pdf)
>  Previous works on expressive speech synthesis focus on modelling the mono-scale style embedding from the current sentence or context, but the multi-scale nature of speaking style in human speech is neglected. In this paper, we propose a multi-scale speaking style modelling method to capture and predict multi-scale speaking style for improving the naturalness and expressiveness of synthetic speech. A multi-scale extractor is proposed to extract speaking style embeddings at three different levels from the ground-truth speech, and explicitly guide the training of a multi-scale style predictor based on hierarchical context information. Both objective and subjective evaluations on a Mandarin audiobooks dataset demonstrate that our proposed method can significantly improve the naturalness and expressiveness of the synthesized speech.      
### 38.Behavioral uncertainty quantification for data-driven control  [ :arrow_down: ](https://arxiv.org/pdf/2204.02671.pdf)
>  This paper explores the problem of uncertainty quantification in the behavioral setting for data-driven control. Building on classical ideas from robust control, the problem is regarded as that of selecting a metric which is best suited to a data-based description of uncertainties. Leveraging on Willems' fundamental lemma, restricted behaviors are viewed as subspaces of fixed dimension, which may be represented by data matrices. Consequently, metrics between restricted behaviors are defined as distances between points on the Grassmannian, i.e., the set of all subspaces of equal dimension in a given vector space. A new metric is defined on the set of restricted behaviors as a direct finite-time counterpart of the classical gap metric. The metric is shown to capture parametric uncertainty for the class of autoregressive (AR) models. Numerical simulations illustrate the value of the new metric with a data-driven mode recognition and control case study.      
### 39.CAIPI in Practice: Towards Explainable Interactive Medical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02661.pdf)
>  Would you trust physicians if they cannot explain their decisions to you? Medical diagnostics using machine learning gained enormously in importance within the last decade. However, without further enhancements many state-of-the-art machine learning methods are not suitable for medical application. The most important reasons are insufficient data set quality and the black-box behavior of machine learning algorithms such as Deep Learning models. Consequently, end-users cannot correct the model's decisions and the corresponding explanations. The latter is crucial for the trustworthiness of machine learning in the medical domain. The research field explainable interactive machine learning searches for methods that address both shortcomings. This paper extends the explainable and interactive CAIPI algorithm and provides an interface to simplify human-in-the-loop approaches for image classification. The interface enables the end-user (1) to investigate and (2) to correct the model's prediction and explanation, and (3) to influence the data set quality. After CAIPI optimization with only a single counterexample per iteration, the model achieves an accuracy of $97.48\%$ on the Medical MNIST and $95.02\%$ on the Fashion MNIST. This accuracy is approximately equal to state-of-the-art Deep Learning optimization procedures. Besides, CAIPI reduces the labeling effort by approximately $80\%$.      
### 40.A New Nonlinear speaker parameterization algorithm for speaker identification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02609.pdf)
>  In this paper we propose a new parameterization algorithm based on nonlinear prediction, which is an extension of the classical LPC parameters. The parameters performances are estimated by two different methods: the Arithmetic-Harmonic Sphericity (AHS) and the Auto-Regressive Vector Model (ARVM). Two different methods are proposed for the parameterization based on the Neural Predictive Coding (NPC): classical neural networks initialization and linear initialization. We applied these two parameters to speaker identification. The fist parameters obtained smaller rates. We show for the first parameters how they can be combined with the classical parameters (LPCC, MFCC, etc.) in order to improve the results of only one classical parameterization (MFCC provides 97.55% and MFCC+NPC 98.78%). For the linear initialization, we obtain 100% which is great improvement. This study opens a new way towards different parameterization schemes that offer better accuracy on speaker recognition tasks.      
### 41.Prosodic Alignment for off-screen automatic dubbing  [ :arrow_down: ](https://arxiv.org/pdf/2204.02530.pdf)
>  The goal of automatic dubbing is to perform speech-to-speech translation while achieving audiovisual coherence. This entails isochrony, i.e., translating the original speech by also matching its prosodic structure into phrases and pauses, especially when the speaker's mouth is visible. In previous work, we introduced a prosodic alignment model to address isochrone or on-screen dubbing. In this work, we extend the prosodic alignment model to also address off-screen dubbing that requires less stringent synchronization constraints. We conduct experiments on four dubbing directions - English to French, Italian, German and Spanish - on a publicly available collection of TED Talks and on publicly available YouTube videos. Empirical results show that compared to our previous work the extended prosodic alignment model provides significantly better subjective viewing experience on videos in which on-screen and off-screen automatic dubbing is applied for sentences with speakers mouth visible and not visible, respectively.      
### 42.Simple and Effective Unsupervised Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.02524.pdf)
>  We introduce the first unsupervised speech synthesis system based on a simple, yet effective recipe. The framework leverages recent work in unsupervised speech recognition as well as existing neural-based speech synthesis. Using only unlabeled speech audio and unlabeled text as well as a lexicon, our method enables speech synthesis without the need for a human-labeled corpus. Experiments demonstrate the unsupervised system can synthesize speech similar to a supervised counterpart in terms of naturalness and intelligibility measured by human evaluation.      
### 43.User-Level Differential Privacy against Attribute Inference Attack of Speech Emotion Recognition in Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.02500.pdf)
>  Many existing privacy-enhanced speech emotion recognition (SER) frameworks focus on perturbing the original speech data through adversarial training within a centralized machine learning setup. However, this privacy protection scheme can fail since the adversary can still access the perturbed data. In recent years, distributed learning algorithms, especially federated learning (FL), have gained popularity to protect privacy in machine learning applications. While FL provides good intuition to safeguard privacy by keeping the data on local devices, prior work has shown that privacy attacks, such as attribute inference attacks, are achievable for SER systems trained using FL. In this work, we propose to evaluate the user-level differential privacy (UDP) in mitigating the privacy leaks of the SER system in FL. UDP provides theoretical privacy guarantees with privacy parameters $\epsilon$ and $\delta$. Our results show that the UDP can effectively decrease attribute information leakage while keeping the utility of the SER system with the adversary accessing one model update. However, the efficacy of the UDP suffers when the FL system leaks more model updates to the adversary. We make the code publicly available to reproduce the results in <a class="link-external link-https" href="https://github.com/usc-sail/fed-ser-leakage" rel="external noopener nofollow">this https URL</a>.      
### 44.Privacy-Preserving Federated Learning via System Immersion and Random Matrix Encryption  [ :arrow_down: ](https://arxiv.org/pdf/2204.02497.pdf)
>  Federated learning (FL) has emerged as a privacy solution for collaborative distributed learning where clients train AI models directly on their devices instead of sharing their data with a centralized (potentially adversarial) server. Although FL preserves local data privacy to some extent, it has been shown that information about clients' data can still be inferred from model updates. In recent years, various privacy-preserving schemes have been developed to address this privacy leakage. However, they often provide privacy at the expense of model performance or system efficiency and balancing these tradeoffs is a crucial challenge when implementing FL schemes. In this manuscript, we propose a Privacy-Preserving Federated Learning (PPFL) framework built on the synergy of matrix encryption and system immersion tools from control theory. The idea is to immerse the learning algorithm, a Stochastic Gradient Decent (SGD), into a higher-dimensional system (the so-called target system) and design the dynamics of the target system so that: the trajectories of the original SGD are immersed/embedded in its trajectories, and it learns on encrypted data (here we use random matrix encryption). Matrix encryption is reformulated at the server as a random change of coordinates that maps original parameters to a higher-dimensional parameter space and enforces that the target SGD converges to an encrypted version of the original SGD optimal solution. The server decrypts the aggregated model using the left inverse of the immersion map. We show that our algorithm provides the same level of accuracy and convergence rate as the standard FL with a negligible computation cost while revealing no information about the clients' data.      
### 45.Distributed Robust Control for Systems with Structured Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2204.02493.pdf)
>  We present D-Phi iteration: an algorithm for distributed, localized, and scalable robust control of systems with structured uncertainties. This algorithm combines the System Level Synthesis (SLS) parametrization for distributed control with stability criteria from L1, L-infinity, and nu robust control. We show in simulation that this algorithm achieves near-optimal nominal performance (within 12% of the LQR controller) while doubling or tripling the stability margin (depending on the stability criterion) compared to the LQR controller. To the best of our knowledge, this is the first distributed and localized algorithm for structured robust control; furthermore, algorithm complexity depends only on the size of local neighborhoods and is independent of global system size. We additionally characterize the suitability of different robustness criteria for distributed and localized computation, and discuss open questions on the topic of distributed robust control.      
### 46.Towards End-to-end Unsupervised Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.02492.pdf)
>  Unsupervised speech recognition has shown great potential to make Automatic Speech Recognition (ASR) systems accessible to every language. However, existing methods still heavily rely on hand-crafted pre-processing. Similar to the trend of making supervised speech recognition end-to-end, we introduce \wvu~which does away with all audio-side pre-processing and improves accuracy through better architecture. In addition, we introduce an auxiliary self-supervised objective that ties model predictions back to the input. Experiments show that \wvu~improves unsupervised recognition results across different languages while being conceptually simpler.      
### 47.Motion Correction via Locally Linear Embedding for Helical Photon-counting CT  [ :arrow_down: ](https://arxiv.org/pdf/2204.02490.pdf)
>  X-ray photon-counting detector (PCD) offers low noise, high resolution, and spectral characterization, representing a next generation of CT and enabling new biomedical applications. It is well known that involuntary patient motion may induce image artifacts with conventional CT scanning, and this problem becomes more serious with PCD due to its high detector pitch and extended scan time. Furthermore, PCD often comes with a substantial number of bad pixels, making analytic image reconstruction challenging and ruling out state-of-the-art motion correction methods that are based on analytical reconstruction. In this paper, we extend our previous locally linear embedding (LLE) cone-beam motion correction method to the helical scanning geometry, which is especially desirable given the high cost of large-area PCD. In addition to our adaption of LLE-based parametric searching to helical cone-beam photon-counting CT geometry, we introduce an unreliable-volume mask to improve the motion estimation accuracy and perform incremental updating on gradually refined sampling grids for optimization of both accuracy and efficiency. Our numerical results demonstrate that our method reduces the estimation errors near the two longitudinal ends of the reconstructed volume and overall image quality. The experimental results on clinical photon-counting scans of the patient extremities show significant resolution improvement after motion correction using our method, which reveals subtle fine structures previously hidden under motion blurring and artifacts.      
### 48.Training-Free Robust Multimodal Learning via Sample-Wise Jacobian Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2204.02485.pdf)
>  Multimodal fusion emerges as an appealing technique to improve model performances on many tasks. Nevertheless, the robustness of such fusion methods is rarely involved in the present literature. In this paper, we propose a training-free robust late-fusion method by exploiting conditional independence assumption and Jacobian regularization. Our key is to minimize the Frobenius norm of a Jacobian matrix, where the resulting optimization problem is relaxed to a tractable Sylvester equation. Furthermore, we provide a theoretical error bound of our method and some insights about the function of the extra modality. Several numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate the efficacy of our method under both adversarial attacks and random corruptions.      
### 49.Configuration Path Control  [ :arrow_down: ](https://arxiv.org/pdf/2204.02471.pdf)
>  Reinforcement learning methods often produce brittle policies -- policies that perform well during training, but generalize poorly beyond their direct training experience, thus becoming unstable under small disturbances. To address this issue, we propose a method for stabilizing a control policy in the space of configuration paths. It is applied post-training and relies purely on the data produced during training, as well as on an instantaneous control-matrix estimation. The approach is evaluated empirically on a planar bipedal walker subjected to a variety of perturbations. The control policies obtained via reinforcement learning are compared against their stabilized counterparts. Across different experiments, we find two- to four-fold increase in stability, when measured in terms of the perturbation amplitudes. We also provide a zero-dynamics interpretation of our approach.      
### 50.Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation  [ :arrow_down: ](https://arxiv.org/pdf/2204.02470.pdf)
>  Self-Supervised Learning (SSL) models have been successfully applied in various deep learning-based speech tasks, particularly those with a limited amount of data. However, the quality of SSL representations depends highly on the relatedness between the SSL training domain(s) and the target data domain. On the contrary, spectral feature (SF) extractors such as log Mel-filterbanks are hand-crafted non-learnable components, and could be more robust to domain shifts. The present work examines the assumption that combining non-learnable SF extractors to SSL models is an effective approach to low resource speech tasks. We propose a learnable and interpretable framework to combine SF and SSL representations. The proposed framework outperforms significantly both baseline and SSL models on Automatic Speech Recognition (ASR) and Speech Translation (ST) tasks on three low resource datasets. We additionally design a mixture of experts based combination model. This last model reveals that the relative contribution of SSL models over conventional SF extractors is very small in case of domain mismatch between SSL training set and the target language data.      
### 51.Improving Voice Trigger Detection with Metric Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.02455.pdf)
>  Voice trigger detection is an important task, which enables activating a voice assistant when a target user speaks a keyword phrase. A detector is typically trained on speech data independent of speaker information and used for the voice trigger detection task. However, such a speaker independent voice trigger detector typically suffers from performance degradation on speech from underrepresented groups, such as accented speakers. In this work, we propose a novel voice trigger detector that can use a small number of utterances from a target speaker to improve detection accuracy. Our proposed model employs an encoder-decoder architecture. While the encoder performs speaker independent voice trigger detection, similar to the conventional detector, the decoder predicts a personalized embedding for each utterance. A personalized voice trigger score is then obtained as a similarity score between the embeddings of enrollment utterances and a test utterance. The personalized embedding allows adapting to target speaker's speech when computing the voice trigger score, hence improving voice trigger detection accuracy. Experimental results show that the proposed approach achieves a 38% relative reduction in a false rejection rate (FRR) compared to a baseline speaker independent voice trigger model.      
### 52.PDE-constrained shape registration to characterize biological growth and morphogenesis from imaging data  [ :arrow_down: ](https://arxiv.org/pdf/2204.02451.pdf)
>  We propose a PDE-constrained shape registration algorithm that captures the deformation and growth of biological tissue from imaging data. Shape registration is the process of evaluating optimum alignment between pairs of geometries through a spatial transformation function. We start from our previously reported work, which uses 3D tensor product B-spline basis functions to interpolate 3D space. Here, the movement of the B-spline control points, composed with an implicit function describing the shape of the tissue, yields the total deformation gradient field. The deformation gradient is then split into growth and elastic contributions. The growth tensor captures addition of mass, i.e. growth, and evolves according to a constitutive equation which is usually a function of the elastic deformation. Stress is generated in the material due to the elastic component of the deformation alone. The result of the registration is obtained by minimizing a total energy functional which includes: a distance measure reflecting similarity between the shapes, and the total elastic energy accounting for the growth of the tissue. We apply the proposed shape registration framework to study zebrafish embryo epiboly process and tissue expansion during skin reconstruction surgery. We anticipate that our PDE-constrained shape registration method will improve our understanding of biological and medical problems in which tissues undergo extreme deformations over time.      
### 53.Imaging Conductivity from Current Density Magnitude using Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.02441.pdf)
>  Conductivity imaging represents one of the most important tasks in medical imaging. In this work we develop a neural network based reconstruction technique for imaging the conductivity from the magnitude of the internal current density. It is achieved by formulating the problem as a relaxed weighted least-gradient problem, and then approximating its minimizer by standard fully connected feedforward neural networks. We derive bounds on two components of the generalization error, i.e., approximation error and statistical error, explicitly in terms of properties of the neural networks (e.g., depth, total number of parameters, and the bound of the network parameters). We illustrate the performance and distinct features of the approach on several numerical experiments. Numerically, it is observed that the approach enjoys remarkable robustness with respect to the presence of data noise.      
### 54.What can predictive speech coders learn from speaker recognizers?  [ :arrow_down: ](https://arxiv.org/pdf/2204.02400.pdf)
>  This paper compares the speech coder and speaker recognizer applications, showing some parallelism between them. In this paper, some approaches used for speaker recognition are applied to speech coding in order to improve the prediction accuracy. Experimental results show an improvement in Segmental SNR (SEGSNR).      
### 55.Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification  [ :arrow_down: ](https://arxiv.org/pdf/2204.02399.pdf)
>  The automatic early diagnosis of prodromal stages of Alzheimer's disease is of great relevance for patient treatment to improve quality of life. We address this problem as a multi-modal classification task. Multi-modal data provides richer and complementary information. However, existing techniques only consider either lower order relations between the data and single/multi-modal imaging data. In this work, we introduce a novel semi-supervised hypergraph learning framework for Alzheimer's disease diagnosis. Our framework allows for higher-order relations among multi-modal imaging and non-imaging data whilst requiring a tiny labelled set. Firstly, we introduce a dual embedding strategy for constructing a robust hypergraph that preserves the data semantics. We achieve this by enforcing perturbation invariance at the image and graph levels using a contrastive based mechanism. Secondly, we present a dynamically adjusted hypergraph diffusion model, via a semi-explicit flow, to improve the predictive uncertainty. We demonstrate, through our experiments, that our framework is able to outperform current techniques for Alzheimer's disease diagnosis.      
