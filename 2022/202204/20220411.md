# ArXiv eess --Mon, 11 Apr 2022
### 1.Legitimate against Illegitimate IRSs on MISO Wiretap Channels  [ :arrow_down: ](https://arxiv.org/pdf/2204.04207.pdf)
>  The low-cost legitimate intelligent reflecting surfaces (IRSs) are applied to the wiretap channel in physical layer security to enhance the secrecy rate. In practice, the eavesdropper can also deploy an IRS, namely illegitimate IRS, to deteriorate the secrecy rate. This paper studies the interplay between a transmitter, a legitimate IRS, and an illegitimate IRS in a multiple-input single-output (MISO) wiretap channel. We formulate a max-min secrecy rate problem, where all the information is available at the transmitter and the receivers. We aim to design an efficient transmit beamforming and phase shifting strategy of the legitimate IRS, under the worst-case secrecy rate achieved based on optimizing the phase-shifting strategy of the illegitimate IRS. We propose three solution methods based on the gradient descent ascent (GDA), the alternate optimization (AO), and the mixed Nash equilibrium (NE) in zero-sum games in strategic form. Simulation results show that for the continuous phase-shifting strategies, AO usually does not guarantee convergence, although it may achieve better performance than GDA in some iterations. GDA usually converges to a stationary point. Discrete phase-shifting strategies improve the convergence behavior of AO and GDA, while there is a single mixed NE with the highest secrecy rate.      
### 2.Underwater Image Enhancement Using Pre-trained Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2204.04199.pdf)
>  The goal of this work is to apply a denoising image transformer to remove the distortion from underwater images and compare it with other similar approaches. Automatic restoration of underwater images plays an important role since it allows to increase the quality of the images, without the need for more expensive equipment. This is a critical example of the important role of the machine learning algorithms to support marine exploration and monitoring, reducing the need for human intervention like the manual processing of the images, thus saving time, effort, and cost. This paper is the first application of the image transformer-based approach called "Pre-Trained Image Processing Transformer" to underwater images. This approach is tested on the UFO-120 dataset, containing 1500 images with the corresponding clean images.      
### 3.Simplified Analysis on Filtering Sensitivity Trade-offs in Continuous- and Discrete-Time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.04172.pdf)
>  A simplified analysis is performed on the Bode-type filtering sensitivity trade-off integrals, which capture the sensitivity characteristics of the estimate and estimation error with respect to the process input and estimated signal in continuous- and discrete-time linear time-invariant filtering systems. Compared with the previous analyses based on complex analysis and Cauchy's residue theorem, the analysis results derived from the simplified method are more explicit, thorough, and require less restrictive assumptions. For continuous-time filtering systems, our simplified analysis reveals that apart from the non-minimum phase zero sets reported in the previous literature, the value and boundedness of filtering sensitivity integrals are also determined by the leading coefficients, relative degrees, minimum phase zeros, and poles of plants and filters. By invoking the simplified method, a comprehensive analysis on the discrete-time filtering sensitivity integrals is conducted for the first time. Numerical examples are provided to verify the validity and correctness of the simplified analysis.      
### 4.Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.04170.pdf)
>  Contrastive learning enables learning useful audio and speech representations without ground-truth labels by maximizing the similarity between latent representations of similar signal segments. In this framework various data augmentation techniques are usually exploited to help enforce desired invariances within the learned representations, improving performance on various audio tasks thanks to more robust embeddings. Now, selecting the most relevant augmentations has proven crucial for better downstream performances. Thus, this work introduces a conditional independance-based method which allows for automatically selecting a suitable distribution on the choice of augmentations and their parametrization from a set of predefined ones, for contrastive self-supervised pre-training. This is performed with respect to a downstream task of interest, hence saving a costly hyper-parameter search. Experiments performed on two different downstream tasks validate the proposed approach showing better results than experimenting without augmentation or with baseline augmentations. We furthermore conduct a qualitative analysis of the automatically selected augmentations and their variation according to the considered final downstream dataset.      
### 5.Optimal Lane-Free Crossing of CAVs through Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2204.04156.pdf)
>  Connected and autonomous vehicles (CAVs), unlike conventional cars, will utilise the whole space of intersections and cross in a lane-free order. This paper formulates such a lane-free crossing of intersections as a multi-objective optimal control problem (OCP) that minimises the overall crossing time, as well as the energy consumption of CAVs. The proposed OCP is convexified by applying the dual problem theory to the constraints that avoid collision of vehicles with each other and with road boundaries. The resulting OCP is smooth and solvable by gradient-based algorithms. Simulation results show that the proposed algorithm reduces the crossing time by an average of 40% and 41% as compared to, respectively, the state-of-the-art reservation-based and lane-free methods, whilst consuming the same amount of energy. Furthermore, it is shown that the resulting crossing time of the proposed algorithm is i) fixed to a constant value regardless of the number of CAVs, and ii) very close to its theoretical limit.      
### 6.Design of an Optimal Testbed for Tracking of Tagged Marine Megafauna  [ :arrow_down: ](https://arxiv.org/pdf/2204.04155.pdf)
>  Underwater acoustic technologies are a key component for exploring the behavior of marine megafauna such as sea turtles, sharks, and seals. The animals are marked with acoustic devices (tags) that periodically emit signals encoding the device's ID along with sensor data such as depth, temperature, or the dominant acceleration axis - data that is collected by a network of deployed receivers. In this work, we aim to optimize the locations of receivers for best tracking of acoustically tagged marine megafauna. The outcomes of such tracking allows the evaluation of the animals' motion patterns, their hours of activity, and their social interactions. In particular, we focus on how to determine the receivers' deployment positions to maximize the coverage area in which the tagged animals can be tracked. For example, an overly-condensed deployment may not allow accurate tracking, whereas a sparse one, may lead to a small coverage area due to too few detections. We formalize the question of where to best deploy the receivers as a non-convex constraint optimization problem that takes into account the local environment and the specifications of the tags, and offer a sub-optimal, low-complexity solution that can be applied to large testbeds. Numerical investigation for three stimulated sea environments shows that our proposed method is able to increase the localization coverage area by 30%, and results from a test case experiment demonstrate similar performance in a real sea environment. We share the implementation of our work to help researchers set up their own acoustic observatory.      
### 7.Karaoker: Alignment-free singing voice synthesis with speech training data  [ :arrow_down: ](https://arxiv.org/pdf/2204.04127.pdf)
>  Existing singing voice synthesis models (SVS) are usually trained on singing data and depend on either error-prone time-alignment and duration features or explicit music score information. In this paper, we propose Karaoker, a multispeaker Tacotron-based model conditioned on voice characteristic features that is trained exclusively on spoken data without requiring time-alignments. Karaoker synthesizes singing voice following a multi-dimensional template extracted from a source waveform of an unseen speaker/singer. The model is jointly conditioned with a single deep convolutional encoder on continuous data including pitch, intensity, harmonicity, formants, cepstral peak prominence and octaves. We extend the text-to-speech training objective with feature reconstruction, classification and speaker identification tasks that guide the model to an accurate result. Except for multi-tasking, we also employ a Wasserstein GAN training scheme as well as new losses on the acoustic model's output to further refine the quality of the model.      
### 8.Prescribed-Time Seeking of a Repulsive Source by Unicycle Angular Velocity Tuning  [ :arrow_down: ](https://arxiv.org/pdf/2204.04118.pdf)
>  All the existing source seeking algorithms for unicycle models in GPS-denied settings guarantee at best an exponential rate of convergence over an infinite interval. Using the recently introduced time-varying feedback tools for prescribed-time stabilization, we achieve source seeking in prescribed time, i.e., the convergence to the source, without the measurements of the position and velocity of the unicycle, in as short a time as the user desires, starting from an arbitrary distance from the source. The convergence is established using a singularly perturbed version of the Lie bracket averaging method, combined with time dilation and time contraction operations. The algorithm is robust, provably, even to an arbitrarily strong gradient-dependent repulsive velocity drift emanating from the source.      
### 9.Automatic Census of Mussel Platforms Using Sentinel 2 Images  [ :arrow_down: ](https://arxiv.org/pdf/2204.04112.pdf)
>  Mussel platforms are big floating structures made of wood (size is normally about 20x20 meters or even a bit larger) that are used for aquaculture, id EST: growing mussels in appropriate marine waters. These structures are very typical in Galician estuaries. Being interesting to produce a periodic census of these structures that would allow knowing their number and positions, as well as changes on those parameters; Satellites that obtain periodic images for earth observation are a natural election for this issue. This paper describes a preliminary application able to construct automatically such a census using Sentinel 2 images (Copernicus Project). Copernicus satellites are run by European Space Agency (ESA) and the produced images are freely distributed on the internet. Sentinel 2 images have thirteen frequency bands and are updated each five days. In our application, we use remote sensing normalized (differential) indexes and artificial Neural Networks applied to multiband data. Different methods are described and tested. Finally, results are presented.      
### 10.Dynamic super-resolution in particle tracking problems  [ :arrow_down: ](https://arxiv.org/pdf/2204.04092.pdf)
>  Particle tracking in biological imaging is concerned with reconstructing the trajectories, locations, or velocities of the targeting particles. The standard approach of particle tracking consists of two steps: first reconstructing statically the source locations in each time step, and second applying tracking techniques to obtain the trajectories and velocities. In contrast, the dynamic reconstruction seeks to simultaneously recover the source locations and velocities from all frames, which enjoys certain advantages. In this paper, we provide a rigorous mathematical analysis for the resolution limit of reconstructing source number, locations, and velocities by general dynamical reconstruction in particle tracking problems, by which we demonstrate the possibility of achieving super-resolution for the dynamic reconstruction. We show that when the location-velocity pairs of the particles are separated beyond certain distances (the resolution limits), the number of particles and the location-velocity pair can be stably recovered. The resolution limits are related to the cut-off frequency of the imaging system, signal-to-noise ratio, and the sparsity of the source. By these estimates, we also derive a stability result for a sparsity-promoting dynamic reconstruction. In addition, we further show that the reconstruction of velocities has a better resolution limit which improves constantly as the particles moving. This result is derived by an observation that the inherent cut-off frequency for the velocity recovery can be viewed as the total observation time multiplies the cut-off frequency of the imaging system, which may lead to a better resolution limit as compared to the one for each diffraction-limited frame. It is anticipated that this observation can inspire new reconstruction algorithms that improve the resolution of particle tracking in practice.      
### 11.Stochastic Gradient-based Fast Distributed Multi-Energy Management for an Industrial Park with Temporally-Coupled Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2204.04088.pdf)
>  Contemporary industrial parks are challenged by the growing concerns about high cost and low efficiency of energy supply. Moreover, in the case of uncertain supply/demand, how to mobilize delay-tolerant elastic loads and compensate real-time inelastic loads to match multi-energy generation/storage and minimize energy cost is a key issue. Since energy management is hardly to be implemented offline without knowing statistical information of random variables, this paper presents a systematic online energy cost minimization framework to fulfill the complementary utilization of multi-energy with time-varying generation, demand and price. Specifically to achieve charging/discharging constraints due to storage and short-term energy balancing, a fast distributed algorithm based on stochastic gradient with two-timescale implementation is proposed to ensure online implementation. To reduce the peak loads, an incentive mechanism is implemented by estimating users' willingness to shift. Analytical results on parameter setting are also given to guarantee feasibility and optimality of the proposed design. Numerical results show that when the bid-ask spread of electricity is small enough, the proposed algorithm can achieve the close-to-optimal cost asymptotically.      
### 12.Declipping of Speech Signals Using Frequency Selective Extrapolation  [ :arrow_down: ](https://arxiv.org/pdf/2204.04068.pdf)
>  The reconstruction of clipped speech signals is an important task in audio signal processing to achieve an enhanced audio quality for further processing. In this paper, Frequency Selective Extrapolation (FSE), which is commonly used for error concealment or the reconstruction of incomplete image data, is adapted to be able to restore audio signals which are distorted from clipping. For this, FSE generates a model of the signal as an iterative superposition of Fourier basis functions. Clipped samples can then be replaced by estimated samples from the model. The performance of the proposed algorithm is evaluated by using different speech test data sets. Compared to other state-of-the-art declipping algorithms, this leads to a maximum gain in SNR of up to 3:5 dB and an average gain of 1 dB.      
### 13.Reconstruction of images taken by a pair of non-regular sampling sensors using correlation based matching  [ :arrow_down: ](https://arxiv.org/pdf/2204.04067.pdf)
>  Multi-view image acquisition systems with two or more cameras can be rather costly due to the number of high resolution image sensors that are required. Recently, it has been shown that by covering a low resolution sensor with a non-regular sampling mask and by using an efficient algorithm for image reconstruction, a high resolution image can be obtained. In this paper, a stereo image reconstruction setup for multi-view scenarios is proposed. A scene is captured by a pair of non-regular sampling sensors and by incorporating information from the adjacent view, the reconstruction quality can be increased. Compared to a state-of-the-art single-view reconstruction algorithm, this leads to a visually noticeable average gain in PSNR of 0.74 dB.      
### 14.Reducing Randomness of Non-Regular Sampling Masks for Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2204.04065.pdf)
>  Increasing spatial image resolution is an often required, yet challenging task in image acquisition. Recently, it has been shown that it is possible to obtain a high resolution image by covering a low resolution sensor with a non-regular sampling mask. Due to the masking, however, some pixel information in the resulting high resolution image is not available and has to be reconstructed by an efficient image reconstruction algorithm in order to get a fully reconstructed high resolution image. In this paper, the influence of different sampling masks with a reduced randomness of the non-regularity on the image reconstruction process is evaluated. Simulation results show that it is sufficient to use sampling masks that are non-regular only on a smaller scale. These sampling masks lead to a visually noticeable gain in PSNR compared to arbitrary chosen sampling masks which are non-regular over the whole image sensor size. At the same time, they simplify the manufacturing process and allow for efficient storage.      
### 15.Reconstruction of Videos Taken by a Non-Regular Sampling Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2204.04064.pdf)
>  Recently, it has been shown that a high resolution image can be obtained without the usage of a high resolution sensor. The main idea has been that a low resolution sensor is covered with a non-regular sampling mask followed by a reconstruction of the incomplete high resolution image captured this way. In this paper, a multi-frame reconstruction approach is proposed where a video is taken by a non-regular sampling sensor and fully reconstructed afterwards. By utilizing the temporal correlation between neighboring frames, the reconstruction quality can be further enhanced. Compared to a state-of-the-art single-frame reconstruction approach, this leads to a visually noticeable gain in PSNR of up to 1.19 dB on average.      
### 16.Deep-Learning-Based Identification of LPV Models for Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.04060.pdf)
>  The framework of Linear Parameter-Varying (LPV) systems is part of the modern modeling and control design toolchain for addressing nonlinear system behaviors through linear surrogate models. Despite the significant research effort spent on LPV data-driven modeling, a key shortcoming of the current identification theory is that often the scheduling variable is assumed to be a given measured signal in the data set. In case of identifying an LPV model of a nonlinear system, the selection of the scheduling, i.e., the scheduling map that describes its relation to measurable signals in the system, is put on the users' shoulder, with only limited supporting tools available. Although, such a choice greatly affects the usability and the complexity of the resulting LPV model. This paper presents a deep-learning based approach to provide joint estimation of a scheduling map and an LPV state-space model of a nonlinear system from input-output data. The approach has consistency guarantees under general innovation type of noise conditions, and its efficiency is demonstrated on the identification problem of a control moment gyroscope.      
### 17.Deep Learning-Based Intra Mode Derivation for Versatile Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2204.04059.pdf)
>  In intra coding, Rate Distortion Optimization (RDO) is performed to achieve the optimal intra mode from a pre-defined candidate list. The optimal intra mode is also required to be encoded and transmitted to the decoder side besides the residual signal, where lots of coding bits are consumed. To further improve the performance of intra coding in Versatile Video Coding (VVC), an intelligent intra mode derivation method is proposed in this paper, termed as Deep Learning based Intra Mode Derivation (DLIMD). In specific, the process of intra mode derivation is formulated as a multi-class classification task, which aims to skip the module of intra mode signaling for coding bits reduction. The architecture of DLIMD is developed to adapt to different quantization parameter settings and variable coding blocks including non-square ones, which are handled by one single trained model. Different from the existing deep learning based classification problems, the hand-crafted features are also fed into the intra mode derivation network besides the learned features from feature learning network. To compete with traditional method, one additional binary flag is utilized in the video codec to indicate the selected scheme with RDO. Extensive experimental results reveal that the proposed method can achieve 2.28%, 1.74%, and 2.18% bit rate reduction on average for Y, U, and V components on the platform of VVC test model, which outperforms the state-of-the-art works.      
### 18.Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2204.04016.pdf)
>  Speech intelligibility assessment plays an important role in the therapy of patients suffering from pathological speech disorders. Automatic and objective measures are desirable to assist therapists in their traditionally subjective and labor-intensive assessments. In this work, we investigate a novel approach for obtaining such a measure using the divergence in disentangled latent speech representations of a parallel utterance pair, obtained from a healthy reference and a pathological speaker. Experiments on an English database of Cerebral Palsy patients, using all available utterances per speaker, show high and significant correlation values (R = -0.9) with subjective intelligibility measures, while having only minimal deviation (+-0.01) across four different reference speaker pairs. We also demonstrate the robustness of the proposed method (R = -0.89 deviating +-0.02 over 1000 iterations) by considering a significantly smaller amount of utterances per speaker. Our results are among the first to show that disentangled speech representations can be used for automatic pathological speech intelligibility assessment, resulting in a reference speaker pair invariant method, applicable in scenarios with only few utterances available.      
### 19.Analysis and transformations of intensity in singing voice  [ :arrow_down: ](https://arxiv.org/pdf/2204.04006.pdf)
>  In this paper we introduce a neural auto-encoder that transforms the voice intensity in recordings of singing voice. Since most recordings of singing voice are not annotated with voice intensity we propose a means to estimate the relative voice intensity from the signal's timbre using a neural intensity estimator. Two methods to overcome the unknown recording factor that relates voice intensity to recorded signal power are given: The unknown recording factor can either be learned alongside the weights of the intensity estimator, or a special loss function based on the scalar product can be used to only match the intensity contour of the recorded signal's power. The intensity models are used to condition a previously introduced bottleneck auto-encoder that disentangles its input, the mel-spectrogram, from the intensity. We evaluate the intensity models by their consistency and by their fitness to provide useful information to the auto-encoder. A perceptive test is carried out that evaluates the perceived intensity change in transformed recordings and the synthesis quality. The perceptive test confirms that changing the conditional input changes the perceived intensity accordingly thus suggesting that the proposed intensity models encode information about the voice intensity.      
### 20.Hierarchical and Multi-Scale Variational Autoencoder for Diverse and Natural Non-Autoregressive Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2204.04004.pdf)
>  This paper proposes a hierarchical and multi-scale variational autoencoder-based non-autoregressive text-to-speech model (HiMuV-TTS) to generate natural speech with diverse speaking styles. Recent advances in non-autoregressive TTS (NAR-TTS) models have significantly improved the inference speed and robustness of synthesized speech. However, the diversity of speaking styles and naturalness are needed to be improved. To solve this problem, we propose the HiMuV-TTS model that first determines the global-scale prosody and then determines the local-scale prosody via conditioning on the global-scale prosody and the learned text representation. In addition, we improve the quality of speech by adopting the adversarial training technique. Experimental results verify that the proposed HiMuV-TTS model can generate more diverse and natural speech as compared to TTS models with single-scale variational autoencoders, and can represent different prosody information in each scale.      
### 21.Machine Learning aided Precise Indoor Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03990.pdf)
>  This study describes a UWB and Machine Learning (ML)-based indoor positioning system. We propose a simple mathematical strategy to create data to reduce the job of measurements for fingerprint-based indoor localization systems. A considerable number of measurements can be avoided this way. The paper compares and contrasts the performance of four distinct models. Most test locations' average error may be reduced to less than 150 mm using the best model.      
### 22.Scoring of Large-Margin Embeddings for Speaker Verification: Cosine or PLDA?  [ :arrow_down: ](https://arxiv.org/pdf/2204.03965.pdf)
>  The emergence of large-margin softmax cross-entropy losses in training deep speaker embedding neural networks has triggered a gradual shift from parametric back-ends to a simpler cosine similarity measure for speaker verification. Popular parametric back-ends include the probabilistic linear discriminant analysis (PLDA) and its variants. This paper investigates the properties of margin-based cross-entropy losses leading to such a shift and aims to find scoring back-ends best suited for speaker verification. In addition, we revisit the pre-processing techniques which have been widely used in the past and assess their effectiveness on large-margin embeddings. Experiments on the state-of-the-art ECAPA-TDNN networks trained with various large-margin softmax cross-entropy losses show a substantial increment in intra-speaker compactness making the conventional PLDA superfluous. In this regard, we found that constraining the within-speaker covariance matrix could improve the performance of the PLDA. It is demonstrated through a series of experiments on the VoxCeleb-1 and SITW core-core test sets with 40.8% equal error rate (EER) reduction and 35.1% minimum detection cost (minDCF) reduction. It also outperforms cosine scoring consistently with reductions in EER and minDCF by 10.9% and 4.9%, respectively.      
### 23.Stability of Non-linear Neural Feedback Loops using Sum of Squares  [ :arrow_down: ](https://arxiv.org/pdf/2204.03913.pdf)
>  Neural network controllers have the potential to improve the performance of feedback systems compared to traditional controllers, due to their ability to act as general function approximators. However, quantifying their safety and robustness properties has proven challenging due to the non-linearities of the activation functions inside the neural network. A key robustness indicator is certifying the stability properties of the feedback system and providing a region of attraction, which has been addressed in previous literature. However, these works only address linear systems or require one to abstract the plant non-linearities and bound them using slope and sector constraints. In this paper we use a Sum of Squares programming framework to compute the stability of non-linear systems with neural network controllers directly. Within this framework, we can propose higher order candidate Lyapunov functions with richer structures that are able to better capture the dynamics of the non-linear system and the nonlinearities in the neural network. We are also able to analyse these systems in continuous time, whereas other methods rely on discretising the system. These higher order Lyapunov functions are used in conjunction with higher order multipliers on the inequality and equality constraints that bound the neural network input-output properties. The volume of the region of attraction computed is increased compared to other methods, allowing for better safety guarantees on the stability of the system. We are also able to easily analyse non-linear polynomial systems, which is not possible to do with other methods. We are also able to conduct robustness analysis on the parameter uncertainty. We show the benefits of our method using numerical examples.      
### 24.Exploring Transformer's potential on automatic piano transcription  [ :arrow_down: ](https://arxiv.org/pdf/2204.03898.pdf)
>  Most recent research about automatic music transcription (AMT) uses convolutional neural networks and recurrent neural networks to model the mapping from music signals to symbolic notation. Based on a high-resolution piano transcription system, we explore the possibility of incorporating another powerful sequence transformation tool -- the Transformer -- to deal with the AMT problem. We argue that the properties of the Transformer make it more suitable for certain AMT subtasks. We confirm the Transformer's superiority on the velocity detection task by experiments on the MAESTRO dataset and a cross-dataset evaluation on the MAPS dataset. We observe a performance improvement on both frame-level and note-level metrics after introducing the Transformer network.      
### 25.SoundBeam: Target sound extraction conditioned on sound-class labels and enrollment clues for increased performance and continuous learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03895.pdf)
>  In many situations, we would like to hear desired sound events (SEs) while being able to ignore interference. Target sound extraction (TSE) aims at tackling this problem by estimating the sound of target SE classes in a mixture while suppressing all other sounds. We can achieve this with a neural network that extracts the target SEs by conditioning it on clues representing the target SE classes. Two types of clues have been proposed, i.e., target SE class labels and enrollment sound samples similar to the target sound. Systems based on SE class labels can directly optimize embedding vectors representing the SE classes, resulting in high extraction performance. However, extending these systems to the extraction of new SE classes not encountered during training is not easy. Enrollment-based approaches extract SEs by finding sounds in the mixtures that share similar characteristics to the enrollment. These approaches do not explicitly rely on SE class definitions and can thus handle new SE classes. In this paper, we introduce a TSE framework, SoundBeam, that combines the advantages of both approaches. We also perform an extensive evaluation of the different TSE schemes using synthesized and real mixtures, which shows the potential of SoundBeam.      
### 26.Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03863.pdf)
>  Self-supervised learning (SSL) approaches such as wav2vec 2.0 and HuBERT models have shown promising results in various downstream tasks in the speech community. In particular, speech representations learned by SSL models have been shown to be effective for encoding various speech-related characteristics. In this context, we propose a novel automatic pronunciation assessment method based on SSL models. First, the proposed method fine-tunes the pre-trained SSL models with connectionist temporal classification to adapt the English pronunciation of English-as-a-second-language (ESL) learners in a data environment. Then, the layer-wise contextual representations are extracted from all across the transformer layers of the SSL models. Finally, the automatic pronunciation score is estimated using bidirectional long short-term memory with the layer-wise contextual representations and the corresponding text. We show that the proposed SSL model-based methods outperform the baselines, in terms of the Pearson correlation coefficient, on datasets of Korean ESL learner children and Speechocean762. Furthermore, we analyze how different representations of transformer layers in the SSL model affect the performance of the pronunciation assessment task.      
### 27.Hierarchical Softmax for End-to-End Low-resource Multilingual Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03855.pdf)
>  Low resource speech recognition has been long-suffering from insufficient training data. While neighbour languages are often used as assistant training data, it would be difficult for the model to induct similar units (character, subword, etc.) across the languages. In this paper, we assume similar units in neighbour language share similar term frequency and form a Huffman tree to perform multi-lingual hierarchical Softmax decoding. During decoding, the hierarchical structure can benefit the training of low-resource languages. Experimental results show the effectiveness of our method.      
### 28.Defense against Adversarial Attacks on Hybrid Speech Recognition using Joint Adversarial Fine-tuning with Denoiser  [ :arrow_down: ](https://arxiv.org/pdf/2204.03851.pdf)
>  Adversarial attacks are a threat to automatic speech recognition (ASR) systems, and it becomes imperative to propose defenses to protect them. In this paper, we perform experiments to show that K2 conformer hybrid ASR is strongly affected by white-box adversarial attacks. We propose three defenses--denoiser pre-processor, adversarially fine-tuning ASR model, and adversarially fine-tuning joint model of ASR and denoiser. Our evaluation shows denoiser pre-processor (trained on offline adversarial examples) fails to defend against adaptive white-box attacks. However, adversarially fine-tuning the denoiser using a tandem model of denoiser and ASR offers more robustness. We evaluate two variants of this defense--one updating parameters of both models and the second keeping ASR frozen. The joint model offers a mean absolute decrease of 19.3\% ground truth (GT) WER with reference to baseline against fast gradient sign method (FGSM) attacks with different $L_\infty$ norms. The joint model with frozen ASR parameters gives the best defense against projected gradient descent (PGD) with 7 iterations, yielding a mean absolute increase of 22.3\% GT WER with reference to baseline; and against PGD with 500 iterations, yielding a mean absolute decrease of 45.08\% GT WER and an increase of 68.05\% adversarial target WER.      
### 29.Prediction of COVID-19 using chest X-ray images  [ :arrow_down: ](https://arxiv.org/pdf/2204.03849.pdf)
>  COVID-19, also known as Novel Coronavirus Disease, is a highly contagious disease that first surfaced in China in late 2019. SARS-CoV-2 is a coronavirus that belongs to the vast family of coronaviruses that causes this disease. The sickness originally appeared in Wuhan, China in December 2019 and quickly spread to over 213 nations, becoming a global pandemic. Fever, dry cough, and tiredness are the most typical COVID-19 symptoms. Aches, pains, and difficulty breathing are some of the other symptoms that patients may face. The majority of these symptoms are indicators of respiratory infections and lung abnormalities, which radiologists can identify. Chest x-rays of COVID-19 patients seem similar, with patchy and hazy lungs rather than clear and healthy lungs. On x-rays, however, pneumonia and other chronic lung disorders can resemble COVID-19. Trained radiologists must be able to distinguish between COVID-19 and an illness that is less contagious. Our AI algorithm seeks to give doctors a quantitative estimate of the risk of deterioration. So that patients at high risk of deterioration can be triaged and treated efficiently. The method could be particularly useful in pandemic hotspots when screening upon admission is important for allocating limited resources like hospital beds.      
### 30.AdvEst: Adversarial Perturbation Estimation to Classify and Detect Adversarial Attacks against Speaker Identification  [ :arrow_down: ](https://arxiv.org/pdf/2204.03848.pdf)
>  Adversarial attacks pose a severe security threat to the state-of-the-art speaker identification systems, thereby making it vital to propose countermeasures against them. Building on our previous work that used representation learning to classify and detect adversarial attacks, we propose an improvement to it using AdvEst, a method to estimate adversarial perturbation. First, we prove our claim that training the representation learning network using adversarial perturbations as opposed to adversarial examples (consisting of the combination of clean signal and adversarial perturbation) is beneficial because it eliminates nuisance information. At inference time, we use a time-domain denoiser to estimate the adversarial perturbations from adversarial examples. Using our improved representation learning approach to obtain attack embeddings (signatures), we evaluate their performance for three applications: known attack classification, attack verification, and unknown attack detection. We show that common attacks in the literature (Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Carlini-Wagner (CW) with different Lp threat models) can be classified with an accuracy of ~96%. We also detect unknown attacks with an equal error rate (EER) of ~9%, which is absolute improvement of ~12% from our previous work.      
### 31.A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.03804.pdf)
>  Generating multi-contrasts/modal MRI of the same anatomy enriches diagnostic information but is limited in practice due to excessive data acquisition time. In this paper, we propose a novel deep-learning model for joint reconstruction and synthesis of multi-modal MRI using incomplete k-space data of several source modalities as inputs. The output of our model includes reconstructed images of the source modalities and high-quality image synthesized in the target modality. Our proposed model is formulated as a variational problem that leverages several learnable modality-specific feature extractors and a multimodal synthesis module. We propose a learnable optimization algorithm to solve this model, which induces a multi-phase network whose parameters can be trained using multi-modal MRI data. Moreover, a bilevel-optimization framework is employed for robust parameter training. We demonstrate the effectiveness of our approach using extensive numerical experiments.      
### 32.Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03793.pdf)
>  Personalization of on-device speech recognition (ASR) has seen explosive growth in recent years, largely due to the increasing popularity of personal assistant features on mobile devices and smart home speakers. In this work, we present Personal VAD 2.0, a personalized voice activity detector that detects the voice activity of a target speaker, as part of a streaming on-device ASR system. Although previous proof-of-concept studies have validated the effectiveness of Personal VAD, there are still several critical challenges to address before this model can be used in production: first, the quality must be satisfactory in both enrollment and enrollment-less scenarios; second, it should operate in a streaming fashion; and finally, the model size should be small enough to fit a limited latency and CPU/Memory budget. To meet the multi-faceted requirements, we propose a series of novel designs: 1) advanced speaker embedding modulation methods; 2) a new training paradigm to generalize to enrollment-less conditions; 3) architecture and runtime optimizations for latency and resource restrictions. Extensive experiments on a realistic speech recognition system demonstrated the state-of-the-art performance of our proposed method.      
### 33.Mitigating Mismatch Compression in Differential Local Field Potentials  [ :arrow_down: ](https://arxiv.org/pdf/2204.03778.pdf)
>  Bidirectional deep brain stimulation (bdDBS) devices capable of recording differential local field potentials (dLFP) enable neural recordings alongside clinical therapy. Efforts to identify objective signals of various brain disorders, or disease readouts, are challenging in dLFP, especially during active DBS. In this report we identified, characterized, and mitigated a major source of distortion in dLFP that we introduce as mismatch compression (MC). MC occurs secondary to impedance mismatches across the dLFP channel resulting in incomplete rejection of artifacts and downstream amplifier gain compression. Using in silico and in vitro models we demonstrate that MC accounts for impedance-related distortions sensitive to DBS amplitude. We then use these models to develop and validate a mitigation strategy for MC that is provided as an opensource library for more reliable oscillatory disease readouts.      
### 34.Multi-objective optimization determines when, which and how to fuse deep networks: an application to predict COVID-19 outcomes  [ :arrow_down: ](https://arxiv.org/pdf/2204.03772.pdf)
>  The COVID-19 pandemic has caused millions of cases and deaths and the AI-related scientific community, after being involved with detecting COVID-19 signs in medical images, has been now directing the efforts towards the development of methods that can predict the progression of the disease. This task is multimodal by its very nature and, recently, baseline results achieved on the publicly available AIforCOVID dataset have shown that chest X-ray scans and clinical information are useful to identify patients at risk of severe outcomes. While deep learning has shown superior performance in several medical fields, in most of the cases it considers unimodal data only. In this respect, when, which and how to fuse the different modalities is an open challenge in multimodal deep learning. To cope with these three questions here we present a novel approach optimizing the setup of a multimodal end-to-end model. It exploits Pareto multi-objective optimization working with a performance metric and the diversity score of multiple candidate unimodal neural networks to be fused. We test our method on the AIforCOVID dataset, attaining state-of-the-art results, not only outperforming the baseline performance but also being robust to external validation. Moreover, exploiting XAI algorithms we figure out a hierarchy among the modalities and we extract the features' intra-modality importance, enriching the trust on the predictions made by the model.      
### 35.Energy self-sufficient systems for monitoring sewer networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03748.pdf)
>  Underground infrastructure networks form the backbone of vital supply and disposal systems. However, they are under-monitored in comparison to their value. This is due, in large part, to the lack of energy supply for monitoring and data transmission. In this paper, we investigate a novel, energy harvesting system used to power underground sewer infrastructure monitoring networks. The system collects the required energy from ambient sources, such as temperature differences or residual light in sewer networks. A prototype was developed that could use either a thermoelectric generator (TEG) or a solar cell to capture the energy needed to acquire and transmit ultrasonic water level data via LoRaWAN. Real-world field trials were satisfactory and showed the potential power output, as well as, possibilities to improve the system. Using an extrapolation model, we proved that the developed solution could work reliably throughout the year.      
### 36.Experimental Validation of DeeP-LCC for Dissipating Stop-and-Go Waves in Mixed Traffic  [ :arrow_down: ](https://arxiv.org/pdf/2204.03747.pdf)
>  We present results on the experimental validation of leading cruise control (LCC) for connected and autonomous vehicles (CAVs). In a mixed traffic situation that is dominated by human-driven vehicles, LCC strategies are promising to smooth undesirable stop-and-go waves. Our experiments are carried out on a mini-scale traffic platform. We first reproduce stop-and-go traffic waves in a miniature scale, and then show that these traffic instabilities can be dissipated by one or a few CAVs that utilize Data-EnablEd Predicted Leading Cruise Control (DeeP-LCC). Rather than identifying a parametric traffic model, DeeP-LCC relies on a data-driven non-parametric behavior representation for traffic prediction and CAV control. DeeP-LCC also incorporates input and output constraints to achieve collision-free guarantees for CAVs. We experimentally demonstrate that DeeP-LCC is able to dissipate traffic waves caused by car-following behavior and significantly improve both driving safety and travel efficiency. CAVs utilizing DeeP-LCC may bring additional societal benefits by mitigating stop-and-go waves in practical traffic.      
### 37.Mitosis domain generalization in histopathology images -- The MIDOG challenge  [ :arrow_down: ](https://arxiv.org/pdf/2204.03742.pdf)
>  The density of mitotic figures within tumor tissue is known to be highly correlated with tumor proliferation and thus is an important marker in tumor grading. Recognition of mitotic figures by pathologists is known to be subject to a strong inter-rater bias, which limits the prognostic value. State-of-the-art deep learning methods can support the expert in this assessment but are known to strongly deteriorate when applied in a different clinical environment than was used for training. One decisive component in the underlying domain shift has been identified as the variability caused by using different whole slide scanners. The goal of the MICCAI MIDOG 2021 challenge has been to propose and evaluate methods that counter this domain shift and derive scanner-agnostic mitosis detection algorithms. The challenge used a training set of 200 cases, split across four scanning systems. As a test set, an additional 100 cases split across four scanning systems, including two previously unseen scanners, were given. The best approaches performed on an expert level, with the winning algorithm yielding an F_1 score of 0.748 (CI95: 0.704-0.781). In this paper, we evaluate and compare the approaches that were submitted to the challenge and identify methodological factors contributing to better performance.      
### 38.Mixing Signals: Data Augmentation Approach for Deep Learning Based Modulation Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03737.pdf)
>  With the rapid development of deep learning, automatic modulation recognition (AMR), as an important task in cognitive radio, has gradually transformed from traditional feature extraction and classification to automatic classification by deep learning technology. However, deep learning models are data-driven methods, which often require a large amount of data as the training support. Data augmentation, as the strategy of expanding dataset, can improve the generalization of the deep learning models and thus improve the accuracy of the models to a certain extent. In this paper, for AMR of radio signals, we propose a data augmentation strategy based on mixing signals and consider four specific methods (Random Mixing, Maximum-Similarity-Mixing, $\theta-$Similarity Mixing and n-times Random Mixing) to achieve data augmentation. Experiments show that our proposed method can improve the classification accuracy of deep learning based AMR models in the full public dataset RML2016.10a. In particular, for the case of a single signal-to-noise ratio signal set, the classification accuracy can be significantly improved, which verifies the effectiveness of the methods.      
### 39.Quantitative Evaluation of Common Cause Failures in High Safety-significant Safety-related Digital Instrumentation and Control Systems in Nuclear Power Plants  [ :arrow_down: ](https://arxiv.org/pdf/2204.03717.pdf)
>  Digital instrumentation and control (DIC) systems at nuclear power plants (NPPs) have many advantages over analog systems. They are proven to be more reliable, cheaper, and easier to maintain given obsolescence of analog components. However, they also pose new engineering and technical challenges, such as possibility of common cause failures (CCFs) unique to digital systems. This paper proposes a Platform for Risk Assessment of DIC (PRADIC) that is developed by Idaho National Laboratory (INL). A methodology for evaluation of software CCFs in high safety-significant safety-related DIC systems of NPPs was developed as part of the framework. The framework integrates three stages of a typical risk assessment, qualitative hazard analysis and quantitative reliability and consequence analyses. The quantified risks compared with respective acceptance criteria provide valuable insights for system architecture alternatives allowing design optimization in terms of risk reduction and cost savings. A comprehensive case study performed to demonstrate the framework capabilities is documented in this paper. Results show that the PRADIC is a powerful tool capable to identify potential digital-based CCFs, estimate their probabilities, and evaluate their impacts on system and plant safety.      
### 40.Deconvolution of the Functional Ultrasound Response in the Mouse Visual Pathway Using Block-Term Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03711.pdf)
>  Functional ultrasound (fUS) indirectly measures brain activity by recording changes in cerebral blood volume and flow in response to neural activation. Conventional approaches model such functional neuroimaging data as the convolution between an impulse response, known as the hemodynamic response function (HRF), and a binarized representation of the input (i.e., source) signal based on the stimulus onsets, the so-called experimental paradigm (EP). However, the EP may not be enough to characterize the whole complexity of the underlying source signals that evoke the hemodynamic changes, such as in the case of spontaneous resting state activity. Furthermore, the HRF varies across brain areas and stimuli. To achieve an adaptable framework that can capture such dynamics and unknowns of the brain function, we propose a deconvolution method for multivariate fUS time-series that reveals both the region-specific HRFs, and the source signals that induce the hemodynamic responses in the studied regions. We start by modeling the fUS time-series as convolutive mixtures and use a tensor-based approach for deconvolution based on two assumptions: (1) HRFs are parametrizable, and (2) source signals are uncorrelated. We test our approach on fUS data acquired during a visual experiment on a mouse subject, focusing on three regions within the mouse brain's colliculo-cortical, image-forming pathway: the lateral geniculate nucleus, superior colliculus and visual cortex. The estimated HRFs in each region are in agreement with prior works, whereas the estimated source signal is observed to closely follow the EP. Yet, we note a few deviations from the EP in the estimated source signal that most likely arise due to the trial-by-trial variability of the neural response across different repetitions of the stimulus observed in the selected regions.      
### 41.Physics-assisted Generative Adversarial Network for X-Ray Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2204.03703.pdf)
>  X-ray tomography is capable of imaging the interior of objects in three dimensions non-invasively, with applications in biomedical imaging, materials science, electronic inspection, and other fields. The reconstruction process can be an ill-conditioned inverse problem, requiring regularization to obtain satisfactory reconstructions. Recently, deep learning has been adopted for tomographic reconstruction. Unlike iterative algorithms which require a distribution that is known a priori, deep reconstruction networks can learn a prior distribution through sampling the training distributions. In this work, we develop a Physics-assisted Generative Adversarial Network (PGAN), a two-step algorithm for tomographic reconstruction. In contrast to previous efforts, our PGAN utilizes maximum-likelihood estimates derived from the measurements to regularize the reconstruction with both known physics and the learned prior. Synthetic objects with spatial correlations are integrated circuits (IC) from a proposed model CircuitFaker. Compared with maximum-likelihood estimation, PGAN can reduce the photon requirement with limited projection angles to achieve a given error rate. We further attribute the improvement to the learned prior by reconstructing objects created without spatial correlations. The advantages of using a prior from deep learning in X-ray tomography may further enable low-photon nanoscale imaging.      
### 42.A Message Passing Based Average Consensus Algorithm for Decentralized Frequency and Phase Synchronization in Distributed Phased Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2204.03691.pdf)
>  We consider the problem of decentralized frequency and phase synchronization in distributed phased arrays via local broadcast of the node electrical states. Frequency and phase synchronization between nodes in a distributed array is necessary to support beamforming, but due to the operational dynamics of the local oscillators of the nodes, the frequencies and phases of their output signals undergo the random drift and jitter in between the update intervals. Furthermore, frequency and phase estimation errors contribute to the total phase errors, leading to a residual phase error in the array that degrades coherent operation. Recently, a classical decentralized frequency and phase synchronization algorithm based on consensus averaging was proposed with which the standard deviation of the residual phase errors upon convergence was reduced to $10^{-4}$ degrees for internode update intervals of $0.1$ ms, however this was obtained for arrays with at least $400$ nodes and a high connectivity ratio of $0.9$. In this paper, we propose a message passing based average consensus (MPAC) algorithm to improve the synchronization of the electrical states of the nodes in distributed arrays. Simulation results show that the proposed MPAC algorithm significantly reduces the residual phase errors to about $10^{-11}$ degrees, requiring only $20$ moderately connected nodes in an array. Furthermore, MPAC converges faster than the DFPC-based algorithms, particularly for the larger arrays with a moderate connectivity.      
### 43.Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2204.03654.pdf)
>  The development of noninvasive brain imaging such as resting-state functional magnetic resonance imaging (rs-fMRI) and its combination with AI algorithm provides a promising solution for the early diagnosis of Autism spectrum disorder (ASD). However, the performance of the current ASD classification based on rs-fMRI still needs to be improved. This paper introduces a classification framework to aid ASD diagnosis based on rs-fMRI. In the framework, we proposed a novel filter feature selection method based on the difference between step distribution curves (DSDC) to select remarkable functional connectivities (FCs) and utilized a multilayer perceptron (MLP) which was pretrained by a simplified Variational Autoencoder (VAE) for classification. We also designed a pipeline consisting of a normalization procedure and a modified hyperbolic tangent (tanh) activation function to replace the original tanh function, further improving the model accuracy. Our model was evaluated by 10 times 10-fold cross-validation and achieved an average accuracy of 78.12%, outperforming the state-of-the-art methods reported on the same dataset. Given the importance of sensitivity and specificity in disease diagnosis, two constraints were designed in our model which can improve the model's sensitivity and specificity by up to 9.32% and 10.21%, respectively. The added constraints allow our model to handle different application scenarios and can be used broadly.      
### 44.PlutoNet: An Efficient Polyp Segmentation Network  [ :arrow_down: ](https://arxiv.org/pdf/2204.03652.pdf)
>  Polyps in the colon can turn into cancerous cells if not removed with early intervention. Deep learning models are used to minimize the number of polyps that goes unnoticed by the experts, and to accurately segment the detected polyps during these interventions. Although these models perform well on these tasks, they require too many parameters, which can pose a problem with real-time applications. To address this problem, we propose a novel segmentation model called PlutoNet which requires only 2,626,337 parameters while outperforming state-of-the-art models on multiple medical image segmentation tasks. We use EfficientNetB0 architecture as a backbone and propose the novel \emph{modified partial decoder}, which is a combination of partial decoder and full scale connections, which further reduces the number of parameters required, as well as captures semantic details. We use asymmetric convolutions to handle varying polyp sizes. Finally, we weight each feature map to improve segmentation by using a squeeze and excitation block. In addition to polyp segmentation in colonoscopy, we tested our model on segmentation of nuclei and surgical instruments to demonstrate its generalizability to different medical image segmentation tasks. Our model outperformed the state-of-the-art models with a Dice score of \%92.3 in CVC-ClinicDB dataset and \%89.3 in EndoScene dataset, a Dice score of \%91.93 on the 2018 Data Science Bowl Challenge dataset, and a Dice score of \%94.8 on Kvasir-Instrument dataset. Our experiments and ablation studies show that our model is superior in terms of accuracy, and it is able generalize well to multiple medical segmentation tasks.      
### 45.Dancing under the stars: video denoising in starlight  [ :arrow_down: ](https://arxiv.org/pdf/2204.04210.pdf)
>  Imaging in low light is extremely challenging due to low photon counts. Using sensitive CMOS cameras, it is currently possible to take videos at night under moonlight (0.05-0.3 lux illumination). In this paper, we demonstrate photorealistic video under starlight (no moon present, $&lt;$0.001 lux) for the first time. To enable this, we develop a GAN-tuned physics-based noise model to more accurately represent camera noise at the lowest light levels. Using this noise model, we train a video denoiser using a combination of simulated noisy video clips and real noisy still images. We capture a 5-10 fps video dataset with significant motion at approximately 0.6-0.7 millilux with no active illumination. Comparing against alternative methods, we achieve improved video quality at the lowest light levels, demonstrating photorealistic video denoising in starlight for the first time.      
### 46.Path Defense in Dynamic Defender-Attacker Blotto Games (dDAB) with Limited Information  [ :arrow_down: ](https://arxiv.org/pdf/2204.04176.pdf)
>  We consider a path guarding problem in dynamic Defender-Attacker Blotto games (dDAB), where a team of robots must defend a path in a graph against adversarial agents. Multi-robot systems are particularly well suited to this application, as recent work has shown the effectiveness of these systems in related areas such as perimeter defense and surveillance. When designing a defender policy that guarantees the defense of a path, information about the adversary and the environment can be helpful and may reduce the number of resources required by the defender to achieve a sufficient level of security. In this work, we characterize the necessary and sufficient number of assets needed to guarantee the defense of a shortest path between two nodes in dDAB games when the defender can only detect assets within $k$-hops of a shortest path. By characterizing the relationship between sensing horizon and required resources, we show that increasing the sensing capability of the defender greatly reduces the number of defender assets needed to defend the path.      
### 47.Self-supervised Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2204.04166.pdf)
>  Over the last few years, deep learning has grown in popularity for speaker verification, identification, and diarization. Inarguably, a significant part of this success is due to the demonstrated effectiveness of their speaker representations. These, however, are heavily dependent on large amounts of annotated data and can be sensitive to new domains. This study proposes an entirely unsupervised deep-learning model for speaker diarization. Specifically, the study focuses on generating high-quality neural speaker representations without any annotated data, as well as on estimating secondary hyperparameters of the model without annotations. <br>The speaker embeddings are represented by an encoder trained in a self-supervised fashion using pairs of adjacent segments assumed to be of the same speaker. The trained encoder model is then used to self-generate pseudo-labels to subsequently train a similarity score between different segments of the same call using probabilistic linear discriminant analysis (PLDA) and further to learn a clustering stopping threshold. We compared our model to state-of-the-art unsupervised as well as supervised baselines on the CallHome benchmarks. According to empirical results, our approach outperforms unsupervised methods when only two speakers are present in the call, and is only slightly worse than recent supervised models.      
### 48.Quantum encoding is suitable for matched filtering  [ :arrow_down: ](https://arxiv.org/pdf/2204.04159.pdf)
>  Matched filtering is a powerful signal searching technique used in several employments from radar and communications applications to gravitational-wave detection. Here we devise a method for matched filtering with the use of quantum bits. Our method's asymptotic time complexity does not depend on template length and, including encoding, is $\mathcal{O}(L(\log_2L)^2)$ for a data with length $L$ and a template with length $N$, which is classically $\mathcal{O}(NL)$. Hence our method has superior time complexity over the classical computation for long templates. We demonstrate our method with real quantum hardware on 4 qubits and also with simulations.      
### 49.C-NMT: A Collaborative Inference Framework for Neural Machine Translation  [ :arrow_down: ](https://arxiv.org/pdf/2204.04043.pdf)
>  Collaborative Inference (CI) optimizes the latency and energy consumption of deep learning inference through the inter-operation of edge and cloud devices. Albeit beneficial for other tasks, CI has never been applied to the sequence- to-sequence mapping problem at the heart of Neural Machine Translation (NMT). In this work, we address the specific issues of collaborative NMT, such as estimating the latency required to generate the (unknown) output sequence, and show how existing CI methods can be adapted to these applications. Our experiments show that CI can reduce the latency of NMT by up to 44% compared to a non-collaborative approach.      
### 50.Capacity Bounds for One-Bit MIMO Gaussian Channels with Analog Combining  [ :arrow_down: ](https://arxiv.org/pdf/2204.04033.pdf)
>  The use of 1-bit analog-to-digital converters (ADCs) is seen as a promising approach to significantly reduce the power consumption and hardware cost of multiple-input multiple-output (MIMO) receivers. However, the nonlinear distortion due to 1-bit quantization fundamentally changes the optimal communication strategy and also imposes a capacity penalty to the system. In this paper, the capacity of a Gaussian MIMO channel in which the antenna outputs are processed by an analog linear combiner and then quantized by a set of zero threshold ADCs is studied. A new capacity upper bound for the zero threshold case is established that is tighter than the bounds available in the literature. In addition, we propose an achievability scheme which configures the analog combiner to create parallel Gaussian channels with phase quantization at the output. Under this class of analog combiners, an algorithm is presented that identifies the analog combiner and input distribution that maximize the achievable rate. Numerical results are provided showing that the rate of the achievability scheme is tight in the low signal-to-noise ratio (SNR) regime. Finally, a new 1-bit MIMO receiver architecture which employs analog temporal and spatial processing is proposed. The proposed receiver attains the capacity in the high SNR regime.      
### 51.Mel-spectrogram features for acoustic vehicle detection and speed estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.04013.pdf)
>  The paper addresses acoustic vehicle detection and speed estimation from single sensor measurements. We predict the vehicle's pass-by instant by minimizing clipped vehicle-to-microphone distance, which is predicted from the mel-spectrogram of input audio, in a supervised learning approach. In addition, mel-spectrogram-based features are used directly for vehicle speed estimation, without introducing any intermediate features. The results show that the proposed features can be used for accurate vehicle detection and speed estimation, with an average error of 7.87 km/h. If we formulate speed estimation as a classification problem, with a 10 km/h discretization interval, the proposed method attains the average accuracy of 48.7% for correct class prediction and 91.0% when an offset of one class is allowed. The proposed method is evaluated on a dataset of 304 urban-environment on-field recordings of ten different vehicles.      
### 52.The Sillwood Technologies System for the VoiceMOS Challenge 2022  [ :arrow_down: ](https://arxiv.org/pdf/2204.03967.pdf)
>  In this paper we describe our entry for the VoiceMOS Challenge 2022 for both the main and out-of-domain (OOD) track of the competition. Our system is based on finetuning pre-trained self-supervised waveform prediction models, while improving its generalisation ability through stochastic weight averaging. Further, we use influence functions to identity possible low-quality data within the training set to further increase our model's performance for the OOD track. Our system ranked 5th and joint 7th for the main track and OOD track, respectively.      
### 53.Lensless coherent diffraction imaging based on spatial light modulator with unknown modulation curve  [ :arrow_down: ](https://arxiv.org/pdf/2204.03947.pdf)
>  Lensless imaging is a popular research field for the advantages of small size, wide field-of-view and low aberration in recent years. However, some traditional lensless imaging methods suffer from slow convergence, mechanical errors and conjugate solution interference, which limit its further application and development. In this work, we proposed a lensless imaging method based on spatial light modulator (SLM) with unknown modulation curve. In our imaging system, we use SLM to modulate the wavefront of object, and introduce the ptychographic scanning algorithm that is able to recover the complex amplitude information even the SLM modulation curve is inaccurate or unknown. In addition, we also design a split-beam interference experiment to calibrate the modulation curve of SLM, and using the calibrated modulation function as the initial value of the expended ptychography iterative engine (ePIE) algorithm can improve the convergence speed. We further analyze the effect of modulation function, algorithm parameters and the characteristics of the coherent light source on the quality of reconstructed image. The simulated and real experiments show that the proposed method is superior to traditional mechanical scanning methods in terms of recovering speed and accuracy, with the recovering resolution up to 14 um.      
### 54.GigaST: A 10,000-hour Pseudo Speech Translation Corpus  [ :arrow_down: ](https://arxiv.org/pdf/2204.03939.pdf)
>  This paper introduces GigaST, a large-scale pseudo speech translation (ST) corpus. We create the corpus by translating the text in GigaSpeech, an English ASR corpus, into German and Chinese. The training set is translated by a strong machine translation system and the test set is translated by human. ST models trained with an addition of our corpus obtain new state-of-the-art results on the MuST-C English-German benchmark test set. We provide a detailed description of the translation process and verify its quality. We make the translated text data public and hope to facilitate research in speech translation. Additionally, we also release the training scripts on NeurST to make it easy to replicate our systems. GigaST dataset is available at <a class="link-external link-https" href="https://st-benchmark.github.io/resources/GigaST" rel="external noopener nofollow">this https URL</a>.      
### 55.Adding Connectionist Temporal Summarization into Conformer to Improve Its Decoder Efficiency For Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03889.pdf)
>  The Conformer model is an excellent architecture for speech recognition modeling that effectively utilizes the hybrid losses of connectionist temporal classification (CTC) and attention to train model parameters. To improve the decoding efficiency of Conformer, we propose a novel connectionist temporal summarization (CTS) method that reduces the number of frames required for the attention decoder fed from the acoustic sequences generated by the encoder, thus reducing operations. However, to achieve such decoding improvements, we must fine-tune model parameters, as cross-attention observations are changed and thus require corresponding refinements. Our final experiments show that, with a beamwidth of 4, the LibriSpeech's decoding budget can be reduced by up to 20% and for FluentSpeech data it can be reduced by 11%, without losing ASR accuracy. An improvement in accuracy is even found for the LibriSpeech "test-other" set. The word error rate (WER) is reduced by 6\% relative at the beam width of 1 and by 3% relative at the beam width of 4.      
### 56.Transducer-based language embedding for spoken language identification  [ :arrow_down: ](https://arxiv.org/pdf/2204.03888.pdf)
>  The acoustic and linguistic features are important cues for the spoken language identification (LID) task. Recent advanced LID systems mainly use acoustic features that lack the usage of explicit linguistic feature encoding. In this paper, we propose a novel transducer-based language embedding approach for LID tasks by integrating an RNN transducer model into a language embedding framework. Benefiting from the advantages of the RNN transducer's linguistic representation capability, the proposed method can exploit both phonetically-aware acoustic features and explicit linguistic features for LID tasks. Experiments were carried out on the large-scale multilingual LibriSpeech and VoxLingua107 datasets. Experimental results showed the proposed method significantly improves the performance on LID tasks with 12% to 59% and 16% to 24% relative improvement on in-domain and cross-domain datasets, respectively.      
### 57.A Study of Different Ways to Use The Conformer Model For Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2204.03879.pdf)
>  SLU combines ASR and NLU capabilities to accomplish speech-to-intent understanding. In this paper, we compare different ways to combine ASR and NLU, in particular using a single Conformer model with different ways to use its components, to better understand the strengths and weaknesses of each approach. We find that it is not necessarily a choice between two-stage decoding and end-to-end systems which determines the best system for research or application. System optimization still entails carefully improving the performance of each component. It is difficult to prove that one direction is conclusively better than the other. In this paper, we also propose a novel connectionist temporal summarization (CTS) method to reduce the length of acoustic encoding sequences while improving the accuracy and processing speed of end-to-end models. This method achieves the same intent accuracy as the best two-stage SLU recognition with complicated and time-consuming decoding but does so at lower computational cost. This stacked end-to-end SLU system yields an intent accuracy of 93.97% for the SmartLights far-field set, 95.18% for the close-field set, and 99.71% for FluentSpeech.      
### 58.Reliable Visualization for Deep Speaker Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03852.pdf)
>  In spite of the impressive success of convolutional neural networks (CNNs) in speaker recognition, our understanding to CNNs' internal functions is still limited. A major obstacle is that some popular visualization tools are difficult to apply, for example those producing saliency maps. The reason is that speaker information does not show clear spatial patterns in the temporal-frequency space, which makes it hard to interpret the visualization results, and hence hard to confirm the reliability of a visualization tool. In this paper, we conduct an extensive analysis on three popular visualization methods based on CAM: Grad-CAM, Score-CAM and Layer-CAM, to investigate their reliability for speaker recognition tasks. Experiments conducted on a state-of-the-art ResNet34SE model show that the Layer-CAM algorithm can produce reliable visualization, and thus can be used as a promising tool to explain CNN-based speaker models. The source code and examples are available in our project page: <a class="link-external link-http" href="http://project.cslt.org/" rel="external noopener nofollow">this http URL</a>.      
### 59.Enhanced exemplar autoencoder with cycle consistency loss in any-to-one voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2204.03847.pdf)
>  Recent research showed that an autoencoder trained with speech of a single speaker, called exemplar autoencoder (eAE), can be used for any-to-one voice conversion (VC). Compared to large-scale many-to-many models such as AutoVC, the eAE model is easy and fast in training, and may recover more details of the target speaker. <br>To ensure VC quality, the latent code should represent and only represent content information. However, this is not easy to attain for eAE as it is unaware of any speaker variation in model training. To tackle the problem, we propose a simple yet effective approach based on a cycle consistency loss. Specifically, we train eAEs of multiple speakers with a shared encoder, and meanwhile encourage the speech reconstructed from any speaker-specific decoder to get a consistent latent code as the original speech when cycled back and encoded again. Experiments conducted on the AISHELL-3 corpus showed that this new approach improved the baseline eAE consistently. The source code and examples are available at the project page: <a class="link-external link-http" href="http://project.cslt.org/" rel="external noopener nofollow">this http URL</a>.      
### 60.Barrier Bayesian Linear Regression: Online Learning of Control Barrier Conditions for Safety-Critical Control of Uncertain Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.03801.pdf)
>  In this work, we consider the problem of designing a safety filter for a nonlinear uncertain control system. Our goal is to augment an arbitrary controller with a safety filter such that the overall closed-loop system is guaranteed to stay within a given state constraint set, referred to as being safe. For systems with known dynamics, control barrier functions (CBFs) provide a scalar condition for determining if a system is safe. For uncertain systems, robust or adaptive CBF certification approaches have been proposed. However, these approaches can be conservative or require the system to have a particular parametric structure. For more generic uncertain systems, machine learning approaches have been used to approximate the CBF condition. These works typically assume that the learning module is sufficiently trained prior to deployment. Safety during learning is not guaranteed. We propose a barrier Bayesian linear regression (BBLR) approach that guarantees safe online learning of the CBF condition for the true, uncertain system. We assume that the error between the nominal system and the true system is bounded and exploit the structure of the CBF condition. We show that our approach can safely expand the set of certifiable control inputs despite system and learning uncertainties. The effectiveness of our approach is demonstrated in simulation using a two-dimensional pendulum stabilization task.      
### 61.Successes and critical failures of neural networks in capturing human-like speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03740.pdf)
>  Natural and artificial audition can in principle evolve different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would improve artificial hearing systems and process models of the mind and brain. Speech recognition - an area ripe for such exploration - is inherently robust in humans to a number transformations at various spectrotemporal granularities. To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus-computable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the specific conditions where model predictions of human performance differ, and (4) demonstrate a crucial failure of all artificial systems to perceptually recover where humans do, suggesting a key specification for theory and model building. These findings encourage a tighter synergy between the cognitive science and engineering of audition.      
### 62.A Kernel Method to Nonlinear Location Estimation with RSS-based Fingerprint  [ :arrow_down: ](https://arxiv.org/pdf/2204.03724.pdf)
>  This paper presents a nonlinear location estimation to infer the position of a user holding a smartphone. We consider a large location with $M$ number of grid points, each grid point is labeled with a unique fingerprint consisting of the received signal strength (RSS) values measured from $N$ number of Bluetooth Low Energy (BLE) beacons. Given the fingerprint observed by the smartphone, the user's current location can be estimated by finding the top-k similar fingerprints from the list of fingerprints registered in the database. Besides the environmental factors, the dynamicity in holding the smartphone is another source to the variation in fingerprint measurements, yet there are not many studies addressing the fingerprint variability due to dynamic smartphone positions held by human hands during online detection. To this end, we propose a nonlinear location estimation using the kernel method. Specifically, our proposed method comprises of two steps: 1) a beacon selection strategy to select a subset of beacons that is insensitive to the subtle change of holding positions, and 2) a kernel method to compute the similarity between this subset of observed signals and all the fingerprints registered in the database. The experimental results based on large-scale data collected in a complex building indicate a substantial performance gain of our proposed approach in comparison to state-of-the-art methods. The dataset consisting of the signal information collected from the beacons is available online.      
### 63.Statistical QoS Analysis of Reconfigurable Intelligent Surface-assisted D2D Communication  [ :arrow_down: ](https://arxiv.org/pdf/2204.03687.pdf)
>  This work performs the statistical QoS analysis of a Rician block-fading reconfigurable intelligent surface (RIS)-assisted D2D link in which the transmit node operates under delay QoS constraints. First, we perform mode selection for the D2D link, in which the D2D pair can either communicate directly by relaying data from RISs or through a base station (BS). Next, we provide closed-form expressions for the effective capacity (EC) of the RIS-assisted D2D link. When channel state information at the transmitter (CSIT) is available, the transmit D2D node communicates with the variable rate $r_t(n)$ (adjustable according to the channel conditions); otherwise, it uses a fixed rate $r_t$. It allows us to model the RIS-assisted D2D link as a Markov system in both cases. We also extend our analysis to overlay and underlay D2D settings. To improve the throughput of the RIS-assisted D2D link when CSIT is unknown, we use the HARQ retransmission scheme and provide the EC analysis of the HARQ-enabled RIS-assisted D2D link. Finally, simulation results demonstrate that: i) the EC increases with an increase in RIS elements, ii) the EC decreases when strict QoS constraints are imposed at the transmit node, iii) the EC decreases with an increase in the variance of the path loss estimation error, iv) the EC increases with an increase in the probability of ON states, v) EC increases by using HARQ when CSIT is unknown, and it can reach up to $5\times$ the usual EC (with no HARQ and without CSIT) by using the optimal number of retransmissions.      
