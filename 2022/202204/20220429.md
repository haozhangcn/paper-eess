# ArXiv eess --Fri, 29 Apr 2022
### 1.Fast Cross-Correlation for TDoA Estimation on Small Aperture Microphone Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2204.13622.pdf)
>  This paper introduces the Fast Cross-Correlation (FCC) method for Time Difference of Arrival (TDoA) Estimation for pairs of microphones on a small aperture microphone array. FCC relies on low-rank decomposition and exploits symmetry in even and odd bases to speed up computation while preserving TDoA accuracy. FCC reduces the number of flops by a factor of 4.5 and the execution speed by factors of 8.2, 2.6 and 2.7 on a Raspberry Pi Zero, a Raspberry Pi 4 and a Nvidia Jetson TX2 devices, respectively, compared to the state-of-the-art Generalized Cross-Correlation (GCC) method that relies on the Fast Fourier Transform (FFT). This improvement can provide portable microphone arrays with extended battery life and allow real-time processing on low-cost hardware.      
### 2.Generative Adversarial Networks for Image Super-Resolution: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2204.13620.pdf)
>  Single image super-resolution (SISR) has played an important role in the field of image processing. Recent generative adversarial networks (GANs) can achieve excellent results on low-resolution images with small samples. However, there are little literatures summarizing different GANs in SISR. In this paper, we conduct a comparative study of GANs from different perspectives. We first take a look at developments of GANs. Second, we present popular architectures for GANs in big and small samples for image applications. Then, we analyze motivations, implementations and differences of GANs based optimization methods and discriminative learning for image super-resolution in terms of supervised, semi-supervised and unsupervised manners. Next, we compare performance of these popular GANs on public datasets via quantitative and qualitative analysis in SISR. Finally, we highlight challenges of GANs and potential research points for SISR.      
### 3.Bona fide Riesz projections for density estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.13606.pdf)
>  The projection of sample measurements onto a reconstruction space represented by a basis on a regular grid is a powerful and simple approach to estimate a probability density function. In this paper, we focus on Riesz bases and propose a projection operator that, in contrast to previous works, guarantees the bona fide properties for the estimate, namely, non-negativity and total probability mass $1$. Our bona fide projection is defined as a convex problem. We propose solution techniques and evaluate them. Results suggest an improved performance, specifically in circumstances prone to rippling effects.      
### 4.Signal Recovery with Non-Expansive Generative Network Priors  [ :arrow_down: ](https://arxiv.org/pdf/2204.13599.pdf)
>  We study compressive sensing with a deep generative network prior. Initial theoretical guarantees for efficient recovery from compressed linear measurements have been developed for signals in the range of a ReLU network with Gaussian weights and logarithmic expansivity: that is when each layer is larger than the previous one by a logarithmic factor. It was later shown that constant expansivity is sufficient for recovery. It has remained open whether the expansivity can be relaxed allowing for networks with contractive layers, as often the case of real generators. In this work we answer this question, proving that a signal in the range of a Gaussian generative network can be recovered from a few linear measurements provided that the width of the layers is proportional to the input layer size (up to log factors). This condition allows the generative network to have contractive layers. Our result is based on showing that Gaussian matrices satisfy a matrix concentration inequality, which we term Range Restricted Weight Distribution Condition (R2WDC), and weakens the Weight Distribution Condition (WDC) upon which previous theoretical guarantees were based on. The WDC has also been used to analyze other signal recovery problems with generative network priors. By replacing the WDC with the R2WDC, we are able to extend previous results for signal recovery with expansive generative network priors to non-expansive ones. We discuss these extensions for phase retrieval, denoising, and spiked matrix recovery.      
### 5.PhysioGAN: Training High Fidelity Generative Model for Physiological Sensor Readings  [ :arrow_down: ](https://arxiv.org/pdf/2204.13597.pdf)
>  Generative models such as the variational autoencoder (VAE) and the generative adversarial networks (GAN) have proven to be incredibly powerful for the generation of synthetic data that preserves statistical properties and utility of real-world datasets, especially in the context of image and natural language text. Nevertheless, until now, there has no successful demonstration of how to apply either method for generating useful physiological sensory data. The state-of-the-art techniques in this context have achieved only limited success. We present PHYSIOGAN, a generative model to produce high fidelity synthetic physiological sensor data readings. PHYSIOGAN consists of an encoder, decoder, and a discriminator. We evaluate PHYSIOGAN against the state-of-the-art techniques using two different real-world datasets: ECG classification and activity recognition from motion sensors datasets. We compare PHYSIOGAN to the baseline models not only the accuracy of class conditional generation but also the sample diversity and sample novelty of the synthetic datasets. We prove that PHYSIOGAN generates samples with higher utility than other generative models by showing that classification models trained on only synthetic data generated by PHYSIOGAN have only 10% and 20% decrease in their classification accuracy relative to classification models trained on the real data. Furthermore, we demonstrate the use of PHYSIOGAN for sensor data imputation in creating plausible results.      
### 6.Predicting Sleeping Quality using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.13584.pdf)
>  Identifying sleep stages and patterns is an essential part of diagnosing and treating sleep disorders. With the advancement of smart technologies, sensor data related to sleeping patterns can be captured easily. In this paper, we propose a Convolution Neural Network (CNN) architecture that improves the classification performance. In particular, we benchmark the classification performance from different methods, including traditional machine learning methods such as Logistic Regression (LR), Decision Trees (DT), k-Nearest Neighbour (k-NN), Naive Bayes (NB) and Support Vector Machine (SVM), on 3 publicly available sleep datasets. The accuracy, sensitivity, specificity, precision, recall, and F-score are reported and will serve as a baseline to simulate the research in this direction in the future.      
### 7.Une version polyatomique de l'algorithme Frank-Wolfe pour résoudre le problème LASSO en grandes dimensions  [ :arrow_down: ](https://arxiv.org/pdf/2204.13557.pdf)
>  Nous nous intéressons à la reconstruction parcimonieuse d'images à l'aide du problème d'optimisation régularisé LASSO. Dans de nombreuses applications pratiques, les grandes dimensions des objets à reconstruire limitent, voire empêchent, l'utilisation des méthodes de résolution proximales classiques. C'est le cas par exemple en radioastronomie. Nous détaillons dans cet article le fonctionnement de l'algorithme \textit{Frank-Wolfe Polyatomique}, spécialement développé pour résoudre le problème LASSO dans ces contextes exigeants. Nous démontrons sa supériorité par rapport aux méthodes proximales dans des situations en grande dimension avec des mesures de Fourier, lors de la résolution de problèmes simulés inspirés de la radio-interférométrie. <br>-- <br>We consider the problem of recovering sparse images by means of the penalised optimisation problem LASSO. For various practical applications, it is impossible to rely on the proximal solvers commonly used for that purpose due to the size of the objects to recover, as it is the case for radio astronomy. In this article we explain the mechanisms of the \textit{Polyatomic Frank-Wolfe algorithm}, specifically designed to minimise the LASSO problem in such challenging contexts. We demonstrate in simulated problems inspired from radio-interferometry the preeminence of this algorithm over the proximal methods for high dimensional images with Fourier measurements.      
### 8.Generalizing Hybrid Integrator-Gain Systems Using Fractional Calculus  [ :arrow_down: ](https://arxiv.org/pdf/2204.13544.pdf)
>  The Hybrid Integral Gain Systems (HIGS) has recently gained a lot of attention in the control of precision motion systems. HIGS is a nonlinear low pass filter with a 52 degree phase advantage over its linear counterpart. This property allows us to avoid the limitations typically associated with linear controllers like the waterbed effect and bode's phase gain relation. In this paper, we generalize HIGS via replacing the involved integer order integrator with a fractional order one to adapt the phase lead from 0 degree (linear low pass filter) to 52 degree (HIGS). To analyze this filter in the frequency domain, the describing function of the proposed filter, i.e., the fractional-order HIGS, is obtained using the Fourier expansion of the output signal. In addition, this generalized HIGS is implemented in a PID structure controlling a double integrator system to validate the performance of the proposed filter in the time domain, in which changing the fractional variable from zero to one, the output varies from the response of a nonlinear control system to a linear one.      
### 9.Sensing RISs: Enabling Dimension-Independent CSI Acquisition for Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2204.13505.pdf)
>  Reconfigurable intelligent surfaces (RISs) are envisioned as a potentially transformative technology for future wireless communications. However, RIS's inability to process signals and their attendant increased channel dimension have brought new challenges to RIS-assisted systems, which greatly increases the pilot overhead required for channel estimation. To address these problems, several prior contributions that enhance the hardware architecture of RISs or develop algorithms to exploit the channels' mathematical properties have been made, where the required pilot overhead is reduced to be proportional to the number of RIS elements. In this paper, we propose a dimension-independent channel state information (CSI) acquisition approach in which the required pilot overhead is independent of the number of RIS elements. Specifically, in contrast to traditional signal transmission methods, where signals from the base station (BS) and the users are transmitted in different time slots, we propose a novel method in which signals are transmitted from the BS and the user simultaneously during CSI acquisition. Under this method, an electromagnetic interference random field (IRF) will be induced on the RIS, and we employ a sensing RIS to capture its features. Moreover, we develop three algorithms for parameter estimation in this system, and also derive the Cramer-Rao lower bound (CRLB) and an asymptotic expression for it. Simulation results verify that our proposed signal transmission method and the corresponding algorithms can achieve dimension-independent CSI acquisition for beamforming.      
### 10.RIS-aided Joint Localization and Synchronization with a Single-Antenna Receiver: Beamforming Design and Low-Complexity Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.13484.pdf)
>  Reconfigurable intelligent surfaces (RISs) have attracted enormous interest thanks to their ability to overcome line-of-sight blockages in mmWave systems, enabling in turn accurate localization with minimal infrastructure. Less investigated are however the benefits of exploiting RIS with suitably designed beamforming strategies for optimized localization and synchronization performance. In this paper, a novel low-complexity method for joint localization and synchronization based on an optimized design of the base station (BS) active precoding and RIS passive phase profiles is proposed, for the challenging case of a single-antenna receiver. The theoretical position error bound is first derived and used as metric to jointly optimize the BS-RIS beamforming, assuming a priori knowledge of the user position. By exploiting the low-dimensional structure of the solution, a novel codebook-based robust design strategy with optimized beam power allocation is then proposed, which provides low-complexity while taking into account the uncertainty on the user position. Finally, a reduced-complexity maximum-likelihood based estimation procedure is devised to jointly recover the user position and the synchronization offset. Extensive numerical analysis shows that the proposed joint BS-RIS beamforming scheme provides enhanced localization and synchronization performance compared to existing solutions, with the proposed estimator attaining the theoretical bounds even at low signal-to-noise-ratio and in the presence of additional uncontrollable multipath propagation.      
### 11.Attention Based Neural Networks for Wireless Channel Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.13465.pdf)
>  In this paper, we deploy the self-attention mechanism to achieve improved channel estimation for orthogonal frequency-division multiplexing waveforms in the downlink. Specifically, we propose a new hybrid encoder-decoder structure (called HA02) for the first time which exploits the attention mechanism to focus on the most important input information. In particular, we implement a transformer encoder block as the encoder to achieve the sparsity in the input features and a residual neural network as the decoder respectively, inspired by the success of the attention mechanism. Using 3GPP channel models, our simulations show superior estimation performance compared with other candidate neural network methods for channel estimation.      
### 12.Efficient Approximation of Action Potentials with High-Order Shape Preservation in Unsupervised Spike Sorting  [ :arrow_down: ](https://arxiv.org/pdf/2204.13463.pdf)
>  This paper presents a novel approximation unit added to the conventional spike processing chain which provides an appreciable reduction of complexity of the high-hardware cost feature extractors. The use of the Taylor polynomial is proposed and modelled employing its cascaded derivatives to non-uniformly capture the essential samples in each spike for reliable feature extraction and sorting. Inclusion of the approximation unit can provide 3X compression (i.e. from 66 to 22 samples) to the spike waveforms while preserving their shapes. Detailed spike waveform sequences based on in-vivo measurements have been generated using a customized neural simulator for performance assessment of the approximation unit tested on six published feature extractors. For noise levels {\sigma}_N between 0.05 and 0.3 and groups of 3 spikes in each channel, all the feature extractors provide almost same sorting performance before and after approximation. The overall implementation cost when including the approximation unit and feature extraction shows a large reduction (i.e. up to 8.7X) in the hardware costly and more accurate feature extractors, offering a substantial improvement in feature extraction design.      
### 13.Mobile EEG artifact correction on limited hardware using artifact subspace recon- struction  [ :arrow_down: ](https://arxiv.org/pdf/2204.13444.pdf)
>  Biological data like electroencephalography (EEG) are typically contaminated by unwanted signals, called artifacts. Therefore, many applications dealing with biological data with low signal-to-noise ratio require robust artifact correction. For some applications like brain-computer-interfaces (BCI), the artifact correction needs to be real-time capable. Artifact subspace reconstruction (ASR) is a statistical method for artifact reduction in EEG. However, in its current implementation, ASR cannot be used in mobile data recordings using limited hardware easily. In this report, we add to the growing field of portable, online signal processing methods by describing an implementation of ASR for limited hardware like single-board computers. We describe the architecture, the process of translating and compiling a Matlab codebase for a research platform, and a set of validation tests using publicly available data sets. The implementation of ASR on limited, portable hardware facilitates the online interpretation of EEG signals acquired outside of the laboratory environment.      
### 14.Safety-Aware Optimal Control in Motion Planning  [ :arrow_down: ](https://arxiv.org/pdf/2204.13380.pdf)
>  Optimisation is a popular tool of generating control laws for motion planning in a complex environment. The existence of multiple irregular obstacles in the working space introduces nonconvex collision avoidance constraints, making the optimal control problem intractable. One efficient approach to address this issue is successive convex approximation (SCA), where the nonconvex problem is convexified and solved successively. However, this approach still faces two main challenges: 1) high computational complexity, incurred by multiple constraints when solving the optimal control problem with a long planning horizon and multiple obstacles; 2) infeasibility, caused by linearization about infeasible reference points. To address these challenges, this paper proposes a backward receding SCA (BRSCA) approach, which leverages dynamic programming with a primal-dual iteration to decrease computational complexity; and designs a dynamic constraints-selection rule to avoid infeasibility. Moreover, it is found that the proposed BRSCA approach is applicable to time-varying control limits. Numerical simulations and hardware experiments demonstrate that BRSCA has a higher probability of finding feasible solutions and reduces the computation time by at least 17.4%, compared to other methodologies in the literature.      
### 15.BAGNet: Bidirectional Aware Guidance Network for Malignant Breast lesions Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.13342.pdf)
>  Breast lesions segmentation is an important step of computer-aided diagnosis system, and it has attracted much attention. However, accurate segmentation of malignant breast lesions is a challenging task due to the effects of heterogeneous structure and similar intensity distributions. In this paper, a novel bidirectional aware guidance network (BAGNet) is proposed to segment the malignant lesion from breast ultrasound images. Specifically, the bidirectional aware guidance network is used to capture the context between global (low-level) and local (high-level) features from the input coarse saliency map. The introduction of the global feature map can reduce the interference of surrounding tissue (background) on the lesion regions. To evaluate the segmentation performance of the network, we compared with several state-of-the-art medical image segmentation methods on the public breast ultrasound dataset using six commonly used evaluation metrics. Extensive experimental results indicate that our method achieves the most competitive segmentation results on malignant breast ultrasound images.      
### 16.Collision Avoidance for Elliptical Agents with Control Barrier Function Utilizing Supporting Lines  [ :arrow_down: ](https://arxiv.org/pdf/2204.13287.pdf)
>  This paper presents a collision avoidance method for elliptical agents traveling in a two-dimensional space. We first formulate a separation condition for two elliptical agents utilizing a signed distance from a supporting line of an agent to the other agent, which renders a positive value if two ellipses are separated by the line. Because this signed distance could yield a shorter length than the actual distance between two ellipses, the supporting line is rotated so that the signed distance from the line to the other ellipse is maximized. We prove that this maximization problem renders the signed distance equivalent to the actual distance between two ellipses, hence not causing the conservative evasive motion. Then, we propose the collision avoidance method utilizing novel control barrier functions incorporating a gradient-based update law of a supporting line. The validity of the proposed methods is evaluated in the simulations.      
### 17.Resource-efficient domain adaptive pre-training for medical images  [ :arrow_down: ](https://arxiv.org/pdf/2204.13280.pdf)
>  The deep learning-based analysis of medical images suffers from data scarcity because of high annotation costs and privacy concerns. Researchers in this domain have used transfer learning to avoid overfitting when using complex architectures. However, the domain differences between pre-training and downstream data hamper the performance of the downstream task. Some recent studies have successfully used domain-adaptive pre-training (DAPT) to address this issue. In DAPT, models are initialized with the generic dataset pre-trained weights, and further pre-training is performed using a moderately sized in-domain dataset (medical images). Although this technique achieved good results for the downstream tasks in terms of accuracy and robustness, it is computationally expensive even when the datasets for DAPT are moderately sized. These compute-intensive techniques and models impact the environment negatively and create an uneven playing field for researchers with limited resources. This study proposed computationally efficient DAPT without compromising the downstream accuracy and robustness. This study proposes three techniques for this purpose, where the first (partial DAPT) performs DAPT on a subset of layers. The second one adopts a hybrid strategy (hybrid DAPT) by performing partial DAPT for a few epochs and then full DAPT for the remaining epochs. The third technique performs DAPT on simplified variants of the base architecture. The results showed that compared to the standard DAPT (full DAPT), the hybrid DAPT technique achieved better performance on the development and external datasets. In contrast, simplified architectures (after DAPT) achieved the best robustness while achieving modest performance on the development dataset .      
### 18.Neural network controllers for uncertain linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.13209.pdf)
>  We consider the design of reliable neural network (NN)-based approximations of traditional stabilizing controllers for linear systems affected by polytopic uncertainty, including controllers with variable structure and those based on a minimal selection policy. We develop a systematic procedure to certify the closed-loop stability and performance of a polytopic system when a rectified linear unit (ReLU)-based approximation replaces such traditional controllers. We provide sufficient conditions to ensure stability involving the worst-case approximation error and the Lipschitz constant characterizing the error function between ReLU-based and traditional controller-based state-to-input mappings, and further provide offline, mixed-integer optimization-based methods that allow us to compute those quantities exactly.      
### 19.TDD frame design for interference handling in mobile IAB networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.13198.pdf)
>  Integrated access and backhaul (IAB) is envisioned as a possible solution to address the need for network densification in situations where fiber connection is not viable. In Release 18, 3rd generation partnership project (3GPP) will take another step on extending IAB capabilities. With mobile IAB (mIAB), IAB nodes can be deployed within vehicles, e.g., buses. As in every new technology, performance assessment and evaluation of the impact of interference is of interest for industry and academia. In this paper, we present contributions on those topics. First, we evaluate the performance of mIAB compared to fiber connected deployments. Moreover, we study the impact of interference on the performance of mIAB networks and propose a solution based on inserting silent slots on the time division duplex (TDD) frame pattern. According to our simulation results, mIAB is capable of improving performance of onboard user equipments (UEs) without harming too much the quality of service (QoS) of surrounding UEs. Furthermore, we show that the TDD frame pattern should be carefully designed to account for scenarios with different levels of interference.      
### 20.Channel Modeling for Physically Secure Electro-Quasistatic In-Body to Out-of-Body Communication with Galvanic Tx and Multimodal Rx  [ :arrow_down: ](https://arxiv.org/pdf/2204.13184.pdf)
>  Increasing number of devices being used in and around the human body has resulted in the exploration of the human body as a communication medium. In this paper, we design a channel model for implantable devices communicating outside the body using physically secure Electro-Quasistatic Human Body Communication. A galvanic receiver shows 5dB lower path loss than capacitive receiver when placed close to transmitter whereas a capacitive receiver has around 15dB lower path loss for larger separation between the transmitter and receiver. Finite Element Method (FEM) based simulations are used to analyze the communication channel for different receiver topologies and experimental data is used to validate the simulation results.      
### 21.A Quantitative Analysis of Physical Security and Path Loss With Frequency for IBOB Channel  [ :arrow_down: ](https://arxiv.org/pdf/2204.13181.pdf)
>  Security vulnerabilities demonstrated in implantable medical devices have opened the door for research into physically secure and low power communication methodologies. In this study, we perform a comparative analysis of commonly used ISM frequency bands and human body communication (HBC) for data transfer from in-body to out-of-body (IBOB). We develop a figure of merit (FoM) that comprises of the critical parameters to quantitatively compare the communication methodologies. We perform finite-element method (FEM)-based simulations and experiments to validate the FoM developed.      
### 22.Link Budget Analysis for Free-Space Optical Satellite Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.13177.pdf)
>  Free-space optical satellite networks (FSOSNs) will employ free-space optical links between satellites and between satellites and ground stations, and the link budget for optical inter-satellite links and optical uplink/downlink is analyzed in this paper. The satellites in these FSOSNs will have limited energy and thereby limited power, and we investigate the effect of link distance and link margin on optical inter-satellite link transmission power, and the effect of slant distance, elevation angle, and link margin on optical uplink/downlink transmission power. We model these optical links and compute the results for various parameters. We observe that the transmission power increases when the link distance increases for inter-satellite and uplink/downlink communications, while the transmission power decreases when the elevation angle increases for uplink/downlink transmission. We also observe an inverse relationship between link margin and link distance. Furthermore, we highlight some practical insights and design guidelines gained from this analysis.      
### 23.Seeker: Synergizing Mobile and Energy Harvesting Wearable Sensors for Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.13106.pdf)
>  There is an increasing demand for intelligent processing on emerging ultra-low-power internet of things (IoT) devices, and recent works have shown substantial efficiency boosts by executing inference tasks directly on the IoT device (node) rather than merely transmitting sensor data. However, the computation and power demands of Deep Neural Network (DNN)-based inference pose significant challenges for nodes in an energy-harvesting wireless sensor network (EH-WSN). Moreover, these tasks often require responses from multiple physically distributed EH sensor nodes, which imposes crucial system optimization challenges in addition to per-node constraints. <br>To address these challenges, we propose \emph{Seeker}, a novel approach to efficiently execute DNN inferences for Human Activity Recognition (HAR) tasks, using both an EH-WSN and a host mobile device. Seeker minimizes communication overheads and maximizes computation at each sensor without violating the quality of service. \emph{Seeker} uses a \emph{store-and-execute} approach to complete a subset of inferences on the EH sensor node, reducing communication with the mobile host. Further, for those inferences unfinished because of harvested energy constraints, it leverages an \emph{activity aware coreset} (AAC) construction to efficiently communicate compact features to the host device where ensemble techniques are used to efficiently finish the inferences. \emph{Seeker} performs HAR with $86.8\%$ accuracy, surpassing the $81.2\%$ accuracy of a state of the art approach. Moreover, by using AAC, it lowers the communication data volume by $8.9\times$.      
### 24.Unaligned Supervision For Automatic Music Transcription in The Wild  [ :arrow_down: ](https://arxiv.org/pdf/2204.13668.pdf)
>  Multi-instrument Automatic Music Transcription (AMT), or the decoding of a musical recording into semantic musical content, is one of the holy grails of Music Information Retrieval. Current AMT approaches are restricted to piano and (some) guitar recordings, due to difficult data collection. In order to overcome data collection barriers, previous AMT approaches attempt to employ musical scores in the form of a digitized version of the same song or piece. The scores are typically aligned using audio features and strenuous human intervention to generate training labels. We introduce NoteEM, a method for simultaneously training a transcriber and aligning the scores to their corresponding performances, in a fully-automated process. Using this unaligned supervision scheme, complemented by pseudo-labels and pitch-shift augmentation, our method enables training on in-the-wild recordings with unprecedented accuracy and instrumental variety. Using only synthetic data and unaligned supervision, we report SOTA note-level accuracy of the MAPS dataset, and large favorable margins on cross-dataset evaluations. We also demonstrate robustness and ease of use; we report comparable results when training on a small, easily obtainable, self-collected dataset, and we propose alternative labeling to the MusicNet dataset, which we show to be more accurate. Our project page is available at <a class="link-external link-https" href="https://benadar293.github.io" rel="external noopener nofollow">this https URL</a>      
### 25.How social influence affects the wisdom of crowds in influence networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.13610.pdf)
>  A long-standing debate is whether social influence improves the collective wisdom of a crowd or undermines it. This paper addresses this question based on a naive learning setting in influence systems theory: in our models individuals evolve their estimates of an unknown truth according to the weighted-average opinion dynamics. A formal mathematization is provided with rigorous theoretical analysis. We obtain various conditions for improving, optimizing and undermining the crowd accuracy, respectively. We prove that if the wisdom of finite-size group is improved, then the collective estimate converges to the truth as group size increases, provided individuals' variances are finite. We show that whether social influence improves or undermines the wisdom is determined by the social power allocation of the influence system: if the influence system allocates relatively larger social power to relatively more accurate individuals, it improves the wisdom; on the contrary, if the influence system assigns less social power to more accurate individuals, it undermines the wisdom. At a population level, individuals' susceptibilities to interpersonal influence and network centralities are both crucial. To improve the wisdom, more accurate individuals should be less susceptible and have larger network centralities. Particularly, in democratic influence networks, if relatively more accurate individuals are relatively less susceptible, the wisdom is improved; if more accurate individuals are more susceptible, the wisdom is undermined, which is consistent with the reported empirical evidence. Our investigation provides a theoretical framework for understanding the role social influence plays in the emergence of collective wisdom.      
### 26.Emotion Recognition In Persian Speech Using Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.13601.pdf)
>  Speech Emotion Recognition (SER) is of great importance in Human-Computer Interaction (HCI), as it provides a deeper understanding of the situation and results in better interaction. In recent years, various machine learning and deep learning algorithms have been developed to improve SER techniques. Recognition of emotions depends on the type of expression that varies between different languages. In this article, to further study this important factor in Farsi, we examine various deep learning techniques on the SheEMO dataset. Using signal features in low- and high-level descriptions and different deep networks and machine learning techniques, Unweighted Average Recall (UAR) of 65.20 is achieved with an accuracy of 78.29.      
### 27.A Close Look into Human Activity Recognition Models using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.13589.pdf)
>  Human activity recognition using deep learning techniques has become increasing popular because of its high effectivity with recognizing complex tasks, as well as being relatively low in costs compared to more traditional machine learning techniques. This paper surveys some state-of-the-art human activity recognition models that are based on deep learning architecture and has layers containing Convolution Neural Networks (CNN), Long Short-Term Memory (LSTM), or a mix of more than one type for a hybrid system. The analysis outlines how the models are implemented to maximize its effectivity and some of the potential limitations it faces.      
### 28.Asymptotically Optimal Quasi-Complementary Code Sets from Multivariate Functions  [ :arrow_down: ](https://arxiv.org/pdf/2204.13538.pdf)
>  Owing to the more significant set size properties as compared to the set of complete complementary codes (CCCs), quasi-complementary code sets (QCCSs) are more convenient to support a large number of users in multicarrier code-division multiple-access (MC-CDMA) system over CCCs. Besides set size, it is also desirable to have a low maximum aperiodic correlation magnitude and small alphabet size. This paper aims to construct asymptotically optimal and near-optimal aperiodic QCCSs having a small alphabet size and low maximum correlation magnitude. Using multivariate functions and its associated graph, we propose a family of QCCSs consisting of multiple sets of CCCs and determine the parameters of the proposed QCCSs. Unlike the existing constructions of aperiodic QCCSs, the proposed construction can maintain a small alphabet size irrespective of the increasing sequence length and large set size.      
### 29.Port-Hamiltonian Dynamic Mode Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2204.13474.pdf)
>  We present a novel physics-informed system identification method to construct a passive linear time-invariant system. In more detail, for a given quadratic energy functional, measurements of the input, state, and output of a system in the time domain, we find a realization that approximates the data well while guaranteeing that the energy functional satisfies a dissipation inequality. To this end, we use the framework of port-Hamiltonian (pH) systems and modify the dynamic mode decomposition to be feasible for continuous-time pH systems. We propose an iterative numerical method to solve the corresponding least-squares minimization problem. We construct an effective initialization of the algorithm by studying the least-squares problem in a weighted norm, for which we present the analytical minimum-norm solution. The efficiency of the proposed method is demonstrated with several numerical examples.      
### 30.Regotron: Regularizing the Tacotron2 architecture via monotonic alignment loss  [ :arrow_down: ](https://arxiv.org/pdf/2204.13437.pdf)
>  Recent deep learning Text-to-Speech (TTS) systems have achieved impressive performance by generating speech close to human parity. However, they suffer from training stability issues as well as incorrect alignment of the intermediate acoustic representation with the input text sequence. In this work, we introduce Regotron, a regularized version of Tacotron2 which aims to alleviate the training issues and at the same time produce monotonic alignments. Our method augments the vanilla Tacotron2 objective function with an additional term, which penalizes non-monotonic alignments in the location-sensitive attention mechanism. By properly adjusting this regularization term we show that the loss curves become smoother, and at the same time Regotron consistently produces monotonic alignments in unseen examples even at an early stage (13\% of the total number of epochs) of its training process, whereas the fully converged Tacotron2 fails to do so. Moreover, our proposed regularization method has no additional computational overhead, while reducing common TTS mistakes and achieving slighlty improved speech naturalness according to subjective mean opinion scores (MOS) collected from 50 evaluators.      
### 31.Pseudo strong labels for large scale weakly supervised audio tagging  [ :arrow_down: ](https://arxiv.org/pdf/2204.13430.pdf)
>  Large-scale audio tagging datasets inevitably contain imperfect labels, such as clip-wise annotated (temporally weak) tags with no exact on- and offsets, due to a high manual labeling cost. This work proposes pseudo strong labels (PSL), a simple label augmentation framework that enhances the supervision quality for large-scale weakly supervised audio tagging. A machine annotator is first trained on a large weakly supervised dataset, which then provides finer supervision for a student model. Using PSL we achieve an mAP of 35.95 balanced train subset of Audioset using a MobileNetV2 back-end, significantly outperforming approaches without PSL. An analysis is provided which reveals that PSL mitigates missing labels. Lastly, we show that models trained with PSL are also superior at generalizing to the Freesound datasets (FSD) than their weakly trained counterparts.      
### 32.On the Role of Field of View for Occlusion Removal with Airborne Optical Sectioning  [ :arrow_down: ](https://arxiv.org/pdf/2204.13371.pdf)
>  Occlusion caused by vegetation is an essential problem for remote sensing applications in areas, such as search and rescue, wildfire detection, wildlife observation, surveillance, border control, and others. Airborne Optical Sectioning (AOS) is an optical, wavelength-independent synthetic aperture imaging technique that supports computational occlusion removal in real-time. It can be applied with manned or unmanned aircrafts, such as drones. In this article, we demonstrate a relationship between forest density and field of view (FOV) of applied imaging systems. This finding was made with the help of a simulated procedural forest model which offers the consideration of more realistic occlusion properties than our previous statistical model. While AOS has been explored with automatic and autonomous research prototypes in the past, we present a free AOS integration for DJI systems. It enables bluelight organizations and others to use and explore AOS with compatible, manually operated, off-the-shelf drones. The (digitally cropped) default FOV for this implementation was chosen based on our new finding.      
### 33.Joint Sum Rate and Blocklength Optimization in RIS-aided Short Packet URLLC Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.13369.pdf)
>  In this paper, a multi-objective optimization problem (MOOP) is proposed for maximizing the achievable finite blocklength (FBL) rate while minimizing the utilized channel blocklengths (CBLs) in a reconfigurable intelligent surface (RIS)-assisted short packet communication system. The formulated MOOP has two objective functions namely maximizing the total FBL rate with a target error probability, and minimizing the total utilized CBLs which is directly proportional to the transmission duration. The considered MOOP variables are the base station (BS) transmit power, number of CBLs, and passive beamforming at the RIS. Since the proposed non-convex problem is intractable to solve, the Tchebyshev method is invoked to transform it into a single-objective OP, then the alternating optimization (AO) technique is employed to iteratively obtain optimized parameters in three main sub-problems. The numerical results show a fundamental trade-off between maximizing the achievable rate in the FBL regime and reducing the transmission duration. Also, the applicability of RIS technology is emphasized in reducing the utilized CBLs while increasing the achievable rate significantly.      
### 34.Semantic Communication: An Information Bottleneck View  [ :arrow_down: ](https://arxiv.org/pdf/2204.13366.pdf)
>  Motivated by recent success of machine learning tools at the PHY layer and driven by high bandwidth demands of the next wireless communication standard 6G, the old idea of semantic communication by Weaver from 1949 has received considerable attention. It breaks with the classic design paradigm according to Shannon by aiming to transmit the meaning of a message rather than its exact copy and thus potentially allows for savings in bandwidth. <br>In this work, inspired by Weaver, we propose an information-theoretic framework where the semantic context is explicitly introduced into probabilistic models. In particular, for bandwidth efficient transmission, we define semantic communication system design as an Information Bottleneck optimization problem and consider important implementation aspects. Further, we uncover the restrictions of the classic 5G communication system design w.r.t. semantic context. Notably, based on the example of distributed image classification, we reveal the huge potential of a semantic communication system design. Numerical results show a tremendous saving in bandwidth of 20 dB with our proposed approach ISCNet compared to a classic PHY layer design.      
### 35.Deep Generalized Unfolding Networks for Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2204.13348.pdf)
>  Deep neural networks (DNN) have achieved great success in image restoration. However, most DNN methods are designed as a black box, lacking transparency and interpretability. Although some methods are proposed to combine traditional optimization algorithms with DNN, they usually demand pre-defined degradation processes or handcrafted assumptions, making it difficult to deal with complex and real-world applications. In this paper, we propose a Deep Generalized Unfolding Network (DGUNet) for image restoration. Concretely, without loss of interpretability, we integrate a gradient estimation strategy into the gradient descent step of the Proximal Gradient Descent (PGD) algorithm, driving it to deal with complex and real-world image degradation. In addition, we design inter-stage information pathways across proximal mapping in different PGD iterations to rectify the intrinsic information loss in most deep unfolding networks (DUN) through a multi-scale and spatial-adaptive way. By integrating the flexible gradient descent and informative proximal mapping, we unfold the iterative PGD algorithm into a trainable DNN. Extensive experiments on various image restoration tasks demonstrate the superiority of our method in terms of state-of-the-art performance, interpretability, and generalizability. The source code is available at <a class="link-external link-https" href="https://github.com/MC-E/Deep-Generalized-Unfolding-Networks-for-Image-Restoration" rel="external noopener nofollow">this https URL</a>.      
### 36.Music Enhancement via Image Translation and Vocoding  [ :arrow_down: ](https://arxiv.org/pdf/2204.13289.pdf)
>  Consumer-grade music recordings such as those captured by mobile devices typically contain distortions in the form of background noise, reverb, and microphone-induced EQ. This paper presents a deep learning approach to enhance low-quality music recordings by combining (i) an image-to-image translation model for manipulating audio in its mel-spectrogram representation and (ii) a music vocoding model for mapping synthetically generated mel-spectrograms to perceptually realistic waveforms. We find that this approach to music enhancement outperforms baselines which use classical methods for mel-spectrogram inversion and an end-to-end approach directly mapping noisy waveforms to clean waveforms. Additionally, in evaluating the proposed method with a listening test, we analyze the reliability of common audio enhancement evaluation metrics when used in the music domain.      
### 37.Improving Multimodal Speech Recognition by Data Augmentation and Speech Representations  [ :arrow_down: ](https://arxiv.org/pdf/2204.13206.pdf)
>  Multimodal speech recognition aims to improve the performance of automatic speech recognition (ASR) systems by leveraging additional visual information that is usually associated to the audio input. While previous approaches make crucial use of strong visual representations, e.g. by finetuning pretrained image recognition networks, significantly less attention has been paid to its counterpart: the speech component. In this work, we investigate ways of improving the base speech recognition system by following similar techniques to the ones used for the visual encoder, namely, transferring representations and data augmentation. First, we show that starting from a pretrained ASR significantly improves the state-of-the-art performance; remarkably, even when building upon a strong unimodal system, we still find gains by including the visual modality. Second, we employ speech data augmentation techniques to encourage the multimodal system to attend to the visual stimuli. This technique replaces previously used word masking and comes with the benefits of being conceptually simpler and yielding consistent improvements in the multimodal setting. We provide empirical results on three multimodal datasets, including the newly introduced Localized Narratives.      
### 38.A Soft-Bodied Aerial Robot for Collision Resilience and Contact-Reactive Perching  [ :arrow_down: ](https://arxiv.org/pdf/2204.13155.pdf)
>  Compared to their biological counterparts, aerial robots demonstrate limited capabilities when tasked to interact in unstructured environments. Very often, the limitation lies in their inability to tolerate collisions and to successfully land, or perch, on objects of unknown shape. Over the past years, efforts to address this have introduced designs that incorporate mechanical impact protection and grasping/perching structures at the cost of reduced agility and flight time due to added weight and bulkiness. In this work, we develop a fabric-based, soft-bodied aerial robot (SoBAR) composed of both contact-reactive perching and embodied impact protection structures while remaining lightweight and streamlined. The robot is capable to 1) pneumatically vary its body stiffness for collision resilience and 2) utilize a hybrid fabric-based, bistable (HFB) grasper to perform passive grasping. When compared to conventional rigid drone frames the SoBAR successfully demonstrates its ability to dissipate impact from head-on collisions and maintain flight stability without any structural damage. Furthermore, in dynamic perching scenarios the HFB grasper is capable to convert impact energy upon contact into firm grasp through rapid body shape conforming in less than 4ms. We exhaustively study and offer insights for this novel perching scheme through grasping characterization, grasp wrench analysis, and experimental grasping validations in objects with various shapes. Finally, we demonstrate the complete control pipeline for SoBAR to approach an object, dynamically perch on it, recover from it, and land.      
### 39.Probabilistic Consensus on Feature Distribution for Multi-robot Systems with Markovian Exploration Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2202.03327.pdf)
>  In this paper, we present a consensus-based decentralized multi-robot approach to reconstruct a discrete distribution of features, modeled as an occupancy grid map, that represent information contained in a bounded planar 2D environment, such as visual cues used for navigation or semantic labels associated with object detection. The robots explore the environment according to a random walk modeled by a discrete-time discrete-state (DTDS) Markov chain and estimate the feature distribution from their own measurements and the estimates communicated by neighboring robots, using a distributed Chernoff fusion protocol. We prove that under this decentralized fusion protocol, each robot's feature distribution converges to the ground truth distribution in an almost sure sense. We verify this result in numerical simulations that show that the Hellinger distance between the estimated and ground truth feature distributions converges to zero over time for each robot. We also validate our strategy through Software-In-The-Loop (SITL) simulations of quadrotors that search a bounded square grid for a set of visual features distributed on a discretized circle.      
