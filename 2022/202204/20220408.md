# ArXiv eess --Fri, 8 Apr 2022
### 1.Control Barrier Functions with Actuation Constraints under Signal Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2204.03631.pdf)
>  We propose control barrier functions (CBFs) for a family of dynamical systems to satisfy a broad fragment of Signal Temporal Logic (STL) specifications, which may include subtasks with nested temporal operators or conflicting requirements (e.g., achieving multiple subtasks within the same time interval). The proposed CBFs take into account the actuation limits of the dynamical system as well as a feasible sequence of subtasks, and they define time-varying feasible sets of states the system must always stay inside. We show some theoretical results on the correctness of the proposed method. We illustrate the benefits of the proposed CBFs and compare their performance with the existing methods via simulations.      
### 2.Pneumonia Detection in Chest X-Rays using Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03618.pdf)
>  With the advancement in AI, deep learning techniques are widely used to design robust classification models in several areas such as medical diagnosis tasks in which it achieves good performance. In this paper, we have proposed the CNN model (Convolutional Neural Network) for the classification of Chest X-ray images for Radiological Society of North America Pneumonia (RSNA) datasets. The study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The proposed method is based on a non-complex CNN and the use of transfer learning algorithms like Xception, InceptionV3/V4, EfficientNetB7. Along with this, the study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The RSNA benchmark MAP score is 0.25, but using the Mask RCNN model on a stratified sample of 3017 along with image augmentation gave a MAP score of 0.15. Meanwhile, the YoloV3 without any hyperparameter tuning gave the MAP score of 0.32 but still, the loss keeps decreasing. Running the model for a greater number of iterations can give better results.      
### 3.An optimized hybrid solution for IoT based lifestyle disease classification using stress data  [ :arrow_down: ](https://arxiv.org/pdf/2204.03573.pdf)
>  Stress, anxiety, and nervousness are all high-risk health states in everyday life. Previously, stress levels were determined by speaking with people and gaining insight into what they had experienced recently or in the past. Typically, stress is caused by an incidence that occurred a long time ago, but sometimes it is triggered by unknown factors. This is a challenging and complex task, but recent research advances have provided numerous opportunities to automate it. The fundamental features of most of these techniques are electro dermal activity (EDA) and heart rate values (HRV). We utilized an accelerometer to measure body motions to solve this challenge. The proposed novel method employs a test that measures a subject's electrocardiogram (ECG), galvanic skin values (GSV), HRV values, and body movements in order to provide a low-cost and time-saving solution for detecting stress lifestyle disease in modern times using cyber physical systems. This study provides a new hybrid model for lifestyle disease classification that decreases execution time while picking the best collection of characteristics and increases classification accuracy. The developed approach is capable of dealing with the class imbalance problem by using WESAD (wearable stress and affect dataset) dataset. The new model uses the Grid search (GS) method to select an optimized set of hyper parameters, and it uses a combination of the Correlation coefficient based Recursive feature elimination (CoC-RFE) method for optimal feature selection and gradient boosting as an estimator to classify the dataset, which achieves high accuracy and helps to provide smart, accurate, and high-quality healthcare systems. To demonstrate the validity and utility of the proposed methodology, its performance is compared to those of other well-established machine learning models.      
### 4.A Pathology-Based Machine Learning Method to Assist in Epithelial Dysplasia Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2204.03572.pdf)
>  The Epithelial Dysplasia (ED) is a tissue alteration commonly present in lesions preceding oral cancer, being its presence one of the most important factors in the progression toward carcinoma. This study proposes a method to design a low computational cost classification system to support the detection of dysplastic epithelia, contributing to reduce the variability of pathologist assessments. We employ a multilayer artificial neural network (MLP-ANN) and defining the regions of the epithelium to be assessed based on the knowledge of the pathologist. The performance of the proposed solution was statistically evaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a variability much inferior to that obtained from three trained evaluators. Moreover, the proposed solution led to results which are very close to those obtained using a convolutional neural network (CNN) implemented by transfer learning, with 100 times less computational complexity. In conclusion, our results show that a simple neural network structure can lead to a performance equivalent to that of much more complex structures, which are routinely used in the literature.      
### 5.Adaptive Spike-Like Representation of EEG Signals for Sleep Stages Scoring  [ :arrow_down: ](https://arxiv.org/pdf/2204.03565.pdf)
>  Recently there has seen promising results on automatic stage scoring by extracting spatio-temporal features from electroencephalogram (EEG). Such methods entail laborious manual feature engineering and domain knowledge. In this study, we propose an adaptive scheme to probabilistically encode, filter and accumulate the input signals and weight the resultant features by the half-Gaussian probabilities of signal intensities. The adaptive representations are subsequently fed into a transformer model to automatically mine the relevance between features and corresponding stages. Extensive experiments on the largest public dataset against state-of-the-art methods validate the effectiveness of our proposed method and reveal promising future directions.      
### 6.RF Signal Transformation and Classification using Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03564.pdf)
>  Deep neural networks (DNNs) designed for computer vision and natural language processing tasks cannot be directly applied to the radio frequency (RF) datasets. To address this challenge, we propose to convert the raw RF data to data types that are suitable for off-the-shelf DNNs by introducing a convolutional transform technique. In addition, we propose a simple 5-layer convolutional neural network architecture (CONV-5) that can operate with raw RF I/Q data without any transformation. Further, we put forward an RF dataset, referred to as RF1024, to facilitate future RF research. RF1024 consists of 8 different RF modulation classes with each class having 1000/200 training/test samples. Each sample of the RF1024 dataset contains 1024 complex I/Q values. Lastly, the experiments are performed on the RadioML2016 and RF1024 datasets to demonstrate the improved classification performance.      
### 7.Lane-Free Crossing of CAVs through Signal-Free Intersections as a Minimum-Time Optimal Control Problem  [ :arrow_down: ](https://arxiv.org/pdf/2204.03550.pdf)
>  Unlike traditional cars, connected and autonomous vehicles (CAVs) can cross intersections in a lane-free and signal-free order to increase the temporal-spatial capacity of intersections. This paper presents an optimal strategy to centrally control the CAVs entering an intersection to minimise the worst crossing time of the vehicles, or equivalently maximise the throughput of the intersection. The strategy is the solution of a minimum-time optimal control problem (OCP) that is highly non-convex due to the existence of constraints to avoid collision of vehicles with each other and with road boundaries. An algorithm is proposed to solve the formulated OCP by smoothing and convexifying the obstacle avoidance constraints using their dual equivalent problems in the form of relaxed necessary conditions. Simulation results show an average of 52% improvement in the crossing time of intersections as compared to the state-of-the-art reservation-based methods. Furthermore, it is shown that the minimum crossing time of an intersection is fixed and does not change regardless of the number of CAVs.      
### 8.Evaluating Procedures for Establishing Generative Adversarial Network-based Stochastic Image Models in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2204.03547.pdf)
>  Modern generative models, such as generative adversarial networks (GANs), hold tremendous promise for several areas of medical imaging, such as unconditional medical image synthesis, image restoration, reconstruction and translation, and optimization of imaging systems. However, procedures for establishing stochastic image models (SIMs) using GANs remain generic and do not address specific issues relevant to medical imaging. In this work, canonical SIMs that simulate realistic vessels in angiography images are employed to evaluate procedures for establishing SIMs using GANs. The GAN-based SIM is compared to the canonical SIM based on its ability to reproduce those statistics that are meaningful to the particular medically realistic SIM considered. It is shown that evaluating GANs using classical metrics and medically relevant metrics may lead to different conclusions about the fidelity of the trained GANs. This work highlights the need for the development of objective metrics for evaluating GANs.      
### 9.Unsignalized Intersection Management Strategy for Mixed Autonomy Traffic Streams  [ :arrow_down: ](https://arxiv.org/pdf/2204.03499.pdf)
>  With the rapid development of connected and automated vehicles (CAVs) and intelligent transportation infrastructure, CAVs and connected human-driven vehicles (CHVs) will coexist on the roads in the future for a long time. This paper comprehensively considers the different traffic characteristics of CHVs and CAVs, and systemically investigates the unsignalized intersection management strategy from upper decision-making level to lower execution level. Combined with the designed vehicle planning and control algorithm, the unsignalized intersection management strategy consists of two parts: the heuristic priority queues based right of way allocation (HPQ) algorithm, and the vehicle planning and control algorithm. In the HPQ algorithm, a vehicle priority management model considering the difference between CAVs and CHVs is built to design the right of way management for CAVs and CHVs, respectively. In the lower level for vehicle planning and control algorithm, different control modes of CAVs are designed according to the upper level decision made by the HPQ algorithm. Moreover, the vehicle control execution is realized by the model predictive controller combined with the geographical environment constraints and the unsignalized intersection management strategy. The proposed strategy is evaluated by simulations, which show that the proposed intersection management strategy can effectively reduce travel time and improve traffic efficiency. The intersection management strategy captures the real-world balance between efficiency and safety for potential future intelligent traffic systems.      
### 10.Nonlinear Kalman Filter Using Cramer Rao Bound  [ :arrow_down: ](https://arxiv.org/pdf/2204.03485.pdf)
>  This paper studies the optimal state estimation for a dynamic system, whose transfer function can be nonlinear and the input noise can be of arbitrary distribution. Our algorithm differs from the conventional extended Kalman filter (EKF) and the particle filter (PF) in that it estimates not only the state vector but also the Cramer-Rao bound (CRB), which serves as an accuracy indicator. Combining the state estimation, the CRB, and the incoming new measurement, the algorithm updates the state estimation according to the maximum likelihood (ML) criterion. To illustrate the effectiveness of the proposed method for autonomous driving, we apply it to estimate the position and velocity of a vehicle based on the noisy measurements of distance and Doppler offset. Simulation results show that the proposed algorithm can achieve estimation significantly more accurate than the standard EKF and the PF.      
### 11.A Deep Learning-Based Approach for Cell Outage Compensation in NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03477.pdf)
>  Cell outage compensation enables a network to react to a catastrophic cell failure quickly and serve users in the outage zone uninterruptedly. Utilizing the promising benefits of non-orthogonal multiple access (NOMA) for improving the throughput of cell edge users, we propose a newly NOMA-based cell outage compensation scheme. In this scheme, the compensation is formulated as a mixed integer non-linear program (MINLP) where outage zone users are associated to neighboring cells and their power are allocated with the objective of maximizing spectral efficiency, subject to maintaining the quality of service for the rest of the users. Owing to the importance of immediate management of cell outage and handling the computational complexity, we develop a low-complexity suboptimal solution for this problem in which the user association scheme is determined by a newly heuristic algorithm, and power allocation is set by applying an innovative deep neural network (DNN). The complexity of our proposed method is in the order of polynomial basis, which is much less than the exponential complexity of finding an optimal solution. Simulation results demonstrate that the proposed method approaches the optimal solution. Moreover, the developed scheme greatly improves fairness and increases the number of served users.      
### 12.Detecting Vocal Fatigue with Neural Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2204.03428.pdf)
>  Vocal fatigue refers to the feeling of tiredness and weakness of voice due to extended utilization. This paper investigates the effectiveness of neural embeddings for the detection of vocal fatigue. We compare x-vectors, ECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English. Low-dimensional mappings of the data reveal that neural embeddings capture information about the change in vocal characteristics of a speaker during prolonged voice usage. We show that vocal fatigue can be reliably predicted using all three kinds of neural embeddings after only 50 minutes of continuous speaking when temporal smoothing and normalization are applied to the extracted embeddings. We employ support vector machines for classification and achieve accuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and 82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score of 76%, when the trained system is applied to a different speaker and recording environment without any adaptation.      
### 13.Low complexity joint position and channel estimation at millimeter wave based on multidimensional orthogonal matching pursuit  [ :arrow_down: ](https://arxiv.org/pdf/2204.03424.pdf)
>  Compressive approaches provide a means of effective channel high resolution channel estimates in millimeter wave MIMO systems, despite the use of analog and hybrid architectures. Such estimates can also be used as part of a joint channel estimation and localization solution. Achieving good localization performance, though, requires high resolution channel estimates and better methods to exploit those channels. In this paper, we propose a low complexity multidimensional orthogonal matching pursuit strategy for compressive channel estimation based by operating with a product of independent dictionaries for the angular and delay domains, instead of a global large dictionary. This leads to higher quality channel estimates but with lower complexity than generalizations of conventional solutions. We couple this new algorithm with a novel localization formulation that does not rely on the absolute time of arrival of the LoS path and exploits the structure of reflections in indoor channels. We show how the new approach is able to operate in realistic 3D scenarios to estimate the communication channel and locate devices in an indoor simulation setting.      
### 14.Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0  [ :arrow_down: ](https://arxiv.org/pdf/2204.03417.pdf)
>  Stuttering is a varied speech disorder that harms an individual's communication ability. Persons who stutter (PWS) often use speech therapy to cope with their condition. Improving speech recognition systems for people with such non-typical speech or tracking the effectiveness of speech therapy would require systems that can detect dysfluencies while at the same time being able to detect speech techniques acquired in therapy. <br>This paper shows that fine-tuning wav2vec 2.0 for the classification of stuttering on a sizeable English corpus containing stuttered speech, in conjunction with multi-task learning, boosts the effectiveness of the general-purpose wav2vec 2.0 features for detecting stuttering in speech; both within and across languages. We evaluate our method on Fluencybank and the German therapy-centric Kassel State of Fluency (KSoF) dataset by training Support Vector Machine classifiers using features extracted from the fine-tuned models for six different stuttering-related events types: blocks, prolongations, sound repetitions, word repetitions, interjections, and - specific to therapy - speech modifications. Using embeddings from the fine-tuned models leads to relative classification performance gains up to 27\% w.r.t. F1-score.      
### 15.Surface Vision Transformers: Flexible Attention-Based Modelling of Biomedical Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2204.03408.pdf)
>  Recent state-of-the-art performances of Vision Transformers (ViT) in computer vision tasks demonstrate that a general-purpose architecture, which implements long-range self-attention, could replace the local feature learning operations of convolutional neural networks. In this paper, we extend ViTs to surfaces by reformulating the task of surface learning as a sequence-to-sequence learning problem, by proposing patching mechanisms for general surface meshes. Sequences of patches are then processed by a transformer encoder and used for classification or regression. We validate our method on a range of different biomedical surface domains and tasks: brain age prediction in the developing Human Connectome Project (dHCP), fluid intelligence prediction in the Human Connectome Project (HCP), and coronary artery calcium score classification using surfaces from the Scottish Computed Tomography of the Heart (SCOT-HEART) dataset, and investigate the impact of pretraining and data augmentation on model performance. Results suggest that Surface Vision Transformers (SiT) demonstrate consistent improvement over geometric deep learning methods for brain age and fluid intelligence prediction and achieve comparable performance on calcium score classification to standard metrics used in clinical practice. Furthermore, analysis of transformer attention maps offers clear and individualised predictions of the features driving each task. Code is available on Github: <a class="link-external link-https" href="https://github.com/metrics-lab/surface-vision-transformers" rel="external noopener nofollow">this https URL</a>      
### 16.Electricity generation from renewable energy based on abandoned wind fan  [ :arrow_down: ](https://arxiv.org/pdf/2204.03390.pdf)
>  In the 21st century, our world is facing difficult conditions for serious environmental pollution and the problem of energy shortage. An innovative idea has emerged to recycle wind energy from air conditioning condenser fans in outdoor buildings. Therefore, the main goal of this research is to develop renewable wind energy from the condenser fan of an air conditioner using Arduino as a microcontroller. This research moves towards a portable, low cost, environmentally friendly mini device that harnesses renewable energies with endless resources for future alternative power generation and reduces the burden of consumers' electricity bills      
### 17.Correcting Misproducted Speech using Spectrogram Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2204.03379.pdf)
>  Learning a new language involves constantly comparing speech productions with reference productions from the environment. Early in speech acquisition, children make articulatory adjustments to match their caregivers' speech. Grownup learners of a language tweak their speech to match the tutor reference. This paper proposes a method to synthetically generate correct pronunciation feedback given incorrect production. Furthermore, our aim is to generate the corrected production while maintaining the speaker's original voice. <br>The system prompts the user to pronounce a phrase. The speech is recorded, and the samples associated with the inaccurate phoneme are masked with zeros. This waveform serves as an input to a speech generator, implemented as a deep learning inpainting system with a U-net architecture, and trained to output a reconstructed speech. The training set is composed of unimpaired proper speech examples, and the generator is trained to reconstruct the original proper speech. We evaluated the performance of our system on phoneme replacement of minimal pair words of English as well as on children with pronunciation disorders. Results suggest that human listeners slightly prefer our generated speech over a smoothed replacement of the inaccurate phoneme with a production of a different speaker.      
### 18.A Framework for Distributed Estimation with Reduced Communication via Event-Based Strategies  [ :arrow_down: ](https://arxiv.org/pdf/2204.03364.pdf)
>  This paper considers the problem of distributed estimation in a sensor network, where multiple sensors are deployed to infer the state of a linear time-invariant (LTI) Gaussian system. By proposing a lossless decomposition of Kalman filter, a framework of event-based distributed estimation is developed, where each sensor node runs a local filter using solely its own measurement, alongside with an event-based synchronization algorithm to fuse the neighboring information. One novelty of the proposed framework is that it decouples the local filter from synchronization process. By doing so, we prove that a general class of triggering strategies can be applied in our framework, which yields stable distributed estimators under the minimal requirements of network connectivity and collective system observability. As compared with existing works, the proposed algorithm enjoys lower data size for each transmission. Moreover, the developed results can be generalized to achieve a distributed implementation of any Luenberger observer. By solving a semi-definite programming (SDP), we further present a low-rank estimator design to obtain the optimal gain of Luenberger observer such that the distributed estimation is realized under the constraint of message complexity. Numerical examples are finally provided to demonstrate the proposed methods.      
### 19.Alternating Direction Based Sequential Boolean Quadratic Programming Method for Transmit Antenna Selection  [ :arrow_down: ](https://arxiv.org/pdf/2204.03356.pdf)
>  The wireless mobile communication system is updated and iterated on the whole almost every decade. It is now in the development period of the application scenarios of the fifth generation mobile communication system (5G). Unfortunately, 5G relies on plenty of small base stations with a large number of antennas that consume a lot of energy. In this paper, a novel Boolean variable quadratic programming algorithm is designed for the antenna selection optimization problem to reduce power consumption. Experiments show that the proposed algorithm achieves high complementarity satisfaction accuracy with only a few steps.      
### 20.Binary Spatial Random Field Reconstruction from Non-Gaussian Inhomogeneous Time-series Observations  [ :arrow_down: ](https://arxiv.org/pdf/2204.03343.pdf)
>  We develop a new model for binary spatial random field reconstruction of a physical phenomenon which is partially observed via inhomogeneous time-series data. We consider a sensor network deployed over a vast geographical region where sensors observe temporal processes and transmit compressed observations to the Fusion Center (FC). Two types of sensors are considered; one collects point observations at specific time points while the other collects integral observations over time intervals. Subsequently, the FC uses the compressed observations to infer the spatial phenomenon modeled as a binary spatial random field. We show that the resulting posterior predictive distribution is intractable and develop a tractable two-step procedure to perform inference. First, we develop procedures to approximately perform Likelihood Ratio Tests on the time-series data, for both point sensors and integral sensors, in order to compress the temporal observations to a single bit. Second, after the compressed observations are transmitted to the FC, we develop a Spatial Best Linear Unbiased Estimator (S-BLUE) in order for the FC to reconstruct the binary spatial random field at an arbitrary spatial location. Finally, we present a comprehensive study of the performance of the proposed approaches using both synthetic and real-world experiments. A weather dataset from the National Environment Agency (NEA) of Singapore with fields including temperature and relative humidity is used in the real-world experiments to validate the proposed approaches.      
### 21.Boosting Self-Supervised Embeddings for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2204.03339.pdf)
>  Self-supervised learning (SSL) representation for speech has achieved state-of-the-art (SOTA) performance on several downstream tasks. However, there remains room for improvement in speech enhancement (SE) tasks. In this study, we used a cross-domain feature to solve the problem that SSL embeddings may lack fine-grained information to regenerate speech signals. By integrating the SSL representation and spectrogram, the result can be significantly boosted. We further study the relationship between the noise robustness of SSL representation via clean-noisy distance (CN distance) and the layer importance for SE. Consequently, we found that SSL representations with lower noise robustness are more important. Furthermore, our experiments on the VCTK-DEMAND dataset demonstrated that fine-tuning an SSL representation with an SE model can outperform the SOTA SSL-based SE methods in PESQ, CSIG and COVL without invoking complicated network architectures. In later experiments, the CN distance in SSL embeddings was observed to increase after fine-tuning. These results verify our expectations and may help design SE-related SSL training in the future.      
### 22.Online Adaptive Identification of Switched Affine Systems Using a Two-Tier Filter Architecture with Memory  [ :arrow_down: ](https://arxiv.org/pdf/2204.03338.pdf)
>  This work proposes an online adaptive identification method for multi-input multi-output (MIMO) switched affine systems with guaranteed parameter convergence. A family of online parameter estimators is used that is equipped with a dual-layer low pass filter architecture to facilitate parameter learning and identification of each subsystem. The filters capture information about the unknown parameters in the form of a prediction error which is used in the parameter estimation algorithm. A salient feature of the proposed method that distinguishes it from most previous results is the use of a memory bank that stores filter values and promotes parameter learning during both active and inactive phases of a subsystem. Specifically, the learnt experience from the previous active phase of a subsystem is retained in the memory and leveraged for parameter learning in its subsequent active and inactive phases. Further, a new notion of intermittent initial excitation (IIE) is introduced that extends the previously established initial excitation (IE) condition to the switched system framework. IIE is shown to be sufficient to ensure exponential convergence of the switched system parameters.      
### 23.MTI-Net: A Multi-Target Speech Intelligibility Prediction Model  [ :arrow_down: ](https://arxiv.org/pdf/2204.03310.pdf)
>  Recently, deep learning (DL)-based non-intrusive speech assessment models have attracted great attention. Many studies report that these DL-based models yield satisfactory assessment performance and good flexibility, but their performance in unseen environments remains a challenge. Furthermore, compared to quality scores, fewer studies elaborate deep learning models to estimate intelligibility scores. This study proposes a multi-task speech intelligibility prediction model, called MTI-Net, for simultaneously predicting human and machine intelligibility measures. Specifically, given a speech utterance, MTI-Net is designed to predict subjective listening test results and word error rate (WER) scores. We also investigate several methods that can improve the prediction performance of MTI-Net. First, we compare different features (including low-level features and embeddings from self-supervised learning (SSL) models) and prediction targets of MTI-Net. Second, we explore the effect of transfer learning and multi-tasking learning on training MTI-Net. Finally, we examine the potential advantages of fine-tuning SSL embeddings. Experimental results demonstrate the effectiveness of using cross-domain features, multi-task learning, and fine-tuning SSL embeddings. Furthermore, it is confirmed that the intelligibility and WER scores predicted by MTI-Net are highly correlated with the ground-truth scores.      
### 24.Music-robust Automatic Lyrics Transcription of Polyphonic Music  [ :arrow_down: ](https://arxiv.org/pdf/2204.03306.pdf)
>  Lyrics transcription of polyphonic music is challenging because singing vocals are corrupted by the background music. To improve the robustness of lyrics transcription to the background music, we propose a strategy of combining the features that emphasize the singing vocals, i.e. music-removed features that represent singing vocal extracted features, and the features that capture the singing vocals as well as the background music, i.e. music-present features. We show that these two sets of features complement each other, and their combination performs better than when they are used alone, thus improving the robustness of the acoustic model to the background music. Furthermore, language model interpolation between a general-purpose language model and an in-domain lyrics-specific language model provides further improvement in transcription results. Our experiments show that our proposed strategy outperforms the existing lyrics transcription systems for polyphonic music. Moreover, we find that our proposed music-robust features specially improve the lyrics transcription performance in metal genre of songs, where the background music is loud and dominant.      
### 25.MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids  [ :arrow_down: ](https://arxiv.org/pdf/2204.03305.pdf)
>  Improving the user's hearing ability to understand speech in noisy environments is critical to the development of hearing aid (HA) devices. For this, it is important to derive a metric that can fairly predict speech intelligibility for HA users. A straightforward approach is to conduct a subjective listening test and use the test results as an evaluation metric. However, conducting large-scale listening tests is time-consuming and expensive. Therefore, several evaluation metrics were derived as surrogates for subjective listening test results. In this study, we propose a multi-branched speech intelligibility prediction model (MBI-Net), for predicting the subjective intelligibility scores of HA users. MBI-Net consists of two branches of models, with each branch consisting of a hearing loss model, a cross-domain feature extraction module, and a speech intelligibility prediction model, to process speech signals from one channel. The outputs of the two branches are fused through a linear layer to obtain predicted speech intelligibility scores. Experimental results confirm the effectiveness of MBI-Net, which produces higher prediction scores than the baseline system in Track 1 and Track 2 on the Clarity Prediction Challenge 2022 dataset.      
### 26.Heterogeneous Ultra-Dense Networks with Traffic Hotspots: A Unified Handover Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2204.03294.pdf)
>  With the ever-growing communication demands and the unceasing miniaturization of mobile devices, the Internet of Things is expanding the amount of mobile terminals to an enormous level. To deal with such numbers of communication data, plenty of base stations (BSs) need to be deployed. However, denser deployments of heterogeneous networks (HetNets) lead to more frequent handovers, which could increase network burden and degrade the users experience, especially in traffic hotspot areas. In this paper, we develop a unified framework to investigate the handover performance of wireless networks with traffic hotspots. Using the stochastic geometry, we derive the theoretical expressions of average distances and handover metrics in HetNets, where the correlations between users and BSs in hotspots are captured. Specifically, the distributions of macro cells are modeled as independent Poisson point processes (PPPs), and the two tiers of small cells outside and inside the hotspots are modeled as PPP and Poisson cluster process (PCP) separately. A modified random waypoint (MRWP) model is also proposed to eliminate the density wave phenomenon in traditional models and to increase the accuracy of handover decision. By combining the PCP and MRWP model, the distributions of distances from a typical terminal to the BSs in different tiers are derived. Afterwards, we derive the expressions of average distances from a typical terminal to different BSs, and reveal that the handover rate, handover failure rate, and ping-pong rate are deduced as the functions of BS density, scattering variance of clustered small cell, user velocity, and threshold of triggered time. Simulation results verify the accuracy of the proposed analytical model and closed-form theoretical expressions.      
### 27.Recursive Frequency Selective Reconstruction of Non-Regularly Sampled Video Data  [ :arrow_down: ](https://arxiv.org/pdf/2204.03277.pdf)
>  High resolution images can be acquired using a non-regular sampling sensor which consists of an underlying low resolution sensor that is covered with a non-regular sampling mask. The reconstructed high resolution image is then obtained during post-processing. Recently, it has been shown that the temporal correlation between neighboring frames can be exploited in order to enhance the reconstruction quality of non-regularly sampled video data. In this paper, a new recursive multi-frame reconstruction approach is proposed in order to further increase the reconstruction quality. By using a new reference order, previously reconstructed frames can be used for the subsequent motion estimation and a new weighting function allows for the incorporation of multiple pixels projected onto the same position. With the new recursive multi-frame approach, a visually noticeable average gain in PSNR of up to 1.13 dB with respect to a state-of-the-art single-frame reconstruction approach can be achieved. Compared to the existing multi-frame approach, a gain of 0.31 dB is possible. SSIM results show the same behavior as PSNR results. Additionally, the pre-reconstruction step of the existing multi-frame approach can be avoided and the new algorithm is, in general, capable of real-time processing.      
### 28.Dynamic Non-Regular Sampling Sensor Using Frequency Selective Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2204.03268.pdf)
>  Both a high spatial and a high temporal resolution of images and videos are desirable in many applications such as entertainment systems, monitoring manufacturing processes, or video surveillance. Due to the limited throughput of pixels per second, however, there is always a trade-off between acquiring sequences with a high spatial resolution at a low temporal resolution or vice versa. In this paper, a modified sensor concept is proposed which is able to acquire both a high spatial and a high temporal resolution. This is achieved by dynamically reading out only a subset of pixels in a non-regular order to obtain a high temporal resolution. A full high spatial resolution is then obtained by performing a subsequent three-dimensional reconstruction of the partially acquired frames. The main benefit of the proposed dynamic readout is that for each frame, different sampling points are available which is advantageous since this information can significantly enhance the reconstruction quality of the proposed reconstruction algorithm. Using the proposed dynamic readout strategy, gains in PSNR of up to 8.55 dB are achieved compared to a static readout strategy. Compared to other state-of-the-art techniques like frame rate up-conversion or super-resolution which are also able to reconstruct sequences with both a high spatial and a high temporal resolution, average gains in PSNR of up to 6.58 dB are possible.      
### 29.Texture-Dependent Frequency Selective Reconstruction of Non-Regularly Sampled Images  [ :arrow_down: ](https://arxiv.org/pdf/2204.03261.pdf)
>  There exist many scenarios where pixel information is available only on a non-regular subset of pixel positions. For further processing, however, it is required to reconstruct such images on a regular grid. Besides many other algorithms, frequency selective reconstruction can be applied for this task. It performs a block-wise generation of a sparse signal model as an iterative superposition of Fourier basis functions and uses this model to replace missing or corrupted pixels in an image. In this paper, it is shown that it is not required to spend the same amount of iterations on both homogeneous and heterogeneous regions. Hence, a new texture-dependent approach for frequency selective reconstruction is introduced that distributes the number of iterations depending on the texture of the regions to be reconstructed. Compared to the original frequency selective reconstruction and depending on the number of iterations, visually noticeable gains in PSNR of up to 1.47 dB can be achieved.      
### 30.Unsupervised Quantized Prosody Representation for Controllable Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.03238.pdf)
>  In this paper, we propose a novel prosody disentangle method for prosodic Text-to-Speech (TTS) model, which introduces the vector quantization (VQ) method to the auxiliary prosody encoder to obtain the decomposed prosody representations in an unsupervised manner. Rely on its advantages, the speaking styles, such as pitch, speaking velocity, local pitch variance, etc., are decomposed automatically into the latent quantize vectors. We also investigate the internal mechanism of VQ disentangle process by means of a latent variables counter and find that higher value dimensions usually represent prosody information. Experiments show that our model can control the speaking styles of synthesis results by directly manipulating the latent variables. The objective and subjective evaluations illustrated that our model outperforms the popular models.      
### 31.Leveraging Real Conversational Data for Multi-Channel Continuous Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2204.03232.pdf)
>  Existing multi-channel continuous speech separation (CSS) models are heavily dependent on supervised data - either simulated data which causes data mismatch between the training and real-data testing, or the real transcribed overlapping data, which is difficult to be acquired, hindering further improvements in the conversational/meeting transcription tasks. In this paper, we propose a three-stage training scheme for the CSS model that can leverage both supervised data and extra large-scale unsupervised real-world conversational data. The scheme consists of two conventional training approaches -- pre-training using simulated data and ASR-loss-based training using transcribed data -- and a novel continuous semi-supervised training between the two, in which the CSS model is further trained by using real data based on the teacher-student learning framework. We apply this scheme to an array-geometry-agnostic CSS model, which can use the multi-channel data collected from any microphone array. Large-scale meeting transcription experiments are carried out on both Microsoft internal meeting data and the AMI meeting corpus. The steady improvement by each training stage has been observed, showing the effect of the proposed method that enables leveraging real conversational data for CSS model training.      
### 32.DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores  [ :arrow_down: ](https://arxiv.org/pdf/2204.03219.pdf)
>  Mean opinion score (MOS) is a typical subjective evaluation metric for speech synthesis systems. Since collecting MOS is time-consuming, it would be desirable if there are accurate MOS prediction models for automatic evaluation. In this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes domain adaptive pre-training to further pre-train self-supervised learning models on synthetic speech. And a proposed module is added to model the opinion score distribution of each utterance. With the proposed components, DDOS outperforms previous works on BVCC dataset. And the zero shot transfer result on BC2019 dataset is significantly improved. DDOS also wins second place in Interspeech 2022 VoiceMOS challenge in terms of system-level score.      
### 33.Resiliency of Nonlinear Control Systems to Stealthy Sensor Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03217.pdf)
>  In this work, we focus on analyzing vulnerability of nonlinear dynamical control systems to stealthy sensor attacks. We start by defining the notion of stealthy attacks in the most general form by leveraging Neyman-Pearson lemma; specifically, an attack is considered to be stealthy if it is stealthy from (i.e., undetected by) any intrusion detector -- i.e., the probability of the detection is not better than a random guess. We then provide a sufficient condition under which a nonlinear control system is vulnerable to stealthy attacks, in terms of moving the system to an unsafe region due to the attacks. In particular, we show that if the closed-loop system is incrementally exponentially stable while the open-loop plant is incrementally unstable, then the system is vulnerable to stealthy yet impactful attacks on sensors. Finally, we illustrate our results on a case study.      
### 34.MC-UNet Multi-module Concatenation based on U-shape Network for Retinal Blood Vessels Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.03213.pdf)
>  Accurate segmentation of the blood vessels of the retina is an important step in clinical diagnosis of ophthalmic diseases. Many deep learning frameworks have come up for retinal blood vessels segmentation tasks. However, the complex vascular structure and uncertain pathological features make the blood vessel segmentation still very challenging. A novel U-shaped network named Multi-module Concatenation which is based on Atrous convolution and multi-kernel pooling is put forward to retinal vessels segmentation in this paper. The proposed network structure retains three layers the essential structure of U-Net, in which the atrous convolution combining the multi-kernel pooling blocks are designed to obtain more contextual information. The spatial attention module is concatenated with dense atrous convolution module and multi-kernel pooling module to form a multi-module concatenation. And different dilation rates are selected by cascading to acquire a larger receptive field in atrous convolution. Adequate comparative experiments are conducted on these public retinal datasets: DRIVE, STARE and CHASE_DB1. The results show that the proposed method is effective, especially for microvessels. The code will be put out at <a class="link-external link-https" href="https://github.com/Rebeccala/MC-UNet" rel="external noopener nofollow">this https URL</a>      
### 35.Convolutional Neural Network for Early Pulmonary Embolism Detection via Computed Tomography Pulmonary Angiography  [ :arrow_down: ](https://arxiv.org/pdf/2204.03204.pdf)
>  This study was conducted to develop a computer-aided detection (CAD) system for triaging patients with pulmonary embolism (PE). The purpose of the system was to reduce the death rate during the waiting period. Computed tomography pulmonary angiography (CTPA) is used for PE diagnosis. Because CTPA reports require a radiologist to review the case and suggest further management, this creates a waiting period during which patients may die. Our proposed CAD method was thus designed to triage patients with PE from those without PE. In contrast to related studies involving CAD systems that identify key PE lesion images to expedite PE diagnosis, our system comprises a novel classification-model ensemble for PE detection and a segmentation model for PE lesion labeling. The models were trained using data from National Cheng Kung University Hospital and open resources. The classification model yielded 0.73 for receiver operating characteristic curve (accuracy = 0.85), while the mean intersection over union was 0.689 for the segmentation model. The proposed CAD system can distinguish between patients with and without PE and automatically label PE lesions to expedite PE diagnosis      
### 36.Musical Information Extraction from the Singing Voice  [ :arrow_down: ](https://arxiv.org/pdf/2204.03166.pdf)
>  Music information retrieval is currently an active research area that addresses the extraction of musically important information from audio signals, and the applications of such information. The extracted information can be used for search and retrieval of music in recommendation systems, or to aid musicological studies or even in music learning. Sophisticated signal processing techniques are applied to convert low-level acoustic signal properties to musical attributes which are further embedded in a rule-based or statistical classification framework to link with high-level descriptions such as melody, genre, mood and artist type. Vocal music comprises a large and interesting category of music where the lead instrument is the singing voice. The singing voice is more versatile than many musical instruments and therefore poses interesting challenges to information retrieval systems. In this paper, we provide a brief overview of research in vocal music processing followed by a description of related work at IIT Bombay leading to the development of an interface for melody detection of singing voice in polyphony.      
### 37.Low-Dose CT Denoising via Sinogram Inner-Structure Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2204.03163.pdf)
>  Low-Dose Computed Tomography (LDCT) technique, which reduces the radiation harm to human bodies, is now attracting increasing interest in the medical imaging field. As the image quality is degraded by low dose radiation, LDCT exams require specialized reconstruction methods or denoising algorithms. However, most of the recent effective methods overlook the inner-structure of the original projection data (sinogram) which limits their denoising ability. The inner-structure of the sinogram represents special characteristics of the data in the sinogram domain. By maintaining this structure while denoising, the noise can be obviously restrained. Therefore, we propose an LDCT denoising network namely Sinogram Inner-Structure Transformer (SIST) to reduce the noise by utilizing the inner-structure in the sinogram domain. Specifically, we study the CT imaging mechanism and statistical characteristics of sinogram to design the sinogram inner-structure loss including the global and local inner-structure for restoring high-quality CT images. Besides, we propose a sinogram transformer module to better extract sinogram features. The transformer architecture using a self-attention mechanism can exploit interrelations between projections of different view angles, which achieves an outstanding performance in sinogram denoising. Furthermore, in order to improve the performance in the image domain, we propose the image reconstruction module to complementarily denoise both in the sinogram and image domain.      
### 38.Deep transfer learning for system identification using long short-term memory neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03125.pdf)
>  Recurrent neural networks (RNNs) have many advantages over more traditional system identification techniques. They may be applied to linear and nonlinear systems, and they require fewer modeling assumptions. However, these neural network models may also need larger amounts of data to learn and generalize. Furthermore, neural networks training is a time-consuming process. Hence, building upon long-short term memory neural networks (LSTM), this paper proposes using two types of deep transfer learning, namely parameter fine-tuning and freezing, to reduce the data and computation requirements for system identification. We apply these techniques to identify two dynamical systems, namely a second-order linear system and a Wiener-Hammerstein nonlinear system. Results show that compared with direct learning, our method accelerates learning by 10% to 50%, which also saves data and computing resources.      
### 39.Stability and Safety through Event-Triggered Intermittent Control with Application to Spacecraft Orbit Stabilization  [ :arrow_down: ](https://arxiv.org/pdf/2204.03110.pdf)
>  In systems where the ability to actuate is a scarce resource, e.g., spacecrafts, it is desirable to only apply a given controller in an intermittent manner--with periods where the controller is on and periods where it is off. Motivated by the event-triggered control paradigm, where state-dependent triggers are utilized in a sample-and-hold context, we generalize this concept to include state triggers where the controller is off thereby creating a framework for intermittent control. Our approach utilizes certificates--either Lyapunov or barrier functions--to design intermittent trigger laws that guarantee stability or safety; the controller is turned on for the period for which is beneficial with regard to the certificate, and turned off until a performance threshold is reached. The main result of this paper is that the intermittent controller scheme guarantees (set) stability when Lyapunov functions are utilized, and safety (forward set invariance) in the setting of barrier functions. As a result, our trigger designs can leverage the intermittent nature of the actuator, and at the same time, achieve the task of stabilization or safety. We further demonstrate the application and benefits of intermittent control in the context of the spacecraft orbit stabilization problem.      
### 40.Control barrier function based attack-recovery with provable guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2204.03077.pdf)
>  This paper studies provable security guarantees for cyber-physical systems (CPS) under actuator attacks. In particular, we consider CPS safety and propose a new attack-detection mechanism based on a zeroing control barrier function (ZCBF) condition. In addition we design an adaptive recovery mechanism based on how close the system is from violating safety. We show that the attack-detection mechanism is sound, i.e., there are no false negatives for adversarial attacks. Finally, we use a Quadratic Programming (QP) approach for online recovery (and nominal) control synthesis. We demonstrate the effectiveness of the proposed method in a simulation case study involving a quadrotor with an attack on its motors.      
### 41.EfficientCellSeg: Efficient Volumetric Cell Segmentation Using Context Aware Pseudocoloring  [ :arrow_down: ](https://arxiv.org/pdf/2204.03014.pdf)
>  Volumetric cell segmentation in fluorescence microscopy images is important to study a wide variety of cellular processes. Applications range from the analysis of cancer cells to behavioral studies of cells in the embryonic stage. Like in other computer vision fields, most recent methods use either large convolutional neural networks (CNNs) or vision transformer models (ViTs). Since the number of available 3D microscopy images is typically limited in applications, we take a different approach and introduce a small CNN for volumetric cell segmentation. Compared to previous CNN models for cell segmentation, our model is efficient and has an asymmetric encoder-decoder structure with very few parameters in the decoder. Training efficiency is further improved via transfer learning. In addition, we introduce Context Aware Pseudocoloring to exploit spatial context in z-direction of 3D images while performing volumetric cell segmentation slice-wise. We evaluated our method using different 3D datasets from the Cell Segmentation Benchmark of the Cell Tracking Challenge. Our segmentation method achieves top-ranking results, while our CNN model has an up to 25x lower number of parameters than other top-ranking methods. Code and pretrained models are available at: <a class="link-external link-https" href="https://github.com/roydenwa/efficient-cell-seg" rel="external noopener nofollow">this https URL</a>      
### 42.End-To-End Optimization of Online Neural Network-supported Two-Stage Dereverberation for Hearing Devices  [ :arrow_down: ](https://arxiv.org/pdf/2204.02978.pdf)
>  A two-stage online dereverberation algorithm for hearing devices is presented in this paper. The approach combines a multi-channel multi-frame linear filtering approach with a single-channel single-frame post-filter. Both components rely on power spectral density (PSD) estimates provided by deep neural networks (DNNs). This contribution extends our prior work, which shows that directly optimizing for a criterion at the output of the multi-channel linear filtering stage results in a more efficient dereverberation, as compared to placing the criterion at the output of the DNN to optimize the PSD estimation. In the present work, we show that the dereverberation performance of the proposed first stage particularly improves the early-to-mid reverberation ratio if trained end-to-end. We thus argue that it can be combined with a post-filtering stage which benefits from the early-to-mid ratio improvement and is consequently able to efficiently suppress the residual late reverberation. This proposed two stage procedure is shown to be both very effective in terms of dereverberation performance and computational demands. Furthermore, the proposed system can be adapted to the needs of different types of hearing-device users by controlling the amount of reduction of early reflections. The proposed system outperforms the previously proposed end-to-end DNN-supported linear filtering algorithm, as well as other traditional approaches, based on an evaluation using the noise-free version of the WHAMR! dataset.      
### 43.Multi-Scale Memory-Based Video Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2204.02977.pdf)
>  Video deblurring has achieved remarkable progress thanks to the success of deep neural networks. Most methods solve for the deblurring end-to-end with limited information propagation from the video sequence. However, different frame regions exhibit different characteristics and should be provided with corresponding relevant information. To achieve fine-grained deblurring, we designed a memory branch to memorize the blurry-sharp feature pairs in the memory bank, thus providing useful information for the blurry query input. To enrich the memory of our memory bank, we further designed a bidirectional recurrency and multi-scale strategy based on the memory bank. Experimental results demonstrate that our model outperforms other state-of-the-art methods while keeping the model complexity and inference time low. The code is available at <a class="link-external link-https" href="https://github.com/jibo27/MemDeblur" rel="external noopener nofollow">this https URL</a>.      
### 44.Follow My Eye: Using Gaze to Supervise Computer-Aided Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2204.02976.pdf)
>  When deep neural network (DNN) was first introduced to the medical image analysis community, researchers were impressed by its performance. However, it is evident now that a large number of manually labeled data is often a must to train a properly functioning DNN. This demand for supervision data and labels is a major bottleneck in current medical image analysis, since collecting a large number of annotations from experienced experts can be time-consuming and expensive. In this paper, we demonstrate that the eye movement of radiologists reading medical images can be a new form of supervision to train the DNN-based computer-aided diagnosis (CAD) system. Particularly, we record the tracks of the radiologists' gaze when they are reading images. The gaze information is processed and then used to supervise the DNN's attention via an Attention Consistency module. To the best of our knowledge, the above pipeline is among the earliest efforts to leverage expert eye movement for deep-learning-based CAD. We have conducted extensive experiments on knee X-ray images for osteoarthritis assessment. The results show that our method can achieve considerable improvement in diagnosis performance, with the help of gaze supervision.      
### 45.Holistic Fault Detection and Diagnosis System in Imbalanced, Scarce, Multi-Domain (ISMD) Data Setting for Component-Level Prognostics and Health Management (PHM)  [ :arrow_down: ](https://arxiv.org/pdf/2204.02969.pdf)
>  In the current Industrial 4.0 revolution, Prognostics and Health Management (PHM) is an emerging field of research. The difficulty of obtaining data from electromechanical systems in an industrial setting increases proportionally with the scale and accessibility of the automated industry, resulting in a less interpolated PHM system. To put it another way, the development of an accurate PHM system for each industrial system necessitates a unique dataset acquired under specified conditions. In most circumstances, obtaining this one-of-a-kind dataset is difficult, and the resulting dataset has a significant imbalance, a lack of certain useful information, and multi-domain knowledge. To address this, this paper provides a fault detection and diagnosis system that evaluates and pre-processes Imbalanced, Scarce, Multi-Domain (ISMD) data acquired from an industrial robot utilizing Signal Processing (SP) techniques and Deep Learning-based (DL) domain knowledge transfer. The domain knowledge transfer is used to produce a synthetic dataset with a high interpolation rate that contains all the useful information about each domain. For domain knowledge transfer and data generation, Continuous Wavelet Transform (CWT) with Generative Adversarial Network (GAN) was used, as well as Convolutional Neural Network (CNN) to test the suggested methodology using transfer learning and categorize several faults. The proposed methodology was tested on a real experimental bench that included an industrial robot created by Hyundai Robotics Co. This development resulted in a satisfactory resolution with 99.7% (highest) classification accuracy achieved by transfer learning on several CNN benchmark models.      
### 46.An Online Learning Approach to Shortest Path and Backpressure Routing in Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.03620.pdf)
>  We consider the adaptive routing problem in multihop wireless networks. The link states are assumed to be random variables drawn from unknown distributions, independent and identically distributed across links and time. This model has attracted a growing interest recently in cognitive radio networks and adaptive communication systems. In such networks, devices are cognitive in the sense of learning the link states and updating the transmission parameters to allow efficient resource utilization. This model contrasts sharply with the vast literature on routing algorithms that assumed complete knowledge about the link state means. The goal is to design an algorithm that learns online optimal paths for data transmissions to maximize the network throughput while attaining low path cost over flows in the network. We develop a novel Online Learning for Shortest path and Backpressure (OLSB) algorithm to achieve this goal. We analyze the performance of OLSB rigorously and show that it achieves a logarithmic regret with time, defined as the loss of an algorithm as compared to a genie that has complete knowledge about the link state means. We further evaluate the performance of OLSB numerically via extensive simulations, which support the theoretical findings and demonstrate its high efficiency.      
### 47.Heterogeneous Target Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2204.03594.pdf)
>  We introduce a new paradigm for single-channel target source separation where the sources of interest can be distinguished using non-mutually exclusive concepts (e.g., loudness, gender, language, spatial location, etc). Our proposed heterogeneous separation framework can seamlessly leverage datasets with large distribution shifts and learn cross-domain representations under a variety of concepts used as conditioning. Our experiments show that training separation models with heterogeneous conditions facilitates the generalization to new concepts with unseen out-of-domain data while also performing substantially higher than single-domain specialist models. Notably, such training leads to more robust learning of new harder source separation discriminative concepts and can yield improvements over permutation invariant training with oracle source selection. We analyze the intrinsic behavior of source separation training with heterogeneous metadata and propose ways to alleviate emerging problems with challenging separation conditions. We release the collection of preparation recipes for all datasets used to further promote research towards this challenging task.      
### 48.Risk-based regulation for all: The need and a method for a wide adoption solution for data-driven inspection targeting  [ :arrow_down: ](https://arxiv.org/pdf/2204.03583.pdf)
>  Access to data and data processing, including the use of machine learning techniques, has become significantly easier and cheaper in recent years. Nevertheless, solutions that can be widely adopted by regulators for market monitoring and inspection targeting in a data-driven way have not been frequently discussed by the scientific community. This article discusses the need and the difficulties for the development of such solutions, presents an effective method to address regulation planning, and illustrates its use to account for the most important and common subject for the majority of regulators: the consumer. This article hopes to contribute to increase the awareness of the regulatory community to the need for data processing methods that are objective, impartial, transparent, explainable, simple to implement and with low computational cost, aiming to the implementation of risk-based regulation in the world.      
### 49.Emotional Speech Recognition with Pre-trained Deep Visual Models  [ :arrow_down: ](https://arxiv.org/pdf/2204.03561.pdf)
>  In this paper, we propose a new methodology for emotional speech recognition using visual deep neural network models. We employ the transfer learning capabilities of the pre-trained computer vision deep models to have a mandate for the emotion recognition in speech task. In order to achieve that, we propose to use a composite set of acoustic features and a procedure to convert them into images. Besides, we present a training paradigm for these models taking into consideration the different characteristics between acoustic-based images and regular ones. In our experiments, we use the pre-trained VGG-16 model and test the overall methodology on the Berlin EMO-DB dataset for speaker-independent emotion recognition. We evaluate the proposed model on the full list of the seven emotions and the results set a new state-of-the-art.      
### 50.Practical Issues and Challenges in CSI-based Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2204.03535.pdf)
>  Next-generation mobile communication network (i.e., 6G) has been envisioned to go beyond classical communication functionality and provide integrated sensing and communication (ISAC) capability to enable more emerging applications, such as smart cities, connected vehicles, AIoT and health care/elder care. Among all the ISAC proposals, the most practical and promising approach is to empower existing wireless network (e.g., WiFi, 4G/5G) with the augmented ability to sense the surrounding human and environment, and evolve wireless communication networks into intelligent communication and sensing network (e.g., 6G). In this paper, based on our experience on CSI-based wireless sensing with WiFi/4G/5G signals, we intend to identify ten major practical and theoretical problems that hinder real deployment of ISAC applications, and provide possible solutions to those critical challenges. Hopefully, this work will inspire further research to evolve existing WiFi/4G/5G networks into next-generation intelligent wireless network (i.e., 6G).      
### 51.Reliable Transiently-Powered Communication  [ :arrow_down: ](https://arxiv.org/pdf/2204.03507.pdf)
>  Frequent power failures can introduce significant packet losses during communication among energy harvesting batteryless wireless sensors. Nodes should be aware of the energy level of their neighbors to guarantee the success of communication and avoid wasting energy. This paper presents TRAP (TRAnsiently-powered Protocol) that allows nodes to communicate only if the energy availability on both sides of the communication channel is sufficient before packet transmission. TRAP relies on a novel modulator circuit, which operates without microcontroller intervention and transmits the energy status almost for free over the radiofrequency backscatter channel. Our experimental results showed that TRAP avoids failed transmissions introduced by the power failures and ensures reliable intermittent communication among batteryless sensors.      
### 52.A Hard and Soft Hybrid Slicing Framework for Service Level Agreement Guarantee via Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03502.pdf)
>  Network slicing is a critical driver for guaranteeing the diverse service level agreements (SLA) in 5G and future networks. Recently, deep reinforcement learning (DRL) has been widely utilized for resource allocation in network slicing. However, existing related works do not consider the performance loss associated with the initial exploration phase of DRL. This paper proposes a new performance-guaranteed slicing strategy with a soft and hard hybrid slicing setting. Mainly, a common slice setting is applied to guarantee slices' SLA when training the neural network. Moreover, the resource of the common slice tends to precisely redistribute to slices with the training of DRL until it converges. Furthermore, experiment results confirm the effectiveness of our proposed slicing framework: the slices' SLA of the training phase can be guaranteed, and the proposed algorithm can achieve the near-optimal performance in terms of the SLA satisfaction ratio, isolation degree and spectrum maximization after convergence.      
### 53.DynLight: Realize dynamic phase duration with multi-level traffic signal control  [ :arrow_down: ](https://arxiv.org/pdf/2204.03471.pdf)
>  Adopting reinforcement learning (RL) for traffic signal control is increasingly popular. Most RL methods use fixed action interval (denoted as tduration) and actuate or maintain a phase every tduration, which makes the phase duration less dynamic and flexible. In addition, the actuated phase can be arbitrary, affecting the real-world deployment, which requires a fixed cyclical phase structure. To address these challenges, we propose a multi-level traffic signal control framework, DynLight, which uses an optimization method Max-QueueLength (M-QL) to determine the phase and uses a deep Q-network to determine the corresponding duration. Based on DynLight, we further propose DynLight-C that adopts a well trained deep Q-network of DynLight and replace M-QL by a fixed cyclical control policy that actuate a set of phases in fixed order to realize cyclical phase structure. Comprehensive experiments on multiple real-world datasets demonstrate that DynLight achives a new state-of-the-art. Furthermore, the deep Q-network of DynLight can learn well on determining the phase duration and DynLight-C demonstrates high performance for deployment.      
### 54.Self supervised learning for robust voice cloning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03421.pdf)
>  Voice cloning is a difficult task which requires robust and informative features incorporated in a high quality TTS system in order to effectively copy an unseen speaker's voice. In our work, we utilize features learned in a self-supervised framework via the Bootstrap Your Own Latent (BYOL) method, which is shown to produce high quality speech representations when specific audio augmentations are applied to the vanilla algorithm. We further extend the augmentations in the training procedure to aid the resulting features to capture the speaker identity and to make them robust to noise and acoustic conditions. The learned features are used as pre-trained utterance-level embeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming to achieve multispeaker speech synthesis without utilizing additional speaker features. This method enables us to train our model in an unlabeled multispeaker dataset as well as use unseen speaker embeddings to copy a speaker's voice. Subjective and objective evaluations are used to validate the proposed model, as well as the robustness to the acoustic conditions of the target utterance.      
### 55.MAESTRO: Matched Speech Text Representations through Modality Matching  [ :arrow_down: ](https://arxiv.org/pdf/2204.03409.pdf)
>  We present Maestro, a self-supervised training method to unify representations learnt from speech and text modalities. Self-supervised learning from speech signals aims to learn the latent structure inherent in the signal, while self-supervised learning from text attempts to capture lexical information. Learning aligned representations from unpaired speech and text sequences is a challenging task. Previous work either implicitly enforced the representations learnt from these two modalities to be aligned in the latent space through multitasking and parameter sharing or explicitly through conversion of modalities via speech synthesis. While the former suffers from interference between the two modalities, the latter introduces additional complexity. In this paper, we propose Maestro, a novel algorithm to learn unified representations from both these modalities simultaneously that can transfer to diverse downstream tasks such as Automated Speech Recognition (ASR) and Speech Translation (ST). Maestro learns unified representations through sequence alignment, duration prediction and matching embeddings in the learned space through an aligned masked-language model loss. We establish a new state-of-the-art (SOTA) on VoxPopuli multilingual ASR with a 11% relative reduction in Word Error Rate (WER), multidomain SpeechStew ASR (3.7% relative) and 21 languages to English multilingual ST on CoVoST 2 with an improvement of 2.8 BLEU averaged over 21 languages.      
### 56.Linguistic-Acoustic Similarity Based Accent Shift for Accent Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03398.pdf)
>  General accent recognition (AR) models tend to directly extract low-level information from spectrums, which always significantly overfit on speakers or channels. Considering accent can be regarded as a series of shifts relative to native pronunciation, distinguishing accents will be an easier task with accent shift as input. But due to the lack of native utterance as an anchor, estimating the accent shift is difficult. In this paper, we propose linguistic-acoustic similarity based accent shift (LASAS) for AR tasks. For an accent speech utterance, after mapping the corresponding text vector to multiple accent-associated spaces as anchors, its accent shift could be estimated by the similarities between the acoustic embedding and those anchors. Then, we concatenate the accent shift with a dimension-reduced text vector to obtain a linguistic-acoustic bimodal representation. Compared with pure acoustic embedding, the bimodal representation is richer and more clear by taking full advantage of both linguistic and acoustic information, which can effectively improve AR performance. Experiments on Accented English Speech Recognition Challenge (AESRC) dataset show that our method achieves 77.42% accuracy on Test set, obtaining a 6.94% relative improvement over a competitive system in the challenge.      
### 57.Robust Event-Driven Interactions in Cooperative Multi-Agent Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.03361.pdf)
>  We present an approach to reduce the communication required between agents in a Multi-Agent learning system by exploiting the inherent robustness of the underlying Markov Decision Process. We compute so-called robustness surrogate functions (off-line), that give agents a conservative indication of how far their state measurements can deviate before they need to update other agents in the system. This results in fully distributed decision functions, enabling agents to decide when it is necessary to update others. We derive bounds on the optimality of the resulting systems in terms of the discounted sum of rewards obtained, and show these bounds are a function of the design parameters. Additionally, we extend the results for the case where the robustness surrogate functions are learned from data, and present experimental results demonstrating a significant reduction in communication events between agents.      
### 58.Information-driven Path Planning for Hybrid Aerial Underwater Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2204.03329.pdf)
>  This paper presents a novel Rapidly-exploring Adaptive Sampling Tree (RAST) algorithm for the adaptive sampling mission of a hybrid aerial underwater vehicle (HAUV) in an air-sea 3D environment. This algorithm innovatively combines the tournament-based point selection sampling strategy, the information heuristic search process and the framework of Rapidly-exploring Random Tree (RRT) algorithm. Hence can guide the vehicle to the region of interest to scientists for sampling and generate a collision-free path for maximizing information collection by the HAUV under the constraints of environmental effects of currents or wind and limited budget. The simulation results show that the fast search adaptive sampling tree algorithm has higher optimization performance, faster solution speed and better stability than the Rapidly-exploring Information Gathering Tree (RIGT) algorithm and the particle swarm optimization (PSO) algorithm.      
### 59.Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-trained DNN-HMM-Based Acoustic-Phonetic Model  [ :arrow_down: ](https://arxiv.org/pdf/2204.03315.pdf)
>  In spoken language understanding (SLU), what the user says is converted to his/her intent. Recent work on end-to-end SLU has shown that accuracy can be improved via pre-training approaches. We revisit ideas presented by Lugosch et al. using speech pre-training and three-module modeling; however, to ease construction of the end-to-end SLU model, we use as our phoneme module an open-source acoustic-phonetic model from a DNN-HMM hybrid automatic speech recognition (ASR) system instead of training one from scratch. Hence we fine-tune on speech only for the word module, and we apply multi-target learning (MTL) on the word and intent modules to jointly optimize SLU performance. MTL yields a relative reduction of 40% in intent-classification error rates (from 1.0% to 0.6%). Note that our three-module model is a streaming method. The final outcome of the proposed three-module modeling approach yields an intent accuracy of 99.4% on FluentSpeech, an intent error rate reduction of 50% compared to that of Lugosch et al. Although we focus on real-time streaming methods, we also list non-streaming methods for comparison.      
### 60.Genre-conditioned Acoustic Models for Automatic Lyrics Transcription of Polyphonic Music  [ :arrow_down: ](https://arxiv.org/pdf/2204.03307.pdf)
>  Lyrics transcription of polyphonic music is challenging not only because the singing vocals are corrupted by the background music, but also because the background music and the singing style vary across music genres, such as pop, metal, and hip hop, which affects lyrics intelligibility of the song in different ways. In this work, we propose to transcribe the lyrics of polyphonic music using a novel genre-conditioned network. The proposed network adopts pre-trained model parameters, and incorporates the genre adapters between layers to capture different genre peculiarities for lyrics-genre pairs, thereby only requiring lightweight genre-specific parameters for training. Our experiments show that the proposed genre-conditioned network outperforms the existing lyrics transcription systems.      
### 61.mulEEG: A Multi-View Representation Learning on EEG Signals  [ :arrow_down: ](https://arxiv.org/pdf/2204.03272.pdf)
>  Modeling effective representations using multiple views that positively influence each other is challenging, and the existing methods perform poorly on Electroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we propose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG representation learning. Our method attempts to effectively utilize the complementary information available in multiple views to learn better representations. We introduce diverse loss that further encourages complementary information across multiple views. Our method with no access to labels beats the supervised training while outperforming multi-view baseline methods on transfer learning experiments carried out on sleep-staging tasks. We posit that our method was able to learn better representations by using complementary multi-views.      
### 62.Arabic Text-To-Speech (TTS) Data Preparation  [ :arrow_down: ](https://arxiv.org/pdf/2204.03255.pdf)
>  People may be puzzled by the fact that voice over recordings data sets exist in addition to Text-to-Speech (TTS), Synthesis system advancements, albeit this is not the case. The goal of this study is to explain the relevance of TTS as well as the data preparation procedures. TTS relies heavily on recorded data since it can have a substantial influence on the outcomes of TTS modules. Furthermore, whether the domain is specialized or general, appropriate data should be developed to address all predicted language variants and domains. Different recording methodologies, taking into account quality and behavior, may also be advantageous in the development of the module. In light of the lack of Arabic language in present synthesizing systems, numerous variables that impact the flow of recorded utterances are being considered in order to manipulate an Arabic TTS module. In this study, two viewpoints will be discussed: linguistics and the creation of high-quality recordings for TTS. The purpose of this work is to offer light on how ground-truth utterances may influence the evolution of speech systems in terms of naturalness, intelligibility, and understanding. Well provide voice actor specs as well as data specs that will assist both voice actors and voice coaches in the studio as well as the annotators who will be evaluating the audios.      
### 63.Expressive Singing Synthesis Using Local Style Token and Dual-path Pitch Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2204.03249.pdf)
>  This paper proposes a controllable singing voice synthesis system capable of generating expressive singing voice with two novel methodologies. First, a local style token module, which predicts frame-level style tokens from an input pitch and text sequence, is proposed to allow the singing voice system to control musical expression often unspecified in sheet music (e.g., breathing and intensity). Second, we propose a dual-path pitch encoder with a choice of two different pitch inputs: MIDI pitch sequence or f0 contour. Because the initial generation of a singing voice is usually executed by taking a MIDI pitch sequence, one can later extract an f0 contour from the generated singing voice and modify the f0 contour to a finer level as desired. Through quantitative and qualitative evaluations, we confirmed that the proposed model could control various musical expressions while not sacrificing the sound quality of the singing voice synthesis system.      
### 64.Speech Pre-training with Acoustic Piece  [ :arrow_down: ](https://arxiv.org/pdf/2204.03240.pdf)
>  Previous speech pre-training methods, such as wav2vec2.0 and HuBERT, pre-train a Transformer encoder to learn deep representations from audio data, with objectives predicting either elements from latent vector quantized space or pre-generated labels (known as target codes) with offline clustering. However, those training signals (quantized elements or codes) are independent across different tokens without considering their relations. According to our observation and analysis, the target codes share obvious patterns aligned with phonemized text data. Based on that, we propose to leverage those patterns to better pre-train the model considering the relations among the codes. The patterns we extracted, called "acoustic piece"s, are from the sentence piece result of HuBERT codes. With the acoustic piece as the training signal, we can implicitly bridge the input audio and natural language, which benefits audio-to-text tasks, such as automatic speech recognition (ASR). Simple but effective, our method "HuBERT-AP" significantly outperforms strong baselines on the LibriSpeech ASR task.      
### 65.Semantic-functional Communications for Multiuser Event Transmissions via Random Maps  [ :arrow_down: ](https://arxiv.org/pdf/2204.03223.pdf)
>  This work introduces a new perspective for physical media sharing in multiuser communication by jointly considering (i) the meaning of the transmitted message and (ii) its function at the end user. Specifically, we have defined a scenario where multiple users (sensors) are continuously transmitting their own states concerning a predetermined event. On the receiver side there is an alarm monitoring system, whose function is to decide whether such a predetermined event has happened in a certain time period and, if yes, in which user. The media access control protocol proposed constitutes an alternative approach to the conventional physical layer methods, because the receiver does not decode the received waveform directly; rather, the relative position of the absence or presence of energy within a multidimensional resource space carries the (semantic) information. The protocol introduced here provides high efficiency in multiuser networks that operate with event-triggered sampling by enabling a constructive reconstruction of transmission collisions. We have demonstrated that the proposed method leads to a better event transmission efficiency than conventional methods like TDMA and slotted ALOHA. Remarkably, the proposed method achieves 100\% efficiency and 0\% error probability in almost all the studied cases, while consistently outperforming TDMA and slotted ALOHA.      
### 66.Distributed Statistical Min-Max Learning in the Presence of Byzantine Agents  [ :arrow_down: ](https://arxiv.org/pdf/2204.03187.pdf)
>  Recent years have witnessed a growing interest in the topic of min-max optimization, owing to its relevance in the context of generative adversarial networks (GANs), robust control and optimization, and reinforcement learning. Motivated by this line of work, we consider a multi-agent min-max learning problem, and focus on the emerging challenge of contending with worst-case Byzantine adversarial agents in such a setup. By drawing on recent results from robust statistics, we design a robust distributed variant of the extra-gradient algorithm - a popular algorithmic approach for min-max optimization. Our main contribution is to provide a crisp analysis of the proposed robust extra-gradient algorithm for smooth convex-concave and smooth strongly convex-strongly concave functions. Specifically, we establish statistical rates of convergence to approximate saddle points. Our rates are near-optimal, and reveal both the effect of adversarial corruption and the benefit of collaboration among the non-faulty agents. Notably, this is the first paper to provide formal theoretical guarantees for large-scale distributed min-max learning in the presence of adversarial agents.      
### 67.3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.03178.pdf)
>  Recently, Conformer based CTC/AED model has become a mainstream architecture for ASR. In this paper, based on our prior work, we identify and integrate several approaches to achieve further improvements for ASR tasks, which we denote as multi-loss, multi-path and multi-level, summarized as "3M" model. Specifically, multi-loss refers to the joint CTC/AED loss and multi-path denotes the Mixture-of-Experts(MoE) architecture which can effectively increase the model capacity without remarkably increasing computation cost. Multi-level means that we introduce auxiliary loss at multiple level of a deep model to help training. We evaluate our proposed method on the public WenetSpeech dataset and experimental results show that the proposed method provides 12.2%-17.6% relative CER improvement over the baseline model trained by Wenet toolkit. On our large scale dataset of 150k hours corpus, the 3M model has also shown obvious superiority over the baseline Conformer model.      
### 68.Enhancement on Model Interpretability and Sleep Stage Scoring Performance with A Novel Pipeline Based on Deep Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2204.03173.pdf)
>  Considering the natural frequency characteristics in sleep medicine, this paper first proposes a time-frequency framework for the representation learning of the electroencephalogram (EEG) following the definition of the American Academy of Sleep Medicine. To meet the temporal-random and transient nature of the defining characteristics of sleep stages, we further design a context-sensitive flexible pipeline that automatically adapts to the attributes of data itself. That is, the input EEG spectrogram is partitioned into a sequence of patches in the time and frequency axes, and then input to a delicate deep learning network for further representation learning to extract the stage-dependent features, which are used in the classification step finally. The proposed pipeline is validated against a large database, i.e., the Sleep Heart Health Study (SHHS), and the results demonstrate that the competitive performance for the wake, N2, and N3 stages outperforms the state-of-art works, with the F1 scores being 0.93, 0.88, and 0.87, respectively, and the proposed method has a high inter-rater reliability of 0.80 kappa. Importantly, we visualize the stage scoring process of the model decision with the Layer-wise Relevance Propagation (LRP) method, which shows that the proposed pipeline is more sensitive and perceivable in the decision-making process than the baseline pipelines. Therefore, the pipeline together with the LRP method can provide better model interpretability, which is important for clinical support.      
### 69.An Instrumented Wheel-On-Limb System of Planetary Rovers for Wheel-Terrain Interactions: System Conception and Preliminary Design  [ :arrow_down: ](https://arxiv.org/pdf/2204.03112.pdf)
>  Understanding the wheel-terrain interaction is of great importance to improve the maneuverability and traversability of the rovers. A well-developed sensing device carried by the rover would greatly facilitate the complex risk-reducing operations on sandy terrains. In this paper, an instrumented wheel-on-limb (WOL) system of planetary rovers for wheel-terrain interaction characterization is presented. Assuming the function of a passive suspension of the wheel, the WOL system allows itself to follow the terrain contour, and keep the wheel remain lowered onto the ground during rover motion including climbing and descending, as well as deploy and place the wheel on the ground before a drive commanding. The system concept, functional requirements, and pre-design work, as well as the system integration are presented.      
### 70.Super-linear Scaling Behavior for Electric Vehicle Chargers and Road Map to Addressing the Infrastructure Gap  [ :arrow_down: ](https://arxiv.org/pdf/2204.03094.pdf)
>  Enabling widespread electric vehicle (EV) adoption requires substantial build-out of charging infrastructure in the coming decade. We formulate the charging infrastructure needs as a scaling analysis problem and use it to estimate the EV infrastructure needs of the US at a county-level resolution. Surprisingly, we find that the current EV infrastructure deployment scales super-linearly with population, deviating from the sub-linear scaling of gasoline stations and other infrastructure. We discuss how this demonstrates the infancy of EV station abundance compared to other mature transportation infrastructures. By considering the power delivery of existing gasoline stations, and appropriate EV efficiencies, we estimate the EV infrastructure gap at the county level, providing a road map for future EV infrastructure expansion. Our reliance on scaling analysis allows us to make a unique forecast in this domain.      
### 71.Audio-Visual Person-of-Interest DeepFake Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.03083.pdf)
>  Face manipulation technology is advancing very rapidly, and new methods are being proposed day by day. The aim of this work is to propose a deepfake detector that can cope with the wide variety of manipulation methods and scenarios encountered in the real world. Our key insight is that each person has specific biometric characteristics that a synthetic generator cannot likely reproduce. Accordingly, we extract high-level audio-visual biometric features which characterize the identity of a person, and use them to create a person-of-interest (POI) deepfake detector. We leverage a contrastive learning paradigm to learn the moving-face and audio segments embeddings that are most discriminative for each identity. As a result, when the video and/or audio of a person is manipulated, its representation in the embedding space becomes inconsistent with the real identity, allowing reliable detection. Training is carried out exclusively on real talking-face videos, thus the detector does not depend on any specific manipulation method and yields the highest generalization ability. In addition, our method can detect both single-modality (audio-only, video-only) and multi-modality (audio-video) attacks, and is robust to low-quality or corrupted videos by building only on high-level semantic features. Experiments on a wide variety of datasets confirm that our method ensures a SOTA performance, with an average improvement in terms of AUC of around 3%, 10%, and 7% for high-quality, low quality and attacked videos, respectively.      
### 72.Late multimodal fusion for image and audio music transcription  [ :arrow_down: ](https://arxiv.org/pdf/2204.03063.pdf)
>  Music transcription, which deals with the conversion of music sources into a structured digital format, is a key problem for Music Information Retrieval (MIR). When addressing this challenge in computational terms, the MIR community follows two lines of research: music documents, which is the case of Optical Music Recognition (OMR), or audio recordings, which is the case of Automatic Music Transcription (AMT). The different nature of the aforementioned input data has conditioned these fields to develop modality-specific frameworks. However, their recent definition in terms of sequence labeling tasks leads to a common output representation, which enables research on a combined paradigm. In this respect, multimodal image and audio music transcription comprises the challenge of effectively combining the information conveyed by image and audio modalities. In this work, we explore this question at a late-fusion level: we study four combination approaches in order to merge, for the first time, the hypotheses regarding end-to-end OMR and AMT systems in a lattice-based search space. The results obtained for a series of performance scenarios -- in which the corresponding single-modality models yield different error rates -- showed interesting benefits of these approaches. In addition, two of the four strategies considered significantly improve the corresponding unimodal standard recognition frameworks.      
### 73.FFC-SE: Fast Fourier Convolution for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2204.03042.pdf)
>  Fast Fourier convolution (FFC) is the recently proposed neural operator showing promising performance in several computer vision problems. The FFC operator allows employing large receptive field operations within early layers of the neural network. It was shown to be especially helpful for inpainting of periodic structures which are common in audio processing. In this work, we design neural network architectures which adapt FFC for speech enhancement. We hypothesize that a large receptive field allows these networks to produce more coherent phases than vanilla convolutional models, and validate this hypothesis experimentally. We found that neural networks based on Fast Fourier convolution outperform analogous convolutional models and show better or comparable results with other speech enhancement baselines.      
### 74.SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.03040.pdf)
>  In this work, we present the SOMOS dataset, the first large-scale mean opinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS) samples. It can be employed to train automatic MOS prediction systems focused on the assessment of modern synthesizers, and can stimulate advancements in acoustic model evaluation. It consists of 20K synthetic utterances of the LJ Speech voice, a public domain speech dataset which is a common benchmark for building neural acoustic models and vocoders. Utterances are generated from 200 TTS systems including vanilla neural acoustic models as well as models which allow prosodic variations. An LPCNet vocoder is used for all systems, so that the samples' variation depends only on the acoustic models. The synthesized utterances provide balanced and adequate domain and length coverage. We collect MOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and share practices leading to reliable crowdsourced annotations for this task. Baseline results of state-of-the-art MOS prediction models on the SOMOS dataset are presented, while we show the challenges that such models face when assigned to evaluate synthetic utterances.      
### 75.Safe Interactive Industrial Robots using Jerk-based Safe Set Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2204.03038.pdf)
>  The need to increase the flexibility of production lines is calling for robots to collaborate with human workers. However, existing interactive industrial robots only guarantee intrinsic safety (reduce collision impact), but not interactive safety (collision avoidance), which greatly limited their flexibility. The issue arises from two limitations in existing control software for industrial robots: 1) lack of support for real-time trajectory modification; 2) lack of intelligent safe control algorithms with guaranteed collision avoidance under robot dynamics constraints. To address the first issue, a jerk-bounded position controller (JPC) was developed previously. This paper addresses the second limitation, on top of the JPC. Specifically, we introduce a jerk-based safe set algorithm (JSSA) to ensure collision avoidance while considering the robot dynamics constraints. The JSSA greatly extends the scope of the original safe set algorithm, which has only been applied for second-order systems with unbounded accelerations. The JSSA is implemented on the FANUC LR Mate 200id/7L robot and validated with HRI tasks. Experiments show that the JSSA can consistently keep the robot at a safe distance from the human while executing the designated task.      
