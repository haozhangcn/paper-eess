# ArXiv eess --Wed, 13 Apr 2022
### 1.Automated Surface Texture Analysis via Discrete Cosine Transform and Discrete Wavelet Transform  [ :arrow_down: ](https://arxiv.org/pdf/2204.05968.pdf)
>  Surface roughness and texture are critical to the functional performance of engineering components. The ability to analyze roughness and texture effectively and efficiently is much needed to ensure surface quality in many surface generation processes, such as machining, surface mechanical treatment, etc. Discrete Wavelet Transform (DWT) and Discrete Cosine Transform (DCT) are two commonly used signal decomposition tools for surface roughness and texture analysis. Both methods require selecting a threshold to decompose a given surface into its three main components: form, waviness, and roughness. However, although DWT and DCT are part of the ISO surface finish standards, there exists no systematic guidance on how to compute these thresholds, and they are often manually selected on case by case basis. This makes utilizing these methods for studying surfaces dependent on the user's judgment and limits their automation potential. Therefore, we present two automatic threshold selection algorithms based on information theory and signal energy. We use machine learning to validate the success of our algorithms both using simulated surfaces as well as digital microscopy images of machined surfaces. Specifically, we generate feature vectors for each surface area or profile and apply supervised classification. Comparing our results with the heuristic threshold selection approach shows good agreement with mean accuracies as high as 95\%. We also compare our results with Gaussian filtering (GF) and show that while GF results for areas can yield slightly higher accuracies, our results outperform GF for surface profiles. We further show that our automatic threshold selection has significant advantages in terms of computational time as evidenced by decreasing the number of mode computations by an order of magnitude compared to the heuristic thresholding for DCT.      
### 2.Safety in Augmented Importance Sampling: Performance Bounds for Robust MPPI  [ :arrow_down: ](https://arxiv.org/pdf/2204.05963.pdf)
>  This work explores the nature of augmented importance sampling in safety-constrained model predictive control problems. When operating in a constrained environment, sampling based model predictive control and motion planning typically utilizes penalty functions or expensive optimization based control barrier algorithms to maintain feasibility of forward sampling. In contrast the presented algorithm utilizes discrete embedded barrier states in augmented importance sampling to apply feedback with respect to a nominal state when sampling. We will demonstrate that this approach of safety of discrete embedded barrier states in augmented importance sampling is more sample efficient by metric of collision free trajectories, is computationally feasible to perform per sample, and results in better safety performance on a cluttered navigation task with extreme un-modeled disturbances. In addition, we will utilize the theoretical properties of augmented importance sampling and safety control to derive a new bound on the free energy of the system.      
### 3.NARX Identification using Derivative-Based Regularized Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2204.05892.pdf)
>  This work presents a novel regularization method for the identification of Nonlinear Autoregressive eXogenous (NARX) models. The regularization method promotes the exponential decay of the influence of past input samples on the current model output. This is done by penalizing the sensitivity (i.e. partial derivative) of the NARX model simulated output with respect to the past inputs. The effectiveness of the approach is demonstrated through a simulation example, where a neural network NARX model is identified with this novel method. Moreover, it is shown that the proposed regularization approach improves the model accuracy in terms of simulation error performance compared to that of other regularization methods and model classes.      
### 4.Analytical Uncertainty Propagation for Multi-Period Stochastic Optimal Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2204.05883.pdf)
>  The increase in renewable energy sources (RESs), like wind or solar power, results in growing uncertainty also in transmission grids. This affects grid stability through fluctuating energy supply and an increased probability of overloaded lines. One key strategy to cope with this uncertainty is the use of distributed energy storage systems (ESSs). In order to securely operate power systems containing renewables and use storage, optimization models are needed that both handle uncertainty and apply ESSs. This paper introduces a compact dynamic stochastic chance-constrained optimal power flow (CC-OPF) model, that minimizes generation costs and includes distributed ESSs. Assuming Gaussian uncertainty, we use affine policies to obtain a tractable, analytically exact reformulation as a second-order cone problem (SOCP). We test the new model on five different IEEE networks with varying sizes of 5, 39, 57, 118 and 300 nodes and include complexity analysis. The results show that the model is computationally efficient and robust with respect to constraint violation risk. The distributed energy storage system leads to more stable operation with flattened generation profiles. Storage absorbed RES uncertainty, and reduced generation cost.      
### 5.VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2204.05841.pdf)
>  Speech restoration aims to remove distortions in speech signals. Prior methods mainly focus on a single type of distortion, such as speech denoising or dereverberation. However, speech signals can be degraded by several different distortions simultaneously in the real world. It is thus important to extend speech restoration models to deal with multiple distortions. In this paper, we introduce VoiceFixer, a unified framework for high-fidelity speech restoration. VoiceFixer restores speech from multiple distortions (e.g., noise, reverberation, and clipping) and can expand degraded speech (e.g., noisy speech) with a low bandwidth to 44.1 kHz full-bandwidth high-fidelity speech. We design VoiceFixer based on (1) an analysis stage that predicts intermediate-level features from the degraded speech, and (2) a synthesis stage that generates waveform using a neural vocoder. Both objective and subjective evaluations show that VoiceFixer is effective on severely degraded speech, such as real-world historical speech recordings. Samples of VoiceFixer are available at <a class="link-external link-https" href="https://haoheliu.github.io/voicefixer" rel="external noopener nofollow">this https URL</a>.      
### 6.GlacierNet2: A Hybrid Multi-Model Learning Architecture for Alpine Glacier Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2204.05818.pdf)
>  In recent decades, climate change has significantly affected glacier dynamics, resulting in mass loss and an increased risk of glacier-related hazards including supraglacial and proglacial lake development, as well as catastrophic outburst flooding. Rapidly changing conditions dictate the need for continuous and detailed observations and analysis of climate-glacier dynamics. Thematic and quantitative information regarding glacier geometry is fundamental for understanding climate forcing and the sensitivity of glaciers to climate change, however, accurately mapping debris-cover glaciers (DCGs) is notoriously difficult based upon the use of spectral information and conventional machine-learning techniques. The objective of this research is to improve upon an earlier proposed deep-learning-based approach, GlacierNet, which was developed to exploit a convolutional neural-network segmentation model to accurately outline regional DCG ablation zones. Specifically, we developed an enhanced GlacierNet2 architecture thatincorporates multiple models, automatic post-processing, and basin-level hydrological flow techniques to improve the mapping of DCGs such that it includes both the ablation and accumulation zones. Experimental evaluations demonstrate that GlacierNet2 improves the estimation of the ablation zone and allows a high level of intersection over union (IOU: 0.8839) score. The proposed architecture provides complete glacier (both accumulation and ablation zone) outlines at regional scales, with an overall IOU score of 0.8619. This is a crucial first step in automating complete glacier mapping that can be used for accurate glacier modeling or mass-balance analysis.      
### 7.Unsupervised Anomaly Detection in 3D Brain MRI using Deep Learning with impured training data  [ :arrow_down: ](https://arxiv.org/pdf/2204.05778.pdf)
>  The detection of lesions in magnetic resonance imaging (MRI)-scans of human brains remains challenging, time-consuming and error-prone. Recently, unsupervised anomaly detection (UAD) methods have shown promising results for this task. These methods rely on training data sets that solely contain healthy samples. Compared to supervised approaches, this significantly reduces the need for an extensive amount of labeled training data. However, data labelling remains error-prone. We study how unhealthy samples within the training data affect anomaly detection performance for brain MRI-scans. For our evaluations, we consider three publicly available data sets and use autoencoders (AE) as a well-established baseline method for UAD. We systematically evaluate the effect of impured training data by injecting different quantities of unhealthy samples to our training set of healthy samples from T1-weighted MRI-scans. We evaluate a method to identify falsely labeled samples directly during training based on the reconstruction error of the AE. Our results show that training with impured data decreases the UAD performance notably even with few falsely labeled samples. By performing outlier removal directly during training based on the reconstruction-loss, we demonstrate that falsely labeled data can be detected and removed to mitigate the effect of falsely labeled data. Overall, we highlight the importance of clean data sets for UAD in brain MRI and demonstrate an approach for detecting falsely labeled data directly during training.      
### 8.GORDA: Graph-based ORientation Distribution Analysis of SLI scatterometry Patterns of Nerve Fibres  [ :arrow_down: ](https://arxiv.org/pdf/2204.05776.pdf)
>  Scattered Light Imaging (SLI) is a novel approach for microscopically revealing the fibre architecture of unstained brain sections. The measurements are obtained by illuminating brain sections from different angles and measuring the transmitted (scattered) light under normal incidence. The evaluation of scattering profiles commonly relies on a peak picking technique and feature extraction from the peaks, which allows quantitative determination of parallel and crossing in-plane nerve fibre directions for each image pixel. However, the estimation of the 3D orientation of the fibres cannot be assessed with the traditional methodology. We propose an unsupervised learning approach using spherical convolutions for estimating the 3D orientation of neural fibres, resulting in a more detailed interpretation of the fibre orientation distributions in the brain.      
### 9.Enhancement of Pitch Controllability using Timbre-Preserving Pitch Augmentation in FastPitch  [ :arrow_down: ](https://arxiv.org/pdf/2204.05753.pdf)
>  The recently developed pitch-controllable text-to-speech (TTS) model, i.e. FastPitch, was conditioned for the pitch contours. However, the quality of the synthesized speech degraded considerably for pitch values that deviated significantly from the average pitch; i.e. the ability to control pitch was limited. To address this issue, we propose two algorithms to improve the robustness of FastPitch. First, we propose a novel timbre-preserving pitch-shifting algorithm for natural pitch augmentation. Pitch-shifted speech samples sound more natural when using the proposed algorithm because the speaker's vocal timbre is maintained. Moreover, we propose a training algorithm that defines FastPitch using pitch-augmented speech datasets with different pitch ranges for the same sentence. The experimental results demonstrate that the proposed algorithms improve the pitch controllability of FastPitch.      
### 10.Ultrasound Shear Wave Elasticity Imaging with Spatio-Temporal Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.05745.pdf)
>  Ultrasound shear wave elasticity imaging is a valuable tool for quantifying the elastic properties of tissue. Typically, the shear wave velocity is derived and mapped to an elasticity value, which neglects information such as the shape of the propagating shear wave or push sequence characteristics. We present 3D spatio-temporal CNNs for fast local elasticity estimation from ultrasound data. This approach is based on retrieving elastic properties from shear wave propagation within small local regions. A large training data set is acquired with a robot from homogeneous gelatin phantoms ranging from 17.42 kPa to 126.05 kPa with various push locations. The results show that our approach can estimate elastic properties on a pixelwise basis with a mean absolute error of 5.01+-4.37 kPa. Furthermore, we estimate local elasticity independent of the push location and can even perform accurate estimates inside the push region. For phantoms with embedded inclusions, we report a 53.93% lower MAE (7.50 kPa) and on the background of 85.24% (1.64 kPa) compared to a conventional shear wave method. Overall, our method offers fast local estimations of elastic properties with small spatio-temporal window sizes.      
### 11.Text-Driven Separation of Arbitrary Sounds  [ :arrow_down: ](https://arxiv.org/pdf/2204.05738.pdf)
>  We propose a method of separating a desired sound source from a single-channel mixture, based on either a textual description or a short audio sample of the target source. This is achieved by combining two distinct models. The first model, SoundWords, is trained to jointly embed both an audio clip and its textual description to the same embedding in a shared representation. The second model, SoundFilter, takes a mixed source audio clip as an input and separates it based on a conditioning vector from the shared text-audio representation defined by SoundWords, making the model agnostic to the conditioning modality. Evaluating on multiple datasets, we show that our approach can achieve an SI-SDR of 9.1 dB for mixtures of two arbitrary sounds when conditioned on text and 10.1 dB when conditioned on audio. We also show that SoundWords is effective at learning co-embeddings and that our multi-modal training approach improves the performance of SoundFilter.      
### 12.Fault Detection and Localization in Active Distribution Networks using Optimally Placed Phasor Measurements Units  [ :arrow_down: ](https://arxiv.org/pdf/2204.05690.pdf)
>  This paper introduces an algorithm able to detect and localize the occurrance of a fault in an Active Distribution Network, using the measurements collected by Phasor Measurement Units (PMUs). First, a basic algorithm that works under the assumption that all grid buses are equipped with a PMU is designed. Then, formal observability conditions that allow detection and localization with a reduced number of PMUs are provided. Based on these conditions, the algorithm is extended to perform correctly when not all network buses are monitored. Moreover, an Optimal Positioning Algorithm, always based on the observability conditions, is designed. This algorithm allows the user to customize the fault localization resolution. The approach is validated through simulations carried out on a benchmark active distribution network.      
### 13.How to Register a Live onto a Liver ? Partial Matching in the Space of Varifolds  [ :arrow_down: ](https://arxiv.org/pdf/2204.05665.pdf)
>  Partial shapes correspondences is a problem that often occurs in computer vision (occlusion, evolution in time...). In medical imaging, data may come from different modalities and be acquired under different conditions which leads to variations in shapes and topologies. In this paper we use an asymmetric data dissimilarity term applicable to various geometric shapes like sets of curves or surfaces, assessing the embedding of a shape into another one without relying on correspondences. It is designed as a data attachment for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework, allowing to compute a meaningful deformation of one shape onto a subset of the other. We refine it in order to control the resulting non-rigid deformations and provide consistent deformations of the shapes along with their ambient space. We show that partial matching can be used for robust multi-modal liver registration between a Computed Tomography (CT) volume and a Cone Beam Computed Tomography (CBCT) volume. The 3D imaging of the patient CBCT at point of care that we call live is truncated while the CT pre-intervention provides a full visualization of the liver. The proposed method allows the truncated surfaces from CBCT to be aligned non-rigidly, yet realistically, with surfaces from CT with an average distance of 2.6mm(+/- 2.2). The generated deformations extend consistently to the liver volume, and are evaluated on points of interest for the physicians, with an average distance of 5.8mm (+/- 2.7) for vessels bifurcations and 5.13mm (+/- 2.5) for tumors landmarks. Such multi-modality volumes registrations would help the physicians in the perspective of navigating their tools in the patient's anatomy to locate structures that are hardly visible in the CBCT used during their procedures. Our code is available at <a class="link-external link-https" href="https://github.com/plantonsanti/PartialMatchingVarifolds" rel="external noopener nofollow">this https URL</a>.      
### 14.Robust online joint state/input/parameter estimation of linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.05663.pdf)
>  This paper presents a method for jointly estimating the state, input, and parameters of linear systems in an online fashion. The method is specially designed for measurements that are corrupted with non-Gaussian noise or outliers, which are commonly found in engineering applications. In particular, it combines recursive, alternating, and iteratively-reweighted least squares into a single, one-step algorithm, which solves the estimation problem online and benefits from the robustness of least-deviation regression methods. The convergence of the iterative method is formally guaranteed. Numerical experiments show the good performance of the estimation algorithm in presence of outliers and in comparison to state-of-the-art methods.      
### 15.Hybrid Simulation-based Resource Planning and Constructability Analysis of RCC Pavement Projects  [ :arrow_down: ](https://arxiv.org/pdf/2204.05659.pdf)
>  One of the critical challenges in infrastructural constructions is designing and planning operations and their related resources. The complex interlinked composition of different factors and variables affecting resource productivity has made simulation a powerful approach for operational planning. The construction sector has recently seen a notable surge in applying various simulation tools to enhance further the quality of projects planning, particularly in large-scale infrastructure developments (e.g., highway construction). Due to possible cost overruns in improper resource allocation, optimizing the design and construction planning stages of megaprojects such as massive pavement projects is essential. Recent studies aimed to build a simulation-based strategy in construction designing and planning by combining various simulation approaches (e.g., discrete-event simulation, system dynamics, agent-based simulation, and hybrid simulation) to enhance the planning phase. This paper introduces an evolving real-time hybrid simulation technique regarding the projects intrinsic time-varying inputs and factors to optimize the planning of Roller Compacted Concrete (RCC) pavement projects. Several scenarios are investigated using various resource combinations to achieve the best execution method for delivering concrete to the project. An actual highway project case study validates the proposed model and its application for future projects. This studys findings exhibit the proficiencies of the simulation-based approach in resource planning of RCC pavement projects within the time and cost constraints and their related regulations.      
### 16.On the Potential of Using Sub-THz Frequencies for Beyond 5G  [ :arrow_down: ](https://arxiv.org/pdf/2204.05650.pdf)
>  This paper studies the potential of using above 71GHz frequencies for 5G-Advanced or later in 6G. More specifically, the focus is to analyze what could be needed in terms of waveform and numerologies. The results suggest that higher baseline subcarrier spacings (SCSs) may be needed when moving above 71GHz, to fulfill the need for higher required bandwidths and phase noise robustness. The required SCS depends on carrier frequency and modulation order. It is also illustrated that single-carrier waveforms, especially Known Tail Discrete Fourier Transform Spread Orthogonal Frequency Division Multiplexing (KT-DFT-s-OFDM) waveform is a potential candidate to be used in 5G-Advanced or 6G for sub-THz frequencies due to its robustness to phase noise, lower output power back-off and flexible adaptation of head and tail lengths.      
### 17.Portfolio Optimization Using a Consistent Vector-Based MSE Estimation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2204.05611.pdf)
>  This paper is concerned with optimizing the global minimum-variance portfolio's (GMVP) weights in high-dimensional settings where both observation and population dimensions grow at a bounded ratio. Optimizing the GMVP weights is highly influenced by the data covariance matrix estimation. In a high-dimensional setting, it is well known that the sample covariance matrix is not a proper estimator of the true covariance matrix since it is not invertible when we have fewer observations than the data dimension. Even with more observations, the sample covariance matrix may not be well-conditioned. This paper determines the GMVP weights based on a regularized covariance matrix estimator to overcome the aforementioned difficulties. Unlike other methods, the proper selection of the regularization parameter is achieved by minimizing the mean-squared error of an estimate of the noise vector that accounts for the uncertainty in the data mean estimation. Using random-matrix-theory tools, we derive a consistent estimator of the achievable mean-squared error that allows us to find the optimal regularization parameter using a simple line search. Simulation results demonstrate the effectiveness of the proposed method when the data dimension is larger than the number of data samples or of the same order.      
### 18.Low Latency Time Domain Multichannel Speech and Music Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2204.05609.pdf)
>  The Goal is to obtain a simple multichannel source separation with very low latency. Applications can be teleconferencing, hearing aids, augmented reality, or selective active noise cancellation. These real time applications need a very low latency, usually less than about 6 ms, and low complexity, because they usually run on small portable devices. For that we don't need the best separation, but "useful" separation, and not just on speech, but also music and noise. Usual frequency domain approaches have higher latency and complexity. Hence we introduce a novel probabilistic optimization method which we call "Random Directions", which can overcome local minima, applied to a simple time domain unmixing structure, and which is scalable for low complexity. Then it is compared to frequency domain approaches on separating speech and music sources, and using 3D microphone setups.      
### 19.Towards Optimal Kron-based Reduction Of Networks (Opti-KRON) for the Electric Power Grid  [ :arrow_down: ](https://arxiv.org/pdf/2204.05554.pdf)
>  For fast timescales or long prediction horizons, the AC optimal power flow (OPF) problem becomes a computational challenge for large-scale, realistic AC networks. To overcome this challenge, this paper presents a novel network reduction methodology that leverages an efficient mixed-integer linear programming (MILP) formulation of a Kron-based reduction that is optimal in the sense that it balances the degree of the reduction with resulting modeling errors in the reduced network. The method takes as inputs the full AC network and a pre-computed library of AC load flow data and uses the graph Laplacian to constraint nodal reductions to only be feasible for neighbors of non-reduced nodes. This results in a highly effective MILP formulation which is embedded within an iterative scheme to successively improve the Kron-based network reduction until convergence. The resulting optimal network reduction is, thus, grounded in the physics of the full network. The accuracy of the network reduction methodology is then explored for a 100+ node medium-voltage distribution feeder example across a wide range of operating conditions. It is finally shown that a network reduction of 25-85% can be achieved within seconds and with worst-case voltage magnitude deviation errors within any super node cluster of less than 0.01pu. These results illustrate that the proposed optimization-based approach to Kron reduction of networks is viable for larger networks and suitable for use within various power system applications.      
### 20.OptimizedDP: An Efficient, User-friendly Library For Optimal Control and Dynamic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2204.05520.pdf)
>  This paper introduces OptimizedDP, a high-performance software library that solves time-dependent Hamilton-Jacobi partial differential equation (PDE), computes backward reachable sets with application in robotics, and contains value iterations algorithm implementation for continuous action-state space Markov Decision Process (MDP) while leveraging user-friendliness of Python for different problem specifications without sacrificing efficiency of the core computation. These algorithms are all based on dynamic programming, and hence can both be challenging to implement and have bad execution runtime due to the large high-dimensional tabular arrays. Although there are existing toolboxes for level set methods that are used to solve the HJ PDE, our toolbox makes solving the PDE at higher dimensions possible as well as having an order of magnitude improvement in execution times compared to other toolboxes while keeping the interface easy to specify different dynamical systems description. Our toolbox is available online at <a class="link-external link-https" href="https://github.com/SFU-MARS/optimized_dp" rel="external noopener nofollow">this https URL</a>.      
### 21.A Finite-State Fixed-Corridor Model for UAS Traffic Management  [ :arrow_down: ](https://arxiv.org/pdf/2204.05517.pdf)
>  This paper proposes a physics-inspired solution for low altitude Unmanned Aircraft System (UAS) Traffic Management (UTM) in urban areas. We decompose UTM into spatial and temporal planning problems. For the spatial planning problem, we use the principles of Eulerian continuum mechanics to safely and optimally allocate finite airspace to a UAS. To this end, the finite airspace is partitioned into planned and unplanned subspaces with unplanned subspace(s) or zone(s) enclosing buildings and restricted no-fly regions. The planned subspace is divided into navigable channels that safely wrap unplanned zone(s). We model the airspace planning problem as a Markov Decision Process (MDP) with states defined based on spatial and temporal airspace features and actions authorizing transitions between safe navigable channels. We apply the proposed traffic management solution to plan safe coordination of small UAS in the airspace above downtown Tucson, Arizona.      
### 22.CorrectSpeech: A Fully Automated System for Speech Correction and Accent Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2204.05460.pdf)
>  This study extends our previous work on text-based speech editing to developing a fully automated system for speech correction and accent reduction. Consider the application scenario that a recorded speech audio contains certain errors, e.g., inappropriate words, mispronunciations, that need to be corrected. The proposed system, named CorrectSpeech, performs the correction in three steps: recognizing the recorded speech and converting it into time-stamped symbol sequence, aligning recognized symbol sequence with target text to determine locations and types of required edit operations, and generating the corrected speech. Experiments show that the quality and naturalness of corrected speech depend on the performance of speech recognition and alignment modules, as well as the granularity level of editing operations. The proposed system is evaluated on two corpora: a manually perturbed version of VCTK and L2-ARCTIC. The results demonstrate that our system is able to correct mispronunciation and reduce accent in speech recordings. Audio samples are available online for demonstration <a class="link-external link-https" href="https://daxintan-cuhk.github.io/CorrectSpeech/" rel="external noopener nofollow">this https URL</a> .      
### 23.A self-paced BCI system with low latency for motor imagery onset detection based on time series prediction paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2204.05450.pdf)
>  In a self-paced motor-imagery brain-computer interface (MI-BCI), the onsets of the MI commands presented in a continuous electroencephalogram (EEG) signal are unknown. To detect these onsets, most self-paced approaches apply a window function on the continuous EEG signal and split it into long segments for further analysis. As a result, the system has a high latency. To reduce the system latency, we propose an algorithm based on the time series prediction concept and use the data of the previously received time samples to predict the upcoming time samples. Our predictor is an encoder-decoder (ED) network built with long short-term memory (LSTM) units. The onsets of the MI commands are detected shortly by comparing the incoming signal with the predicted signal. The proposed method is validated on dataset IVc from BCI competition III. The simulation results show that the proposed algorithm improves the average F1-score achieved by the winner of the competition by 26.7% for latencies shorter than one second.      
### 24.Identifying the Dynamics of a System by Leveraging Data from Similar Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.05446.pdf)
>  We study the problem of identifying the dynamics of a linear system when one has access to samples generated by a similar (but not identical) system, in addition to data from the true system. We use a weighted least squares approach and provide finite sample performance guarantees on the quality of the identified dynamics. Our results show that one can effectively use the auxiliary data generated by the similar system to reduce the estimation error due to the process noise, at the cost of adding a portion of error that is due to intrinsic differences in the models of the true and auxiliary systems. We also provide numerical experiments to validate our theoretical results. Our analysis can be applied to a variety of important settings. For example, if the system dynamics change at some point in time (e.g., due to a fault), how should one leverage data from the prior system in order to learn the dynamics of the new system? As another example, if there is abundant data available from a simulated (but imperfect) model of the true system, how should one weight that data compared to the real data from the system? Our analysis provides insights into the answers to these questions.      
### 25.Lost Vibration Test Data Recovery Using Convolutional Neural Network: A Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2204.05440.pdf)
>  Data loss in Structural Health Monitoring (SHM) networks has recently become one of the main challenges for engineers. Therefore, a data recovery method for SHM, generally an expensive procedure, is essential. Lately, some techniques offered to recover this valuable raw data using Neural Network (NN) algorithms. Among them, the convolutional neural network (CNN) based on convolution, a mathematical operation, can be applied to non-image datasets such as signals to extract important features without human supervision. However, the effect of different parameters has not been studied and optimized for SHM applications. Therefore, this paper aims to propose different architectures and investigate the effects of different hyperparameters for one of the newest proposed methods, which is based on a CNN algorithm for the Alamosa Canyon Bridge as a real structure. For this purpose, three different CNN models were considered to predict one and two malfunctioned sensors by finding the correlation between other sensors, respectively. Then the CNN algorithm was trained by experimental data, and the results showed that the method had a reliable performance in predicting Alamosa Canyon Bridge's missed data. The accuracy of the model was increased by adding a convolutional layer. Also, a standard neural network with two hidden layers was trained with the same inputs and outputs of the CNN models. Based on the results, the CNN model had higher accuracy, lower computational cost, and was faster than the standard neural network.      
### 26.Can Self-Supervised Learning solve the problem of child speech recognition?  [ :arrow_down: ](https://arxiv.org/pdf/2204.05419.pdf)
>  Despite recent advancements in deep learning technologies, Child Speech Recognition remains a challenging task. Current Automatic Speech Recognition (ASR) models required substantial amounts of annotated data for training, which is scarce. In this work, we explore using the ASR model, wav2vec2, with different pretraining and finetuning configurations for self supervised learning (SSL) towards improving automatic child speech recognition. The pretrained wav2vec2 models were finetuned using different amounts of child speech training data to discover the optimum amount of data required to finetune the model for the task of child ASR. Our trained model receives the best word error rate (WER) of 8.37 on the in domain MyST dataset and WER of 10.38 on the out of domain PFSTAR dataset. We do not use any Language Models (LM) in our experiments.      
### 27.Active power control of wind farms: an instantaneous approach on waked conditions  [ :arrow_down: ](https://arxiv.org/pdf/2204.05417.pdf)
>  This paper presents a closed-loop controller for wind farms to provide active power control services using a high-fidelity computational fluid dynamics based wind plant simulator. The proposed design enhances power tracking stability and allows for simple understanding, where each turbine is considered as a pure time-delay system. The paper investigates the control performance with different nominal power distributions in a fully waked condition and limited power availability. Results demonstrate the improvement in power production obtained by closing the control loop, compared to greedy operation. Additionally, power tracking capabilities are enhanced with a nominal power distribution favored by axial-induction, as well as the occurrence of turbine saturation and the distribution of loads.      
### 28.A Switching Thrust Tracking Controller for Load Constrained Wind Turbines  [ :arrow_down: ](https://arxiv.org/pdf/2204.05413.pdf)
>  Wind turbines are prone to structural degradation, particularly in offshore locations. Based on the structural health condition of the tower, power de-rating strategies can be used to reduce structural loads at the cost of power losses.This paper introduces a novel closed-loop switching control architecture to constrain the thrust in individual turbines. By taking inspiration from developments in the field of reference governors, an existing demanded power tracking controller is extended by a thrust tracking controller. The latter is activated only when a user-defined constraint on fore-aft thrust force is exceeded, which can be set based on the actual damage status of the turbine. Having a down-regulation with monotonic aerodynamic load response, a simple linear thrust tracking controller is proposed. Such a scheme can reduce aerodynamic loads while incurring acceptable losses on power production which, in a wind farm setting, can be compensated for by other turbines. Large eddy simulations demonstrate the performance of the proposed scheme on satisfying thrust constraints.      
### 29.Transfer Learning for Autonomous Chatter Detection in Machining  [ :arrow_down: ](https://arxiv.org/pdf/2204.05400.pdf)
>  Large-amplitude chatter vibrations are one of the most important phenomena in machining processes. It is often detrimental in cutting operations causing a poor surface finish and decreased tool life. Therefore, chatter detection using machine learning has been an active research area over the last decade. Three challenges can be identified in applying machine learning for chatter detection at large in industry: an insufficient understanding of the universality of chatter features across different processes, the need for automating feature extraction, and the existence of limited data for each specific workpiece-machine tool combination. These three challenges can be grouped under the umbrella of transfer learning. This paper studies automating chatter detection by evaluating transfer learning of prominent as well as novel chatter detection methods. We investigate chatter classification accuracy using a variety of features extracted from turning and milling experiments with different cutting configurations. The studied methods include Fast Fourier Transform (FFT), Power Spectral Density (PSD), the Auto-correlation Function (ACF), Wavelet Packet Transform (WPT), and Ensemble Empirical Mode Decomposition (EEMD). We also examine more recent approaches based on Topological Data Analysis (TDA) and similarity measures of time series based on Discrete Time Warping (DTW). We evaluate the transfer learning potential of each approach by training and testing both within and across the turning and milling data sets. Our results show that carefully chosen time-frequency features can lead to high classification accuracies albeit at the cost of requiring manual pre-processing and the tagging of an expert user. On the other hand, we found that the TDA and DTW approaches can provide accuracies and F1 scores on par with the time-frequency methods without the need for manual preprocessing.      
### 30.PolyARBerNN: A Neural Network Guided Solver and Optimizer for Bounded Polynomial Inequalities  [ :arrow_down: ](https://arxiv.org/pdf/2204.05365.pdf)
>  Constraints solvers play a significant role in the analysis, synthesis, and formal verification of complex embedded and cyber-physical systems. In this paper, we study the problem of designing a scalable constraints solver for an important class of constraints named polynomial constraint inequalities (also known as non-linear real arithmetic theory). In this paper, we introduce a solver named PolyARBerNN that uses convex polynomials as abstractions for highly nonlinear polynomials. Such abstractions were previously shown to be powerful to prune the search space and restrict the usage of sound and complete solvers to small search spaces. Compared with the previous efforts on using convex abstractions, PolyARBerNN provides three main contributions namely (i) a neural network guided abstraction refinement procedure that helps selecting the right abstraction out of a set of pre-defined abstractions, (ii) a Bernstein polynomial-based search space pruning mechanism that can be used to compute tight estimates of the polynomial maximum and minimum values which can be used as an additional abstraction of the polynomials, and (iii) an optimizer that transforms polynomial objective functions into polynomial constraints (on the gradient of the objective function) whose solutions are guaranteed to be close to the global optima. These enhancements together allowed the PolyARBerNN solver to solve complex instances and scales more favorably compared to the state-of-art non-linear real arithmetic solvers while maintaining the soundness and completeness of the resulting solver. In particular, our test benches show that PolyARBerNN achieved 100X speedup compared with Z3 8.9, Yices 2.6, and NASALib (a solver that uses Bernstein expansion to solve multivariate polynomial constraints) on a variety of standard test benches.      
### 31.A Concurrent Switching Model for Traffic Congestion Control  [ :arrow_down: ](https://arxiv.org/pdf/2204.05358.pdf)
>  We introduce a new conservation-based approach for traffic coordination modeling and control in a network of interconnected roads (NOIR) with switching movement phase rotations at every NOIR junction. For modeling of traffic evolution, we first assume that the movement phase rotation is cyclic at every NOIR junction, but the duration of each movement phase can be arbitrarily commanded by traffic signals. Then, we propose a novel concurrent switching dynamics (CSD) with deterministic transitions among a finite number of states, representing the NOIR movement phases. We define the CSD control as a cyclic receding horizon optimization problem with periodic quadratic cost and constraints. More specifically, the cost is defined so that the traffic density is minimized and the boundary inflow is uniformly distributed over the boundary inlet roads, whereas the cost parameters are periodically changed with time. The constraints are linear and imposed by a trapezoidal fundamental diagram at every NOIR road so that traffic feasibility is assured and traffic over-saturation is avoided. The success of the proposed traffic boundary control is demonstrated by simulation of traffic congestion control in Downtown Phoenix.      
### 32.Leveraging Deep Neural Networks for Massive MIMO Data Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.05350.pdf)
>  Massive multiple-input multiple-output (MIMO) is a key technology for emerging next-generation wireless systems. Utilizing large antenna arrays at base-stations, massive MIMO enables substantial spatial multiplexing gains by simultaneously serving a large number of users. However, the complexity in massive MIMO signal processing (e.g., data detection) increases rapidly with the number of users, making conventional hand-engineered algorithms less computationally efficient. Low-complexity massive MIMO detection algorithms, especially those inspired or aided by deep learning, have emerged as a promising solution. While there exist many MIMO detection algorithms, the aim of this magazine paper is to provide insight into how to leverage deep neural networks (DNN) for massive MIMO detection. We review recent developments in DNN-based MIMO detection that incorporate the domain knowledge of established MIMO detection algorithms with the learning capability of DNNs. We then present a comparison of the key numerical performance metrics of these works. We conclude by describing future research areas and applications of DNNs in massive MIMO receivers.      
### 33.Cognitive Radio Inspired Uplink Rate-Splitting Multiple Access  [ :arrow_down: ](https://arxiv.org/pdf/2204.05825.pdf)
>  With the exponential increase of the number of devices in the communication ecosystem toward the upcoming sixth generation (6G) of wireless networks, more enabling technologies and potential wireless architectures are necessary to fulfill the networking requirements of high throughput, massive connectivity, ultra reliability, and heterogeneous Quality of Service (QoS). To this end, schemes based on rate-splitting multiple access (RSMA) are expected to play a pivotal role in next generation communication networks. In this work, we investigate an uplink network consisting of a primary user (PU) and a secondary user (SU) and, by introducing the concept of cognitive radio (CR) into the RSMA framework, a protocol based on RSMA is proposed. This protocol aims to serve the SU in a resource block which is originally allocated solely for the PU without negatively affecting the QoS of the PU. Moreover, a similar but simpler protocol based on successive interference cancellation is proposed. We derive closed-form expressions for the outage probability of the SU for the two proposed protocols, ensuring that there exists no negative impact for the PU. To obtain further insights, asymptotic analysis is performed and the corresponding diversity gains are presented. In the numerical results, we validate the the theoretical analysis and illustrate the superiority of the proposed protocols over two benchmark schemes.      
### 34.Stochastic Multi-armed Bandits with Non-stationary Rewards Generated by a Linear Dynamical System  [ :arrow_down: ](https://arxiv.org/pdf/2204.05782.pdf)
>  The stochastic multi-armed bandit has provided a framework for studying decision-making in unknown environments. We propose a variant of the stochastic multi-armed bandit where the rewards are sampled from a stochastic linear dynamical system. The proposed strategy for this stochastic multi-armed bandit variant is to learn a model of the dynamical system while choosing the optimal action based on the learned model. Motivated by mathematical finance areas such as Intertemporal Capital Asset Pricing Model proposed by Merton and Stochastic Portfolio Theory proposed by Fernholz that both model asset returns with stochastic differential equations, this strategy is applied to quantitative finance as a high-frequency trading strategy, where the goal is to maximize returns within a time period.      
### 35.On Top-$k$ Selection from $m$-wise Partial Rankings via Borda Counting  [ :arrow_down: ](https://arxiv.org/pdf/2204.05742.pdf)
>  We analyze the performance of the Borda counting algorithm in a non-parametric model. The algorithm needs to utilize probabilistic rankings of the items within $m$-sized subsets to accurately determine which items are the overall top-$k$ items in a total of $n$ items. The Borda counting algorithm simply counts the cumulative scores for each item from these partial ranking observations. This generalizes a previous work of a similar nature by Shah et al. using probabilistic pairwise comparison data. The performance of the Borda counting algorithm critically depends on the associated score separation $\Delta_k$ between the $k$-th item and the $(k+1)$-th item. Specifically, we show that if $\Delta_k$ is greater than certain value, then the top-$k$ items selected by the algorithm is asymptotically accurate almost surely; if $\Delta_k$ is below certain value, then the result will be inaccurate with a constant probability. In the special case of $m=2$, i.e., pairwise comparison, the resultant bound is tighter than that given by Shah et al., leading to a reduced gap between the error probability upper and lower bounds. These results are further extended to the approximate top-$k$ selection setting. Numerical experiments demonstrate the effectiveness and accuracy of the Borda counting algorithm, compared with the spectral MLE-based algorithm, particularly when the data does not necessarily follow an assumed parametric model.      
### 36.Modeling and computation of an integral operator Riccati equation for an infinite-dimensional stochastic differential equation governing streamflow discharge  [ :arrow_down: ](https://arxiv.org/pdf/2204.05716.pdf)
>  We propose a linear-quadratic (LQ) control problem of streamflow discharge by optimizing an infinite-dimensional jump-driven stochastic differential equation (SDE). Our SDE is a superposition of Ornstein-Uhlenbeck processes (supOU process), generating a sub-exponential autocorrelation function observed in actual data. The integral operator Riccati equation is heuristically derived to determine the optimal control of the infinite-dimensional system. In addition, its finite-dimensional version is derived with a discretized distribution of the reversion speed and computed by a finite difference scheme. The optimality of the Riccati equation is analyzed by a verification argument. The supOU process is parameterized based on the actual data of a perennial river. The convergence of the numerical scheme is analyzed through computational experiments. Finally, we demonstrate the application of the proposed model to realistic problems along with the Kolmogorov backward equation for the performance evaluation of controls.      
### 37.ADFF: Attention Based Deep Feature Fusion Approach for Music Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.05649.pdf)
>  Music emotion recognition (MER), a sub-task of music information retrieval (MIR), has developed rapidly in recent years. However, the learning of affect-salient features remains a challenge. In this paper, we propose an end-to-end attention-based deep feature fusion (ADFF) approach for MER. Only taking log Mel-spectrogram as input, this method uses adapted VGGNet as spatial feature learning module (SFLM) to obtain spatial features across different levels. Then, these features are fed into squeeze-and-excitation (SE) attention-based temporal feature learning module (TFLM) to get multi-level emotion-related spatial-temporal features (ESTFs), which can discriminate emotions well in the final emotion space. In addition, a novel data processing is devised to cut the single-channel input into multi-channel to improve calculative efficiency while ensuring the quality of MER. Experiments show that our proposed method achieves 10.43% and 4.82% relative improvement of valence and arousal respectively on the R2 score compared to the state-of-the-art model, meanwhile, performs better on datasets with distinct scales and in multi-task learning.      
### 38.Convolutional recurrent autoencoder network for learning underwater ocean acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2204.05573.pdf)
>  Underwater ocean acoustics is a complex physical phenomenon involving not only widely varying physical parameters and dynamical scales but also uncertainties in the ocean parameters. Thus, it is difficult to construct generalized physical models which can work in a broad range of situations. In this regard, we propose a convolutional recurrent autoencoder network (CRAN) architecture, which is a data-driven deep learning model for acoustic propagation. Being data-driven it is independent of how the data is obtained and can be employed for learning various ocean acoustic phenomena. The CRAN model can learn a reduced-dimensional representation of physical data and can predict the system evolution efficiently. Two cases of increasing complexity are considered to demonstrate the generalization ability of the CRAN. The first case is a one-dimensional wave propagation with spatially-varying discontinuous initial conditions. The second case corresponds to a far-field transmission loss distribution in a two-dimensional ocean domain with depth-dependent sources. For both cases, the CRAN can learn the essential elements of wave propagation physics such as characteristic patterns while predicting long-time system evolution with satisfactory accuracy. Such ability of the CRAN to learn complex ocean acoustics phenomena has the potential of real-time prediction for marine vessel decision-making and online control.      
### 39.Speech Emotion Recognition with Global-Aware Fusion on Multi-scale Feature Representation  [ :arrow_down: ](https://arxiv.org/pdf/2204.05571.pdf)
>  Speech Emotion Recognition (SER) is a fundamental task to predict the emotion label from speech data. Recent works mostly focus on using convolutional neural networks~(CNNs) to learn local attention map on fixed-scale feature representation by viewing time-varied spectral features as images. However, rich emotional feature at different scales and important global information are not able to be well captured due to the limits of existing CNNs for SER. In this paper, we propose a novel GLobal-Aware Multi-scale (GLAM) neural network (The code is available at <a class="link-external link-https" href="https://github.com/lixiangucas01/GLAM" rel="external noopener nofollow">this https URL</a>) to learn multi-scale feature representation with global-aware fusion module to attend emotional information. Specifically, GLAM iteratively utilizes multiple convolutional kernels with different scales to learn multiple feature representation. Then, instead of using attention-based methods, a simple but effective global-aware fusion module is applied to grab most important emotional information globally. Experiments on the benchmark corpus IEMOCAP over four emotions demonstrates the superiority of our proposed model with 2.5% to 4.5% improvements on four common metrics compared to previous state-of-the-art approaches.      
### 40.Near-Optimal Distributed Linear-Quadratic Regulator for Networked Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.05551.pdf)
>  This paper studies the trade-off between the degree of decentralization and the performance of a distributed controller in a linear-quadratic control setting. We study a system of interconnected agents over a graph and a distributed controller, called $\kappa$-distributed control, which lets the agents make control decisions based on the state information within distance $\kappa$ on the underlying graph. This controller can tune its degree of decentralization using the parameter $\kappa$ and thus allows a characterization of the relationship between decentralization and performance. We show that under mild assumptions, including stabilizability, detectability, and a polynomially growing graph condition, the performance difference between $\kappa$-distributed control and centralized optimal control becomes exponentially small in $\kappa$. This result reveals that distributed control can achieve near-optimal performance with a moderate degree of decentralization, and thus it is an effective controller architecture for large-scale networked systems.      
### 41.Inducing Social Optimality in Games via Adaptive Incentive Design  [ :arrow_down: ](https://arxiv.org/pdf/2204.05507.pdf)
>  How can a social planner adaptively incentivize selfish agents who are learning in a strategic environment to induce a socially optimal outcome in the long run? We propose a two-timescale learning dynamics to answer this question in both atomic and non-atomic games. In our learning dynamics, players adopt a class of learning rules to update their strategies at a faster timescale, while a social planner updates the incentive mechanism at a slower timescale. In particular, the update of the incentive mechanism is based on each player's externality, which is evaluated as the difference between the player's marginal cost and the society's marginal cost in each time step. We show that any fixed point of our learning dynamics corresponds to the optimal incentive mechanism such that the corresponding Nash equilibrium also achieves social optimality. We also provide sufficient conditions for the learning dynamics to converge to a fixed point so that the adaptive incentive mechanism eventually induces a socially optimal outcome. Finally, we demonstrate that the sufficient conditions for convergence are satisfied in a variety of games, including (i) atomic networked quadratic aggregative games, (ii) atomic Cournot competition, and (iii) non-atomic network routing games.      
### 42.Small Footprint Multi-channel ConvMixer for Keyword Spotting with Centroid Based Awareness  [ :arrow_down: ](https://arxiv.org/pdf/2204.05445.pdf)
>  It is critical for a keyword spotting model to have a small footprint as it typically runs on-device with low computational resources. However, maintaining the previous SOTA performance with reduced model size is challenging. In addition, a far-field and noisy environment with multiple signals interference aggravates the problem causing the accuracy to degrade significantly. In this paper, we present a multi-channel ConvMixer for speech command recognitions. The novel architecture introduces an additional audio channel mixing for channel audio interaction in a multi-channel audio setting to achieve better noise-robust features with more efficient computation. Besides, we proposed a centroid based awareness component to enhance the system by equipping it with additional spatial geometry information in the latent feature projection space. We evaluate our model using the new MISP challenge 2021 dataset. Our model achieves significant improvement against the official baseline with a 55% gain in the competition score (0.152) on raw microphone array input and a 63% (0.126) boost upon front-end speech enhancement.      
