# ArXiv eess --Wed, 20 Apr 2022
### 1.Hybrid Transformer Network for Different Horizons-based Enriched Wind Speed Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2204.09019.pdf)
>  Highly accurate different horizon-based wind speed forecasting facilitates a better modern power system. This paper proposed a novel astute hybrid wind speed forecasting model and applied it to different horizons. The proposed hybrid forecasting model decomposes the original wind speed data into IMFs (Intrinsic Mode Function) using Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN). We fed the obtained subseries from ICEEMDAN to the transformer network. Each transformer network computes the forecast subseries and then passes to the fusion phase. Get the primary wind speed forecasting from the fusion of individual transformer network forecast subseries. Estimate the residual error values and predict errors using a multilayer perceptron neural network. The forecast error is added to the primary forecast wind speed to leverage the high accuracy of wind speed forecasting. Comparative analysis with real-time Kethanur, India wind farm dataset results reveals the proposed ICEEMDAN-TNF-MLPN-RECS hybrid model's superior performance with MAE=1.7096*10^-07, MAPE=2.8416*10^-06, MRE=2.8416*10^-08, MSE=5.0206*10^-14, and RMSE=2.2407*10^-07 for case study 1 and MAE=6.1565*10^-07, MAPE=9.5005*10^-06, MRE=9.5005*10^-08, MSE=8.9289*10^-13, and RMSE=9.4493*10^-07 for case study 2 enriched wind speed forecasting than state-of-the-art methods and reduces the burden on the power system engineer.      
### 2.Short time quaternion quadratic phase Fourier transform and its uncertainty principles  [ :arrow_down: ](https://arxiv.org/pdf/2204.09017.pdf)
>  In this paper, we extend the quadratic phase Fourier transform of a complex valued functions to that of the quaternion valued functions of two variables. We call it the quaternion quadratic phase Fourier transform (QQPFT). Based on the relation between the QQPFT and the quaternion Fourier transform (QFT) we obtain the sharp Hausdorff-Young inequality for QQPFT. We define the short time quaternion quadratic phase Fourier transform (STQQPFT) and explore some of its properties including inner product relation and inversion formula. We find its relation with that of the 2D quaternion ambiguity function and the quaternion Wigner-Ville distribution associated with QQPFT and obtain the Lieb's uncertainty and entropy uncertainty principles for these three transforms.      
### 3.Benchmarking Domain Generalization on EEG-based Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.09016.pdf)
>  Electroencephalography (EEG) based emotion recognition has demonstrated tremendous improvement in recent years. Specifically, numerous domain adaptation (DA) algorithms have been exploited in the past five years to enhance the generalization of emotion recognition models across subjects. The DA methods assume that calibration data (although unlabeled) exists in the target domain (new user). However, this assumption conflicts with the application scenario that the model should be deployed without the time-consuming calibration experiments. We argue that domain generalization (DG) is more reasonable than DA in these applications. DG learns how to generalize to unseen target domains by leveraging knowledge from multiple source domains, which provides a new possibility to train general models. In this paper, we for the first time benchmark state-of-the-art DG algorithms on EEG-based emotion recognition. Since convolutional neural network (CNN), deep brief network (DBN) and multilayer perceptron (MLP) have been proved to be effective emotion recognition models, we use these three models as solid baselines. Experimental results show that DG achieves an accuracy of up to 79.41\% on the SEED dataset for recognizing three emotions, indicting the potential of DG in zero-training emotion recognition when multiple sources are available.      
### 4.Time Difference on Arrival Extraction from Two-Way Ranging  [ :arrow_down: ](https://arxiv.org/pdf/2204.08996.pdf)
>  Two-Way Ranging enables the distance estimation between two active parties and allows time of flight measurements despite relative clock offset and drift. Limited by the number of messages, scalable solutions build on Time Difference on Arrival to infer timing information at passive listeners. However, the demand for accurate distance estimates dictates a tight bound on the time synchronization, thus limiting scalability to the localization of passive tags relative to static, synchronized anchors. This work describes the extraction of Time Difference on Arrival information from a Two-Way Ranging process, enabling the extraction of distance information on passive listeners and further allowing scalable tag localization without the need for static or synchronized anchors. The expected error is formally deducted. The extension allows the extraction of the timing difference despite relative clock offset and drift for the Double-Sided Two-Way Ranging and Single-Sided Two-Way Ranging with additional carrier frequency offset estimation.      
### 5.Evaluating Digital Sine wave Generator Using Analog Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2204.08995.pdf)
>  This work aims to relate comparison metrics for both Direct Digital Synthesizers (DDS) and their analog counterparts. The proposed metrics are Total Harmonic Distortion (THD) and maximum absolute error. Error is theoretically formulated into closed forms for known systematic parameters of DDS, sample rate, and bit counts. By the use of Matlab scripting, the system model is simulated for a wide range of parameters sweep.      
### 6.Calculate the Optimum Threshold for Double Energy Detection Technique in Cognitive Radio Networks (CRNs)  [ :arrow_down: ](https://arxiv.org/pdf/2204.08994.pdf)
>  One of the most important technical challenges when designing a Cognitive Radio Networks (CRNs) is spectrum sensing, which has the responsibility of recognizing the presence or absence of the primary users in the frequency bands. A common technique used for spectrum sensing is double energy detection since it can operate without any prior information regarding the characteristics of the primary user signals. A double threshold energy detection algorithm is based on the use of two thresholds, to check the energy of the received signals and decided whether the spectrum is occupied or not. Furthermore, thresholds play a key role in the energy detection algorithm, by considering the stochastic features of noise in this model, as a result calculating the optimal threshold is a crucial task. In this paper, the Bi-Section algorithm was used to detect the optimum energy level in the fuzzy region which is an area between the low and high energy threshold. For this purpose, the decision threshold was determined by the use of the Bisection function for cognitive users. Numerical simulations show that the proposed method achieves better detection performance than the conventional double-threshold energy-sensing schemes. Moreover, the presented technique has advantages such as increasing the probability of detection of primary users and decreasing the probability of Collison between primary and secondary users.      
### 7.Study of Robust Sparsity-Aware RLS algorithms with Jointly-Optimized Parameters for Impulsive Noise Environments  [ :arrow_down: ](https://arxiv.org/pdf/2204.08990.pdf)
>  This paper proposes a unified sparsity-aware robust recursive least-squares RLS (S-RRLS) algorithm for the identification of sparse systems under impulsive noise. The proposed algorithm generalizes multiple algorithms only by replacing the specified criterion of robustness and sparsity-aware penalty. Furthermore, by jointly optimizing the forgetting factor and the sparsity penalty parameter, we develop the jointly-optimized S-RRLS (JO-S-RRLS) algorithm, which not only exhibits low misadjustment but also can track well sudden changes of a sparse system. Simulations in impulsive noise scenarios demonstrate that the proposed S-RRLS and JO-S-RRLS algorithms outperform existing techniques.      
### 8.Efficient Deep Learning-based Estimation of the Vital Signs on Smartphones  [ :arrow_down: ](https://arxiv.org/pdf/2204.08989.pdf)
>  Nowadays, due to the widespread use of smartphones in everyday life and the improvement of computational capabilities of these devices, many complex tasks can now be deployed on them. Concerning the need for continuous monitoring of vital signs, especially for the elderly or those with certain types of diseases, the development of algorithms that can estimate vital signs using smartphones has attracted researchers worldwide. Such algorithms estimate vital signs (heart rate and oxygen saturation level) by processing an input PPG signal. These methods often apply multiple pre-processing steps to the input signal before the prediction step. This can increase the computational complexity of these methods, meaning only a limited number of mobile devices can run them. Furthermore, multiple pre-processing steps also require the design of a couple of hand-crafted stages to obtain an optimal result. This research proposes a novel end-to-end solution to mobile-based vital sign estimation by deep learning. The proposed method does not require any pre-processing. Due to the use of fully convolutional architecture, the parameter count of our proposed model is, on average, a quarter of the ordinary architectures that use fully-connected layers as the prediction heads. As a result, the proposed model has less over-fitting chance and computational complexity. A public dataset for vital sign estimation, including 62 videos collected from 35 men and 27 women, is also provided. The experimental results demonstrate state-of-the-art estimation accuracy.      
### 9.Per-clip adaptive Lagrangian multiplier optimisation with low-resolution proxies  [ :arrow_down: ](https://arxiv.org/pdf/2204.08966.pdf)
>  This work focuses on reducing the computational cost of repeated video encodes by using a lower resolution clip as a proxy. Features extracted from the low resolution clip are used to learn an optimal lagrange multiplier for rate control on the original resolution clip. In addition to reducing the computational cost and encode time by using lower resolution clips, we also investigate the use of older, but faster codecs such as H.264 to create proxies. This work shows that the computational load is reduced by 22 times using 144p proxies. Our tests are based on the YouTube UGC dataset, hence our results are based on a practical instance of the adaptive bitrate encoding problem. Further improvements are possible, by optimising the placement and sparsity of operating points required for the rate distortion curves.      
### 10.Per Clip Lagrangian Multiplier Optimisation for HEVC  [ :arrow_down: ](https://arxiv.org/pdf/2204.08965.pdf)
>  The majority of internet traffic is video content. This drives the demand for video compression in order to deliver high quality video at low target bitrates. This paper investigates the impact of adjusting the rate distortion equation on compression performance. An constant of proportionality, k, is used to modify the Lagrange multiplier used in H.265 (HEVC). Direct optimisation methods are deployed to maximise BD-Rate improvement for a particular clip. This leads to up to 21% BD-Rate improvement for an individual clip. Furthermore we use a more realistic corpus of material provided by YouTube. The results show that direct optimisation using BD-rate as the objective function can lead to further gains in bitrate savings that are not available with previous approaches.      
### 11.Adaptable Semantic Compression and Resource Allocation for Task-Oriented Communications  [ :arrow_down: ](https://arxiv.org/pdf/2204.08910.pdf)
>  Task-oriented communication is a new paradigm that aims at providing efficient connectivity for accomplishing intelligent tasks rather than the reception of every transmitted bit. In this paper, a deep learning-based task-oriented communication architecture is proposed where the user extracts, compresses and transmits semantics in an end-to-end (E2E) manner. Furthermore, an approach is proposed to compress the semantics according to their importance relevant to the task, namely, adaptable semantic compression (ASC). Assuming a delay-intolerant system, supporting multiple users indicates a problem that executing with the higher compression ratio requires fewer channel resources but leads to the distortion of semantics, while executing with the lower compression ratio requires more channel resources and thus may lead to a transmission failure due to delay constraint. To solve the problem, both compression ratio and resource allocation are optimized for the task-oriented communication system to maximize the success probability of tasks. Specifically, due to the nonconvexity of the problem, we propose a compression ratio and resource allocation (CRRA) algorithm by separating the problem into two subproblems and solving iteratively to obtain the convergent solution. Furthermore, considering the scenarios where users have various service levels, a compression ratio, resource allocation, and user selection (CRRAUS) algorithm is proposed to deal with the problem. In CRRAUS, users are adaptively selected to complete the corresponding intelligent tasks based on branch and bound method at the expense of higher algorithm complexity compared with CRRA. Simulation results show that the proposed CRRA and CRRAUS algorithms can obtain at least 15% and 10% success gains over baseline algorithms, respectively.      
### 12.Channel estimation for double IRS assisted broadband single-user SISO communication  [ :arrow_down: ](https://arxiv.org/pdf/2204.08885.pdf)
>  In this paper, two Intelligent reflecting surfaces (double IRS) assisted single-user single input single output (SISO) communication system is considered. The cascaded channels (mobile user (MU)$\rightarrow$IRS-1$\rightarrow$base station (BS), MU$\rightarrow$IRS-2$\rightarrow$BS and MU$\rightarrow$IRS-1$\rightarrow$IRS-2$\rightarrow$BS channels) are estimated under Bayesian setting. Here, the goal is to evaluate the performance of the estimator in case of MU$\rightarrow$IRS-1$\rightarrow$BS and MU$\rightarrow$IRS-2$\rightarrow$BS channel links using Bayesian Cramer-Rao lower bound (CRLB). Without the knowledge of closed form pdf of inner product of circularly symmetric complex Gaussian (CSCG) random vectors, we cannot obtain the fisher information. Hence, by numerical computation we obtain the Bayesian CRLB. In the simulation results, we show that we can approximate the pdf of the inner product of CSCG random vectors by a Rayleigh distribution by increasing the number of elements on the IRS, which is analogous to Central Limit Theorem (CLT). Also, the results convey that the mean squared error (MSE) almost matches with the Bayesian CRLB.      
### 13.An Investigation of Monotonic Transducers for Large-Scale Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.08858.pdf)
>  The two most popular loss functions for streaming end-to-end automatic speech recognition (ASR) are the RNN-Transducer (RNN-T) and the connectionist temporal classification (CTC) objectives. Both perform an alignment-free training by marginalizing over all possible alignments, but use different transition rules. Between these two loss types we can classify the monotonic RNN-T (MonoRNN-T) and the recently proposed CTC-like Transducer (CTC-T), which both can be realized using the graph temporal classification-transducer (GTC-T) loss function. Monotonic transducers have a few advantages. First, RNN-T can suffer from runaway hallucination, where a model keeps emitting non-blank symbols without advancing in time, often in an infinite loop. Secondly, monotonic transducers consume exactly one model score per time step and are therefore more compatible and unifiable with traditional FST-based hybrid ASR decoders. However, the MonoRNN-T so far has been found to have worse accuracy than RNN-T. It does not have to be that way, though: By regularizing the training - via joint LAS training or parameter initialization from RNN-T - both MonoRNN-T and CTC-T perform as well - or better - than RNN-T. This is demonstrated for LibriSpeech and for a large-scale in-house data set.      
### 14.Two-Stream Graph Convolutional Network for Intra-oral Scanner Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.08797.pdf)
>  Precise segmentation of teeth from intra-oral scanner images is an essential task in computer-aided orthodontic surgical planning. The state-of-the-art deep learning-based methods often simply concatenate the raw geometric attributes (i.e., coordinates and normal vectors) of mesh cells to train a single-stream network for automatic intra-oral scanner image segmentation. However, since different raw attributes reveal completely different geometric information, the naive concatenation of different raw attributes at the (low-level) input stage may bring unnecessary confusion in describing and differentiating between mesh cells, thus hampering the learning of high-level geometric representations for the segmentation task. To address this issue, we design a two-stream graph convolutional network (i.e., TSGCN), which can effectively handle inter-view confusion between different raw attributes to more effectively fuse their complementary information and learn discriminative multi-view geometric representations. Specifically, our TSGCN adopts two input-specific graph-learning streams to extract complementary high-level geometric representations from coordinates and normal vectors, respectively. Then, these single-view representations are further fused by a self-attention module to adaptively balance the contributions of different views in learning more discriminative multi-view representations for accurate and fully automatic tooth segmentation. We have evaluated our TSGCN on a real-patient dataset of dental (mesh) models acquired by 3D intraoral scanners. Experimental results show that our TSGCN significantly outperforms state-of-the-art methods in 3D tooth (surface) segmentation. Github: <a class="link-external link-https" href="https://github.com/ZhangLingMing1/TSGCNet" rel="external noopener nofollow">this https URL</a>.      
### 15.Single-Channel Speech Dereverberation using Subband Network with A Reverberation Time Shortening Target  [ :arrow_down: ](https://arxiv.org/pdf/2204.08765.pdf)
>  This work proposes a subband network for single-channel speech dereverberation, and also a new learning target based on reverberation time shortening (RTS). In the time-frequency domain, we propose to use a subband network to perform dereverberation for different frequency bands independently. The time-domain convolution can be well decomposed to subband convolutions, thence it is reasonable to train the subband network to perform subband deconvolution. The learning target for dereverberation is usually set as the direct-path speech or optionally with some early reflections. This type of target suddenly truncates the reverberation, and thus it may not be suitable for network training, and leads to a large prediction error. In this work, we propose a RTS learning target to suppress reverberation and meanwhile maintain the exponential decaying property of reverberation, which will ease the network training, and thus reduce the prediction error and signal distortions. Experiments show that the subband network can achieve outstanding dereverberation performance, and the proposed target has a smaller prediction error than the target of direct-path speech and early reflections.      
### 16.A Stackelberg game for incentive-based demand response in energy markets  [ :arrow_down: ](https://arxiv.org/pdf/2204.08730.pdf)
>  In modern buildings renewable energy generators and storage devices are spreading, and consequently the role of the users in the power grid is shifting from passive to active. We design a demand response scheme that exploits the prosumers' flexibility to provide ancillary services to the main grid. We propose a hierarchical scheme to coordinate the interactions between the distribution system operator and a community of smart prosumers. The framework inherits characteristics from price-based and incentive-based schemes and it retains the advantages of both. We cast the problem as a Stackelberg game with the prosumers as followers and the distribution system operator as leader. We solve the resulting bilevel optimization program via a KKT reformulation, proving the existence and the convergence to a local Stackelberg equilibrium. Finally, we provide numerical simulations to corroborate our claims on the benefits of the proposed framework.      
### 17.Audio Deep Fake Detection System with Neural Stitching for ADD 2022  [ :arrow_down: ](https://arxiv.org/pdf/2204.08720.pdf)
>  This paper describes our best system and methodology for ADD 2022: The First Audio Deep Synthesis Detection Challenge\cite{Yi2022ADD}. The very same system was used for both two rounds of evaluation in Track 3.2 with a similar training methodology. The first round of Track 3.2 data is generated from Text-to-Speech(TTS) or voice conversion (VC) algorithms, while the second round of data consists of generated fake audio from other participants in Track 3.1, aiming to spoof our systems. Our systems use a standard 34-layer ResNet, with multi-head attention pooling \cite{india2019self} to learn the discriminative embedding for fake audio and spoof detection. We further utilize neural stitching to boost the model's generalization capability in order to perform equally well in different tasks, and more details will be explained in the following sessions. The experiments show that our proposed method outperforms all other systems with a 10.1% equal error rate(EER) in Track 3.2.      
### 18.Adaptive Conductance Control  [ :arrow_down: ](https://arxiv.org/pdf/2204.08711.pdf)
>  Neuromodulation is central to the adaptation and robustness of animal nervous systems. This paper explores the classical paradigm of indirect adaptive control to design neuromodulatory controllers in conductance-based neuronal models. The adaptive control of maximal conductance parameters is shown to provide a methodology aligned with the central concepts of neuromodulation in physiology and of impedance control in robotics.      
### 19.Time Domain Adversarial Voice Conversion for ADD 2022  [ :arrow_down: ](https://arxiv.org/pdf/2204.08692.pdf)
>  In this paper, we describe our speech generation system for the first Audio Deep Synthesis Detection Challenge (ADD 2022). Firstly, we build an any-to-many voice conversion (VC) system to convert source speech with arbitrary language content into the target speaker%u2019s fake speech. Then the converted speech generated from VC is post-processed in the time domain to improve the deception ability. The experimental results show that our system has adversarial ability against anti-spoofing detectors with a little compromise in audio quality and speaker similarity. This system ranks top in Track 3.1 in the ADD 2022, showing that our method could also gain good generalization ability against different detectors.      
### 20.Consensus of networked double integrator systems under sensor bias  [ :arrow_down: ](https://arxiv.org/pdf/2204.08666.pdf)
>  A novel distributed control law for consensus of networked double integrator systems with biased measurements is developed in this article. The agents measure relative positions over a time-varying, undirected graph with an unknown and constant sensor bias corrupting the measurements. An adaptive control law is derived using Lyapunov methods to estimate the individual sensor biases accurately. The proposed algorithm ensures that position consensus is achieved exponentially in addition to bias estimation. The results leverage recent advances in collective initial excitation based results in adaptive estimation. Conditions connecting bipartite graphs and collective initial excitation are also developed. The algorithms are illustrated via simulation studies on a network of double integrators with local communication and biased measurements.      
### 21.Dir-MUSIC Algorithm for DOA Estimation of Partial Discharge Based on Signal Strength represented by Antenna Gain Array Manifold  [ :arrow_down: ](https://arxiv.org/pdf/2204.08661.pdf)
>  Inspection robots are widely used in the field of smart grid monitoring in substations, and partial discharge (PD) is an important sign of the insulation state of equipments. PD direction of arrival (DOA) algorithms using conventional beamforming and time difference of arrival (TDOA) require large-scale antenna arrays and high computational complexity, which make them difficult to implement on inspection robots. To address this problem, a novel directional multiple signal classification (Dir-MUSIC) algorithm for PD direction finding based on signal strength is proposed, and a miniaturized directional spiral antenna circular array is designed in this paper. First, the Dir-MUSIC algorithm is derived based on the array manifold characteristics. This method uses strength intensity information rather than the TDOA information, which could reduce the computational difficulty and the requirement of array size. Second, the effects of signal-to-noise ratio (SNR) and array manifold error on the performance of the algorithm are discussed through simulations in detail. Then according to the positioning requirements, the antenna array and its arrangement are developed, optimized, and simulation results suggested that the algorithm has reliable direction-finding performance in the form of 6 elements. Finally, the effectiveness of the algorithm is tested by using the designed spiral circular array in real scenarios. The experimental results show that the PD direction-finding error is 3.39°, which can meet the need for Partial discharge DOA estimation using inspection robots in substations.      
### 22.Interaction-Aware Labeled Multi-Bernoulli Filter  [ :arrow_down: ](https://arxiv.org/pdf/2204.08655.pdf)
>  Tracking multiple objects through time is an important part of an intelligent transportation system. Random finite set (RFS)-based filters are one of the emerging techniques for tracking multiple objects. In multi-object tracking (MOT), a common assumption is that each object is moving independent of its surroundings. But in many real-world applications, target objects interact with one another and the environment. Such interactions, when considered for tracking, are usually modeled by an interactive motion model which is application specific. In this paper, we present a novel approach to incorporate target interactions within the prediction step of an RFS-based multi-target filter, i.e. labeled multi-Bernoulli (LMB) filter. The method has been developed for two practical applications of tracking a coordinated swarm and vehicles. The method has been tested for a complex vehicle tracking dataset and compared with the LMB filter through the OSPA and OSPA$^{(2)}$ metrics. The results demonstrate that the proposed interaction-aware method depicts considerable performance enhancement over the LMB filter in terms of the selected metrics.      
### 23.Unsupervised Motor Imagery Saliency Detection Based on Self-Attention Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2204.08633.pdf)
>  Detecting the salient parts of motor-imagery electroencephalogram (MI-EEG) signals can enhance the performance of the brain-computer interface (BCI) system and reduce the computational burden required for processing lengthy MI-EEG signals. In this paper, we propose an unsupervised method based on the self-attention mechanism to detect the salient intervals of MI-EEG signals automatically. Our suggested method can be used as a preprocessing step within any BCI algorithm to enhance its performance. The effectiveness of the suggested method is evaluated on the most widely used BCI algorithm, the common spatial pattern (CSP) algorithm, using dataset 2a from BCI competition IV. The results indicate that the proposed method can effectively prune MI-EEG signals and significantly enhance the performance of the CSP algorithm in terms of classification accuracy.      
### 24.A Subject-Independent Brain-Computer Interface Framework Based on Supervised Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2204.08626.pdf)
>  A calibration procedure is required in motor imagery-based brain-computer interface (MI-BCI) to tune the system for new users. This procedure is time-consuming and prevents naïve users from using the system immediately. Developing a subject-independent MI-BCI system to reduce the calibration phase is still challenging due to the subject-dependent characteristics of the MI signals. Many algorithms based on machine learning and deep learning have been developed to extract high-level features from the MI signals to improve the subject-to-subject generalization of a BCI system. However, these methods are based on supervised learning and extract features useful for discriminating various MI signals. Hence, these approaches cannot find the common underlying patterns in the MI signals and their generalization level is limited. This paper proposes a subject-independent MI-BCI based on a supervised autoencoder (SAE) to circumvent the calibration phase. The suggested framework is validated on dataset 2a from BCI competition IV. The simulation results show that our SISAE model outperforms the conventional and widely used BCI algorithms, common spatial and filter bank common spatial patterns, in terms of the mean Kappa value, in eight out of nine subjects.      
### 25.DFRC with Improved Communication-Sensing Trade-off via Private Subcarrier Permutations and Pairing with Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2204.08590.pdf)
>  Dual function radar communication (DFRC) systems can achieve significant improvements in spectrum efficiency, system complexity and energy efficiency, and are attracting a lot of attention for next generation wireless system design. This paper considers DFRC systems using MIMO radar with a sparse transmit array, transmitting OFDM waveforms, and assigning shared and private subcarriers to active transmit antennas. Subcarrier sharing allows antennas to modulate data symbols onto the same subcarriers and enables high communication rate, while the use of private subcarriers trades-off communication rate for sensing performance by enabling the formulation of a virtual array with larger aperture than the physical receive array. We propose to exploit the permutation of private subcarriers among the available subcarriers and the pairing between active antennas and private subcarriers to recover some of the communication rate loss. Exploiting the $1$-sparse property of private subcarriers, we also propose a low complexity algorithm to identify private subcarriers and detect the antenna-subcarrier pairing.      
### 26.PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of Networked Microgrids Through Full-Field Measurement  [ :arrow_down: ](https://arxiv.org/pdf/2204.08557.pdf)
>  A Physics-Informed Dynamic Graph Neural Network (PIDGeuN) is presented to accurately, efficiently and robustly predict the nonlinear transient dynamics of microgrids in the presence of disturbances. The graph-based architecture of PIDGeuN provides a natural representation of the microgrid topology. Using only the state information that is practically measurable, PIDGeuN employs a time delay embedding formulation to fully reproduce the system dynamics, avoiding the dependency of conventional methods on internal dynamic states such as controllers. Based on a judiciously designed message passing mechanism, the PIDGeuN incorporates two physics-informed techniques to improve its prediction performance, including a physics-data-infusion approach to determining the inter-dependencies between buses, and a loss term to respect the known physical law of the power system, i.e., the Kirchhoff's law, to ensure the feasibility of the model prediction. Extensive tests show that PIDGeuN can provide accurate and robust prediction of transient dynamics for nonlinear microgrids over a long-term time period. Therefore, the PIDGeuN offers a potent tool for the modeling of large scale networked microgrids (NMs), with potential applications to predictive or preventive control in real time applications for the stable and resilient operations of NMs.      
### 27.On the Herdability of Linear Time-Invariant Systems with Special Topological Structures  [ :arrow_down: ](https://arxiv.org/pdf/2204.08536.pdf)
>  In this paper, we investigate the herdability property, namely the capability of a system to be driven towards the (interior of the) positive orthant, for linear time-invariant state-space models. Herdability of certain matrix pairs (A,B), where A is the adjacency matrix of a multi-agent network, and B is a selection matrix that singles out a subset of the agents (the "network leaders"), is explored. The cases when the graph associated with A, G(A), is directed and clustering balanced (in particular, structurally balanced), or it has a tree topology and there is a single leader, are investigated.      
### 28.Impact of Cyber Failures on Operation and Adequacy of Multi-Microgrid Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.08526.pdf)
>  Large-scale successful integration of microgeneration, together with active loads, energy storage devices, and energy scheduling strategies, requires the extensive adoption of advanced information and communication technologies (ICTs) at the distribution network level; this brings so-called Cyber-Physical Multi-MicroGrid (CPMMG) systems into the picture. However, as such ICTs are not failure-free, their integration affects the system's operation and adequacy. To quantify how cyber failures influence a CPMMG system, this study proposes an adequacy framework based on sequential Monte Carlo Simulation (MCS). In the proposed framework, the typical structure of a CPMMG is exemplified, and the consequences of various cyber failures in this system are explained. Possible operation modes -- normal, island, joint, and shutdown modes -- are then explained and modeled. Finally, the adequacy index Expected Energy Not Served (EENS) is computed based on the proposed methodology, and two new adequacy indices are proposed: Interrupted but Gained Compensation (IbGC) and Supplied by Expensive Resources (SbER). A comprehensive case study is conducted to reveal the salient features of the proposed framework.      
### 29.Modeling the Cooperative Process of Learning a Task  [ :arrow_down: ](https://arxiv.org/pdf/2204.08519.pdf)
>  In this paper, we propose a mathematical model for a Transactive Memory System (TMS) involved in the cooperative process of learning a task. The model is based on an intertwined dynamics involving both the individuals level of expertise and the interaction network among the cooperators. The model shows that if all the agents are non-stubborn, then all of them are able to acquire the competence of the most expert members of the group, asymptotically reaching their level of proficiency. Conversely, when dealing with all stubborn agents, the capability to pass on the task depends on the connectedness properties of the interaction graph.      
### 30.Multi-dimensional extensions of the Hegselmann-Krause model  [ :arrow_down: ](https://arxiv.org/pdf/2204.08515.pdf)
>  In this paper, we consider two multi-dimensional Hagselmann-Krause (HK) models for opinion dynamics. The two models describe how individuals adjust their opinions on multiple topics, based on the influence of their peers. The models differ in the criterion according to which individuals decide whom they want to be influenced from. In the average-based model, individuals compare their average opinions on the various topics with those of the other individuals and interact only with those individuals whose average opinions lie within a confidence interval. For this model, we provide an alternative proof for the contractivity of the range of opinions and show that the agents' opinions reach consensus/clustering if and only if their average opinions do so. In the uniform affinity model agents compare their opinions on every single topic and influence each other only if, topic-wise, such opinions do not differ more than a given tolerance. We identify conditions under which the uniform affinity model enjoys the order-preservation property topic-wise and we prove that the global range of opinions (and hence the range of opinions on every single topic) are nonincreasing.      
### 31.Enhancing Non-mass Breast Ultrasound Cancer Classification With Knowledge Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2204.08478.pdf)
>  Much progress has been made in the deep neural network (DNN) based diagnosis of mass lesions breast ultrasound (BUS) images. However, the non-mass lesion is less investigated because of the limited data. Based on the insight that mass data is sufficient and shares the same knowledge structure with non-mass data of identifying the malignancy of a lesion based on the ultrasound image, we propose a novel transfer learning framework to enhance the generalizability of the DNN model for non-mass BUS with the help of mass BUS. Specifically, we train a shared DNN with combined non-mass and mass data. With the prior of different marginal distributions in input and output space, we employ two domain alignment strategies in the proposed transfer learning framework with the insight of capturing domain-specific distribution to address the issue of domain shift. Moreover, we propose a cross-domain semantic-preserve data generation module called CrossMix to recover the missing distribution between non-mass and mass data that is not presented in training data. Experimental results on an in-house dataset demonstrate that the DNN model trained with combined data by our framework achieves a 10% improvement in AUC on the malignancy prediction task of non-mass BUS compared to training directly on non-mass data.      
### 32.Self Supervised Lesion Recognition For Breast Ultrasound Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2204.08477.pdf)
>  Previous deep learning based Computer Aided Diagnosis (CAD) system treats multiple views of the same lesion as independent images. Since an ultrasound image only describes a partial 2D projection of a 3D lesion, such paradigm ignores the semantic relationship between different views of a lesion, which is inconsistent with the traditional diagnosis where sonographers analyze a lesion from at least two views. In this paper, we propose a multi-task framework that complements Benign/Malignant classification task with lesion recognition (LR) which helps leveraging relationship among multiple views of a single lesion to learn a complete representation of the lesion. To be specific, LR task employs contrastive learning to encourage representation that pulls multiple views of the same lesion and repels those of different lesions. The task therefore facilitates a representation that is not only invariant to the view change of the lesion, but also capturing fine-grained features to distinguish between different lesions. Experiments show that the proposed multi-task framework boosts the performance of Benign/Malignant classification as two sub-tasks complement each other and enhance the learned representation of ultrasound images.      
### 33.U-Net and its variants for Medical Image Segmentation : A short review  [ :arrow_down: ](https://arxiv.org/pdf/2204.08470.pdf)
>  The paper is a short review of medical image segmentation using U-Net and its variants. As we understand going through a medical images is not an easy job for any clinician either radiologist or pathologist. Analysing medical images is the only way to perform non-invasive diagnosis. Segmenting out the regions of interest has significant importance in medical images and is key for diagnosis. This paper also gives a bird eye view of how medical image segmentation has evolved. Also discusses challenge's and success of the deep neural architectures. Following how different hybrid architectures have built upon strong techniques from visual recognition tasks. In the end we will see current challenges and future directions for medical image segmentation(MIS).      
### 34.IOP-FL: Inside-Outside Personalization for Federated Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2204.08467.pdf)
>  Federated learning (FL) allows multiple medical institutions to collaboratively learn a global model without centralizing all clients data. It is difficult, if possible at all, for such a global model to commonly achieve optimal performance for each individual client, due to the heterogeneity of medical data from various scanners and patient demographics. This problem becomes even more significant when deploying the global model to unseen clients outside the FL with new distributions not presented during federated training. To optimize the prediction accuracy of each individual client for critical medical tasks, we propose a novel unified framework for both Inside and Outside model Personalization in FL (IOP-FL). Our inside personalization is achieved by a lightweight gradient-based approach that exploits the local adapted model for each client, by accumulating both the global gradients for common knowledge and local gradients for client-specific optimization. Moreover, and importantly, the obtained local personalized models and the global model can form a diverse and informative routing space to personalize a new model for outside FL clients. Hence, we design a new test-time routing scheme inspired by the consistency loss with a shape constraint to dynamically incorporate the models, given the distribution information conveyed by the test data. Our extensive experimental results on two medical image segmentation tasks present significant improvements over SOTA methods on both inside and outside personalization, demonstrating the great potential of our IOP-FL scheme for clinical practice. Code will be released at <a class="link-external link-https" href="https://github.com/med-air/IOP-FL" rel="external noopener nofollow">this https URL</a>.      
### 35.Robust PCA Unrolling Network for Super-resolution Vessel Extraction in X-ray Coronary Angiography  [ :arrow_down: ](https://arxiv.org/pdf/2204.08466.pdf)
>  Although robust PCA has been increasingly adopted to extract vessels from X-ray coronary angiography (XCA) images, challenging problems such as inefficient vessel-sparsity modelling, noisy and dynamic background artefacts, and high computational cost still remain unsolved. Therefore, we propose a novel robust PCA unrolling network with sparse feature selection for super-resolution XCA vessel imaging. Being embedded within a patch-wise spatiotemporal super-resolution framework that is built upon a pooling layer and a convolutional long short-term memory network, the proposed network can not only gradually prune complex vessel-like artefacts and noisy backgrounds in XCA during network training but also iteratively learn and select the high-level spatiotemporal semantic information of moving contrast agents flowing in the XCA-imaged vessels. The experimental results show that the proposed method significantly outperforms state-of-the-art methods, especially in the imaging of the vessel network and its distal vessels, by restoring the intensity and geometry profiles of heterogeneous vessels against complex and dynamic backgrounds.      
### 36.CapillaryX: A Software Design Pattern for Analyzing Medical Images in Real-time using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.08462.pdf)
>  Recent advances in digital imaging, e.g., increased number of pixels captured, have meant that the volume of data to be processed and analyzed from these images has also increased. Deep learning algorithms are state-of-the-art for analyzing such images, given their high accuracy when trained with a large data volume of data. Nevertheless, such analysis requires considerable computational power, making such algorithms time- and resource-demanding. Such high demands can be met by using third-party cloud service providers. However, analyzing medical images using such services raises several legal and privacy challenges and does not necessarily provide real-time results. This paper provides a computing architecture that locally and in parallel can analyze medical images in real-time using deep learning thus avoiding the legal and privacy challenges stemming from uploading data to a third-party cloud provider. To make local image processing efficient on modern multi-core processors, we utilize parallel execution to offset the resource-intensive demands of deep neural networks. We focus on a specific medical-industrial case study, namely the quantifying of blood vessels in microcirculation images for which we have developed a working system. It is currently used in an industrial, clinical research setting as part of an e-health application. Our results show that our system is approximately 78% faster than its serial system counterpart and 12% faster than a master-slave parallel system architecture.      
### 37.Decentralized Control of Distributed Cloud Networks with Generalized Network Flows  [ :arrow_down: ](https://arxiv.org/pdf/2204.09030.pdf)
>  Emerging distributed cloud architectures, e.g., fog and mobile edge computing, are playing an increasingly important role in the efficient delivery of real-time stream-processing applications such as augmented reality, multiplayer gaming, and industrial automation. While such applications require processed streams to be shared and simultaneously consumed by multiple users/devices, existing technologies lack efficient mechanisms to deal with their inherent multicast nature, leading to unnecessary traffic redundancy and network congestion. In this paper, we establish a unified framework for distributed cloud network control with generalized (mixed-cast) traffic flows that allows optimizing the distributed execution of the required packet processing, forwarding, and replication operations. We first characterize the enlarged multicast network stability region under the new control framework (with respect to its unicast counterpart). We then design a novel queuing system that allows scheduling data packets according to their current destination sets, and leverage Lyapunov drift-plus-penalty theory to develop the first fully decentralized, throughput- and cost-optimal algorithm for multicast cloud network flow control. Numerical experiments validate analytical results and demonstrate the performance gain of the proposed design over existing cloud network control techniques.      
### 38.On the Locality of Attention in Direct Speech Translation  [ :arrow_down: ](https://arxiv.org/pdf/2204.09028.pdf)
>  Transformers have achieved state-of-the-art results across multiple NLP tasks. However, the self-attention mechanism complexity scales quadratically with the sequence length, creating an obstacle for tasks involving long sequences, like in the speech domain. In this paper, we discuss the usefulness of self-attention for Direct Speech Translation. First, we analyze the layer-wise token contributions in the self-attention of the encoder, unveiling local diagonal patterns. To prove that some attention weights are avoidable, we propose to substitute the standard self-attention with a local efficient one, setting the amount of context used based on the results of the analysis. With this approach, our model matches the baseline performance, and improves the efficiency by skipping the computation of those weights that standard attention discards.      
### 39.STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.08999.pdf)
>  Runtime verification or runtime monitoring equips safety-critical cyber-physical systems to augment design assurance measures and ensure operational safety and security. Cyber-physical systems have interaction failures, attack surfaces, and attack vectors resulting in unanticipated hazards and loss scenarios. These interaction failures pose challenges to runtime verification regarding monitoring specifications and monitoring placements for in-time detection of hazards. We develop a well-formed workflow model that connects system theoretic process analysis, commonly referred to as STPA, hazard causation information to lower-level runtime monitoring to detect hazards at the operational phase. Specifically, our model follows the DepDevOps paradigm to provide evidence and insights to runtime monitoring on what to monitor, where to monitor, and the monitoring context. We demonstrate and evaluate the value of multilevel monitors by injecting hazards on an autonomous emergency braking system model.      
### 40.Optimal Power Flow Schedules with Reduced Low-Frequency Oscillations  [ :arrow_down: ](https://arxiv.org/pdf/2204.08998.pdf)
>  The dynamic response of power grids to small events or persistent stochastic disturbances influences their stable operation. Low-frequency inter-area oscillations are of particular concern due to insufficient damping. This paper studies the effect of the operating point on the linear time-invariant dynamics of power networks. A pertinent metric based on the frequency response of grid dynamics is proposed to quantify power system's stability against inter-area oscillations. We further put forth an optimal power flow formulation to yield a grid dispatch that optimizes this novel stability metric. A semidefinite program (SDP) relaxation is employed to yield a computationally tractable convex problem. Numerical tests on the IEEE-39 bus system demonstrate that the SDP relaxation is exact yielding a rank-1 solution. The relative trade-off of the proposed small-signal stability metric versus the generation cost is also studied.      
### 41.Deep learning based closed-loop optimization of geothermal reservoir production  [ :arrow_down: ](https://arxiv.org/pdf/2204.08987.pdf)
>  To maximize the economic benefits of geothermal energy production, it is essential to optimize geothermal reservoir management strategies, in which geologic uncertainty should be considered. In this work, we propose a closed-loop optimization framework, based on deep learning surrogates, for the well control optimization of geothermal reservoirs. In this framework, we construct a hybrid convolution-recurrent neural network surrogate, which combines the convolution neural network (CNN) and long short-term memory (LSTM) recurrent network. The convolution structure can extract spatial information of geologic parameter fields and the recurrent structure can approximate sequence-to-sequence mapping. The trained model can predict time-varying production responses (rate, temperature, etc.) for cases with different permeability fields and well control sequences. In the closed-loop optimization framework, production optimization based on the differential evolution (DE) algorithm, and data assimilation based on the iterative ensemble smoother (IES), are performed alternately to achieve real-time well control optimization and geologic parameter estimation as the production proceeds. In addition, the averaged objective function over the ensemble of geologic parameter estimations is adopted to consider geologic uncertainty in the optimization process. Several geothermal reservoir development cases are designed to test the performance of the proposed production optimization framework. The results show that the proposed framework can achieve efficient and effective real-time optimization and data assimilation in the geothermal reservoir production process.      
### 42.Disappeared Command: Spoofing Attack On Automatic Speech Recognition Systems with Sound Masking  [ :arrow_down: ](https://arxiv.org/pdf/2204.08977.pdf)
>  The development of deep learning technology has greatly promoted the performance improvement of automatic speech recognition (ASR) technology, which has demonstrated an ability comparable to human hearing in many tasks. Voice interfaces are becoming more and more widely used as input for many applications and smart devices. However, existing research has shown that DNN is easily disturbed by slight disturbances and makes false recognition, which is extremely dangerous for intelligent voice applications controlled by voice.      
### 43.A comparison of different atmospheric turbulence simulation methods for image restoration  [ :arrow_down: ](https://arxiv.org/pdf/2204.08974.pdf)
>  Atmospheric turbulence deteriorates the quality of images captured by long-range imaging systems by introducing blur and geometric distortions to the captured scene. This leads to a drastic drop in performance when computer vision algorithms like object/face recognition and detection are performed on these images. In recent years, various deep learning-based atmospheric turbulence mitigation methods have been proposed in the literature. These methods are often trained using synthetically generated images and tested on real-world images. Hence, the performance of these restoration methods depends on the type of simulation used for training the network. In this paper, we systematically evaluate the effectiveness of various turbulence simulation methods on image restoration. In particular, we evaluate the performance of two state-or-the-art restoration networks using six simulations method on a real-world LRFID dataset consisting of face images degraded by turbulence. This paper will provide guidance to the researchers and practitioners working in this field to choose the suitable data generation models for training deep models for turbulence mitigation. The implementation codes for the simulation methods, source codes for the networks, and the pre-trained models will be publicly made available.      
### 44.Rendering Nighttime Image Via Cascaded Color and Brightness Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2204.08970.pdf)
>  Image signal processing (ISP) is crucial for camera imaging, and neural networks (NN) solutions are extensively deployed for daytime scenes. The lack of sufficient nighttime image dataset and insights on nighttime illumination characteristics poses a great challenge for high-quality rendering using existing NN ISPs. To tackle it, we first built a high-resolution nighttime RAW-RGB (NR2R) dataset with white balance and tone mapping annotated by expert professionals. Meanwhile, to best capture the characteristics of nighttime illumination light sources, we develop the CBUnet, a two-stage NN ISP to cascade the compensation of color and brightness attributes. Experiments show that our method has better visual quality compared to traditional ISP pipeline, and is ranked at the second place in the NTIRE 2022 Night Photography Rendering Challenge for two tracks by respective People's and Professional Photographer's choices. The code and relevant materials are avaiable on our website: <a class="link-external link-https" href="https://njuvision.github.io/CBUnet" rel="external noopener nofollow">this https URL</a>.      
### 45.When Is Partially Observable Reinforcement Learning Not Scary?  [ :arrow_down: ](https://arxiv.org/pdf/2204.08967.pdf)
>  Applications of Reinforcement Learning (RL), in which agents learn to make a sequence of decisions despite lacking complete information about the latent states of the controlled system, that is, they act under partial observability of the states, are ubiquitous. Partially observable RL can be notoriously difficult -- well-known information-theoretic results show that learning partially observable Markov decision processes (POMDPs) requires an exponential number of samples in the worst case. Yet, this does not rule out the existence of large subclasses of POMDPs over which learning is tractable. <br>In this paper we identify such a subclass, which we call weakly revealing POMDPs. This family rules out the pathological instances of POMDPs where observations are uninformative to a degree that makes learning hard. We prove that for weakly revealing POMDPs, a simple algorithm combining optimism and Maximum Likelihood Estimation (MLE) is sufficient to guarantee polynomial sample complexity. To the best of our knowledge, this is the first provably sample-efficient result for learning from interactions in overcomplete POMDPs, where the number of latent states can be larger than the number of observations.      
### 46.MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2204.08958.pdf)
>  No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual quality of images in accordance with human subjective perception. Unfortunately, existing NR-IQA methods are far from meeting the needs of predicting accurate quality scores on GAN-based distortion images. To this end, we propose Multi-dimension Attention Network for no-reference Image Quality Assessment (MANIQA) to improve the performance on GAN-based distortion. We firstly extract features via ViT, then to strengthen global and local interactions, we propose the Transposed Attention Block (TAB) and the Scale Swin Transformer Block (SSTB). These two modules apply attention mechanisms across the channel and spatial dimension, respectively. In this multi-dimensional manner, the modules cooperatively increase the interaction among different regions of images globally and locally. Finally, a dual branch structure for patch-weighted quality prediction is applied to predict the final score depending on the weight of each patch's score. Experimental results demonstrate that MANIQA outperforms state-of-the-art methods on four standard datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our method ranked first place in the final testing phase of the NTIRE 2022 Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and models are available at <a class="link-external link-https" href="https://github.com/IIGROUP/MANIQA" rel="external noopener nofollow">this https URL</a>.      
### 47.Deep learning-based surrogate model for 3-D patient-specific computational fluid dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2204.08939.pdf)
>  Optimization and uncertainty quantification have been playing an increasingly important role in computational hemodynamics. However, existing methods based on principled modeling and classic numerical techniques have faced significant challenges, particularly when it comes to complex 3D patient-specific shapes in the real world. First, it is notoriously challenging to parameterize the input space of arbitrarily complex 3-D geometries. Second, the process often involves massive forward simulations, which are extremely computationally demanding or even infeasible. We propose a novel deep learning surrogate modeling solution to address these challenges and enable rapid hemodynamic predictions. Specifically, a statistical generative model for 3-D patient-specific shapes is developed based on a small set of baseline patient-specific geometries. An unsupervised shape correspondence solution is used to enable geometric morphing and scalable shape synthesis statistically. Moreover, a simulation routine is developed for automatic data generation by automatic meshing, boundary setting, simulation, and post-processing. An efficient supervised learning solution is proposed to map the geometric inputs to the hemodynamics predictions in latent spaces. Numerical studies on aortic flows are conducted to demonstrate the effectiveness and merit of the proposed techniques.      
### 48.Electronic DC-SQUID Emulator  [ :arrow_down: ](https://arxiv.org/pdf/2204.08925.pdf)
>  Pulsed readout of Direct Current (DC) SUperconducting Quantum Interference Device (SQUID) is crucial for experiments which need to be performed at millikelvin temperatures, such as the readout of superconducting and electron spin based qubits. Pulsed readout algorithms used in these experiments are usually specific to the experimental setup and require some optimization. We present a circuit that emulates the behavior of a DC-SQUID in order to allow the development and evaluation of pulsed readout algorithms at room temperature without the need of a running dilution refrigerator. This novel circuit also constitutes a low cost device which can be used to teach the principles of a DC-SQUID in courses aimed at training the next generation of quantum engineers.      
### 49.Blockwise Streaming Transformer for Spoken Language Understanding and Simultaneous Speech Translation  [ :arrow_down: ](https://arxiv.org/pdf/2204.08920.pdf)
>  Although Transformers have gained success in several speech processing tasks like spoken language understanding (SLU) and speech translation (ST), achieving online processing while keeping competitive performance is still essential for real-world interaction. In this paper, we take the first step on streaming SLU and simultaneous ST using a blockwise streaming Transformer, which is based on contextual block processing and blockwise synchronous beam search. Furthermore, we design an automatic speech recognition (ASR)-based intermediate loss regularization for the streaming SLU task to improve the classification performance further. As for the simultaneous ST task, we propose a cross-lingual encoding method, which employs a CTC branch optimized with target language translations. In addition, the CTC translation output is also used to refine the search space with CTC prefix score, achieving joint CTC/attention simultaneous translation for the first time. Experiments for SLU are conducted on FSC and SLURP corpora, while the ST task is evaluated on Fisher-CallHome Spanish and MuST-C En-De corpora. Experimental results show that the blockwise streaming Transformer achieves competitive results compared to offline models, especially with our proposed methods that further yield a 2.4% accuracy gain on the SLU task and a 4.3 BLEU gain on the ST task over streaming baselines.      
### 50.Event-triggered Approximate Byzantine Consensus with Multi-hop Communication  [ :arrow_down: ](https://arxiv.org/pdf/2204.08883.pdf)
>  In this paper, we consider a resilient consensus problem for the multi-agent network where some of the agents are subject to Byzantine attacks and may transmit erroneous state values to their neighbors. In particular, we develop an event-triggered update rule to tackle this problem as well as reduce the communication for each agent. Our approach is based on the mean subsequence reduced (MSR) algorithm with agents being capable to communicate with multi-hop neighbors. Since delays are critical in such an environment, we provide necessary graph conditions for the proposed algorithm to perform well with delays in the communication. We highlight that through multi-hop communication, the network connectivity can be reduced especially in comparison with the common onehop communication case. Lastly, we show the effectiveness of the proposed algorithm by a numerical example.      
### 51.A Convolutional-Attentional Neural Framework for Structure-Aware Performance-Score Synchronization  [ :arrow_down: ](https://arxiv.org/pdf/2204.08822.pdf)
>  Performance-score synchronization is an integral task in signal processing, which entails generating an accurate mapping between an audio recording of a performance and the corresponding musical score. Traditional synchronization methods compute alignment using knowledge-driven and stochastic approaches, and are typically unable to generalize well to different domains and modalities. We present a novel data-driven method for structure-aware performance-score synchronization. We propose a convolutional-attentional architecture trained with a custom loss based on time-series divergence. We conduct experiments for the audio-to-MIDI and audio-to-image alignment tasks pertained to different score modalities. We validate the effectiveness of our method via ablation studies and comparisons with state-of-the-art alignment approaches. We demonstrate that our approach outperforms previous synchronization methods for a variety of test settings across score modalities and acoustic conditions. Our method is also robust to structural differences between the performance and score sequences, which is a common limitation of standard alignment approaches.      
### 52.UID2021: An Underwater Image Dataset for Evaluation of No-reference Quality Assessment Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2204.08813.pdf)
>  Achieving subjective and objective quality assessment of underwater images is of high significance in underwater visual perception and image/video processing. However, the development of underwater image quality assessment (UIQA) is limited for the lack of comprehensive human subjective user study with publicly available dataset and reliable objective UIQA metric. To address this issue, we establish a large-scale underwater image dataset, dubbed UID2021, for evaluating no-reference UIQA metrics. The constructed dataset contains 60 multiply degraded underwater images collected from various sources, covering six common underwater scenes (i.e. bluish scene, bluish-green scene, greenish scene, hazy scene, low-light scene, and turbid scene), and their corresponding 900 quality improved versions generated by employing fifteen state-of-the-art underwater image enhancement and restoration algorithms. Mean opinion scores (MOS) for UID2021 are also obtained by using the pair comparison sorting method with 52 observers. Both in-air NR-IQA and underwater-specific algorithms are tested on our constructed dataset to fairly compare the performance and analyze their strengths and weaknesses. Our proposed UID2021 dataset enables ones to evaluate NR UIQA algorithms comprehensively and paves the way for further research on UIQA. Our UID2021 will be a free download and utilized for research purposes at: <a class="link-external link-https" href="https://github.com/Hou-Guojia/UID2021" rel="external noopener nofollow">this https URL</a>.      
### 53.Decentralized non-convex optimization via bi-level SQP and ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2204.08786.pdf)
>  Non-convex optimization problems arise in many problems of practical relevance-for example in distributed nonlinear MPC or distributed optimal power flow. Only few existing decentralized optimization methods have local convergence guarantees for general nonconvex problems. We present novel convergence results for non-convex problems for a bi-level SQP method that solves the inner quadratic problems via ADMM. A decentralized stopping criterion borrowed from inexact Newton methods allows the early termination of ADMM as an inner algorithm to improve computational efficiency. The method shows competitive numerical performance to existing methods for an optimal power flow problem.      
### 54.Incorporating Semi-Supervised and Positive-Unlabeled Learning for Boosting Full Reference Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2204.08763.pdf)
>  Full-reference (FR) image quality assessment (IQA) evaluates the visual quality of a distorted image by measuring its perceptual difference with pristine-quality reference, and has been widely used in low-level vision tasks. Pairwise labeled data with mean opinion score (MOS) are required in training FR-IQA model, but is time-consuming and cumbersome to collect. In contrast, unlabeled data can be easily collected from an image degradation or restoration process, making it encouraging to exploit unlabeled training data to boost FR-IQA performance. Moreover, due to the distribution inconsistency between labeled and unlabeled data, outliers may occur in unlabeled data, further increasing the training difficulty. In this paper, we suggest to incorporate semi-supervised and positive-unlabeled (PU) learning for exploiting unlabeled data while mitigating the adverse effect of outliers. Particularly, by treating all labeled data as positive samples, PU learning is leveraged to identify negative samples (i.e., outliers) from unlabeled data. Semi-supervised learning (SSL) is further deployed to exploit positive unlabeled data by dynamically generating pseudo-MOS. We adopt a dual-branch network including reference and distortion branches. Furthermore, spatial attention is introduced in the reference branch to concentrate more on the informative regions, and sliced Wasserstein distance is used for robust difference map computation to address the misalignment issues caused by images recovered by GAN models. Extensive experiments show that our method performs favorably against state-of-the-arts on the benchmark datasets PIPAL, KADID-10k, TID2013, LIVE and CSIQ.      
### 55.Edge-enhanced Feature Distillation Network for Efficient Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2204.08759.pdf)
>  With the recently massive development in convolution neural networks, numerous lightweight CNN-based image super-resolution methods have been proposed for practical deployments on edge devices. However, most existing methods focus on one specific aspect: network or loss design, which leads to the difficulty of minimizing the model size. To address the issue, we conclude block devising, architecture searching, and loss design to obtain a more efficient SR structure. In this paper, we proposed an edge-enhanced feature distillation network, named EFDN, to preserve the high-frequency information under constrained resources. In detail, we build an edge-enhanced convolution block based on the existing reparameterization methods. Meanwhile, we propose edge-enhanced gradient loss to calibrate the reparameterized path training. Experimental results show that our edge-enhanced strategies preserve the edge and significantly improve the final restoration quality. Code is available at <a class="link-external link-https" href="https://github.com/icandle/EFDN" rel="external noopener nofollow">this https URL</a>.      
### 56.A Thin Format Vision-Based Tactile Sensor with A Micro Lens Array (MLA)  [ :arrow_down: ](https://arxiv.org/pdf/2204.08691.pdf)
>  Vision-based tactile sensors have been widely studied in the robotics field for high spatial resolution and compatibility with machine learning algorithms. However, the currently employed sensor's imaging system is bulky limiting its further application. Here we present a micro lens array (MLA) based vison system to achieve a low thickness format of the sensor package with high tactile sensing performance. Multiple micromachined micro lens units cover the whole elastic touching layer and provide a stitched clear tactile image, enabling high spatial resolution with a thin thickness of 5 mm. The thermal reflow and soft lithography method ensure the uniform spherical profile and smooth surface of micro lens. Both optical and mechanical characterization demonstrated the sensor's stable imaging and excellent tactile sensing, enabling precise 3D tactile information, such as displacement mapping and force distribution with an ultra compact-thin structure.      
### 57.Audio-Visual Wake Word Spotting System For MISP Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2204.08686.pdf)
>  This paper presents the details of our system designed for the Task 1 of Multimodal Information Based Speech Processing (MISP) Challenge 2021. The purpose of Task 1 is to leverage both audio and video information to improve the environmental robustness of far-field wake word spotting. In the proposed system, firstly, we take advantage of speech enhancement algorithms such as beamforming and weighted prediction error (WPE) to address the multi-microphone conversational audio. Secondly, several data augmentation techniques are applied to simulate a more realistic far-field scenario. For the video information, the provided region of interest (ROI) is used to obtain visual representation. Then the multi-layer CNN is proposed to learn audio and visual representations, and these representations are fed into our two-branch attention-based network which can be employed for fusion, such as transformer and conformed. The focal loss is used to fine-tune the model and improve the performance significantly. Finally, multiple trained models are integrated by casting vote to achieve our final 0.091 score.      
### 58.Detection Interval for Diffusion Molecular Communication: How Long is Enough?  [ :arrow_down: ](https://arxiv.org/pdf/2204.08636.pdf)
>  Molecular communication has a key role to play in future medical applications, including detecting, analyzing, and addressing infectious disease outbreaks. Overcoming inter-symbol interference (ISI) is one of the key challenges in the design of molecular communication systems. In this paper, we propose to optimize the detection interval to minimize the impact of ISI while ensuring the accurate detection of the transmitted information symbol, which is suitable for the absorbing and passive receivers. For tractability, based on the signal-to-interference difference (SID) and signal-to-interference-and-noise amplitude ratio (SINAR), we propose a modified-SINAR (mSINAR) to measure the bit error rate (BER) performance for the molecular communication system with a variable detection interval. Besides, we derive the optimal detection interval in closed form. Using simulation results, we show that the BER performance of our proposed mSINAR scheme is superior to the competing schemes, and achieves similar performance to optimal intervals found by the exhaustive search.      
### 59.Quaternion Optimized Model with Sparse Regularization for Color Image Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2204.08629.pdf)
>  This paper addresses the color image completion problem in accordance with low-rank quatenrion matrix optimization that is characterized by sparse regularization in a transformed domain. This research was inspired by an appreciation of the fact that different signal types, including audio formats and images, possess structures that are inherently sparse in respect of their respective bases. Since color images can be processed as a whole in the quaternion domain, we depicted the sparsity of the color image in the quaternion discrete cosine transform (QDCT) domain. In addition, the representation of a low-rank structure that is intrinsic to the color image is a vital issue in the quaternion matrix completion problem. To achieve a more superior low-rank approximation, the quatenrion-based truncated nuclear norm (QTNN) is employed in the proposed model. Moreover, this model is facilitated by a competent alternating direction method of multipliers (ADMM) based on the algorithm. Extensive experimental results demonstrate that the proposed method can yield vastly superior completion performance in comparison with the state-of-the-art low-rank matrix/quaternion matrix approximation methods tested on color image recovery.      
### 60.Self Supervised Adversarial Domain Adaptation for Cross-Corpus and Cross-Language Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.08625.pdf)
>  Despite the recent advancement in speech emotion recognition (SER) within a single corpus setting, the performance of these SER systems degrades significantly for cross-corpus and cross-language scenarios. The key reason is the lack of generalisation in SER systems towards unseen conditions, which causes them to perform poorly in cross-corpus and cross-language settings. Recent studies focus on utilising adversarial methods to learn domain generalised representation for improving cross-corpus and cross-language SER to address this issue. However, many of these methods only focus on cross-corpus SER without addressing the cross-language SER performance degradation due to a larger domain gap between source and target language data. This contribution proposes an adversarial dual discriminator (ADDi) network that uses the three-players adversarial game to learn generalised representations without requiring any target data labels. We also introduce a self-supervised ADDi (sADDi) network that utilises self-supervised pre-training with unlabelled data. We propose synthetic data generation as a pretext task in sADDi, enabling the network to produce emotionally discriminative and domain invariant representations and providing complementary synthetic data to augment the system. The proposed model is rigorously evaluated using five publicly available datasets in three languages and compared with multiple studies on cross-corpus and cross-language SER. Experimental results demonstrate that the proposed model achieves improved performance compared to the state-of-the-art methods.      
### 61.Automated Audio Captioning using Audio Event Clues  [ :arrow_down: ](https://arxiv.org/pdf/2204.08567.pdf)
>  Audio captioning is an important research area that aims to generate meaningful descriptions for audio clips. Most of the existing research extracts acoustic features of audio clips as input to encoder-decoder and transformer architectures to produce the captions in a sequence-to-sequence manner. Due to data insufficiency and the architecture's inadequate learning capacity, additional information is needed to generate natural language sentences, as well as acoustic features. To address these problems, an encoder-decoder architecture is proposed that learns from both acoustic features and extracted audio event labels as inputs. The proposed model is based on pre-trained acoustic features and audio event detection. Various experiments used different acoustic features, word embedding models, audio event label extraction methods, and implementation configurations to show which combinations have better performance on the audio captioning task. Results of the extensive experiments on multiple datasets show that using audio event labels with the acoustic features improves the recognition performance and the proposed method either outperforms or achieves competitive results with the state-of-the-art models.      
### 62.State-Output Risk-Constrained Quadratic Control of Partially Observed Linear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.08548.pdf)
>  We propose a methodology for performing risk-averse quadratic regulation of partially observed Linear Time-Invariant (LTI) systems disturbed by process and output noise. To compensate against the induced variability due to both types of noises, state regulation is subject to two risk constraints. The latter renders the resulting controller cautious of stochastic disturbances, by restricting the statistical variability, namely, a simplified version of the cumulative expected predictive variance of both the state and the output. Our proposed formulation results in an optimal risk-averse policy that preserves favorable characteristics of the classical Linear Quadratic (LQ) control. In particular, the optimal policy has an affine structure with respect to the minimum mean square error (mmse) estimates. The linear component of the policy regulates the state more strictly in riskier directions, where the process and output noise covariance, cross-covariance, and the corresponding penalties are simultaneously large. This is achieved by "inflating" the state penalty in a systematic way. The additional affine terms force the state against pure and cross third-order statistics of the process and output disturbances. Another favorable characteristic of our optimal policy is that it can be pre-computed off-line, thus, avoiding limitations of prior work. Stability analysis shows that the derived controller is always internally stable regardless of parameter tuning. The functionality of the proposed risk-averse policy is illustrated through a working example via extensive numerical simulations.      
### 63.Designing an AI-Based Adaptive Controller Augmented with a System Identifier for a Micro-Class Robot Equipped with a Vibrating Actuator  [ :arrow_down: ](https://arxiv.org/pdf/2204.08541.pdf)
>  In this paper, an adaptive control scheme based on using neural networks is designed to guarantee the desired behavior of a micro-robot which is equipped with vibrating actuators and follows the principle of slip-stick movement. There are two tiny shaking motors which have been utilized to run the micro-class robotic system. Dynamic modeling equations are expressed by considering the spring coefficient of the bases. After that, the effect of the spring on the foundations was investigated. In addition to designing neural-based controller, an AI-based system identifier has been developed to help the controller update its parameters and achieve its desired targets. Using this method, several specific paths for the movement of this micro robot are simulated. Based on the simulation results, the proposed controlling strategy guarantees acceptable performance for tracking different paths due to plotted near-zero errors and handles the nonlinear behavior of the micro-robot system.      
### 64.AB/BA analysis: A framework for estimating keyword spotting recall improvement while maintaining audio privacy  [ :arrow_down: ](https://arxiv.org/pdf/2204.08474.pdf)
>  Evaluation of keyword spotting (KWS) systems that detect keywords in speech is a challenging task under realistic privacy constraints. The KWS is designed to only collect data when the keyword is present, limiting the availability of hard samples that may contain false negatives, and preventing direct estimation of model recall from production data. Alternatively, complementary data collected from other sources may not be fully representative of the real application. In this work, we propose an evaluation technique which we call AB/BA analysis. Our framework evaluates a candidate KWS model B against a baseline model A, using cross-dataset offline decoding for relative recall estimation, without requiring negative examples. Moreover, we propose a formulation with assumptions that allow estimation of relative false positive rate between models with low variance even when the number of false positives is small. Finally, we propose to leverage machine-generated soft labels, in a technique we call Semi-Supervised AB/BA analysis, that improves the analysis time, privacy, and cost. Experiments with both simulation and real data show that AB/BA analysis is successful at measuring recall improvement in conjunction with the trade-off in relative false positive rate.      
### 65.Machine Learning-Based Automated Thermal Comfort Prediction: Integration of Low-Cost Thermal and Visual Cameras for Higher Accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2204.08463.pdf)
>  Recent research is trying to leverage occupants' demand in the building's control loop to consider individuals' well-being and the buildings' energy savings. To that end, a real-time feedback system is needed to provide data about occupants' comfort conditions that can be used to control the building's heating, cooling, and air conditioning (HVAC) system. The emergence of thermal imaging techniques provides an excellent opportunity for contactless data gathering with no interruption in occupant conditions and activities. There is increasing attention to infrared thermal camera usage in public buildings because of their non-invasive quality in reading the human skin temperature. However, the state-of-the-art methods need additional modifications to become more reliable. To capitalize potentials and address some existing limitations, new solutions are required to bring a more holistic view toward non-intrusive thermal scanning by leveraging the benefit of machine learning and image processing. This research implements an automated approach to collect and register simultaneous thermal and visual images and read the facial temperature in different regions. This paper also presents two additional investigations. First, through utilizing IButton wearable thermal sensors on the forehead area, we investigate the reliability of an in-expensive thermal camera (FLIR Lepton) in reading the skin temperature. Second, by studying the false-color version of thermal images, we look into the possibility of non-radiometric thermal images for predicting personalized thermal comfort. The results shows the strong performance of Random Forest and K-Nearest Neighbor prediction algorithms in predicting personalized thermal comfort. In addition, we have found that non-radiometric images can also indicate thermal comfort when the algorithm is trained with larger amounts of data.      
### 66.3D Convolutional Networks for Action Recognition: Application to Sport Gesture Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2204.08460.pdf)
>  3D convolutional networks is a good means to perform tasks such as video segmentation into coherent spatio-temporal chunks and classification of them with regard to a target taxonomy. In the chapter we are interested in the classification of continuous video takes with repeatable actions, such as strokes of table tennis. Filmed in a free marker less ecological environment, these videos represent a challenge from both segmentation and classification point of view. The 3D convnets are an efficient tool for solving these problems with window-based approaches.      
