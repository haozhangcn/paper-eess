# ArXiv eess --Fri, 15 Apr 2022
### 1.MIMO Channel Estimation using Score-Based Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2204.07122.pdf)
>  Channel estimation is a critical task in multiple-input multiple-output digital communications that has effects on end-to-end system performance. In this work, we introduce a novel approach for channel estimation using deep score-based generative models. These models are trained to estimate the gradient of the log-prior distribution, and can be used to iteratively refine estimates, given observed measurements of a signal. We introduce a framework for training score-based generative models for wireless channels, as well as performing channel estimation using posterior sampling at test time. We derive theoretical robustness guarantees of channel estimation with posterior sampling in single-input single-output scenarios, and show that the observations regarding estimation performance are verified experimentally in MIMO channels. Our results in simulated clustered delay line channels show competitive in-distribution performance without error floors in the high signal-to-noise ratio regime, and robust out-of-distribution performance, outperforming competing deep learning methods by up to 5 dB in end-to-end communication performance, while the complexity analysis reveals how model architecture can efficiently trade performance for estimation latency.      
### 2.RadioSES: mmWave-Based Audioradio Speech Enhancement and Separation System  [ :arrow_down: ](https://arxiv.org/pdf/2204.07092.pdf)
>  Speech enhancement and separation have been a long-standing problem, especially with the recent advances using a single microphone. Although microphones perform well in constrained settings, their performance for speech separation decreases in noisy conditions. In this work, we propose RadioSES, an audioradio speech enhancement and separation system that overcomes inherent problems in audio-only systems. By fusing a complementary radio modality, RadioSES can estimate the number of speakers, solve source association problem, separate and enhance noisy mixture speeches, and improve both intelligibility and perceptual quality. We perform millimeter-wave sensing to detect and localize speakers, and introduce an audioradio deep learning framework to fuse the separate radio features with the mixed audio features. Extensive experiments using commercial off-the-shelf devices show that RadioSES outperforms a variety of state-of-the-art baselines, with consistent performance gains in different environmental settings. Compared with the audiovisual methods, RadioSES provides similar improvements (e.g., ~3 dB gains in SiSDR), along with the benefits of lower computational complexity and being less privacy concerning.      
### 3.End-to-end Learning for Joint Depth and Image Reconstruction from Diffracted Rotation  [ :arrow_down: ](https://arxiv.org/pdf/2204.07076.pdf)
>  Monocular depth estimation is still an open challenge due to the ill-posed nature of the problem at hand. Deep learning based techniques have been extensively studied and proved capable of producing acceptable depth estimation accuracy even if the lack of meaningful and robust depth cues within single RGB input images severally limits their performance. Coded aperture-based methods using phase and amplitude masks encode strong depth cues within 2D images by means of depth-dependent Point Spread Functions (PSFs) at the price of a reduced image quality. In this paper, we propose a novel end-to-end learning approach for depth from diffracted rotation. A phase mask that produces a Rotating Point Spread Function (RPSF) as a function of defocus is jointly optimized with the weights of a depth estimation neural network. To this aim, we introduce a differentiable physical model of the aperture mask and exploit an accurate simulation of the camera imaging pipeline. Our approach requires a significantly less complex model and less training data, yet it is superior to existing methods in the task of monocular depth estimation on indoor benchmarks. In addition, we address the problem of image degradation by incorporating a non-blind and non-uniform image deblurring module to recover the sharp all-in-focus image from its RPSF-blurred counterpart.      
### 4.Uncertainty Principles for the Short-time Free Metaplectic Transform  [ :arrow_down: ](https://arxiv.org/pdf/2204.07048.pdf)
>  The free metaplectic transformation (FMT) has gained much popularity in recent times because of its various application in signal processing, paraxial optical systems, digital algorithms, optical encryption and so on. However, the FMT is inadequate for localized analysis of non-transient signals, as such, it is imperative to introduce a unique localized transform coined as the short time free metaplectic transform (STFMT). In this paper, we investigate the STFMT. Firstly, we propose the definition of the STFMT, and provide the time frequency analysis of the proposed transform in the FMT domain. Secondly, we investigate the basic properties of the proposed transform including the reconstruction formula, Moyals formula. The emergence of the STFMT definition and its properties broadens the development of time-frequency representation of higher-dimensional signals theory to a certain extent. Finally, we extend some different uncertainty principles (UP) from quantum mechanics including Liebs, Pitts UP, Heisenbergs uncertainty principle, Hausdorff-Young, Hardys UP, Beurlings UP, Logarithmic UP, and Nazarovs UP which have already been well studied in the FMT domain      
### 5.Ensemble learning using individual neonatal data for seizure detection  [ :arrow_down: ](https://arxiv.org/pdf/2204.07043.pdf)
>  Sharing medical data between institutions is difficult in practice due to data protection laws and official procedures within institutions. Therefore, most existing algorithms are trained on relatively small electroencephalogram (EEG) data sets which is likely to be detrimental to prediction accuracy. In this work, we simulate a case when the data can not be shared by splitting the publicly available data set into disjoint sets representing data in individual institutions. We propose to train a (local) detector in each institution and aggregate their individual predictions into one final prediction. Four aggregation schemes are compared, namely, the majority vote, the mean, the weighted mean and the Dawid-Skene method. The approach allows different detector architectures amongst the institutions. The method was validated on an independent data set using only a subset of EEG channels. The ensemble reaches accuracy comparable to a single detector trained on all the data when sufficient amount of data is available in each institution. The weighted mean aggregation scheme showed best overall performance, it was only marginally outperformed by the Dawid-Skene method when local detectors approach performance of a single detector trained on all available data.      
### 6.Distributed Optimal Control with Recovered Robustness for Uncertain Network Systems: A Complementary Design Approach  [ :arrow_down: ](https://arxiv.org/pdf/2204.07041.pdf)
>  This paper considers the distributed robust suboptimal consensus control problem of linear multi-agent systems, with both H2 and H_infty performance requirements. A novel two-step complementary design approach is proposed. In the first step, a distributed control law is designed for the nominal multi-agent system to achieve consensus with a prescribed H2 performance. In the second step, an extra control input, depending on some carefully chosen residual signals indicating the modeling mismatch, is designed to complement the H2 performance by providing robustness guarantee in terms of H_infty requirement with respect to disturbances or uncertainties. The proposed complementary design approach provides an additional degree of freedom for design, having two separate controls to deal with the H2 performance and the robustness of consensus, respectively. Thereby, it does not need to make much trade-off, and can be expected to be much less conservative than the trade-off design such as the mixed H2/H_infty control method. Besides, this complementary approach will recover the achievable H2 performance when external disturbances or uncertainties do not exist. The effectiveness of the theoretical results and the advantages of the complementary approach are validated via numerical simulations.      
### 7.LDPC codes: tracking non-stationary channel noise using sequential variational Bayesian estimates  [ :arrow_down: ](https://arxiv.org/pdf/2204.07037.pdf)
>  We present a sequential Bayesian learning method for tracking non-stationary signal-to-noise ratios in LDPC codes using probabilistic graphical models. We represent the LDPC code as a cluster graph using a general purpose cluster graph construction algorithm called the layered trees running intersection property (LTRIP) algorithm. The channel noise estimator is a global Gamma cluster, which we extend to allow for Bayesian tracking of non-stationary noise variation. We evaluate our proposed model on real-world 5G drive test data. Our results show that our model is capable of tracking non-stationary channel noise, which outperforms an LDPC code with a fixed knowledge of the actual average channel noise.      
### 8.Short-wavelength Reverberant Wave Systems for Physical Realization of Reservoir Computing  [ :arrow_down: ](https://arxiv.org/pdf/2204.07036.pdf)
>  Machine learning (ML) has found widespread application over a broad range of important tasks. To enhance ML performance, researchers have investigated computational architectures whose physical implementations promise compactness, high-speed execution, physical robustness, and low energy cost. Here, we experimentally demonstrate an approach that uses the high sensitivity of reverberant short wavelength waves for physical realization and enhancement of computational power of a type of ML known as reservoir computing (RC). The potential computation power of RC systems increases with their effective size. We here exploit the intrinsic property of short wavelength reverberant wave sensitivity to perturbations to expand the effective size of the RC system by means of spatial and spectral perturbations. Working in the microwave regime, this scheme is tested experimentally on different ML tasks. Our results indicate the general applicability of reverberant wave-based implementations of RC and of our effective reservoir size expansion technique      
### 9.Epileptic Seizure Risk Assessment by Multi-Channel Imaging of the EEG  [ :arrow_down: ](https://arxiv.org/pdf/2204.07034.pdf)
>  Refractory epileptic patients can suffer a seizure at any moment. Seizure prediction would substantially improve their lives. In this work, based on scalp EEG and its transformation into images, the likelihood of an epileptic seizure occurring at any moment is computed using an average of the softmax layer output (the likelihood) of a CNN, instead of the output of the classification layer. Results show that by analyzing the likelihood and thresholding it, prediction has higher sensitivity or a lower FPR/h. The best threshold for the likelihood was higher than 50% for 5 patients, and was lower for the remaining 36. However, more testing is needed, especially in new seizures, to better assess the real performance of this method. This work is a proof of concept with a positive outlook.      
### 10.Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma  [ :arrow_down: ](https://arxiv.org/pdf/2204.07004.pdf)
>  Purpose: (1) To assess the performance of geometric deep learning (PointNet) in diagnosing glaucoma from a single optical coherence tomography (OCT) 3D scan of the optic nerve head (ONH); (2) To compare its performance to that obtained with a standard 3D convolutional neural network (CNN), and with a gold-standard glaucoma parameter, i.e. retinal nerve fiber layer (RNFL) thickness. <br>Methods: 3D raster scans of the ONH were acquired with Spectralis OCT for 477 glaucoma and 2,296 non-glaucoma subjects at the Singapore National Eye Centre. All volumes were automatically segmented using deep learning to identify 7 major neural and connective tissues including the RNFL, the prelamina, and the lamina cribrosa (LC). Each ONH was then represented as a 3D point cloud with 1,000 points chosen randomly from all tissue boundaries. To simplify the problem, all ONH point clouds were aligned with respect to the plane and center of Bruch's membrane opening. Geometric deep learning (PointNet) was then used to provide a glaucoma diagnosis from a single OCT point cloud. The performance of our approach was compared to that obtained with a 3D CNN, and with RNFL thickness. <br>Results: PointNet was able to provide a robust glaucoma diagnosis solely from the ONH represented as a 3D point cloud (AUC=95%). The performance of PointNet was superior to that obtained with a standard 3D CNN (AUC=87%) and with that obtained from RNFL thickness alone (AUC=80%). <br>Discussion: We provide a proof-of-principle for the application of geometric deep learning in the field of glaucoma. Our technique requires significantly less information as input to perform better than a 3D CNN, and with an AUC superior to that obtained from RNFL thickness alone. Geometric deep learning may have wide applicability in the field of Ophthalmology.      
### 11.A Machine Learning Approach to Automatic Classification of Eight Sleep Disorders  [ :arrow_down: ](https://arxiv.org/pdf/2204.06997.pdf)
>  In this research, we attempt to answer the following basic research questions: Is a machine learning model able to classify all types of sleep disorders with high accuracy? Among the different modalities of sleep disorder signals, are some more important than others? Do raw signals improve the performance of a deep learning model when they are used as inputs? Prior research showed that most sleep disorders belong to eight categories. To study the performance of machine learning models in classifying polysomnography recordings into the eight categories of sleep pathologies, we selected the Cyclic Alternating Pattern Sleep Database. We developed a multi-channel Deep Learning model where a set of Convolutional Neural Networks were applied to six channels of raw signals of different modalities, including three channels of EEG signals and one channel each of EMG, ECG , and EOG signals. To compare the performance of the DL model with other models, we designed a model that took spectral features, instead of raw signals, as its inputs. We first studied the "importance" issue of signal modalities using the RF algorithm. We found that ECG contributed most to the important features and EMG second, among the four signal modalities. We then studied the accuracy performance of the proposed machine learning models. We verified that the multi-channel DL-R model, which took raw signals as its inputs, outperformed all other models, with its sensitivity and specificity scores both being above 95 %. This accuracy performance is on a par with those published results which dealt with fewer types of sleep disorders. We adopted two popular heatmap-generating techniques, with which we confirmed that the DL model's superior performance was owing to the CNN network's ability to extract potent features from raw signals.      
### 12.Optimal Myopic Attacks on Nonlinear Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.06996.pdf)
>  Recent high-profile incidents have exposed security risks in control systems. Particularly important and safety-critical modules for security analysis are estimation and control (E&amp;C). Prior works have analyzed the security of E&amp;C for linear, time-invariant systems; however, there are few analyses of nonlinear systems despite their broad use. In an effort to facilitate identifying vulnerabilities in control systems, in this work we establish a class of optimal attacks on nonlinear E&amp;C. Specifically, we define two attack objectives and illustrate that realizing the optimal attacks against the widely-adopted extended Kalman filter with industry-standard anomaly detection is equivalent to solving convex quadratically-constrained quadratic programs. Given an appropriate information model for the attacker (i.e., a specified amount of attacker knowledge), we provide practical relaxations on the optimal attacks to allow for their computation at runtime. We also show that the difference between the optimal and relaxed attacks is bounded. Finally, we illustrate the use of the introduced attack designs on a case-study.      
### 13.LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections  [ :arrow_down: ](https://arxiv.org/pdf/2204.06955.pdf)
>  Accurate segmentation of medical images is essential for diagnosis and treatment of diseases. These problems are solved by highly complex models, such as deep networks (DN), requiring a large amount of labeled data for training. Thereby, many DNs possess task- or imaging modality specific architectures with a decision-making process that is often hard to explain and interpret. Here, we propose a framework that embeds existing DNs into a low-dimensional subspace induced by the learnable explicit feature map (LEFM) layer. Compared to the existing DN, the framework adds one hyperparameter and only modestly increase the number of learnable parameters. The method is aimed at, but not limited to, segmentation of low-dimensional medical images, such as color histopathological images of stained frozen sections. Since features in the LEFM layer are polynomial functions of the original features, proposed LEFM-Nets contribute to the interpretability of network decisions. In this work, we combined LEFM with the known networks: DeepLabv3+, UNet, UNet++ and MA-net. New LEFM-Nets are applied to the segmentation of adenocarcinoma of a colon in a liver from images of hematoxylin and eosin (H&amp;E) stained frozen sections. LEFM-Nets are also tested on nuclei segmentation from images of H&amp;E stained frozen sections of ten human organs. On the first problem, LEFM-Nets achieved statistically significant performance improvement in terms of micro balanced accuracy and $F_1$ score than original networks. LEFM-Nets achieved only better performance in comparison with the original networks on the second problem. The source code is available at <a class="link-external link-https" href="https://github.com/dsitnik/lefm" rel="external noopener nofollow">this https URL</a>.      
### 14.Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2204.06931.pdf)
>  Purpose: The optic nerve head (ONH) undergoes complex and deep 3D morphological changes during the development and progression of glaucoma. Optical coherence tomography (OCT) is the current gold standard to visualize and quantify these changes, however the resulting 3D deep-tissue information has not yet been fully exploited for the diagnosis and prognosis of glaucoma. To this end, we aimed: (1) To compare the performance of two relatively recent geometric deep learning techniques in diagnosing glaucoma from a single OCT scan of the ONH; and (2) To identify the 3D structural features of the ONH that are critical for the diagnosis of glaucoma. <br>Methods: In this study, we included a total of 2,247 non-glaucoma and 2,259 glaucoma scans from 1,725 subjects. All subjects had their ONHs imaged in 3D with Spectralis OCT. All OCT scans were automatically segmented using deep learning to identify major neural and connective tissues. Each ONH was then represented as a 3D point cloud. We used PointNet and dynamic graph convolutional neural network (DGCNN) to diagnose glaucoma from such 3D ONH point clouds and to identify the critical 3D structural features of the ONH for glaucoma diagnosis. <br>Results: Both the DGCNN (AUC: 0.97$\pm$0.01) and PointNet (AUC: 0.95$\pm$0.02) were able to accurately detect glaucoma from 3D ONH point clouds. The critical points formed an hourglass pattern with most of them located in the inferior and superior quadrant of the ONH. <br>Discussion: The diagnostic accuracy of both geometric deep learning approaches was excellent. Moreover, we were able to identify the critical 3D structural features of the ONH for glaucoma diagnosis that tremendously improved the transparency and interpretability of our method. Consequently, our approach may have strong potential to be used in clinical applications for the diagnosis and prognosis of a wide range of ophthalmic disorders.      
### 15.Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2204.06929.pdf)
>  Ultrasound (US) imaging is widely used for anatomical structure inspection in clinical diagnosis. The training of new sonographers and deep learning based algorithms for US image analysis usually requires a large amount of data. However, obtaining and labeling large-scale US imaging data are not easy tasks, especially for diseases with low incidence. Realistic US image synthesis can alleviate this problem to a great extent. In this paper, we propose a generative adversarial network (GAN) based image synthesis framework. Our main contributions include: 1) we present the first work that can synthesize realistic B-mode US images with high-resolution and customized texture editing features; 2) to enhance structural details of generated images, we propose to introduce auxiliary sketch guidance into a conditional GAN. We superpose the edge sketch onto the object mask and use the composite mask as the network input; 3) to generate high-resolution US images, we adopt a progressive training strategy to gradually generate high-resolution images from low-resolution images. In addition, a feature loss is proposed to minimize the difference of high-level features between the generated and real images, which further improves the quality of generated images; 4) the proposed US image synthesis method is quite universal and can also be generalized to the US images of other anatomical structures besides the three ones tested in our study (lung, hip joint, and ovary); 5) extensive experiments on three large US image datasets are conducted to validate our method. Ablation studies, customized texture editing, user studies, and segmentation tests demonstrate promising results of our method in synthesizing realistic US images.      
### 16.Gamma Correction in Holographic Projection  [ :arrow_down: ](https://arxiv.org/pdf/2204.06913.pdf)
>  In a computer-generated holographic projection system, the image is generated via diffraction of light from spatial light modulators. In this process, several factors contribute to non-linearities between the replay field and the target image. This article evaluates the gamma response of the overall system experimentally, and then applies a gamma correction method, with the aim of increasing the image quality of a holographic projection system. Both a notable increase in replay field quality alongside a significant reduction in mean squared error were observed, demonstrating the effectiveness of gamma correction in holographic projection.      
### 17.Lombard Effect for Bilingual Speakers in Cantonese and English: importance of spectro-temporal features  [ :arrow_down: ](https://arxiv.org/pdf/2204.06907.pdf)
>  For a better understanding of the mechanisms underlying speech perception and the contribution of different signal features, computational models of speech recognition have a long tradition in hearing research. Due to the diverse range of situations in which speech needs to be recognized, these models need to be generalizable across many acoustic conditions, speakers, and languages. This contribution examines the importance of different features for speech recognition predictions of plain and Lombard speech for English in comparison to Cantonese in stationary and modulated noise. While Cantonese is a tonal language that encodes information in spectro-temporal features, the Lombard effect is known to be associated with spectral changes in the speech signal. These contrasting properties of tonal languages and the Lombard effect form an interesting basis for the assessment of speech recognition models. Here, an automatic speech recognition-based ASR model using spectral or spectro-temporal features is evaluated with empirical data. The results indicate that spectro-temporal features are crucial in order to predict the speaker-specific speech recognition threshold SRT$_{50}$ in both Cantonese and English as well as to account for the improvement of speech recognition in modulated noise, while effects due to Lombard speech can already be predicted by spectral features.      
### 18.Formal Development of Safe Automated Driving using Differential Dynamic Logic  [ :arrow_down: ](https://arxiv.org/pdf/2204.06873.pdf)
>  The challenges in providing convincing arguments for safe and correct behavior of automated driving (AD) systems have so far hindered their widespread commercial deployment. Conventional development approaches such as testing and simulation are limited by non-exhaustive analysis, and can thus not guarantee correctness in all possible scenarios. Formal methods is an approach to provide mathematical proofs of correctness, using a model of a system, that could be used to give the necessary arguments. This paper investigates the use of differential dynamic logic and the deductive verification tool KeYmaera X in the development of an AD feature. Specifically, formal models and safety proofs of different design variants of a Decision &amp; Control module for an in-lane AD feature are presented. In doing so, the assumptions and invariant conditions necessary to guarantee safety are identified, and the paper shows how such an analysis helps during the development process in requirement refinement and formulation of the operational design domain. Furthermore, it is shown how the performance of the different models is formally analyzed exhaustively, in all their allowed behaviors.      
### 19.A Generalized Switched-Capacitor Modular Multilevel Inverter Topology for Multiphase Electrical Machines with Capacitor-Voltage Self-Balancing Capability  [ :arrow_down: ](https://arxiv.org/pdf/2204.06867.pdf)
>  Recent research on multilevel inverters shows exciting properties, including the potential to generate multiple output voltages and integrated voltage boosting. However, most presented inverter topologies have a restricted number of output voltage levels and limited output voltage boosting ratio. In addition, balancing the voltage of capacitors in multilevel converters is very important and should be considered in the topology or control method. This paper describes a generalized switched-capacitor circuit topology for multilevel dc-to-ac inverters that can be developed for the desired output voltage levels. Also, the maximum ac output voltage can vary from values much lower than the dc input voltage to several times of it depending on the design requirement. High-voltage dc input and ac output could be handled using low-voltage capacitors, which substantially decreases overall cost and volume. The proposed topology further allows for easy expansion through stackable circuits for multiple load phases. It has an inherent capacity for balancing the voltage of capacitors. To validate the feasibility and practicality of this concept, we provide circuit descriptions, control strategies, design recommendations, and pertinent simulation findings for the suggested inverter topology.      
### 20.Ensuring accurate stain reproduction in deep generative networks for virtual immunohistochemistry  [ :arrow_down: ](https://arxiv.org/pdf/2204.06849.pdf)
>  Immunohistochemistry is a valuable diagnostic tool for cancer pathology. However, it requires specialist labs and equipment, is time-intensive, and is difficult to reproduce. Consequently, a long term aim is to provide a digital method of recreating physical immunohistochemical stains. Generative Adversarial Networks have become exceedingly advanced at mapping one image type to another and have shown promise at inferring immunostains from haematoxylin and eosin. However, they have a substantial weakness when used with pathology images as they can fabricate structures that are not present in the original data. CycleGANs can mitigate invented tissue structures in pathology image mapping but have a related disposition to generate areas of inaccurate staining. In this paper, we describe a modification to the loss function of a CycleGAN to improve its mapping ability for pathology images by enforcing realistic stain replication while retaining tissue structure. Our approach improves upon others by considering structure and staining during model training. We evaluated our network using the Fréchet Inception distance, coupled with a new technique that we propose to appraise the accuracy of virtual immunohistochemistry. This assesses the overlap between each stain component in the inferred and ground truth images through colour deconvolution, thresholding and the Sorensen-Dice coefficient. Our modified loss function resulted in a Dice coefficient for the virtual stain of 0.78 compared with the real AE1/AE3 slide. This was superior to the unaltered CycleGAN's score of 0.74. Additionally, our loss function improved the Fréchet Inception distance for the reconstruction to 74.54 from 76.47. We, therefore, describe an advance in virtual restaining that can extend to other immunostains and tumour types and deliver reproducible, fast and readily accessible immunohistochemistry worldwide.      
### 21.Interpretable Vertebral Fracture Quantification via Anchor-Free Landmarks Localization  [ :arrow_down: ](https://arxiv.org/pdf/2204.06818.pdf)
>  Vertebral body compression fractures are early signs of osteoporosis. Though these fractures are visible on Computed Tomography (CT) images, they are frequently missed by radiologists in clinical settings. Prior research on automatic methods of vertebral fracture classification proves its reliable quality; however, existing methods provide hard-to-interpret outputs and sometimes fail to process cases with severe abnormalities such as highly pathological vertebrae or scoliosis. We propose a new two-step algorithm to localize the vertebral column in 3D CT images and then detect individual vertebrae and quantify fractures in 2D simultaneously. We train neural networks for both steps using a simple 6-keypoints based annotation scheme, which corresponds precisely to the current clinical recommendation. Our algorithm has no exclusion criteria, processes 3D CT in 2 seconds on a single GPU, and provides an interpretable and verifiable output. The method approaches expert-level performance and demonstrates state-of-the-art results in vertebrae 3D localization (the average error is 1 mm), vertebrae 2D detection (precision and recall are 0.99), and fracture identification (ROC AUC at the patient level is up to 0.96). Our anchor-free vertebra detection network shows excellent generalizability on a new domain by achieving ROC AUC 0.95, sensitivity 0.85, specificity 0.9 on a challenging VerSe dataset with many unseen vertebra types.      
### 22.A Novel Approach for Cancellation of Non-Aligned Inter Spreading Factor Interference in LoRa Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.06803.pdf)
>  Long Range (LoRa) has become a key enabler technology for low power wide area networks. However, due to its ALOHA-based medium access scheme, LoRa has to cope with collisions that limit the capacity and network scalability. Collisions between randomly overlapped signals modulated with different spreading factors (SFs) result in inter-SF interference, which increases the packet loss likelihood when signal-to-interference ratio (SIR) is low. This issue cannot be resolved by channel coding since the probability of error distance is not concentrated around the adjacent symbol. In this paper, we analytically model this interference, and propose an interference cancellation method based on the idea of segmentation of the received signal. This scheme has three steps. First, the SF of the interference signal is identified, then the equivalent data symbol and complex amplitude of the interference are estimated. Finally, the estimated interference signal is subtracted from the received signal before demodulation. Unlike conventional serial interference cancellation (SIC), this scheme can directly estimate and reconstruct the non-aligned inter-SF interference without synchronization. Simulation results show that the proposed method can significantly reduce the symbol error rate (SER) under low SIR compared with the conventional demodulation. Moreover, it also shows high robustness to fractional sample timing offset (STO) and carrier frequency offset (CFO) of interference. The presented results clearly show the effectiveness of the proposed method in terms of the SER performance.      
### 23.Upside Risk Effect on Reliability of Microgrids Considering Demand Response Program and COVID-19: An Investigation on Health System and Power System Interactions  [ :arrow_down: ](https://arxiv.org/pdf/2204.06786.pdf)
>  COVID-19 has a vast impact on the power systems considering the customers demand and human resources. During this situation, the utilization of microgrids (MGs) may help the power systems balance the generation and consumption of power, which leads to customer satisfaction. In this paper, the optimal power scheduling of energy sources in an islanded MG by considering the upside risk (UR) is proposed for the very first time. The intended islanded MG consists of various sources such as wind turbine (WT), photovoltaic (PV), diesel generator (DGR), and battery. The goals of this work are minimizing the energy not supplied (ENS) in islanded mode considering the COVID-19s effect and implementing the demand response program (DRP). The difference between target ENS and actual ENS when actual ENS is less than the target is defined as UR. The results indicate that the UR related to the ENS of the islanded MG decreases significantly by slightly increasing the ENS. Moreover, COVID-19 decreases the ENS considerably and has a bigger effect than the DRP.      
### 24.A crowdsourced implementation of ITU-T P.910  [ :arrow_down: ](https://arxiv.org/pdf/2204.06784.pdf)
>  The gold standard for measuring video quality is the subjective test, and the most prevalent is the ITU-T P.910, a lab-based subjective standard in use for the past two decades. However, in practice using P.910 is slow, expensive, and requires a lab, which all create barriers to usage. As a result, most research papers that need to measure video quality don't use P.910 but rather metrics that are not well correlated to subjective opinion. We provide an open-source extension of P.910 based on crowdsourcing principles which address the speed, usage cost, and barrier to usage issues. We implement Absolute Category Rating (ACR), ACR with hidden reference (ACR-HR), and Degradation Category Rating (DCR). It includes rater, environment, hardware, and network qualifications, as well as gold and trapping questions to ensure quality. We have validated that the implementation is both accurate and highly reproducible compared to existing P.910 lab studies.      
### 25.Information fusion approach for biomass estimation in a plateau mountainous forest using a synergistic system comprising UAS-based digital camera and LiDAR  [ :arrow_down: ](https://arxiv.org/pdf/2204.06746.pdf)
>  Forest land plays a vital role in global climate, ecosystems, farming and human living environments. Therefore, forest biomass estimation methods are necessary to monitor changes in the forest structure and function, which are key data in natural resources research. Although accurate forest biomass measurements are important in forest inventory and assessments, high-density measurements that involve airborne light detection and ranging (LiDAR) at a low flight height in large mountainous areas are highly expensive. The objective of this study was to quantify the aboveground biomass (AGB) of a plateau mountainous forest reserve using a system that synergistically combines an unmanned aircraft system (UAS)-based digital aerial camera and LiDAR to leverage their complementary advantages. In this study, we utilized digital aerial photogrammetry (DAP), which has the unique advantages of speed, high spatial resolution, and low cost, to compensate for the deficiency of forestry inventory using UAS-based LiDAR that requires terrain-following flight for high-resolution data acquisition. Combined with the sparse LiDAR points acquired by using a high-altitude and high-speed UAS for terrain extraction, dense normalized DAP point clouds can be obtained to produce an accurate and high-resolution canopy height model (CHM). Based on the CHM and spectral attributes obtained from multispectral images, we estimated and mapped the AGB of the region of interest with considerable cost efficiency. Our study supports the development of predictive models for large-scale wall-to-wall AGB mapping by leveraging the complementarity between DAP and LiDAR measurements. This work also reveals the potential of utilizing a UAS-based digital camera and LiDAR synergistically in a plateau mountainous forest area.      
### 26.Hierarchical-Absolute Reciprocity Calibration for Millimeter-wave Hybrid Beamforming Systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.06705.pdf)
>  In time-division duplexing (TDD) millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems, the reciprocity mismatch severely degrades the performance of the hybrid beamforming (HBF). In this work, to mitigate the detrimental effect of the reciprocity mismatch, we investigate reciprocity calibration for the mmWave-HBF system with a fully-connected phase shifter network. To reduce the overhead and computational complexity of reciprocity calibration, we first decouple digital radio frequency (RF) chains and analog RF chains with beamforming design. Then, the entire calibration problem of the HBF system is equivalently decomposed into two subproblems corresponding to the digital-chain calibration and analog-chain calibration. To solve the calibration problems efficiently, a closed-form solution to the digital-chain calibration problem is derived, while an iterative-alternating optimization algorithm for the analog-chain calibration problem is proposed. To measure the performance of the proposed algorithm, we derive the Cramér-Rao lower bound on the errors in estimating mismatch coefficients. The results reveal that the estimation errors of mismatch coefficients of digital and analog chains are uncorrelated, and that the mismatch coefficients of receive digital chains can be estimated perfectly. Simulation results are presented to validate the analytical results and to show the performance of the proposed calibration approach.      
### 27.Adaptive Modulation for Wobbling UAV Air-to-Ground Links in Millimeter-wave Bands  [ :arrow_down: ](https://arxiv.org/pdf/2204.06673.pdf)
>  The emerging millimeter-wave (mm-wave) unmanned aerial vehicle (UAV) air-to-ground (A2G) communications are facing the Doppler effect problem that arises from the inevitable wobbling of the UAV. The fast time-varying channel for UAV A2G communications may lead to the outdated channel state information (CSI) from the channel estimation. In this paper, we introduce two detectors to demodulate the received signal and get the instantaneous bit error probability (BEP) of a mm-wave UAV A2G link under imperfect CSI. Based on the designed detectors, we propose an adaptive modulation scheme to maximize the average transmission rate under imperfect CSI by optimizing the data transmission time subject to the maximum tolerable BEP. A power control policy is in conjunction with adaptive modulation to minimize the transmission power while maintaining both the BEP under the threshold and the maximized average transmission rate. Numerical results show that the proposed adaptive modulation scheme in conjunction with the power control policy could maximize the temporally averaged transmission rate, while saves as much as 50\% energy.      
### 28.Exploring the Impacts of Power Grid Signals on Data Center Operations using a Receding-Horizon Scheduling Model  [ :arrow_down: ](https://arxiv.org/pdf/2204.06654.pdf)
>  Data centers (DaCes) can help decarbonize the power grid by helping absorb renewable power (e.g., wind and solar) due to their ability to shift power loads across space and time. However, to harness such load-shifting flexibility, it is necessary to understand how grid signals (carbon signals and price/load allocations) affect DaCe operations. An obstacle that arises here is the lack of computationally-tractable DaCe scheduling models that can capture objectives, constraints, and information flows that arise at the interface of DaCes and the grid. To address this gap, we present a receding-horizon scheduling model (a mixed-integer programming model) that captures the resource management layer between the DaCe scheduler and the grid while accounting for logical constraints, different types of objectives, and forecasts of incoming job profiles and of available computing capacity. We use our model to conduct extensive case studies based on public data from Microsoft Azure and MISO. Our studies show that DaCes can provide significant temporal load-shifting flexibility in response to carbon emission signals and peak demand charges from electricity markets without sacrificing much scheduling performance. Models and case studies are shared as easy-to-use Julia code.      
### 29.A Bandwagon Bias Based Model for Opinion Dynamics: Intertwining between Homophily and Influence Mechanisms  [ :arrow_down: ](https://arxiv.org/pdf/2204.06609.pdf)
>  Recently a model for the interplay between homophily-based appraisal dynamics and influence-based opinion dynamics has been proposed. The model explores for the first time how the opinions of a group of agents on a certain number of issues/topics is influenced by the agents' mutual appraisal and, conversely, the agents' mutual appraisal is updated based on the agents' opinions on the various issues, according to a homophily model. In this paper we show that a simplified (and, in some situations, more feasible) version of the model, that accounts only for the signs of the agents' appraisals rather than for their numerical values, provides an equally accurate and effective model of the opinion dynamics in small networks. The equilibria reached by this model correspond, almost surely, to situations in which the agents' network is complete and structurally balanced. On the other hand, we ensure that such equlibria can always be reached in a finite number of steps, and, differently from the original model, we rule out other types of equilibria that correspond to disconnected social networks.      
### 30.Masked Siamese Networks for Label-Efficient Learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.07141.pdf)
>  We propose Masked Siamese Networks (MSN), a self-supervised learning framework for learning image representations. Our approach matches the representation of an image view containing randomly masked patches to the representation of the original unmasked image. This self-supervised pre-training strategy is particularly scalable when applied to Vision Transformers since only the unmasked patches are processed by the network. As a result, MSNs improve the scalability of joint-embedding architectures, while producing representations of a high semantic level that perform competitively on low-shot image classification. For instance, on ImageNet-1K, with only 5,000 annotated images, our base MSN model achieves 72.4% top-1 accuracy, and with 1% of ImageNet-1K labels, we achieve 75.7% top-1 accuracy, setting a new state-of-the-art for self-supervised learning on this benchmark. Our code is publicly available.      
### 31.Residual Swin Transformer Channel Attention Network for Image Demosaicing  [ :arrow_down: ](https://arxiv.org/pdf/2204.07098.pdf)
>  Image demosaicing is problem of interpolating full- resolution color images from raw sensor (color filter array) data. During last decade, deep neural networks have been widely used in image restoration, and in particular, in demosaicing, attaining significant performance improvement. In recent years, vision transformers have been designed and successfully used in various computer vision applications. One of the recent methods of image restoration based on a Swin Transformer (ST), SwinIR, demonstrates state-of-the-art performance with a smaller number of parameters than neural network-based methods. Inspired by the success of SwinIR, we propose in this paper a novel Swin Transformer-based network for image demosaicing, called RSTCANet. To extract image features, RSTCANet stacks several residual Swin Transformer Channel Attention blocks (RSTCAB), introducing the channel attention for each two successive ST blocks. Extensive experiments demonstrate that RSTCANet out- performs state-of-the-art image demosaicing methods, and has a smaller number of parameters.      
### 32.Learning and controlling the source-filter representation of speech with a variational autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2204.07075.pdf)
>  Understanding and controlling latent representations in deep generative models is a challenging yet important problem for analyzing, transforming and generating various types of data. In speech processing, inspiring from the anatomical mechanisms of phonation, the source-filter model considers that speech signals are produced from a few independent and physically meaningful continuous latent factors, among which the fundamental frequency $f_0$ and the formants are of primary importance. In this work, we show that the source-filter model of speech production naturally arises in the latent space of a variational autoencoder (VAE) trained in an unsupervised manner on a dataset of natural speech signals. Using only a few seconds of labeled speech signals generated with an artificial speech synthesizer, we experimentally illustrate that $f_0$ and the formant frequencies are encoded in orthogonal subspaces of the VAE latent space and we develop a weakly-supervised method to accurately and independently control these speech factors of variation within the learned latent subspaces. Without requiring additional information such as text or human-labeled data, this results in a deep generative model of speech spectrograms that is conditioned on $f_0$ and the formant frequencies, and which is applied to the transformation of speech signals.      
### 33.EvoSTS Forecasting: Evolutionary Sparse Time-Series Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2204.07066.pdf)
>  In this work, we highlight our novel evolutionary sparse time-series forecasting algorithm also known as EvoSTS. The algorithm attempts to evolutionary prioritize weights of Long Short-Term Memory (LSTM) Network that best minimize the reconstruction loss of a predicted signal using a learned sparse coded dictionary. In each generation of our evolutionary algorithm, a set number of children with the same initial weights are spawned. Each child undergoes a training step and adjusts their weights on the same data. Due to stochastic back-propagation, the set of children has a variety of weights with different levels of performance. The weights that best minimize the reconstruction loss with a given signal dictionary are passed to the next generation. The predictions from the best-performing weights of the first and last generation are compared. We found improvements while comparing the weights of these two generations. However, due to several confounding parameters and hyperparameter limitations, some of the weights had negligible improvements. To the best of our knowledge, this is the first attempt to use sparse coding in this way to optimize time series forecasting model weights, such as those of an LSTM network.      
### 34.Streamable Neural Audio Synthesis With Non-Causal Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2204.07064.pdf)
>  Deep learning models are mostly used in an offline inference fashion. However, this strongly limits the use of these models inside audio generation setups, as most creative workflows are based on real-time digital signal processing. Although approaches based on recurrent networks can be naturally adapted to this buffer-based computation, the use of convolutions still poses some serious challenges. To tackle this issue, the use of causal streaming convolutions have been proposed. However, this requires specific complexified training and can impact the resulting audio quality. <br>In this paper, we introduce a new method allowing to produce non-causal streaming models. This allows to make any convolutional model compatible with real-time buffer-based processing. As our method is based on a post-training reconfiguration of the model, we show that it is able to transform models trained without causal constraints into a streaming model. We show how our method can be adapted to fit complex architectures with parallel branches. To evaluate our method, we apply it on the recent RAVE model, which provides high-quality real-time audio synthesis. We test our approach on multiple music and speech datasets and show that it is faster than overlap-add methods, while having no impact on the generation quality. Finally, we introduce two open-source implementation of our work as Max/MSP and PureData externals, and as a VST audio plugin. This allows to endow traditional digital audio workstation with real-time neural audio synthesis on a laptop CPU.      
### 35.Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2204.07062.pdf)
>  Content based providers transmits real time complex signal such as video data from one region to another. During this transmission process, the signals usually end up distorted or degraded where the actual information present in the video is lost. This normally happens in the streaming video services applications. Hence there is a need to know the level of degradation that happened in the receiver side. This video degradation can be estimated by network state parameters like data rate and packet loss values. Our proposed solution vQoS GAN (video Quality of Service Generative Adversarial Network) can estimate the network state parameters from the degraded received video data using a deep learning approach of semi supervised generative adversarial network algorithm. A robust and unique design of deep learning network model has been trained with the video data along with data rate and packet loss class labels and achieves over 95 percent of training accuracy. The proposed semi supervised generative adversarial network can additionally reconstruct the degraded video data to its original form for a better end user experience.      
### 36.From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2204.07018.pdf)
>  This paper investigates the impact of different standard environmental sound representations (spectrograms) on the recognition performance and adversarial attack robustness of a victim residual convolutional neural network, namely ResNet-18. Our main motivation for focusing on such a front-end classifier rather than other complex architectures is balancing recognition accuracy and the total number of training parameters. Herein, we measure the impact of different settings required for generating more informative Mel-frequency cepstral coefficient (MFCC), short-time Fourier transform (STFT), and discrete wavelet transform (DWT) representations on our front-end model. This measurement involves comparing the classification performance over the adversarial robustness. We demonstrate an inverse relationship between recognition accuracy and model robustness against six benchmarking attack algorithms on the balance of average budgets allocated by the adversary and the attack cost. Moreover, our experimental results have shown that while the ResNet-18 model trained on DWT spectrograms achieves a high recognition accuracy, attacking this model is relatively more costly for the adversary than other 2D representations. We also report some results on different convolutional neural network architectures such as ResNet-34, ResNet-56, AlexNet, and GoogLeNet, SB-CNN, and LSTM-based.      
### 37.Atmospheric Turbulence Removal with Complex-Valued Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2204.06989.pdf)
>  Atmospheric turbulence distorts visual imagery and is always problematic for information interpretation by both human and machine. Most well-developed approaches to remove atmospheric turbulence distortion are model-based. However, these methods require high computation and large memory preventing their feasibility of real-time operation. Deep learning-based approaches have hence gained more attention but currently work efficiently only on static scenes. This paper presents a novel learning-based framework offering short temporal spanning to support dynamic scenes. We exploit complex-valued convolutions as phase information, altered by atmospheric turbulence, is captured better than using ordinary real-valued convolutions. Two concatenated modules are proposed. The first module aims to remove geometric distortions and, if enough memory, the second module is applied to refine micro details of the videos. Experimental results show that our proposed framework efficiently mitigate the atmospheric turbulence distortion and significantly outperforms the existing methods.      
### 38.HyDe: The First Open-Source, Python-Based, GPU-Accelerated Hyperspectral Denoising Package  [ :arrow_down: ](https://arxiv.org/pdf/2204.06979.pdf)
>  As with any physical instrument, hyperspectral cameras induce different kinds of noise in the acquired data. Therefore, Hyperspectral denoising is a crucial step for analyzing hyperspectral images (HSIs). Conventional computational methods rarely use GPUs to improve efficiency and are not fully open-source. Alternatively, deep learning-based methods are often open-source and use GPUs, but their training and utilization for real-world applications remain non-trivial for many researchers. Consequently, we propose HyDe: the first open-source, GPU-accelerated Python-based, hyperspectral image denoising toolbox, which aims to provide a large set of methods with an easy-to-use environment. HyDe includes a variety of methods ranging from low-rank wavelet-based methods to deep neural network (DNN) models. HyDe's interface dramatically improves the interoperability of these methods and the performance of the underlying functions. In fact, these methods maintain similar HSI denoising performance to their original implementations while consuming nearly ten times less energy. Furthermore, we present a method for training DNNs for denoising HSIs which are not spatially related to the training dataset, i.e., training on ground-level HSIs for denoising HSIs with other perspectives including airborne, drone-borne, and space-borne. To utilize the trained DNNs, we show a sliding window method to effectively denoise HSIs which would otherwise require more than 40 GB. The package can be found at: \url{<a class="link-external link-https" href="https://github.com/Helmholtz-AI-Energy/HyDe" rel="external noopener nofollow">this https URL</a>}.      
### 39.Proof of Federated Training: Accountable Cross-Network Model Training and Inference  [ :arrow_down: ](https://arxiv.org/pdf/2204.06919.pdf)
>  Blockchain has widely been adopted to design accountable federated learning frameworks; however, the existing frameworks do not scale for distributed model training over multiple independent blockchain networks. For storing the pre-trained models over blockchain, current approaches primarily embed a model using its structural properties that are neither scalable for cross-chain exchange nor suitable for cross-chain verification. This paper proposes an architectural framework for cross-chain verifiable model training using federated learning, called Proof of Federated Training (PoFT), the first of its kind that enables a federated training procedure span across the clients over multiple blockchain networks. Instead of structural embedding, PoFT uses model parameters to embed the model over a blockchain and then applies a verifiable model exchange between two blockchain networks for cross-network model training. We implement and test PoFT over a large-scale setup using Amazon EC2 instances and observe that cross-chain training can significantly boosts up the model efficacy. In contrast, PoFT incurs marginal overhead for inter-chain model exchanges.      
### 40.Stabilization of rank-deficient continuous-time switched affine systems  [ :arrow_down: ](https://arxiv.org/pdf/2204.06912.pdf)
>  This paper treats the global stabilization problem of continuous-time switched affine systems that have rank-deficient convex combinations of their dynamic matrices. For these systems, the already known set of attainable equilibrium points has higher dimensionality than in the full-rank case due to the existence of what we define as singular equilibrium points. Our main goal is to design a state-dependent switching function to ensure global asymptotic stability of a chosen point inside this set with conditions expressed in terms of linear matrix inequalities. For this class of systems, global exponential stability is generally impossible to be guaranteed. Hence, the proposed switching function is shown to ensure global asymptotic and local exponential stability of the desired equilibrium point. The position control and the velocity control with integral action of a dc motor driven by an h-bridge fed via a boost converter are used for validation. This practical application example is composed of eight subsystems, and all possible convex combinations of the dynamic matrices are singular.      
### 41.Flexible LED Index Modulation for MIMO Optical Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2204.06858.pdf)
>  The limited bandwidth of optical wireless communication (OWC) front-end devices motivates the use of multiple-input-multiple-output (MIMO) techniques to enhance data rates. It is known that very high multiplexing gains could be achieved by spatial multiplexing (SMX) in exchange for exhaustive detection complexity. Alternatively, in spatial modulation (SM), a single light emitting diode (LED) is activated per time instance where information is carried by both the signal and the LED index. Since only an LED is active, both transmitter (TX) and receiver (RX) complexity reduces significantly while retaining the information transmission in the spatial domain. However, significant spectral efficiency losses occur in SM compared to SMX. In this paper, we propose a technique which adopts the advantages of both systems. Accordingly, the proposed flexible LED index modulation (FLIM) technique harnesses the inactive state of the LEDs as a transmit symbol. Therefore, the number of active LEDs changes in each transmission, unlike conventional techniques. Moreover, the system complexity is reduced by employing a linear minimum mean squared error (MMSE) equalizer and an angle perturbed receiver at the RX. Numerical results show that FLIM outperforms the reference systems by at least 6 dB in the low and medium/high spectral efficiency regions.      
### 42.Learning Task-Aware Energy Disaggregation: a Federated Approach  [ :arrow_down: ](https://arxiv.org/pdf/2204.06767.pdf)
>  We consider the problem of learning the energy disaggregation signals for residential load data. Such task is referred as non-intrusive load monitoring (NILM), and in order to find individual devices' power consumption profiles based on aggregated meter measurements, a machine learning model is usually trained based on large amount of training data coming from a number of residential homes. Yet collecting such residential load datasets require both huge efforts and customers' approval on sharing metering data, while load data coming from different regions or electricity users may exhibit heterogeneous usage patterns. Both practical concerns make training a single, centralized NILM model challenging. In this paper, we propose a decentralized and task-adaptive learning scheme for NILM tasks, where nested meta learning and federated learning steps are designed for learning task-specific models collectively. Simulation results on benchmark dataset validate proposed algorithm's performance on efficiently inferring appliance-level consumption for a variety of homes and appliances.      
### 43.Iterative Inner/outer Approximations for Scalable Semidefinite Programs using Block Factor-width-two Matrices  [ :arrow_down: ](https://arxiv.org/pdf/2204.06759.pdf)
>  In this paper, we propose iterative inner/outer approximations based on a recent notion of block factor-width-two matrices for solving semidefinite programs (SDPs). Our inner/outer approximating algorithms generate a sequence of upper/lower bounds of increasing accuracy for the optimal SDP cost. The block partition in our algorithms offers flexibility in terms of both numerical efficiency and solution quality, which includes the approach of scaled diagonally dominance (SDD) approximation as a special case. We discuss both the theoretical results and numerical implementation in detail. Our main theorems guarantee that the proposed iterative algorithms generate monotonically decreasing upper (increasing lower) bounds. Extensive numerical results confirm our findings.      
### 44.Control-oriented meta-learning  [ :arrow_down: ](https://arxiv.org/pdf/2204.06716.pdf)
>  Real-time adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With both fully-actuated and underactuated nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.      
### 45.Learning fixed-complexity polyhedral Lyapunov functions from counterexamples  [ :arrow_down: ](https://arxiv.org/pdf/2204.06693.pdf)
>  In this paper, we present an algorithm for synthesizing polyhedral Lyapunov functions for hybrid systems with multiple modes, each with linear dynamics and state-based switching between these modes. The problem of proving global asymptotic stability (GAS) for such systems is quite challenging. In this paper, we present an algorithm to synthesize a fixed-complexity polyhedral Lyapunov function to prove that such a system is GAS. Such functions are defined as the piecewise maximum over a fixed number of linear functions. Previous work on this problem reduces to a system of \emph{bilinear} constraints that are well-known to be computationally hard to solve precisely. Therefore, heuristic approaches such as alternating descent have been employed. In this paper, we first prove that deciding if there exists a polyhedral Lyapunov function for a given piecewise linear system is a NP-hard problem. We then present a counterexample-guided algorithm for solving this problem. Our approach alternates between choosing candidate Lyapunov functions based on a finite set of counterexamples, and verifying if these candidates satisfy the Lyapunov conditions. If the verification of a given candidate fails, we find a new counterexample that is added back to our set. We prove that if this algorithm terminates, it discovers a valid Lyapunov function or concludes that no such Lyapunov function exists. However, our initial algorithm can be non-terminating. We modify our algorithm to provide a terminating version based on the so-called cutting-plane argument from nonsmooth optimization. We demonstrate our algorithm on small numerical examples.      
### 46.Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2204.06660.pdf)
>  We study the problem of expert advice under partial bandit feedback setting and create a sequential minimax optimal algorithm. Our algorithm works with a more general partial monitoring setting, where, in contrast to the classical bandit feedback, the losses can be revealed in an adversarial manner. Our algorithm adopts a universal prediction perspective, whose performance is analyzed with regret against a general expert selection sequence. The regret we study is against a general competition class that covers many settings (such as the switching or contextual experts settings) and the expert selection sequences in the competition class are determined by the application at hand. Our regret bounds are second order bounds in terms of the sum of squared losses and the normalized regret of our algorithm is invariant under arbitrary affine transforms of the loss sequence. Our algorithm is truly online and does not use any preliminary information about the loss sequences.      
### 47.Predicting score distribution to improve non-intrusive speech quality estimation  [ :arrow_down: ](https://arxiv.org/pdf/2204.06616.pdf)
>  Deep noise suppressors (DNS) have become an attractive solution to remove background noise, reverberation, and distortions from speech and are widely used in telephony/voice applications. They are also occasionally prone to introducing artifacts and lowering the perceptual quality of the speech. Subjective listening tests that use multiple human judges to derive a mean opinion score (MOS) are a popular way to measure these models' performance. Deep neural network based non-intrusive MOS estimation models have recently emerged as a popular cost-efficient alternative to these tests. These models are trained with only the MOS labels, often discarding the secondary statistics of the opinion scores. In this paper, we investigate several ways to integrate the distribution of opinion scores (e.g. variance, histogram information) to improve the MOS estimation performance. Our model is trained on a corpus of 419K denoised samples by 320 different DNS models and model variations and evaluated on 18K test samples from DNSMOS. We show that with very minor modification of a single task MOS estimation pipeline, these freely available labels can provide up to a 0.016 RMSE and 1% SRCC improvement.      
### 48.Large-Scale Streaming End-to-End Speech Translation with Neural Transducers  [ :arrow_down: ](https://arxiv.org/pdf/2204.05352.pdf)
>  Neural transducers have been widely used in automatic speech recognition (ASR). In this paper, we introduce it to streaming end-to-end speech translation (ST), which aims to convert audio signals to texts in other languages directly. Compared with cascaded ST that performs ASR followed by text-based machine translation (MT), the proposed Transformer transducer (TT)-based ST model drastically reduces inference latency, exploits speech information, and avoids error propagation from ASR to MT. To improve the modeling capacity, we propose attention pooling for the joint network in TT. In addition, we extend TT-based ST to multilingual ST, which generates texts of multiple languages at the same time. Experimental results on a large-scale 50 thousand (K) hours pseudo-labeled training set show that TT-based ST not only significantly reduces inference time but also outperforms non-streaming cascaded ST for English-German translation.      
