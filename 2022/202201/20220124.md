# ArXiv eess --Mon, 24 Jan 2022
### 1.Conformal Metasurfaces: a Novel Solution for Vehicular Communications  [ :arrow_down: ](https://arxiv.org/pdf/2201.08820.pdf)
>  In future 6G millimeter wave (mmWave)/sub-THz vehicle-to-everything (V2X) communication systems, vehicles are expected to be equipped with massive antenna arrays to realize beam-based links capable of compensating for the severe path loss. However, vehicle-to-vehicle (V2V) direct links are prone to be blocked by surrounding vehicles. Emerging metasurface technologies enable the control of the electromagnetic wave reflection towards the desired direction, enriching the channel scattering to boost communication performance. Reconfigurable intelligent surfaces (RIS), and mostly the pre-configured counterpart intelligent reflecting surfaces (IRS), are a promising low-cost relaying system for 6G. This paper proposes using conformal metasurfaces (either C-RIS or C-IRS) deployed on vehicles' body to mitigate the blockage impact in a highway multi-lane scenario. In particular, conformal metasurfaces create artificial reflections to mitigate blockage by compensating for the non-flat shape of the vehicle's body, such as the lateral doors, with proper phase patterns. We analytically derive the phase pattern to apply to a cylindrical C-RIS/C-IRS approximating the shape of the car body, as a function of both incidence and reflection angles, considering cylindrical RIS/IRS as a generalization of conventional planar ones. We propose a novel design for optimally pre-configured C-IRS to mimic the behavior of an EM flat surface on car doors, proving the benefits of C-RIS and C-IRS in a multi-lane V2V highway scenario. The results show a consistent reduction of blockage probability when exploiting C-RIS/C-IRS, 20% for pre-configured C-IRS, and 70% for C-RIS, as well as a remarkable improvement in terms of average signal-to-noise ratio, respectively 10-20 dB for C-IRS and 30-40 dB for C-RIS.      
### 2.Improving Across-Dataset Brain Tissue Segmentation Using Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2201.08741.pdf)
>  Brain tissue segmentation has demonstrated great utility in quantifying MRI data through Voxel-Based Morphometry and highlighting subtle structural changes associated with various conditions within the brain. However, manual segmentation is highly labor-intensive, and automated approaches have struggled due to properties inherent to MRI acquisition, leaving a great need for an effective segmentation tool. Despite the recent success of deep convolutional neural networks (CNNs) for brain tissue segmentation, many such solutions do not generalize well to new datasets, which is critical for a reliable solution. Transformers have demonstrated success in natural image segmentation and have recently been applied to 3D medical image segmentation tasks due to their ability to capture long-distance relationships in the input where the local receptive fields of CNNs struggle. This study introduces a novel CNN-Transformer hybrid architecture designed for brain tissue segmentation. We validate our model's performance across four multi-site T1w MRI datasets, covering different vendors, field strengths, scan parameters, time points, and neuropsychiatric conditions. In all situations, our model achieved the greatest generality and reliability. Out method is inherently robust and can serve as a valuable tool for brain-related T1w MRI studies. The code for the TABS network is available at: <a class="link-external link-https" href="https://github.com/raovish6/TABS" rel="external noopener nofollow">this https URL</a>.      
### 3.Ordered Transmission-based Detection in Distributed Networks in the Presence of Byzantines  [ :arrow_down: ](https://arxiv.org/pdf/2201.08737.pdf)
>  The ordered transmission (OT) scheme reduces the number of transmissions needed in the network to make the final decision, while it maintains the same probability of error as the system without using OT scheme. In this paper, we investigate the performance of the system using OT scheme in the presence of Byzantine attacks for binary hypothesis testing problem. We analyze the probability of error for the system under attack and evaluate the number of transmissions saved using Monte Carlo method. We also derive the bounds for the number of transmissions saved in the system under attack. The optimal attacking strategy for the OT-based system is investigated. Simulation results show that the Byzantine attacks have significant impact on the number of transmissions saved even when the signal strength is sufficiently large.      
### 4.SparseAlign: A Super-Resolution Algorithm for Automatic Marker Localization and Deformation Estimation in Cryo-Electron Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2201.08706.pdf)
>  Tilt-series alignment is crucial to obtaining high-resolution reconstructions in cryo-electron tomography. Beam-induced local deformation of the sample is hard to estimate from the low-contrast sample alone, and often requires fiducial gold bead markers. The state-of-the-art approach for deformation estimation uses (semi-)manually labelled marker locations in projection data to fit the parameters of a polynomial deformation model. Manually-labelled marker locations are difficult to obtain when data are noisy or markers overlap in projection data. We propose an alternative mathematical approach for simultaneous marker localization and deformation estimation by extending a grid-free super-resolution algorithm first proposed in the context of single-molecule localization microscopy. Our approach does not require labelled marker locations; instead, we use an image-based loss where we compare the forward projection of markers with the observed data. We equip this marker localization scheme with an additional deformation estimation component and solve for a reduced number of deformation parameters. Using extensive numerical studies on marker-only samples, we show that our approach automatically finds markers and reliably estimates sample deformation without labelled marker data. We further demonstrate the applicability of our approach for a broad range of model mismatch scenarios, including experimental electron tomography data of gold markers on ice.      
### 5.Moment Propagation Through Carleman Linearization with Application to Probabilistic Safety Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2201.08648.pdf)
>  We develop a method to approximate the moments of a discrete-time stochastic polynomial system. Our method is built upon Carleman linearization with truncation. Specifically, we take a stochastic polynomial system with finitely many states and transform it into an infinite-dimensional system with linear deterministic dynamics, which describe the exact evolution of the moments of the original polynomial system. We then truncate this deterministic system to obtain a finite-dimensional linear system, and use it for moment approximation by iteratively propagating the moments along the finite-dimensional linear dynamics across time. We provide efficient online computation methods for this propagation scheme with several error bounds for the approximation. Our result also shows that precise values of certain moments can be obtained when the truncated system is sufficiently large. Furthermore, we investigate techniques to reduce the offline computation load using reduced Kronecker power. Based on the obtained approximate moments and their errors, we also provide probability bounds for the state to be outside of given hyperellipsoidal regions. Those bounds allow us to conduct probabilistic safety analysis online through convex optimization. We demonstrate our results on a logistic map with stochastic dynamics and a vehicle dynamics subject to stochastic disturbance.      
### 6.Tensor-based Basis Function Learning for Three-dimensional Sound Speed Fields  [ :arrow_down: ](https://arxiv.org/pdf/2201.08583.pdf)
>  Basis function learning is the stepping stone towards effective three-dimensional (3D) sound speed field (SSF) inversion for various acoustic signal processing tasks, including ocean acoustic tomography, underwater target localization/tracking, and underwater communications. Classical basis functions include the empirical orthogonal functions (EOFs), Fourier basis functions, and their combinations. The unsupervised machine learning method, e.g., the K-SVD algorithm, has recently tapped into the basis function design, showing better representation performance than the EOFs. However, existing methods do not consider basis function learning approaches that treat 3D SSF data as a third-order tensor, and thus cannot fully utilize the 3D interactions/correlations therein. To circumvent such a drawback, basis function learning is linked to tensor decomposition in this paper, which is the primary drive for recent multi-dimensional data mining. In particular, a tensor-based basis function learning framework is proposed, which can include the classical basis functions (using EOFs and/or Fourier basis functions) as its special cases. This provides a unified tensor perspective for understanding and representing 3D SSFs. Numerical results using the South China Sea 3D SSF data have demonstrated the excellent performance of the tensor-based basis functions.      
### 7.SegTransVAE: Hybrid CNN -- Transformer with Regularization for medical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2201.08582.pdf)
>  Current research on deep learning for medical image segmentation exposes their limitations in learning either global semantic information or local contextual information. To tackle these issues, a novel network named SegTransVAE is proposed in this paper. SegTransVAE is built upon encoder-decoder architecture, exploiting transformer with the variational autoencoder (VAE) branch to the network to reconstruct the input images jointly with segmentation. To the best of our knowledge, this is the first method combining the success of CNN, transformer, and VAE. Evaluation on various recently introduced datasets shows that SegTransVAE outperforms previous methods in Dice Score and $95\%$-Haudorff Distance while having comparable inference time to a simple CNN-based architecture network. The source code is available at: <a class="link-external link-https" href="https://github.com/itruonghai/SegTransVAE" rel="external noopener nofollow">this https URL</a>.      
### 8.Performance Analysis of Hybrid RF-Reconfigurable Intelligent Surfaces Assisted FSO Communication  [ :arrow_down: ](https://arxiv.org/pdf/2201.08563.pdf)
>  Optical reconfigurable intelligent surface (ORIS) is an emerging technology that can achieve reconfigurable optical propagation environments by precisely adjusting signal's reflection and shape through a large number of passive reflecting elements. In this paper, we investigate the performance of an ORIS-assisted dual-hop hybrid radio frequency (RF) and free space optics (FSO) communication system. By jointly considering the physical models of ORIS, RF channel, atmospheric turbulence, and pointing error, the closed-form solutions of the system's precise outage probability, asymptotic outage probability and BER have been derived. It is shown through numerical results that the derivation results are accurate and the RF-FSO links with ORISs show a slightly worse performance than the traditional RF-FSO links. Based on theoretical analysis and simulation results, the system design and effect of each parameter have been discussed.      
### 9.RHONN Modelling-enabled Nonlinear Predictive Control for Lateral Dynamics Stabilization of An In-wheel Motor Driven Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2201.08558.pdf)
>  Featuring the fast response and flexibility in control allocation, an electric vehicle with in-wheel motors is a good platform for implementing advanced vehicle dynamics control. Among many active safety functions of an in-wheel motor driven vehicle (IMDV), lateral stability control is a key technology, which can be realized through torque vectoring. To further advance the lateral stabilization performance of the IMDV, in this paper a novel data-driven nonlinear model predictive control (NMPC) is proposed based the recurrent high-order neural network (RHONN) modelling method. First, the new RHONN model is developed to represent vehicle's nonlinear dynamic behaviors. Different from the conventional physics-based modelling method, the RHONN model only needs data and forms high-order polynomials. Based on the RHONN model, the steady-state responses of vehicle's yaw rate and sideslip angle are iteratively optimized and set as the control objectives for low-level controller, aiming to improve the system robustness. Besides, a nonlinear model predictive controller is designed based on the RHONN, which is expected to improve the prediction accuracy during the receding horizon control. Further, a constrained optimization problem is formulated to derive the required yaw moment for vehicle lateral dynamics stabilization. Finally, the performance of the developed RHONN-based nonlinear MPC is validated on an IMDV in the CarSim/Simulink simulation environment. The validation results show that the developed approach outperforms the conventional method, and further improves the stable margin of the system. It is able to enhance the lateral stabilization performance of the IMDV under various driving scenarios, demonstrating the feasibility and effectiveness of the proposed approach.      
### 10.Underwater Node Localization using Optoacoustic Signals  [ :arrow_down: ](https://arxiv.org/pdf/2201.08540.pdf)
>  Localization of underwater networks is important in many military and civil applications. Because GPS receivers do not work below the water surface, traditional localization methods form a relative topology of underwater nodes (UWNs) and utilize either anchor nodes or floating gateways with dual transceivers in order to determine global coordinates. However, these methods introduce logistical complications and security risks in deploying the anchor and/or surface gateways. This paper tackles such an issue by proposing new localization techniques which can remotely localize UWNs using optoacoustic signals. In our approach, GPS coordinates are transmitted from air to the UWN via creating an underwater temporary isotropic acoustic transmitter with the optoacoustic process. We analyze the process of controlling the shape and size of the plasma to create the isotropic acoustic transmitter and experimentally validate the generation of isotropic acoustic signals. Then two methods of localization are proposed for static and dynamic UWNs. Finally, the simulation results with experimental values show the effectiveness of our approach. Comparing to the traditional techniques, our approach achieves the same accuracy without using any surface or underwater anchor nodes.      
### 11.Noise-specific denoising method with applications to high-frequency ultrasonic images  [ :arrow_down: ](https://arxiv.org/pdf/2201.08527.pdf)
>  Denoising is of utmost importance for the visualization and processing of images featuring low signal-to-noise ratio. Total variation methods are among the most popular techniques to perform this task improving the signal-to-noise ratio while preserving coherent intensity discontinuities. In this work, a novel method, termed maximum likelihood data, is proposed, endowing the total variation formulation with the capability to deal with noise-specific models and pre-processing stages for a certain image of interest. To do this, the data fidelity term is modified by means of a maximum likelihood estimator between the original and the denoised image. To assess the improvements of the proposed method with respect to the total variation formulation, we study the denoising of high-frequency ultrasonic images on in-silico and in-vivo setups. The proposed method delivered a better contrast, preservation and localization of the structures while diminishing the intensity bias of the total variation formulation for the multiplicative noise. The enhancement of medical images through denoising helps to improve the outcome of subsequently applied image processing such as registration and segmentation procedures.      
### 12.On minimum phase transformation and filter design  [ :arrow_down: ](https://arxiv.org/pdf/2201.08515.pdf)
>  Minimum-phase finite impulse response filters are widely used in practice, and much research has been devoted to the design of such filters. However, for the important case of Chebyshev filters there is a curious mismatch between current best practice and well-established theoretical principles. The paper shows that this difference can be understood through analysis of the time-domain factorization of a suitable extended matrix. This analysis explains why the definition of a factorable linear phase filter must be revised. The time domain analysis of factorization suggests initial values leading to fast and accurate convergence of iterative algorithms for the design of minimum-phase finite impulse response filters. Numerical results are provided to demonstrate that a significant improvement in filter tap accuracy is obtained when the well-established theoretical principles are correctly applied to the design of minimum phase finite impulse response filters.      
### 13.Vertical Federated Edge Learning with Distributed Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2201.08512.pdf)
>  This letter studies a vertical federated edge learning (FEEL) system for collaborative objects/human motion recognition by exploiting the distributed integrated sensing and communication (ISAC). In this system, distributed edge devices first send wireless signals to sense targeted objects/human, and then exchange intermediate computed vectors (instead of raw sensing data) for collaborative recognition while preserving data privacy. To boost the spectrum and hardware utilization efficiency for FEEL, we exploit ISAC for both target sensing and data exchange, by employing dedicated frequency-modulated continuous-wave (FMCW) signals at each edge device. Under this setup, we propose a vertical FEEL framework for realizing the recognition based on the collected multi-view wireless sensing data. In this framework, each edge device owns an individual local L-model to transform its sensing data into an intermediate vector with relatively low dimensions, which is then transmitted to a coordinating edge device for final output via a common downstream S-model. By considering a human motion recognition task, experimental results show that our vertical FEEL based approach achieves recognition accuracy up to 98\% with an improvement up to 8\% compared to the benchmarks, including on-device training and horizontal FEEL.      
### 14.DDPG-Driven Deep-Unfolding with Adaptive Depth for Channel Estimation with Sparse Bayesian Learning  [ :arrow_down: ](https://arxiv.org/pdf/2201.08477.pdf)
>  Deep-unfolding neural networks (NNs) have received great attention since they achieve satisfactory performance with relatively low complexity. Typically, these deep-unfolding NNs are restricted to a fixed-depth for all inputs. However, the optimal number of layers required for convergence changes with different inputs. In this paper, we first develop a framework of deep deterministic policy gradient (DDPG)-driven deep-unfolding with adaptive depth for different inputs, where the trainable parameters of deep-unfolding NN are learned by DDPG, rather than updated by the stochastic gradient descent algorithm directly. Specifically, the optimization variables, trainable parameters, and architecture of deep-unfolding NN are designed as the state, action, and state transition of DDPG, respectively. Then, this framework is employed to deal with the channel estimation problem in massive multiple-input multiple-output systems. Specifically, first of all we formulate the channel estimation problem with an off-grid basis and develop a sparse Bayesian learning (SBL)-based algorithm to solve it. Secondly, the SBL-based algorithm is unfolded into a layer-wise structure with a set of introduced trainable parameters. Thirdly, the proposed DDPG-driven deep-unfolding framework is employed to solve this channel estimation problem based on the unfolded structure of the SBL-based algorithm. To realize adaptive depth, we design the halting score to indicate when to stop, which is a function of the channel reconstruction error. Furthermore, the proposed framework is extended to realize the adaptive depth of the general deep neural networks (DNNs). Simulation results show that the proposed algorithm outperforms the conventional optimization algorithms and DNNs with fixed depth with much reduced number of layers.      
### 15.SoftDropConnect (SDC) -- Effective and Efficient Quantification of the Network Uncertainty in Deep MR Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2201.08418.pdf)
>  Recently, deep learning has achieved remarkable successes in medical image analysis. Although deep neural networks generate clinically important predictions, they have inherent uncertainty. Such uncertainty is a major barrier to report these predictions with confidence. In this paper, we propose a novel yet simple Bayesian inference approach called SoftDropConnect (SDC) to quantify the network uncertainty in medical imaging tasks with gliomas segmentation and metastases classification as initial examples. Our key idea is that during training and testing SDC modulates network parameters continuously so as to allow affected information processing channels still in operation, instead of disabling them as Dropout or DropConnet does. When compared with three popular Bayesian inference methods including Bayes By Backprop, Dropout, and DropConnect, our SDC method (SDC-W after optimization) outperforms the three competing methods with a substantial margin. Quantitatively, our proposed method generates results withsubstantially improved prediction accuracy (by 10.0%, 5.4% and 3.7% respectively for segmentation in terms of dice score; by 11.7%, 3.9%, 8.7% on classification in terms of test accuracy) and greatly reduced uncertainty in terms of mutual information (by 64%, 33% and 70% on segmentation; 98%, 88%, and 88% on classification). Our approach promises to deliver better diagnostic performance and make medical AI imaging more explainable and trustworthy.      
### 16.Steerable Pyramid Transform Enables Robust Left Ventricle Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2201.08388.pdf)
>  Although multifarious variants of convolutional neural networks (CNNs) have proved successful in cardiac index quantification, they seem vulnerable to mild input perturbations, e.g., spatial transformations, image distortions, and adversarial attacks. Such brittleness erodes our trust in CNN-based automated diagnosis of various cardiovascular diseases. In this work, we describe a simple and effective method to learn robust CNNs for left ventricle (LV) quantification, including cavity and myocardium areas, directional dimensions, and regional wall thicknesses. The key to the success of our approach is the use of the biologically-inspired steerable pyramid transform (SPT) as fixed front-end processing, which brings three computational advantages to LV quantification. First, the basis functions of SPT match the anatomical structure of the LV as well as the geometric characteristics of the estimated indices. Second, SPT enables sharing a CNN across different orientations as a form of parameter regularization, and explicitly captures the scale variations of the LV in a natural way. Third, the residual highpass subband can be conveniently discarded to further encourage robust feature learning. A concise and effective metric, named Robustness Ratio, is proposed to evaluate the robustness under various input perturbations. Extensive experiments on 145 cardiac sequences show that our SPT-augmented method performs favorably against state-of-the-art algorithms in terms of prediction accuracy, but is significantly more robust under input perturbations.      
### 17.Improving Specificity in Mammography Using Cross-correlation between Wavelet and Fourier Transform  [ :arrow_down: ](https://arxiv.org/pdf/2201.08385.pdf)
>  Breast cancer is in the most common malignant tumor in women. It accounted for 30% of new malignant tumor cases. Although the incidence of breast cancer remains high around the world, the mortality rate has been continuously reduced. This is mainly due to recent developments in molecular biology technology and improved level of comprehensive diagnosis and standard treatment. Early detection by mammography is an integral part of that. The most common breast abnormalities that may indicate breast cancer are masses and calcifications. Previous detection approaches usually obtain relatively high sensitivity but unsatisfactory specificity. We will investigate an approach that applies the discrete wavelet transform and Fourier transform to parse the images and extracts statistical features that characterize an image's content, such as the mean intensity and the skewness of the intensity. A naive Bayesian classifier uses these features to classify the images. We expect to achieve an optimal high specificity.      
### 18.Skyline variations allow estimating distance to trees on landscape photos using semantic segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2201.08816.pdf)
>  Approximate distance estimation can be used to determine fundamental landscape properties including complexity and openness. We show that variations in the skyline of landscape photos can be used to estimate distances to trees on the horizon. A methodology based on the variations of the skyline has been developed and used to investigate potential relationships with the distance to skyline objects. The skyline signal, defined by the skyline height expressed in pixels, was extracted for several Land Use/Cover Area frame Survey (LUCAS) landscape photos. Photos were semantically segmented with DeepLabV3+ trained with the Common Objects in Context (COCO) dataset. This provided pixel-level classification of the objects forming the skyline. A Conditional Random Fields (CRF) algorithm was also applied to increase the details of the skyline signal. Three metrics, able to capture the skyline signal variations, were then considered for the analysis. These metrics shows a functional relationship with distance for the class of trees, whose contours have a fractal nature. In particular, regression analysis was performed against 475 ortho-photo based distance measurements, and, in the best case, a R2 score equal to 0.47 was achieved. This is an encouraging result which shows the potential of skyline variation metrics for inferring distance related information.      
### 19.Hairpin RF Resonators for Transceiver Arrays with High Inter-channel Isolation and B1 Efficiency at Ultrahigh Field 7T MR Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2201.08794.pdf)
>  Sufficient electromagnetic decoupling among resonant elements in RF array coils is required to maintain the integrity of the magnetic flux density map from individual channel at ultra-high field magnetic resonance imaging. A close-fitting or high-density transceiver array for augmented performance in parallel imaging and imaging quality, leads to strong coupling between elements of the array making the decoupling a very challenging task at ultra-high fields. High impedance RF coils have demonstrated to be a prominent design method to circumvent these coupling issues. However, inherent characteristics of these coils have ramification on the B1 field efficiency and SNR or the complexity of the design. In this work, we propose a hairpin RF coil, a simple design based on high impedance technique that provides excellent decoupling performance and superior RF magnetic field efficiency compared to the current state high impedance coils. In order to validate the feasibility of the proposed hairpin RF coils, systematical studies on decoupling performance, field distribution, and SNR are performed, and the results are compared with those obtained from one high impedance RF coil namely self-decoupled RF coil. To investigate the proposed hairpin RF coil design, a 7T 8-channel head coil array using hairpin resonators is built and evaluated. The MR imaging results in a cylindrical phantom obtained from the 8-channel array demonstrated a 13 % increase in SNR field intensity of the hairpin design compared to the self-decoupled coils at 7T under the same circumstance. Furthermore, the characteristics of the hairpin RF coils are evaluated using a more realistic human head voxel model in ANSYS HFSS.      
### 20.Mitigating Smart Jammers in MU-MIMO via Joint Channel Estimation and Data Detection  [ :arrow_down: ](https://arxiv.org/pdf/2201.08778.pdf)
>  Wireless systems must be resilient to jamming attacks. Existing mitigation methods require knowledge of the jammer's transmit characteristics. However, this knowledge may be difficult to acquire, especially for smart jammers that attack only specific instants during transmission in order to evade mitigation. We propose a novel method that mitigates attacks by smart jammers on massive multi-user multiple-input multiple-output (MU-MIMO) basestations (BSs). Our approach builds on recent progress in joint channel estimation and data detection (JED) and exploits the fact that a jammer cannot change its subspace within a coherence interval. Our method, called MAED (short for MitigAtion, Estimation, and Detection), uses a novel problem formulation that combines jammer estimation and mitigation, channel estimation, and data detection, instead of separating these tasks. We solve the problem approximately with an efficient iterative algorithm. Our results show that MAED effectively mitigates a wide range of smart jamming attacks without having any a priori knowledge about the attack type.      
### 21.Low-Interception Waveform: To Prevent the Recognition of Spectrum Waveform Modulation via Adversarial Examples  [ :arrow_down: ](https://arxiv.org/pdf/2201.08731.pdf)
>  Deep learning is applied to many complex tasks in the field of wireless communication, such as modulation recognition of spectrum waveforms, because of its convenience and efficiency. This leads to the problem of a malicious third party using a deep learning model to easily recognize the modulation format of the transmitted waveform. Some existing works address this problem directly using the concept of adversarial examples in the image domain without fully considering the characteristics of the waveform transmission in the physical world. Therefore, we propose a low-intercept waveform~(LIW) generation method that can reduce the probability of the modulation being recognized by a third party without affecting the reliable communication of the friendly party. Our LIW exhibits significant low-interception performance even in the physical hardware experiment, decreasing the accuracy of the state of the art model to approximately $15\%$ with small perturbations.      
### 22.Clipped DeepControl: deep neural network two-dimensional pulse design with an amplitude constraint layer  [ :arrow_down: ](https://arxiv.org/pdf/2201.08668.pdf)
>  Advanced radio-frequency pulse design used in magnetic resonance imaging has recently been demonstrated with deep learning of (convolutional) neural networks and reinforcement learning. For two-dimensionally selective radio-frequency pulses, the (convolutional) neural network pulse prediction time (few milliseconds) was in comparison more than three orders of magnitude faster than the conventional optimal control computation. The network pulses were from the supervised training capable of compensating scan-subject dependent inhomogeneities of B0 and B+1 fields. Unfortunately, the network presented with a non-negligible percentage of pulse amplitude overshoots in the test subset, despite the optimal control pulses used in training were fully constrained. Here, we have extended the convolutional neural network with a custom-made clipping layer that completely eliminates the risk of pulse amplitude overshoots, while preserving the ability to compensate the inhomogeneous field conditions.      
### 23.The Security of Deep Learning Defences for Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2201.08661.pdf)
>  Deep learning has shown great promise in the domain of medical image analysis. Medical professionals and healthcare providers have been adopting the technology to speed up and enhance their work. These systems use deep neural networks (DNN) which are vulnerable to adversarial samples; images with imperceivable changes that can alter the model's prediction. Researchers have proposed defences which either make a DNN more robust or detect the adversarial samples before they do harm. However, none of these works consider an informed attacker which can adapt to the defence mechanism. We show that an informed attacker can evade five of the current state of the art defences while successfully fooling the victim's deep learning model, rendering these defences useless. We then suggest better alternatives for securing healthcare DNNs from such attacks: (1) harden the system's security and (2) use digital signatures.      
### 24.On the adaptation of recurrent neural networks for system identification  [ :arrow_down: ](https://arxiv.org/pdf/2201.08660.pdf)
>  This paper presents a transfer learning approach which enables fast and efficient adaptation of Recurrent Neural Network (RNN) models of dynamical systems. A nominal RNN model is first identified using available measurements. The system dynamics are then assumed to change, leading to an unacceptable degradation of the nominal model performance on the perturbed system. To cope with the mismatch, the model is augmented with an additive correction term trained on fresh data from the new dynamic regime. The correction term is learned through a Jacobian Feature Regression (JFR) method defined in terms of the features spanned by the model's Jacobian with respect to its nominal parameters. A non-parametric view of the approach is also proposed, which extends recent work on Gaussian Process (GP) with Neural Tangent Kernel (NTK-GP) to the RNN case (RNTK-GP). This can be more efficient for very large networks or when only few data points are available. Implementation aspects for fast and efficient computation of the correction term, as well as the initial state estimation for the RNN model are described. Numerical examples show the effectiveness of the proposed methodology in presence of significant system variations.      
### 25.First electrical White Rabbit absolute calibration inter-comparison  [ :arrow_down: ](https://arxiv.org/pdf/2201.08640.pdf)
>  A time transfer link consisting of PTP White Rabbit (PTP-WR) devices can transfer time with sub-nanosecond accuracy. Originally White Rabbit devices were calibrated as a set of two devices. Progress in calibration makes individual absolute calibrated PTP-WR devices possible. This enables exchange of PTP-WR devices without the need for expensive in-situ end-to-end calibrations. <br>Electrical absolute calibration is the basis of absolute calibration. It calibrates the time relationship between the internal timestamp and the external electrical time reference plane. In this paper we examine the electrical time transfer accuracy when a link is setup using electrical absolute calibrated PTP-WR devices calibrated by different laboratories.      
### 26.Training Hybrid Classical-Quantum Classifiers via Stochastic Variational Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2201.08629.pdf)
>  Quantum machine learning has emerged as a potential practical application of near-term quantum devices. In this work, we study a two-layer hybrid classical-quantum classifier in which a first layer of quantum stochastic neurons implementing generalized linear models (QGLMs) is followed by a second classical combining layer. The input to the first, hidden, layer is obtained via amplitude encoding in order to leverage the exponential size of the fan-in of the quantum neurons in the number of qubits per neuron. To facilitate implementation of the QGLMs, all weights and activations are binary. While the state of the art on training strategies for this class of models is limited to exhaustive search and single-neuron perceptron-like bit-flip strategies, this letter introduces a stochastic variational optimization approach that enables the joint training of quantum and classical layers via stochastic gradient descent. Experiments show the advantages of the approach for a variety of activation functions implemented by QGLM neurons.      
### 27.Quantitative phase and refractive index imaging of 3D objects via optical transfer function reshaping  [ :arrow_down: ](https://arxiv.org/pdf/2201.08594.pdf)
>  Deconvolution phase microscopy enables high-contrast visualization of transparent samples through reconstructions of their transmitted phases or refractive indexes. Herein, we propose a method to extend 2D deconvolution phase microscopy to thick 3D samples. The refractive index distribution of a sample can be obtained at a specific axial plane by measuring only four intensity images obtained under optimized illumination patterns. Also, the optical phase delay of a sample can be measured using different illumination patterns.      
### 28.Computation of Regions of Attraction for Hybrid Limit Cycles Using Reachability: An Application to Walking Robots  [ :arrow_down: ](https://arxiv.org/pdf/2201.08538.pdf)
>  Contact-rich robotic systems, such as legged robots and manipulators, are often represented as hybrid systems. However, the stability analysis and region-of-attraction computation for these systems are often challenging because of the discontinuous state changes upon contact (also referred to as state resets). In this work, we cast the computation of region-ofattraction as a Hamilton-Jacobi (HJ) reachability problem. This enables us to leverage HJ reachability tools that are compatible with general nonlinear system dynamics, and can formally deal with state and input constraints as well as bounded disturbances. Our main contribution is the generalization of HJ reachability framework to account for the discontinuous state changes originating from state resets, which has remained a challenge until now. We apply our approach for computing region-of-attractions for several underactuated walking robots and demonstrate that the proposed approach can (a) recover a bigger region-of-attraction than state-of-the-art approaches, (b) handle state resets, nonlinear dynamics, external disturbances, and input constraints, and (c) also provides a stabilizing controller for the system that can leverage the state resets for enhancing system stability.      
### 29.Spatiotemporal Analysis Using Riemannian Composition of Diffusion Operators  [ :arrow_down: ](https://arxiv.org/pdf/2201.08530.pdf)
>  Multivariate time-series have become abundant in recent years, as many data-acquisition systems record information through multiple sensors simultaneously. In this paper, we assume the variables pertain to some geometry and present an operator-based approach for spatiotemporal analysis. Our approach combines three components that are often considered separately: (i) manifold learning for building operators representing the geometry of the variables, (ii) Riemannian geometry of symmetric positive-definite matrices for multiscale composition of operators corresponding to different time samples, and (iii) spectral analysis of the composite operators for extracting different dynamic modes. We propose a method that is analogous to the classical wavelet analysis, which we term Riemannian multi-resolution analysis (RMRA). We provide some theoretical results on the spectral analysis of the composite operators, and we demonstrate the proposed method on simulations and on real data.      
### 30.Can Machines Generate Personalized Music? A Hybrid Favorite-aware Method for User Preference Music Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2201.08526.pdf)
>  User preference music transfer (UPMT) is a new problem in music style transfer that can be applied to many scenarios but remains understudied.      
### 31.Orthonormal Sketches for Secure Coded Regression}  [ :arrow_down: ](https://arxiv.org/pdf/2201.08522.pdf)
>  In this work, we propose a method for speeding up linear regression distributively, while ensuring security. We leverage randomized sketching techniques, and improve straggler resilience in asynchronous systems. Specifically, we apply a random orthonormal matrix and then subsample in \textit{blocks}, to simultaneously secure the information and reduce the dimension of the regression problem. In our setup, the transformation corresponds to an encoded encryption in an \textit{approximate} gradient coding scheme, and the subsampling corresponds to the responses of the non-straggling workers; in a centralized coded computing network. We focus on the special case of the \textit{Subsampled Randomized Hadamard Transform}, which we generalize to block sampling; and discuss how it can be used to secure the data. We illustrate the performance through numerical experiments.      
### 32.Unmanned Aerial Vehicle Swarm-Enabled Edge Computing: Potentials, Promising Technologies, and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2201.08517.pdf)
>  Unmanned aerial vehicle (UAV) swarm enabled edge computing is envisioned to be promising in the sixth generation wireless communication networks due to their wide application sensories and flexible deployment. However, most of the existing works focus on edge computing enabled by a single or a small scale UAVs, which are very different from UAV swarm-enabled edge computing. In order to facilitate the practical applications of UAV swarm-enabled edge computing, the state of the art research is presented in this article. The potential applications, architectures and implementation considerations are illustrated. Moreover, the promising enabling technologies for UAV swarm-enabled edge computing are discussed. Furthermore, we outline challenges and open issues in order to shed light on the future research directions.      
### 33.How does unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis  [ :arrow_down: ](https://arxiv.org/pdf/2201.08514.pdf)
>  Self-training, a semi-supervised learning algorithm, leverages a large amount of unlabeled data to improve learning when the labeled data are limited. Despite empirical successes, its theoretical characterization remains elusive. To the best of our knowledge, this work establishes the first theoretical analysis for the known iterative self-training paradigm and proves the benefits of unlabeled data in both training convergence and generalization ability. To make our theoretical analysis feasible, we focus on the case of one-hidden-layer neural networks. However, theoretical understanding of iterative self-training is non-trivial even for a shallow neural network. One of the key challenges is that existing neural network landscape analysis built upon supervised learning no longer holds in the (semi-supervised) self-training paradigm. We address this challenge and prove that iterative self-training converges linearly with both convergence rate and generalization accuracy improved in the order of $1/\sqrt{M}$, where $M$ is the number of unlabeled samples. Experiments from shallow neural networks to deep neural networks are also provided to justify the correctness of our established theoretical insights on self-training.      
### 34.alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty quantification from exoplanet astrometry to black hole feature extraction  [ :arrow_down: ](https://arxiv.org/pdf/2201.08506.pdf)
>  Inference is crucial in modern astronomical research, where hidden astrophysical features and patterns are often estimated from indirect and noisy measurements. Inferring the posterior of hidden features, conditioned on the observed measurements, is essential for understanding the uncertainty of results and downstream scientific interpretations. Traditional approaches for posterior estimation include sampling-based methods and variational inference. However, sampling-based methods are typically slow for high-dimensional inverse problems, while variational inference often lacks estimation accuracy. In this paper, we propose alpha-DPI, a deep learning framework that first learns an approximate posterior using alpha-divergence variational inference paired with a generative neural network, and then produces more accurate posterior samples through importance re-weighting of the network samples. It inherits strengths from both sampling and variational inference methods: it is fast, accurate, and scalable to high-dimensional problems. We apply our approach to two high-impact astronomical inference problems using real data: exoplanet astrometry and black hole feature extraction.      
### 35.Deep reinforcement learning under signal temporal logic constraints using Lagrangian relaxation  [ :arrow_down: ](https://arxiv.org/pdf/2201.08504.pdf)
>  Deep reinforcement learning (DRL) has attracted much attention as an approach to solve sequential decision making problems without mathematical models of systems or environments. In general, a constraint may be imposed on the decision making. In this study, we consider the optimal decision making problems with constraints to complete temporal high-level tasks in the continuous state-action domain. We describe the constraints using signal temporal logic (STL), which is useful for time sensitive control tasks since it can specify continuous signals within a bounded time interval. To deal with the STL constraints, we introduce an extended constrained Markov decision process (CMDP), which is called a $\tau$-CMDP. We formulate the STL constrained optimal decision making problem as the $\tau$-CMDP and propose a two-phase constrained DRL algorithm using the Lagrangian relaxation method. Through simulations, we also demonstrate the learning performance of the proposed algorithm.      
### 36.Kinit Classification in Ethiopian Chants, Azmaris and Modern Music: A New Dataset and CNN Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2201.08448.pdf)
>  In this paper, we create EMIR, the first-ever Music Information Retrieval dataset for Ethiopian music. EMIR is freely available for research purposes and contains 600 sample recordings of Orthodox Tewahedo chants, traditional Azmari songs and contemporary Ethiopian secular music. Each sample is classified by five expert judges into one of four well-known Ethiopian Kinits, Tizita, Bati, Ambassel and Anchihoye. Each Kinit uses its own pentatonic scale and also has its own stylistic characteristics. Thus, Kinit classification needs to combine scale identification with genre recognition. After describing the dataset, we present the Ethio Kinits Model (EKM), based on VGG, for classifying the EMIR clips. In Experiment 1, we investigated whether Filterbank, Mel-spectrogram, Chroma, or Mel-frequency Cepstral coefficient (MFCC) features work best for Kinit classification using EKM. MFCC was found to be superior and was therefore adopted for Experiment 2, where the performance of EKM models using MFCC was compared using three different audio sample lengths. 3s length gave the best results. In Experiment 3, EKM and four existing models were compared on the EMIR dataset: AlexNet, ResNet50, VGG16 and LSTM. EKM was found to have the best accuracy (95.00%) as well as the fastest training time. We hope this work will encourage others to explore Ethiopian music and to experiment with other models for Kinit classification.      
### 37.Learning Estimates At The Edge Using Intermittent And Aged Measurement Updates  [ :arrow_down: ](https://arxiv.org/pdf/2201.08020.pdf)
>  Cyber Physical Systems (CPS) applications have agents that actuate in their local vicinity, while requiring measurements that capture the state of their larger environment to make actuation choices. These measurements are made by sensors and communicated over a network as update packets. Network resource constraints dictate that updates arrive at an agent intermittently and be aged on their arrival. This can be alleviated by providing an agent with a fast enough rate of estimates of the measurements. <br>Often works on estimation assume knowledge of the dynamic model of the system being measured. However, as CPS applications become pervasive, such information may not be available in practice. In this work, we propose a novel deep neural network architecture that leverages Long Short Term Memory (LSTM) networks to learn estimates in a model-free setting using only updates received over the network. We detail an online algorithm that enables training of our architecture. <br>The architecture is shown to provide good estimates of measurements of both a linear and a non-linear dynamic system. It learns good estimates even when the learning proceeds over a generic network setting in which the distributions that govern the rate and age of received measurements may change significantly over time. We demonstrate the efficacy of the architecture by comparing it with the baselines of the Time-varying Kalman Filter and the Unscented Kalman Filter. The architecture enables empirical insights with regards to maintaining the ages of updates at the estimator, which are used by it and also the baselines.      
### 38.CapillaryNet: An Automated System to Quantify Skin Capillary Density and Red Blood Cell Velocity from Handheld Vital Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2104.11574.pdf)
>  Capillaries are the smallest vessels in the body responsible for delivering oxygen and nutrients to surrounding cells. Various life-threatening diseases are known to alter the density of healthy capillaries and the flow velocity of erythrocytes within the capillaries. In previous studies, capillary density and flow velocity were manually assessed by trained specialists. However, manual analysis of a standard 20-second microvascular video requires 20 minutes on average and necessitates extensive training. Thus, manual analysis has been reported to hinder the application of microvascular microscopy in a clinical environment. To address this problem, this paper presents a fully automated state-of-the-art system to quantify skin nutritive capillary density and red blood cell velocity captured by handheld-based microscopy videos. The proposed method combines the speed of traditional computer vision algorithms with the accuracy of convolutional neural networks to enable clinical capillary analysis. The results show that the proposed system fully automates capillary detection with an accuracy exceeding that of trained analysts and measures several novel microvascular parameters that had eluded quantification thus far, namely, capillary hematocrit and intracapillary flow velocity heterogeneity. The proposed end-to-end system, named CapillaryNet, can detect capillaries at $\sim$0.9 seconds per frame with $\sim$93\% accuracy. The system is currently being used as a clinical research product in a larger e-health application to analyse capillary data captured from patients suffering from COVID-19, pancreatitis, and acute heart diseases. CapillaryNet narrows the gap between the analysis of microcirculation images in a clinical environment and state-of-the-art systems.      
