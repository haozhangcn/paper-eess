# ArXiv eess --Fri, 28 Jan 2022
### 1.PRNU Based Source Camera Identification for Webcam and Smartphone Videos  [ :arrow_down: ](https://arxiv.org/pdf/2201.11737.pdf)
>  This communication is about an application of image forensics where we use camera sensor fingerprints to identify source camera (SCI: Source Camera Identification) in webcam/smartphone videos. Sensor or camera fingerprints are based on computing the intrinsic noise that is always present in this kind of sensors due to manufacturing imperfections. This is an unavoidable characteristic that links each sensor with its noise pattern. PRNU (Photo Response Non-Uniformity) has become the default technique to compute a camera fingerprint. There are many applications nowadays dealing with PRNU patterns for camera identification using still images. In this work we focus on video, first on webcam video and afterwards on smartphone video. Webcams and smartphones are the most used video cameras nowadays. Three possible methods for SCI are implemented and assessed in this work.      
### 2.Change Detection of Markov Kernels with Unknown Post Change Kernel using Maximum Mean Discrepancy  [ :arrow_down: ](https://arxiv.org/pdf/2201.11722.pdf)
>  In this paper, we develop a new change detection algorithm for detecting a change in the Markov kernel over a metric space in which the post-change kernel is unknown. Under the assumption that the pre- and post-change Markov kernel is geometrically ergodic, we derive an upper bound on the mean delay and a lower bound on the mean time between false alarms.      
### 3.Simplicial Convolutional Filters  [ :arrow_down: ](https://arxiv.org/pdf/2201.11720.pdf)
>  We study linear filters for processing signals supported on abstract topological spaces modeled as simplicial complexes, which may be interpreted as generalizations of graphs that account for nodes, edges, triangular faces etc. To process such signals, we develop simplicial convolutional filters defined as matrix polynomials of the lower and upper Hodge Laplacians. First, we study the properties of these filters and show that they are linear and shift-invariant, as well as permutation and orientation equivariant. These filters can also be implemented in a distributed fashion with a low computational complexity, as they involve only (multiple rounds of) simplicial shifting between upper and lower adjacent simplices. Second, focusing on edge-flows, we study the frequency responses of these filters and examine how we can use the Hodge-decomposition to delineate gradient, curl and harmonic frequencies. We discuss how these frequencies correspond to the lower- and the upper-adjacent couplings and the kernel of the Hodge Laplacian, respectively, and can be tuned independently by our filter designs. Third, we study different procedures for designing simplicial convolutional filters and discuss their relative advantages. Finally, we corroborate our simplicial filters in several applications: to extract different frequency components of a simplicial signal, to denoise edge flows, and to analyze financial markets and traffic networks.      
### 4.Matched Illumination  [ :arrow_down: ](https://arxiv.org/pdf/2201.11700.pdf)
>  In previous work, it was shown that a camera can theoretically be made more colorimetric - its RGBs become more linearly related to XYZ tristimuli - by placing a specially designed color filter in the optical path. While the prior art demonstrated the principle, the optimal color-correction filters were not actually manufactured. In this paper, we provide a novel way of creating the color filtering effect without making a physical filter: we modulate the spectrum of the light source by using a spectrally tunable lighting system to recast the prefiltering effect from a lighting perspective. According to our method, if we wish to measure color under a D65 light, we relight the scene with a modulated D65 spectrum where the light modulation mimics the effect of color prefiltering in the prior art. We call our optimally modulated light, the matched illumination. In the experiments, using synthetic and real measurements, we show that color measurement errors can be reduced by about 50% or more on simulated data and 25% or more on real images when the matched illumination is used.      
### 5.Towards Data-driven LQR with KoopmanizingFlows  [ :arrow_down: ](https://arxiv.org/pdf/2201.11640.pdf)
>  We propose a novel framework for learning linear time-invariant (LTI) models for a class of continuous-time non-autonomous nonlinear dynamics based on a representation of Koopman operators. In general, the operator is infinite-dimensional but, crucially, linear. To utilize it for efficient LTI control, we learn a finite representation of the Koopman operator that is linear in controls while concurrently learning meaningful lifting coordinates. For the latter, we rely on KoopmanizingFlows - a diffeomorphism-based representation of Koopman operators. With such a learned model, we can replace the nonlinear infinite-horizon optimal control problem with quadratic costs to that of a linear quadratic regulator (LQR), facilitating efficacious optimal control for nonlinear systems. The prediction and control efficacy of the proposed method is verified on simulation examples.      
### 6.Automatic Classification of Neuromuscular Diseases in Children Using Photoacoustic Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2201.11630.pdf)
>  Neuromuscular diseases (NMDs) cause a significant burden for both healthcare systems and society. They can lead to severe progressive muscle weakness, muscle degeneration, contracture, deformity and progressive disability. The NMDs evaluated in this study often manifest in early childhood. As subtypes of disease, e.g. Duchenne Muscular Dystropy (DMD) and Spinal Muscular Atrophy (SMA), are difficult to differentiate at the beginning and worsen quickly, fast and reliable differential diagnosis is crucial. Photoacoustic and ultrasound imaging has shown great potential to visualize and quantify the extent of different diseases. The addition of automatic classification of such image data could further improve standard diagnostic procedures. We compare deep learning-based 2-class and 3-class classifiers based on VGG16 for differentiating healthy from diseased muscular tissue. This work shows promising results with high accuracies above 0.86 for the 3-class problem and can be used as a proof of concept for future approaches for earlier diagnosis and therapeutic monitoring of NMDs.      
### 7.Internal language model estimation through explicit context vector learning for attention-based encoder-decoder ASR  [ :arrow_down: ](https://arxiv.org/pdf/2201.11627.pdf)
>  An end-to-end (E2E) speech recognition model implicitly learns a biased internal language model (ILM) during training. To fused an external LM during inference, the scores produced by the biased ILM need to be estimated and subtracted. In this paper we propose two novel approaches to estimate the biased ILM based on Listen-Attend-Spell (LAS) models. The simpler method is to replace the context vector of the LAS decoder at every time step with a learnable vector. The other more advanced method is to use a simple feed-forward network to directly map query vectors to context vectors, making the generation of the context vectors independent of the LAS encoder. Both the learnable vector and the mapping network are trained on the transcriptions of the training data to minimize the perplexity while all the other parameters of the LAS model is fixed. Experiments show that the ILMs estimated by the proposed methods achieve the lowest perplexity. In addition, they also significantly outperform the shallow fusion method and two previously proposed Internal Language Model Estimation (ILME) approaches on multiple datasets.      
### 8.Analysis and Optimization of the Latency Budget in Wireless Systems with Mobile Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2201.11590.pdf)
>  We present a framework to analyse the latency budget in wireless systems with Mobile Edge Computing (MEC). Our focus is on teleoperation and telerobotics, as use cases that are representative of mission-critical uplink-intensive IoT systems with requirements on low latency and high reliability. The study is motivated by a general question: What is the optimal compression strategy in reliability and latency constrained systems? We address this question by studying the latency of an uplink connection from a multi-sensor IoT device to the base station. This is a critical link tasked with a timely and reliable transfer of potentially significant amount of data from the multitude of sensors. We introduce a comprehensive model for the latency budget, incorporating data compression and data transmission. The uplink latency is a random variable whose distribution depends on the computational capabilities of the device and on the properties of the wireless link. We formulate two optimization problems corresponding to two transmission strategies: (1) Outage-constrained, and (2) Latency-constrained. We derive the optimal system parameters under a reliability criterion. We show that the obtained results are superior compared to the ones based on the optimization of the expected latency.      
### 9.Synthesizing Dysarthric Speech Using Multi-talker TTS for Dysarthric Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2201.11571.pdf)
>  Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech recognition (ASR) systems may help dysarthric talkers communicate more effectively. To have robust dysarthria-specific ASR, sufficient training speech is required, which is not readily available. Recent advances in Text-To-Speech (TTS) synthesis multi-speaker end-to-end TTS systems suggest the possibility of using synthesis for data augmentation. In this paper, we aim to improve multi-speaker end-to-end TTS systems to synthesize dysarthric speech for improved training of a dysarthria-specific DNN-HMM ASR. In the synthesized speech, we add dysarthria severity level and pause insertion mechanisms to other control parameters such as pitch, energy, and duration. Results show that a DNN-HMM model trained on additional synthetic dysarthric speech achieves WER improvement of 12.2% compared to the baseline, the addition of the severity level and pause insertion controls decrease WER by 6.5%, showing the effectiveness of adding these parameters. Audio samples are available at      
### 10.Pan-Tumor CAnine cuTaneous Cancer Histology (CATCH) Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2201.11446.pdf)
>  Due to morphological similarities, the differentiation of histologic sections of cutaneous tumors into individual subtypes can be challenging. Recently, deep learning-based approaches have proven their potential for supporting pathologists in this regard. However, many of these supervised algorithms require a large amount of annotated data for robust development. We present a publicly available dataset consisting of 350 whole slide images of seven different canine cutaneous tumors complemented by 12,424 polygon annotations for 13 histologic classes including seven cutaneous tumor subtypes. Regarding sample size and annotation extent, this exceeds most publicly available datasets which are oftentimes limited to the tumor area or merely provide patch-level annotations. We validated our model for tissue segmentation, achieving a class-averaged Jaccard coefficient of 0.7047, and 0.9044 for tumor in particular. For tumor subtype classification, we achieve a slide-level accuracy of 0.9857. Since canine cutaneous tumors possess various histologic homologies to human tumors, we believe that the added value of this dataset is not limited to veterinary pathology but extends to more general fields of application.      
### 11.Multi-Frame Quality Enhancement On Compressed Video Using Quantised Data of Deep Belief Networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.11389.pdf)
>  In the age of streaming and surveillance compressed video enhancement has become a problem in need of constant improvement. Here, we investigate a way of improving the Multi-Frame Quality Enhancement approach. This approach consists of making use of the frames that have the peak quality in the region to improve those that have a lower quality in that region. This approach consists of obtaining quantized data from the videos using a deep belief network. The quantized data is then fed into the MF-CNN architecture to improve the compressed video. We further investigate the impact of using a Bi-LSTM for detecting the peak quality frames. Our approach obtains better results than the first approach of the MFQE which uses an SVM for PQF detection. On the other hand, our MFQE approach does not outperform the latest version of the MQFE approach that uses a Bi-LSTM for PQF detection.      
### 12.Phase Retrieval for Radar Waveform Design  [ :arrow_down: ](https://arxiv.org/pdf/2201.11384.pdf)
>  The ability of a radar to discriminate in both range and Doppler velocity is completely characterized by the ambiguity function (AF) of its transmit waveform. Mathematically, it is obtained by correlating the waveform with its Doppler-shifted and delayed replicas. We consider the inverse problem of designing a radar transmit waveform that satisfies the specified AF magnitude. This process can be viewed as a signal reconstruction with some variation of phase retrieval methods. We provide a trust-region algorithm that minimizes a smoothed non-convex least-squares objective function to iteratively recover the underlying signal-of-interest for either time- or band-limited support. The method first approximates the signal using an iterative spectral algorithm and then refines the attained initialization based upon a sequence of gradient iterations. Our theoretical analysis shows that unique signal reconstruction is possible using signal samples no more than thrice the number of signal frequencies or time samples. Numerical experiments demonstrate that our method recovers both time- and band-limited signals from even sparsely and randomly sampled AFs with mean-square-error of $1\times 10^{-6}$ and $9\times 10^{-2}$ for the full noiseless samples and sparse noisy samples, respectively.      
### 13.Enabling Radio Sensing for Multimodal Intelligent Transportation Systems: From Virtual Testing to Immersive Testbeds  [ :arrow_down: ](https://arxiv.org/pdf/2201.11382.pdf)
>  In this paper, the necessity for application-oriented development and evaluation of Joint Communication and Sensing (JC&amp;S) applications, especially in transportation, is addressed. More specifically, an integrative evaluation chain for immersively testing JC&amp;S location capabilities, reaching from early-stage testing, over model- and scenario-enabled ray tracing simulation, to real-world evaluation (laboratory and field testing) is presented. This includes a discussion of both challenges and requirements for location-aware applications in Intelligent Transportation Systems. Within this scope, a reproducible methodology for testing sensing and localization capabilities is derived and application scenarios are presented. This includes a proposal of a scenario-based sensing evaluation using radio propagation simulation. The paper empirically discusses a proof-of-concept of the developed method given a smart parking scenario, in which a passive occupancy detection of vehicles is performed. The conducted findings underline the need for scenario-based JC&amp;S evaluation in both virtual and real-world environments and proposes consecutive research work.      
### 14.Design of Battery management system for Residential applications  [ :arrow_down: ](https://arxiv.org/pdf/2201.11346.pdf)
>  Battery management system plays an important role for modern battery-powered application such as Electric vehicles, portable electronic equipment and storage for renewable energy sources. It also increases the life-cycle of the battery, battery state and efficiency. Monitoring the state of charge of the battery is a crucial factor for battery management system. This paper deals with monitoring the state of charge of the battery along with temperature, current for Solar panel fitted with battery for residential application. Microcontroller is used for controlling purpose, analog sensors are used for sensing the parameters of voltage, current. The information of the battery is given with tabular form and shown in photograph. Battery parameters are displayed with the LCD screen.      
### 15.Few-shot Transfer Learning for Holographic Image Reconstruction using a Recurrent Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2201.11333.pdf)
>  Deep learning-based methods in computational microscopy have been shown to be powerful but in general face some challenges due to limited generalization to new types of samples and requirements for large and diverse training data. Here, we demonstrate a few-shot transfer learning method that helps a holographic image reconstruction deep neural network rapidly generalize to new types of samples using small datasets. We pre-trained a convolutional recurrent neural network on a large dataset with diverse types of samples, which serves as the backbone model. By fixing the recurrent blocks and transferring the rest of the convolutional blocks of the pre-trained model, we reduced the number of trainable parameters by ~90% compared with standard transfer learning, while achieving equivalent generalization. We validated the effectiveness of this approach by successfully generalizing to new types of samples using small holographic datasets for training, and achieved (i) ~2.5-fold convergence speed acceleration, (ii) ~20% computation time reduction per epoch, and (iii) improved reconstruction performance over baseline network models trained from scratch. This few-shot transfer learning approach can potentially be applied in other microscopic imaging methods, helping to generalize to new types of samples without the need for extensive training time and data.      
### 16.Deep Recurrent Learning for Heart Sounds Segmentation based on Instantaneous Frequency Features  [ :arrow_down: ](https://arxiv.org/pdf/2201.11320.pdf)
>  In this work, a novel stack of well-known technologies is presented to determine an automatic method to segment the heart sounds in a phonocardiogram (PCG). We will show a deep recurrent neural network (DRNN) capable of segmenting a PCG into its main components and a very specific way of extracting instantaneous frequency that will play an important role in the training and testing of the proposed model. More specifically, it involves a Long Short-Term Memory (LSTM) neural network accompanied by the Fourier Synchrosqueezed Transform (FSST) used to extract instantaneous time-frequency features from a PCG. The present approach was tested on heart sound signals longer than 5 seconds and shorter than 35 seconds from freely-available databases. This approach proved that, with a relatively small architecture, a small set of data, and the right features, this method achieved an almost state-of-the-art performance, showing an average sensitivity of 89.5%, an average positive predictive value of 89.3\% and an average accuracy of 91.3%.      
### 17.Unmixing based PAN guided fusion network for hyperspectral imagery  [ :arrow_down: ](https://arxiv.org/pdf/2201.11318.pdf)
>  The hyperspectral image (HSI) has been widely used in many applications due to its fruitful spectral information. However, the limitation of imaging sensors has reduced its spatial resolution that causes detail loss. One solution is to fuse the low spatial resolution hyperspectral image (LR-HSI) and the panchromatic image (PAN) with inverse features to get the high-resolution hyperspectral image (HR-HSI). Most of the existing fusion methods just focus on small fusion ratios like 4 or 6, which might be impractical for some large ratios' HSI and PAN image pairs. Moreover, the ill-posedness of restoring detail information in HSI with hundreds of bands from PAN image with only one band has not been solved effectively, especially under large fusion ratios. Therefore, a lightweight unmixing-based pan-guided fusion network (Pgnet) is proposed to mitigate this ill-posedness and improve the fusion performance significantly. Note that the fusion process of the proposed network is under the projected low-dimensional abundance subspace with an extremely large fusion ratio of 16. Furthermore, based on the linear and nonlinear relationships between the PAN intensity and abundance, an interpretable PAN detail inject network (PDIN) is designed to inject the PAN details into the abundance feature efficiently. Comprehensive experiments on simulated and real datasets demonstrate the superiority and generality of our method over several state-of-the-art (SOTA) methods qualitatively and quantitatively (The codes in pytorch and paddle versions and dataset could be available at <a class="link-external link-https" href="https://github.com/rs-lsl/Pgnet" rel="external noopener nofollow">this https URL</a>). (This is a improved version compared with the publication in Tgrs with the modification in the deduction of the PDIN block.)      
### 18.Low-Complexity Linear Diversity-Combining Detector for MIMO-OTFS  [ :arrow_down: ](https://arxiv.org/pdf/2201.11317.pdf)
>  This paper presents a low complexity detector for multiple-input multiple-output (MIMO) systems based on the recently proposed orthogonal time frequency space (OTFS) modulation. In the proposed detector, the copies of the transmitted symbol-vectors received through the different diversity branches (propagation paths and receive antennas) are linearly combined using the maximum ratio combining (MRC) technique to iteratively improve the signal to interference plus noise ratio (SINR) at the output of the combiner. To alleviate the performance degradation due to spatial correlation at the receiver antennas, we present a sample-based method to estimate such correlation and find the optimized combining weights for MRC from the estimated correlation matrix. The detector performance and complexity improve over the linear minimum mean square error (LMMSE) and message passing (MP) detectors proposed in the literature for MIMO-OTFS.      
### 19.Time-varying microwave photonic filter for arbitrary waveform signal-to-noise ratio improvement  [ :arrow_down: ](https://arxiv.org/pdf/2201.11285.pdf)
>  A time-varying microwave photonic filter (TV-MPF) based on stimulated Brillouin scattering (SBS) is proposed and utilized to suppress the in-band noise of broadband arbitrary microwave waveforms, thereby improving the signal-to-noise ratio (SNR). The filter-controlling signal is designed according to the signal to be filtered and drives the TV-MPF so that the passband of the filter is always aligned with the frequencies of the signal to be filtered. By continuously tracking the signal spectral component, the TV-MPF only retains the spectral components of the signal and filters out the noise other than the spectral component of the signal at the current time, so as to improve the in-band SNR of the signal to be filtered. An experiment is performed. A variety of signals with different formats and in-band SNRs are used to test the noise suppression capability of the TV-MPF, and the waveform mean-square error is calculated to quantify the improvement of the signal, demonstrating the excellent adaptability of the proposed TV-MPF to different kinds of signals.      
### 20.HistoKT: Cross Knowledge Transfer in Computational Pathology  [ :arrow_down: ](https://arxiv.org/pdf/2201.11246.pdf)
>  The lack of well-annotated datasets in computational pathology (CPath) obstructs the application of deep learning techniques for classifying medical images. %Since pathologist time is expensive, dataset curation is intrinsically difficult. Many CPath workflows involve transferring learned knowledge between various image domains through transfer learning. Currently, most transfer learning research follows a model-centric approach, tuning network parameters to improve transfer results over few datasets. In this paper, we take a data-centric approach to the transfer learning problem and examine the existence of generalizable knowledge between histopathological datasets. First, we create a standardization workflow for aggregating existing histopathological data. We then measure inter-domain knowledge by training ResNet18 models across multiple histopathological datasets, and cross-transferring between them to determine the quantity and quality of innate shared knowledge. Additionally, we use weight distillation to share knowledge between models without additional training. We find that hard to learn, multi-class datasets benefit most from pretraining, and a two stage learning framework incorporating a large source domain such as ImageNet allows for better utilization of smaller datasets. Furthermore, we find that weight distillation enables models trained on purely histopathological features to outperform models using external natural image data.      
### 21.Stochastic Identification-based Active Sensing Acousto-Ultrasound SHM Using Stationary Time Series Models  [ :arrow_down: ](https://arxiv.org/pdf/2201.11233.pdf)
>  In this work, a probabilistic damage detection and identification scheme using stochastic time series models in the context of acousto-ultrasound guided wave-based SHM is proposed, and its performance is assessed experimentally. In order to simplify the damage detection and identification process, model parameters are modified based on the singular value decomposition (SVD) as well as the principal component analysis (PCA)-based truncation approach. The modified model parameters are then used to estimate a statistical characteristic quantity that follows a chi-squared distribution. A probabilistic threshold is used instead of a user-defined margin to facilitate automatic damage detection. The method's effectiveness is assessed via multiple experiments using both metallic and composite coupons and under various damage scenarios using damage intersecting and damage non-intersecting paths. The results of the study confirm the high potential and effectiveness of the stochastic time series methods for guided wave-based damage detection and identification in a potentially automated way.      
### 22.Implementation of Advanced Wind Turbine Controllers for Scaled Turbine Testing in a Wind Tunnel  [ :arrow_down: ](https://arxiv.org/pdf/2201.11198.pdf)
>  Based on a series of two experimental campaigns testing advanced controllers on a scaled wind turbine operating in a wind tunnel, this contribution describes the overall experimental method, challenges faced, lessons learned, and opportunities for future work. The two campaigns, run in Fall 2018 and Fall 2019, tested unconstrained and constrained optimal blade pitch controllers, respectively, using preview disturbance measurements of the oncoming wind. Specifically, the first study considered an extension to the linear-quadratic regulator to include feedforward action, while the second deployed model predictive control to incorporate actuator constraints into the optimal control problem. The results of the campaigns have already been published in technical conference and journal papers on control systems; however, detail on how the controllers were implemented was not included in those works. We aim to fill that gap with this contribution, which is targeted at the wind energy community. We describe several aspects of the experimental setup, in particular providing details of the software and hardware used for the controller; share insight on several aspects of the procedure that were difficult and how we overcame those challenges; and summarize the key differences between simulation-based studies and physical testing. By doing so, we hope to share what we learned during our experimental campaigns and provide a point of reference for others looking to carry out experiments on scaled wind turbines operating in wind tunnel facilities.      
### 23.Extending the Use of MDL for High-Dimensional Problems: Variable Selection, Robust Fitting, and Additive Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2201.11171.pdf)
>  In the signal processing and statistics literature, the minimum description length (MDL) principle is a popular tool for choosing model complexity. Successful examples include signal denoising and variable selection in linear regression, for which the corresponding MDL solutions often enjoy consistent properties and produce very promising empirical results. This paper demonstrates that MDL can be extended naturally to the high-dimensional setting, where the number of predictors $p$ is larger than the number of observations $n$. It first considers the case of linear regression, then allows for outliers in the data, and lastly extends to the robust fitting of nonparametric additive models. Results from numerical experiments are presented to demonstrate the efficiency and effectiveness of the MDL approach.      
### 24.Grid-friendly Matching Control of Synchronous Machines by DC/AC Converters in Bulk Power Networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.11649.pdf)
>  An islanded inverter-based microgrid is a collection of heterogeneous DC energy resources, e.g., photovoltaic arrays, fuel cells, and energy-storage devices, interfaced to an AC distribution network and operated independently from the bulk power system. Energy conversion is typically managed by power electronics in voltage source inverters. Drawing from the control of synchronous machines in bulk power systems, different control schemes have been recently adopted in order to achieve a stable network operation. The vast majority of academic and industrial efforts opt for these strategies during real-time operation. <br>Starting with a dynamical averaged DC/AC converter model, we review different controllers by presenting their main scope analytically and through simulations. Next, we explore a new alternative of controlling DC/AC converters in bulk power systems by matching traditional synchronous machines with emphasis on the role that DC-circuit can play in control architecture, usually neglected in conventional strategies. Compared to standard emulation methods, our controller relies solely on readily available DC-side measurements and takes into account the natural DC and AC storage elements. As a result, our controller is generally faster and less vulnerable to delays and measurement inaccuracies. We additionally provide insightful interpretations of the suggested control, various plug-and-play properties of the closed-loop, such as steady-state power flow analysis, passivity with respect to the DC and AC ports, stability proof as well as high-level control architectures contributing to enhancing the controller performance and attaining further control goals, which we illustrate in both analysis and simulation.      
### 25.Asymmetric Coded Caching for Multi-Antenna Location-Dependent Content Delivery  [ :arrow_down: ](https://arxiv.org/pdf/2201.11611.pdf)
>  Efficient usage of in-device storage and computation capabilities are key solutions to support data-intensive applications such as immersive digital experience. This paper proposes a location-dependent multi-antenna coded caching -based content delivery scheme tailored specifically for wireless immersive viewing applications. First, a memory assignment phase is performed where the content relevant to the identified wireless bottleneck areas are incentivized. As a result, unequal fractions of location-dependent multimedia content are cached at each user. Then, a novel packet generation process is carried out given asymmetric cache placement. During the subsequent delivery phase, the number of packets transmitted to each user is the same, while the sizes of the packets are proportional to the corresponding location-dependent cache ratios. Finally, each user is served with location-specific content using joint multicast beamforming and multi-rate modulation scheme that simultaneously benefits from global caching and spatial multiplexing gains. Numerical experiments and mathematical analysis demonstrate significant performance gains compared to the state-of-the-art.      
### 26.Total variation-based phase retrieval for diffraction tomography  [ :arrow_down: ](https://arxiv.org/pdf/2201.11579.pdf)
>  In optical diffraction tomography (ODT), the three-dimensional scattering potential of a microscopic object rotating around its center is recovered by a series of illuminations with coherent light. Reconstruction algorithms such as the filtered backpropagation require knowledge of the complex-valued wave at the measurement plane, whereas often only intensities, i.e., phaseless measurements, are available in practice. <br>We propose a new reconstruction approach for ODT with unknown phase information based on three key ingredients. First, the light propagation is modeled using Born's approximation enabling us to use the Fourier diffraction theorem. Second, we stabilize the inversion of the non-uniform discrete Fourier transform via total variation regularization utilizing a primal-dual iteration, which also yields a novel numerical inversion formula for ODT with known phase. The third ingredient is a hybrid input-output scheme. We achieved convincing numerical results, which indicate that ODT with phaseless data is possible. The so-obtained 2D and 3D reconstructions are even comparable to the ones with known phase.      
### 27.ASOC: Adaptive Self-aware Object Co-localization  [ :arrow_down: ](https://arxiv.org/pdf/2201.11547.pdf)
>  The primary goal of this paper is to localize objects in a group of semantically similar images jointly, also known as the object co-localization problem. Most related existing works are essentially weakly-supervised, relying prominently on the neighboring images' weak-supervision. Although weak supervision is beneficial, it is not entirely reliable, for the results are quite sensitive to the neighboring images considered. In this paper, we combine it with a self-awareness phenomenon to mitigate this issue. By self-awareness here, we refer to the solution derived from the image itself in the form of saliency cue, which can also be unreliable if applied alone. Nevertheless, combining these two paradigms together can lead to a better co-localization ability. Specifically, we introduce a dynamic mediator that adaptively strikes a proper balance between the two static solutions to provide an optimal solution. Therefore, we call this method \textit{ASOC}: Adaptive Self-aware Object Co-localization. We perform exhaustive experiments on several benchmark datasets and validate that weak-supervision supplemented with self-awareness has superior performance outperforming several compared competing methods.      
### 28.Eye-focused Detection of Bell's Palsy in Videos  [ :arrow_down: ](https://arxiv.org/pdf/2201.11479.pdf)
>  In this paper, we present how Bell's Palsy, a neurological disorder, can be detected just from a subject's eyes in a video. We notice that Bell's Palsy patients often struggle to blink their eyes on the affected side. As a result, we can observe a clear contrast between the blinking patterns of the two eyes. Although previous works did utilize images/videos to detect this disorder, none have explicitly focused on the eyes. Most of them require the entire face. One obvious advantage of having an eye-focused detection system is that subjects' anonymity is not at risk. Also, our AI decisions based on simple blinking patterns make them explainable and straightforward. Specifically, we develop a novel feature called blink similarity, which measures the similarity between the two blinking patterns. Our extensive experiments demonstrate that the proposed feature is quite robust, for it helps in Bell's Palsy detection even with very few labels. Our proposed eye-focused detection system is not only cheaper but also more convenient than several existing methods.      
### 29.The MSXF TTS System for ICASSP 2022 ADD Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2201.11400.pdf)
>  This paper presents our MSXF TTS system for Task 3.1 of the Audio Deep Synthesis Detection (ADD) Challenge 2022. We use an end to end text to speech system, and add a constraint loss to the system when training stage. The end to end TTS system is VITS, and the pre-training self-supervised model is wav2vec 2.0. And we also explore the influence of the speech speed and volume in spoofing. The faster speech means the less the silence part in audio, the easier to fool the detector. We also find the smaller the volume, the better spoofing ability, though we normalize volume for submission. Our team is identified as C2, and we got the fourth place in the challenge.      
### 30.Capacity of First Arrival Position Channel in Diffusion-Based Molecular Communication  [ :arrow_down: ](https://arxiv.org/pdf/2201.11383.pdf)
>  In [1], the impulse response of the first arrival position (FAP) channel of 2D and 3D spaces in molecular communication (MC) is derived, but its Shannon capacity remains open. The main difficulty of depicting the FAP channel capacity comes from the fact that the FAP density becomes a multi-dimensional Cauchy distribution when the drift velocity approaches zero. As a result, the commonly used techniques in maximizing the mutual information no longer work because the first and second moments of Cauchy distributions do not exist. <br>Our main contribution in this paper is a complete characterization of the zero-drift FAP channel capacity for the 2D and 3D spaces. The capacity formula for FAP channel turns out to have a similar form compared to the Gaussian channel case (under second-moment power constraint). It is also worth mentioning that the capacity value of 3D FAP channel is twice as large as 2D FAP channel. This is an evidence that the FAP channel has larger capacity as the spatial dimension grows. Finally, our technical contributions are the application of a modified logarithmic constraint as a replacement of the usual power constraint, and the choice of output signal constraint as a substitution to input signal constraint in order to keep the resulting formula concise.      
### 31.Benchmarking learned non-Cartesian k-space trajectories and reconstruction networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.11356.pdf)
>  We benchmark the current existing methods to jointly learn non-Cartesian k-space trajectory and reconstruction: PILOT, BJORK, and compare them with those obtained from the recently developed generalized hybrid learning (HybLearn) framework. We present the advantages of using projected gradient descent to enforce MR scanner hardware constraints as compared to using added penalties in the cost function. Further, we use the novel HybLearn scheme to jointly learn and compare our results through a retrospective study on fastMRI validation dataset.      
### 32.Iteratively Weighted MMSE Uplink Precoding for Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2201.11299.pdf)
>  In this paper, we investigate a cell-free massive MIMO system with both access points and user equipments equipped with multiple antennas over the Weichselberger Rayleigh fading channel. We study the uplink spectral efficiency (SE) based on a two-layer decoding structure with maximum ratio (MR) or local minimum mean-square error (MMSE) combining applied in the first layer and optimal large-scale fading decoding method implemented in the second layer, respectively. To maximize the weighted sum SE, an uplink precoding structure based on an Iteratively Weighted sum-MMSE (I-WMMSE) algorithm using only channel statistics is proposed. Furthermore, with MR combining applied in the first layer, we derive novel achievable SE expressions and optimal precoding structures in closed-form. Numerical results validate our proposed results and show that the I-WMMSE precoding can achieve excellent sum SE performance.      
### 33.Network Slicing with MEC and Deep Reinforcement Learning for the Internet of Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2201.11295.pdf)
>  The interconnection of vehicles in the future fifth generation (5G) wireless ecosystem forms the so-called Internet of vehicles (IoV). IoV offers new kinds of applications requiring delay-sensitive, compute-intensive and bandwidth-hungry services. Mobile edge computing (MEC) and network slicing (NS) are two of the key enabler technologies in 5G networks that can be used to optimize the allocation of the network resources and guarantee the diverse requirements of IoV applications. <br>As traditional model-based optimization techniques generally end up with NP-hard and strongly non-convex and non-linear mathematical programming formulations, in this paper, we introduce a model-free approach based on deep reinforcement learning (DRL) to solve the resource allocation problem in MEC-enabled IoV network based on network slicing. Furthermore, the solution uses non-orthogonal multiple access (NOMA) to enable a better exploitation of the scarce channel resources. The considered problem addresses jointly the channel and power allocation, the slice selection and the vehicles selection (vehicles grouping). We model the problem as a single-agent Markov decision process. Then, we solve it using DRL using the well-known DQL algorithm. We show that our approach is robust and effective under different network conditions compared to benchmark solutions.      
### 34.Online Change Point Detection for Weighted and Directed Random Dot Product Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2201.11222.pdf)
>  Given a sequence of random (directed and weighted) graphs, we address the problem of online monitoring and detection of changes in the underlying data distribution. Our idea is to endow sequential change-point detection (CPD) techniques with a graph representation learning substrate based on the versatile Random Dot Product Graph (RDPG) model. We consider efficient, online updates of a judicious monitoring function, which quantifies the discrepancy between the streaming graph observations and the nominal RDPG. This reference distribution is inferred via spectral embeddings of the first few graphs in the sequence. We characterize the distribution of this running statistic to select thresholds that guarantee error-rate control, and under simplifying approximations we offer insights on the algorithm's detection resolution and delay. The end result is a lightweight online CPD algorithm, that is also explainable by virtue of the well-appreciated interpretability of RDPG embeddings. This is in stark contrast with most existing graph CPD approaches, which either rely on extensive computation, or they store and process the entire observed time series. An apparent limitation of the RDPG model is its suitability for undirected and unweighted graphs only, a gap we aim to close here to broaden the scope of the CPD framework. Unlike previous proposals, our non-parametric RDPG model for weighted graphs does not require a priori specification of the weights' distribution to perform inference and estimation. This network modeling contribution is of independent interest beyond CPD. We offer an open-source implementation of the novel online CPD algorithm for weighted and direct graphs, whose effectiveness and efficiency are demonstrated via (reproducible) synthetic and real network data experiments.      
### 35.Learning Mixtures of Linear Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2201.11211.pdf)
>  We study the problem of learning a mixture of multiple linear dynamical systems (LDSs) from unlabeled short sample trajectories, each generated by one of the LDS models. Despite the wide applicability of mixture models for time-series data, learning algorithms that come with end-to-end performance guarantees are largely absent from existing literature. There are multiple sources of technical challenges, including but not limited to (1) the presence of latent variables (i.e. the unknown labels of trajectories); (2) the possibility that the sample trajectories might have lengths much smaller than the dimension $d$ of the LDS models; and (3) the complicated temporal dependence inherent to time-series data. To tackle these challenges, we develop a two-stage meta-algorithm, which is guaranteed to efficiently recover each ground-truth LDS model up to error $\tilde{O}(\sqrt{d/T})$, where $T$ is the total sample size. We validate our theoretical studies with numerical experiments, confirming the efficacy of the proposed algorithm.      
### 36.On The Energy Statistics of Feature Maps in Pruning of Neural Networks with Skip-Connections  [ :arrow_down: ](https://arxiv.org/pdf/2201.11209.pdf)
>  We propose a new structured pruning framework for compressing Deep Neural Networks (DNNs) with skip connections, based on measuring the statistical dependency of hidden layers and predicted outputs. The dependence measure defined by the energy statistics of hidden layers serves as a model-free measure of information between the feature maps and the output of the network. The estimated dependence measure is subsequently used to prune a collection of redundant and uninformative layers. Model-freeness of our measure guarantees that no parametric assumptions on the feature map distribution are required, making it computationally appealing for very high dimensional feature space in DNNs. Extensive numerical experiments on various architectures show the efficacy of the proposed pruning approach with competitive performance to state-of-the-art methods.      
### 37.Discovering Phonetic Inventories with Crosslingual Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2201.11207.pdf)
>  The high cost of data acquisition makes Automatic Speech Recognition (ASR) model training problematic for most existing languages, including languages that do not even have a written script, or for which the phone inventories remain unknown. Past works explored multilingual training, transfer learning, as well as zero-shot learning in order to build ASR systems for these low-resource languages. While it has been shown that the pooling of resources from multiple languages is helpful, we have not yet seen a successful application of an ASR model to a language unseen during training. A crucial step in the adaptation of ASR from seen to unseen languages is the creation of the phone inventory of the unseen language. The ultimate goal of our work is to build the phone inventory of a language unseen during training in an unsupervised way without any knowledge about the language. In this paper, we 1) investigate the influence of different factors (i.e., model architecture, phonotactic model, type of speech representation) on phone recognition in an unknown language; 2) provide an analysis of which phones transfer well across languages and which do not in order to understand the limitations of and areas for further improvement for automatic phone inventory creation; and 3) present different methods to build a phone inventory of an unseen language in an unsupervised way. To that end, we conducted mono-, multi-, and crosslingual experiments on a set of 13 phonetically diverse languages and several in-depth analyses. We found a number of universal phone tokens (IPA symbols) that are well-recognized cross-linguistically. Through a detailed analysis of results, we conclude that unique sounds, similar sounds, and tone languages remain a major challenge for phonetic inventory discovery.      
### 38.DIREG3D: DIrectly REGress 3D Hands from Multiple Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2201.11187.pdf)
>  In this paper, we present DIREG3D, a holistic framework for 3D Hand Tracking. The proposed framework is capable of utilizing camera intrinsic parameters, 3D geometry, intermediate 2D cues, and visual information to regress parameters for accurately representing a Hand Mesh model. Our experiments show that information like the size of the 2D hand, its distance from the optical center, and radial distortion is useful for deriving highly reliable 3D poses in camera space from just monocular information. Furthermore, we extend these results to a multi-view camera setup by fusing features from different viewpoints.      
### 39.Rapid solution for searching similar audio items  [ :arrow_down: ](https://arxiv.org/pdf/2201.11178.pdf)
>  A naive approach for finding similar audio items would be to compare each entry from the feature vector of the test example with each feature vector of the candidates in a k-nearest neighbors fashion. There are already two problems with this approach: audio signals are represented by high dimensional vectors and the number of candidates can be very large - think thousands. The search process would have a high complexity. Our paper will treat this problem through hashing methodologies more specifically the Locality Sensitive Hashing. This project will be in the spirit of classification and clustering problems. The computer sound production principles will be used to determine which features that describe an audio signal are the most useful. That will down-sample the size of the feature vectors and speed up the process subsequently.      
### 40.Tackling data scarcity in speech translation using zero-shot multilingual machine translation techniques  [ :arrow_down: ](https://arxiv.org/pdf/2201.11172.pdf)
>  Recently, end-to-end speech translation (ST) has gained significant attention as it avoids error propagation. However, the approach suffers from data scarcity. It heavily depends on direct ST data and is less efficient in making use of speech transcription and text translation data, which is often more easily available. In the related field of multilingual text translation, several techniques have been proposed for zero-shot translation. A main idea is to increase the similarity of semantically similar sentences in different languages. We investigate whether these ideas can be applied to speech translation, by building ST models trained on speech transcription and text translation data. We investigate the effects of data augmentation and auxiliary loss function. The techniques were successfully applied to few-shot ST using limited ST data, with improvements of up to +12.9 BLEU points compared to direct end-to-end ST and +3.1 BLEU points compared to ST models fine-tuned from ASR model.      
### 41.Policy Optimization over Submanifolds for Constrained Feedback Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2201.11157.pdf)
>  In this paper, we study linearly constrained policy optimizations over the manifold of Schur stabilizing controllers, equipped with a Riemannian metric that emerges naturally in the context of optimal control problems. We provide extrinsic analysis of a generic constrained smooth cost function, that subsequently facilitates subsuming any such constrained problem into this framework. By studying the second order geometry of this manifold, we provide a Newton-type algorithm with local convergence guarantees that exploits this inherent geometry without relying on the exponential mapping nor a retraction. The algorithm hinges instead upon the developed stability certificate and the linear structure of the constraints. We then apply our methodology to two well-known constrained optimal control problems. Finally, several numerical examples showcase the performance of the proposed algorithm.      
### 42.Asymptotics for Outlier Hypothesis Testing  [ :arrow_down: ](https://arxiv.org/pdf/2201.09200.pdf)
>  We revisit the outlier hypothesis testing framework of Li \emph{et al.} (TIT 2014) and derive fundamental limits for the optimal test. In outlier hypothesis testing, one is given multiple observed sequences, where most sequences are generated i.i.d. from a nominal distribution. The task is to discern the set of outlying sequences that are generated according to anomalous distributions. The nominal and anomalous distributions are \emph{unknown}. We consider the case of multiple outliers where the number of outliers is unknown and each outlier can follow a different anomalous distribution. Under this setting, we study the tradeoff among the probabilities of misclassification error, false alarm and false reject. Specifically, we propose a threshold-based test that ensures exponential decay of misclassification error and false alarm probabilities. We study two constraints on the false reject probability, with one constraint being that it is a non-vanishing constant and the other being that it has an exponential decay rate. For both cases, we characterize bounds on the false reject probability, as a function of the threshold, for each tuple of nominal and anomalous distributions. Finally, we demonstrate the asymptotic optimality of our test under the generalized Neyman-Pearson criterion.      
