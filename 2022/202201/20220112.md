# ArXiv eess --Wed, 12 Jan 2022
### 1.Spectrum Surveying: Active Radio Map Estimation with Autonomous UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2201.04125.pdf)
>  Radio maps find numerous applications in wireless communications and mobile robotics tasks, including resource allocation, interference coordination, and mission planning. Although numerous techniques have been proposed to construct radio maps from spatially distributed measurements, the locations of such measurements are assumed predetermined beforehand. In contrast, this paper proposes spectrum surveying, where a mobile robot such as an unmanned aerial vehicle (UAV) collects measurements at a set of locations that are actively selected to obtain high-quality map estimates in a short surveying time. This is performed in two steps. First, two novel algorithms, a model-based online Bayesian estimator and a data-driven deep learning algorithm, are devised for updating a map estimate and an uncertainty metric that indicates the informativeness of measurements at each possible location. These algorithms offer complementary benefits and feature constant complexity per measurement. Second, the uncertainty metric is used to plan the trajectory of the UAV to gather measurements at the most informative locations. To overcome the combinatorial complexity of this problem, a dynamic programming approach is proposed to obtain lists of waypoints through areas of large uncertainty in linear time. Numerical experiments conducted on a realistic dataset confirm that the proposed scheme constructs accurate radio maps quickly.      
### 2.Improving ECG Classification Interpretability using Saliency Maps  [ :arrow_down: ](https://arxiv.org/pdf/2201.04070.pdf)
>  Cardiovascular disease is a large worldwide healthcare issue; symptoms often present suddenly with minimal warning. The electrocardiogram (ECG) is a fast, simple and reliable method of evaluating the health of the heart, by measuring electrical activity recorded through electrodes placed on the skin. ECGs often need to be analyzed by a cardiologist, taking time which could be spent on improving patient care and outcomes. Because of this, automatic ECG classification systems using machine learning have been proposed, which can learn complex interactions between ECG features and use this to detect abnormalities. However, algorithms built for this purpose often fail to generalize well to unseen data, reporting initially impressive results which drop dramatically when applied to new environments. Additionally, machine learning algorithms suffer a "black-box" issue, in which it is difficult to determine how a decision has been made. This is vital for applications in healthcare, as clinicians need to be able to verify the process of evaluation in order to trust the algorithm. This paper proposes a method for visualizing model decisions across each class in the MIT-BIH arrhythmia dataset, using adapted saliency maps averaged across complete classes to determine what patterns are being learned. We do this by building two algorithms based on state-of-the-art models. This paper highlights how these maps can be used to find problems in the model which could be affecting generalizability and model performance. Comparing saliency maps across complete classes gives an overall impression of confounding variables or other biases in the model, unlike what would be highlighted when comparing saliency maps on an ECG-by-ECG basis.      
### 3.A novel method for error analysis in radiation thermometry with application to industrial furnaces  [ :arrow_down: ](https://arxiv.org/pdf/2201.04069.pdf)
>  Accurate temperature measurements are essential for the proper monitoring and control of industrial furnaces. However, measurement uncertainty is a risk for such a critical parameter. Certain instrumental and environmental errors must be considered when using spectral-band radiation thermometry techniques, such as the uncertainty in the emissivity of the target surface, reflected radiation from surrounding objects, or atmospheric absorption and emission, to name a few. Undesired contributions to measured radiation can be isolated using measurement models, also known as error-correction models. This paper presents a methodology for budgeting significant sources of error and uncertainty during temperature measurements in a petrochemical furnace scenario. A continuous monitoring system is also presented, aided by a deep-learning-based measurement correction model, to allow domain experts to analyze the furnace's operation in real-time. To validate the proposed system's functionality, a real-world application case in a petrochemical plant is presented. The proposed solution demonstrates the viability of precise industrial furnace monitoring, thereby increasing operational security and improving the efficiency of such energy-intensive systems.      
### 4.ExBrainable: An Open-Source GUI for CNN-based EEG Decoding and Model Interpretation  [ :arrow_down: ](https://arxiv.org/pdf/2201.04065.pdf)
>  We have developed a graphic user interface (GUI), ExBrainable, dedicated to convolutional neural networks (CNN) model training and visualization in electroencephalography (EEG) decoding. Available functions include model training, evaluation, and parameter visualization in terms of temporal and spatial representations. We demonstrate these functions using a well-studied public dataset of motor-imagery EEG and compare the results with existing knowledge of neuroscience. The primary objective of ExBrainable is to provide a fast, simplified, and user-friendly solution of EEG decoding for investigators across disciplines to leverage cutting-edge methods in brain/neuroscience research.      
### 5.VR Viewport Pose Model for Quantifying and Exploiting Frame Correlations  [ :arrow_down: ](https://arxiv.org/pdf/2201.04060.pdf)
>  The importance of the dynamics of the viewport pose, i.e., location and orientation of users' points of view, for virtual reality (VR) experiences calls for the development of VR viewport pose models. In this paper, informed by our experimental measurements of viewport trajectories in 3 VR games and across 3 different types of VR interfaces, we first develop a statistical model of viewport poses in VR environments. Based on the developed model, we examine the correlations between pixels in VR frames that correspond to different viewport poses, and obtain an analytical expression for the visibility similarity (ViS) of the pixels across different VR frames. We then propose a lightweight ViS-based ALG-ViS algorithm that adaptively splits VR frames into background and foreground, reusing the background across different frames. Our implementation of ALG-ViS in two Oculus Quest 2 rendering systems demonstrates ALG-ViS running in real time, supporting the full VR frame rate, and outperforming baselines on measures of frame quality and bandwidth consumption.      
### 6.Development and Virtual Testing of 5G Connected Adaptive Cruise Control  [ :arrow_down: ](https://arxiv.org/pdf/2201.04052.pdf)
>  It is estimated that 90% of crashes occur due to human error, mainly induced by poor judgement, distraction or lack of situation awareness. The development of systems that aim to increase road safety and to improve driving comfort is the key challenge that many OEMs are currently tackling. The use of fast and reliable of innovative communication technologies such as 5G can enhance advancements and developments in the field of ADAS. The aim of the paper is the study of the potential improvements connectivity can bring to ACC systems in terms of safety and vehicle comfort. Starting from state-of-art ACC present in literature, a novel connected ACC is designed and deeply reported. The main features of the algorithms consist in integrating information about other road vehicles fed by 5G and about potential grip given by smart sensors such as Pirelli Cyber Tyre. The novel solution is then compared to the standard ACC by means of several simulations considering two real traffic situations with different road friction coefficients. Finally benefits and limitations of the proposed algorithm are deeply discussed.      
### 7.Image quality measurements and denoising using Fourier Ring Correlations  [ :arrow_down: ](https://arxiv.org/pdf/2201.03992.pdf)
>  Image quality is a nebulous concept with different meanings to different people. To quantify image quality a relative difference is typically calculated between a corrupted image and a ground truth image. But what metric should we use for measuring this difference? Ideally, the metric should perform well for both natural and scientific images. The structural similarity index (SSIM) is a good measure for how humans perceive image similarities, but is not sensitive to differences that are scientifically meaningful in microscopy. In electron and super-resolution microscopy, the Fourier Ring Correlation (FRC) is often used, but is little known outside of these fields. Here we show that the FRC can equally well be applied to natural images, e.g. the Google Open Images dataset. We then define a loss function based on the FRC, show that it is analytically differentiable, and use it to train a U-net for denoising of images. This FRC-based loss function allows the network to train faster and achieve similar or better results than when using L1- or L2- based losses. We also investigate the properties and limitations of neural network denoising with the FRC analysis.      
### 8.Electric vehicle charge scheduling with flexible service operations  [ :arrow_down: ](https://arxiv.org/pdf/2201.03972.pdf)
>  Driven by climate change, rising environmental awareness, and financial incentives, more and more commercial fleets transition to electric vehicles. However, this endeavor remains challenging as time-inefficient charge operations and lack of public charging infrastructure require fleet operators to invest into additional private on-premise charging stations. Here, grid capacity constraints and investment cost limit the number of available charging stations such that charging bottlenecks may arise. Accordingly, efficient scheduling of charge and service operations becomes inevitable to realize profitable fleets. Creating the underlying schedules constitutes a challenging optimization problem, especially when additional factors, such as battery degradation, variable energy prices, and non-linear battery behavior need to be considered. In this paper, we study the resulting joint charge and service operations scheduling problem, that combines the scheduling of vehicle service operations and charge scheduling. We propose an exact algorithm based on branch &amp; price to solve this problem. This algorithm bases on an exact labeling algorithm developed for a novel resource constrained shortest path problem, which models our pricing problem, and leverages a custom branching rule and a primal heuristic to accelerate the branch &amp; bound phase. We benchmark our algorithm in a comprehensive numerical study and show that it can solve realistic problem instances with computational times below one hour, thus enabling its application in practice. Additionally, we analyze the benefit of jointly scheduling charging and service operations in practice. We find that our integrated approach lowers the amount of charging infrastructure required for fleet operation by up to 57% besides enabling cost savings of up to 5%.      
### 9.Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.03943.pdf)
>  State-of-the-art automatic speech recognition (ASR) system development is data and computation intensive. The optimal design of deep neural networks (DNNs) for these systems often require expert knowledge and empirical evaluation. In this paper, a range of neural architecture search (NAS) techniques are used to automatically learn two types of hyper-parameters of factored time delay neural networks (TDNN-Fs): i) the left and right splicing context offsets; and ii) the dimensionality of the bottleneck linear projection at each hidden layer. These techniques include the differentiable neural architecture search (DARTS) method integrating architecture learning with lattice-free MMI training; Gumbel-Softmax and pipelined DARTS methods reducing the confusion over candidate architectures and improving the generalization of architecture selection; and Penalized DARTS incorporating resource constraints to balance the trade-off between performance and system complexity. Parameter sharing among TDNN-F architectures allows an efficient search over up to 7^28 different systems. Statistically significant word error rate (WER) reductions of up to 1.2% absolute and relative model size reduction of 31% were obtained over a state-of-the-art 300-hour Switchboard corpus trained baseline LF-MMI TDNN-F system featuring speed perturbation, i-Vector and learning hidden unit contribution (LHUC) based speaker adaptation as well as RNNLM rescoring. Performance contrasts on the same task against recent end-to-end systems reported in the literature suggest the best NAS auto-configured system achieves state-of-the-art WERs of 9.9% and 11.1% on the NIST Hub5' 00 and Rt03s test sets respectively with up to 96% model size reduction. Further analysis using Bayesian learning shows that ...      
### 10.Co-Design of Lipschitz Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2201.03886.pdf)
>  Empirical experiences have shown that simultaneous (rather than conventional sequential) plant and controller design procedure leads to an improvement in performance and saving of plant resources. Such a simultaneous synthesis procedure is called as "co-design". In this letter we study the co-design problem for a class of Lipschitz nonlinear dynamical systems having a quadratic control objective and state-feedback controller. We propose a novel time independent reformulation of the co-design optimization problem whose constraints ensure stability of the system. We also present a gradient-based co-design solution procedure which involves system coordinate transformation and whose output is provably stable solution for the original system. We show the efficacy of the solution procedure through co-design of a single-link robot.      
### 11.Learning to Enhance or Not: Neural Network-Based Switching of Enhanced and Observed Signals for Overlapping Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2201.03881.pdf)
>  The combination of a deep neural network (DNN) -based speech enhancement (SE) front-end and an automatic speech recognition (ASR) back-end is a widely used approach to implement overlapping speech recognition. However, the SE front-end generates processing artifacts that can degrade the ASR performance. We previously found that such performance degradation can occur even under fully overlapping conditions, depending on the signal-to-interference ratio (SIR) and signal-to-noise ratio (SNR). To mitigate the degradation, we introduced a rule-based method to switch the ASR input between the enhanced and observed signals, which showed promising results. However, the rule's optimality was unclear because it was heuristically designed and based only on SIR and SNR values. In this work, we propose a DNN-based switching method that directly estimates whether ASR will perform better on the enhanced or observed signals. We also introduce soft-switching that computes a weighted sum of the enhanced and observed signals for ASR input, with weights given by the switching model's output posteriors. The proposed learning-based switching showed performance comparable to that of rule-based oracle switching. The soft-switching further improved the ASR performance and achieved a relative character error rate reduction of up to 23 % as compared with the conventional method.      
### 12.MR-SVS: Singing Voice Synthesis with Multi-Reference Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2201.03864.pdf)
>  Multi-speaker singing voice synthesis is to generate the singing voice sung by different speakers. To generalize to new speakers, previous zero-shot singing adaptation methods obtain the timbre of the target speaker with a fixed-size embedding from single reference audio. However, they face several challenges: 1) the fixed-size speaker embedding is not powerful enough to capture full details of the target timbre; 2) single reference audio does not contain sufficient timbre information of the target speaker; 3) the pitch inconsistency between different speakers also leads to a degradation in the generated voice. In this paper, we propose a new model called MR-SVS to tackle these problems. Specifically, we employ both a multi-reference encoder and a fixed-size encoder to encode the timbre of the target speaker from multiple reference audios. The Multi-reference encoder can capture more details and variations of the target timbre. Besides, we propose a well-designed pitch shift method to address the pitch inconsistency problem. Experiments indicate that our method outperforms the baseline method both in naturalness and similarity.      
### 13.Theoretical Performance of LoRa System in Multi-Path and Interference Channels  [ :arrow_down: ](https://arxiv.org/pdf/2201.03825.pdf)
>  This paper presents a semi-analytical approximation of Symbol Error Rate (SER) for the well known LoRa Internet of Things (IoT) modulation scheme in the following two scenarios: 1) in multi-path frequency selective fading channel with Additive White Gaussian Noise (AW GN) and 2) in the presence of a second interfering LoRa user in flat-fading AW GN channel. Performances for both coherent and non-coherent cases are derived by considering the common Discrete Fourier transform (DF T) based detector on the received LoRa waveform. By considering these two scenarios, the detector exhibits parasitic peaks that severely degrade the performance of the LoRa receiver. We propose in that sense a theoretical expression for this result, from which a unified framework based on peak detection probabilities allows us to derive SER, which is validated by Monte Carlo simulations. Fast computation of the derived closedform SER allows to carry out deep performance analysis for these two scenarios.      
### 14.COROLLA: An Efficient Multi-Modality Fusion Framework with Supervised Contrastive Learning for Glaucoma Grading  [ :arrow_down: ](https://arxiv.org/pdf/2201.03795.pdf)
>  Glaucoma is one of the ophthalmic diseases that may cause blindness, for which early detection and treatment are very important. Fundus images and optical coherence tomography (OCT) images are both widely-used modalities in diagnosing glaucoma. However, existing glaucoma grading approaches mainly utilize a single modality, ignoring the complementary information between fundus and OCT. In this paper, we propose an efficient multi-modality supervised contrastive learning framework, named COROLLA, for glaucoma grading. Through layer segmentation as well as thickness calculation and projection, retinal thickness maps are extracted from the original OCT volumes and used as a replacing modality, resulting in more efficient calculations with less memory usage. Given the high structure and distribution similarities across medical image samples, we employ supervised contrastive learning to increase our models' discriminative power with better convergence. Moreover, feature-level fusion of paired fundus image and thickness map is conducted for enhanced diagnosis accuracy. On the GAMMA dataset, our COROLLA framework achieves overwhelming glaucoma grading performance compared to state-of-the-art methods.      
### 15.Reciprocal Adversarial Learning for Brain Tumor Segmentation: A Solution to BraTS Challenge 2021 Segmentation Task  [ :arrow_down: ](https://arxiv.org/pdf/2201.03777.pdf)
>  This paper proposes an adversarial learning based training approach for brain tumor segmentation task. In this concept, the 3D segmentation network learns from dual reciprocal adversarial learning approaches. To enhance the generalization across the segmentation predictions and to make the segmentation network robust, we adhere to the Virtual Adversarial Training approach by generating more adversarial examples via adding some noise on original patient data. By incorporating a critic that acts as a quantitative subjective referee, the segmentation network learns from the uncertainty information associated with segmentation results. We trained and evaluated network architecture on the RSNA-ASNR-MICCAI BraTS 2021 dataset. Our performance on the online validation dataset is as follows: Dice Similarity Score of 81.38%, 90.77% and 85.39%; Hausdorff Distance (95\%) of 21.83 mm, 5.37 mm, 8.56 mm for the enhancing tumor, whole tumor and tumor core, respectively. Similarly, our approach achieved a Dice Similarity Score of 84.55%, 90.46% and 85.30%, as well as Hausdorff Distance (95\%) of 13.48 mm, 6.32 mm and 16.98 mm on the final test dataset. Overall, our proposed approach yielded better performance in segmentation accuracy for each tumor sub-region. Our code implementation is publicly available at <a class="link-external link-https" href="https://github.com/himashi92/vizviva_brats_2021" rel="external noopener nofollow">this https URL</a>      
### 16.An analysis of reconstruction noise from undersampled 4D flow MRI  [ :arrow_down: ](https://arxiv.org/pdf/2201.03715.pdf)
>  Novel Magnetic Resonance (MR) imaging modalities can quantify hemodynamics but require long acquisition times, precluding its widespread use for early diagnosis of cardiovascular disease. To reduce the acquisition times, reconstruction methods from undersampled measurements are routinely used, that leverage representations designed to increase image compressibility. <br>Reconstructed anatomical and hemodynamic images may present visual artifacts. Although some of these artifact are essentially reconstruction errors, and thus a consequence of undersampling, others may be due to measurement noise or the random choice of the sampled frequencies. Said otherwise, a reconstructed image becomes a random variable, and both its bias and its covariance can lead to visual artifacts; the latter leads to spatial correlations that may be misconstrued for visual information. Although the nature of the former has been studied in the literature, the latter has not received as much attention. <br>In this study, we investigate the theoretical properties of the random perturbations arising from the reconstruction process, and perform a number of numerical experiments on simulated and MR aortic flow. Our results show that the correlation length remains limited to two to three pixels when a Gaussian undersampling pattern is combined with recovery algorithms based on $\ell_1$-norm minimization. However, the correlation length may increase significantly for other undersampling patterns, higher undersampling factors (i.e., 8x or 16x compression), and different reconstruction methods.      
### 17.Robust Trajectory Tracking and Payload Delivery of a Quadrotor Under Multiple State Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2201.03711.pdf)
>  With quadrotors becoming immensely popular in applications such as relief operations, infrastructure maintenance etc., a key control design challenge arises when the quadrotor has to manoeuvre through constrained spaces during various operational scenarios: for example, inspecting a pipeline within predefined velocity and space, dropping relief material at a precise location under tight spaces etc., under the face of parametric uncertainties and external disturbances. To tackle such scenarios, a controller needs to ensure a predefined tracking accuracy so as not to violate the constraints while simultaneously tackling uncertainties and disturbances. However, state-of-the-art controllers dealing with constrained system motion are either not applicable for an underactuated system like quadrotor, or cannot tackle system uncertainties under full state constraints. This work attempts to fill such a gap in literature by designing Barrier Lyapunov Function (BLF) based robust controllers to satisfy multiple state-constraints while simultaneously negotiating parametric uncertainties and external disturbances. The superiority of the BLF control method over a typical unconstrained controller is demonstrated, followed by a robust control design to satisfy position and orientation constraints on quadrotor dynamics. Finally, full state-constraints on a quadrotor(i.e., constraints on the position, orientation, linear velocity and angular velocity) are satisfied with robust control. For each control design, the closed-loop system stability is studied analytically and the efficacy of the design is validated extensively either via realistic simulation scenarios or via experiments performed on a real quadrotor.      
### 18.Neuroplastic graph attention networks for nuclei segmentation in histopathology images  [ :arrow_down: ](https://arxiv.org/pdf/2201.03669.pdf)
>  Modern histopathological image analysis relies on the segmentation of cell structures to derive quantitative metrics required in biomedical research and clinical diagnostics. State-of-the-art deep learning approaches predominantly apply convolutional layers in segmentation and are typically highly customized for a specific experimental configuration; often unable to generalize to unknown data. As the model capacity of classical convolutional layers is limited by a finite set of learned kernels, our approach uses a graph representation of the image and focuses on the node transitions in multiple magnifications. We propose a novel architecture for semantic segmentation of cell nuclei robust to differences in experimental configuration such as staining and variation of cell types. The architecture is comprised of a novel neuroplastic graph attention network based on residual graph attention layers and concurrent optimization of the graph structure representing multiple magnification levels of the histopathological image. The modification of graph structure, which generates the node features by projection, is as important to the architecture as the graph neural network itself. It determines the possible message flow and critical properties to optimize attention, graph structure, and node updates in a balanced magnification loss. In experimental evaluation, our framework outperforms ensembles of state-of-the-art neural networks, with a fraction of the neurons typically required, and sets new standards for the segmentation of new nuclei datasets.      
### 19.Data-driven Meets Geometric Control: Zero Dynamics, Subspace Stabilization, and Malicious Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2201.03656.pdf)
>  Studying structural properties of linear dynamical systems through invariant subspaces is one of the key contributions of the geometric approach to system theory. In general, a model of the dynamics is required in order to compute the invariant subspaces of interest. In this paper we overcome this limitation by finding data-driven formulas for some of the foundational tools of geometric control. In particular, for an unknown linear system, we show how controlled and conditioned invariant subspaces can be found directly from experimental data. We use our formulas and approach to (i) find a feedback gain that confines the system state within a desired subspace, (ii) compute the invariant zeros of the unknown system, and (iii) design attacks that remain undetectable.      
### 20.3D Segmentation with Fully Trainable Gabor Kernels and Pearson's Correlation Coefficient  [ :arrow_down: ](https://arxiv.org/pdf/2201.03644.pdf)
>  The convolutional layer and loss function are two fundamental components in deep learning. Because of the success of conventional deep learning kernels, the less versatile Gabor kernels become less popular despite the fact that they can provide abundant features at different frequencies, orientations, and scales with much fewer parameters. For existing loss functions for multi-class image segmentation, there is usually a tradeoff among accuracy, robustness to hyperparameters, and manual weight selections for combining different losses. Therefore, to gain the benefits of using Gabor kernels while keeping the advantage of automatic feature generation in deep learning, we propose a fully trainable Gabor-based convolutional layer where all Gabor parameters are trainable through backpropagation. Furthermore, we propose a loss function based on the Pearson's correlation coefficient, which is accurate, robust to learning rates, and does not require manual weight selections. Experiments on 43 3D brain magnetic resonance images with 19 anatomical structures show that, using the proposed loss function with a proper combination of conventional and Gabor-based kernels, we can train a network with only 1.6 million parameters to achieve an average Dice coefficient of 83%. This size is 44 times smaller than the V-Net which has 71 million parameters. This paper demonstrates the potentials of using learnable parametric kernels in deep learning for 3D segmentation.      
### 21.Iterative RAKI with Complex-Valued Convolution for Improved Image Reconstruction with Limited Scan-Specific Training Samples  [ :arrow_down: ](https://arxiv.org/pdf/2201.03560.pdf)
>  MRI scan time reduction is commonly achieved by Parallel Imaging methods, typically based on uniform undersampling of the inverse image space (a.k.a. k-space) and simultaneous signal reception with multiple receiver coils. The GRAPPA method interpolates missing k-space signals by linear combination of adjacent, acquired signals across all coils, and can be described by a convolution in k-space. Recently, a more generalized method called RAKI was introduced. RAKI is a deep-learning method that generalizes GRAPPA with additional convolution layers, on which a non-linear activation function is applied. This enables non-linear estimation of missing signals by convolutional neural networks. In analogy to GRAPPA, the convolution kernels in RAKI are trained using scan-specific training samples obtained from auto-calibration-signals (ACS). RAKI provides superior reconstruction quality compared to GRAPPA, however, often requires much more ACS due to its increased number of unknown parameters. In order to overcome this limitation, this study investigates the influence of training data on the reconstruction quality for standard 2D imaging, with particular focus on its amount and contrast information. Furthermore, an iterative k-space interpolation approach (iRAKI) is evaluated, which includes training data augmentation via an initial GRAPPA reconstruction, and refinement of convolution filters by iterative training. Using only 18, 20 and 25 ACS lines (8%), iRAKI outperforms RAKI by suppressing residual artefacts occurring at accelerations factors R=4 and R=5, and yields strong noise suppression in comparison to GRAPPA, underlined by quantitative quality metrics. Combination with a phase-constraint yields further improvement. Additionally, iRAKI shows better performance than GRAPPA and RAKI in case of pre-scan calibration and strongly varying contrast between training- and undersampled data.      
### 22.Demonstrating The Risk of Imbalanced Datasets in Chest X-ray Image-based Diagnostics by Prototypical Relevance Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2201.03559.pdf)
>  The recent trend of integrating multi-source Chest X-Ray datasets to improve automated diagnostics raises concerns that models learn to exploit source-specific correlations to improve performance by recognizing the source domain of an image rather than the medical pathology. We hypothesize that this effect is enforced by and leverages label-imbalance across the source domains, i.e, prevalence of a disease corresponding to a source. Therefore, in this work, we perform a thorough study of the effect of label-imbalance in multi-source training for the task of pneumonia detection on the widely used ChestX-ray14 and CheXpert datasets. The results highlight and stress the importance of using more faithful and transparent self-explaining models for automated diagnosis, thus enabling the inherent detection of spurious learning. They further illustrate that this undesirable effect of learning spurious correlations can be reduced considerably when ensuring label-balanced source domain datasets.      
### 23.Creation of a Modular Soft Robotic Fish Testing Platform  [ :arrow_down: ](https://arxiv.org/pdf/2201.04098.pdf)
>  Research on the co-optimization of soft robotic design and control requires rapid means for real-world validation. Existing creation pipelines do not allow for the swift prototyping of soft robots to quickly test various design configurations and control policies. This work proposes a pipeline for rapid iterative design and fabrication of a miniaturized modular silicone-elastomer-based robotic fish. The modular design allows simple and rapid iterations of robotic fishes with varying configurations to assist current research efforts on the development of design optimization methods. The proposed robotic fish can serve as a standardized test platform on which performance metrics such as thrust and range of motion can be evaluated. We further show the design of an underwater evaluation setup capable of measuring input pressure, tail deformation, and thrust. Multiple robotic fish prototypes with varying stiffness and internal pneumatic chamber configurations are fabricated and experimentally evaluated. The presented flexible modular design principle for the robot and its evaluation platform unlocks the possibilities of more efficient soft robotic fish and will benefit research on design optimization and underwater exploration in the future.      
### 24.Identification of chicken egg fertility using SVM classifier based on first-order statistical feature extraction  [ :arrow_down: ](https://arxiv.org/pdf/2201.04063.pdf)
>  This study aims to identify chicken eggs fertility using the support vector machine (SVM) classifier method. The classification basis used the first-order statistical (FOS) parameters as feature extraction in the identification process. This research was developed based on the process's identification process, which is still manual (conventional). Although currently there are many technologies in the identification process, they still need development. Thus, this research is one of the developments in the field of image processing technology. The sample data uses datasets from previous studies with a total of 100 egg images. The egg object in the image is a single object. From these data, the classification of each fertile and infertile egg is 50 image data. Chicken egg image data became input in image processing, with the initial process is segmentation. This initial segmentation aims to get the cropped image according to the object. The cropped image is repaired using image preprocessing with grayscaling and image enhancement methods. This method (image enhancement) used two combination methods: contrast limited adaptive histogram equalization (CLAHE) and histogram equalization (HE). The improved image becomes the input for feature extraction using the FOS method. The FOS uses five parameters, namely mean, entropy, variance, skewness, and kurtosis. The five parameters entered into the SVM classifier method to identify the fertility of chicken eggs. The results of these experiments, the method proposed in the identification process has a success percentage of 84.57%. Thus, the implementation of this method can be used as a reference for future research improvements. In addition, it may be possible to use a second-order feature extraction method to improve its accuracy and improve supervised learning for classification.      
### 25.State Estimation in Electric Power Systems Leveraging Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.04056.pdf)
>  The goal of the state estimation (SE) algorithm is to estimate complex bus voltages as state variables based on the available set of measurements in the power system. Because phasor measurement units (PMUs) are increasingly being used in transmission power systems, there is a need for a fast SE solver that can take advantage of PMU high sampling rates. This paper proposes training a graph neural network (GNN) to learn the estimates given the PMU voltage and current measurements as inputs, with the intent of obtaining fast and accurate predictions during the evaluation phase. GNN is trained using synthetic datasets, created by randomly sampling sets of measurements in the power system and labelling them with a solution obtained using a linear SE with PMUs solver. The presented results display the accuracy of GNN predictions in various test scenarios and tackle the sensitivity of the predictions to the missing input data.      
### 26.LOKO: Localization-aware Roll-out Planning for Future Mobile Networks  [ :arrow_down: ](https://arxiv.org/pdf/2201.04051.pdf)
>  The roll-out phase of the next generation of mobile networks (5G) has started and operators are required to devise deployment solutions while pursuing localization accuracy maximization. Enabling location-based services is expected to be a unique selling point for service providers now able to deliver critical mobile services, e.g., autonomous driving, public safety, remote operations. In this paper, we propose a novel roll-out base station placement solution that, given a Throughput-Positioning Ratio (TPR) target, selects the location of new-generation base stations (among available candidate sites) such that the throughput and localization accuracy are jointly maximized. Moving away from the canonical position error bound (PEB) analysis, we develop a realistic framework in which each positioning measurement is affected by errors depending upon the actual wireless channel between the measuring base station and the target device. Our solution, referred to as LOKO, is a fast-converging algorithm that can be readily applied to current 5G (or future) roll-out processes. LOKO is validated by means of an exhaustive simulation campaign considering real existing deployments of a major European network operator as well as synthetic scenarios.      
### 27.Fourier Series and Transforms via Convolution  [ :arrow_down: ](https://arxiv.org/pdf/2201.03974.pdf)
>  In this paper we show an alternative way of defining Fourier Series and Transform by using the concept of convolution with exponential signals. This approach has the advantage of simplifying proofs of transforms properties and, in our view, may be interesting for educational purposes.      
### 28.Emotion Intensity and its Control for Emotional Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2201.03967.pdf)
>  Emotional voice conversion (EVC) seeks to convert the emotional state of an utterance while preserving the linguistic content and speaker identity. In EVC, emotions are usually treated as discrete categories overlooking the fact that speech also conveys emotions with various intensity levels that the listener can perceive. In this paper, we aim to explicitly characterize and control the intensity of emotion. We propose to disentangle the speaker style from linguistic content and encode the speaker style into a style embedding in a continuous space that forms the prototype of emotion embedding. We further learn the actual emotion encoder from an emotion-labelled database and study the use of relative attributes to represent fine-grained emotion intensity. To ensure emotional intelligibility, we incorporate emotion classification loss and emotion embedding similarity loss into the training of the EVC network. As desired, the proposed network controls the fine-grained emotion intensity in the output speech. Through both objective and subjective evaluations, we validate the effectiveness of the proposed network for emotional expressiveness and emotion intensity control.      
### 29.Where Is My Mind (looking at)? Predicting Visual Attention from Brain Activity  [ :arrow_down: ](https://arxiv.org/pdf/2201.03902.pdf)
>  Visual attention estimation is an active field of research at the crossroads of different disciplines: computer vision, artificial intelligence and medicine. One of the most common approaches to estimate a saliency map representing attention is based on the observed images. In this paper, we show that visual attention can be retrieved from EEG acquisition. The results are comparable to traditional predictions from observed images, which is of great interest. For this purpose, a set of signals has been recorded and different models have been developed to study the relationship between visual attention and brain activity. The results are encouraging and comparable with other approaches estimating attention with other modalities. The codes and dataset considered in this paper have been made available at \url{<a class="link-external link-https" href="https://figshare.com/s/3e353bd1c621962888ad" rel="external noopener nofollow">this https URL</a>} to promote research in the field.      
### 30.Deep Learning-Aided 6G Wireless Networks: A Comprehensive Survey of Revolutionary PHY Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2201.03866.pdf)
>  Deep learning (DL) has proven its unprecedented success in diverse fields such as computer vision, natural language processing, and speech recognition by its strong representation ability and ease of computation. As we move forward to a thoroughly intelligent society with 6G wireless networks, new applications and use-cases have been emerging with stringent requirements for next-generation wireless communications. Therefore, recent studies have focused on the potential of DL approaches in satisfying these rigorous needs and overcoming the deficiencies of existing model-based techniques. The main objective of this article is to unveil the state-of-the-art advancements in the field of DL-based physical layer (PHY) methods to pave the way for fascinating applications of 6G. In particular, we have focused our attention on four promising PHY concepts foreseen to dominate next-generation communications, namely massive multiple-input multiple-output (MIMO) systems, sophisticated multi-carrier (MC) waveform designs, reconfigurable intelligent surface (RIS)-empowered communications, and PHY security. We examine up-to-date developments in DL-based techniques, provide comparisons with state-of-the-art methods, and introduce a comprehensive guide for future directions. We also present an overview of the underlying concepts of DL, along with the theoretical background of well-known DL techniques. Furthermore, this article provides programming examples for a number of DL techniques and the implementation of a DL-based MIMO by sharing user-friendly code snippets, which might be useful for interested readers.      
### 31.Music2Video: Automatic Generation of Music Video with fusion of audio and text  [ :arrow_down: ](https://arxiv.org/pdf/2201.03809.pdf)
>  Creation of images using generative adversarial networks has been widely adapted into multi-modal regime with the advent of multi-modal representation models pre-trained on large corpus. Various modalities sharing a common representation space could be utilized to guide the generative models to create images from text or even from audio source. Departing from the previous methods that solely rely on either text or audio, we exploit the expressiveness of both modality. Based on the fusion of text and audio, we create video whose content is consistent with the distinct modalities that are provided. A simple approach to automatically segment the video into variable length intervals and maintain time consistency in generated video is part of our method. Our proposed framework for generating music video shows promising results in application level where users can interactively feed in music source and text source to create artistic music videos. Our code is available at <a class="link-external link-https" href="https://github.com/joeljang/music2video" rel="external noopener nofollow">this https URL</a>.      
### 32.Graph Neural Network Aided Expectation Propagation Detector for MU-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2201.03731.pdf)
>  Multiuser massive multiple-input multiple-output (MU-MIMO) systems can be used to meet high throughput requirements of 5G and beyond networks. In an uplink MUMIMO system, a base station is serving a large number of users, leading to a strong multi-user interference (MUI). Designing a high performance detector in the presence of a strong MUI is a challenging problem. This work proposes a novel detector based on the concepts of expectation propagation (EP) and graph neural network, referred to as the GEPNet detector, addressing the limitation of the independent Gaussian approximation in EP. The simulation results show that the proposed GEPNet detector significantly outperforms the state-of-the-art MU-MIMO detectors in strong MUI scenarios with equal number of transmit and receive antennas.      
### 33.CVSS Corpus and Massively Multilingual Speech-to-Speech Translation  [ :arrow_down: ](https://arxiv.org/pdf/2201.03713.pdf)
>  We introduce CVSS, a massively multilingual-to-English speech-to-speech translation (S2ST) corpus, covering sentence-level parallel S2ST pairs from 21 languages into English. CVSS is derived from the Common Voice speech corpus and the CoVoST 2 speech-to-text translation (ST) corpus, by synthesizing the translation text from CoVoST 2 into speech using state-of-the-art TTS systems. Two versions of translation speeches are provided: 1) CVSS-C: All the translation speeches are in a single high-quality canonical voice; 2) CVSS-T: The translation speeches are in voices transferred from the corresponding source speeches. In addition, CVSS provides normalized translation text which matches the pronunciation in the translation speech. On each version of CVSS, we built baseline multilingual direct S2ST models and cascade S2ST models, verifying the effectiveness of the corpus. To build strong cascade S2ST baselines, we trained an ST model on CoVoST 2, which outperforms the previous state-of-the-art trained on the corpus without extra data by 5.8 BLEU. Nevertheless, the performance of the direct S2ST models approaches the strong cascade baselines when trained from scratch, and with only 0.1 or 0.7 BLEU difference on ASR transcribed translation when initialized from matching ST models.      
### 34.nnDetection: A Self-configuring Method for Medical Object Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.00817.pdf)
>  Simultaneous localisation and categorization of objects in medical images, also referred to as medical object detection, is of high clinical relevance because diagnostic decisions often depend on rating of objects rather than e.g. pixels. For this task, the cumbersome and iterative process of method configuration constitutes a major research bottleneck. Recently, nnU-Net has tackled this challenge for the task of image segmentation with great success. Following nnU-Net's agenda, in this work we systematize and automate the configuration process for medical object detection. The resulting self-configuring method, nnDetection, adapts itself without any manual intervention to arbitrary medical detection problems while achieving results en par with or superior to the state-of-the-art. We demonstrate the effectiveness of nnDetection on two public benchmarks, ADAM and LUNA16, and propose 11 further medical object detection tasks on public data sets for comprehensive method evaluation. Code is at <a class="link-external link-https" href="https://github.com/MIC-DKFZ/nnDetection" rel="external noopener nofollow">this https URL</a> .      
