# ArXiv eess --Mon, 3 Jan 2022
### 1.Magnetoelectric Bio-Implants Powered and Programmed by a Single Transmitter for Coordinated Multisite Stimulation  [ :arrow_down: ](https://arxiv.org/pdf/2112.15552.pdf)
>  This article presents a hardware platform including stimulating implants wirelessly powered and controlled by a shared transmitter (TX) for coordinated leadless multisite stimulation. The adopted novel single-TX, multiple-implant structure can flexibly deploy stimuli, improve system efficiency, easily scale stimulating channel quantity, and relieve efforts in device synchronization. In the proposed system, a wireless link leveraging magnetoelectric (ME) effect is co-designed with a robust and efficient system-on-chip (SoC) to enable reliable operation and individual programming of every implant. Each implant integrates a 0.8-mm2 chip, a 6-mm2 ME film, and an energy storage capacitor within a 6.2-mm3 size. ME power transfer is capable of safely transmitting milliwatt power to devices placed several centimeters away from the TX coil, maintaining good efficiency with size constraints, and tolerating 60 degree, 1.5-cm misalignment in angular and lateral movement. The SoC robustly operates with 2-V source amplitude variations that spans a 40-mm TX-implant distance change, realizes individual addressability through physical unclonable function (PUF) IDs, and achieves 90% efficiency for 1.5-3.5-V stimulation with fully programmable stimulation parameters.      
### 2.Transfer learning for cancer diagnosis in histopathological images  [ :arrow_down: ](https://arxiv.org/pdf/2112.15523.pdf)
>  Transfer learning allows us to exploit knowledge gained from one task to assist in solving another but relevant task. In modern computer vision research, the question is which architecture performs better for a given dataset. In this paper, we compare the performance of 14 pre-trained ImageNet models on the histopathologic cancer detection dataset, where each model has been configured as a naive model, feature extractor model, or fine-tuned model. Densenet161 has been shown to have high precision whilst Resnet101 has a high recall. A high precision model is suitable to be used when follow-up examination cost is high, whilst low precision but a high recall/sensitivity model can be used when the cost of follow-up examination is low. Results also show that transfer learning helps to converge a model faster.      
### 3.Coupled Tank Non-linear System; Modeling and Level Control using PID and Fuzzy Logic Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2112.15506.pdf)
>  Liquid level control is very important in industrial field, where the liquid level is required, and to prevent overflows. The coupled-tank is a common system in industrial control processes. The system consists of two tanks connected together and the liquid flows between them. Tanks contain an inlet and outlet for each tank. The main principle of controlling this system is to maintain a constant level of liquid in both tanks when there are an inflow and outflow of liquid in each tank. To control liquid level in the coupled tank system, the mathematical model of the system had been derived and evaluated as a form of linear model. The mathematical model of coupled tank was developed to apply to both conventional and fuzzy control systems where the dynamic behavior of the system was considered. When the system had been designed the corresponding model was implemented in simulation by using Matlab and Simulink tools.      
### 4.Advanced Smart Drone Swarm Security Network by Using Strategic Alliance for Blockchain Governance Game  [ :arrow_down: ](https://arxiv.org/pdf/2112.15454.pdf)
>  This paper deals with the design of the secure network of the Advanced Smart Drone Swarm security network by using the Strategic Alliance for Blockchain Governance Game (SABGG). The SABGG is the system model of the stochastic game to find best strategies towards preparation for preventing a network malfunction by an attacker and the newly proposed adapts this innovative game model into the artificial drone swarm security. Analytically tractable solutions enable to estimate the moment of safety modes and to deliver the optimal accountability of ally drones for preventing attacks. This research helps for whom considers the advanced secure drone swarm architecture with the SABGG within a decentralized network.      
### 5.On Mathematics of Bubbles in Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15453.pdf)
>  A new concept called biased derivative is proposed. It has a potential to better understand and model some aspects of dynamical systems associated with creating bubbles.      
### 6.Efficient Single Image Super-Resolution Using Dual Path Connections with Multiple Scale Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.15386.pdf)
>  Deep convolutional neural networks have been demonstrated to be effective for SISR in recent years. On the one hand, residual connections and dense connections have been used widely to ease forward information and backward gradient flows to boost performance. However, current methods use residual connections and dense connections separately in most network layers in a sub-optimal way. On the other hand, although various networks and methods have been designed to improve computation efficiency, save parameters, or utilize training data of multiple scale factors for each other to boost performance, it either do super-resolution in HR space to have a high computation cost or can not share parameters between models of different scale factors to save parameters and inference time. To tackle these challenges, we propose an efficient single image super-resolution network using dual path connections with multiple scale learning named as EMSRDPN. By introducing dual path connections inspired by Dual Path Networks into EMSRDPN, it uses residual connections and dense connections in an integrated way in most network layers. Dual path connections have the benefits of both reusing common features of residual connections and exploring new features of dense connections to learn a good representation for SISR. To utilize the feature correlation of multiple scale factors, EMSRDPN shares all network units in LR space between different scale factors to learn shared features and only uses a separate reconstruction unit for each scale factor, which can utilize training data of multiple scale factors to help each other to boost performance, meanwhile which can save parameters and support shared inference for multiple scale factors to improve efficiency. Experiments show EMSRDPN achieves better performance and comparable or even better parameter and inference efficiency over SOTA methods.      
### 7.Weakly Supervised Change Detection Using Guided Anisotropic Difusion  [ :arrow_down: ](https://arxiv.org/pdf/2112.15367.pdf)
>  Large scale datasets created from crowdsourced labels or openly available data have become crucial to provide training data for large scale learning algorithms. While these datasets are easier to acquire, the data are frequently noisy and unreliable, which is motivating research on weakly supervised learning techniques. In this paper we propose original ideas that help us to leverage such datasets in the context of change detection. First, we propose the guided anisotropic diffusion (GAD) algorithm, which improves semantic segmentation results using the input images as guides to perform edge preserving filtering. We then show its potential in two weakly-supervised learning strategies tailored for change detection. The first strategy is an iterative learning method that combines model optimisation and data cleansing using GAD to extract the useful information from a large scale change detection dataset generated from open vector data. The second one incorporates GAD within a novel spatial attention layer that increases the accuracy of weakly supervised networks trained to perform pixel-level predictions from image-level labels. Improvements with respect to state-of-the-art are demonstrated on 4 different public datasets.      
### 8.WiSig: A Large-Scale WiFi Signal Dataset for Receiver and Channel Agnostic RF Fingerprinting  [ :arrow_down: ](https://arxiv.org/pdf/2112.15363.pdf)
>  RF fingerprinting leverages circuit-level variability of transmitters to identify them using signals they send. Signals used for identification are impacted by a wireless channel and receiver circuitry, creating additional impairments that can confuse transmitter identification. Eliminating these impairments or just evaluating them, requires data captured over a prolonged period of time, using many spatially separated transmitters and receivers. In this paper, we present WiSig; a large scale WiFi dataset containing 10 million packets captured from 174 off-the-shelf WiFi transmitters and 41 USRP receivers over 4 captures spanning a month. WiSig is publicly available, not just as raw captures, but as conveniently pre-processed subsets of limited size, along with the scripts and examples. A preliminary evaluation performed using WiSig shows that changing receivers, or using signals captured on a different day can significantly degrade a trained classifier's performance. While capturing data over more days or more receivers limits the degradation, it is not always feasible and novel data-driven approaches are needed. WiSig provides the data to develop and evaluate these approaches towards channel and receiver agnostic transmitter fingerprinting.      
### 9.Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network  [ :arrow_down: ](https://arxiv.org/pdf/2112.15362.pdf)
>  Recently, hyperspectral imaging (HSI) has attracted increasing research attention, especially for the ones based on a coded aperture snapshot spectral imaging (CASSI) system. Existing deep HSI reconstruction models are generally trained on paired data to retrieve original signals upon 2D compressed measurements given by a particular optical hardware mask in CASSI, during which the mask largely impacts the reconstruction performance and could work as a "model hyperparameter" governing on data augmentations. This mask-specific training style will lead to a hardware miscalibration issue, which sets up barriers to deploying deep HSI models among different hardware and noisy environments. To address this challenge, we introduce mask uncertainty for HSI with a complete variational Bayesian learning treatment and explicitly model it through a mask decomposition inspired by real hardware. Specifically, we propose a novel Graph-based Self-Tuning (GST) network to reason uncertainties adapting to varying spatial structures of masks among different hardware. Moreover, we develop a bilevel optimization framework to balance HSI reconstruction and uncertainty estimation, accounting for the hyperparameter property of masks. Extensive experimental results and model discussions validate the effectiveness (over 33/30 dB) of the proposed GST method under two miscalibration scenarios and demonstrate a highly competitive performance compared with the state-of-the-art well-calibrated methods. Our code and pre-trained model are available at <a class="link-external link-https" href="https://github.com/Jiamian" rel="external noopener nofollow">this https URL</a> Wang/mask_uncertainty_spectral_SCI      
### 10.An Off-grid Compressive Sensing Strategy for the Subarray Synthesis of Non-uniform Linear Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2112.15343.pdf)
>  With the increasing popularity of large-scale antenna arrays, the subarraying technology becomes more attractive. In this paper, we propose two effective subarraying methods right after formulating the subarray synthesis as a compressive sensing (CS) problem: i) Orthogonal matching pursuit based subarray synthesis (OMP-SS), a common CS approach which can be used for the subarray synthesis to attain the subarray information (the subarray number, the number of elements per subarray and corresponding excitation coeffcients) and ii) Off-grid orthogonal matching pursuit based subarray synthesis (OGOMP-SS), an advanced approach for optimizing antenna elements positions and the subarray information mentioned above simultaneously. In addition, two user-defined modes are designed for different application scenarios, wherein, mode-1 is to optimize the pattern synthesis performance for the given the number of subarrays, and mode-2 is to obtain the minimum number of subarrays for the cases when the pattern synthsis accuracy is satisfied. Finally, our simulation results reveal that it is of paramount significance to optimize antenna elements positions for the subarray synthesis performance on the one hand and demonstrate the excellent performances of proposed schemes in comparison with other competitive state-of-the-art subarray synthesis methods on the other hand.      
### 11.Systematic dispersion compensation for spectral domain optical coherence tomography using time-frequency analysis and iterative optimization for iridocorneal angle imaging  [ :arrow_down: ](https://arxiv.org/pdf/2112.15302.pdf)
>  Dispersion is a common phenomenon in optics due to the frequency dependence of the refractive index in polychromatic light. This issue, if left untreated in optical coherence tomography (OCT) imaging, leads to signal broadening of the coherence length and deterioration of the axial resolution. We report a new numeric method for the systematic dispersion compensation in a spectral-domain (SD) OCT for imaging the iridocorneal angle of human cadaver eyes. The dispersion compensation for our OCT system is calculated by an automated iterative process that minimizes the wavenumber-dependent variance of the ridge extracted from the energy distribution of a mirror's spectral interferogram using Short-Time Fourier Transform (STFT) Time-Frequency Analysis (TFA). The average axial resolution of 2.7 um in air was achieved at a range of depths up to 2 mm. Compensated OCT images of the iridocorneal angle in human cadaver eyes were much clearer than non-compensated images. We demonstrate the feasibility, effectiveness, and robustness of the proposed method for dispersion compensation in an SD-OCT by evaluating both the mirror and human cadaver eye measurements. We also verified that our imaging system is able to visualize the iridocorneal angle details, such as trabecular meshwork (TM), Schlemm's canal (SC), and collector channels (CCs), which are important ocular outflow structures and play a crucial role in glaucoma managements.      
### 12.CSformer: Bridging Convolution and Transformer for Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2112.15299.pdf)
>  Convolution neural networks (CNNs) have succeeded in compressive image sensing. However, due to the inductive bias of locality and weight sharing, the convolution operations demonstrate the intrinsic limitations in modeling the long-range dependency. Transformer, designed initially as a sequence-to-sequence model, excels at capturing global contexts due to the self-attention-based architectures even though it may be equipped with limited localization abilities. This paper proposes CSformer, a hybrid framework that integrates the advantages of leveraging both detailed spatial information from CNN and the global context provided by transformer for enhanced representation learning. The proposed approach is an end-to-end compressive image sensing method, composed of adaptive sampling and recovery. In the sampling module, images are measured block-by-block by the learned sampling matrix. In the reconstruction stage, the measurement is projected into dual stems. One is the CNN stem for modeling the neighborhood relationships by convolution, and the other is the transformer stem for adopting global self-attention mechanism. The dual branches structure is concurrent, and the local features and global representations are fused under different resolutions to maximize the complementary of features. Furthermore, we explore a progressive strategy and window-based transformer block to reduce the parameter and computational complexity. The experimental results demonstrate the effectiveness of the dedicated transformer-based architecture for compressive sensing, which achieves superior performance compared to state-of-the-art methods on different datasets.      
### 13.Stability-Preserving Automatic Tuning of PID Control with Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.15187.pdf)
>  PID control has been the dominant control strategy in the process industry due to its simplicity in design and effectiveness in controlling a wide range of processes. However, traditional methods on PID tuning often require extensive domain knowledge and field experience. To address the issue, this work proposes an automatic PID tuning framework based on reinforcement learning (RL), particularly the deterministic policy gradient (DPG) method. Different from existing studies on using RL for PID tuning, in this work, we consider the closed-loop stability throughout the RL-based tuning process. In particular, we propose a novel episodic tuning framework that allows for an episodic closed-loop operation under selected PID parameters where the actor and critic networks are updated once at the end of each episode. To ensure the closed-loop stability during the tuning, we initialize the training with a conservative but stable baseline PID controller and the resultant reward is used as a benchmark score. A supervisor mechanism is used to monitor the running reward (e.g., tracking error) at each step in the episode. As soon as the running reward exceeds the benchmark score, the underlying controller is replaced by the baseline controller as an early correction to prevent instability. Moreover, we use layer normalization to standardize the input to each layer in actor and critic networks to overcome the issue of policy saturation at action bounds, to ensure the convergence to the optimum. The developed methods are validated through setpoint tracking experiments on a second-order plus dead-time system. Simulation results show that with our scheme, the closed-loop stability can be maintained throughout RL explorations and the explored PID parameters by the RL agent converge quickly to the optimum.      
### 14.Product Form of Projection-Based Model Reduction and its Application to Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15182.pdf)
>  Orthogonal projection-based reduced order models (PROM) are the output of widely-used model reduction methods. In this work, a novel product form is derived for the reduction error system of these reduced models, and it is shown that any such PROM can be obtained from a sequence of 1-dimensional projection reductions. Investigating the error system product form, we then define interface-invariant PROMs, model order reductions with projection-invariant input and output matrices, and it is shown that for such PROMs the error product systems are strictly proper. Furthermore, exploiting this structure, an analytic $\mathcal{H}_{\infty}$ reduction error bound is obtained and an $\mathcal{H}_{\infty}$ bound optimization problem is defined. Interface-invariant reduced models are natural to graph-based model reduction of multi-agent systems where subsets of agents function as the input and output of the system. In the second part of this study, graph contractions are used as a constructive solution approach to the $\mathcal{H}_{\infty}$ bound optimization problem for multi-agent systems. Edge-based contractions are then utilized in a greedy-edge reduction algorithm and are demonstrated for the model reduction of a first-order Laplacian controlled consensus protocol.      
### 15.A Resolution Enhancement Plug-in for Deformable Registration of Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2112.15180.pdf)
>  Image registration is a fundamental task for medical imaging. Resampling of the intensity values is required during registration and better spatial resolution with finer and sharper structures can improve the resampling performance and hence the registration accuracy. Super-resolution (SR) is an algorithmic technique targeting at spatial resolution enhancement which can achieve an image resolution beyond the hardware limitation. In this work, we consider SR as a preprocessing technique and present a CNN-based resolution enhancement module (REM) which can be easily plugged into the registration network in a cascaded manner. Different residual schemes and network configurations of REM are investigated to obtain an effective architecture design of REM. In fact, REM is not confined to image registration, it can also be straightforwardly integrated into other vision tasks for enhanced resolution. The proposed REM is thoroughly evaluated for deformable registration on medical images quantitatively and qualitatively at different upscaling factors. Experiments on LPBA40 brain MRI dataset demonstrate that REM not only improves the registration accuracy, especially when the input images suffer from degraded spatial resolution, but also generates resolution enhanced images which can be exploited for successive diagnosis.      
### 16.Colour alignment for relative colour constancy via non-standard references  [ :arrow_down: ](https://arxiv.org/pdf/2112.15106.pdf)
>  Relative colour constancy is an essential requirement for many scientific imaging applications. However, most digital cameras differ in their image formations and native sensor output is usually inaccessible, e.g., in smartphone camera applications. This makes it hard to achieve consistent colour assessment across a range of devices, and that undermines the performance of computer vision algorithms. To resolve this issue, we propose a colour alignment model that considers the camera image formation as a black-box and formulates colour alignment as a three-step process: camera response calibration, response linearisation, and colour matching. The proposed model works with non-standard colour references, i.e., colour patches without knowing the true colour values, by utilising a novel balance-of-linear-distances feature. It is equivalent to determining the camera parameters through an unsupervised process. It also works with a minimum number of corresponding colour patches across the images to be colour aligned to deliver the applicable processing. Two challenging image datasets collected by multiple cameras under various illumination and exposure conditions were used to evaluate the model. Performance benchmarks demonstrated that our model achieved superior performance compared to other popular and state-of-the-art methods.      
### 17.Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15094.pdf)
>  Linear dynamical systems are canonical models for learning-based control of plants with uncertain dynamics. The setting consists of a stochastic differential equation that captures the state evolution of the plant understudy, while the true dynamics matrices are unknown and need to be learned from the observed data of state trajectory. An important issue is to ensure that the system is stabilized and destabilizing control actions due to model uncertainties are precluded as soon as possible. A reliable stabilization procedure for this purpose that can effectively learn from unstable data to stabilize the system in a finite time is not currently available. In this work, we propose a novel Bayesian learning algorithm that stabilizes unknown continuous-time stochastic linear systems. The presented algorithm is flexible and exposes effective stabilization performance after a remarkably short time period of interacting with the system.      
### 18.Elastic 3D Wavefield Simulation on budget GPUs using the GLSL shading language  [ :arrow_down: ](https://arxiv.org/pdf/2112.15071.pdf)
>  Forward wavefield simulation is an important step in Full Waveform Inversion systems. Fast simulations are instrumental to get inversion result in reasonable time frames. Most of research and software aims towards utilizing costly computer clusters composed of multiple CPUs and numerous high end GPUs to shorten the forward simulation time. Using this type of hardware has some disadvantages as: high cost, complex programming models and unavailability of resources. In this work, we present a finite difference elastic 3D wavefield forward simulation that takes advantage of any modern low end GPU, by using the GLSL shading language.Some of the advantages of using GLSL are: runs in any modern GPU, has a simplified computing and memory model and provides state of art performance thanks to its very well optimized vendor developed drivers. We show that our GLSL implementation easily outperforms a multicore CPU implementation in a modern PC. We further benchmark our result using a real seismic event, and show that we can get accurate simulations in reasonable time using our system.      
### 19.Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2112.15011.pdf)
>  In clinics, a radiology report is crucial for guiding a patient's treatment. Unfortunately, report writing imposes a heavy burden on radiologists. To effectively reduce such a burden, we hereby present an automatic, multi-modal approach for report generation from chest x-ray. Our approach, motivated by the observation that the descriptions in radiology reports are highly correlated with the x-ray images, features two distinct modules: (i) Learned knowledge base. To absorb the knowledge embedded in the above-mentioned correlation, we automatically build a knowledge base based on textual embedding. (ii) Multi-modal alignment. To promote the semantic alignment among reports, disease labels and images, we explicitly utilize textual embedding to guide the learning of the visual feature space. We evaluate the performance of the proposed model using metrics from both natural language generation and clinic efficacy on the public IU and MIMIC-CXR datasets. Our ablation study shows that each module contributes to improving the quality of generated reports. Furthermore, with the aid of both modules, our approach clearly outperforms state-of-the-art methods.      
### 20.Knowledge Matters: Radiology Report Generation with General and Specific Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2112.15009.pdf)
>  Automatic radiology report generation is critical in clinics which can relieve experienced radiologists from the heavy workload and remind inexperienced radiologists of misdiagnosis or missed diagnose. Existing approaches mainly formulate radiology report generation as an image captioning task and adopt the encoder-decoder framework. However, in the medical domain, such pure data-driven approaches suffer from the following problems: 1) visual and textual bias problem; 2) lack of expert knowledge. In this paper, we propose a knowledge-enhanced radiology report generation approach introduces two types of medical knowledge: 1) General knowledge, which is input independent and provides the broad knowledge for report generation; 2) Specific knowledge, which is input dependent and provides the fine-grained knowledge for report generation. To fully utilize both the general and specific knowledge, we also propose a knowledge-enhanced multi-head attention mechanism. By merging the visual features of the radiology image with general knowledge and specific knowledge, the proposed model can improve the quality of generated reports. Experimental results on two publicly available datasets IU-Xray and MIMIC-CXR show that the proposed knowledge enhanced approach outperforms state-of-the-art image captioning based methods. Ablation studies also demonstrate that both general and specific knowledge can help to improve the performance of radiology report generation.      
### 21.Using Mobility Patterns for the Planning of Vehicle-to-Grid Infrastructures that Support Photovoltaics in Cities  [ :arrow_down: ](https://arxiv.org/pdf/2112.15006.pdf)
>  The vehicle-to-grid (V2G) concept utilises electric vehicles as distributed energy storage and thus may help to balance out the intermittent availability of renewable energy sources such as photovoltaics. V2G is therefore considered to play an important role for achieving low-carbon energy and transportation systems in cities. However, the adequate planning of city-wide V2G infrastructures requires detailed knowledge of the aggregate mobility patterns of individuals and also needs to keep track with ongoing developments of urban transportation modes. Here, we introduce an initial framework that infers population-wide mobility patterns from anonymised mobile phone location data and subsequently superimposes a vehicle charging and discharging scheme. The framework allows for the estimation of the aggregate V2G energy supply and demand at fine-grained spatial and temporal scales under a given electric vehicle usage scenario. This information provides an adequate basis for assessing the role of V2G in the context of maximising the deployment of photovoltaics, as well as for the sizing and placement of the required vehicle (dis)charging infrastructure. The proposed framework is applied to Singapore as a case study.      
### 22.Data-Driven State Estimation for Light-Emitting Diode Underwater Optical Communication  [ :arrow_down: ](https://arxiv.org/pdf/2112.14948.pdf)
>  Light-Emitting Diodes (LEDs) based underwater optical wireless communications (UOWCs), a technology with low latency and high data rates, have attracted significant importance for underwater robots. However, maintaining a controlled line of sight link between transmitter and receiver is challenging due to the constant movement of the underlying optical platform caused by the dynamic uncertainties of the LED model and vibration effects. Additionally, the alignment angle required for tracking is not directly measured and has to be estimated. Besides, the light scattering propagates beam pulse in water temporally, resulting in time-varying underwater optical links with interference. We address the state estimation problem by designing an LED communication system that provides the angular position and velocity information to overcome the challenges. In this way, we leverage the power of deep learning-based observer design to explore the LED communication's state space properly. Simulation results are presented to illustrate the performance of the data-driven LED state estimation.      
### 23.Risk-Bounded Control with Kalman Filtering and Stochastic Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2112.14912.pdf)
>  In this paper, we study Stochastic Control Barrier Functions (SCBFs) to enable the design of probabilistic safe real-time controllers in presence of uncertainties and based on noisy measurements. Our goal is to design controllers that bound the probability of a system failure in finite-time to a given desired value. To that end, we first estimate the system states from the noisy measurements using an Extended Kalman filter, and compute confidence intervals on the filtering errors. Then, we account for filtering errors and derive sufficient conditions on the control input based on the estimated states to bound the probability that the real states of the system enter an unsafe region within a finite time interval. We show that these sufficient conditions are linear constraints on the control input, and, hence, they can be used in tractable optimization problems to achieve safety, in addition to other properties like reachability, and stability. Our approach is evaluated using a simulation of a lane-changing scenario on a highway with dense traffic.      
### 24.On-Policy Robust Adaptive Discrete-Time Regulator for Passive Unidirectional System using Stochastic Hill-climbing Algorithm and Associated Search Element  [ :arrow_down: ](https://arxiv.org/pdf/2112.14901.pdf)
>  Non-linear discrete-time state-feedback regulators are widely used in passive unidirectional systems. Offline system identification is required for tuning parameters of these regulators. However, offline system identification is challenging in some applications. Furthermore, the parameters of a system may be slowly changing over time, which makes the system identification less effective. Many adaptive regulators have been proposed to tune the parameters online when the offline information is neither accessible nor time-invariant. Stability and convergence of these adaptive regulators are challenging, especially in unidirectional systems. In this paper, a novel adaptive regulator is proposed for first-order unidirectional passive systems. In this method, an associated search element checks the eligibility of the update law. Then, a stochastic hill-climbing algorithm updates the parameters of the discrete-time state-feedback regulator. Simulation results demonstrate the effectiveness of the proposed method. The experiments on regulating of two passive systems show the ability of the method in regulating of passive unidirectional system in the presence of noise and disturbance.      
### 25.An overview of the quantitative causality analysis and causal graph reconstruction based on a rigorous formalism of information flow  [ :arrow_down: ](https://arxiv.org/pdf/2112.14839.pdf)
>  Inference of causal relations from data now has become an important field in artificial intelligence. During the past 16 years, causality analysis (in a quantitative sense) has been developed independently in physics from first principles. This short note is a brief summary of this line of work, including part of the theory and several representative applications.      
### 26.Constrained Wrapped Least Squares: A Tool for High Accuracy GNSS Attitude Determination  [ :arrow_down: ](https://arxiv.org/pdf/2112.14813.pdf)
>  Attitude determination is a popular application of Global Navigation Satellite Systems (GNSS). Many methods have been developed to solve the attitude determination problem with different performance offerings. We develop a constrained wrapped least-squares (C-WLS) method for high-accuracy attitude determination. This approach is built on an optimization model that leverages prior information related to the antenna array and the integer nature of the carrier-phase ambiguities in an innovative way. The proposed approach adopts an efficient search strategy to estimate the vehicle's attitude parameters using ambiguous carrier-phase observations directly, without requiring prior carrier-phase ambiguity fixing. The performance of the proposed method is evaluated via simulations and experimentally utilizing data collected using multiple GNSS receivers. The simulation and experimental results demonstrate excellent performance, with the proposed method outperforming the ambiguity function method, the constrained LAMBDA and multivariate constrained LAMBDA methods, three prominent attitude determination algorithms.      
### 27.Video Reconstruction from a Single Motion Blurred Image using Learned Dynamic Phase Coding  [ :arrow_down: ](https://arxiv.org/pdf/2112.14768.pdf)
>  Video reconstruction from a single motion-blurred image is a challenging problem, which can enhance existing cameras' capabilities. Recently, several works addressed this task using conventional imaging and deep learning. Yet, such purely-digital methods are inherently limited, due to direction ambiguity and noise sensitivity. Some works proposed to address these limitations using non-conventional image sensors, however, such sensors are extremely rare and expensive. To circumvent these limitations with simpler means, we propose a hybrid optical-digital method for video reconstruction that requires only simple modifications to existing optical systems. We use a learned dynamic phase-coding in the lens aperture during the image acquisition to encode the motion trajectories, which serve as prior information for the video reconstruction process. The proposed computational camera generates a sharp frame burst of the scene at various frame rates from a single coded motion-blurred image, using an image-to-video convolutional neural network. We present advantages and improved performance compared to existing methods, using both simulations and a real-world camera prototype.      
### 28.Non-Linear Age of Information: An Energy Efficient Receiver-Centric Approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.15553.pdf)
>  The age of information (AoI) performance metric for point-to-point wireless communication systems is analytically studied under Rician-faded channels and when the receiver is equipped with multiple antennas. The general scenario of a non-linear AoI function is considered, which includes the conventional linear AoI as a special case. The stop-and-wait transmission policy is adopted, where the source node samples and then transmits new data only upon the successful reception of previous data. This approach can serve as a performance benchmark for any queuing system used in practice. New analytical and closed-form expressions are derived with respect to the average AoI and average peak AoI for the considered system configuration. We particularly focus on the energy efficiency of the said mode of operation, whereas some useful engineering insights are provided.      
### 29.Data-Driven Optimal Control of Bilinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15510.pdf)
>  This paper develops a method to learn optimal controls from data for bilinear systems without a priori knowledge of the system dynamics. Given an unknown bilinear system, we first characterize when the available data is suitable to solve the optimal control problem. This characterization leads us to propose an online control experiment design procedure that guarantees that any input/state trajectory can be represented as a linear combination of collected input/state data matrices. Leveraging this data-based representation, we transform the original optimal control problem into an equivalent data-based optimization problem with bilinear constraints. We solve the latter by iteratively employing a convex-concave procedure to convexify it and find a locally optimal control sequence. Simulations show that the performance of the proposed data-based approach is comparable with model-based methods.      
### 30.NOMA Versus Massive MIMO in Rayleigh Fading  [ :arrow_down: ](https://arxiv.org/pdf/2112.15493.pdf)
>  This paper compares the sum rates and rate regions achieved by power-domain NOMA (non-orthogonal multiple access) and standard massive MIMO (multiple-input multiple-output) techniques. We prove analytically that massive MIMO always outperforms NOMA in i.i.d.~Rayleigh fading channels, if a sufficient number of antennas are used at the base stations. The simulation results show that the crossing point occurs already when having 20-30 antennas, which is far less than what is considered for the next generation cellular networks.      
### 31.Human and Machine Type Communications can Coexist in Uplink Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15492.pdf)
>  Future cellular networks are expected to support new communication paradigms such as machine-type communication (MTC) services along with human-type communication (HTC) services. This requires base stations to serve a large number of devices in relatively short channel coherence intervals which renders allocation of orthogonal pilot sequence per-device approaches impractical. Furthermore, the stringent power constraints, place-and-play type connectivity and various data rate requirements of MTC devices make it impossible for the traditional cellular architecture to accommodate MTC and HTC services together. Massive multiple-input-multiple-output (MaMIMO) technology has the potential to allow the coexistence of HTC and MTC services, thanks to its inherent spatial multiplexing properties and low transmission power requirements. In this work, we investigate the performance of a single cell under a shared physical channel assumption for MTC and HTC services and propose a novel scheme for sharing the time-frequency resources. The analysis reveals that MaMIMO can significantly enhance the performance of such a setup and allow the inclusion of MTC services into the cellular networks without requiring additional resources.      
### 32.Centralized and Distributed Power Allocation for Max-Min Fairness in Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2112.15490.pdf)
>  Cell-free Massive MIMO systems consist of a large number of geographically distributed access points (APs) that serve users by coherent joint transmission. Downlink power allocation is important in these systems, to determine which APs should transmit to which users and with what power. If the system is implemented correctly, it can deliver a more uniform user performance than conventional cellular networks. To this end, previous works have shown how to perform system-wide max-min fairness power allocation when using maximum ratio precoding. In this paper, we first generalize this method to arbitrary precoding, and then train a neural network to perform approximately the same power allocation but with reduced computational complexity. Finally, we train one neural network per AP to mimic system-wide max-min fairness power allocation, but using only local information. By learning the structure of the local propagation environment, this method outperforms the state-of-the-art distributed power allocation method from the Cell-free Massive MIMO literature.      
### 33.MRT-based Joint Unicast and Multigroup Multicast Transmission in Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15489.pdf)
>  We study joint unicast and multigroup multicast transmission in single-cell massive multiple-input-multiple-output (MIMO) systems, under maximum ratio transmission. For the unicast transmission, the objective is to maximize the weighted sum spectral efficiency (SE) of the unicast user terminals (UTs) and for the multicast transmission the objective is to maximize the minimum SE of the multicast UTs. These two problems are coupled to each other in a conflicting manner, due to their shared power resource and interference. To address this, we formulate a multiobjective optimization problem (MOOP). We derive the Pareto boundary of the MOOP analytically and determine the values of the system parameters to achieve any desired Pareto optimal point. Moreover, we prove that the Pareto region is convex, hence the system should serve the unicast and multicast UTs at the same time-frequency resource.      
### 34.A Research Agenda for Artificial Intelligence in the Field of Flexible Production Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.15484.pdf)
>  Production companies face problems when it comes to quickly adapting their production control to fluctuating demands or changing requirements. Control approaches aiming to encapsulate production functions in the sense of services have shown to be promising in order to increase flexibility of Cyber-Physical Production Systems. But an existing challenge of such approaches is finding production plans based on provided functionalities for a set of requirements, especially when there is no direct (i.e., syntactic) match between demanded and provided functions. In such cases it can become complicated to find those provided functions that can be arranged into a plan satisfying the demand. While there is a variety of different approaches to production planning, flexible production poses specific requirements that are not covered by existing research. In this contribution, we first capture these requirements for flexible production environments. Afterwards, an overview of current Artificial Intelligence approaches that can be utilized in order to overcome the aforementioned challenges is given. Approaches from both symbolic AI planning as well as approaches based on Machine Learning are discussed and eventually compared against the requirements. Based on this comparison, a research agenda is derived.      
### 35.Channel Estimation for Hybrid Massive MIMO Systems with Adaptive-Resolution ADCs  [ :arrow_down: ](https://arxiv.org/pdf/2112.15419.pdf)
>  Achieving high channel estimation accuracy and reducing hardware cost as well as power dissipation constitute substantial challenges in the design of massive multiple-input multiple-output (MIMO) systems. To resolve these difficulties, sophisticated pilot designs have been conceived for the family of energy-efficient hybrid analog-digital (HAD) beamforming architecture relying on adaptive-resolution analog-to-digital converters (RADCs). In this paper, we jointly optimize the pilot sequences, the number of RADC quantization bits and the hybrid receiver combiner in the uplink of multiuser massive MIMO systems. We solve the associated mean square error (MSE) minimization problem of channel estimation in the context of correlated Rayleigh fading channels subject to practical constraints. The associated mixed-integer problem is quite challenging due to the nonconvex nature of the objective function and of the constraints. By relying on advanced fractional programming (FP) techniques, we first recast the original problem into a more tractable yet equivalent form, which allows the decoupling of the fractional objective function. We then conceive a pair of novel algorithms for solving the resultant problems for codebook-based and codebook-free pilot schemes, respectively. To reduce the design complexity, we also propose a simplified algorithm for the codebook-based pilot scheme. Our simulation results confirm the superiority of the proposed algorithms over the relevant state-of-the-art benchmark schemes.      
### 36.Fast Graph Subset Selection Based on G-optimal Design  [ :arrow_down: ](https://arxiv.org/pdf/2112.15403.pdf)
>  Graph sampling theory extends the traditional sampling theory to graphs with topological structures. As a key part of the graph sampling theory, subset selection chooses nodes on graphs as samples to reconstruct the original signal. Due to the eigen-decomposition operation for Laplacian matrices of graphs, however, existing subset selection methods usually require high-complexity calculations. In this paper, with an aim of enhancing the computational efficiency of subset selection on graphs, we propose a novel objective function based on the optimal experimental design. Theoretical analysis shows that this function enjoys an $\alpha$-supermodular property with a provable lower bound on $\alpha$. The objective function, together with an approximate of the low-pass filter on graphs, suggests a fast subset selection method that does not require any eigen-decomposition operation. Experimental results show that the proposed method exhibits high computational efficiency, while having competitive results compared to the state-of-the-art ones, especially when the sampling rate is low.      
### 37.InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering  [ :arrow_down: ](https://arxiv.org/pdf/2112.15399.pdf)
>  We present an information-theoretic regularization technique for few-shot novel view synthesis based on neural implicit representation. The proposed approach minimizes potential reconstruction inconsistency that happens due to insufficient viewpoints by imposing the entropy constraint of the density in each ray. In addition, to alleviate the potential degenerate issue when all training images are acquired from almost redundant viewpoints, we further incorporate the spatially smoothness constraint into the estimated images by restricting information gains from a pair of rays with slightly different viewpoints. The main idea of our algorithm is to make reconstructed scenes compact along individual rays and consistent across rays in the neighborhood. The proposed regularizers can be plugged into most of existing neural volume rendering techniques based on NeRF in a straightforward way. Despite its simplicity, we achieve consistently improved performance compared to existing neural view synthesis methods by large margins on multiple standard benchmarks. Our project website is available at \url{<a class="link-external link-http" href="http://cvlab.snu.ac.kr/research/InfoNeRF" rel="external noopener nofollow">this http URL</a>}.      
### 38.$H^2$-Optimal Reduction of Positive Networks using Riemannian Augmented Lagrangian Method  [ :arrow_down: ](https://arxiv.org/pdf/2112.15389.pdf)
>  In this study, we formulate the model reduction problem of a stable and positive network system as a constrained Riemannian optimization problem with the $H^2$-error objective function of the original and reduced network systems. We improve the reduction performance of the clustering-based method, which is one of the most known methods for model reduction of positive network systems, by using the output of the clustering-based method as the initial point for the proposed method. The proposed method reduces the dimension of the network system while preserving the properties of stability, positivity, and interconnection structure by applying the Riemannian augmented Lagrangian method (RALM) and deriving the Riemannian gradient of the Lagrangian. To check the efficiency of our method, we conduct a numerical experiment and compare it with the clustering-based method in the sense of $H^2$-error and $H^\infty$-error.      
### 39.Statistical Device Activity Detection for OFDM-based Massive Grant-Free Access  [ :arrow_down: ](https://arxiv.org/pdf/2112.15354.pdf)
>  Existing works on grant-free access, proposed to support massive machine-type communication (mMTC) for the Internet of things (IoT), mainly concentrate on narrow band systems under flat fading. However, little is known about massive grant-free access for wideband systems under frequency-selective fading. This paper investigates massive grant-free access in a wideband system under frequency-selective fading. First, we present an orthogonal frequency division multiplexing (OFDM)-based massive grant-free access scheme. Then, we propose two different but equivalent models for the received pilot signal, which are essential for designing various device activity detection and channel estimation methods for OFDM-based massive grant-free access. One directly models the received signal for actual devices, whereas the other can be interpreted as a signal model for virtual devices. Next, we investigate statistical device activity detection under frequency-selective Rayleigh fading based on the two signal models. We first model device activities as unknown deterministic quantities and propose three maximum likelihood (ML) estimation-based device activity detection methods with different detection accuracies and computation times. We also model device activities as random variables with a known joint distribution and propose three maximum a posterior probability (MAP) estimation-based device activity methods, which further enhance the accuracies of the corresponding ML estimation-based methods. Optimization techniques and matrix analysis are applied in designing and analyzing these methods. Finally, numerical results show that the proposed statistical device activity detection methods outperform existing state-of-the-art device activity detection methods under frequency-selective Rayleigh fading.      
### 40.Training Recurrent Neural Networks by Sequential Least Squares and the Alternating Direction Method of Multipliers  [ :arrow_down: ](https://arxiv.org/pdf/2112.15348.pdf)
>  For training recurrent neural network models of nonlinear dynamical systems from an input/output training dataset based on rather arbitrary convex and twice-differentiable loss functions and regularization terms, we propose the use of sequential least squares for determining the optimal network parameters and hidden states. In addition, to handle non-smooth regularization terms such as L1, L0, and group-Lasso regularizers, as well as to impose possibly non-convex constraints such as integer and mixed-integer constraints, we combine sequential least squares with the alternating direction method of multipliers (ADMM). The performance of the resulting algorithm, that we call NAILS (Nonconvex ADMM Iterations and Least Squares), is tested in a nonlinear system identification benchmark.      
### 41.Efficient Multi-Beam Training For Terahertz Wireless communications  [ :arrow_down: ](https://arxiv.org/pdf/2112.15346.pdf)
>  Although Terahertz communication systems can provide high data rates, it needs high directional beamforming at transmitters and receivers to achieve such rates over a long distance. Therefore, an efficient beam training method is vital to accelerate the link establishment. In this study, we propose a low-complexity beam training scheme of terahertz communication system which uses a low-cost small-scale hybrid architecture to assist a large-scale array for data transmission. The proposed scheme includes two key stages: (1) coarse AoAs/AoDs estimation for beam subset optimization in auxiliary array stage, and (2) accurate AoAs/AoDs estimation by exploiting channel sparsity in data transmission array stage. The analysis shows that the complexity of the scheme is linear with the number of main paths, and thus greatly reduces the complexity of beam training. Simulation results have verified the better performance in spectral efficiency of the proposed scheme than that of the related work.      
### 42.Sufficient Statistic Memory AMP  [ :arrow_down: ](https://arxiv.org/pdf/2112.15327.pdf)
>  Approximate message passing (AMP) is a promising technique for unknown signal reconstruction of certain high-dimensional linear systems with non-Gaussian signaling. A distinguished feature of the AMP-type algorithms is that their dynamics can be rigorously described by state evolution. However, state evolution does not necessarily guarantee the convergence of iterative algorithms. To solve the convergence problem of AMP-type algorithms in principle, this paper proposes a memory AMP (MAMP) under a sufficient statistic condition, named sufficient statistic MAMP (SS-MAMP). We show that the covariance matrices of SS-MAMP are L-banded and convergent. Given an arbitrary MAMP, we can construct an SS-MAMP by damping, which not only ensures the convergence of MAMP but also preserves the orthogonality of MAMP, i.e., its dynamics can be rigorously described by state evolution. As a byproduct, we prove that the Bayes-optimal orthogonal/vector AMP (BO-OAMP/VAMP) is an SS-MAMP. As a result, we reveal two interesting properties of BO-OAMP/VAMP for large systems: 1) the covariance matrices are L-banded and are convergent in BO-OAMP/VAMP, and 2) damping and memory are useless (i.e., do not bring performance improvement) in BO-OAMP/VAMP. As an example, we construct a sufficient statistic Bayes-optimal MAMP (BO-MAMP), which is Bayes optimal if its state evolution has a unique fixed point and its MSE is not worse than the original BO-MAMP. Finally, simulations are provided to verify the validity and accuracy of the theoretical results.      
### 43.Efficient Channel Estimation for RIS-Aided MIMO Communications with Unitary Approximate Message Passing  [ :arrow_down: ](https://arxiv.org/pdf/2112.15281.pdf)
>  Reconfigurable intelligent surface (RIS) is very promising for wireless networks to achieve high energy efficiency, extended coverage, improved capacity, massive connectivity, etc. To unleash the full potentials of RIS-aided communications, acquiring accurate channel state information is crucial, which however is very challenging. For RIS-aided multiple-input and multiple-output (MIMO) communications, the existing channel estimation methods have computational complexity growing rapidly with the number of RIS units $N$ (e.g., in the order of $N^2$ or $N^3$) and/or have special requirements on the matrices involved (e.g., the matrices need to be sparse for algorithm convergence to achieve satisfactory performance), which hinder their applications. In this work, instead of using the conventional signal model in the literature, we derive a new signal model obtained through proper vectorization and reduction operations. Then, leveraging the unitary approximate message passing (UAMP), we develop a more efficient channel estimator that has complexity linear with $N$ and does not have special requirements on the relevant matrices, thanks to the robustness of UAMP. These facilitate the applications of the proposed algorithm to a general RIS-aided MIMO system with a larger $N$. Moreover, extensive numerical results show that the proposed estimator delivers much better performance and/or requires significantly less number of training symbols, thereby leading to notable reductions in both training overhead and latency.      
### 44.BP-Net: Cuff-less, Calibration-free, and Non-invasive Blood Pressure Estimation via a Generic Deep Convolutional Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2112.15271.pdf)
>  Objective: The paper focuses on development of robust and accurate processing solutions for continuous and cuff-less blood pressure (BP) monitoring. In this regard, a robust deep learning-based framework is proposed for computation of low latency, continuous, and calibration-free upper and lower bounds on the systolic and diastolic BP. Method: Referred to as the BP-Net, the proposed framework is a novel convolutional architecture that provides longer effective memory while achieving superior performance due to incorporation of casual dialated convolutions and residual connections. To utilize the real potential of deep learning in extraction of intrinsic features (deep features) and enhance the long-term robustness, the BP-Net uses raw Electrocardiograph (ECG) and Photoplethysmograph (PPG) signals without extraction of any form of hand-crafted features as it is common in existing solutions. Results: By capitalizing on the fact that datasets used in recent literature are not unified and properly defined, a benchmark dataset is constructed from the MIMIC-I and MIMIC-III databases obtained from PhysioNet. The proposed BP-Net is evaluated based on this benchmark dataset demonstrating promising performance and shows superior generalizable capacity. Conclusion: The proposed BP-Net architecture is more accurate than canonical recurrent networks and enhances the long-term robustness of the BP estimation task. Significance: The proposed BP-Net architecture addresses key drawbacks of existing BP estimation solutions, i.e., relying heavily on extraction of hand-crafted features, such as pulse arrival time (PAT), and; Lack of robustness. Finally, the constructed BP-Net dataset provides a unified base for evaluation and comparison of deep learning-based BP estimation algorithms.      
### 45.Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal Difference and Successor Representation  [ :arrow_down: ](https://arxiv.org/pdf/2112.15156.pdf)
>  Distributed Multi-Agent Reinforcement Learning (MARL) algorithms has attracted a surge of interest lately mainly due to the recent advancements of Deep Neural Networks (DNNs). Conventional Model-Based (MB) or Model-Free (MF) RL algorithms are not directly applicable to the MARL problems due to utilization of a fixed reward model for learning the underlying value function. While DNN-based solutions perform utterly well when a single agent is involved, such methods fail to fully generalize to the complexities of MARL problems. In other words, although recently developed approaches based on DNNs for multi-agent environments have achieved superior performance, they are still prone to overfiting, high sensitivity to parameter selection, and sample inefficiency. The paper proposes the Multi-Agent Adaptive Kalman Temporal Difference (MAK-TD) framework and its Successor Representation-based variant, referred to as the MAK-SR. Intuitively speaking, the main objective is to capitalize on unique characteristics of Kalman Filtering (KF) such as uncertainty modeling and online second order learning. The proposed MAK-TD/SR frameworks consider the continuous nature of the action-space that is associated with high dimensional multi-agent environments and exploit Kalman Temporal Difference (KTD) to address the parameter uncertainty. By leveraging the KTD framework, SR learning procedure is modeled into a filtering problem, where Radial Basis Function (RBF) estimators are used to encode the continuous space into feature vectors. On the other hand, for learning localized reward functions, we resort to Multiple Model Adaptive Estimation (MMAE), to deal with the lack of prior knowledge on the observation noise covariance and observation mapping function. The proposed MAK-TD/SR frameworks are evaluated via several experiments, which are implemented through the OpenAI Gym MARL benchmarks.      
### 46.Towards Automated Sample Collection and Return in Extreme Underwater Environments  [ :arrow_down: ](https://arxiv.org/pdf/2112.15127.pdf)
>  In this report, we present the system design, operational strategy, and results of coordinated multi-vehicle field demonstrations of autonomous marine robotic technologies in search-for-life missions within the Pacific shelf margin of Costa Rica and the Santorini-Kolumbo caldera complex, which serve as analogs to environments that may exist in oceans beyond Earth. This report focuses on the automation of ROV manipulator operations for targeted biological sample-collection-and-return from the seafloor. In the context of future extraterrestrial exploration missions to ocean worlds, an ROV is an analog to a planetary lander, which must be capable of high-level autonomy. Our field trials involve two underwater vehicles, the SuBastian ROV and the Nereid Under Ice (NUI) hybrid ROV for mixed initiative (i.e., teleoperated or autonomous) missions, both equipped 7-DoF hydraulic manipulators. We describe an adaptable, hardware-independent computer vision architecture that enables high-level automated manipulation. The vision system provides a 3D understanding of the workspace to inform manipulator motion planning in complex unstructured environments. We demonstrate the effectiveness of the vision system and control framework through field trials in increasingly challenging environments, including the automated collection and return of biological samples from within the active undersea volcano, Kolumbo. Based on our experiences in the field, we discuss the performance of our system and identify promising directions for future research.      
### 47.Audio-to-symbolic Arrangement via Cross-modal Music Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.15110.pdf)
>  Could we automatically derive the score of a piano accompaniment based on the audio of a pop song? This is the audio-to-symbolic arrangement problem we tackle in this paper. A good arrangement model should not only consider the audio content but also have prior knowledge of piano composition (so that the generation "sounds like" the audio and meanwhile maintains musicality.) To this end, we contribute a cross-modal representation-learning model, which 1) extracts chord and melodic information from the audio, and 2) learns texture representation from both audio and a corrupted ground truth arrangement. We further introduce a tailored training strategy that gradually shifts the source of texture information from corrupted score to audio. In the end, the score-based texture posterior is reduced to a standard normal distribution, and only audio is needed for inference. Experiments show that our model captures major audio information and outperforms baselines in generation quality.      
### 48.Frequency Selection for Platoon Communications in Secondary Spectrum Using Radio Environment Maps  [ :arrow_down: ](https://arxiv.org/pdf/2112.15066.pdf)
>  Platoon-based driving is an idea that vehicles follow each other at a close distance, in order to increase road throughput and fuel savings. This requires reliable wireless communications to adjust the speeds of vehicles. Although there is a dedicated frequency band for vehicle-to-vehicle (V2V) communications, studies have shown that it is too congested to provide reliable transmission for the platoons. Additional spectrum resources, i.e., secondary spectrum channels, can be utilized when these are not occupied by other users. Characteristics of interference in these channels are usually location-dependent and can be stored in the so-called Radio Environment Maps (REMs). This paper aims to design REM, in order to support the selection of secondary spectrum channel for intra-platoon communications. We propose to assess the channel's quality in terms of outage probability computed, with the use of estimated interference distributions stored in REM. A frequency selection algorithm that minimizes the number of channel switches along the planned platoon route is proposed. Additionally, the REM creation procedure is shown that reduces the number of database entries using (Density-Based Spatial Clustering of Applications with Noise) DBSCAN algorithm. The proposals are tested using real IQ samples captured on a real road. Application of the DBSCAN clustering to the constructed REM provided 7% reduction in its size. Utilization of the proposed channel selection algorithm resulted in a 35 times reduction of channel switches concerning channel assignment performed independently in every location.      
### 49.Decentralized Optimization Over the Stiefel Manifold by an Approximate Augmented Lagrangian Function  [ :arrow_down: ](https://arxiv.org/pdf/2112.14949.pdf)
>  In this paper, we focus on the decentralized optimization problem over the Stiefel manifold, which is defined on a connected network of $d$ agents. The objective is an average of $d$ local functions, and each function is privately held by an agent and encodes its data. The agents can only communicate with their neighbors in a collaborative effort to solve this problem. In existing methods, multiple rounds of communications are required to guarantee the convergence, giving rise to high communication costs. In contrast, this paper proposes a decentralized algorithm, called DESTINY, which only invokes a single round of communications per iteration. DESTINY combines gradient tracking techniques with a novel approximate augmented Lagrangian function. The global convergence to stationary points is rigorously established. Comprehensive numerical experiments demonstrate that DESTINY has a strong potential to deliver a cutting-edge performance in solving a variety of testing problems.      
### 50.AutoCast: Scalable Infrastructure-less Cooperative Perception for Distributed Collaborative Driving  [ :arrow_down: ](https://arxiv.org/pdf/2112.14947.pdf)
>  Autonomous vehicles use 3D sensors for perception. Cooperative perception enables vehicles to share sensor readings with each other to improve safety. Prior work in cooperative perception scales poorly even with infrastructure support. AutoCast enables scalable infrastructure-less cooperative perception using direct vehicle-to-vehicle communication. It carefully determines which objects to share based on positional relationships between traffic participants, and the time evolution of their trajectories. It coordinates vehicles and optimally schedules transmissions in a distributed fashion. Extensive evaluation results under different scenarios show that, unlike competing approaches, AutoCast can avoid crashes and near-misses which occur frequently without cooperative perception, its performance scales gracefully in dense traffic scenarios providing 2-4x visibility into safety critical objects compared to existing cooperative perception schemes, its transmission schedules can be completed on the real radio testbed, and its scheduling algorithm is near-optimal with negligible computation overhead.      
### 51.SFU-HW-Tracks-v1: Object Tracking Dataset on Raw Video Sequences  [ :arrow_down: ](https://arxiv.org/pdf/2112.14934.pdf)
>  We present a dataset that contains object annotations with unique object identities (IDs) for the High Efficiency Video Coding (HEVC) v1 Common Test Conditions (CTC) sequences. Ground-truth annotations for 13 sequences were prepared and released as the dataset called SFU-HW-Tracks-v1. For each video frame, ground truth annotations include object class ID, object ID, and bounding box location and its dimensions. The dataset can be used to evaluate object tracking performance on uncompressed video sequences and study the relationship between video compression and object tracking.      
### 52.Dense Depth Estimation from Multiple 360-degree Images Using Virtual Depth  [ :arrow_down: ](https://arxiv.org/pdf/2112.14931.pdf)
>  In this paper, we propose a dense depth estimation pipeline for multiview 360\degree\: images. The proposed pipeline leverages a spherical camera model that compensates for radial distortion in 360\degree\: images. The key contribution of this paper is the extension of a spherical camera model to multiview by introducing a translation scaling scheme. Moreover, we propose an effective dense depth estimation method by setting virtual depth and minimizing photonic reprojection error. We validate the performance of the proposed pipeline using the images of natural scenes as well as the synthesized dataset for quantitive evaluation. The experimental results verify that the proposed pipeline improves estimation accuracy compared to the current state-of-art dense depth estimation methods.      
### 53.Feature extraction with mel scale separation method on noise audio recordings  [ :arrow_down: ](https://arxiv.org/pdf/2112.14930.pdf)
>  This paper focuses on improving the accuracy of noise audio recordings. High-quality audio recording, extraction using the mel frequency cepstral coefficients (MFCC) method produces high accuracy. While the low-quality is because of noise, the accuracy is low. Improved accuracy by investigating the effect of bandwidth on the mel scale. The proposed improvement uses the mel scale separation methods into two frequency channels (MFCC dual channel). For the comparison method using the mel scale bandwidth without separation (MFCC single-channel). Feature analysis using k-mean clustering. The data uses a noise variance of up to -16 dB. Testing on the MFCC single channel method for -16 dB noise has an accuracy of 47.5%, while the MFCC dual-channel method has an accuracy better of 76.25%. The next test used adaptive noise-canceling (ANC) to reduce noise before extraction. The result is that the MFCC single-channel method has an accuracy of 82.5% and the MFCC dual-channel method has an accuracy better of 83.75%. High-quality audio recording testing for the MFCC single-channel method has an accuracy of 92.5% and the MFCC dual-channel method has an accuracy better of 97.5%. The test results show the effect of mel scale bandwidth to increase accuracy. The MFCC dual-channel method has higher accuracy.      
### 54.Parallel Network Flow Allocation in Repeated Routing Games via LQR Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2112.14888.pdf)
>  In this article, we study the repeated routing game problem on a parallel network with affine latency functions on each edge. We cast the game setup in a LQR control theoretic framework, leveraging the Rosenthal potential formulation. We use control techniques to analyze the convergence of the game dynamics with specific cases that lend themselves to optimal control. We design proper dynamics parameters so that the conservation of flow is guaranteed. We provide an algorithmic solution for the general optimal control setup using a multiparametric quadratic programming approach (explicit MPC). Finally we illustrate with numerics the impact of varying system parameters on the solutions.      
### 55.Learned Autoscaling for Cloud Microservices with Multi-Armed Bandits  [ :arrow_down: ](https://arxiv.org/pdf/2112.14845.pdf)
>  As cloud applications shift from monolithic architectures to loosely coupled microservices, several challenges in resource management arise. Application developers are tasked with determining compute capacity needed for each microservice in an application. This allocation dictates both the cost and performance of the application and typically relies on using either machine utilization (e.g. CPU, RAM) metrics. Our approach, COLA, relies on training a contextual multi armed bandit on representative workloads for an application and uses techniques to generalize performance to unseen workloads. We evaluate workloads of varying complexity including those with a fixed rate, diurnal pattern and dynamic request distribution. Across a set of five open-source microservice applications, we compare COLA against a variety of utilization and machine learning baselines. We find COLA provides the most cost effective autoscaling solution for a desired median or tail latency target on 13 of 18 workloads. On average, clusters managed by COLA cost 25.1\% fewer dollars than the next closest alternative that meets a specified target latency. We discuss several optimizations, inspired by systems and machine learning literature, we make during training to efficiently explore the space of possible microservice configurations. These optimizations enable us to train our models over the course of a few hours. The cost savings from managing a cluster with COLA result in the system paying for its own training cost within a few days.      
### 56.Explainable Signature-based Machine Learning Approach for Identification of Faults in Grid-Connected Photovoltaic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.14842.pdf)
>  The transformation of conventional power networks into smart grids with the heavy penetration level of renewable energy resources, particularly grid-connected Photovoltaic (PV) systems, has increased the need for efficient fault identification systems. Malfunctioning any single component in grid-connected PV systems may lead to grid instability and other serious consequences, showing that a reliable fault identification system is the utmost requirement for ensuring operational integrity. Therefore, this paper presents a novel fault identification approach based on statistical signatures of PV operational states. These signatures are unique because each fault has a different nature and distinctive impact on the electrical system. Thus, the Random Forest Classifier trained on these extracted signatures showed 100% accuracy in identifying all types of faults. Furthermore, the performance comparison of the proposed framework with other Machine Learning classifiers depicts its credibility. Moreover, to elevate user trust in the predicted outcomes, SHAP (Shapley Additive Explanation) was utilized during the training phase to extract a complete model response (global explanation). This extracted global explanation can help in the assessment of predicted outcomes credibility by decoding each prediction in terms of features contribution. Hence, the proposed explainable signature-based fault identification technique is highly credible and fulfills all the requirements of smart grids.      
### 57.Facial Input Decompositions for Robust Peak and Reachable Set Estimation under Polyhedral Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2112.14838.pdf)
>  This work bounds extreme values of state functions and approximates reachable sets for a class of input-affine continuous-time systems that are affected by polyhedral-bounded uncertainty. Instances of these systems may arise in data-driven peak estimation, in which the state function must be bounded for all systems that are that are consistent with a set of state-derivative data records corrupted under L-infinity bounded noise. Existing occupation measure-based methods form a convergent sequence of outer approximations to the true peak value or reachable set volume, given an initial set, by solving a hierarchy of semidefinite programs in increasing size. These techniques scale combinatorially in the number of state variables and uncertain parameters. We present tractable algorithms for peak and reachable set estimation that scale linearly in the number of faces of the uncertainty-bounding polytope rather than combinatorially in the number of uncertain parameters by leveraging convex duality and a theorem of alternatives (facial decomposition). The sequence of decomposed semidefinite programs will converge to the true optimal value under mild assumptions (convergence and smoothness of dynamics).      
### 58.Graph Neural Networks for Communication Networks: Context, Use Cases and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2112.14792.pdf)
>  Graph neural networks (GNN) have shown outstanding applications in many fields where data is fundamentally represented as graphs (e.g., chemistry, biology, recommendation systems). In this vein, communication networks comprise many fundamental components that are naturally represented in a graph-structured manner (e.g., topology, configurations, traffic flows). This position article presents GNNs as a fundamental tool for modeling, control and management of communication networks. GNNs represent a new generation of data-driven models that can accurately learn and reproduce the complex behaviors behind real networks. As a result, such models can be applied to a wide variety of networking use cases, such as planning, online optimization, or troubleshooting. The main advantage of GNNs over traditional neural networks lies in its unprecedented generalization capabilities when applied to other networks and configurations unseen during training, which is a critical feature for achieving practical data-driven solutions for networking. This article comprises a brief tutorial on GNNs and their possible applications to communication networks. To showcase the potential of this technology, we present two use cases with state-of-the-art GNN models respectively applied to wired and wireless networks. Lastly, we delve into the key open challenges and opportunities yet to be explored in this novel research area.      
