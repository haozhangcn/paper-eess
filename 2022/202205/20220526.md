# ArXiv eess --Thu, 26 May 2022
### 1.Boosting Tail Neural Network for Realtime Custom Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2205.12933.pdf)
>  In this paper, we propose a Boosting Tail Neural Network (BTNN) for improving the performance of Realtime Custom Keyword Spotting (RCKS) that is still an industrial challenge for demanding powerful classification ability with limited computation resources. Inspired by Brain Science that a brain is only partly activated for a nerve simulation and numerous machine learning algorithms are developed to use a batch of weak classifiers to resolve arduous problems, which are often proved to be effective. We show that this method is helpful to the RCKS problem. The proposed approach achieve better performances in terms of wakeup rate and false alarm. <br>In our experiments compared with those traditional algorithms that use only one strong classifier, it gets 18\% relative improvement. We also point out that this approach may be promising in future ASR exploration.      
### 2.RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.12902.pdf)
>  Glaucoma is one of the most severe eye diseases, characterized by rapid progression and leading to irreversible blindness. It is often the case that pathology diagnostics is carried out when the one's sight has already significantly degraded due to the lack of noticeable symptoms at early stage of the disease. Regular glaucoma screenings of the population shall improve early-stage detection, however the desirable frequency of etymological checkups is often not feasible due to excessive load imposed by manual diagnostics on limited number of specialists. Considering the basic methodology to detect glaucoma is to analyze fundus images for the \textit{optic-disc-to-optic-cup ratio}, Machine Learning domain can offer sophisticated tooling for image processing and classification. In our work, we propose an advanced image pre-processing technique combined with an ensemble of deep classification networks. Our \textit{Retinal Auto Detection (RADNet)} model has been successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92, and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset with AUC of 0.91.      
### 3.EVM Mitigation with PAPR and ACLR Constraints in Large-Scale MIMO-OFDM Using TOP-ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2205.12894.pdf)
>  Although signal distortion-based peak-to-average power ratio (PAPR) reduction is a feasible candidate for orthogonal frequency division multiplexing (OFDM) to meet standard/regulatory requirements, the error vector magnitude (EVM) stemming from the PAPR reduction has a deleterious impact on the performance of high data-rate achieving multiple-input multiple-output (MIMO) systems. Moreover, these systems must constrain the adjacent channel leakage ratio (ACLR) to comply with regulatory requirements. Several recent works have investigated the mitigation of the EVM seen at the receivers by capitalizing on the excess spatial dimensions inherent in the large-scale MIMO that assume the availability of perfect channel state information (CSI) with spatially uncorrelated wireless channels. Unfortunately, practical systems operate with erroneous CSI and spatially correlated channels. Additionally, most standards support user-specific/CSI-aware beamformed and cell-specific/non-CSI-aware broadcasting channels. Hence, we formulate a robust EVM mitigation problem under channel uncertainty with nonconvex PAPR and ACLR constraints catering to beamforming/broadcasting. To solve this formidable problem, we develop an efficient scheme using our recently proposed three-operator alternating direction method of multipliers (TOP-ADMM) algorithm and benchmark it against two three-operator algorithms previously presented for machine learning purposes. Numerical results show the efficacy of the proposed algorithm under imperfect CSI and spatially correlated channels.      
### 4.SOPHIE: SOft and flexible aerial vehicle for PHysical Interaction with the Environment  [ :arrow_down: ](https://arxiv.org/pdf/2205.12883.pdf)
>  This paper presents the first design of a soft, 3D-printed in flexible filament, lightweight UAV, capable of adapting to the industrial environment using soft tendons, specifically landing and stabilizing on pipelines without the need for an auxiliary system. The flexibility of the UAV can be controlled during the additive manufacturing process by adjusting the infill rate distribution. However, the increase in flexibility implies difficulties in controlling the UAV, as well as structural, aerodynamic and aeroelastic effects. This article provides insight into the dynamics of the system and validates the flyability of the vehicle for densities as low as 6%, enough to consider the vehicle as "soft". At lower densities, strong non-linear dynamics appear, which translates to complex modeling, and it is suggested to switch to data-based approaches.      
### 5.Compensation of Driving Signals for Soundfield Synthesis through Irregular Loudspeaker Arrays Based on Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.12872.pdf)
>  In this article we propose a technique for soundfield synthesis for irregular loudspeaker arrays, i.e. where the spacing between loudspeakers is not constant, based on deep learning. The input are the driving signals obtained through a plane wave decomposition-based technique. While the considered driving signals are able to correctly reproduce the soundfield with a regular array, they show degraded performances when using irregular setups. Through a Convolutional Neural Network (CNN) we modify the driving signals in order to compensate the errors in the reproduction of the desired soundfield. Since no ground-truth driving signals are available for the compensated ones, we train the model by calculating the loss between the desired soundfield at a number of control points and the one obtained through the driving signals estimated by the network. Numerical results show better performances both with respect to the plane wave decomposition-based technique and the pressure-matching approach.      
### 6.Worldwide Energy Harvesting Potential of Hybrid CPV/PV Technology  [ :arrow_down: ](https://arxiv.org/pdf/2205.12858.pdf)
>  Hybridization of multi-junction concentrator photovoltaics with single-junction flat plate solar cells (CPV/PV) can deliver the highest power output per module area of any PV technology. Conversion efficiencies up to 34.2% have been published under the AM1.5g spectrum at standard test conditions for the EyeCon module which combines Fresnel lenses and III-V four-junction solar cells with bifacial c-Si. We investigate here its energy yield and compare it to conventional CPV as well as flat plate PV. The advantage of the hybrid CPV/PV module is that it converts direct sunlight with the most advanced multi-junction cell technology, while accessing diffuse, lens-scattered and back side irradiance with a Si cell that also serves as the heat distributor for the concentrator cells. This article quantifies that hybrid bifacial CPV/PV modules are expected to generate a 25 - 35% higher energy yield with respect to their closest competitor in regions with a diffuse irradiance fraction around 50%. Additionally, the relative cost of electricity generated by hybrid CPV/PV technology was calculated worldwide under certain economic assumptions. Therefore, this article gives clear guidance towards establishing competitive business cases for the technology.      
### 7.Structure Unbiased Adversarial Model for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12857.pdf)
>  Generative models have been widely proposed in image recognition to generate more images where the distribution is similar to that of the real images. It often introduces a discriminator network to discriminate original real data and generated data. <br>However, such discriminator often considers the distribution of the data and did not pay enough attention to the intrinsic gap due to structure. <br>In this paper, we reformulate a new image to image translation problem to reduce structural gap, in addition to the typical intensity distribution gap. We further propose a simple yet important Structure Unbiased Adversarial Model for Medical Image Segmentation (SUAM) with learnable inverse structural deformation for medical image segmentation. It consists of a structure extractor, an attention diffeomorphic registration and a structure \&amp; intensity distribution rendering module. The structure extractor aims to extract the dominant structure of the input image. The attention diffeomorphic registration is proposed to reduce the structure gap with an inverse deformation field to warp the prediction masks back to their original form. The structure rendering module is to render the deformed structure to an image with targeted intensity distribution. We apply the proposed SUAM on both optical coherence tomography (OCT), magnetic resonance imaging (MRI) and computerized tomography (CT) data. Experimental results show that the proposed method has the capability to transfer both intensity and structure distributions.      
### 8.A Comparative Study of Gastric Histopathology Sub-size Image Classification: from Linear Regression to Visual Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2205.12843.pdf)
>  Gastric cancer is the fifth most common cancer in the world. At the same time, it is also the fourth most deadly cancer. Early detection of cancer exists as a guide for the treatment of gastric cancer. Nowadays, computer technology has advanced rapidly to assist physicians in the diagnosis of pathological pictures of gastric cancer. Ensemble learning is a way to improve the accuracy of algorithms, and finding multiple learning models with complementarity types is the basis of ensemble learning. The complementarity of sub-size pathology image classifiers when machine performance is insufficient is explored in this experimental platform. We choose seven classical machine learning classifiers and four deep learning classifiers for classification experiments on the GasHisSDB database. Among them, classical machine learning algorithms extract five different image virtual features to match multiple classifier algorithms. For deep learning, we choose three convolutional neural network classifiers. In addition, we also choose a novel Transformer-based classifier. The experimental platform, in which a large number of classical machine learning and deep learning methods are performed, demonstrates that there are differences in the performance of different classifiers on GasHisSDB. Classical machine learning models exist for classifiers that classify Abnormal categories very well, while classifiers that excel in classifying Normal categories also exist. Deep learning models also exist with multiple models that can be complementarity. Suitable classifiers are selected for ensemble learning, when machine performance is insufficient. This experimental platform demonstrates that multiple classifiers are indeed complementarity and can improve the efficiency of ensemble learning. This can better assist doctors in diagnosis, improve the detection of gastric cancer, and increase the cure rate.      
### 9.Guiding Vector Fields for Following Occluded Paths  [ :arrow_down: ](https://arxiv.org/pdf/2205.12760.pdf)
>  Accurately following a geometric desired path in a two-dimensional space is a fundamental task for many engineering systems, in particular mobile robots. When the desired path is occluded by obstacles, it is necessary and crucial to temporarily deviate from the path for obstacle/collision avoidance. In this paper, we develop a composite guiding vector field via the use of smooth bump functions, and provide theoretical guarantees that the integral curves of the vector field can follow an arbitrary sufficiently smooth desired path and avoid collision with obstacles of arbitrary shapes. These two behaviors are reactive since path (re)-planning and global map construction are not involved. To deal with the common deadlock problem, we introduce a switching vector field, and the Zeno behavior is excluded. Simulations are conducted to support the theoretical results.      
### 10.Semantic-preserved Communication System for Highly Efficient Speech Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2205.12727.pdf)
>  Deep learning (DL) based semantic communication methods have been explored for the efficient transmission of images, text, and speech in recent years. In contrast to traditional wireless communication methods that focus on the transmission of abstract symbols, semantic communication approaches attempt to achieve better transmission efficiency by only sending the semantic-related information of the source data. In this paper, we consider semantic-oriented speech transmission which transmits only the semantic-relevant information over the channel for the speech recognition task, and a compact additional set of semantic-irrelevant information for the speech reconstruction task. We propose a novel end-to-end DL-based transceiver which extracts and encodes the semantic information from the input speech spectrums at the transmitter and outputs the corresponding transcriptions from the decoded semantic information at the receiver. For the speech to speech transmission, we further include a CTC alignment module that extracts a small number of additional semantic-irrelevant but speech-related information for the better reconstruction of the original speech signals at the receiver. The simulation results confirm that our proposed method outperforms current methods in terms of the accuracy of the predicted text for the speech to text transmission and the quality of the recovered speech signals for the speech to speech transmission, and significantly improves transmission efficiency. More specifically, the proposed method only sends 16% of the amount of the transmitted symbols required by the existing methods while achieving about 10% reduction in WER for the speech to text transmission. For the speech to speech transmission, it results in an even more remarkable improvement in terms of transmission efficiency with only 0.2% of the amount of the transmitted symbols required by the existing method.      
### 11.COVID-19 Severity Classification on Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.12705.pdf)
>  Biomedical imaging analysis combined with artificial intelligence (AI) methods has proven to be quite valuable in order to diagnose COVID-19. So far, various classification models have been used for diagnosing COVID-19. However, classification of patients based on their severity level is not yet analyzed. In this work, we classify covid images based on the severity of the infection. First, we pre-process the X-ray images using a median filter and histogram equalization. Enhanced X-ray images are then augmented using SMOTE technique for achieving a balanced dataset. Pre-trained Resnet50, VGG16 model and SVM classifier are then used for feature extraction and classification. The result of the classification model confirms that compared with the alternatives, with chest X-Ray images, the ResNet-50 model produced remarkable classification results in terms of accuracy (95%), recall (0.94), and F1-Score (0.92), and precision (0.91).      
### 12.Trilateration-Based Device-Free Sensing: Two Base Stations and One Passive IRS Are Sufficient  [ :arrow_down: ](https://arxiv.org/pdf/2205.12667.pdf)
>  The classic trilateration technique can localize each target based on its distances to three anchors with known coordinates. Usually, this technique requires all the anchors and targets, e.g., the satellites and the mobile phones in Global Navigation Satellite System (GNSS), to actively transmit/receive radio signals such that the delay of the one-way radio signal propagated between each anchor and each target can be measured. Excitingly, this paper will show that the trilateration technique can be generalized to the scenario where one of the three anchors and all the targets merely reflect the radio signals passively as in radar networks, even if the propagation delay between the passive IRS and the passive targets is difficult to be measured directly, and the data association issue for multi-sensor multi-target tracking arises. Specifically, we consider device-free sensing in a cellular network consisting of two base stations (BSs), one passive intelligent reflecting surface (IRS), and multiple passive targets, to realize integrated sensing and communication (ISAC). The two BSs transmit the orthogonal frequency division multiplexing (OFDM) signals in the downlink and estimate the locations of the targets based on their reflected signals via/not via the IRS. We propose an efficient trilateration-based strategy that can first estimate the distances of each target to the two BSs and the IRS and then localize the targets. Numerical results show that the considered networked sensing architecture with heterogenous anchors can outperform its counterpart with three BSs.      
### 13.Implicit Function Theorem: Estimates on the size of the domain  [ :arrow_down: ](https://arxiv.org/pdf/2205.12661.pdf)
>  In this article, we provide explicit estimates on the domain on which the Implicit Function Theorem (ImFT) and the Inverse Function Theorem (IFT) are valid. For maps that are continuously differentiable upto second order, the estimates depend upon the magnitude of the first-order derivatives evaluated at the point of interest and a bound on the second-order derivatives over a region of interest. One of the key contributions of this article is to come up with estimates that require minimal numerical computation. In particular, we do not perform any optimization to come up with these estimates. The derived bounds are then applied to compute the robustness margin for Quadratic Problems and then utilize these bounds to compute the allowable power variations to ensure stable operations of the Power System Networks. Another key application of these bounds is in estimating the domain of feedback linearization for discrete-time control systems which are to be presented in a companion paper along with results on the feedback linearizability of the numerical integration techniques.      
### 14.On the Impact of Hardware Impairments on RIS-aided Localization  [ :arrow_down: ](https://arxiv.org/pdf/2205.12599.pdf)
>  We investigate a reconfigurable intelligent surface (RIS)-aided near-field localization system with single-antenna user equipment (UE) and base station (BS) under hardware impairments by considering a practical phase-dependent RIS amplitude variations model. To analyze the localization performance under the mismatch between the practical model and the ideal model with unit-amplitude RIS elements, we employ the misspecified Cramér-Rao bound (MCRB). Based on the MCRB derivation, the lower bound (LB) on the mean-squared error for estimation of UE position is evaluated and shown to converge to the MCRB at low signal-to-noise ratios (SNRs). Simulation results indicate more severe performance degradation due to the model misspecification with increasing SNR. In addition, the mismatched maximum likelihood (MML) estimator is derived and found to be tight to the LB in the high SNR regime. Finally, we observe that the model mismatch can lead to an order-of-magnitude localization performance loss at high SNRs.      
### 15.A Real-World Radio Frequency Signal Dataset Based on LTE System and Variable Channels  [ :arrow_down: ](https://arxiv.org/pdf/2205.12577.pdf)
>  Radio Frequency Fingerprint (RFF) identification on account of deep learning has the potential to enhance the security performance of wireless networks. Recently, several RFF datasets were proposed to satisfy requirements of large-scale datasets. However, most of these datasets are collected from 2.4G WiFi devices and through similar channel environments. Meanwhile, they only provided receiving data collected by the specific equipment. This paper utilizes software radio peripheral as a dataset generating platform. Therefore, the user can customize the parameters of the dataset, such as frequency band, modulation mode, antenna gain, and so on. In addition, the proposed dataset is generated through various and complex channel environments, which aims to better characterize the radio frequency signals in the real world. We collect the dataset at transmitters and receivers to simulate a real-world RFF dataset based on the long-term evolution (LTE). Furthermore, we verify the dataset and confirm its reliability. The dataset and reproducible code of this paper can be downloaded from GitHub link: <a class="link-external link-https" href="https://github.com/njuptzsp/XSRPdataset" rel="external noopener nofollow">this https URL</a>.      
### 16.Learning dynamics from partial observations with structured neural ODEs  [ :arrow_down: ](https://arxiv.org/pdf/2205.12550.pdf)
>  Identifying dynamical systems from experimental data is a notably difficult task. Prior knowledge generally helps, but the extent of this knowledge varies with the application, and customized models are often needed. We propose a flexible framework to incorporate a broad spectrum of physical insight into neural ODE-based system identification, giving physical interpretability to the resulting latent space. This insight is either enforced through hard constraints in the optimization problem or added in its cost function. In order to link the partial and possibly noisy observations to the latent state, we rely on tools from nonlinear observer theory to build a recognition model. We demonstrate the performance of the proposed approach on numerical simulations and on an experimental dataset from a robotic exoskeleton.      
### 17.Using Loaded N-port Structures to Achieve the Continuous-Space Electromagnetic Channel Capacity Bound  [ :arrow_down: ](https://arxiv.org/pdf/2205.12501.pdf)
>  A method for achieving the continuous-space electromagnetic channel capacity bound using loaded N-port structures is described. It is relevant for the design of compact multiple-input multiple-output (MIMO) antennas that can achieve channel capacity bounds when constrained by size. The method is not restricted to a specific antenna configuration and a closed-form expression for the channel capacity limits are provided with various constraints. Furthermore, using loaded N-port structures to represent arbitrary antenna geometries, an efficient optimization approach is proposed for finding the optimum MIMO antenna design that achieves the channel capacity bounds. Simulation results of the channel capacity bounds achieved using our MIMO antenna design with one square wavelength size are provided. These show that at least 18 ports can be supported in one square wavelength and achieve the continuous-space electromagnetic channel capacity bound. The results demonstrate that our method can link continuous-space electromagnetic channel capacity bounds to MIMO antenna design.      
### 18.A Survey of Graph-Theoretic Approaches for Analyzing the Resilience of Networked Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.12498.pdf)
>  As the scale of networked control systems increases and interactions between different subsystems become more sophisticated, questions of the resilience of such networks increase in importance. The need to redefine classical system and control-theoretic notions using the language of graphs has recently started to gain attention as a fertile and important area of research. This paper presents an overview of graph-theoretic methods for analyzing the resilience of networked control systems. We discuss various distributed algorithms operating on networked systems and investigate their resilience against adversarial actions by looking at the structural properties of their underlying networks. We present graph-theoretic methods to quantify the attack impact, and reinterpret some system-theoretic notions of robustness from a graph-theoretic standpoint to mitigate the impact of the attacks. Moreover, we discuss miscellaneous problems in the security of networked control systems which use graph-theory as a tool in their analyses. We conclude by introducing some avenues for further research in this field.      
### 19.An Investigation on Applying Acoustic Feature Conversion to ASR of Adult and Child Speech  [ :arrow_down: ](https://arxiv.org/pdf/2205.12477.pdf)
>  The performance of child speech recognition is generally less satisfactory compared to adult speech due to limited amount of training data. Significant performance degradation is expected when applying an automatic speech recognition (ASR) system trained on adult speech to child speech directly, as a result of domain mismatch. The present study is focused on adult-to-child acoustic feature conversion to alleviate this mismatch. Different acoustic feature conversion approaches, including deep neural network based and signal processing based, are investigated and compared under a fair experimental setting, in which converted acoustic features from the same amount of labeled adult speech are used to train the ASR models from scratch. Experimental results reveal that not all of the conversion methods lead to ASR performance gain. Specifically, as a classic unsupervised domain adaptation method, the statistic matching does not show an effectiveness. A disentanglement-based auto-encoder (DAE) conversion framework is found to be useful and the approach of F0 normalization achieves the best performance. It is noted that the F0 distribution of converted features is an important attribute to reflect the conversion quality, while utilizing an adult-child deep classification model to make judgment is shown to be inappropriate.      
### 20.Vehicle Guidance and Tracking Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.12470.pdf)
>  Our application of command and control is the Aegis Combat System. Major components of this system include missile guidance and missile tracking. To look further into some of the aspects of these systems, an extremely simplified model of the Aegis Combat System will be designed. In this simplified model, a small-scale car will autonomously follow a small-scale remote-controlled car. There will be three major components of this system: the controller and the two small-scale cars. Through this model, the team can demonstrate the real-world application of certain aspects of C2 such as command, communication, and sensor data fusion. Figure 1 shows a picture of the Aegis Combat System.      
### 21.Over-the-Air Design of GAN Training for mmWave MIMO Channel Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12445.pdf)
>  Future wireless systems are trending towards higher carrier frequencies that offer larger communication bandwidth but necessitate the use of large antenna arrays. Existing signal processing techniques for channel estimation do not scale well to this "high-dimensional" regime in terms of performance and pilot overhead. Meanwhile, training deep learning based approaches for channel estimation requires large labeled datasets mapping pilot measurements to clean channel realizations, which can only be generated offline using simulated channels. In this paper, we develop a novel unsupervised over-the-air (OTA) algorithm that utilizes noisy received pilot measurements to train a deep generative model to output beamspace MIMO channel realizations. Our approach leverages Generative Adversarial Networks (GAN), while using a conditional input to distinguish between Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) channel realizations. We also present a federated implementation of the OTA algorithm that distributes the GAN training over multiple users and greatly reduces the user side computation. We then formulate channel estimation from a limited number of pilot measurements as an inverse problem and reconstruct the channel by optimizing the input vector of the trained generative model. Our proposed approach significantly outperforms Orthogonal Matching Pursuit on both LOS and NLOS channel models, and EM-GM-AMP -- an Approximate Message Passing algorithm -- on LOS channel models, while achieving comparable performance on NLOS channel models in terms of the normalized channel reconstruction error. More importantly, our proposed framework has the potential to be trained online using real noisy pilot measurements, is not restricted to a specific channel model and can even be utilized for a federated OTA design of a dataset generator from noisy data.      
### 22.Design of an embedded system with on-demand image capturing and transmission for remote agricultural monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2205.12441.pdf)
>  The ability to visually verify some element of a remotely controlled agricultural automation system through a photograph is valuable in many cases, not only in the operational phase of the system, but especially in the design and implementation phases. Owing to the remote location of many of the application sites, cellular technology is one enabling medium through which wireless transmission of the photographs could be realized. As data usage is a concern for systems using cellular technology, MQTT chosen over other protocols due to its lower message-to-header overhead. This paper outlines the hardware and firmware design of the LTE Cat-M1 enabled embedded system and the backend web development of the cloud-based web application to facilitate the receiving of the photograph. A satisfactory degree of implementation success was achieved in this project, with deployment to a production environment possible after further refinements.      
### 23.Skin Cancer Diagnostics with an All-Inclusive Smartphone Application  [ :arrow_down: ](https://arxiv.org/pdf/2205.12438.pdf)
>  Among the different types of skin cancer, melanoma is considered to be the deadliest and is difficult to treat at advanced stages. Detection of melanoma at earlier stages can lead to reduced mortality rates. Desktop-based computer-aided systems have been developed to assist dermatologists with early diagnosis. However, there is significant interest in developing portable, at-home melanoma diagnostic systems which can assess the risk of cancerous skin lesions. Here, we present a smartphone application that combines image capture capabilities with preprocessing and segmentation to extract the Asymmetry, Border irregularity, Color variegation, and Diameter (ABCD) features of a skin lesion. Using the feature sets, classification of malignancy is achieved through support vector machine classifiers. By using adaptive algorithms in the individual data-processing stages, our approach is made computationally light, user friendly, and reliable in discriminating melanoma cases from benign ones. Images of skin lesions are either captured with the smartphone camera or imported from public datasets. The entire process from image capture to classification runs on an Android smartphone equipped with a detachable 10x lens, and processes an image in less than a second. The overall performance metrics are evaluated on a public database of 200 images with Synthetic Minority Over-sampling Technique (SMOTE) (80% sensitivity, 90% specificity, 88% accuracy, and 0.85 area under curve (AUC)) and without SMOTE (55% sensitivity, 95% specificity, 90% accuracy, and 0.75 AUC). The evaluated performance metrics and computation times are comparable or better than previous methods. This all-inclusive smartphone application is designed to be easy-to-download and easy-to-navigate for the end user, which is imperative for the eventual democratization of such medical diagnostic systems.      
### 24.Interaction of a priori Anatomic Knowledge with Self-Supervised Contrastive Learning in Cardiac Magnetic Resonance Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2205.12429.pdf)
>  Training deep learning models on cardiac magnetic resonance imaging (CMR) can be a challenge due to the small amount of expert generated labels and inherent complexity of data source. Self-supervised contrastive learning (SSCL) has recently been shown to boost performance in several medical imaging tasks. However, it is unclear how much the pre-trained representation reflects the primary organ of interest compared to spurious surrounding tissue. In this work, we evaluate the optimal method of incorporating prior knowledge of anatomy into a SSCL training paradigm. Specifically, we evaluate using a segmentation network to explicitly local the heart in CMR images, followed by SSCL pretraining in multiple diagnostic tasks. We find that using a priori knowledge of anatomy can greatly improve the downstream diagnostic performance. Furthermore, SSCL pre-training with in-domain data generally improved downstream performance and more human-like saliency compared to end-to-end training and ImageNet pre-trained networks. However, introducing anatomic knowledge to pre-training generally does not have significant impact.      
### 25.Lyapunov based Stochastic Stability of a Quantum Decision System for Human-Machine Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2205.12378.pdf)
>  In mathematical psychology, decision makers are modeled using the Lindbladian equations from quantum mechanics to capture important human-centric features such as order effects and violation of the sure thing principle. We consider human-machine interaction involving a quantum decision maker (human) and a controller (machine). Given a sequence of human decisions over time, how can the controller dynamically provide input messages to adapt these decisions so as to converge to a specific decision? We show via novel stochastic Lyapunov arguments how the Lindbladian dynamics of the quantum decision maker can be controlled to converge to a specific decision asymptotically. Our methodology yields a useful mathematical framework for human-sensor decision making. The stochastic Lyapunov results are also of independent interest as they generalize recent results in the literature.      
### 26.DRL-based Resource Allocation in Remote State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12267.pdf)
>  Remote state estimation, where sensors send their measurements of distributed dynamic plants to a remote estimator over shared wireless resources, is essential for mission-critical applications of Industry 4.0. Existing algorithms on dynamic radio resource allocation for remote estimation systems assumed oversimplified wireless communications models and can only work for small-scale settings. In this work, we consider remote estimation systems with practical wireless models over the orthogonal multiple-access and non-orthogonal multiple-access schemes. We derive necessary and sufficient conditions under which remote estimation systems can be stabilized. The conditions are described in terms of the transmission power budget, channel statistics, and plants' parameters. For each multiple-access scheme, we formulate a novel dynamic resource allocation problem as a decision-making problem for achieving the minimum overall long-term average estimation mean-square error. Both the estimation quality and the channel quality states are taken into account for decision making. We systematically investigated the problems under different multiple-access schemes with large discrete, hybrid discrete-and-continuous, and continuous action spaces, respectively. We propose novel action-space compression methods and develop advanced deep reinforcement learning algorithms to solve the problems. Numerical results show that our algorithms solve the resource allocation problems effectively and provide much better scalability than the literature.      
### 27.Joint Beam Management and Power Allocation in THz-NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.12938.pdf)
>  This paper investigates how to apply non-orthogonal multiple access (NOMA) as an add-on in terahertz (THz) networks. In particular, prior to the implementation of NOMA, it is assumed that there exists a legacy THz system, where spatial beams have already been configured to serve legacy primary users. The aim of this paper is to study how these pre-configured spatial beams can be used as a type of bandwidth resources, on which additional secondary users are served without degrading the performance of the legacy primary users. A joint beam management and power allocation problem is first formulated as a mixed combinatorial non-convex optimization problem, and then solved by two methods with different performance-complexity tradeoffs, one based on the branch and bound method and the other based on successive convex approximation. Both analytical and simulation results are presented to illustrate the new features of beam-based resource allocation in THz-NOMA networks and also demonstrate that those pre-configured spatial beams can be employed to improve the system throughput and connectivity in a spectrally efficient manner.      
### 28.These Maps Are Made For Walking: Real-Time Terrain Property Estimation for Mobile Robots  [ :arrow_down: ](https://arxiv.org/pdf/2205.12925.pdf)
>  The equations of motion governing mobile robots are dependent on terrain properties such as the coefficient of friction, and contact model parameters. Estimating these properties is thus essential for robotic navigation. Ideally any map estimating terrain properties should run in real time, mitigate sensor noise, and provide probability distributions of the aforementioned properties, thus enabling risk-mitigating navigation and planning. This paper addresses these needs and proposes a Bayesian inference framework for semantic mapping which recursively estimates both the terrain surface profile and a probability distribution for terrain properties using data from a single RGB-D camera. The proposed framework is evaluated in simulation against other semantic mapping methods and is shown to outperform these state-of-the-art methods in terms of correctly estimating simulated ground-truth terrain properties when evaluated using a precision-recall curve and the Kullback-Leibler divergence test. Additionally, the proposed method is deployed on a physical legged robotic platform in both indoor and outdoor environments, and we show our method correctly predicts terrain properties in both cases. The proposed framework runs in real-time and includes a ROS interface for easy integration.      
### 29.Image Colorization using U-Net with Skip Connections and Fusion Layer on Landscape Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.12867.pdf)
>  We present a novel technique to automatically colorize grayscale images that combine the U-Net model and Fusion Layer features. This approach allows the model to learn the colorization of images from pre-trained U-Net. Moreover, the Fusion layer is applied to merge local information results dependent on small image patches with global priors of an entire image on each class, forming visually more compelling colorization results. Finally, we validate our approach with a user study evaluation and compare it against state-of-the-art, resulting in improvements.      
### 30.On Building Spoken Language Understanding Systems for Low Resourced Languages  [ :arrow_down: ](https://arxiv.org/pdf/2205.12818.pdf)
>  Spoken dialog systems are slowly becoming and integral part of the human experience due to their various advantages over textual interfaces. Spoken language understanding (SLU) systems are fundamental building blocks of spoken dialog systems. But creating SLU systems for low resourced languages is still a challenge. In a large number of low resourced language, we don't have access to enough data to build automatic speech recognition (ASR) technologies, which are fundamental to any SLU system. Also, ASR based SLU systems do not generalize to unwritten languages. In this paper, we present a series of experiments to explore extremely low-resourced settings where we perform intent classification with systems trained on as low as one data-point per intent and with only one speaker in the dataset. We also work in a low-resourced setting where we do not use language specific ASR systems to transcribe input speech, which compounds the challenge of building SLU systems to simulate a true low-resourced setting. We test our system on Belgian Dutch (Flemish) and English and find that using phonetic transcriptions to make intent classification systems in such low-resourced setting performs significantly better than using speech features. Specifically, when using a phonetic transcription based system over a feature based system, we see average improvements of 12.37% and 13.08% for binary and four-class classification problems respectively, when averaged over 49 different experimental settings.      
### 31.Ultra-compact Binary Neural Networks for Human Activity Recognition on RISC-V Processors  [ :arrow_down: ](https://arxiv.org/pdf/2205.12781.pdf)
>  Human Activity Recognition (HAR) is a relevant inference task in many mobile applications. State-of-the-art HAR at the edge is typically achieved with lightweight machine learning models such as decision trees and Random Forests (RFs), whereas deep learning is less common due to its high computational complexity. In this work, we propose a novel implementation of HAR based on deep neural networks, and precisely on Binary Neural Networks (BNNs), targeting low-power general purpose processors with a RISC-V instruction set. BNNs yield very small memory footprints and low inference complexity, thanks to the replacement of arithmetic operations with bit-wise ones. However, existing BNN implementations on general purpose processors impose constraints tailored to complex computer vision tasks, which result in over-parametrized models for simpler problems like HAR. Therefore, we also introduce a new BNN inference library, which targets ultra-compact models explicitly. With experiments on a single-core RISC-V processor, we show that BNNs trained on two HAR datasets obtain higher classification accuracy compared to a state-of-the-art baseline based on RFs. Furthermore, our BNN reaches the same accuracy of a RF with either less memory (up to 91%) or more energy-efficiency (up to 70%), depending on the complexity of the features extracted by the RF.      
### 32.Surprises in adversarially-trained linear regression  [ :arrow_down: ](https://arxiv.org/pdf/2205.12695.pdf)
>  State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially constructed. Adversarial training is one of the most effective approaches to defend against such examples. We show that for linear regression problems, adversarial training can be formulated as a convex problem. This fact is then used to show that $\ell_\infty$-adversarial training produces sparse solutions and has many similarities to the lasso method. Similarly, $\ell_2$-adversarial training has similarities with ridge regression. We use a robust regression framework to analyze and understand these similarities and also point to some differences. Finally, we show how adversarial training behaves differently from other regularization methods when estimating overparameterized models (i.e., models with more parameters than datapoints). It minimizes a sum of three terms which regularizes the solution, but unlike lasso and ridge regression, it can sharply transition into an interpolation mode. We show that for sufficiently many features or sufficiently small regularization parameters, the learned model perfectly interpolates the training data while still exhibiting good out-of-sample performance.      
### 33.Optimizing UAV Recharge Scheduling for Heterogeneous and Persistent Aerial Service  [ :arrow_down: ](https://arxiv.org/pdf/2205.12656.pdf)
>  The adoption of UAVs in communication networks is becoming reality thanks to the deployment of advanced solutions for connecting UAVs and using them as communication relays. However, the use of UAVs introduces novel energy constraints and scheduling challenges in the dynamic management of network devices, due to the need to call back and recharge, or substitute, UAVs that run out of energy. In this paper, we design UAV recharging schemes under realistic assumptions on limited flight times and time consuming charging operations. Such schemes are designed to minimize the size of the fleet to be devoted to a persistent service of a set of aerial locations, hence its cost. We consider a fleet of homogeneous UAVs both under homogeneous and heterogeneous service topologies. For UAVs serving aerial locations with homogeneous distances to a recharge station, we design a simple scheduling, that we name HORR, which we prove to be feasible and optimal, in the sense that it uses the minimum possible number of UAVs to guarantee the coverage of the aerial service locations. For the case of non-evenly distributed aerial locations, we demonstrate that the problem becomes NP-hard, and design a lightweight recharging scheduling scheme, PHERR, that extends the operation of HORR to the heterogeneous case, leveraging the partitioning of the set of service locations. We show that PHERR is near-optimal because it approaches the performance limits identified through a lower bound that we formulate on the total fleet size.      
### 34.NTIRE 2022 Challenge on High Dynamic Range Imaging: Methods and Results  [ :arrow_down: ](https://arxiv.org/pdf/2205.12633.pdf)
>  This paper reviews the challenge on constrained high dynamic range (HDR) imaging that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop, held in conjunction with CVPR 2022. This manuscript focuses on the competition set-up, datasets, the proposed methods and their results. The challenge aims at estimating an HDR image from multiple respective low dynamic range (LDR) observations, which might suffer from under- or over-exposed regions and different sources of noise. The challenge is composed of two tracks with an emphasis on fidelity and complexity constraints: In Track 1, participants are asked to optimize objective fidelity scores while imposing a low-complexity constraint (i.e. solutions can not exceed a given number of operations). In Track 2, participants are asked to minimize the complexity of their solutions while imposing a constraint on fidelity scores (i.e. solutions are required to obtain a higher fidelity score than the prescribed baseline). Both tracks use the same data and metrics: Fidelity is measured by means of PSNR with respect to a ground-truth HDR image (computed both directly and with a canonical tonemapping operation), while complexity metrics include the number of Multiply-Accumulate (MAC) operations and runtime (in seconds).      
### 35.Robust Differential Dynamic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2205.12632.pdf)
>  Differential Dynamic Programming is an optimal control technique often used for trajectory generation. Many variations of this algorithm have been developed in the literature, including algorithms for stochastic dynamics or state and input constraints. In this contribution, we develop a robust version of Differential Dynamic Programming that uses generalized plants and multiplier relaxations for uncertainties. To this end, we study a version of the Bellman principle and use convex relaxations to account for uncertainties in the dynamic program. The resulting algorithm can be seen as a robust trajectory generation tool for nonlinear systems.      
### 36.Heterogeneous Reservoir Computing Models for Persian Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.12594.pdf)
>  Over the last decade, deep-learning methods have been gradually incorporated into conventional automatic speech recognition (ASR) frameworks to create acoustic, pronunciation, and language models. Although it led to significant improvements in ASRs' recognition accuracy, due to their hard constraints related to hardware requirements (e.g., computing power and memory usage), it is unclear if such approaches are the most computationally- and energy-efficient options for embedded ASR applications. Reservoir computing (RC) models (e.g., echo state networks (ESNs) and liquid state machines (LSMs)), on the other hand, have been proven inexpensive to train, have vastly fewer parameters, and are compatible with emergent hardware technologies. However, their performance in speech processing tasks is relatively inferior to that of the deep-learning-based models. To enhance the accuracy of the RC in ASR applications, we propose heterogeneous single and multi-layer ESNs to create non-linear transformations of the inputs that capture temporal context at different scales. To test our models, we performed a speech recognition task on the Farsdat Persian dataset. Since, to the best of our knowledge, standard RC has not yet been employed to conduct any Persian ASR tasks, we also trained conventional single-layer and deep ESNs to provide baselines for comparison. Besides, we compared the RC performance with a standard long-short-term memory (LSTM) model. Heterogeneous RC models (1) show improved performance to the standard RC models; (2) perform on par in terms of recognition accuracy with the LSTM, and (3) reduce the training time considerably.      
### 37.On-Demand Redundancy Grouping: Selectable Soft-Error Tolerance for a Multicore Cluster  [ :arrow_down: ](https://arxiv.org/pdf/2205.12580.pdf)
>  With the shrinking of technology nodes and the use of parallel processor clusters in hostile and critical environments, such as space, run-time faults caused by radiation are a serious cross-cutting concern, also impacting architectural design. This paper introduces an architectural approach to run-time configurable soft-error tolerance at the core level, augmenting a six-core open-source RISC-V cluster with a novel On-Demand Redundancy Grouping (ODRG) scheme. ODRG allows the cluster to operate either as two fault-tolerant cores, or six individual cores for high-performance, with limited overhead to switch between these modes during run-time. The ODRG unit adds less than 11% of a core's area for a three-core group, or a total of 1% of the cluster area, and shows negligible timing increase, which compares favorably to a commercial state-of-the-art implementation, and is 2.5$\times$ faster in fault recovery re-synchronization. Furthermore, unlike other implementations, when redundancy is not necessary, the ODRG approach allows the redundant cores to be used for independent computation, allowing up to 2.96$\times$ increase in performance for selected applications.      
### 38.Power-based Safety Layer for Aerial Vehicles in Physical Interaction using Lyapunov Exponents  [ :arrow_down: ](https://arxiv.org/pdf/2205.12562.pdf)
>  As the performance of autonomous systems increases, safety concerns arise, especially when operating in non-structured environments. To deal with these concerns, this work presents a safety layer for mechanical systems that detects and responds to unstable dynamics caused by external disturbances. The safety layer is implemented independently and on top of already present nominal controllers, like pose or wrench tracking, and limits power flow when the system's response would lead to instability. This approach is based on the computation of the Largest Lyapunov Exponent (LLE) of the system's error dynamics, which represent a measure of the dynamics' divergence or convergence rate. By actively computing this metric, divergent and possibly dangerous system behaviors can be promptly detected. The LLE is then used in combination with Control Barrier Functions (CBFs) to impose power limit constraints on a jerk controlled system. The proposed architecture is experimentally validated on an Omnidirectional Micro Aerial Vehicle (OMAV) both in free flight and interaction tasks.      
### 39.Some equivalence relation between persistent homology and morphological dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2205.12546.pdf)
>  In Mathematical Morphology (MM), connected filters based on dynamics are used to filter the extrema of an image. Similarly, persistence is a concept coming from Persistent Homology (PH) and Morse Theory (MT) that represents the stability of the extrema of a Morse function. Since these two concepts seem to be closely related, in this paper we examine their relationship, and we prove that they are equal on n-D Morse functions, n $\ge$ 1. More exactly, pairing a minimum with a 1-saddle by dynamics or pairing the same 1-saddle with a minimum by persistence leads exactly to the same pairing, assuming that the critical values of the studied Morse function are unique. This result is a step further to show how much topological data analysis and mathematical morphology are related, paving the way for a more in-depth study of the relations between these two research fields.      
### 40.Misleading Deep-Fake Detection with GAN Fingerprints  [ :arrow_down: ](https://arxiv.org/pdf/2205.12543.pdf)
>  Generative adversarial networks (GANs) have made remarkable progress in synthesizing realistic-looking images that effectively outsmart even humans. Although several detection methods can recognize these deep fakes by checking for image artifacts from the generation process, multiple counterattacks have demonstrated their limitations. These attacks, however, still require certain conditions to hold, such as interacting with the detection method or adjusting the GAN directly. In this paper, we introduce a novel class of simple counterattacks that overcomes these limitations. In particular, we show that an adversary can remove indicative artifacts, the GAN fingerprint, directly from the frequency spectrum of a generated image. We explore different realizations of this removal, ranging from filtering high frequencies to more nuanced frequency-peak cleansing. We evaluate the performance of our attack with different detection methods, GAN architectures, and datasets. Our results show that an adversary can often remove GAN fingerprints and thus evade the detection of generated images.      
### 41.TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12523.pdf)
>  Direct speech-to-speech translation (S2ST) systems leverage recent progress in speech representation learning, where a sequence of discrete representations (units) derived in a self-supervised manner, are predicted from the model and passed to a vocoder for speech synthesis, still facing the following challenges: 1) Acoustic multimodality: the discrete units derived from speech with same content could be indeterministic due to the acoustic property (e.g., rhythm, pitch, and energy), which causes deterioration of translation accuracy; 2) high latency: current S2ST systems utilize autoregressive models which predict each unit conditioned on the sequence previously generated, failing to take full advantage of parallelism. In this work, we propose TranSpeech, a speech-to-speech translation model with bilateral perturbation. To alleviate the acoustic multimodal problem, we propose bilateral perturbation, which consists of the style normalization and information enhancement stages, to learn only the linguistic information from speech samples and generate more deterministic representations. With reduced multimodality, we step forward and become the first to establish a non-autoregressive S2ST technique, which repeatedly masks and predicts unit choices and produces high-accuracy results in just a few cycles. Experimental results on three language pairs demonstrate the state-of-the-art results by up to 2.5 BLEU points over the best publicly-available textless S2ST baseline. Moreover, TranSpeech shows a significant improvement in inference latency, enabling speedup up to 21.4x than autoregressive technique. Audio samples are available at \url{<a class="link-external link-https" href="https://TranSpeech.github.io/" rel="external noopener nofollow">this https URL</a>}      
### 42.Molecular Absorption Effect: A Double-edged Sword of Terahertz Communications  [ :arrow_down: ](https://arxiv.org/pdf/2205.12520.pdf)
>  Communications in the terahertz band (THz) (0.1--10~THz) have been regarded as a promising technology for future 6G and beyond wireless systems, to overcome the challenges of evergrowing wireless data traffic and crowded spectrum. As the frequency increases from the microwave band to the THz band, new spectrum features pose unprecedented challenges to wireless communication system design. The molecular absorption effect is one of the new THz spectrum properties, which enlarges the path loss and noise at specific frequencies. This brings in a double-edged sword for THz wireless communication systems. On one hand, from the data rate viewpoint, molecular absorption is detrimental, since it mitigates the received signal power and degrades the channel capacity. On the other hand, it is worth noticing that for wireless security and covertness, the molecular absorption effect can be utilized to safeguard THz communications among users. In this paper, the features of the molecular absorption effect and their impact on the THz system design are analyzed under various scenarios, with the ultimate goal of providing guidelines to how better exploit this unique THz phenomenon. Specifically, since the molecular absorption greatly depends on the propagation medium, different communication scenarios consisting of various media are discussed, including terrestrial, air and space, sea surface and nano-scale communications. Furthermore, two novel molecular absorption enlightened secure and covert communication schemes are presented, where the molecular absorption effect is utilized as the key and unique feature to boost security and covertness.      
### 43.Mathematical Modelling of TEAM and VTEAM Memristor Model Using VerilogA  [ :arrow_down: ](https://arxiv.org/pdf/2205.12472.pdf)
>  Anyone who looks into the circuitry world will be familiar with the three fundamental circuit elements - capacitor, resistor, and inductor. These circuit elements are defined by the relation between two of the four fundamental circuit variables current, voltage, charge, and flux. However, in 1971, Prof. Leon Chua proposed on the grounds of symmetry that there should be a fourth fundamental circuit element that gives the relation between flux and charge. He named this the memristor, which is short for memory resistor. This theory was then practicallymodeled, in May 2008 when the researchers at HP Labs published a paper announcing a model for a physical realization of a memristor. This report mainly focuses on the model of memristor and its applications. The advantages of variable resistance, flexibility, no leakage current, and compatibility with CMOS. The element memristor exhibits different characteristics for different applications which results in the formation of different models of the memristor. This paper gives a review of different models of the memristor. Memristors devices can be used in many applications such as memory, logic, and neuromorphic systems. A computer model of the memristor would be a useful tool for analyzing circuit behavior to help in developing the application of this memristor is a passive circuit element via simulation. In this paper, various VerilogA model of memristor devices are simulated for sinusoidal inputs and output are verified Various window functions has been used. The circuit analysis of the various memristor models is done      
### 44.FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12465.pdf)
>  Functional magnetic resonance imaging (fMRI) is one of the most common imaging modalities to investigate brain functions. Recent studies in neuroscience stress the great potential of functional brain networks constructed from fMRI data for clinical predictions. Traditional functional brain networks, however, are noisy and unaware of downstream prediction tasks, while also incompatible with the deep graph neural network (GNN) models. In order to fully unleash the power of GNNs in network-based fMRI analysis, we develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via deep brain network generation. In particular, we formulate (1) prominent region of interest (ROI) features extraction, (2) brain networks generation, and (3) clinical predictions with GNNs, in an end-to-end trainable model under the guidance of particular prediction tasks. Along with the process, the key novel component is the graph generator which learns to transform raw time-series features into task-oriented brain networks. Our learnable graphs also provide unique interpretations by highlighting prediction-related brain regions. Comprehensive experiments on two datasets, i.e., the recently released and currently largest publicly available fMRI dataset Adolescent Brain Cognitive Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior effectiveness and interpretability of FBNETGEN. The implementation is available at <a class="link-external link-https" href="https://github.com/Wayfear/FBNETGEN" rel="external noopener nofollow">this https URL</a>.}      
### 45.Improving CTC-based ASR Models with Gated Interlayer Collaboration  [ :arrow_down: ](https://arxiv.org/pdf/2205.12462.pdf)
>  For Automatic Speech Recognition (ASR), the CTC-based methods have become a dominant paradigm due to its simple architecture and efficient non-autoregressive inference manner. However, these methods without external language models usually lack the capacity of modeling the conditional dependencies and the textual interaction. In this work, we present a Gated Interlayer Collaboration (GIC) mechanism which introduces the contextual information into the models and relaxes the conditional independence assumption of the CTC-based models. Specifically, we train the model with intermediate CTC losses calculated by the interlayer outputs of the model, in which the probability distributions of the intermediate layers naturally serve as soft label sequences. The GIC block consists of an embedding layer to obtain the textual embedding of the soft label at each position, and a gate unit to fuse the textual embedding and the acoustic features. Experiments on AISHELL-1 and AIDATATANG benchmarks show that the proposed method outperforms the recently published CTC-based ASR models. Specifically, our method achieves CER of 4.0%/4.4% on AISHELL-1 dev/test sets and CER of 3.8%/4.4% on AIDATATANG dev/test sets using CTC greedy search decoding without external language models.      
### 46.A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.12459.pdf)
>  Deep Neural Networks have been successfully applied in hyperspectral image classification. However, most of prior works adopt general deep architectures while ignore the intrinsic structure of the hyperspectral image, such as the physical noise generation. This would make these deep models unable to generate discriminative features and provide impressive classification performance. To leverage such intrinsic information, this work develops a novel deep learning framework with the noise inclined module and denoise framework for hyperspectral image classification. First, we model the spectral signature of hyperspectral image with the physical noise model to describe the high intraclass variance of each class and great overlapping between different classes in the image. Then, a noise inclined module is developed to capture the physical noise within each object and a denoise framework is then followed to remove such noise from the object. Finally, the CNN with noise inclined module and the denoise framework is developed to obtain discriminative features and provides good classification performance of hyperspectral image. Experiments are conducted over two commonly used real-world datasets and the experimental results show the effectiveness of the proposed method. The implementation of the proposed method and other compared methods could be accessed at <a class="link-external link-https" href="https://github.com/shendu-sw/noise-physical-framework" rel="external noopener nofollow">this https URL</a>.      
### 47.A Lightweight NMS-free Framework for Real-time Visual Fault Detection System of Freight Trains  [ :arrow_down: ](https://arxiv.org/pdf/2205.12458.pdf)
>  Real-time vision-based system of fault detection (RVBS-FD) for freight trains is an essential part of ensuring railway transportation safety. Most existing vision-based methods still have high computational costs based on convolutional neural networks. The computational cost is mainly reflected in the backbone, neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper, we propose a lightweight NMS-free framework to achieve real-time detection and high accuracy simultaneously. First, we use a lightweight backbone for feature extraction and design a fault detection pyramid to process features. This fault detection pyramid includes three novel individual modules using attention mechanism, bottleneck, and dilated convolution for feature enhancement and computation reduction. Instead of using NMS, we calculate different loss functions, including classification and location costs in the detection head, to further reduce computation. Experimental results show that our framework achieves over 83 frames per second speed with a smaller model size and higher accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource requirements of our method are low during the training and testing process.      
### 48.Transportation-Inequalities, Lyapunov Stability and Sampling for Dynamical Systems on Continuous State Space  [ :arrow_down: ](https://arxiv.org/pdf/2205.12448.pdf)
>  We study the concentration phenomenon for discrete-time random dynamical systems with an unbounded state space. We develop a heuristic approach towards obtaining exponential concentration inequalities for dynamical systems using an entirely functional analytic framework. We also show that existence of exponential-type Lyapunov function, compared to the purely deterministic setting, not only implies stability but also exponential concentration inequalities for sampling from the stationary distribution, via \emph{transport-entropy inequality} (T-E). These results have significant impact in \emph{reinforcement learning} (RL) and \emph{controls}, leading to exponential concentration inequalities even for unbounded observables, while neither assuming reversibility nor exact knowledge of random dynamical system (assumptions at heart of concentration inequalities in statistical mechanics and Markov diffusion processes).      
### 49.FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech  [ :arrow_down: ](https://arxiv.org/pdf/2205.12446.pdf)
>  We introduce FLEURS, the Few-shot Learning Evaluation of Universal Representations of Speech benchmark. FLEURS is an n-way parallel speech dataset in 102 languages built on top of the machine translation FLoRes-101 benchmark, with approximately 12 hours of speech supervision per language. FLEURS can be used for a variety of speech tasks, including Automatic Speech Recognition (ASR), Speech Language Identification (Speech LangID), Translation and Retrieval. In this paper, we provide baselines for the tasks based on multilingual pre-trained models like mSLAM. The goal of FLEURS is to enable speech technology in more languages and catalyze research in low-resource speech understanding.      
### 50.Constant Curvature Curve Tube Codes for Low-Latency Analog Error Correction  [ :arrow_down: ](https://arxiv.org/pdf/2205.12332.pdf)
>  Recent research in ultra-reliable and low latency communications (URLLC) for future wireless systems has spurred interest in short block-length codes. In this context, we introduce a new class of high-dimension constant curvature curves codes for analog error correction of independent continuous-alphabet uniform sources. In particular, we employ the circumradius function from knot theory to prescribe insulating tubes about the centerline of constant curvature curves. We then use tube packing density within a hypersphere to optimize the curve parameters. The resulting constant curvature curve tube (C3T) codes possess the smallest possible latency -- block-length is unity under bandwidth expansion mapping. Further, the codes provide within $5$ dB of Shannon's optimal performance theoretically achievable at the lower range of signal-to-noise ratios and BW expansion factors. We exploit the fact that the C3T encoder locus is a geodesic on a flat torus in even dimensions and a generalized helix in odd dimensions to obtain useful code properties and provide noise-reducing projections at the decoder stage. We validate the performance of these codes using fully connected multi-layer perceptrons that approximate maximum likelihood decoders. For the case of independent and identically distributed uniform sources, we show that analog error correction is advantageous over digital coding in terms of required block-lengths needed to match {signal-to-noise ratio, source-to-distortion ratio} tuples. The best possible digital codes require two to three orders of magnitude higher latency compared to C3T codes, thereby demonstrating the latter's utility for URLLC.      
### 51.Adaptive multilingual speech recognition with pretrained models  [ :arrow_down: ](https://arxiv.org/pdf/2205.12304.pdf)
>  Multilingual speech recognition with supervised learning has achieved great results as reflected in recent research. With the development of pretraining methods on audio and text data, it is imperative to transfer the knowledge from unsupervised multilingual models to facilitate recognition, especially in many languages with limited data. Our work investigated the effectiveness of using two pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for text, together with the adaptive weight techniques to massively improve the recognition quality on the public datasets containing CommonVoice and Europarl. Overall, we noticed an 44% improvement over purely supervised learning, and more importantly, each technique provides a different reinforcement in different languages. We also explore other possibilities to potentially obtain the best model by slightly adding either depth or relative attention to the architecture.      
### 52.On Observer-based Asymptotic Stabilization of Non-uniformly Observable Systems via Hybrid and Smooth Control: a Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2205.12300.pdf)
>  For systems that are not observable at the very equilibrium of interest to be stabilized, output-feedback stabilization is considerably challenging. In this paper we solve this control problem for the case-study of a second-order system that is bilinear and affine, both in the input and the output, but it is unobservable at the target equilibrium. The case-study is representative of a well-studied class of non-uniformly observable systems and stems from automotive control. Our main contribution is a novel certainty-equivalence hybrid controller that achieves asymptotic stabilization semiglobally. The controller relies on a switched observer that estimates the state, provided that the latter is 'kept away' from the singular equilibrium. To achieve both competing tasks, stabilization and estimation, the controller also relies on the keen construction of a piecewise-constant, converging, reference. Our main results are illustrated via numerical simulations on a meaningful example.      
### 53.Wavelet Feature Maps Compression for Image-to-Image CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2205.12268.pdf)
>  Convolutional Neural Networks (CNNs) are known for requiring extensive computational resources, and quantization is among the best and most common methods for compressing them. While aggressive quantization (i.e., less than 4-bits) performs well for classification, it may cause severe performance degradation in image-to-image tasks such as semantic segmentation and depth estimation. In this paper, we propose Wavelet Compressed Convolution (WCC) -- a novel approach for high-resolution activation maps compression integrated with point-wise convolutions, which are the main computational cost of modern architectures. To this end, we use an efficient and hardware-friendly Haar-wavelet transform, known for its effectiveness in image compression, and define the convolution on the compressed activation map. We experiment on various tasks, that benefit from high-resolution input, and by combining WCC with light quantization, we achieve compression rates equivalent to 1-4bit activation quantization with relatively small and much more graceful degradation in performance.      
### 54.An Artificial Bee Colony optimization-based approach for sizing and composition of Arctic offshore drilling support fleets considering cost-efficiency  [ :arrow_down: ](https://arxiv.org/pdf/2205.12263.pdf)
>  This article presents an optimization-based approach for sizing and composition of an Arctic offshore drilling support fleet considering cost-efficiency. The approach studies the main types of duties related to Arctic offshore drillings: supply, towing, anchor handling, standby, oil spill response, firefighting, and ice management. The approach considers the combined effect of the expected costs of accidental events, the versatility of individual support vessels, and ice management. The approach applies an Artificial Bee Colony algorithm-based optimization procedure. As demonstrated through case studies, the approach may help to find a range of cost-efficient fleet compositions. Some of the obtained solutions are similar to corresponding real-life fleets, indicating that the approach works in principle. Sensitivity analyses indicate that the consideration of the expected costs from accidental events significantly impacts the obtained solution, and that investments to reduce these costs may improve the overall cost-efficiency of an Arctic offshore drilling support fleet.      
