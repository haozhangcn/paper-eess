# ArXiv eess --Thu, 5 May 2022
### 1.Intelligent Reflecting Surface Aided Mobile Edge Computing With Binary Offloading: Energy Minimization for IoT Devices  [ :arrow_down: ](https://arxiv.org/pdf/2205.02194.pdf)
>  Mobile edge computing (MEC) is envisioned as a promising technique to support computation-intensive and timecritical applications in future Internet of Things (IoT) era. However, the uplink transmission performance will be highly impacted by the hostile wireless channel, the low bandwidth, and the low transmission power of IoT devices. Recently, intelligent reflecting surface (IRS) has drawn much attention because of its capability to control the wireless environments so as to enhance the spectrum and energy efficiencies of wireless communications. In this paper, we consider an IRS-aided multidevice MEC system where each IoT device follows the binary offloading policy, i.e., a task has to be computed as a whole either locally or remotely at the edge server. We aim to minimize the total energy consumption of devices by jointly optimizing the binary offloading modes, the CPU frequencies, the offloading powers, the offloading times and the IRS phase shifts for all devices. Two algorithms, which are greedy-based and penalty-based, are proposed to solve the challenging nonconvex and discontinuous problem. It is found that the penalty-based method has only linear complexity with respect to the number of devices, but it performs close to the greedy-based method with cubic complexity with respect to number of devices. Furthermore, binary offloading via IRS indeed saves more energy compared to the case without IRS.      
### 2.Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models  [ :arrow_down: ](https://arxiv.org/pdf/2205.02152.pdf)
>  Recent studies indicate that detecting radiographic patterns on CT scans can yield high sensitivity and specificity for COVID-19 localization. In this paper, we investigate the appropriateness of deep learning models transferability, for semantic segmentation of pneumonia-infected areas in CT images. Transfer learning allows for the fast initialization/ reutilization of detection models, given that large volumes of training are not available. Our work explores the efficacy of using pre-trained U-Net architectures, on a specific CT data set, for identifying Covid-19 side-effects over images from different datasets. Experimental results indicate improvement in the segmentation accuracy of identifying COVID-19 infected regions.      
### 3.Data Cleansing for Indoor Positioning Wi-Fi Fingerprinting Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2205.02096.pdf)
>  Wearable and IoT devices requiring positioning and localisation services grow in number exponentially every year. This rapid growth also produces millions of data entries that need to be pre-processed prior to being used in any indoor positioning system to ensure the data quality and provide a high Quality of Service (QoS) to the end-user. In this paper, we offer a novel and straightforward data cleansing algorithm for WLAN fingerprinting radio maps. This algorithm is based on the correlation among fingerprints using the Received Signal Strength (RSS) values and the Access Points (APs)'s identifier. We use those to compute the correlation among all samples in the dataset and remove fingerprints with low level of correlation from the dataset. We evaluated the proposed method on 14 independent publicly-available datasets. As a result, an average of 14% of fingerprints were removed from the datasets. The 2D positioning error was reduced by 2.7% and 3D positioning error by 5.3% with a slight increase in the floor hit rate by 1.2% on average. Consequently, the average speed of position prediction was also increased by 14%.      
### 4.Does a PESQNet (Loss) Require a Clean Reference Input? The Original PESQ Does, But ACR Listening Tests Don't  [ :arrow_down: ](https://arxiv.org/pdf/2205.02085.pdf)
>  Perceptual evaluation of speech quality (PESQ) requires a clean speech reference as input, but predicts the results from (reference-free) absolute category rating (ACR) tests. In this work, we train a fully convolutional recurrent neural network (FCRN) as deep noise suppression (DNS) model, with either a non-intrusive or an intrusive PESQNet, where only the latter has access to a clean speech reference. The PESQNet is used as a mediator providing a perceptual loss during the DNS training to maximize the PESQ score of the enhanced speech signal. For the intrusive PESQNet, we investigate two topologies, called early-fusion (EF) and middle-fusion (MF) PESQNet, and compare to the non-intrusive PESQNet to evaluate and to quantify the benefits of employing a clean speech reference input during DNS training. Detailed analyses show that the DNS trained with the MF-intrusive PESQNet outperforms the Interspeech 2021 DNS Challenge baseline and the same DNS trained with an MSE loss by 0.23 and 0.12 PESQ points, respectively. Furthermore, we can show that only marginal benefits are obtained compared to the DNS trained with the non-intrusive PESQNet. Therefore, as ACR listening tests, the PESQNet does not necessarily require a clean speech reference input, opening the possibility of using real data for DNS training.      
### 5.Rate-Splitting Multiple Access for 6G -- Part III: Interplay with Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2205.02036.pdf)
>  This letter is the third part of a three-part tutorial that focuses on rate-splitting multiple access (RSMA) for 6G. As Part III of the tutorial, this letter provides an overview of integrating RSMA and reconfigurable intelligent surface (RIS). We first introduce two potential PHY layer techniques, namely, RSMA and RIS, including the need for integrating RSMA with RIS and how they could help each other. Next, we provide a general model of an RIS-aided RSMA system and summarize some key performance metrics. Then, we discuss the major advantages of RIS-aided RSMA networks, and illustrate the rate region of RIS-aided RSMA for both perfect and imperfect channel conditions. Finally, we summarize the research challenges and open problems for RIS-aided RSMA systems. In conclusion, RSMA is a promising technology for next generation multiple access (NGMA) and future networks such as 6G and beyond.      
### 6.On the Diversity and Coded Modulation Design of Fluid Antenna Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.01962.pdf)
>  Reconfigurability is a desired characteristic of future communication networks. From a transceiver's standpoint, this can be materialized through the implementation of fluid antennas (FAs). An FA consists of a dielectric holder, in which a radiating liquid moves between pre-defined locations (called ports) that serve as the transceiver's antennas. Due to the nature of liquids, FAs can practically take any size and shape, making them both flexible and reconfigurable. In this paper, we deal with the outage probability of FAs under general fading channels, where a port is scheduled based on selection combining. An analytical framework is provided for the performance with and without estimation errors, as a result of post-scheduling delays. We show that although FAs achieve maximum diversity, this cannot be realized in the presence of delays. Hence, a linear prediction scheme is proposed that overcomes delays and restores the lost diversity by predicting the next scheduled port. Moreover, we design space-time coded modulations that exploit the FA's sequential operation with space-time rotations and code diversity. The derived expressions for the pairwise error probability and average word error rate give an accurate estimate of the performance. We illustrate that the proposed design attains maximum diversity, while keeping a low-complexity receiver, thereby confirming the feasibility of FAs.      
### 7.A Global Asymptotic Convergent Observer for SLAM  [ :arrow_down: ](https://arxiv.org/pdf/2205.01953.pdf)
>  This paper examines the global convergence problem of SLAM algorithms, an issue that faces topological obstructions. This is because the state-space of attitude dynamics is defined on a non-contractible manifold: the special orthogonal group of order three SO(3). Therefore, this paper presents a novel, gradient-based hybrid observer to overcome these topological obstacles. The Lyapunov stability theorem is used to prove the globally asymptotic convergence of the proposed algorithm. Finally, comparative analyses of two simulations were conducted to evaluate the performance of the proposed scheme and to demonstrate the superiority of the proposed hybrid observer to a smooth observer.      
### 8.Explainable Anomaly Detection for Industrial Control System Cybersecurity  [ :arrow_down: ](https://arxiv.org/pdf/2205.01930.pdf)
>  Industrial Control Systems (ICSs) are becoming more and more important in managing the operation of many important systems in smart manufacturing, such as power stations, water supply systems, and manufacturing sites. While massive digital data can be a driving force for system performance, data security has raised serious concerns. Anomaly detection, therefore, is essential for preventing network security intrusions and system attacks. Many AI-based anomaly detection methods have been proposed and achieved high detection performance, however, are still a "black box" that is hard to be interpreted. In this study, we suggest using Explainable Artificial Intelligence to enhance the perspective and reliable results of an LSTM-based Autoencoder-OCSVM learning model for anomaly detection in ICS. We demonstrate the performance of our proposed method based on a well-known SCADA dataset.      
### 9.Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary Differential Equations  [ :arrow_down: ](https://arxiv.org/pdf/2205.01897.pdf)
>  Recent research in deep learning has shown that neural networks can learn differential equations governing dynamical systems. In this paper, we adapt this concept to Virtual Analog (VA) modeling to learn the ordinary differential equations (ODEs) governing the first-order and the second-order diode clipper. The proposed models achieve performance comparable to state-of-the-art recurrent neural networks (RNNs) albeit using fewer parameters. We show that this approach does not require oversampling and allows to increase the sampling rate after the training has completed, which results in increased accuracy. Using a sophisticated numerical solver allows to increase the accuracy at the cost of slower processing. ODEs learned this way do not require closed forms but are still physically interpretable.      
### 10.A Nonlinear Car-following Controller Design Inspired By Human-driving Behaviors to Increase Comfort and Enhance Safety  [ :arrow_down: ](https://arxiv.org/pdf/2205.01879.pdf)
>  This paper investigates the car-following problem and proposes a nonlinear controller that considers driving comfort, safety concerns, steady-state response and transient response. This controller is designed based on the demands of lower cost, faster response, increased comfort, enhanced safety and elevated extendability from the automotive industry. Design insights and intuitions are provided in detail. Also, theoretical analysis are performed on plant stability, string stability and tracking performance of the closed-loop system. Conditions and guidelines are provided on the selection of control parameters. Comprehensive simulations are conducted to demonstrate the efficacy of the proposed controller in different driving scenarios.      
### 11.Joint Image Compression and Denoising via Latent-Space Scalability  [ :arrow_down: ](https://arxiv.org/pdf/2205.01874.pdf)
>  When it comes to image compression in digital cameras, denoising is traditionally performed prior to compression. However, there are applications where image noise may be necessary to demonstrate the trustworthiness of the image, such as court evidence and image forensics. This means that noise itself needs to be coded, in addition to the clean image itself. In this paper, we present a learnt image compression framework where image denoising and compression are performed jointly. The latent space of the image codec is organized in a scalable manner such that the clean image can be decoded from a subset of the latent space at a lower rate, while the noisy image is decoded from the full latent space at a higher rate. The proposed codec is compared against established compression and denoising benchmarks, and the experiments reveal considerable bitrate savings of up to 80% compared to cascade compression and denoising.      
### 12.Meta-Cognition. An Inverse-Inverse Reinforcement Learning Approach for Cognitive Radars  [ :arrow_down: ](https://arxiv.org/pdf/2205.01794.pdf)
>  This paper considers meta-cognitive radars in an adversarial setting. A cognitive radar optimally adapts its waveform (response) in response to maneuvers (probes) of a possibly adversarial moving target. A meta-cognitive radar is aware of the adversarial nature of the target and seeks to mitigate the adversarial target. How should the meta-cognitive radar choose its responses to sufficiently confuse the adversary trying to estimate the radar's utility function? This paper abstracts the radar's meta-cognition problem in terms of the spectra (eigenvalues) of the state and observation noise covariance matrices, and embeds the algebraic Riccati equation into an economics-based utility maximization setup. This adversarial target is an inverse reinforcement learner. By observing a noisy sequence of radar's responses (waveforms), the adversarial target uses a statistical hypothesis test to detect if the radar is a utility maximizer. In turn, the meta-cognitive radar deliberately chooses sub-optimal responses that increasing its Type-I error probability of the adversary's detector. We call this counter-adversarial step taken by the meta-cognitive radar as inverse inverse reinforcement learning (I-IRL). We illustrate the meta-cognition results of this paper via simple numerical examples. Our approach for meta-cognition in this paper is based on revealed preference theory in micro-economics and inspired by results in differential privacy and adversarial obfuscation in machine learning.      
### 13.The ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts  [ :arrow_down: ](https://arxiv.org/pdf/2205.01780.pdf)
>  The ICML Expressive Vocalization (ExVo) Competition is focused on understanding and generating vocal bursts: laughs, gasps, cries, and other non-verbal vocalizations that are central to emotional expression and communication. ExVo 2022, includes three competition tracks using a large-scale dataset of 59,201 vocalizations from 1,702 speakers. The first, ExVo-MultiTask, requires participants to train a multi-task model to recognize expressed emotions and demographic traits from vocal bursts. The second, ExVo-Generate, requires participants to train a generative model that produces vocal bursts conveying ten different emotions. The third, ExVo-FewShot, requires participants to leverage few-shot learning incorporating speaker identity to train a model for the recognition of 10 emotions conveyed by vocal bursts. This paper describes the three tracks and provides performance measures for baseline models using state-of-the-art machine learning strategies. The baseline for each track is as follows, for ExVo-MultiTask, a combined score, computing the harmonic mean of Concordance Correlation Coefficient (CCC), Unweighted Average Recall (UAR), and inverted Mean Absolute Error (MAE) ($S_{MTL}$) is at best, 0.335 $S_{MTL}$; for ExVo-Generate, we report FrÃ©chet inception distance (FID) scores ranging from 4.81 to 8.27 (depending on the emotion) between the training set and generated samples. We then combine the inverted FID with perceptual ratings of the generated samples ($S_{Gen}$) and obtain 0.174 $S_{Gen}$; and for ExVo-FewShot, a mean CCC of 0.444 is obtained.      
### 14.Deep Multi-Scale U-Net Architecture and Noise-Robust Training Strategies for Histopathological Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.01777.pdf)
>  Although the U-Net architecture has been extensively used for segmentation of medical images, we address two of its shortcomings in this work. Firstly, the accuracy of vanilla U-Net degrades when the target regions for segmentation exhibit significant variations in shape and size. Even though the U-Net already possesses some capability to analyze features at various scales, we propose to explicitly add multi-scale feature maps in each convolutional module of the U-Net encoder to improve segmentation of histology images. Secondly, the accuracy of a U-Net model also suffers when the annotations for supervised learning are noisy or incomplete. This can happen due to the inherent difficulty for a human expert to identify and delineate all instances of specific pathology very precisely and accurately. We address this challenge by introducing auxiliary confidence maps that emphasize less on the boundaries of the given target regions. Further, we utilize the bootstrapping properties of the deep network to address the missing annotation problem intelligently. In our experiments on a private dataset of breast cancer lymph nodes, where the primary task was to segment germinal centres and sinus histiocytosis, we observed substantial improvement over a U-Net baseline based on the two proposed augmentations.      
### 15.Data-Consistent Non-Cartesian Deep Subspace Learning for Efficient Dynamic MR Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2205.01770.pdf)
>  Non-Cartesian sampling with subspace-constrained image reconstruction is a popular approach to dynamic MRI, but slow iterative reconstruction limits its clinical application. Data-consistent (DC) deep learning can accelerate reconstruction with good image quality, but has not been formulated for non-Cartesian subspace imaging. In this study, we propose a DC non-Cartesian deep subspace learning framework for fast, accurate dynamic MR image reconstruction. Four novel DC formulations are developed and evaluated: two gradient decent approaches, a directly solved approach, and a conjugate gradient approach. We applied a U-Net model with and without DC layers to reconstruct T1-weighted images for cardiac MR Multitasking (an advanced multidimensional imaging method), comparing our results to the iteratively reconstructed reference. Experimental results show that the proposed framework significantly improves reconstruction accuracy over the U-Net model without DC, while significantly accelerating the reconstruction over conventional iterative reconstruction.      
### 16.Effect of Random Histogram Equalization on Breast Calcification Analysis Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.01684.pdf)
>  Early detection and analysis of calcifications in mammogram images is crucial in a breast cancer diagnosis workflow. Management of calcifications that require immediate follow-up and further analyzing its benignancy or malignancy can result in a better prognosis. Recent studies have shown that deep learning-based algorithms can learn robust representations to analyze suspicious calcifications in mammography. In this work, we demonstrate that randomly equalizing the histograms of calcification patches as a data augmentation technique can significantly improve the classification performance for analyzing suspicious calcifications. We validate our approach by using the CBIS-DDSM dataset for two classification tasks. The results on both the tasks show that the proposed methodology gains more than 1% mean accuracy and F1-score when equalizing the data with a probability of 0.4 when compared to not using histogram equalization. This is further supported by the t-tests, where we obtain a p-value of p&lt;0.0001, thus showing the statistical significance of our approach.      
### 17.SpineNetV2: Automated Detection, Labelling and Radiological Grading Of Clinical MR Scans  [ :arrow_down: ](https://arxiv.org/pdf/2205.01683.pdf)
>  This technical report presents SpineNetV2, an automated tool which: (i) detects and labels vertebral bodies in clinical spinal magnetic resonance (MR) scans across a range of commonly used sequences; and (ii) performs radiological grading of lumbar intervertebral discs in T2-weighted scans for a range of common degenerative changes. SpineNetV2 improves over the original SpineNet software in two ways: (1) The vertebral body detection stage is significantly faster, more accurate and works across a range of fields-of-view (as opposed to just lumbar scans). (2) Radiological grading adopts a more powerful architecture, adding several new grading schemes without loss in performance. A demo of the software is available at the project website: <a class="link-external link-http" href="http://zeus.robots.ox.ac.uk/spinenet2/" rel="external noopener nofollow">this http URL</a>.      
### 18.Physics to the Rescue: Deep Non-line-of-sight Reconstruction for High-speed Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2205.01679.pdf)
>  Computational approach to imaging around the corner, or non-line-of-sight (NLOS) imaging, is becoming a reality thanks to major advances in imaging hardware and reconstruction algorithms. A recent development towards practical NLOS imaging, Nam et al. demonstrated a high-speed non-confocal imaging system that operates at 5Hz, 100x faster than the prior art. This enormous gain in acquisition rate, however, necessitates numerous approximations in light transport, breaking many existing NLOS reconstruction methods that assume an idealized image formation model. To bridge the gap, we present a novel deep model that incorporates the complementary physics priors of wave propagation and volume rendering into a neural network for high-quality and robust NLOS reconstruction. This orchestrated design regularizes the solution space by relaxing the image formation model, resulting in a deep model that generalizes well on real captures despite being exclusively trained on synthetic data. Further, we devise a unified learning framework that enables our model to be flexibly trained using diverse supervision signals, including target intensity images or even raw NLOS transient measurements. Once trained, our model renders both intensity and depth images at inference time in a single forward pass, capable of processing more than 5 captures per second on a high-end GPU. Through extensive qualitative and quantitative experiments, we show that our method outperforms prior physics and learning based approaches on both synthetic and real measurements. We anticipate that our method along with the fast capturing system will accelerate future development of NLOS imaging for real world applications that require high-speed imaging.      
### 19.FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for Fundus Images Quality Grading  [ :arrow_down: ](https://arxiv.org/pdf/2205.01676.pdf)
>  Objective: Ophthalmological pathologies such as glaucoma, diabetic retinopathy and age-related macular degeneration are major causes of blindness and vision impairment. There is a need for novel decision support tools that can simplify and speed up the diagnosis of these pathologies. A key step in this process is to automatically estimate the quality of the fundus images to make sure these are interpretable by a human operator or a machine learning model. We present a novel fundus image quality scale and deep learning (DL) model that can estimate fundus image quality relative to this new scale. <br>Methods: A total of 1,245 images were graded for quality by two ophthalmologists within the range 1-10, with a resolution of 0.5. A DL regression model was trained for fundus image quality assessment. The architecture used was Inception-V3. The model was developed using a total of 89,947 images from 6 databases, of which 1,245 were labeled by the specialists and the remaining 88,702 images were used for pre-training and semi-supervised learning. The final DL model was evaluated on an internal test set (n=209) as well as an external test set (n=194). <br>Results: The final DL model, denoted FundusQ-Net, achieved a mean absolute error of 0.61 (0.54-0.68) on the internal test set. When evaluated as a binary classification model on the public DRIMDB database as an external test set the model obtained an accuracy of 99%. <br>Significance: the proposed algorithm provides a new robust tool for automated quality grading of fundus images.      
### 20.Deep Learning Framework for Real-time Fetal Brain Segmentation in MRI  [ :arrow_down: ](https://arxiv.org/pdf/2205.01675.pdf)
>  Fetal brain segmentation is an important first step for slice-level motion correction and slice-to-volume reconstruction in fetal MRI. Fast and accurate segmentation of the fetal brain on fetal MRI is required to achieve real-time fetal head pose estimation and motion tracking for slice re-acquisition and steering. To address this critical unmet need, in this work we analyzed the speed-accuracy performance of a variety of deep neural network models, and devised a symbolically small convolutional neural network that combines spatial details at high resolution with context features extracted at lower resolutions. We used multiple branches with skip connections to maintain high accuracy while devising a parallel combination of convolution and pooling operations as an input downsampling module to further reduce inference time. We trained our model as well as eight alternative, state-of-the-art networks with manually-labeled fetal brain MRI slices and tested on two sets of normal and challenging test cases. Experimental results show that our network achieved the highest accuracy and lowest inference time among all of the compared state-of-the-art real-time segmentation methods. We achieved average Dice scores of 97.99\% and 84.04\% on the normal and challenging test sets, respectively, with an inference time of 3.36 milliseconds per image on an NVIDIA GeForce RTX 2080 Ti. Code, data, and the trained models are available at <a class="link-external link-https" href="https://github.com/bchimagine/real_time_fetal_brain_segmentation" rel="external noopener nofollow">this https URL</a>.      
### 21.MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2205.01674.pdf)
>  Robust self-training (RST) can augment the adversarial robustness of image classification models without significantly sacrificing models' generalizability. However, RST and other state-of-the-art defense approaches failed to preserve the generalizability and reproduce their good adversarial robustness on small medical image sets. In this work, we propose the Multi-instance RST with a drop-max layer, namely MIRST-DM, which involves a sequence of iteratively generated adversarial instances during training to learn smoother decision boundaries on small datasets. The proposed drop-max layer eliminates unstable features and helps learn representations that are robust to image perturbations. The proposed approach was validated using a small breast ultrasound dataset with 1,190 images. The results demonstrate that the proposed approach achieves state-of-the-art adversarial robustness against three prevalent attacks.      
### 22.A Deep Learning-based Integrated Framework for Quality-aware Undersampled Cine Cardiac MRI Reconstruction and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2205.01673.pdf)
>  Cine cardiac magnetic resonance (CMR) imaging is considered the gold standard for cardiac function evaluation. However, cine CMR acquisition is inherently slow and in recent decades considerable effort has been put into accelerating scan times without compromising image quality or the accuracy of derived results. In this paper, we present a fully-automated, quality-controlled integrated framework for reconstruction, segmentation and downstream analysis of undersampled cine CMR data. The framework enables active acquisition of radial k-space data, in which acquisition can be stopped as soon as acquired data are sufficient to produce high quality reconstructions and segmentations. This results in reduced scan times and automated analysis, enabling robust and accurate estimation of functional biomarkers. To demonstrate the feasibility of the proposed approach, we perform realistic simulations of radial k-space acquisitions on a dataset of subjects from the UK Biobank and present results on in-vivo cine CMR k-space data collected from healthy subjects. The results demonstrate that our method can produce quality-controlled images in a mean scan time reduced from 12 to 4 seconds per slice, and that image quality is sufficient to allow clinically relevant parameters to be automatically estimated to within 5% mean absolute difference.      
### 23.Combining Reciprocity and CSI Feedback in MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.02112.pdf)
>  Reciprocity-based time-division duplex (TDD) Massive MIMO (multiple-input multiple-output) systems utilize channel estimates obtained in the uplink to perform precoding in the downlink. However, this method has been criticized of breaking down, in the sense that the channel estimates are not good enough to spatially separate multiple user terminals, at low uplink reference signal signal-to-noise ratios, due to insufficient channel estimation quality. Instead, codebook-based downlink precoding has been advocated for as an alternative solution in order to bypass this problem. We analyze this problem by considering a "grid-of-beams world" with a finite number of possible downlink channel realizations. Assuming that the terminal accurately can detect the downlink channel, we show that in the case where reciprocity holds, carefully designing a mapping between the downlink channel and the uplink reference signals will perform better than both the conventional TDD Massive MIMO and frequency-division duplex (FDD) Massive MIMO approach. We derive elegant metrics for designing this mapping, and further, we propose algorithms that find good sequence mappings.      
### 24.Vehicle Noise: Comparison of Loudness Ratings in the Field and the Laboratory  [ :arrow_down: ](https://arxiv.org/pdf/2205.02110.pdf)
>  Objective: Distorted loudness perception is one of the main complaints of hearing aid users. Being able to measure loudness perception correctly in the clinic is essential for fitting hearing aids. For this, experiments in the clinic should be able to reflect and capture loudness perception as in everyday-life situations. Little research has been done comparing loudness perception in the field and in the laboratory. Design: Participants rated the loudness in the field and in the laboratory of 36 driving actions done by four different vehicles. The field measurements were done in a restricted street and recorded with a 360deg camera and a tetrahedral microphone. The recorded stimuli, which are openly accessible, were presented in three different conditions in the laboratory: 360deg video recordings with a head-mounted display, video recordings with a desktop monitor, and audio-only. Sample: Thirteen normal-hearing participants and 18 hearing-impaired participants participated in the study. Results: The driving actions were rated significantly louder in the laboratory than in the field for the audio-only condition. These loudness rating differences were bigger for louder sounds in two laboratory conditions, i.e., the higher the sound level of a driving action was the more likely it was to be rated louder in the laboratory. There were no significant differences in the loudness ratings between the three laboratory conditions and between groups. Conclusions: The results of this experiment further remark the importance of increasing the realism and immersion when measuring loudness in the clinic.      
### 25.SVTS: Scalable Video-to-Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2205.02058.pdf)
>  Video-to-speech synthesis (also known as lip-to-speech) refers to the translation of silent lip movements into the corresponding audio. This task has received an increasing amount of attention due to its self-supervised nature (i.e., can be trained without manual labelling) combined with the ever-growing collection of audio-visual data available online. Despite these strong motivations, contemporary video-to-speech works focus mainly on small- to medium-sized corpora with substantial constraints in both vocabulary and setting. In this work, we introduce a scalable video-to-speech framework consisting of two components: a video-to-spectrogram predictor and a pre-trained neural vocoder, which converts the mel-frequency spectrograms into waveform audio. We achieve state-of-the art results for GRID and considerably outperform previous approaches on LRW. More importantly, by focusing on spectrogram prediction using a simple feedforward model, we can efficiently and effectively scale our method to very large and unconstrained datasets: To the best of our knowledge, we are the first to show intelligible results on the challenging LRS3 dataset.      
### 26.Planning a Cost-Effective Delay-Constrained Passive Optical Network for 5G Fronthaul  [ :arrow_down: ](https://arxiv.org/pdf/2205.02055.pdf)
>  With the rapid growth in the telecommunications industry moving towards 5G and beyond (5GB) and the emergence of data-hungry and time-sensitive applications, Mobile Network Operators (MNOs) are faced with a considerable challenge to keep up with these new demands. Cloud radio access network (CRAN) has emerged as a cost-effective architecture that improves 5GB performance. The fronthaul segment of the CRAN necessitates a high-capacity and low-latency connection. Optical technologies presented by Passive Optical Networks (PON) have gained attention as a promising technology to meet the fronthaul challenges. In this paper, we proposed an Integer Linear Program (ILP) that optimizes the total cost of ownership (TCO) for 5G using CRAN architecture under different delay thresholds. We considered the Time and Wavelength Division Multiplexing Passive Optical Network (TWDM-PON) as a fronthaul with different splitting ratios.      
### 27.Self-Supervised Super-Resolution for Multi-Exposure Push-Frame Satellites  [ :arrow_down: ](https://arxiv.org/pdf/2205.02031.pdf)
>  Modern Earth observation satellites capture multi-exposure bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-exposure sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the exposure times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the exposure times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-exposure approaches that we adapted to the multi-exposure case.      
### 28.Angular Control Charts: A New Perspective for Monitoring Reliability of Multi-State Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.02024.pdf)
>  Control charts, as had been used traditionally for quality monitoring, were applied alternatively to monitor systems' reliability. In other words, they can be applied to detect changes in the failure behavior of systems. Such purpose imposed modifying traditional control charts in addition to developing charts that are more compatible with reliability monitoring. The latter developed category is known as probability limits control charts. The existing reliability monitoring control charts were only dedicated to binary-state systems, and they can't be used to monitor several states simultaneously. Therefore, this paper develops a design of control charts that accommodates multi-state systems, called here as the Angular Control Chart, which represents a new version of the probability limits control charts. This design is able to monitor state transitions simultaneously and individually in addition. Illustrative system examples are implemented to explore the monitoring procedure of the new design and to demonstrate its efficiency, effectiveness, and limitations.      
### 29.Design of a novel Korean learning application for efficient pronunciation correction  [ :arrow_down: ](https://arxiv.org/pdf/2205.02001.pdf)
>  The Korean wave, which denotes the global popularity of South Korea's cultural economy, contributes to the increasing demand for the Korean language. However, as there does not exist any application for foreigners to learn Korean, this paper suggested a design of a novel Korean learning application. Speech recognition, speech-to-text, and speech-to-waveform are the three key systems in the proposed system. The Google API and the librosa library will transform the user's voice into a sentence and MFCC. The software will then display the user's phrase and answer, with mispronounced elements highlighted in red, allowing users to more easily recognize the incorrect parts of their pronunciation. Furthermore, the Siamese network might utilize those translated spectrograms to provide a similarity score, which could subsequently be used to offer feedback to the user. Despite the fact that we were unable to collect sufficient foreigner data for this research, it is notable that we presented a novel Korean pronunciation correction method for foreigners.      
### 30.ON-TRAC Consortium Systems for the IWSLT 2022 Dialect and Low-resource Speech Translation Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2205.01987.pdf)
>  This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2022: low-resource and dialect speech translation. For the Tunisian Arabic-English dataset (low-resource and dialect tracks), we build an end-to-end model as our joint primary submission, and compare it against cascaded models that leverage a large fine-tuned wav2vec 2.0 model for ASR. Our results show that in our settings pipeline approaches are still very competitive, and that with the use of transfer learning, they can outperform end-to-end models for speech translation (ST). For the Tamasheq-French dataset (low-resource track) our primary submission leverages intermediate representations from a wav2vec 2.0 model trained on 234 hours of Tamasheq audio, while our contrastive model uses a French phonetic transcription of the Tamasheq audio as input in a Conformer speech translation architecture jointly trained on automatic speech recognition, ST and machine translation losses. Our results highlight that self-supervised models trained on smaller sets of target data are more effective to low-resource end-to-end ST fine-tuning, compared to large off-the-shelf models. Results also illustrate that even approximate phonetic transcriptions can improve ST scores.      
### 31.EqVIO: An Equivariant Filter for Visual Inertial Odometry  [ :arrow_down: ](https://arxiv.org/pdf/2205.01980.pdf)
>  Visual Inertial Odometry (VIO) is the problem of estimating a robot's trajectory by combining information from an inertial measurement unit (IMU) and a camera, and is of great interest to the robotics community. This paper develops a novel Lie group symmetry for the VIO problem and applies the recently proposed equivariant filter. The symmetry is shown to be compatible with the invariance of the VIO reference frame, lead to exact linearisation of bias-free IMU dynamics, and provide equivariance of the visual measurement function. As a result, the equivariant filter (EqF) based on this Lie group is a consistent estimator for VIO with lower linearisation error in the propagation of state dynamics and a higher order equivariant output approximation than standard formulations. Experimental results on the popular EuRoC and UZH-FPV datasets demonstrate that the proposed system outperforms other state-of-the-art VIO algorithms in terms of both speed and accuracy.      
### 32.Dynamic Median Consensus for Marine Multi-Robot Systems Using Acoustic Communication  [ :arrow_down: ](https://arxiv.org/pdf/2205.01948.pdf)
>  In this paper, we present a dynamic median consensus protocol for multi-agent systems using acoustic communication. The motivating target scenario is a multi-agent system consisting of underwater robots acting as intelligent sensors, applied to continuous monitoring of the state of a marine environment. The proposed protocol allows each agent to track the median value of individual measurements of all agents through local communication with neighbouring agents. Median is chosen as a measure robust to outliers, as opposed to average value, which is usually used. In contrast to the existing consensus protocols, the proposed protocol is dynamic, uses a switching communication topology and converges to median of measured signals. Stability and correctness of the protocol are theoretically proven. The protocol is tested in simulation, and accuracy and influence of protocol parameters on the system output are analyzed. The protocol is implemented and validated by a set of experiments on an underwater group of robots comprising of aMussel units. This experimental setup is one of the first deployments of any type of consensus protocol for an underwater setting. Both simulation and experimental results confirm the correctness of the presented approach.      
### 33.Joint Compute-Caching-Communication Control for Online Data-Intensive Service Delivery  [ :arrow_down: ](https://arxiv.org/pdf/2205.01944.pdf)
>  Emerging Metaverse applications, designed to deliver highly interactive and immersive experiences that seamlessly blend physical reality and digital virtuality, are accelerating the need for distributed compute platforms with unprecedented storage, computation, and communication requirements. To this end, the integrated evolution of next-generation networks (e.g., 5G and beyond) and distributed cloud technologies (e.g., fog and mobile edge computing), have emerged as a promising paradigm to address the interaction- and resource-intensive nature of Metaverse applications. In this paper, we focus on the design of control policies for the joint orchestration of compute, caching, and communication (3C) resources in next-generation distributed cloud networks for the efficient delivery of Metaverse applications that require the real-time aggregation, processing, and distribution of multiple live media streams and pre-stored digital assets. We describe Metaverse applications via directed acyclic graphs able to model the combination of real-time stream-processing and content distribution pipelines. We design the first throughput-optimal control policy that coordinates joint decisions around (i) routing paths and processing locations for live data streams, together with (ii) cache selection and distribution paths for associated data objects. We then extend the proposed solution to include a max-throughput database placement policy and two efficient replacement policies. In addition, we characterize the network stability regions for all studied scenarios. Numerical results demonstrate the superior performance obtained via the novel multi-pipeline flow control and 3C resource orchestration mechanisms of the proposed policy, compared with state-of-the-art algorithms that lack full 3C integrated control.      
### 34.DeeptDCS: Deep Learning-Based Estimation of Currents Induced During Transcranial Direct Current Stimulation  [ :arrow_down: ](https://arxiv.org/pdf/2205.01858.pdf)
>  Objective: Transcranial direct current stimulation (tDCS) is a non-invasive brain stimulation technique used to generate conduction currents in the head and disrupt brain functions. To rapidly evaluate the tDCS-induced current density in near real-time, this paper proposes a deep learning-based emulator, named DeeptDCS. Methods: The emulator leverages Attention U-net taking the volume conductor models (VCMs) of head tissues as inputs and outputting the three-dimensional current density distribution across the entire head. The electrode configurations are also incorporated into VCMs without increasing the number of input channels; this enables the straightforward incorporation of the non-parametric features of electrodes (e.g., thickness, shape, size, and position) in the training and testing of the proposed emulator. Results: Attention U-net outperforms standard U-net and its other three variants (Residual U-net, Attention Residual U-net, and Multi-scale Residual U-net) in terms of accuracy. The generalization ability of DeeptDCS to non-trained electrode positions can be greatly enhanced through fine-tuning the model. The computational time required by one emulation via DeeptDCS is a fraction of a second. Conclusion: DeeptDCS is at least two orders of magnitudes faster than a physics-based open-source simulator, while providing satisfactorily accurate results. Significance: The high computational efficiency permits the use of DeeptDCS in applications requiring its repetitive execution, such as uncertainty quantification and optimization studies of tDCS.      
### 35.i-Code: An Integrative and Composable Multimodal Learning Framework  [ :arrow_down: ](https://arxiv.org/pdf/2205.01818.pdf)
>  Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The encoder outputs are then integrated with a multimodal fusion network, which uses novel attention mechanisms and other architectural innovations to effectively combine information from the different modalities. The entire system is pretrained end-to-end with new objectives including masked modality unit modeling and cross-modality contrastive learning. Unlike previous research using only video for pretraining, the i-Code framework can dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space. Experimental results demonstrate how i-Code can outperform state-of-the-art techniques on five video understanding tasks and the GLUE NLP benchmark, improving by as much as 11% and demonstrating the power of integrative multimodal pretraining.      
### 36.Frequency Domain-Based Detection of Generated Audio  [ :arrow_down: ](https://arxiv.org/pdf/2205.01806.pdf)
>  Attackers may manipulate audio with the intent of presenting falsified reports, changing an opinion of a public figure, and winning influence and power. The prevalence of inauthentic multimedia continues to rise, so it is imperative to develop a set of tools that determines the legitimacy of media. We present a method that analyzes audio signals to determine whether they contain real human voices or fake human voices (i.e., voices generated by neural acoustic and waveform models). Instead of analyzing the audio signals directly, the proposed approach converts the audio signals into spectrogram images displaying frequency, intensity, and temporal content and evaluates them with a Convolutional Neural Network (CNN). Trained on both genuine human voice signals and synthesized voice signals, we show our approach achieves high accuracy on this classification task.      
### 37.Splicing Detection and Localization In Satellite Imagery Using Conditional GANs  [ :arrow_down: ](https://arxiv.org/pdf/2205.01805.pdf)
>  The widespread availability of image editing tools and improvements in image processing techniques allow image manipulation to be very easy. Oftentimes, easy-to-use yet sophisticated image manipulation tools yields distortions/changes imperceptible to the human observer. Distribution of forged images can have drastic ramifications, especially when coupled with the speed and vastness of the Internet. Therefore, verifying image integrity poses an immense and important challenge to the digital forensic community. Satellite images specifically can be modified in a number of ways, including the insertion of objects to hide existing scenes and structures. In this paper, we describe the use of a Conditional Generative Adversarial Network (cGAN) to identify the presence of such spliced forgeries within satellite images. Additionally, we identify their locations and shapes. Trained on pristine and falsified images, our method achieves high success on these detection and localization objectives.      
### 38.Synthesized Speech Detection Using Convolutional Transformer-Based Spectrogram Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2205.01800.pdf)
>  Synthesized speech is common today due to the prevalence of virtual assistants, easy-to-use tools for generating and modifying speech signals, and remote work practices. Synthesized speech can also be used for nefarious purposes, including creating a purported speech signal and attributing it to someone who did not speak the content of the signal. We need methods to detect if a speech signal is synthesized. In this paper, we analyze speech signals in the form of spectrograms with a Compact Convolutional Transformer (CCT) for synthesized speech detection. A CCT utilizes a convolutional layer that introduces inductive biases and shared weights into a network, allowing a transformer architecture to perform well with fewer data samples used for training. The CCT uses an attention mechanism to incorporate information from all parts of a signal under analysis. Trained on both genuine human voice signals and synthesized human voice signals, we demonstrate that our CCT approach successfully differentiates between genuine and synthesized speech signals.      
### 39.Traversing Supervisor Problem: An Approximately Optimal Approach to Multi-Robot Assistance  [ :arrow_down: ](https://arxiv.org/pdf/2205.01768.pdf)
>  The number of multi-robot systems deployed in field applications has increased dramatically over the years. Despite the recent advancement of navigation algorithms, autonomous robots often encounter challenging situations where the control policy fails and the human assistance is required to resume robot tasks. Human-robot collaboration can help achieve high-levels of autonomy, but monitoring and managing multiple robots at once by a single human supervisor remains a challenging problem. Our goal is to help a supervisor decide which robots to assist in which order such that the team performance can be maximized. We formulate the one-to-many supervision problem in uncertain environments as a dynamic graph traversal problem. An approximation algorithm based on the profitable tour problem on a static graph is developed to solve the original problem, and the approximation error is bounded and analyzed. Our case study on a simulated autonomous farm demonstrates superior team performance than baseline methods in task completion time and human working time, and that our method can be deployed in real-time for robot fleets with moderate size.      
### 40.On monoaural speech enhancement for automatic recognition of real noisy speech using mixture invariant training  [ :arrow_down: ](https://arxiv.org/pdf/2205.01751.pdf)
>  In this paper, we explore an improved framework to train a monoaural neural enhancement model for robust speech recognition. The designed training framework extends the existing mixture invariant training criterion to exploit both unpaired clean speech and real noisy data. It is found that the unpaired clean speech is crucial to improve quality of separated speech from real noisy speech. The proposed method also performs remixing of processed and unprocessed signals to alleviate the processing artifacts. Experiments on the single-channel CHiME-3 real test sets show that the proposed method improves significantly in terms of speech recognition performance over the enhancement system trained either on the mismatched simulated data in a supervised fashion or on the matched real data in an unsupervised fashion. Between 16% and 39% relative WER reduction has been achieved by the proposed system compared to the unprocessed signal using end-to-end and hybrid acoustic models without retraining on distorted data.      
### 41.Intelligent Reflecting Surface Networks with Multi-Order-Reflection Effect: System Modelling and Critical Bounds  [ :arrow_down: ](https://arxiv.org/pdf/2205.01739.pdf)
>  In this paper, we model, analyze and optimize the multi-user and multi-order-reflection (MUMOR) intelligent reflecting surface (IRS) networks. We first derive a complete MUMOR IRS network model applicable for the arbitrary times of reflections, size and number of IRSs/reflectors. The optimal condition for achieving sum-rate upper bound with one IRS in a closed-form function and the analytical condition to achieve interference-free transmission are derived, respectively. Leveraging this optimal condition, we obtain the MUMOR sum-rate upper bound of the IRS network with different network topologies, where the linear graph (LG), complete graph (CG) and null graph (NG) topologies are considered. Simulation results verify our theories and derivations and demonstrate that the sum-rate upper bounds of different network topologies are under a K-fold improvement given K-piece IRS.      
### 42.License Plate Privacy in Collaborative Visual Analysis of Traffic Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2205.01724.pdf)
>  Traffic scene analysis is important for emerging technologies such as smart traffic management and autonomous vehicles. However, such analysis also poses potential privacy threats. For example, a system that can recognize license plates may construct patterns of behavior of the corresponding vehicles' owners and use that for various illegal purposes. In this paper we present a system that enables traffic scene analysis while at the same time preserving license plate privacy. The system is based on a multi-task model whose latent space is selectively compressed depending on the amount of information the specific features carry about analysis tasks and private information. Effectiveness of the proposed method is illustrated by experiments on the Cityscapes dataset, for which we also provide license plate annotations.      
### 43.On the Level Crossing Rate of Fluid Antenna Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.01711.pdf)
>  Multiple-input multiple-output (MIMO) technology has significantly impacted wireless communication, by providing extraordinary performance gains. However, a minimum inter-antenna space constraint in MIMO systems does not allow its integration in devices with limited space. In this context, the concept of fluid antenna systems (FASs) appears to be a potent solution, where there is no such restriction. In this paper, we investigate the average level crossing rate (LCR) of such FASs. Specifically, we derive closed-form analytical expressions of the LCR of such systems and extensive Monte-Carlo simulations validate the proposed analytical framework. Moreover, we also demonstrate that under certain conditions, the LCR obtained coincides with that of a conventional selection combining-based receiver. Finally, the numerical results also provide insights regarding the selection of appropriate parameters that enhance the system performance.      
### 44.Smart City Intersections: Intelligence Nodes for Future Metropolises  [ :arrow_down: ](https://arxiv.org/pdf/2205.01686.pdf)
>  Traffic intersections are the most suitable locations for the deployment of computing, communications, and intelligence services for smart cities of the future. The abundance of data to be collected and processed, in combination with privacy and security concerns, motivates the use of the edge-computing paradigm which aligns well with physical intersections in metropolises. This paper focuses on high-bandwidth, low-latency applications, and in that context it describes: (i) system design considerations for smart city intersection intelligence nodes; (ii) key technological components including sensors, networking, edge computing, low latency design, and AI-based intelligence; and (iii) applications such as privacy preservation, cloud-connected vehicles, a real-time "radar-screen", traffic management, and monitoring of pedestrian behavior during pandemics. The results of the experimental studies performed on the COSMOS testbed located in New York City are illustrated. Future challenges in designing human-centered smart city intersections are summarized.      
### 45.Deep Sequence Modeling for Anomalous ISP Traffic Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2205.01685.pdf)
>  Internet traffic in the real world is susceptible to various external and internal factors which may abruptly change the normal traffic flow. Those unexpected changes are considered outliers in traffic. However, deep sequence models have been used to predict complex IP traffic, but their comparative performance for anomalous traffic has not been studied extensively. In this paper, we investigated and evaluated the performance of different deep sequence models for anomalous traffic prediction. Several deep sequences models were implemented to predict real traffic without and with outliers and show the significance of outlier detection in real-world traffic prediction. First, two different outlier detection techniques, such as the Three-Sigma rule and Isolation Forest, were applied to identify the anomaly. Second, we adjusted those abnormal data points using the Backward Filling technique before training the model. Finally, the performance of different models was compared for abnormal and adjusted traffic. LSTM_Encoder_Decoder (LSTM_En_De) is the best prediction model in our experiment, reducing the deviation between actual and predicted traffic by more than 11\% after adjusting the outliers. All other models, including Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), LSTM_En_De with Attention layer (LSTM_En_De_Atn), Gated Recurrent Unit (GRU), show better prediction after replacing the outliers and decreasing prediction error by more than 29%, 24%, 19%, and 10% respectively. Our experimental results indicate that the outliers in the data can significantly impact the quality of the prediction. Thus, outlier detection and mitigation assist the deep sequence model in learning the general trend and making better predictions.      
### 46.The scope for AI-augmented interpretation of building blueprints in commercial and industrial property insurance  [ :arrow_down: ](https://arxiv.org/pdf/2205.01671.pdf)
>  This report, commissioned by the WTW research network, investigates the use of AI in property risk assessment. It (i) reviews existing work on risk assessment in commercial and industrial properties and automated information extraction from building blueprints; and (ii) presents an exploratory 'proof-of concept-solution' exploring the feasibility of using machine learning for the automated extraction of information from building blueprints to support insurance risk assessment.      
