# ArXiv eess --Wed, 4 May 2022
### 1.Learning Enriched Features for Fast Image Restoration and Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2205.01649.pdf)
>  Given a degraded input image, image restoration aims to recover the missing high-quality image content. Numerous applications demand effective image restoration, e.g., computational photography, surveillance, autonomous vehicles, and remote sensing. Significant advances in image restoration have been made in recent years, dominated by convolutional neural networks (CNNs). The widely-used CNN-based methods typically operate either on full-resolution or on progressively low-resolution representations. In the former case, spatial details are preserved but the contextual information cannot be precisely encoded. In the latter case, generated outputs are semantically reliable but spatially less accurate. This paper presents a new architecture with a holistic goal of maintaining spatially-precise high-resolution representations through the entire network, and receiving complementary contextual information from the low-resolution representations. The core of our approach is a multi-scale residual block containing the following key elements: (a) parallel multi-resolution convolution streams for extracting multi-scale features, (b) information exchange across the multi-resolution streams, (c) non-local attention mechanism for capturing contextual information, and (d) attention based multi-scale feature aggregation. Our approach learns an enriched set of features that combines contextual information from multiple scales, while simultaneously preserving the high-resolution spatial details. Extensive experiments on six real image benchmark datasets demonstrate that our method, named as MIRNet-v2 , achieves state-of-the-art results for a variety of image processing tasks, including defocus deblurring, image denoising, super-resolution, and image enhancement. The source code and pre-trained models are available at <a class="link-external link-https" href="https://github.com/swz30/MIRNetv2" rel="external noopener nofollow">this https URL</a>      
### 2.GITz: Graphene-assisted IRS Design for THz Communication  [ :arrow_down: ](https://arxiv.org/pdf/2205.01606.pdf)
>  Graphene-based intelligent reflecting surface (GIRS) has been proved to provide a promising propagation environment to enhance the quality of high frequency terahertz (THz) wireless communication. In this paper, we characterize GIRS for THz communication (GITz) using material specific parameters of graphene to tune the reflection of the incident wave at IRS. In particular, we propose a GITz design model considering the incident signal frequency material level parameters like conductivity, Fermi-level, patch width to control the reflection amplitude (RA) at the communication receiver. We have obtained the closed-form expression of RA for an accurate design and characterization of GIRS, which is incomplete in the existing research due to the inclusion of only phase-shift. The numerical simulation results demonstrate the effectiveness of the proposed characterization by providing key insights.      
### 3.An untrained deep learning method for reconstructing dynamic magnetic resonance images from accelerated model-based data  [ :arrow_down: ](https://arxiv.org/pdf/2205.01604.pdf)
>  The purpose of this work is to implement physics-based regularization as a stopping condition in tuning an untrained deep neural network for reconstructing MR images from accelerated data. The ConvDecoder neural network was trained with a physics-based regularization term incorporating the spoiled gradient echo equation that describes variable-flip angle (VFA) data. Fully-sampled VFA k-space data were retrospectively accelerated by factors of R={8,12,18,36} and reconstructed with ConvDecoder (CD), ConvDecoder with the proposed regularization (CD+r), locally low-rank (LR) reconstruction, and compressed sensing with L1-wavelet regularization (L1). Final images from CD+r training were evaluated at the \emph{argmin} of the regularization loss; whereas the CD, LR, and L1 reconstructions were chosen optimally based on ground truth data. The performance measures used were the normalized root-mean square error, the concordance correlation coefficient (CCC), and the structural similarity index (SSIM). The CD+r reconstructions, chosen using the stopping condition, yielded SSIMs that were similar to the CD (p=0.47) and LR SSIMs (p=0.95) across R and that were significantly higher than the L1 SSIMs (p=0.04). The CCC values for the CD+r T1 maps across all R and subjects were greater than those corresponding to the L1 (p=0.15) and LR (p=0.13) T1 maps, respectively. For R &gt; 12 (&lt;4.2 minutes scan time), L1 and LR T1 maps exhibit a loss of spatially refined details compared to CD+r. We conclude that the use of an untrained neural network together with a physics-based regularization loss shows promise as a measure for determining the optimal stopping point in training without relying on fully-sampled ground truth data.      
### 4.Optimal Thermal Management, Charging, and Eco-driving of Battery Electric Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2205.01560.pdf)
>  This paper addresses optimal battery thermal management (BTM), charging, and eco-driving of a battery electric vehicle (BEV) with the goal of improving its grid-to-meter energy efficiency. Thus, an optimisation problem is formulated, aiming at finding the optimal trade-off between trip time and charging cost. The formulated problem is then transformed into a hybrid dynamical system, where the dynamics in driving and charging modes are modeled with different functions and with different state and control vectors. Moreover, to improve computational efficiency, we propose modelling the driving dynamics in a spatial domain, where decisions are made along the traveled distance. Charging dynamics are modeled in a temporal domain, where decisions are made along a normalized charging time. The actual charging time is modeled as a scalar variable that is optimized simultaneously with the optimal state and control trajectories, for both charging and driving modes. The performance of the proposed algorithm is assessed over a road with a hilly terrain, where two charging possibilities are considered along the driving route. According to the results, trip time including driving and charging times, is reduced by 44 %, compared to a case without battery active heating/cooling.      
### 5.Physical Layer Security for 6G Systems why it is needed and how to make it happen  [ :arrow_down: ](https://arxiv.org/pdf/2205.01552.pdf)
>  Sixth generations (6G) systems will be required to meet diverse constraints in an integrated ground-air-space global network. In particular, meeting overly aggressive latency constraints, operating in massive connectivity regimes, with low energy footprint and low computational effort, while providing explicit security guarantees, can be challenging. In this setting, quality of security (QoSec) is envisioned as a flexible security framework for future networks with highly diverse non-functional requirements. Mirroring the differentiated services (DiffServ) networking paradigm, different security levels could be conceptualized, moving away from static security controls, captured currently in zero-trust security architectures. In parallel, the integration of communications and sensing, along with embedded (on-device) AI, can provide the foundations for building autonomous and adaptive security controls, orchestrated by a vertical security plane in coordination with a vertical semantic plane. It is in this framework, that we envision the incorporation of physical layer security (PLS) schemes in 6G security protocols, introducing security controls at all layers, for the first time.      
### 6.Attentive activation function for improving end-to-end spoofing countermeasure systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.01528.pdf)
>  The main objective of the spoofing countermeasure system is to detect the artifacts within the input speech caused by the speech synthesis or voice conversion process. In order to achieve this, we propose to adopt an attentive activation function, more specifically attention rectified linear unit (AReLU) to the end-to-end spoofing countermeasure system. Since the AReLU employs the attention mechanism to boost the contribution of relevant input features while suppressing the irrelevant ones, introducing AReLU can help the countermeasure system to focus on the features related to the artifacts. The proposed framework was experimented on the logical access (LA) task of ASVSpoof2019 dataset, and outperformed the systems using the standard non-learnable activation functions.      
### 7.MS Lesion Segmentation: Revisiting Weighting Mechanisms for Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.01509.pdf)
>  Federated learning (FL) has been widely employed for medical image analysis to facilitate multi-client collaborative learning without sharing raw data. Despite great success, FL's performance is limited for multiple sclerosis (MS) lesion segmentation tasks, due to variance in lesion characteristics imparted by different scanners and acquisition parameters. In this work, we propose the first FL MS lesion segmentation framework via two effective re-weighting mechanisms. Specifically, a learnable weight is assigned to each local node during the aggregation process, based on its segmentation performance. In addition, the segmentation loss function in each client is also re-weighted according to the lesion volume for the data during training. Comparison experiments on two FL MS segmentation scenarios using public and clinical datasets have demonstrated the effectiveness of the proposed method by outperforming other FL methods significantly. Furthermore, the segmentation performance of FL incorporating our proposed aggregation mechanism can exceed centralised training with all the raw data. The extensive evaluation also indicated the superiority of our method when estimating brain volume differences estimation after lesion inpainting.      
### 8.Frequency-Selective Geometry Upsampling of Point Clouds  [ :arrow_down: ](https://arxiv.org/pdf/2205.01458.pdf)
>  The demand for high-resolution point clouds has increased throughout the last years. However, capturing high-resolution point clouds is expensive and thus, frequently replaced by upsampling of low-resolution data. Most state-of-the-art methods are either restricted to a rastered grid, incorporate normal vectors, or are trained for a single use case. We propose to use the frequency selectivity principle, where a frequency model is estimated locally that approximates the surface of the point cloud. Then, additional points are inserted into the approximated surface. Our novel frequency-selective geometry upsampling shows superior results in terms of subjective as well as objective quality compared to state-of-the-art methods for scaling factors of 2 and 4. On average, our proposed method shows a 4.4 times smaller point-to-point error than the second best state-of-the-art PU-Net for a scale factor of 4.      
### 9.Sea Ice Concentration Estimation Techniques Using Machine Learning: An End-To-End Workflow for Estimating Concentration Maps from SAR Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.01403.pdf)
>  Sea ice concentration is an important metric used to characterize polar sea ice behavior. Understanding this behavior and accurately representing it is of critical importance for climate science research, and also has important uses in the context of maritime navigation. An end-to-end workflow for generating learned concentration estimation models from synthetic aperture radar data, trained on existing passive microwave data, is presented here. A novel objective function was introduced to account for uncertainty in the passive microwave measurements, which can be extended to account for arbitrary sources of error in the training data, and a recent set of in-situ observations was used to evaluate the reliability of the chosen passive microwave concentration estimation model. Google Colaboratory was used as the development platform, and all notebooks, training data, and trained models are available on GitHub. This chapter is an overview of the most interesting aspects of this investigation, and a detailed report is also available on GitHub.      
### 10.A Unified Framework for Verification of Observational Properties for Partially-Observed Discrete-Event Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.01392.pdf)
>  In this paper, we investigate property verification problems in partially-observed discrete-event systems (DES). Particularly, we are interested in verifying observational properties that are related to the information-flow of the system. Observational properties considered here include diagnosability, predictability, detectability and opacity, which have drawn considerable attentions in the literature. However, in contrast to existing results, where different verification procedures are developed for different properties case-by-case, in this work, we provide a unified framework for verifying all these properties by reducing each of them as an instance of HyperLTL model checking. Our approach is based on the construction of a Kripke structure that effectively captures the issue of unobservability as well as the finite string semantics in partially-observed DES so that HyperLTL model checking techniques can be suitably applied. Then for each observational property considered, we explicitly provide the HyperLTL formula to be checked over the Kripke structure for the purpose of verification. Our approach is uniform in the sense that all different properties can be verified with the same model checking engine. Furthermore, our unified framework also brings new insights for classifying observational properties for partially-observed DES in terms of their verification complexity.      
### 11.A Mapping Approach to Convert MTPs into a Capability and Skill Ontology  [ :arrow_down: ](https://arxiv.org/pdf/2205.01382.pdf)
>  Being able to quickly integrate new equipment and functions into an existing plant is a major goal for both discrete and process manufacturing. But currently, these two industry domains use different approaches to achieve this goal. While the Module Type Package (MTP) is getting more and more adapted in practical applications of process manufacturing, so-called skill-based manufacturing approaches are favored in the context of discrete manufacturing. The two approaches are incompatible because their models feature different contents and they use different technologies. This contribution provides a comparison of the MTP with a skill-based approach as well as an automated mapping that can be used to transfer the contents of an MTP into a skill ontology. Through this mapping an MTP can be semantically lifted in order to apply functions like querying or reasoning. Furthermore, machines that were previously described using two incompatible models can now be used in one production process.      
### 12.Complex-order Reset Control System  [ :arrow_down: ](https://arxiv.org/pdf/2205.01378.pdf)
>  According to the well-known loop shaping method for the design of controllers, the performance of the controllers in terms of step response, steady-state disturbance rejection and noise attenuation and robustness can be improved by increasing the gain at lower frequencies and decreasing it at higher frequencies and increasing the phase margin as much as possible. However, the inherent properties of linear controllers, the Bode's phase-gain relation, create a limitation. In theory, a complex-order transfer function can break the Bode's gain-phase relation; however, such transfer function cannot be directly implemented and should be approximated. This paper proposes a reset element and a tuning method to approximate a Complex-Order Controller (CLOC) and, through a simulation example, shows the benefits of using such a controller.      
### 13.Prediction-Based Reachability Analysis for Collision Risk Assessment on Highways  [ :arrow_down: ](https://arxiv.org/pdf/2205.01357.pdf)
>  Real-time safety systems are crucial components of intelligent vehicles. This paper introduces a prediction-based collision risk assessment approach on highways. Given a point mass vehicle dynamics system, a stochastic forward reachable set considering two-dimensional motion with vehicle state probability distributions is firstly established. We then develop an acceleration prediction model, which provides multi-modal probabilistic acceleration distributions to propagate vehicle states. The collision probability is calculated by summing up the probabilities of the states where two vehicles spatially overlap. Simulation results show that the prediction model has superior performance in terms of vehicle motion position errors, and the proposed collision detection approach is agile and effective to identify the collision in cut-in crash events.      
### 14.Efficient dynamic filter for robust and low computational feature extraction  [ :arrow_down: ](https://arxiv.org/pdf/2205.01304.pdf)
>  Unseen noise signal which is not considered in a model training process is difficult to anticipate and would lead to performance degradation. Various methods have been investigated to mitigate unseen noise. In our previous work, an Instance-level Dynamic Filter (IDF) and a Pixel Dynamic Filter (PDF) were proposed to extract noise-robust features. However, the performance of the dynamic filter might be degraded since simple feature pooling is used to reduce the computational resource in the IDF part. In this paper, we propose an efficient dynamic filter to enhance the performance of the dynamic filter. Instead of utilizing the simple feature mean, we separate Time-Frequency (T-F) features as non-overlapping chunks, and separable convolutions are carried out for each feature direction (inter chunks and intra chunks). Additionally, we propose Dynamic Attention Pooling that maps high dimensional features as low dimensional feature embeddings. These methods are applied to the IDF for keyword spotting and speaker verification tasks. We confirm that our proposed method performs better in unseen environments (unseen noise and unseen speakers) than state-of-the-art models.      
### 15.Improving Dual-Microphone Speech Enhancement by Learning Cross-Channel Features with Multi-Head Attention  [ :arrow_down: ](https://arxiv.org/pdf/2205.01280.pdf)
>  Hand-crafted spatial features, such as inter-channel intensity difference (IID) and inter-channel phase difference (IPD), play a fundamental role in recent deep learning based dual-microphone speech enhancement (DMSE) systems. However, learning the mutual relationship between artificially designed spatial and spectral features is hard in the end-to-end DMSE. In this work, a novel architecture for DMSE using a multi-head cross-attention based convolutional recurrent network (MHCA-CRN) is presented. The proposed MHCA-CRN model includes a channel-wise encoding structure for preserving intra-channel features and a multi-head cross-attention mechanism for fully exploiting cross-channel features. In addition, the proposed approach specifically formulates the decoder with an extra SNR estimator to estimate frame-level SNR under a multi-task learning framework, which is expected to avoid speech distortion led by end-to-end DMSE module. Finally, a spectral gain function is adopted to further suppress the unnatural residual noise. Experiment results demonstrated superior performance of the proposed model against several state-of-the-art models.      
### 16.Real-time Cooperative Vehicle Coordination at Unsignalized Road Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2205.01278.pdf)
>  Cooperative coordination at unsignalized road intersections, which aims to improve the driving safety and traffic throughput for connected and automated vehicles, has attracted increasing interests in recent years. However, most existing investigations either suffer from computational complexity or cannot harness the full potential of the road infrastructure. To this end, we first present a dedicated intersection coordination framework, where the involved vehicles hand over their control authorities and follow instructions from a centralized coordinator. Then a unified cooperative trajectory optimization problem will be formulated to maximize the traffic throughput while ensuring the driving safety and long-term stability of the coordination system. To address the key computational challenges in the real-world deployment, we reformulate this non-convex sequential decision problem into a model-free Markov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep Deterministic Policy Gradient (TD3)-based strategy in the deep reinforcement learning (DRL) framework. Simulation and practical experiments show that the proposed strategy could achieve near-optimal performance in sub-static coordination scenarios and significantly improve the traffic throughput in the realistic continuous traffic flow. The most remarkable advantage is that our strategy could reduce the time complexity of computation to milliseconds, and is shown scalable when the road lanes increase.      
### 17.A Performance-Consistent and Computation-Efficient CNN System for High-Quality Automated Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.01239.pdf)
>  The research on developing CNN-based fully-automated Brain-Tumor-Segmentation systems has been progressed rapidly. For the systems to be applicable in practice, a good The research on developing CNN-based fully-automated Brain-Tumor-Segmentation systems has been progressed rapidly. For the systems to be applicable in practice, a good processing quality and reliability are the must. Moreover, for wide applications of such systems, a minimization of computation complexity is desirable, which can also result in a minimization of randomness in computation and, consequently, a better performance consistency. To this end, the CNN in the proposed system has a unique structure with 2 distinguished characters. Firstly, the three paths of its feature extraction block are designed to extract, from the multi-modality input, comprehensive feature information of mono-modality, paired-modality and cross-modality data, respectively. Also, it has a particular three-branch classification block to identify the pixels of 4 classes. Each branch is trained separately so that the parameters are updated specifically with the corresponding ground truth data of a target tumor areas. The convolution layers of the system are custom-designed with specific purposes, resulting in a very simple config of 61,843 parameters in total. The proposed system is tested extensively with BraTS2018 and BraTS2019 datasets. The mean Dice scores, obtained from the ten experiments on BraTS2018 validation samples, are 0.787+0.003, 0.886+0.002, 0.801+0.007, for enhancing tumor, whole tumor and tumor core, respectively, and 0.751+0.007, 0.885+0.002, 0.776+0.004 on BraTS2019. The test results demonstrate that the proposed system is able to perform high-quality segmentation in a consistent manner. Furthermore, its extremely low computation complexity will facilitate its implementation/application in various environments.      
### 18.Analysis of the Visually Detectable Wear Progress on Ball Screws  [ :arrow_down: ](https://arxiv.org/pdf/2205.01149.pdf)
>  The actual progression of pitting on ball screw drive spindles is not well known since previous studies have only relied on the investigation of indirect wear effects (e. g. temperature, motor current, structure-borne noise). Using images from a camera system for ball screw drives, this paper elaborates on the visual analysis of pitting itself. Due to its direct, condition-based assessment of the wear state, an image-based approach offers several advantages, such as: Good interpretability, low influence of environmental conditions, and high spatial resolution. The study presented in this paper is based on a dataset containing the entire wear progression from original condition to component failure of ten ball screw drive spindles. The dataset is being analyzed regarding the following parameters: Axial length, tangential length, and surface area of each pit, the total number of pits, and the time of initial visual appearance of each pit. The results provide evidence that wear development can be quantified based on visual wear characteristics. In addition, using the dedicated camera system, the actual course of the growth curve of individual pits can be captured during machine operation. Using the findings of the analysis, the authors propose a formula for standards-based wear quantification based on geometric wear characteristics.      
### 19.Fast algorithms for nonlinear and constrained phase retrieval in near-field X-ray holography based on Tikhonov regularization  [ :arrow_down: ](https://arxiv.org/pdf/2205.01099.pdf)
>  Based on phase retrieval, lensless coherent imaging and in particular holography offers quantitative phase and amplitude images. This is of particular importance for spectral ranges where suitable lenses are challenging, such as for hard x-rays. Here, we propose a phase retrieval approach for inline x-ray holography based on Tikhonov regularization applied to the full nonlinear forward model of image formation. The approach can be seen as a nonlinear generalization of the well-established contrast-transfer-function (CTF) reconstruction method. While similar methods have been proposed before, the current work achieves nonlinear, constrained phase retrieval at competitive computation times. We thus enable high-throughput imaging of optically strong objects beyond the scope of CTF. Using different examples of inline holograms obtained from illumination by a x-ray waveguide-source, we demonstrate superior image quality even for samples which do not obey the assumption of a weakly varying phase. Since the presented approach does not rely on linearization, we expect it to be well suited also for other probes such as visible light or electrons, which often exhibit strong phase interaction.      
### 20.Adaptive Traffic Signal Control for Developing Countries Using Fused Parameters Derived from Crowd-Source Data  [ :arrow_down: ](https://arxiv.org/pdf/2205.01640.pdf)
>  Advancement of mobile technologies has enabled economical collection, storage, processing, and sharing of traffic data. These data are made accessible to intended users through various application program interfaces (API) and can be used to recognize and mitigate congestion in real time. In this paper, quantitative (time of arrival) and qualitative (color-coded congestion levels) data were acquired from the Google traffic APIs. New parameters that reflect heterogeneous traffic conditions were defined and utilized for real-time control of traffic signals while maintaining the green-to-red time ratio. The proposed method utilizes a congestion-avoiding principle commonly used in computer networking. Adaptive congestion levels were observed on three different intersections of Delhi (India), in peak hours. It showed good variation, hence sensitive for the control algorithm to act efficiently. Also, simulation study establishes that proposed control algorithm decreases waiting time and congestion. The proposed method provides an inexpensive alternative for traffic sensing and tracking technologies.      
### 21.AutoFi: Towards Automatic WiFi Human Sensing via Geometric Self-Supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.01629.pdf)
>  WiFi sensing technology has shown superiority in smart homes among various sensors for its cost-effective and privacy-preserving merits. It is empowered by Channel State Information (CSI) extracted from WiFi signals and advanced machine learning models to analyze motion patterns in CSI. Many learning-based models have been proposed for kinds of applications, but they severely suffer from environmental dependency. Though domain adaptation methods have been proposed to tackle this issue, it is not practical to collect high-quality, well-segmented and balanced CSI samples in a new environment for adaptation algorithms, but randomly captured CSI samples can be easily collected. In this paper, we firstly explore how to learn a robust model from these low-quality CSI samples, and propose AutoFi, an automatic WiFi sensing model based on a novel geometric self-supervised learning algorithm. The AutoFi fully utilizes unlabeled low-quality CSI samples that are captured randomly, and then transfers the knowledge to specific tasks defined by users, which is the first work to achieve cross-task transfer in WiFi sensing. The AutoFi is implemented on a pair of Atheros WiFi APs for evaluation. The AutoFi transfers knowledge from randomly collected CSI samples into human gait recognition and achieves state-of-the-art performance. Furthermore, we simulate cross-task transfer using public datasets to further demonstrate its capacity for cross-task learning. For the UT-HAR and Widar datasets, the AutoFi achieves satisfactory results on activity recognition and gesture recognition without any prior training. We believe that the AutoFi takes a huge step toward automatic WiFi sensing without any developer engagement while overcoming the cross-site issue.      
### 22.Automatic Segmentation of Aircraft Dents in Point Clouds  [ :arrow_down: ](https://arxiv.org/pdf/2205.01614.pdf)
>  Dents on the aircraft skin are frequent and may easily go undetected during airworthiness checks, as their inspection process is tedious and extremely subject to human factors and environmental conditions. Nowadays, 3D scanning technologies are being proposed for more reliable, human-independent measurements, yet the process of inspection and reporting remains laborious and time consuming because data acquisition and validation are still carried out by the engineer. For full automation of dent inspection, the acquired point cloud data must be analysed via a reliable segmentation algorithm, releasing humans from the search and evaluation of damage. This paper reports on two developments towards automated dent inspection. The first is a method to generate a synthetic dataset of dented surfaces to train a fully convolutional neural network. The training of machine learning algorithms needs a substantial volume of dent data, which is not readily available. Dents are thus simulated in random positions and shapes, within criteria and definitions of a Boeing 737 structural repair manual. The noise distribution from the scanning apparatus is then added to reflect the complete process of 3D point acquisition on the training. The second proposition is a surface fitting strategy to convert 3D point clouds to 2.5D. This allows higher resolution point clouds to be processed with a small amount of memory compared with state-of-the-art methods involving 3D sampling approaches. Simulations with available ground truth data show that the proposed technique reaches an intersection-over-union of over 80%. Experiments over dent samples prove an effective detection of dents with a speed of over 500 000 points per second.      
### 23.PSCNN: A 885.86 TOPS/W Programmable SRAM-based Computing-In-Memory Processor for Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2205.01569.pdf)
>  Computing-in-memory (CIM) has attracted significant attentions in recent years due to its massive parallelism and low power consumption. However, current CIM designs suffer from large area overhead of small CIM macros and bad programmablity for model execution. This paper proposes a programmable CIM processor with a single large sized CIM macro instead of multiple smaller ones for power efficient computation and a flexible instruction set to support various binary 1-D convolution Neural Network (CNN) models in an easy way. Furthermore, the proposed architecture adopts the pooling write-back method to support fused or independent convolution/pooling operations to reduce 35.9\% of latency, and the flexible ping-pong feature SRAM to fit different feature map sizes during layer-by-layer execution.The design fabricated in TSMC 28nm technology achieves 150.8 GOPS throughput and 885.86 TOPS/W power efficiency at 10 MHz when executing our binary keyword spotting model, which has higher power efficiency and flexibility than previous designs.      
### 24.Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2205.01550.pdf)
>  Point clouds have the characteristics of disorder, unstructured and sparseness.Aiming at the problem of the non-structural nature of point clouds, thanks to the excellent performance of convolutional neural networks in image processing, one of the solutions is to extract features from point clouds based on two-dimensional convolutional neural networks. The three-dimensional information carried in the point cloud can be converted to two-dimensional, and then processed by a two-dimensional convolutional neural network, and finally back-projected to <a class="link-external link-http" href="http://three-dimensional.In" rel="external noopener nofollow">this http URL</a> the process of projecting 3D information to 2D and back-projection, certain information loss will inevitably be caused to the point cloud and category inconsistency will be introduced in the back-projection stage;Another solution is the voxel-based point cloud segmentation method, which divides the point cloud into small grids one by one.However, the point cloud is sparse, and the direct use of 3D convolutional neural network inevitably wastes computing resources. In this paper, we propose a feature extraction module based on multi-scale ultra-sparse convolution and a feature selection module based on channel attention, and build a point cloud segmentation network framework based on <a class="link-external link-http" href="http://this.By" rel="external noopener nofollow">this http URL</a> introducing multi-scale sparse convolution, network could capture richer feature information based on convolution kernels of different sizes, improving the segmentation result of point cloud segmentation.      
### 25.Average Age of Information Minimization in Reliable Covert Communication on Time-Varying Channels  [ :arrow_down: ](https://arxiv.org/pdf/2205.01533.pdf)
>  In this letter, we propose reliable covert communications with the aim of minimizing age of information (AoI) in the time-varying channels. We named the time duration that channel state information (CSI) is valid as a new metric, as age of channel variation (AoC). To find reliable covert communication in a fresh manner in dynamic environments, this work considers a new constraint that shows a relation between AoI and AoC. With the aid of the proposed constraint, this paper addresses two main challenges of reliable covert communication with the aim of minimizing AoI: 1) users packets with desirable size; 2) guaranteeing the negligible probability of Willies detection, in time-varying networks. In the simulation results, we compare the performance of the proposed constraint in reliable covert communication with the aim of minimizing AoI with conventional optimization of the requirement of information freshness in covert communications.      
### 26.Real-Time Streaming and Event-driven Control of Scientific Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2205.01476.pdf)
>  Advancements in scientific instrument sensors and connected devices provide unprecedented insight into ongoing experiments and present new opportunities for control, optimization, and steering. However, the diversity of sensors and heterogeneity of their data result in make it challenging to fully realize these new opportunities. Organizing and synthesizing diverse data streams in near-real-time requires both rich automation and Machine Learning (ML). To efficiently utilize ML during an experiment, the entire ML lifecycle must be addressed, including refining experiment configurations, retraining models, and applying decisions-tasks that require an equally diverse array of computational resources spanning centralized HPC to the accelerators at the edge. Here we present the Manufacturing Data and Machine Learning platform (MDML). The MDML is designed to standardize the research and operational environment for advanced data analytics and ML-enabled automated process optimization by providing the cyberinfrastructure to integrate sensor data streams and AI in cyber-physical systems for in-situ analysis. To achieve this, the MDML provides a fabric to receive and aggregate IoT data and simultaneously orchestrate remote computation across the computing continuum. In this paper we describe the MDML and show how it is used in advanced manufacturing to act on IoT data and orchestrate distributed ML to guide experiments.      
### 27.Revisiting Communication-Efficient Federated Learning with Balanced Global and Local Updates  [ :arrow_down: ](https://arxiv.org/pdf/2205.01470.pdf)
>  In federated learning (FL), a number of devices train their local models and upload the corresponding parameters or gradients to the base station (BS) to update the global model while protecting their data privacy. However, due to the limited computation and communication resources, the number of local trainings (a.k.a. local update) and that of aggregations (a.k.a. global update) need to be carefully chosen. In this paper, we investigate and analyze the optimal trade-off between the number of local trainings and that of global aggregations to speed up the convergence and enhance the prediction accuracy over the existing works. Our goal is to minimize the global loss function under both the delay and the energy consumption constraints. In order to make the optimization problem tractable, we derive a new and tight upper bound on the loss function, which allows us to obtain closed-form expressions for the number of local trainings and that of global aggregations. Simulation results show that our proposed scheme can achieve a better performance in terms of the prediction accuracy, and converge much faster than the baseline schemes.      
### 28.An Empirical Analysis of the Use of Real-Time Reachability for the Safety Assurance of Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2205.01419.pdf)
>  Recent advances in machine learning technologies and sensing have paved the way for the belief that safe, accessible, and convenient autonomous vehicles may be realized in the near future. Despite tremendous advances within this context, fundamental challenges around safety and reliability are limiting their arrival and comprehensive adoption. Autonomous vehicles are often tasked with operating in dynamic and uncertain environments. As a result, they often make use of highly complex components, such as machine learning approaches, to handle the nuances of sensing, actuation, and control. While these methods are highly effective, they are notoriously difficult to assure. Moreover, within uncertain and dynamic environments, design time assurance analyses may not be sufficient to guarantee safety. Thus, it is critical to monitor the correctness of these systems at runtime. One approach for providing runtime assurance of systems with components that may not be amenable to formal analysis is the simplex architecture, where an unverified component is wrapped with a safety controller and a switching logic designed to prevent dangerous behavior. In this paper, we propose using a real-time reachability algorithm for the implementation of the simplex architecture to assure the safety of a 1/10 scale open source autonomous vehicle platform known as F1/10. The reachability algorithm that we leverage (a) provides provable guarantees of safety, and (b) is used to detect potentially unsafe scenarios. In our approach, the need to analyze an underlying controller is abstracted away, instead focusing on the effects of the controller's decisions on the system's future states. We demonstrate the efficacy of our architecture through a vast set of experiments conducted both in simulation and on an embedded hardware platform.      
### 29.Cost-Efficient and QoS-Aware User Association and 3D Placement of 6G Aerial Mobile Access Points  [ :arrow_down: ](https://arxiv.org/pdf/2205.01390.pdf)
>  6G networks require a flexible infrastructure to dynamically provide ubiquitous network coverage. Mobile Access Points (MAP) deployment is a promising solution. In this paper, we formulate the joint 3D MAP deployment and user association problem over a dynamic network under interference and mobility constraints. First, we propose an iterative algorithm to optimize the deployment of MAPs. Our solution efficiently and quickly determines the number, position and configuration of MAPs for highly dynamic scenarios. MAPs provide appropriate Quality of Service (QoS) connectivity to mobile ground user in mmwave or sub-6GHz bands and find their optimal positions in a 3D grid. Each MAP also implies an energy cost (e.g. for travel) to be minimized. Once all MAPs deployed, a deep multiagent reinforcement learning algorithm is proposed to associate multiple users to multiple MAPs under interference constraint. Each user acts as an independent agent that operates in a fully distributed architecture and maximizes the network sum-rate.      
### 30.Deep Learning in Multimodal Remote Sensing Data Fusion: A Comprehensive Review  [ :arrow_down: ](https://arxiv.org/pdf/2205.01380.pdf)
>  With the extremely rapid advances in remote sensing (RS) technology, a great quantity of Earth observation (EO) data featuring considerable and complicated heterogeneity is readily available nowadays, which renders researchers an opportunity to tackle current geoscience applications in a fresh way. With the joint utilization of EO data, much research on multimodal RS data fusion has made tremendous progress in recent years, yet these developed traditional algorithms inevitably meet the performance bottleneck due to the lack of the ability to comprehensively analyse and interpret these strongly heterogeneous data. Hence, this non-negligible limitation further arouses an intense demand for an alternative tool with powerful processing competence. Deep learning (DL), as a cutting-edge technology, has witnessed remarkable breakthroughs in numerous computer vision tasks owing to its impressive ability in data representation and reconstruction. Naturally, it has been successfully applied to the field of multimodal RS data fusion, yielding great improvement compared with traditional methods. This survey aims to present a systematic overview in DL-based multimodal RS data fusion. More specifically, some essential knowledge about this topic is first given. Subsequently, a literature survey is conducted to analyse the trends of this field. Some prevalent sub-fields in the multimodal RS data fusion are then reviewed in terms of the to-be-fused data modalities, i.e., spatiospectral, spatiotemporal, light detection and ranging-optical, synthetic aperture radar-optical, and RS-Geospatial Big Data fusion. Furthermore, We collect and summarize some valuable resources for the sake of the development in multimodal RS data fusion. Finally, the remaining challenges and potential future directions are highlighted.      
### 31.MMSE Signal Detection for MIMO Systems based on Ordinary Differential Equation  [ :arrow_down: ](https://arxiv.org/pdf/2205.01338.pdf)
>  Motivated by emerging technologies for energy efficient analog computing and continuous-time processing, this paper proposes continuous-time minimum mean squared error estimation for multiple-input multiple-output (MIMO) systems based on an ordinary differential equation. Mean squared error (MSE) is a principal detection performance measure of estimation methods for MIMO systems. We derive an analytical MSE formula that indicates the MSE at any time. The MSE of the proposed method depends on a regularization parameter which affects the convergence property of the MSE. Furthermore, we extend the proposed method by using a time-dependent regularization parameter to achieve better convergence performance. Numerical experiments indicated excellent agreement with the theoretical values and improvement in the convergence performance owing to the use of the time-dependent parameter.      
### 32.Large-scale Virtual Clinical Trials of Closed-loop Treatments for People with Type 1 Diabetes  [ :arrow_down: ](https://arxiv.org/pdf/2205.01332.pdf)
>  We propose a virtual clinical trial for assessing the safety and efficacy of closed-loop diabetes treatments prior to an actual clinical trial. Such virtual trials enable rapid and risk-free pretrial testing of algorithms, and they can be used to compare different treatment variations for large and diverse populations. The participants are represented by multiple mathematical models, consisting of stochastic differential equations, and we use Monte Carlo closed-loop simulations to compute detailed statistics of the closed-loop treatments. We implement the virtual clinical trial using high-performance software and hardware, and we present an example trial with two mathematical models of one~million participants over 52~weeks (i.e., two~million simulations), which can be completed in 2~h 9~min.      
### 33.Few-Shot Musical Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2205.01273.pdf)
>  Deep learning-based approaches to musical source separation are often limited to the instrument classes that the models are trained on and do not generalize to separate unseen instruments. To address this, we propose a few-shot musical source separation paradigm. We condition a generic U-Net source separation model using few audio examples of the target instrument. We train a few-shot conditioning encoder jointly with the U-Net to encode the audio examples into a conditioning vector to configure the U-Net via feature-wise linear modulation (FiLM). We evaluate the trained models on real musical recordings in the MUSDB18 and MedleyDB datasets. We show that our proposed few-shot conditioning paradigm outperforms the baseline one-hot instrument-class conditioned model for both seen and unseen instruments. To extend the scope of our approach to a wider variety of real-world scenarios, we also experiment with different conditioning example characteristics, including examples from different recordings, with multiple sources, or negative conditioning examples.      
### 34.Applications of Deep Learning to the Design of Enhanced Wireless Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.01210.pdf)
>  Innovation in the physical layer of communication systems has traditionally been achieved by breaking down the transceivers into sets of processing blocks, each optimized independently based on mathematical models. Conversely, deep learning (DL)-based systems are able to handle increasingly complex tasks for which no tractable models are available. This thesis aims at comparing different approaches to unlock the full potential of DL in the physical layer. <br>First, we describe a neural network (NN)-based block strategy, where an NN is optimized to replace a block in a communication system. We apply this strategy to introduce a multi-user multiple-input multiple-output (MU-MIMO) detector that builds on top of an existing DL-based architecture. Second, we detail an end-to-end strategy, in which the transmitter and receiver are modeled as an autoencoder. This approach is illustrated with the design of waveforms that achieve high throughputs while satisfying peak-to-average power ratio (PAPR) and adjacent channel leakage ratio (ACLR) constraints. Lastly, we propose a hybrid strategy, where multiple DL components are inserted into a traditional architecture but are trained to optimize the end-to-end performance. To demonstrate its benefits, we propose a DL-enhanced MU-MIMO receiver that both enable lower bit error rates (BERs) compared to a conventional receiver and remains scalable to any number of users. <br>Each approach has its own strengths and shortcomings. While the first one is the easiest to implement, its individual block optimization does not ensure the overall system optimality. On the other hand, systems designed with the second approach are computationally complex but allow for new opportunities such as pilotless transmissions. Finally, the combined flexibility and end-to-end performance gains of the third approach motivate its use for short-term practical implementations.      
### 35.NHA12D: A New Pavement Crack Dataset and a Comparison Study Of Crack Detection Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2205.01198.pdf)
>  Crack detection plays a key role in automated pavement inspection. Although a large number of algorithms have been developed in recent years to further boost performance, there are still remaining challenges in practice, due to the complexity of pavement images. To further accelerate the development and identify the remaining challenges, this paper conducts a comparison study to evaluate the performance of the state of the art crack detection algorithms quantitatively and objectively. A more comprehensive annotated pavement crack dataset (NHA12D) that contains images with different viewpoints and pavements types is proposed. In the comparison study, crack detection algorithms were trained equally on the largest public crack dataset collected and evaluated on the proposed dataset (NHA12D). Overall, the U-Net model with VGG-16 as backbone has the best all-around performance, but models generally fail to distinguish cracks from concrete joints, leading to a high false-positive rate. It also found that detecting cracks from concrete pavement images still has huge room for improvement. Dataset for concrete pavement images is also missing in the literature. Future directions in this area include filling the gap for concrete pavement images and using domain adaptation techniques to enhance the detection results on unseen datasets.      
### 36.3D Convolutional Neural Networks for Dendrite Segmentation Using Fine-Tuning and Hyperparameter Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2205.01167.pdf)
>  Dendritic microstructures are ubiquitous in nature and are the primary solidification morphologies in metallic materials. Techniques such as x-ray computed tomography (XCT) have provided new insights into dendritic phase transformation phenomena. However, manual identification of dendritic morphologies in microscopy data can be both labor intensive and potentially ambiguous. The analysis of 3D datasets is particularly challenging due to their large sizes (terabytes) and the presence of artifacts scattered within the imaged volumes. In this study, we trained 3D convolutional neural networks (CNNs) to segment 3D datasets. Three CNN architectures were investigated, including a new 3D version of FCDense. We show that using hyperparameter optimization (HPO) and fine-tuning techniques, both 2D and 3D CNN architectures can be trained to outperform the previous state of the art. The 3D U-Net architecture trained in this study produced the best segmentations according to quantitative metrics (pixel-wise accuracy of 99.84% and a boundary displacement error of 0.58 pixels), while 3D FCDense produced the smoothest boundaries and best segmentations according to visual inspection. The trained 3D CNNs are able to segment entire 852 x 852 x 250 voxel 3D volumes in only ~60 seconds, thus hastening the progress towards a deeper understanding of phase transformation phenomena such as dendritic solidification.      
### 37.D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2205.01135.pdf)
>  The non-uniformly distributed nature of the 3D dynamic point cloud (DPC) brings significant challenges to its high-efficient inter-frame compression. This paper proposes a novel 3D sparse convolution-based Deep Dynamic Point Cloud Compression (D-DPCC) network to compensate and compress the DPC geometry with 3D motion estimation and motion compensation in the feature space. In the proposed D-DPCC network, we design a {\it Multi-scale Motion Fusion} (MMF) module to accurately estimate the 3D optical flow between the feature representations of adjacent point cloud frames. Specifically, we utilize a 3D sparse convolution-based encoder to obtain the latent representation for motion estimation in the feature space and introduce the proposed MMF module for fused 3D motion embedding. Besides, for motion compensation, we propose a 3D {\it Adaptively Weighted Interpolation} (3DAWI) algorithm with a penalty coefficient to adaptively decrease the impact of distant neighbors. We compress the motion embedding and the residual with a lossy autoencoder-based network. To our knowledge, this paper is the first work proposing an end-to-end deep dynamic point cloud compression framework. The experimental result shows that the proposed D-DPCC framework achieves an average 76\% BD-Rate (Bjontegaard Delta Rate) gains against state-of-the-art Video-based Point Cloud Compression (V-PCC) v13 in inter mode.      
### 38.Initial Access for Millimeter-Wave and Terahertz Communications with Hybrid Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2205.01098.pdf)
>  In order to achieve terabits-per-second (Tbps) data rates in the sixth-generation (6G) mobile system, wireless communications are required to exploit the abundant spectrum in the millimeter-wave (mmWave) and terahertz (THz) bands. However, high-frequency transmission heavily relies on high beamforming gain to compensate for severe propagation loss. A beam-based system faces a barrier in the process of initial access, where a base station must broadcast synchronization signals and system information to all users within its coverage. Hence, this paper proposes a novel omnidirectional broadcasting scheme for mmWave and THz systems with hybrid beamforming. It provides an instantaneously equal gain over all directions by forming complementary beams over sub-arrays. Numerical results verify that it can achieve omnidirectional coverage with a performance that remarkably outperforms the previous scheme.      
