# ArXiv eess --Wed, 25 May 2022
### 1.A Two-Stage Mechanism for Demand Response Markets  [ :arrow_down: ](https://arxiv.org/pdf/2205.12236.pdf)
>  We present a two-stage mechanism for creating markets for demand response. Demand response involves system operators using incentives to modulate electricity consumption around peak hours or when faced with an incidental supply shortage. However, system operators typically have imperfect information about their customers' counterfactual consumption, that is, their consumption had the incentive been absent. The standard approach to estimate the reduction in a customer's electricity consumption then is to estimate their counterfactual baseline. However, this approach is not robust to estimation errors or strategic exploitation by the consumers and can potentially lead to overpayments to customers who do not reduce their consumption and underpayments to those who do. In addition, the incentive payments are often designed based on models of consumer behavior or other ad-hoc rules that are only partially accurate at best. The two-stage mechanism proposed in this paper circumvents the aforementioned issues. In the day-ahead market, the participating loads submit the probability distribution of their next-day consumption. In real-time, if and when called upon for demand response, the loads report the realization of their baseline demand and receive credit for reductions below their reported baseline. The mechanism guarantees ex post incentive compatibility of truthful reporting of the probability distribution in the day-ahead market and truthful reporting of the realized baseline demand in real-time. The mechanism can be viewed as an extension of the celebrated Vickrey-Clarke-Groves mechanism augmented with a carefully crafted second-stage penalty for deviations from the day-ahead bids.      
### 2.OpenVVC: a Lightweight Software Decoder for the Versatile Video Coding Standard  [ :arrow_down: ](https://arxiv.org/pdf/2205.12217.pdf)
>  In the recent years, users requirements for higher resolution, coupled with the apparition of new multimedia applications, have created the need for a new video coding standard. The new generation video coding standard, called Versatile Video Coding (VVC), has been developed by the Joint Video Experts Team, and offers coding capability beyond the previous generation High Efficiency Video Coding (HEVC) standard. Due to the incorporation of more advanced and complex tools, the decoding complexity of VVC standard compared to HEVC has approximately doubled. This complexity increase raises new research challenges to achieve live software decoding. In this context, we developed OpenVVC, an open-source software decoder that supports a broad range of VVC functionalities. This paper presents the OpenVVC software architecture, its parallelism strategy as well as a detailed set of experimental results. By combining extensive data level parallelism with frame level parallelism, OpenVVC achieves real-time decoding of UHD video content. Moreover, the memory required by OpenVVC is remarkably low, which presents a great advantage for its integration on embedded platforms with low memory resources. The code of the OpenVVC decoder is publicly available at <a class="link-external link-https" href="https://github.com/OpenVVC/OpenVVC" rel="external noopener nofollow">this https URL</a>      
### 3.Rate-Splitting Multiple Access and its Interplay with Intelligent Reflecting Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2205.12207.pdf)
>  Rate-splitting multiple access (RSMA) has recently appeared as a powerful technique for improving the downlink performance of multiple-input multiple-output (MIMO) systems. By flexibly managing interference, RSMA can deliver high spectral and energy efficiency, as well as robustness to imperfect channel state information (CSI). In another development, an intelligent reflecting surface (IRS) has emerged as a method to control the wireless environment through software-configurable, near-passive, sub-wavelength reflecting elements. This article presents the potential of synergy between IRS and RSMA. Three important improvements achievable by IRS-RSMA schemes are identified, supported by insightful numerical examples, and mapped to beyond-5G use cases, along with future research directions.      
### 4.Automated WBRT Treatment Planning via Deep Learning Auto-Contouring and Customizable Landmark-Based Field Aperture Design  [ :arrow_down: ](https://arxiv.org/pdf/2205.12189.pdf)
>  In this work, we developed and evaluated a novel pipeline consisting of two landmark-based field aperture generation approaches for WBRT treatment planning; they are fully automated and customizable. The automation pipeline is beneficial for both clinicians and patients, where we can reduce clinician workload and reduce treatment planning time. The customizability of the field aperture design addresses different clinical requirements and allows the personalized design to become feasible. The performance results regarding quantitative and qualitative evaluations demonstrated that our plans were comparable with the original clinical plans. This technique has been deployed as part of a fully automated treatment planning tool for whole-brain cancer and could be translated to other treatment sites in the future.      
### 5.Towards Real-World 6G Drone Communication: Position and Camera Aided Beam Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2205.12187.pdf)
>  Millimeter-wave (mmWave) and terahertz (THz) communication systems typically deploy large antenna arrays to guarantee sufficient receive signal power. The beam training overhead associated with these arrays, however, make it hard for these systems to support highly-mobile applications such as drone communication. To overcome this challenge, this paper proposes a machine learning-based approach that leverages additional sensory data, such as visual and positional data, for fast and accurate mmWave/THz beam prediction. The developed framework is evaluated on a real-world multi-modal mmWave drone communication dataset comprising of co-existing camera, practical GPS, and mmWave beam training data. The proposed sensing-aided solution achieves a top-1 beam prediction accuracy of 86.32% and close to 100% top-3 and top-5 accuracies, while considerably reducing the beam training overhead. This highlights a promising solution for enabling highly mobile 6G drone communications.      
### 6.Competitive Prediction-Aware Online Algorithms for Energy Generation Scheduling in Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2205.12168.pdf)
>  Online decision-making in the presence of uncertain future information is abundant in many problem domains. In the critical problem of energy generation scheduling for microgrids, one needs to decide when to switch energy supply between a cheaper local generator with startup cost and the costlier on-demand external grid, considering intermittent renewable generation and fluctuating demands. Without knowledge of future input, competitive online algorithms are appealing as they provide optimality guarantees against the optimal offline solution. In practice, however, future input, e.g., wind generation, is often predictable within a limited time window, and can be exploited to further improve the competitiveness of online algorithms. In this paper, we exploit the structure of information in the prediction window to design a novel prediction-aware online algorithm for energy generation scheduling in microgrids. Our algorithm achieves the best competitive ratio to date for this important problem, which is at most $3-2/(1+\mathcal{O}(\frac{1}{w})),$ where $w$ is the prediction window size. We also characterize a non-trivial lower bound of the competitive ratio and show that the competitive ratio of our algorithm is only $9\%$ away from the lower bound, when a few hours of prediction is available. Simulation results based on real-world traces corroborate our theoretical analysis and highlight the advantage of our new prediction-aware design.      
### 7.D$^\text{2}$UF: Deep Coded Aperture Design and Unrolling Algorithm for Compressive Spectral Image Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2205.12158.pdf)
>  Compressive spectral imaging (CSI) has attracted significant attention since it employs synthetic apertures to codify spatial and spectral information, sensing only 2D projections of the 3D spectral image. However, these optical architectures suffer from a trade-off between the spatial and spectral resolution of the reconstructed image due to technology limitations. To overcome this issue, compressive spectral image fusion (CSIF) employs the projected measurements of two CSI architectures with different resolutions to estimate a high-spatial high-spectral resolution. This work presents the fusion of the compressive measurements of a low-spatial high-spectral resolution coded aperture snapshot spectral imager (CASSI) architecture and a high-spatial low-spectral resolution multispectral color filter array (MCFA) system. Unlike previous CSIF works, this paper proposes joint optimization of the sensing architectures and a reconstruction network in an end-to-end (E2E) manner. The trainable optical parameters are the coded aperture (CA) in the CASSI and the colored coded aperture in the MCFA system, employing a sigmoid activation function and regularization function to encourage binary values on the trainable variables for an implementation purpose. Additionally, an unrolling-based network inspired by the alternating direction method of multipliers (ADMM) optimization is formulated to address the reconstruction step and the acquisition systems design jointly. Finally, a spatial-spectral inspired loss function is employed at the end of each unrolling layer to increase the convergence of the unrolling network. The proposed method outperforms previous CSIF methods, and experimental results validate the method with real measurements.      
### 8.A Novel LFM Waveform for Terahertz-Band Joint Radar and Communications over Inter-Satellite Links  [ :arrow_down: ](https://arxiv.org/pdf/2205.12155.pdf)
>  There is no doubt that we need to keep our eyes on the sky as satellite networks aim to address the demands of 6G and beyond communications systems. On the other hand, existence of millions of space debris pieces, large or small, poses a threat to the new space communications systems which consist of large number of small satellites, especially in the low-orbit. In this study, a dual-functioning pulsed linear frequency modulated (LFM) waveform at Terahertz (THz) bands is proposed for both wireless communications and space debris sensing over low-orbit inter-satellite links (ISLs). Initially, the ambiguity function of the proposed waveform is derived. Then, velocity and range estimation performance for radar function and bit error rate performance for the communications function are investigated. Simulation results indicate important performance gains in the THz-bands when compared to the legacy LFM systems.      
### 9.A Novel Data-Driven Method for the Analysis and Reconstruction of Cardiac Cine MRI  [ :arrow_down: ](https://arxiv.org/pdf/2205.12097.pdf)
>  Cardiac cine magnetic resonance imaging (MRI) can be considered the optimal criterion for measuring cardiac function. This imaging technique can provide us with detailed information about cardiac structure, tissue composition and even blood flow. This work considers the application of the higher order dynamic mode decomposition (HODMD) method to a set of MR images of a heart, with the ultimate goal of identifying the main patterns and frequencies driving the heart dynamics. A novel algorithm based on singular value decomposition combined with HODMD is introduced, providing a three-dimensional reconstruction of the heart. This algorithm is applied (i) to reconstruct corrupted or missing images, and (ii) to build a reduced order model of the heart dynamics.      
### 10.Reconfigurable Intelligent Surfaces for Energy Efficiency in Full-duplex Communication System  [ :arrow_down: ](https://arxiv.org/pdf/2205.12079.pdf)
>  In this letter, we study the reconfigurable intelligent surfaces (RIS) aided full-duplex (FD) communication system. By jointly designing the active beamforming of two multi-antenna sources and passive beamforming of RIS, we aim to maximize the energy efficiency of the system, where extra self-interference cancellation power consumption in FD system is also considered. We divide the optimization problem into active and passive beamforming design subproblems, and adopt the alternative optimization framework to solve them iteratively. Dinkelbach's method is used to tackle the fractional objective function in active beamforming problem. Penalty method and successive convex approximation are exploited for passive beamforming design. Simulation results show the energy efficiency of our scheme outperforms other benchmarks.      
### 11.Sharp Analysis of RLS-based Digital Precoder with Limited PAPR in Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2205.12077.pdf)
>  This paper focuses on the performance analysis of a class of limited peak-to-average power ratio (PAPR) precoders for downlink multi-user massive multiple-input multiple-output (MIMO) systems. Contrary to conventional precoding approaches based on simple linear precoders maximum ratio transmission (MRT) and regularized zero forcing (RZF), the precoders in this paper are obtained by solving a convex optimization problem. To be specific, for the precoders we analyze in this paper, the power of each precoded symbol entry is restricted, which allows them to present a reduced PAPR at each antenna. By using the Convex Gaussian Min-max Theorem (CGMT), we analytically characterize the empirical distribution of the precoded vector and the joint empirical distribution between the distortion and the intended symbol vector. This allows us to study the performance of these precoders in terms of per-antenna power, per-user distortion power, signal to interference and noise ratio, and bit error probability. We show that for this class of precoders, there is an optimal transmit power that maximizes the system performance.      
### 12.Edge Semantic Cognitive Intelligence for 6G Networks: Models, Framework, and Applications  [ :arrow_down: ](https://arxiv.org/pdf/2205.12073.pdf)
>  Edge intelligence is anticipated to underlay the pathway to connected intelligence for 6G networks, but the organic confluence of edge computing and artificial intelligence still needs to be carefully treated. To this end, this article discusses the concepts of edge intelligence from the semantic cognitive perspective. Two instructive theoretical models for edge semantic cognitive intelligence (ESCI) are first established. Afterwards, the ESCI framework orchestrating deep learning with semantic communication is discussed. Two representative applications are present to shed light on the prospect of ESCI in 6G networks. Some open problems are finally listed to elicit the future research directions of ESCI.      
### 13.C-AND: Mixed Writing Scheme for Disturb Reduction in 1T Ferroelectric FET Memory  [ :arrow_down: ](https://arxiv.org/pdf/2205.12061.pdf)
>  Ferroelectric field effect transistor (FeFET) memory has shown the potential to meet the requirements of the growing need for fast, dense, low-power, and non-volatile memories. In this paper, we propose a memory architecture named crossed-AND (C-AND), in which each storage cell consists of a single ferroelectric transistor. The write operation is performed using different write schemes and different absolute voltages, to account for the asymmetric switching voltages of the FeFET. It enables writing an entire wordline in two consecutive cycles and prevents current and power through the channel of the transistor. During the read operation, the current and power are mostly sensed at a single selected device in each column. The read scheme additionally enables reading an entire word without read errors, even along long bitlines. Our Simulations demonstrate that, in comparison to the previously proposed AND architecture, the C-AND architecture diminishes read errors, reduces write disturbs, enables the usage of longer bitlines, and saves up to 2.92X in memory cell area.      
### 14.Defending a Music Recommender Against Hubness-Based Adversarial Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2205.12032.pdf)
>  Adversarial attacks can drastically degrade performance of recommenders and other machine learning systems, resulting in an increased demand for defence mechanisms. We present a new line of defence against attacks which exploit a vulnerability of recommenders that operate in high dimensional data spaces (the so-called hubness problem). We use a global data scaling method, namely Mutual Proximity (MP), to defend a real-world music recommender which previously was susceptible to attacks that inflated the number of times a particular song was recommended. We find that using MP as a defence greatly increases robustness of the recommender against a range of attacks, with success rates of attacks around 44% (before defence) dropping to less than 6% (after defence). Additionally, adversarial examples still able to fool the defended system do so at the price of noticeably lower audio quality as shown by a decreased average SNR.      
### 15.IRS Phase-Shift Feedback Overhead-Aware Model Based on Rank-One Tensor Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2205.12024.pdf)
>  In this paper, we propose a rank-one tensor modeling approach that yields a compact representation of the optimum IRS phase-shift vector for reducing the feedback overhead. The main idea consists of factorizing the IRS phase-shift vector as a Kronecker product of smaller vectors, namely factors. The proposed phase-shift model allows the network to trade-off between achievable data rate and feedback reduction by controling the factorization parameters. Our simulations show that the proposed phase-shift factorization drastically reduces the feedback overhead, while improving the data rate in some scenarios, compared to the state-of-the-art schemes.      
### 16.Core-shell enhanced single particle model for LiFePO$_4$ batteries  [ :arrow_down: ](https://arxiv.org/pdf/2205.12008.pdf)
>  In this paper, a novel electrochemical model for LiFePO$_4$ battery cells that accounts for the positive particle lithium intercalation and deintercalation dynamics is proposed. Starting from the enhanced single particle model, mass transport and balance equations along with suitable boundary conditions are introduced to model the phase transformation phenomena during lithiation and delithiation in the positive electrode material. The lithium-poor and lithium-rich phases are modeled using the core-shell principle, where a core composition is encapsulated with a shell composition. The coupled partial differential equations describing the phase transformation are discretized using the finite difference method, from which a system of ordinary differential equations written in state-space representation is obtained. Finally, model parameter identification is performed using experimental data from a 49Ah LFP pouch cell.      
### 17.PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit  [ :arrow_down: ](https://arxiv.org/pdf/2205.12007.pdf)
>  PaddleSpeech is an open-source all-in-one speech toolkit. It aims at facilitating the development and research of speech processing technologies by providing an easy-to-use command-line interface and a simple code structure. This paper describes the design philosophy and core architecture of PaddleSpeech to support several essential speech-to-text and text-to-speech tasks. PaddleSpeech achieves competitive or state-of-the-art performance on various speech datasets and implements the most popular methods. It also provides recipes and pretrained models to quickly reproduce the experimental results in this paper. PaddleSpeech is publicly avaiable at <a class="link-external link-https" href="https://github.com/PaddlePaddle/PaddleSpeech" rel="external noopener nofollow">this https URL</a>.      
### 18.Ptychographic reconstruction with wavefront initialization  [ :arrow_down: ](https://arxiv.org/pdf/2205.11996.pdf)
>  X-ray ptychography is a cutting edge imaging technique providing ultra-high spatial resolutions. In ptychography, phase retrieval, i.e., the recovery of a complex valued signal from intensity-only measurements, is enabled by exploiting a redundancy of information contained in diffraction patterns measured with overlapping illuminations. For samples that are considerably larger than the probe we show that during the iteration the bulk information has to propagate from the sample edges to the center. This constitutes an inherent limitation of reconstruction speed for algorithms that use a flat initialization. Here, we experimentally demonstrate that a considerable improvement of computational speed can be achieved by utilizing a low resolution sample wavefront retrieved from measured diffraction patterns as initialization. In addition, we show that this approach avoids phase singularity artifacts due to strong phase gradients. Wavefront initialization is computationally fast and compatible with non-bulky samples. Therefore, the presented approach is readily adaptable with established ptychographic reconstruction algorithms implying a wide spread use.      
### 19.Co-optimization of Battery Routing and Load Restoration for Microgrids with Mobile Energy Storage Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.11992.pdf)
>  Mobile energy storage systems (MESS) offer great operational flexibility to enhance the resiliency of distribution systems in an emergency condition. The optimal placement and sizing of those units are pivotal for quickly restoring the curtailed loads. In this paper, we propose a model for load restoration in a microgrid while concurrently optimizing the MESS routes required for the same. The model is formulated as a mixed integer second order cone program by considering the state of charge and evolution of the lower and upper bounds of battery capacities. Simulation results tested on the IEEE 123- bus benchmark system demonstrate the efficacy of the proposed model.      
### 20.Generative Models for Reproducible Coronary Calcium Scoring  [ :arrow_down: ](https://arxiv.org/pdf/2205.11967.pdf)
>  Purpose: Coronary artery calcium (CAC) score, i.e. the amount of CAC quantified in CT, is a strong and independent predictor of coronary heart disease (CHD) events. However, CAC scoring suffers from limited interscan reproducibility, which is mainly due to the clinical definition requiring application of a fixed intensity level threshold for segmentation of calcifications. This limitation is especially pronounced in non-ECG-synchronized CT where lesions are more impacted by cardiac motion and partial volume effects. Therefore, we propose a CAC quantification method that does not require a threshold for segmentation of CAC. Approach: Our method utilizes a generative adversarial network where a CT with CAC is decomposed into an image without CAC and an image showing only CAC. The method, using a CycleGAN, was trained using 626 low-dose chest CTs and 514 radiotherapy treatment planning CTs. Interscan reproducibility was compared to clinical calcium scoring in radiotherapy treatment planning CTs of 1,662 patients, each having two scans. Results: A lower relative interscan difference in CAC mass was achieved by the proposed method: 47% compared to 89% manual clinical calcium scoring. The intraclass correlation coefficient of Agatston scores was 0.96 for the proposed method compared to 0.91 for automatic clinical calcium scoring. Conclusions: The increased interscan reproducibility achieved by our method may lead to increased reliability of CHD risk categorization and improved accuracy of CHD event prediction.      
### 21.Comparison of Fractional-Order and Integer-Order H-infinty Control of a Non-Collocated Two-Mass Oscillator  [ :arrow_down: ](https://arxiv.org/pdf/2205.11957.pdf)
>  We consider the robust control of a two-mass oscillator with a dominant input delay. Our aim is to compare a fractional-order tuning approach including the partial compensation of non-minimum phase zeros with a classical H-infinity loop-shaping design, since both these designs lead to a relatively high controller order. First of all a detailed physical model is derived and validated using measurement data. Based on the linearized model both controllers are designed to be comparable, i.e. they show a similar crossover frequency in the open loop and the final controller order is reduced to the same range for both designs. The major differences between both are the different methods how the feed-forward action is included. The loop-shaping approach with fractional-order elements relies on the plant inverse using a flat output, whereas the H-infinty design incorporates a two-degree of freedom control, i.e. the reference signal is included into the known inputs of the generalized plant. Each controller is tested in simulation and experiment. As both open-loops are nearly identical in the frequency range of interest, the results from an input disturbance experiment show no major difference. The different design approaches of the feed-forward path are clearly visible in the tracking experiment.      
### 22.3D helical CT reconstruction with memory efficient invertible Learned Primal-Dual method  [ :arrow_down: ](https://arxiv.org/pdf/2205.11952.pdf)
>  Helical acquisition geometry is the most common geometry used in computed tomography (CT) scanners for medical imaging. We adapt the invertible Learned Primal-Dual (iLPD) deep neural network architecture so that it can be applied to helical 3D CT reconstruction. We achieve this by splitting the geometry and the data in parts that fit the memory and by splitting images into corresponding sub-volumes. The architecture can be applied to images different in size along the rotation axis. We perform the experiments on tomographic data simulated from realistic helical geometries.      
### 23.Aerosense: A Self-Sustainable And Long-Range Bluetooth Wireless Sensor Node for Aerodynamic and Aeroacoustic Monitoring on Wind Turbines  [ :arrow_down: ](https://arxiv.org/pdf/2205.11902.pdf)
>  This paper presents a low-power, self-sustainable, and modular wireless sensor node for aerodynamic and acoustic measurements on wind turbines and other industrial structures. It includes 40 high-accuracy barometers, 10 microphones, 5 differential pressure sensors, and implements a lossy and a lossless on-board data compression algorithm to decrease the transmission energy cost. The wireless transmitter is based on Bluetooth Low Energy 5.1 tuned for long-range and high throughput while maintaining adequate per-bit energy efficiency (80 nJ). Moreover, we field-assessed the node capability to collect precise and accurate aerodynamic data. Outdoor experimental tests revealed that the system can acquire and sustain a data rate of 850 kbps over 438 m. The power consumption while collecting and streaming all measured data is 120 mW, enabling self-sustainability and long-term in-situ monitoring with a 111 cm^2 photovoltaic panel.      
### 24.Stability in data-driven MPC: an inherent robustness perspective  [ :arrow_down: ](https://arxiv.org/pdf/2205.11859.pdf)
>  Data-driven model predictive control (DD-MPC) based on Willems' Fundamental Lemma has received much attention in recent years, allowing to control systems directly based on an implicit data-dependent system description. The literature contains many successful practical applications as well as theoretical results on closed-loop stability and robustness. In this paper, we provide a tutorial introduction to DD-MPC for unknown linear time-invariant (LTI) systems with focus on (robust) closed-loop stability. We first address the scenario of noise-free data, for which we present a DD-MPC scheme with terminal equality constraints and derive closed-loop properties. In case of noisy data, we introduce a simple yet powerful approach to analyze robust stability of DD-MPC by combining continuity of DD-MPC w.r.t. noise with inherent robustness of model-based MPC, i.e., robustness of nominal MPC w.r.t. small disturbances. Moreover, we discuss how the presented proof technique allows to show closed-loop stability of a variety of DD-MPC schemes with noisy data, as long as the corresponding model-based MPC is inherently robust.      
### 25.Neural Contextual Bandits Based Dynamic Sensor Selection for Low-Power Body-Area Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.11832.pdf)
>  Providing health monitoring devices with machine intelligence is important for enabling automatic mobile healthcare applications. However, this brings additional challenges due to the resource scarcity of these devices. This work introduces a neural contextual bandits based dynamic sensor selection methodology for high-performance and resource-efficient body-area networks to realize next generation mobile health monitoring devices. The methodology utilizes contextual bandits to select the most informative sensor combinations during runtime and ignore redundant data for decreasing transmission and computing power in a body area network (BAN). The proposed method has been validated using one of the most common health monitoring applications: cardiac activity monitoring. Solutions from our proposed method are compared against those from related works in terms of classification performance and energy while considering the communication energy consumption. Our final solutions could reach $78.8\%$ AU-PRC on the PTB-XL ECG dataset for cardiac abnormality detection while decreasing the overall energy consumption and computational energy by $3.7 \times$ and $4.3 \times$, respectively.      
### 26.Sensing Performance of Multi-Channel RFID-based Finger Augmentation Devices for Tactile Internet  [ :arrow_down: ](https://arxiv.org/pdf/2205.11811.pdf)
>  Radiofrequency finger augmentation devices (R-FADs) are a recently introduced class of epidermal radiofrequency identification (RFID) sensor-tags attached to the fingers, communicating with a body-worn reader. These devices are promising candidates to enable Tactile Internet (TI) applications in the short term. R-FAD based on auto-tuning RFID microchips can be used as dielectric probes for the material of touched objects. However, due to the nearly unpredictable intrinsic variability of finger-object interaction, a single sensorized finger (single-channel device) is not enough to guarantee reliable data sampling. These limitations can be overcome by exploiting a multi-channel R-FAD sensorizing multiple fingers of the hand. In this paper, the dielectric-sensing performance of a multi-channel R-FAD, composed of sensors encapsulated into soft elastomers, is numerically and experimentally characterized, involving a set of volunteers. The inter-sensor coupling is negligible, thus enabling simultaneous independent dielectric measurements. The multi-sensor configuration allows for 100% reliability of the on-hand communication link for touched objects in a wide range of permittivity. Experiments moreover demonstrate that multi-channel measurements can halve the measurement uncertainty of the single-channel case. The achievable precision is suitable to discriminate among low-, medium-, and high-permittivity materials.      
### 27.SepIt: Approaching a Single Channel Speech Separation Bound  [ :arrow_down: ](https://arxiv.org/pdf/2205.11801.pdf)
>  We present an upper bound for the Single Channel Speech Separation task, which is based on an assumption regarding the nature of short segments of speech. Using the bound, we are able to show that while the recent methods have made significant progress for a few speakers, there is room for improvement for five and ten speakers. We then introduce a Deep neural network, SepIt, that iteratively improves the different speakers' estimation. At test time, SpeIt has a varying number of iterations per test sample, based on a mutual information criterion that arises from our analysis. In an extensive set of experiments, SepIt outperforms the state-of-the-art neural networks for 2, 3, 5, and 10 speakers.      
### 28.UNet#: A UNet-like Redesigning Skip Connections for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.11759.pdf)
>  As an essential prerequisite for developing a medical intelligent assistant system, medical image segmentation has received extensive research and concentration from the neural network community. A series of UNet-like networks with encoder-decoder architecture has achieved extraordinary success, in which UNet2+ and UNet3+ redesign skip connections, respectively proposing dense skip connection and full-scale skip connection and dramatically improving compared with UNet in medical image segmentation. However, UNet2+ lacks sufficient information explored from the full scale, which will affect the learning of organs' location and boundary. Although UNet3+ can obtain the full-scale aggregation feature map, owing to the small number of neurons in the structure, it does not satisfy the segmentation of tiny objects when the number of samples is small. This paper proposes a novel network structure combining dense skip connections and full-scale skip connections, named UNet-sharp (UNet\#) for its shape similar to symbol \#. The proposed UNet\# can aggregate feature maps of different scales in the decoder sub-network and capture fine-grained details and coarse-grained semantics from the full scale, which benefits learning the exact location and accurately segmenting the boundary of organs or lesions. We perform deep supervision for model pruning to speed up testing and make it possible for the model to run on mobile devices; furthermore, designing two classification-guided modules to reduce false positives achieves more accurate segmentation results. Various experiments of semantic segmentation and instance segmentation on different modalities (EM, CT, MRI) and dimensions (2D, 3D) datasets, including the nuclei, brain tumor, liver, and lung, demonstrate that the proposed method outperforms state-of-the-art models.      
### 29.Robotic agricultural instrument for automated extraction of nematode cysts and eggs from soil to improve integrated pest management  [ :arrow_down: ](https://arxiv.org/pdf/2205.11757.pdf)
>  Soybeans are an important crop for global food security. Every year, soybean yields are reduced by numerous soybean diseases, particularly the soybean cyst nematode (SCN). It is difficult to visually identify the presence of SCN in the field, let alone its population densities or numbers, as there are no obvious aboveground disease symptoms. The only definitive way to assess SCN population densities is to directly extract the SCN cysts from soil and then extract the eggs from cysts and count them. Extraction is typically conducted in commercial soil analysis laboratories and university plant diagnostic clinics and involves repeated steps of sieving, washing, collecting, grinding, and cleaning. Here we present a robotic instrument to reproduce and automate the functions of the conventional methods to extract nematode cysts from soil and subsequently extract eggs from the recovered nematode cysts. We incorporated mechanisms to actuate the stage system, manipulate positions of individual sieves using the gripper, recover cysts and cyst-sized objects from soil suspended in water, and grind the cysts to release their eggs. All system functions are controlled and operated by a touchscreen interface software. The performance of the robotic instrument is evaluated using soil samples infested with SCN from two farms at different locations and results were comparable to the conventional technique. Our new technology brings the benefits of automation to SCN soil diagnostics, a step towards long-term integrated pest management of this serious soybean pest.      
### 30.Vehicular Connectivity on Complex Trajectories: Roadway-Geometry Aware ISAC Beam-tracking  [ :arrow_down: ](https://arxiv.org/pdf/2205.11749.pdf)
>  In this paper, we propose sensing-assisted beamforming designs for vehicles on arbitrarily shaped roads by relying on integrated sensing and communication (ISAC) signalling.Specifically, we aim to address the limitations of conventional ISAC beam-tracking schemes that do not apply to complex road geometries. To improve the tracking accuracy and communication quality of service (QoS) in vehicle to infrastructure (V2I) networks, it is essential to model the complicated roadway geometry. To that end, we impose the curvilinear coordinate system (CCS) in an interacting multiple model extended Kalman filter (IMM-EKF) framework. By doing so, both the position and the motion of the vehicle on a complicated road can be explicitly modeled and precisely tracked attributing to the benefits from the CCS. Furthermore, an optimization problem is formulated to maximize the array gain through dynamically adjusting the array size and thereby controlling the beamwidth, which takes the performance loss caused by beam misalignment into account.Numerical simulations demonstrate that the roadway geometry-aware ISAC beamforming approach outperforms the communication-only based and ISAC kinematic-only based technique in the tracking performance. Moreover, the effectiveness of the dynamic beamwidth design is also verified by our numerical results.      
### 31.Demand Response Method Considering Multiple Types of Flexible Loads in Industrial Parks  [ :arrow_down: ](https://arxiv.org/pdf/2205.11743.pdf)
>  With the rapid development of the energy internet, the proportion of flexible loads in smart grid is getting much higher than before. It is highly important to model flexible loads based on demand response. Therefore, a new demand response method considering multiple flexible loads is proposed in this paper to character the integrated demand response (IDR) resources. Firstly, a physical process analytical deduction (PPAD) model is proposed to improve the classification of flexible loads in industrial parks. Scenario generation, data point augmentation, and smooth curves under various operating conditions are considered to enhance the applicability of the model. Secondly, in view of the strong volatility and poor modeling effect of Wasserstein-generative adversarial networks (WGAN), an improved WGAN-gradient penalty (IWGAN-GP) model is developed to get a faster convergence speed than traditional WGAN and generate a higher quality samples. Finally, the PPAD and IWGAN-GP models are jointly implemented to reveal the degree of correlation between flexible loads. Meanwhile, an intelligent offline database is built to deal with the impact of nonlinear factors in different response scenarios. Numerical examples have been performed with the results proving that the proposed method is significantly better than the existing technologies in reducing load modeling deviation and improving the responsiveness of park loads.      
### 32.Trends in Workplace Wearable Technologies and Connected-Worker Solutions for Next-Generation Occupational Safety, Health, and Productivity  [ :arrow_down: ](https://arxiv.org/pdf/2205.11740.pdf)
>  The workplace influences the safety, health, and productivity of workers at multiple levels. To protect and promote total worker health, smart hardware, and software tools have emerged for the identification, elimination, substitution, and control of occupational hazards. Wearable devices enable constant monitoring of individual workers and the environment, whereas connected worker solutions provide contextual information and decision support. Here, the recent trends in commercial workplace technologies to monitor and manage occupational risks, injuries, accidents, and diseases are reviewed. Workplace safety wearables for safe lifting, ergonomics, hazard identification, sleep monitoring, fatigue management, and heat and cold stress are discussed. Examples of workplace productivity wearables for asset tracking, augmented reality, gesture and motion control, brain wave sensing, and work stress management are given. Workplace health wearables designed for work-related musculoskeletal disorders, functional movement disorders, respiratory hazards, cardiovascular health, outdoor sun exposure, and continuous glucose monitoring are shown. Connected worker platforms are discussed with information about the architecture, system modules, intelligent operations, and industry applications. Predictive analytics provide contextual information about occupational safety risks, resource allocation, equipment failure, and predictive maintenance. Altogether, these examples highlight the ground-level benefits of real-time visibility about frontline workers, work environment, distributed assets, workforce efficiency, and safety compliance      
### 33.Open Droplet Microfluidics for Testing Multi-Drug Resistance and Antibiotic Resilience in Bacteria  [ :arrow_down: ](https://arxiv.org/pdf/2205.11714.pdf)
>  New combinations of existing antibiotics are being investigated to combat bacterial resilience. This requires detection technologies with reasonable cost, accuracy, resolution, and throughput. Here, we present a multi -drug screening platform for bacterial cultures by combining droplet microfluidics, search algorithms, and imaging with a wide field of view. We remotely alter the chemical microenvironment around cells and test 12 combinations of resistant cell types and chemicals. Fluorescence intensity readouts allow us to infer bacterial resistance to specific antibiotics within 8 hours. The platform has potential to detect and identify parameters of bacterial resilience in cell cultures, biofilms, and microbial aggregates.      
### 34.A Variational Bayesian Perspective on Massive MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2205.11649.pdf)
>  Optimal data detection in massive multiple-input multiple-output (MIMO) systems requires prohibitive computational complexity. A variety of detection algorithms have been proposed in the literature, offering different trade-offs between complexity and detection performance. In this paper, we build upon variational Bayes (VB) inference to design low-complexity multiuser detection algorithms for massive MIMO systems. We first examine the massive MIMO detection problem with perfect channel state information at the receiver (CSIR) and show that a conventional VB method with known noise variance yields poor detection performance. To address this limitation, we devise two new VB algorithms that use the noise variance and covariance matrix postulated by the algorithms themselves. We further develop the VB framework for massive MIMO detection with imperfect CSIR. Simulation results show that the proposed VB methods achieve significantly lower detection errors compared with existing schemes for a wide range of channel models.      
### 35.Machine Learning for Electricity Market Clearing  [ :arrow_down: ](https://arxiv.org/pdf/2205.11641.pdf)
>  This paper seeks to design a machine learning twin of the optimal power flow (OPF) optimization, which is used in market-clearing procedures by wholesale electricity markets. The motivation for the proposed approach stems from the need to obtain the digital twin, which is much faster than the original, while also being sufficiently accurate and producing consistent generation dispatches and locational marginal prices (LMPs), which are primal and dual solutions of the OPF optimization, respectively. Availability of market-clearing tools based on this approach will enable computationally tractable evaluation of multiple dispatch scenarios under a given unit commitment. Rather than direct solution of OPF, the Karush-Kuhn-Tucker (KKT) conditions for the OPF problem in question may be written, and in parallel the LMPs of generators and loads may be expressed in terms of the OPF Lagrangian multipliers. Also, taking advantage of the practical fact that many of the Lagrangian multipliers associated with lines will be zero (thermal limits are not binding), we build and train an ML scheme which maps flexible resources (loads and renewables) to the binding lines, and supplement it with an efficient power-grid aware linear map to optimal dispatch and LMPs. The scheme is validated and illustrated on IEEE models. We also report a trade of analysis between quality of the reconstruction and number of samples needed to train the model.      
### 36.A fuzzy feedback linearization scheme applied to vibration control of a smart structure  [ :arrow_down: ](https://arxiv.org/pdf/2205.11609.pdf)
>  Smart structures are usually designed with a stimulus-response mechanism to mimic the autoregulatory process of living systems. In this work, in order to simulate this natural and self-adjustable behavior, a fuzzy feedback linearization scheme is applied to a shape memory two-bar truss. This structural system exhibits both constitutive and geometrical nonlinearities presenting the snap-through behavior and chaotic dynamics. On this basis, a nonlinear controller is employed for vibration suppression in the chaotic smart truss. The control scheme is primarily based on feedback linearization and enhanced by a fuzzy inference system to cope with modeling inaccuracies and external disturbances. The overall control system performance is evaluated by means of numerical simulations, promoting vibration reduction and avoiding snap-through behavior.      
### 37.A framework for the development of intelligent mechanical systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.11594.pdf)
>  From autonomous vacuum cleaners to self-driving cars, intelligent mechanical systems are becoming an intrinsic part of our daily lives. In this work, a framework for the development of intelligent mechanical systems is presented.Considering that in this scenario the adopted control approach plays an essential role, I show that the proposed scheme should be able to not only adapt itself to changes in the environment, but also learn from its own experience.      
### 38.An intelligent controller for underactuated mechanical systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.11585.pdf)
>  This paper presents an intelligent controller for uncertain underactuated nonlinear systems. The adopted approach is based on sliding mode control and enhanced by an artificial neural network to cope with modeling inaccuracies and external disturbances that can arise. The sliding surfaces are defined as a linear combination of both actuated and unactuated variables. A radial basis function is added to compensate the performance drop when, in order to avoid the chattering phenomenon, the sign function is substituted by a saturation function in the conventional sliding mode controller. An application of the proposed scheme is introduced for an inverted pendulum, in order to illustrate the controller design method, and numerical results are presented to demonstrate the improved performance of the resulting intelligent controller.      
### 39.BolT: Fused Window Transformers for fMRI Time Series Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2205.11578.pdf)
>  Functional magnetic resonance imaging (fMRI) enables examination of inter-regional interactions in the brain via functional connectivity (FC) analyses that measure the synchrony between the temporal activations of separate regions. Given their exceptional sensitivity, deep-learning methods have received growing interest for FC analyses of high-dimensional fMRI data. In this domain, models that operate directly on raw time series as opposed to pre-computed FC features have the potential benefit of leveraging the full scale of information present in fMRI data. However, previous models are based on architectures suboptimal for temporal integration of representations across multiple time scales. Here, we present BolT, blood-oxygen-level-dependent transformer, for analyzing multi-variate fMRI time series. BolT leverages a cascade of transformer encoders equipped with a novel fused window attention mechanism. Transformer encoding is performed on temporally-overlapped time windows within the fMRI time series to capture short time-scale representations. To integrate information across windows, cross-window attention is computed between base tokens in each time window and fringe tokens from neighboring time windows. To transition from local to global representations, the extent of window overlap and thereby number of fringe tokens is progressively increased across the cascade. Finally, a novel cross-window regularization is enforced to align the high-level representations of global $CLS$ features across time windows. Comprehensive experiments on public fMRI datasets clearly illustrate the superior performance of BolT against state-of-the-art methods. Posthoc explanatory analyses to identify landmark time points and regions that contribute most significantly to model decisions corroborate prominent neuroscientific findings from recent fMRI studies.      
### 40.From Hours to Seconds: Towards 100x Faster Quantitative Phase Imaging via Differentiable Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2205.11521.pdf)
>  With applications ranging from metabolomics to histopathology, quantitative phase microscopy (QPM) is a powerful label-free imaging modality. Despite significant advances in fast multiplexed imaging sensors and deep-learning-based inverse solvers, the throughput of QPM is currently limited by the speed of electronic hardware. Complementarily, to improve throughput further, here we propose to acquire images in a compressed form such that more information can be transferred beyond the existing electronic hardware bottleneck. To this end, we present a learnable optical compression-decompression framework that learns content-specific features. The proposed differentiable optical-electronic quantitative phase microscopy ($\partial \mu$) first uses learnable optical feature extractors as image compressors. The intensity representation produced by these networks is then captured by the imaging sensor. Finally, a reconstruction network running on electronic hardware decompresses the QPM images. The proposed system achieves compression of $\times$ 64 while maintaining the SSIM of $\sim 0.90$ and PSNR of $\sim 30$ dB. The promising results demonstrated by our experiments open up a new pathway for achieving end-to-end optimized (i.e., optics and electronic) compact QPM systems that provide unprecedented throughput improvements.      
### 41.Cardiomegaly Detection using Deep Convolutional Neural Network with U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2205.11515.pdf)
>  Cardiomegaly is indeed a medical disease in which the heart is enlarged. Cardiomegaly is better to handle if caught early, so early detection is critical. The chest X-ray, being one of the most often used radiography examinations, has been used to detect and visualize abnormalities of human organs for decades. X-ray is also a significant medical diagnosis tool for cardiomegaly. Even for domain experts, distinguishing the many types of diseases from the X-ray is a difficult and time-consuming task. Deep learning models are also most effective when used on huge data sets, yet due to privacy concerns, large datasets are rarely available inside the medical industry. A Deep learning-based customized retrained U-Net model for detecting Cardiomegaly disease is presented in this research. In the training phase, chest X-ray images from the "ChestX-ray8" open source real dataset are used. To reduce computing time, this model performs data preprocessing, picture improvement, image compression, and classification before moving on to the training step. The work used a chest x-ray image dataset to simulate and produced a diagnostic accuracy of 94%, a sensitivity of 96.2 percent, and a specificity of 92.5 percent, which beats prior pre-trained model findings for identifying Cardiomegaly disease.      
### 42.Data-Driven Learning of Safety-Critical Control with Stochastic Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2205.11513.pdf)
>  Control barrier functions are widely used to synthesize safety-critical controls. The existence of Gaussian-type noise may lead to unsafe actions and result in severe consequences. While studies are widely done in safety-critical control for stochastic systems, in many real-world applications, we do not have the knowledge of the stochastic component of the dynamics. In this paper, we study safety-critical control of stochastic systems with an unknown diffusion part and propose a data-driven method to handle these scenarios. More specifically, we propose a data-driven stochastic control barrier function (DDSCBF) framework and use supervised learning to learn the unknown stochastic dynamics via the DDSCBF scheme. Under some reasonable assumptions, we provide guarantees that the DDSCBF scheme can approximate the It derivative of the stochastic control barrier function (SCBF) under partially unknown dynamics using the universal approximation theorem. We also show that we can achieve the same safety guarantee using the DDSCBF scheme as with SCBF in previous work without requiring the knowledge of stochastic dynamics. We use two non-linear stochastic systems to validate our theory in simulations.      
### 43.Psychotic Relapse Prediction in Schizophrenia Patients using A Mobile Sensing-based Supervised Deep Learning Model  [ :arrow_down: ](https://arxiv.org/pdf/2205.12225.pdf)
>  Mobile sensing-based modeling of behavioral changes could predict an oncoming psychotic relapse in schizophrenia patients for timely interventions. Deep learning models could complement existing non-deep learning models for relapse prediction by modeling latent behavioral features relevant to the prediction. However, given the inter-individual behavioral differences, model personalization might be required for a predictive model. In this work, we propose RelapsePredNet, a Long Short-Term Memory (LSTM) neural network-based model for relapse prediction. The model is personalized for a particular patient by training using data from patients most similar to the given patient. Several demographics and baseline mental health scores were considered as personalization metrics to define patient similarity. We investigated the effect of personalization on training dataset characteristics, learned embeddings, and relapse prediction performance. We compared RelapsePredNet with a deep learning-based anomaly detection model for relapse prediction. Further, we investigated if RelapsePredNet could complement ClusterRFModel (a random forest model leveraging clustering and template features proposed in prior work) in a fusion model, by identifying latent behavioral features relevant for relapse prediction. The CrossCheck dataset consisting of continuous mobile sensing data obtained from 63 schizophrenia patients, each monitored for up to a year, was used for our evaluations. The proposed RelapsePredNet outperformed the deep learning-based anomaly detection model for relapse prediction. The F2 score for prediction were 0.21 and 0.52 in the full test set and the Relapse Test Set (consisting of data from patients who have had relapse only), respectively. These corresponded to a 29.4% and 38.8% improvement compared to the existing deep learning-based model for relapse prediction.      
### 44.Merkel Podcast Corpus: A Multimodal Dataset Compiled from 16 Years of Angela Merkel's Weekly Video Podcasts  [ :arrow_down: ](https://arxiv.org/pdf/2205.12194.pdf)
>  We introduce the Merkel Podcast Corpus, an audio-visual-text corpus in German collected from 16 years of (almost) weekly Internet podcasts of former German chancellor Angela Merkel. To the best of our knowledge, this is the first single speaker corpus in the German language consisting of audio, visual and text modalities of comparable size and temporal extent. We describe the methods used with which we have collected and edited the data which involves downloading the videos, transcripts and other metadata, forced alignment, performing active speaker recognition and face detection to finally curate the single speaker dataset consisting of utterances spoken by Angela Merkel. The proposed pipeline is general and can be used to curate other datasets of similar nature, such as talk show contents. Through various statistical analyses and applications of the dataset in talking face generation and TTS, we show the utility of the dataset. We argue that it is a valuable contribution to the research community, in particular, due to its realistic and challenging material at the boundary between prepared and spontaneous speech.      
### 45.Performance analysis of downlink MIMO-NOMA systems over Weibull fading channels  [ :arrow_down: ](https://arxiv.org/pdf/2205.12152.pdf)
>  This work analyzes the performance of a downlink multiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA) multi-user communications system. To reduce hardware complexity and exploit antenna diversity, we consider a transmit antenna selection (TAS) scheme and equal-gain combining (EGC) receivers operating over independent and identically distributed (i.i.d.) Weibull fading channels. Performance metrics such as the outage probability (OP) and the average bit error rate (ABER) are derived in an exact manner. An asymptotic analysis for the OP and for the ABER is also carried out. Moreover, we obtain exact expressions for the probability density function (PDF) and the cumulative distribution function (CDF) of the end-to-end signal-to-noise ratio (SNR). Interestingly, our results indicate that, except for the first user (nearest user), in a high-SNR regime the ABER achieves a performance floor that depends solely on the user's power allocation coefficient and on the type of modulation, and not on the channel statistics or the amount of transmit and receive antennas. To the best of the authors' knowledge, no performance analyses have been reported in the literature for the considered scenario. The validity of all our expressions is confirmed via Monte-Carlo simulations.      
### 46.Full-Reference Calibration-Free Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2205.12129.pdf)
>  One major problem of objective Image Quality Assessment (IQA) methods is the lack of linearity of their quality estimates with respect to scores expressed by human subjects. For this reason, usually IQA metrics undergo a calibration process based on subjective quality examples. However, example-based training makes generalization problematic, hampering result comparison across different applications and operative conditions. In this paper, new Full Reference (FR) techniques, providing estimates linearly correlated with human scores without using calibration are introduced. To reach this objective, these techniques are deeply rooted on principles and theoretical constraints. Restricting the interest on the IQA of the set of natural images, it is first recognized that application of estimation theory and psycho physical principles to images degraded by Gaussian blur leads to a so-called canonical IQA method, whose estimates are not only highly linearly correlated to subjective scores, but are also straightforwardly related to the Viewing Distance (VD). Then, it is shown that mainstream IQA methods can be reconducted to the canonical method applying a preliminary metric conversion based on a unique specimen image. The application of this scheme is then extended to a significant class of degraded images other than Gaussian blur, including noisy and compressed images. The resulting calibration-free FR IQA methods are suited for applications where comparability and interoperability across different imaging systems and on different VDs is a major requirement. A comparison of their statistical performance with respect to some conventional calibration prone methods is finally provided.      
### 47.Differential real-time single-pixel imaging with Fourier domain regularization -- applications to VIS-IR imaging and polarization imaging  [ :arrow_down: ](https://arxiv.org/pdf/2205.12111.pdf)
>  The speed and quality of single-pixel imaging (SPI) are fundamentally limited by image modulation frequency and by the levels of optical noise and compression noise. In an approach to come close to these limits, we introduce a SPI technique, which is inherently differential, and comprises a novel way of measuring the zeroth spatial frequency of images and makes use of varied thresholding of sampling patterns. With the proposed sampling, the entropy of the detection signal is increased in comparison to standard SPI protocols. Image reconstruction is obtained with a single matrix-vector product so the cost of the reconstruction method scales proportionally with the number of measured samples. A differential operator is included in the reconstruction and following the method is based on finding the generalized inversion of the modified measurement matrix with regularization in the Fourier domain. We demonstrate $256 \times 256$ SPI at up to $17~$Hz at visible and near-infrared wavelength ranges using two polarization or spectral channels. A low bit-resolution data acquisition device with alternating-current-coupling can be used in the measurement indicating that the proposed method combines improved noise robustness with a differential removal of the direct current component of the signal.      
### 48.Fully Automatic In-Situ Reconfiguration of RF Photonic Filters in a CMOS-Compatible Silicon Photonic Process  [ :arrow_down: ](https://arxiv.org/pdf/2205.12048.pdf)
>  Automatic reconfiguration of optical filters is the key to novel flexible RF photonic receivers and Software Defined Radios (SDRs). Although silicon photonics (SiP) is a promising technology platform to realize such receivers, process variations and lack of in-situ tuning capability limits the adoption of SiP filters in widely-tunable RF photonic receivers. To address this issue, this work presents a first `in-situ' automatic reconfiguration algorithm and demonstrates a software configurable integrated optical filter that can be reconfigured on-the-fly based on user specifications. The presented reconfiguration scheme avoids the use of expensive and bulky equipment such as Optical Vector Network Analyzer (OVNA), does not use simulation data for reconfiguration, reduces the total number of thermo-optic tuning elements required and eliminates several time consuming configuration steps as in the prior art. This makes this filter ideal in a real world scenario where user specifies the filter center frequency, bandwidth, required rejection &amp; filter type (Butterworth, Chebyshev, etc.) and the filter is automatically configured regardless of process, voltage &amp; temperature (PVT) variations. We fabricated our design in AIM Photonics' Active SiP process and have demonstrated our reconfiguration algorithm for a second-order filter with 3dB bandwidth of 3 GHz, 2.2 dB insertion loss and &gt;30 dB out-of-band rejection using only two reference laser wavelength settings. Since the filter photonic integrated circuit (PIC) is fabricated using a CMOS-compatible SiP foundry, the design is manufacturable with repeatable and scalable performance suited for its integration with electronics to realize complex chip-scale RF photonic systems.      
### 49.PatchNR: Learning from Small Data by Patch Normalizing Flow Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2205.12021.pdf)
>  Learning neural networks using only a small amount of data is an important ongoing research topic with tremendous potential for applications. In this paper, we introduce a regularizer for the variational modeling of inverse problems in imaging based on normalizing flows. Our regularizer, called patchNR, involves a normalizing flow learned on patches of very few images. The subsequent reconstruction method is completely unsupervised and the same regularizer can be used for different forward operators acting on the same class of images. By investigating the distribution of patches versus those of the whole image class, we prove that our variational model is indeed a MAP approach. Our model can be generalized to conditional patchNRs, if additional supervised information is available. Numerical examples for low-dose CT, limited-angle CT and superresolution of material images demonstrate that our method provides high quality results among unsupervised methods, but requires only few data.      
### 50.Concurrent Credit Assignment for Data-efficient Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.12020.pdf)
>  The capability to widely sample the state and action spaces is a key ingredient toward building effective reinforcement learning algorithms. The variational optimization principles exposed in this paper emphasize the importance of an occupancy model to synthesizes the general distribution of the agent's environmental states over which it can act (defining a virtual ``territory''). The occupancy model is the subject of frequent updates as the exploration progresses and that new states are undisclosed during the course of the training. By making a uniform prior assumption, the resulting objective expresses a balance between two concurrent tendencies, namely the widening of the occupancy space and the maximization of the rewards, reminding of the classical exploration/exploitation trade-off. Implemented on an actor-critic off-policy on classic continuous action benchmarks, it is shown to provide significant increase in the sampling efficacy, that is reflected in a reduced training time and higher returns, in both the dense and the sparse rewards cases.      
### 51.GMM-based Codebook Construction and Feedback Encoding in FDD Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.12002.pdf)
>  We propose a precoder codebook construction and feedback encoding scheme which is based on Gaussian mixture models (GMMs). In an offline phase, the base station (BS) first fits a GMM to uplink (UL) training samples. Thereafter, it designs a codebook in an unsupervised manner by exploiting the GMM's clustering capability. We design one codebook entry per GMM component. After offloading the GMM-but not the codebook-to the mobile terminal (MT) in the online phase, the MT utilizes the GMM to determine the best fitting codebook entry. To this end, no channel estimation is necessary at the MT. Instead, the MT's observed signal is used to evaluate how responsible each component of the GMM is for the signal. The feedback consists of the index of the GMM component with the highest responsibility and the BS then employs the corresponding codebook entry. Simulation results show that the proposed codebook design and feedback encoding scheme outperforms conventional Lloyd clustering based codebook design algorithms, especially in configurations with reduced pilot overhead.      
### 52.Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.11998.pdf)
>  The choice of modeling units affects the performance of the acoustic modeling and plays an important role in automatic speech recognition (ASR). In mandarin scenarios, the Chinese characters represent meaning but are not directly related to the pronunciation. Thus only considering the writing of Chinese characters as modeling units is insufficient to capture speech features. In this paper, we present a novel method involves with multi-level modeling units, which integrates multi-level information for mandarin speech recognition. Specifically, the encoder block considers syllables as modeling units, and the decoder block deals with character modeling units. During inference, the input feature sequences are converted into syllable sequences by the encoder block and then converted into Chinese characters by the decoder block. This process is conducted by a unified end-to-end model without introducing additional conversion models. By introducing InterCE auxiliary task, our method achieves competitive results with CER of 4.1%/4.6% and 4.6%/5.2% on the widely used AISHELL-1 benchmark without a language model, using the Conformer and the Transformer backbones respectively.      
### 53.Highly Accurate FMRI ADHD Classification using time distributed multi modal 3D CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2205.11993.pdf)
>  This work proposes an algorithm for fMRI data analysis for the classification of ADHD disorders. There have been several breakthroughs in the analysis of fMRI via 3D convolutional neural networks (CNNs). With these new techniques it is possible to preserve the 3D spatial data of fMRI data. Additionally there have been recent advances in the use of 3D generative adversarial neural networks (GANs) for the generation of normal MRI data. This work utilizes multi modal 3D CNNs with data augmentation from 3D GAN for ADHD prediction from fMRI. By leveraging a 3D-GAN it would be possible to use deepfake data to enhance the accuracy of 3D CNN classification of brain disorders. A comparison will be made between a time distributed single modal 3D CNN model for classification and the modified multi modal model with MRI data as well.      
### 54.Parameter estimation and system identification for continuously-observed quantum systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.11977.pdf)
>  This paper gives an overview of parameter estimation and system identification for quantum input-output systems by continuous observation of the output field. We present recent results on the quantum Fisher information of the output with respect to unknown dynamical parameters. We discuss the structure of continuous-time measurements as solutions of the quantum Zakai equation, and their relationship to parameter estimation methods. Proceeding beyond parameter estimation, the paper also gives an overview of the emerging topic of quantum system identification for black-box modeling of quantum systems by continuous observation of a traveling wave probe, for the case of ergodic quantum input-output systems and linear quantum systems. Empirical methods for such black-box modeling are also discussed.      
### 55.A Wireless-Vision Dataset for Privacy Preserving Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.11962.pdf)
>  Human Activity Recognition (HAR) has recently received remarkable attention in numerous applications such as assisted living and remote monitoring. Existing solutions based on sensors and vision technologies have obtained achievements but still suffering from considerable limitations in the environmental requirement. Wireless signals like WiFi-based sensing have emerged as a new paradigm since it is convenient and not restricted in the environment. In this paper, a new WiFi-based and video-based neural network (WiNN) is proposed to improve the robustness of activity recognition where the synchronized video serves as the supplement for the wireless data. Moreover, a wireless-vision benchmark (WiVi) is collected for 9 class actions recognition in three different visual conditions, including the scenes without occlusion, with partial occlusion, and with full occlusion. Both machine learning methods - support vector machine (SVM) as well as deep learning methods are used for the accuracy verification of the data set. Our results show that WiVi data set satisfies the primary demand and all three branches in the proposed pipeline keep more than $80\%$ of activity recognition accuracy over multiple action segmentation from 1s to 3s. In particular, WiNN is the most robust method in terms of all the actions on three action segmentation compared to the others.      
### 56.GraSens: A Gabor Residual Anti-aliasing Sensing Framework for Action Recognition using WiFi  [ :arrow_down: ](https://arxiv.org/pdf/2205.11945.pdf)
>  WiFi-based human action recognition (HAR) has been regarded as a promising solution in applications such as smart living and remote monitoring due to the pervasive and unobtrusive nature of WiFi signals. However, the efficacy of WiFi signals is prone to be influenced by the change in the ambient environment and varies over different sub-carriers. To remedy this issue, we propose an end-to-end Gabor residual anti-aliasing sensing network (GraSens) to directly recognize the actions using the WiFi signals from the wireless devices in diverse scenarios. In particular, a new Gabor residual block is designed to address the impact of the changing surrounding environment with a focus on learning reliable and robust temporal-frequency representations of WiFi signals. In each block, the Gabor layer is integrated with the anti-aliasing layer in a residual manner to gain the shift-invariant features. Furthermore, fractal temporal and frequency self-attention are proposed in a joint effort to explicitly concentrate on the efficacy of WiFi signals and thus enhance the quality of output features scattered in different subcarriers. Experimental results throughout our wireless-vision action recognition dataset (WVAR) and three public datasets demonstrate that our proposed GraSens scheme outperforms state-of-the-art methods with respect to recognition accuracy.      
### 57.Flying-Qubit Control via a Three-level Atom with Tunable Waveguide Couplings  [ :arrow_down: ](https://arxiv.org/pdf/2205.11900.pdf)
>  The control of flying qubits is at the core of quantum networks. As often carried by single-photon fields, the flying-qubit control involves not only their logical states but also their shapes. In this paper, we explore a variety of flying-qubit control problems using a three-level atom with time-varying tunable couplings to two input-output channels. It is shown that one can tune the couplings of a $\Lambda$-type atom to distribute a single photon into the two channels with arbitrary shapes, or use a $V$-type atom to catch an arbitrary-shape distributed single photon. The $\Lambda$-type atom can also be designed to transfer a flying qubit from one channel to the other, with both the central frequency and the photon shape being converted. With a $\Xi$-type atom, one can use the tunable coupling to shape a pair of correlated photons via cascaded emission. In all cases, analytical formulas are derived for the coupling functions to fulfil these control tasks, and their physical limitations are discussed as well. These results provide useful control protocols for high-fidelity quantum information transmission over complex quantum networks.      
### 58.Deep Reinforcement Learning for Radio Resource Allocation in NOMA-based Remote State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2205.11861.pdf)
>  Remote state estimation, where many sensors send their measurements of distributed dynamic plants to a remote estimator over shared wireless resources, is essential for mission-critical applications of Industry 4.0. Most of the existing works on remote state estimation assumed orthogonal multiple access and the proposed dynamic radio resource allocation algorithms can only work for very small-scale settings. In this work, we consider a remote estimation system with non-orthogonal multiple access. We formulate a novel dynamic resource allocation problem for achieving the minimum overall long-term average estimation mean-square error. Both the estimation quality state and the channel quality state are taken into account for decision making at each time. The problem has a large hybrid discrete and continuous action space for joint channel assignment and power allocation. We propose a novel action-space compression method and develop an advanced deep reinforcement learning algorithm to solve the problem. Numerical results show that our algorithm solves the resource allocation problem effectively, presents much better scalability than the literature, and provides significant performance gain compared to some benchmarks.      
### 59.Beam Aware Stochastic Multihop Routing for Flying Ad-hoc Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.11843.pdf)
>  Routing is a crucial component in the design of Flying Ad-Hoc Networks (FANETs). State of the art routing solutions exploit the position of Unmanned Aerial Vehicles (UAVs) and their mobility information to determine the existence of links between them, but this information is often unreliable, as the topology of FANETs can change quickly and unpredictably. In order to improve the tracking performance, the uncertainty introduced by imperfect measurements and tracking algorithms needs to be accounted for in the routing. Another important element to consider is beamforming, which can reduce interference, but requires accurate channel and position information to work. In this work, we present the Beam Aware Stochastic Multihop Routing for FANETs (BA-SMURF), a Software-Defined Networking (SDN) routing scheme that takes into account the positioning uncertainty and beamforming design to find the most reliable routes in a FANET. Our simulation results show that joint consideration of the beamforming and routing can provide a 5% throughput improvement with respect to the state of the art.      
### 60.SUSing: SU-net for Singing Voice Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2205.11841.pdf)
>  Singing voice synthesis is a generative task that involves multi-dimensional control of the singing model, including lyrics, pitch, and duration, and includes the timbre of the singer and singing skills such as vibrato. In this paper, we proposed SU-net for singing voice synthesis named SUSing. Synthesizing singing voice is treated as a translation task between lyrics and music score and spectrum. The lyrics and music score information is encoded into a two-dimensional feature representation through the convolution layer. The two-dimensional feature and its frequency spectrum are mapped to the target spectrum in an autoregressive manner through a SU-net network. Within the SU-net the stripe pooling method is used to replace the alternate global pooling method to learn the vertical frequency relationship in the spectrum and the changes of frequency in the time domain. The experimental results on the public dataset Kiritan show that the proposed method can synthesize more natural singing voices.      
### 61.Model-Based and Graph-Based Priors for Group Testing  [ :arrow_down: ](https://arxiv.org/pdf/2205.11838.pdf)
>  The goal of the group testing problem is to identify a set of defective items within a larger set of items, using suitably-designed tests whose outcomes indicate whether any defective item is present. In this paper, we study how the number of tests can be significantly decreased by leveraging the structural dependencies between the items, i.e., by incorporating prior information. To do so, we pursue two different perspectives: (i) As a generalization of the uniform combinatorial prior, we consider the case that the defective set is uniform over a \emph{subset} of all possible sets of a given size, and study how this impacts the information-theoretic limits on the number of tests for approximate recovery; (ii) As a generalization of the i.i.d.~prior, we introduce a new class of priors based on the Ising model, where the associated graph represents interactions between items. We show that this naturally leads to an Integer Quadratic Program decoder, which can be converted to an Integer Linear Program and/or relaxed to a non-integer variant for improved computational complexity, while maintaining strong empirical recovery performance.      
### 62.Advanced Manufacturing Configuration by Sample-efficient Batch Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2205.11827.pdf)
>  We propose a framework for the configuration and operation of expensive-to-evaluate advanced manufacturing methods, based on Bayesian optimization. The framework unifies a tailored acquisition function, a parallel acquisition procedure, and the integration of process information providing context to the optimization procedure. The novel acquisition function is demonstrated and analyzed on benchmark illustrative problems. We apply the optimization approach to atmospheric plasma spraying in simulation and experiments. Our results demonstrate that the proposed framework can efficiently find input parameters that produce the desired outcome and minimize the process cost.      
### 63.TDASS: Target Domain Adaptation Speech Synthesis Framework for Multi-speaker Low-Resource TTS  [ :arrow_down: ](https://arxiv.org/pdf/2205.11824.pdf)
>  Recently, synthesizing personalized speech by text-to-speech (TTS) application is highly demanded. But the previous TTS models require a mass of target speaker speeches for training. It is a high-cost task, and hard to record lots of utterances from the target speaker. Data augmentation of the speeches is a solution but leads to the low-quality synthesis speech problem. Some multi-speaker TTS models are proposed to address the issue. But the quantity of utterances of each speaker imbalance leads to the voice similarity problem. We propose the Target Domain Adaptation Speech Synthesis Network (TDASS) to address these issues. Based on the backbone of the Tacotron2 model, which is the high-quality TTS model, TDASS introduces a self-interested classifier for reducing the non-target influence. Besides, a special gradient reversal layer with different operations for target and non-target is added to the classifier. We evaluate the model on a Chinese speech corpus, the experiments show the proposed method outperforms the baseline method in terms of voice quality and voice similarity.      
### 64.Thunder: Thumbnail based Fast Lightweight Image Denoising Network  [ :arrow_down: ](https://arxiv.org/pdf/2205.11823.pdf)
>  To achieve promising results on removing noise from real-world images, most of existing denoising networks are formulated with complex network structure, making them impractical for deployment. Some attempts focused on reducing the number of filters and feature channels but suffered from large performance loss, and a more practical and lightweight denoising network with fast inference speed is of high demand. <br>To this end, a \textbf{Thu}mb\textbf{n}ail based \textbf{D}\textbf{e}noising Netwo\textbf{r}k dubbed Thunder, is proposed and implemented as a lightweight structure for fast restoration without comprising the denoising capabilities. Specifically, the Thunder model contains two newly-established modules: <br>(1) a wavelet-based Thumbnail Subspace Encoder (TSE) which can leverage sub-bands correlation to provide an approximate thumbnail based on the low-frequent feature; (2) a Subspace Projection based Refine Module (SPR) which can restore the details for thumbnail progressively based on the subspace projection approach. <br>Extensive experiments have been carried out on two real-world denoising benchmarks, demonstrating that the proposed Thunder outperforms the existing lightweight models and achieves competitive performance on PSNR and SSIM when compared with the complex designs.      
### 65.MetaSID: Singer Identification with Domain Adaptation for Metaverse  [ :arrow_down: ](https://arxiv.org/pdf/2205.11821.pdf)
>  Metaverse has stretched the real world into unlimited space. There will be more live concerts in Metaverse. The task of singer identification is to identify the song belongs to which singer. However, there has been a tough problem in singer identification, which is the different live effects. The studio version is different from the live version, the data distribution of the training set and the test set are different, and the performance of the classifier decreases. This paper proposes the use of the domain adaptation method to solve the live effect in singer identification. Three methods of domain adaptation combined with Convolutional Recurrent Neural Network (CRNN) are designed, which are Maximum Mean Discrepancy (MMD), gradient reversal (Revgrad), and Contrastive Adaptation Network (CAN). MMD is a distance-based method, which adds domain loss. Revgrad is based on the idea that learned features can represent different domain samples. CAN is based on class adaptation, it takes into account the correspondence between the categories of the source domain and target domain. Experimental results on the public dataset of Artist20 show that CRNN-MMD leads to an improvement over the baseline CRNN by 0.14. The CRNN-RevGrad outperforms the baseline by 0.21. The CRNN-CAN achieved state of the art with the F1 measure value of 0.83 on album split.      
### 66.Singer Identification for Metaverse with Timbral and Middle-Level Perceptual Features  [ :arrow_down: ](https://arxiv.org/pdf/2205.11817.pdf)
>  Metaverse is an interactive world that combines reality and virtuality, where participants can be virtual avatars. Anyone can hold a concert in a virtual concert hall, and users can quickly identify the real singer behind the virtual idol through the singer identification. Most singer identification methods are processed using the frame-level features. However, expect the singer's timbre, the music frame includes music information, such as melodiousness, rhythm, and tonal. It means the music information is noise for using frame-level features to identify the singers. In this paper, instead of only the frame-level features, we propose to use another two features that address this problem. Middle-level feature, which represents the music's melodiousness, rhythmic stability, and tonal stability, and is able to capture the perceptual features of music. The timbre feature, which is used in speaker identification, represents the singers' voice features. Furthermore, we propose a convolutional recurrent neural network (CRNN) to combine three features for singer identification. The model firstly fuses the frame-level feature and timbre feature and then combines middle-level features to the mix features. In experiments, the proposed method achieves comparable performance on an average F1 score of 0.81 on the benchmark dataset of Artist20, which significantly improves related works.      
### 67.Increasing Cellular Network Energy Efficiency for Railway Corridors  [ :arrow_down: ](https://arxiv.org/pdf/2205.11808.pdf)
>  Modern trains act as Faraday cages making it challenging to provide high cellular data capacities to passengers. A solution is the deployment of linear cells along railway tracks, forming a cellular corridor. To provide a sufficiently high data capacity, many cell sites need to be installed at regular distances. However, such cellular corridors with high power sites in short distance intervals are not sustainable due to the infrastructure power consumption. To render railway connectivity more sustainable, we propose to deploy fewer high-power radio units with intermediate low-power support repeater nodes. We show that these repeaters consume only 5 % of the energy of a regular cell site and help to maintain the same data capacity in the trains. In a further step, we introduce a sleep mode for the repeater nodes that enables autonomous solar powering and even eases installation because no cables to the relays are needed.      
### 68.Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.11790.pdf)
>  Offline Reinforcement learning (RL) has shown potent in many safe-critical tasks in robotics where exploration is risky and expensive. However, it still struggles to acquire skills in temporally extended tasks. In this paper, we study the problem of offline RL for temporally extended tasks. We propose a hierarchical planning framework, consisting of a low-level goal-conditioned RL policy and a high-level goal planner. The low-level policy is trained via offline RL. We improve the offline training to deal with out-of-distribution goals by a perturbed goal sampling process. The high-level planner selects intermediate sub-goals by taking advantages of model-based planning methods. It plans over future sub-goal sequences based on the learned value function of the low-level policy. We adopt a Conditional Variational Autoencoder to sample meaningful high-dimensional sub-goal candidates and to solve the high-level long-term strategy optimization problem. We evaluate our proposed method in long-horizon driving and robot navigation tasks. Experiments show that our method outperforms baselines with different hierarchical designs and other regular planners without hierarchy in these complex tasks.      
### 69.Constrained Error Pattern Generation for GRAND  [ :arrow_down: ](https://arxiv.org/pdf/2205.11773.pdf)
>  Maximum-likelihood (ML) decoding can be used to obtain the optimal performance of error correction codes. However, the size of the search space and consequently the decoding complexity grows exponentially, making it impractical to be employed for long codes. In this paper, we propose an approach to constrain the search space for error patterns under a recently introduced near ML decoding scheme called guessing random additive noise decoding (GRAND). In this approach, the syndrome-based constraints which divide the search space into disjoint sets are progressively evaluated. By employing $p$ constraints extracted from the parity check matrix, the average number of queries reduces by a factor of $2^p$ while the error correction performance remains intact.      
### 70.Video Capsule Endoscopy and Ingestible Electronics: Emerging Trends in Sensors, Circuits, Materials, Telemetry, Optics, and Rapid Reading Software  [ :arrow_down: ](https://arxiv.org/pdf/2205.11751.pdf)
>  Real-time monitoring of the gastrointestinal tract in a safe and comfortable manner is valuable for the diagnosis and therapy of many diseases. Within this realm, our review captures the trends in ingestible capsule systems with a focus on hardware and software technologies used for capsule endoscopy and remote patient monitoring. We introduce the structure and functions of the gastrointestinal tract, and the FDA guidelines for ingestible wireless telemetric medical devices. We survey the advanced features incorporated in ingestible capsule systems, such as microrobotics, closed-loop feedback, physiological sensing, nerve stimulation, sampling and delivery, panoramic imaging with adaptive frame rates, and rapid reading software. Examples of experimental and commercialized capsule systems are presented with descriptions of their sensors, devices, and circuits for gastrointestinal health monitoring. We also show the recent research in biocompatible materials and batteries, edible electronics, and alternative energy sources for ingestible capsule systems. The results from clinical studies are discussed for the assessment of key performance indicators related to the safety and effectiveness of ingestible capsule procedures. Lastly, the present challenges and outlook are summarized with respect to the risks to health, clinical testing and approval process, and technology adoption by patients and clinicians.      
### 71.Deep Learning-based automated classification of Chinese Speech Sound Disorders  [ :arrow_down: ](https://arxiv.org/pdf/2205.11748.pdf)
>  This article describes a system for analyzing acoustic data in order to assist in the diagnosis and classification of children's speech disorders using a computer. The analysis concentrated on identifying and categorizing four distinct types of Chinese misconstructions. The study collected and generated a speech corpus containing 2540 Stopping, Velar, Consonant-vowel, and Affricate samples from 90 children aged 3-6 years with normal or pathological articulatory features. Each recording was accompanied by a detailed annotation from the field of speech therapy. Classification of the speech samples was accomplished using three well-established neural network models for image classification. The feature maps are created using three sets of MFCC parameters extracted from speech sounds and aggregated into a three-dimensional data structure as model input. We employ six techniques for data augmentation in order to augment the available dataset while avoiding over-simulation. The experiments examine the usability of four different categories of Chinese phrases and characters. Experiments with different data subsets demonstrate the system's ability to accurately detect the analyzed pronunciation disorders.      
### 72.Adaptive Few-Shot Learning Algorithm for Rare Sound Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2205.11738.pdf)
>  Sound event detection is to infer the event by understanding the surrounding environmental sounds. Due to the scarcity of rare sound events, it becomes challenging for the well-trained detectors which have learned too much prior knowledge. Meanwhile, few-shot learning methods promise a good generalization ability when facing a new limited-data task. Recent approaches have achieved promising results in this field. However, these approaches treat each support example independently, ignoring the information of other examples from the whole task. Because of this, most of previous methods are constrained to generate a same feature embedding for all test-time tasks, which is not adaptive to each inputted data. In this work, we propose a novel task-adaptive module which is easy to plant into any metric-based few-shot learning frameworks. The module could identify the task-relevant feature dimension. Incorporating our module improves the performance considerably on two datasets over baseline methods, especially for the transductive propagation network. Such as +6.8% for 5-way 1-shot accuracy on ESC-50, and +5.9% on noiseESC-50. We investigate our approach in the domain-mismatch setting and also achieve better results than previous methods.      
### 73.Low-Complexity Block Coordinate Descend Based Multiuser Detection for Uplink Grant-Free NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2205.11607.pdf)
>  Grant-free non-orthogonal multiple access (NOMA) scheme is considered as a promising candidate for the enabling of massive connectivity and reduced signalling overhead for Internet of Things (IoT) applications in massive machine-type communication (mMTC) networks. Exploiting the inherent nature of sporadic transmissions in the grant-free NOMA systems, compressed sensing based multiuser detection (CS-MUD) has been deemed as a powerful solution to user activity detection (UAD) and data detection (DD). In this paper, block coordinate descend (BCD) method is employed in CS-MUD to reduce the computational complexity. We propose two modified BCD based algorithms, called enhanced BCD (EBCD) and complexity reduction enhanced BCD (CR-EBCD), respectively. To be specific, by incorporating a novel candidate set pruning mechanism into the original BCD framework, our proposed EBCD algorithm achieves remarkable CS-MUD performance improvement. In addition, the proposed CR-EBCD algorithm further ameliorates the proposed EBCD by eliminating the redundant matrix multiplications during the iteration process. As a consequence, compared with the proposed EBCD algorithm, our proposed CR-EBCD algorithm enjoys two orders of magnitude complexity saving without any CS-MUD performance degradation, rendering it a viable solution for future mMTC scenarios. Extensive simulation results demonstrate the bound-approaching performance as well as ultra-low computational complexity.      
