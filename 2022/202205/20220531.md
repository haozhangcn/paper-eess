# ArXiv eess --Tue, 31 May 2022
### 1.GAN-based Medical Image Small Region Forgery Detection via a Two-Stage Cascade Framework  [ :arrow_down: ](https://arxiv.org/pdf/2205.15170.pdf)
>  Using generative adversarial network (GAN)\cite{RN90} for data enhancement of medical images is significantly helpful for many computer-aided diagnosis (CAD) tasks. A new attack called CT-GAN has emerged. It can inject or remove lung cancer lesions to CT scans. Because the tampering region may even account for less than 1\% of the original image, even state-of-the-art methods are challenging to detect the traces of such tampering. <br>This paper proposes a cascade framework to detect GAN-based medical image small region forgery like CT-GAN. In the local detection stage, we train the detector network with small sub-images so that interference information in authentic regions will not affect the detector. We use depthwise separable convolution and residual to prevent the detector from over-fitting and enhance the ability to find forged regions through the attention mechanism. The detection results of all sub-images in the same image will be combined into a heatmap. In the global classification stage, using gray level co-occurrence matrix (GLCM) can better extract features of the heatmap. Because the shape and size of the tampered area are uncertain, we train PCA and SVM methods for classification. Our method can classify whether a CT image has been tampered and locate the tampered position. Sufficient experiments show that our method can achieve excellent performance.      
### 2.FiltPIM: In-Memory Filter for DNA Sequencing  [ :arrow_down: ](https://arxiv.org/pdf/2205.15140.pdf)
>  Aligning the entire genome of an organism is a compute-intensive task. Pre-alignment filters substantially reduce computation complexity by filtering potential alignment locations. The base-count filter successfully removes over 68% of the potential locations through a histogram-based heuristic. This paper presents FiltPIM, an efficient design of the basecount filter that is based on memristive processing-in-memory. The in-memory design reduces CPU-to-memory data transfer and utilizes both intra-crossbar and inter-crossbar memristive stateful-logic parallelism. The reduction in data transfer and the efficient stateful-logic computation together improve filtering time by 100x compared to a CPU implementation of the filter.      
### 3.A Novel Control-Oriented Cell Transition Model Including Service Stations on Highways  [ :arrow_down: ](https://arxiv.org/pdf/2205.15115.pdf)
>  In this paper, we propose a novel model that describes how the traffic evolution on a highway stretch is affected by the presence of a service station. The presented model enhances the classical CTM dynamics by adding the dynamics associated with the service stations, where the vehicles may stop before merging back into the mainstream. We name it CTMs. We discuss its flexibility in describing different complex scenarios where multiple stations are characterized by different drivers' average stopping times corresponding to different services. The model has been developed to help design control strategies aimed at decreasing traffic congestion. Thus, we discuss how classical control schemes can interact with the proposed \gls{CTMs}. Finally, we validate the proposed model through numerical simulations and assess the effects of service stations on traffic evolution, which appear to be beneficial, especially for relatively short congested periods.      
### 4.Predictive Rate Selection for Ultra-Reliable Communication using Statistical Radio Maps  [ :arrow_down: ](https://arxiv.org/pdf/2205.15030.pdf)
>  This paper proposes exploiting the spatial correlation of wireless channel statistics beyond the conventional received signal strength maps by constructing statistical radio maps to predict any relevant channel statistics to assist communications. Specifically, from stored channel samples acquired by previous users in the network, we use Gaussian processes (GPs) to estimate quantiles of the channel distribution at a new position using a non-parametric model. This prior information is then used to select the transmission rate for some target level of reliability. The approach is tested with synthetic data, simulated from urban micro-cell environments, highlighting how the proposed solution helps to reduce the training estimation phase, which is especially attractive for the tight latency constraints inherent to ultra-reliable low-latency (URLLC) deployments.      
### 5.Carleman Lifting for Nonlinear System Identification with Guaranteed Error Bounds  [ :arrow_down: ](https://arxiv.org/pdf/2205.15009.pdf)
>  This paper concerns identification of uncontrolled or closed loop nonlinear systems using a set of trajectories that are generated by the system in a domain of attraction. The objective is to ensure that the trajectories of the identified systems are close to the trajectories of the real system, as quantified by an error bound that is \textit{prescribed a priori}. A majority of existing methods for nonlinear system identification rely on techniques such as neural networks, autoregressive moving averages, and spectral decomposition that do not provide systematic approaches to meet pre-defined error bounds. The developed method is based on Carleman linearization-based lifting of the nonlinear system to an infinite dimensional linear system. The linear system is then truncated to a suitable order, computed based on the prescribed error bound, and parameters of the truncated linear system are estimated from data. The effectiveness of the technique is demonstrated by identifying an approximation of the Van der Pol oscillator from data within a prescribed error bound.      
### 6.Abnormal Signal Recognition with Time-Frequency Spectrogram: A Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.15001.pdf)
>  With the increasingly complex and changeable electromagnetic environment, wireless communication systems are facing jamming and abnormal signal injection, which significantly affects the normal operation of a communication system. In particular, the abnormal signals may emulate the normal signals, which makes it very challenging for abnormal signal recognition. In this paper, we propose a new abnormal signal recognition scheme, which combines time-frequency analysis with deep learning to effectively identify synthetic abnormal communication signals. Firstly, we emulate synthetic abnormal communication signals including seven jamming patterns. Then, we model an abnormal communication signals recognition system based on the communication protocol between the transmitter and the receiver. To improve the performance, we convert the original signal into the time-frequency spectrogram to develop an image classification algorithm. Simulation results demonstrate that the proposed method can effectively recognize the abnormal signals under various parameter configurations, even under low signal-to-noise ratio (SNR) and low jamming-to-signal ratio (JSR) conditions.      
### 7.OutFin, a multi-device and multi-modal dataset for outdoor localization based on the fingerprinting approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.14921.pdf)
>  In recent years, fingerprint-based positioning has gained researchers attention since it is a promising alternative to the Global Navigation Satellite System and cellular network-based localization in urban areas. Despite this, the lack of publicly available datasets that researchers can use to develop, evaluate, and compare fingerprint-based positioning solutions constitutes a high entry barrier for studies. As an effort to overcome this barrier and foster new research efforts, this paper presents OutFin, a novel dataset of outdoor location fingerprints that were collected using two different smartphones. OutFin is comprised of diverse data types such as WiFi, Bluetooth, and cellular signal strengths, in addition to measurements from various sensors including the magnetometer, accelerometer, gyroscope, barometer, and ambient light sensor. The collection area spanned four dispersed sites with a total of 122 reference points. Each site is different in terms of its visibility to the Global Navigation Satellite System and reference points number, arrangement, and spacing. Before OutFin was made available to the public, several experiments were conducted to validate its technical quality.      
### 8.Convergence Analysis of Consensus-ADMM for General QCQP  [ :arrow_down: ](https://arxiv.org/pdf/2205.14884.pdf)
>  In this letter, we analyze the convergence properties of the consensus-alternating direction method of multipliers (ADMM) for solving general quadratically constrained quadratic programs. We prove that the consensus-ADMM converges under a mild condition, namely, the augmented Lagrangian parameter is chosen to be sufficiently large. It is shown that the augmented Lagrangian function is monotonically non-increasing under such a condition, and is bounded from below. Furthermore, we additionally prove the convergence of the point sequence generated by the consensus-ADMM. Numerical simulations confirm our theoretical analyses.      
### 9.Effect of Prefix/Suffix Configurations on OTFS Systems with Rectangular Waveforms  [ :arrow_down: ](https://arxiv.org/pdf/2205.14872.pdf)
>  Recently, orthogonal time-frequency-space (OTFS) modulation is used as a promising candidate waveform for high mobility communication scenarios. In practical transmission, OTFS with rectangular pulse shaping is implemented using different prefix/suffix configurations including reduced-cyclic prefix (RCP), full-CP (FCP), full-zero suffix (FZS), and reduced-zero padded (RZP). However, for each prefix/suffix type, different effective channel are seen at the receiver side resulting in dissimilar performance of the various OTFS configurations given a specific communication scenario. To fulfill this gap, in this paper, we study and model the effective channel in OTFS systems using various prefix/suffix configurations. Then, from the input-output relation analysis of the received signal, we show that the OTFS has a simple sparse structure for all prefix/suffix types, where the only difference is the phase term introduced when extending quasi-periodically in the delay-Doppler grid. We provide a comprehensive comparison between all OTFS types in terms of channel estimation/equalization complexity, symbol detection performance, power and spectral efficiencies, which helps in deciding the optimal prefix/suffix configuration for a specific scenario. Finally, we propose a novel OTFS structure namely reduced-FCP (RFCP) where the information of the CP block is decodable.      
### 10.Underwater Acoustic Communication Channel Modeling using Reservoir Computing  [ :arrow_down: ](https://arxiv.org/pdf/2205.14856.pdf)
>  Underwater acoustic (UWA) communications have been widely used but greatly impaired due to the complicated nature of the underwater environment. In order to improve UWA communications, modeling and understanding the UWA channel is indispensable. However, there exist many challenges due to the high uncertainties of the underwater environment and the lack of real-world measurement data. In this work, the capability of reservoir computing and deep learning has been explored for modeling the UWA communication channel accurately using real underwater data collected from a water tank with disturbance and from Lake Tahoe. We leverage the capability of reservoir computing for modeling dynamical systems and provided a data-driven approach to modeling the UWA channel using Echo State Network (ESN). In addition, the potential application of transfer learning to reservoir computing has been examined. Experimental results show that ESN is able to model chaotic UWA channels with better performance compared to popular deep learning models in terms of mean absolute percentage error (MAPE), specifically, ESN has outperformed deep neural network by 2% and as much as 40% in benign and chaotic UWA respectively.      
### 11.BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2205.14807.pdf)
>  Binaural audio plays a significant role in constructing immersive augmented and virtual realities. As it is expensive to record binaural audio from the real world, synthesizing them from mono audio has attracted increasing attention. This synthesis process involves not only the basic physical warping of the mono audio, but also room reverberations and head/ear related filtrations, which, however, are difficult to accurately simulate in traditional digital signal processing. In this paper, we formulate the synthesis process from a different perspective by decomposing the binaural audio into a common part that shared by the left and right channels as well as a specific part that differs in each channel. Accordingly, we propose BinauralGrad, a novel two-stage framework equipped with diffusion models to synthesize them respectively. Specifically, in the first stage, the common information of the binaural audio is generated with a single-channel diffusion model conditioned on the mono audio, based on which the binaural audio is generated by a two-channel diffusion model in the second stage. Combining this novel perspective of two-stage synthesis with advanced generative models (i.e., the diffusion models),the proposed BinauralGrad is able to generate accurate and high-fidelity binaural audio samples. Experiment results show that on a benchmark dataset, BinauralGrad outperforms the existing baselines by a large margin in terms of both object and subject evaluation metrics (Wave L2: 0.128 vs. 0.157, MOS: 3.80 vs. 3.61). The generated audio samples are available online.      
### 12.To catch a chorus, verse, intro, or anything else: Analyzing a song with structural functions  [ :arrow_down: ](https://arxiv.org/pdf/2205.14700.pdf)
>  Conventional music structure analysis algorithms aim to divide a song into segments and to group them with abstract labels (e.g., 'A', 'B', and 'C'). However, explicitly identifying the function of each segment (e.g., 'verse' or 'chorus') is rarely attempted, but has many applications. We introduce a multi-task deep learning framework to model these structural semantic labels directly from audio by estimating "verseness," "chorusness," and so forth, as a function of time. We propose a 7-class taxonomy (i.e., intro, verse, chorus, bridge, outro, instrumental, and silence) and provide rules to consolidate annotations from four disparate datasets. We also propose to use a spectral-temporal Transformer-based model, called SpecTNT, which can be trained with an additional connectionist temporal localization (CTL) loss. In cross-dataset evaluations using four public datasets, we demonstrate the effectiveness of the SpecTNT model and CTL loss, and obtain strong results overall: the proposed system outperforms state-of-the-art chorus-detection and boundary-detection methods at detecting choruses and boundaries, respectively.      
### 13.Joint Constrained Bayesian Optimization of Planning, Guidance, Control, and State Estimation of an Autonomous Underwater Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2205.14669.pdf)
>  The performance of a guidance, navigation and control (GNC) system of an autonomous underwater vehicle (AUV) heavily depends on the correct tuning of its parameters. Our objective is to automatically tune these parameters with respect to arbitrary high-level control objectives within different operational scenarios. In contrast to literature, an overall tuning is performed for the entire GNC system, which is new in the context of autonomous underwater vehicles. The main challenges in solving the optimization problem are computationally expensive objective function evaluations, crashing simulations due to infeasible parametrization and the numerous tunable parameters (in our case 13). These challenges are met by using constrained Bayesian optimization with crash constraints. The method is demonstrated in simulation on a GNC system of an underactuated miniature AUV designed within the TRIPLE-nanoAUV initiative for exploration of sub-glacial lakes. We quantify the substantial reduction in energy consumption achieved by tuning the overall system. Furthermore, different parametrizations are automatically generated for different power consumption functions, robustness, and accuracy requirements. E.g. energy consumption can be reduced by ~28%, if the maximum allowed deviation from the planned path is increased by ~65%. This shows the versatile practical applicability of the optimization-based tuning approach.      
### 14.Safeguarding NOMA Networks via Reconfigurable Dual-Functional Surface under Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2205.14595.pdf)
>  This paper investigates the use of the reconfigurable dual-functional surface to guarantee the full-space secure transmission in non-orthogonal multiple access (NOMA) networks. In the presence of eavesdroppers, the downlink communication from the base station to the legitimate users is safeguarded by the simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS), where three practical operating protocols, namely energy splitting (ES), mode selection (MS), and time splitting (TS), are studied. The joint optimization of power allocation, active and passive beamforming is investigated to maximize the secrecy energy efficiency (SEE), taking into account the imperfect channel state information (CSI) of all channels. For ES, by approximating the semi-infinite constraints with the S-procedure and general sign-definiteness, the problem is solved by an alternating optimization framework. Besides, the proposed algorithm is extended to the MS protocol by solving a mixed-integer non-convex problem. While for TS, a two-layer iterative method is proposed. Simulation results show that: 1) The proposed STAR-RIS assisted NOMA networks are able to provide up to 33.6\% higher SEE than conventional RIS counterparts; 2) TS and ES protocols are generally preferable for low and high power domain, respectively; 3) The accuracy of CSI estimation and the bit resolution power consumption are crucial to reap the SEE benefits offered by STAR-RIS.      
### 15.Mean square stability conditions for platoons with lossy inter-vehicle communication channels  [ :arrow_down: ](https://arxiv.org/pdf/2205.14582.pdf)
>  This paper studies the mean-square stability of heterogeneous LTI vehicular platoons with inter-vehicle communication channels affected by random data loss. We consider a discrete-time platoon system with predecessor following topology and constant time-headway spacing policy. Lossy channels are modeled by Bernoulli processes allowed to be correlated in space. We make use of a class of compensation strategies to reduce the effect of data loss. Necessary and sufficient conditions are derived to guarantee the convergence of the mean and variance of the tracking errors, which depend not only on the controller design but also on the compensation strategy and the probabilities of successful transmission. Through numerical simulations, we illustrate the theoretical results, describing different platoon behaviors. We also provide insights on the mean-square stability as a necessary condition for string stability in this stochastic setting.      
### 16.Input-to-State Safety with Input Delay in Longitudinal Vehicle Control  [ :arrow_down: ](https://arxiv.org/pdf/2205.14567.pdf)
>  Safe longitudinal control is discussed for a connected automated truck traveling behind a preceding connected vehicle. A controller is proposed based on control barrier function theory and predictor feedback for provably safe, collision-free behavior by taking into account the significant response time of the truck as input delay and the uncertainty of its dynamical model as input disturbance. The benefits of the proposed controller compared to control designs that neglect the delay or treat the delay as disturbance are shown by numerical simulations.      
### 17.QoE-Aware Resource Allocation for Semantic Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.14530.pdf)
>  With the aim of accomplishing intelligence tasks, semantic communications transmit task-related information only, yielding significant performance gains over conventional communications. To guarantee user requirements for different types of tasks, we perform the semantic-aware resource allocation in a multi-cell multi-task network in this paper. Specifically, an approximate measure of semantic entropy is first developed to quantify the semantic information for different tasks, based on which a novel quality-of-experience (QoE) model is proposed. We formulate the QoE-aware semantic resource allocation in terms of the number of transmitted semantic symbols, channel assignment, and power allocation. To solve this problem, we first decouple it into two independent subproblems. The first one is to optimize the number of transmitted semantic symbols with given channel assignment and power allocation, which is solved by the exhaustive searching method. The second one is the channel assignment and power allocation subproblem, which is modeled as a many-to-one matching game and solved by the proposed low-complexity matching algorithm. Simulation results demonstrate the effectiveness and superiority of the proposed method on the overall QoE.      
### 18.Risk of Stochastic Systems for Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2205.14523.pdf)
>  The wide availability of data coupled with the computational advances in artificial intelligence and machine learning promise to enable many future technologies such as autonomous driving. While there has been a variety of successful demonstrations of these technologies, critical system failures have repeatedly been reported. Even if rare, such system failures pose a serious barrier to adoption without a rigorous risk assessment. This paper presents a framework for the systematic and rigorous risk verification of systems. We consider a wide range of system specifications formulated in signal temporal logic (STL) and model the system as a stochastic process, permitting discrete-time and continuous-time stochastic processes. We then define the STL robustness risk as the risk of lacking robustness against failure. This definition is motivated as system failures are often caused by missing robustness to modeling errors, system disturbances, and distribution shifts in the underlying data generating process. Within the definition, we permit general classes of risk measures and focus on tail risk measures such as the value-at-risk and the conditional value-at-risk. While the STL robustness risk is in general hard to compute, we propose the approximate STL robustness risk as a more tractable notion that upper bounds the STL robustness risk. We show how the approximate STL robustness risk can accurately be estimated from system trajectory data. For discrete-time stochastic processes, we show under which conditions the approximate STL robustness risk can even be computed exactly. We illustrate our verification algorithm in the autonomous driving simulator CARLA and show how a least risky controller can be selected among four neural network lane keeping controllers for five meaningful system specifications.      
### 19.Q-LIC: Quantizing Learned Image Compression with Channel Splitting  [ :arrow_down: ](https://arxiv.org/pdf/2205.14510.pdf)
>  Learned image compression (LIC) has reached a comparable coding gain with traditional hand-crafted methods such as VVC intra. However, the large network complexity prohibits the usage of LIC on resource-limited embedded systems. Network quantization is an efficient way to reduce the network burden. This paper presents a quantized LIC (QLIC) by channel splitting. First, we explore that the influence of quantization error to the reconstruction error is different for various channels. Second, we split the channels whose quantization has larger influence to the reconstruction error. After the splitting, the dynamic range of channels is reduced so that the quantization error can be reduced. Finally, we prune several channels to keep the number of overall channels as origin. By using the proposal, in the case of 8-bit quantization for weight and activation of both main and hyper path, we can reduce the BD-rate by 0.61%-4.74% compared with the previous QLIC. Besides, we can reach better coding gain compared with the state-of-the-art network quantization method when quantizing MS-SSIM models. Moreover, our proposal can be combined with other network quantization methods to further improve the coding gain. The moderate coding loss caused by the quantization validates the feasibility of the hardware implementation for QLIC in the future.      
### 20.PO-ELIC: Perception-Oriented Efficient Learned Image Coding  [ :arrow_down: ](https://arxiv.org/pdf/2205.14501.pdf)
>  In the past years, learned image compression (LIC) has achieved remarkable performance. The recent LIC methods outperform VVC in both PSNR and MS-SSIM. However, the low bit-rate reconstructions of LIC suffer from artifacts such as blurring, color drifting and texture missing. Moreover, those varied artifacts make image quality metrics correlate badly with human perceptual quality. In this paper, we propose PO-ELIC, i.e., Perception-Oriented Efficient Learned Image Coding. To be specific, we adapt ELIC, one of the state-of-the-art LIC models, with adversarial training techniques. We apply a mixture of losses including hinge-form adversarial loss, Charbonnier loss, and style loss, to finetune the model towards better perceptual quality. Experimental results demonstrate that our method achieves comparable perceptual quality with HiFiC with much lower bitrate.      
### 21.Controller-Aware Dynamic Network Management for Industry 4.0  [ :arrow_down: ](https://arxiv.org/pdf/2205.14449.pdf)
>  In this paper, we consider a cyber-physical manufacturing system (CPMS) scenario containing physical components (robots, sensors, and actuators), operating in a digitally connected, constrained environment to perform industrial tasks. The CPMS has a centralized control plane with digital twins (DTs) of the physical resources, computational resources, and a network manager that allocates network resources. Existing approaches for allocation of network resources are typically fixed with respect to controller-dependent run-time specifications, which may impact the performance of physical processes. We propose a dynamic network management framework, where the network resource allocation schemes are controller-aware. The information about the controllers of the physical resources is implemented at the DT level, and metrics, such as regret bounds, take the process performance measures into account. The proposed network management schemes optimize physical system performance by balancing the shared resources between the physical assets on the plant floor, and by considering their control requirements, providing a new perspective for dynamic resource allocation. A simulation study is provided to illustrate the performance of the proposed network management approaches and compare their efficiencies.      
### 22.Incentive Mechanism Design for Emergency Frequency Control in Multi-Infeed Hybrid AC-DC System  [ :arrow_down: ](https://arxiv.org/pdf/2205.14399.pdf)
>  In multi-infeed hybrid AC-DC (MIDC) systems, the emergency frequency control (EFC) with LCC-HVDC systems participating is of vital importance for system frequency stability. Nevertheless, when regional power systems are operated by different decision-makers, the LCC-HVDC systems and their connected AC systems might be unwilling to participate in the EFC due to the costs and losses. In this paper, to incentivize the LCC-HVDC systems and their connected adjacent AC systems to participate in the droop-based EFC, a novel control-parameter-based incentive mechanism is proposed, which can deal with various possible emergency frequency faults. Then, a non-cooperative-based incentive game model is formulated to implement the incentive mechanism in the MIDC system. An algorithm for seeking the Nash equilibrium is designed, and the uniqueness of Nash equilibrium is proven. Moreover, the individual rationality, incentive compatibility and social optimality of the proposed mechanism are analyzed and proven. The effectiveness of the proposed incentive mechanism is verified through a case study.      
### 23.Transfer Learning-based Channel Estimation in Orthogonal Frequency Division Multiplexing Systems Using Data-nulling Superimposed Pilots  [ :arrow_down: ](https://arxiv.org/pdf/2205.14308.pdf)
>  Data-nulling superimposed pilot (DNSP) effectively alleviates the superimposed interference of superimposed training (ST)-based channel estimation (CE) in orthogonal frequency division multiplexing (OFDM) systems, while facing the challenges of the estimation accuracy and computational complexity. By developing the promising solutions of deep learning (DL) in the physical layer of wireless communication, we fuse the DNSP and DL to tackle these challenges in this paper. Nevertheless, due to the changes of wireless scenarios, the model mismatch of DL leads to the performance degradation of CE, and thus faces the issue of network retraining. To address this issue, a lightweight transfer learning (TL) network is further proposed for the DL-based DNSP scheme, and thus structures a TL-based CE in OFDM systems. Specifically, based on the linear receiver, the least squares estimation is first employed to extract the initial features of CE. With the extracted features, we develop a convolutional neural network (CNN) to fuse the solutions of DLbased CE and the CE of DNSP. Finally, a lightweight TL network is constructed to address the model mismatch. To this end, a novel CE network for the DNSP scheme in OFDM systems is structured, which improves its estimation accuracy and alleviates the model mismatch. The experimental results show that in all signal-to-noise-ratio (SNR) regions, the proposed method achieves lower normalized mean squared error (NMSE) than the existing DNSP schemes with minimum mean square error (MMSE)-based CE. For example, when the SNR is 0 decibel (dB), the proposed scheme achieves similar NMSE as that of the MMSE-based CE scheme at 20 dB, thereby significantly improving the estimation accuracy of CE. In addition, relative to the existing schemes, the improvement of the proposed scheme presents its robustness against the impacts of parameter variations.      
### 24.Deep Representation Decomposition for Rate-Invariant Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2205.14294.pdf)
>  While promising performance for speaker verification has been achieved by deep speaker embeddings, the advantage would reduce in the case of speaking-style variability. Speaking rate mismatch is often observed in practical speaker verification systems, which may actually degrade the system performance. To reduce intra-class discrepancy caused by speaking rate, we propose a deep representation decomposition approach with adversarial learning to learn speaking rate-invariant speaker embeddings. Specifically, adopting an attention block, we decompose the original embedding into an identity-related component and a rate-related component through multi-task training. Additionally, to reduce the latent relationship between the two decomposed components, we further propose a cosine mapping block to train the parameters adversarially to minimize the cosine similarity between the two decomposed components. As a result, identity-related features become robust to speaking rate and then are used for verification. Experiments are conducted on VoxCeleb1 data and HI-MIA data to demonstrate the effectiveness of our proposed approach.      
### 25.P2M-DeTrack: Processing-in-Pixel-in-Memory for Energy-efficient and Real-Time Multi-Object Detection and Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2205.14285.pdf)
>  Today's high resolution, high frame rate cameras in autonomous vehicles generate a large volume of data that needs to be transferred and processed by a downstream processor or machine learning (ML) accelerator to enable intelligent computing tasks, such as multi-object detection and tracking. The massive amount of data transfer incurs significant energy, latency, and bandwidth bottlenecks, which hinders real-time processing. To mitigate this problem, we propose an algorithm-hardware co-design framework called Processing-in-Pixel-in-Memory-based object Detection and Tracking (P2M-DeTrack). P2M-DeTrack is based on a custom faster R-CNN-based model that is distributed partly inside the pixel array (front-end) and partly in a separate FPGA/ASIC (back-end). The proposed front-end in-pixel processing down-samples the input feature maps significantly with judiciously optimized strided convolution and pooling. Compared to a conventional baseline design that transfers frames of RGB pixels to the back-end, the resulting P2M-DeTrack designs reduce the data bandwidth between sensor and back-end by up to 24x. The designs also reduce the sensor and total energy (obtained from in-house circuit simulations at Globalfoundries 22nm technology node) per frame by 5.7x and 1.14x, respectively. Lastly, they reduce the sensing and total frame latency by an estimated 1.7x and 3x, respectively. We evaluate our approach on the multi-object object detection (tracking) task of the large-scale BDD100K dataset and observe only a 0.5% reduction in the mean average precision (0.8% reduction in the identification F1 score) compared to the state-of-the-art.      
### 26.A Low-complexity Brain-computer Interface for High-complexity Robot Swarm Control  [ :arrow_down: ](https://arxiv.org/pdf/2205.14265.pdf)
>  A brain-computer interface (BCI) is a system that allows a human operator to use only mental commands in controlling end effectors that interact with the world around them. Such a system consists of a measurement device to record the human user's brain activity, which is then processed into commands that drive a system end effector. BCIs involve either invasive measurements which allow for high-complexity control but are generally infeasible, or noninvasive measurements which offer lower quality signals but are more practical to use. In general, BCI systems have not been developed that efficiently, robustly, and scalably perform high-complexity control while retaining the practicality of noninvasive measurements. Here we leverage recent results from feedback information theory to fill this gap by modeling BCIs as a communications system and deploying a human-implementable interaction algorithm for noninvasive control of a high-complexity robot swarm. We construct a scalable dictionary of robotic behaviors that can be searched simply and efficiently by a BCI user, as we demonstrate through a large-scale user study testing the feasibility of our interaction algorithm, a user test of the full BCI system on (virtual and real) robot swarms, and simulations that verify our results against theoretical models. Our results provide a proof of concept for how a large class of high-complexity effectors (even beyond robotics) can be effectively controlled by a BCI system with low-complexity and noisy inputs.      
### 27.Two-Leg Deep Space Relay Architectures: Performance, Challenges, and Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2205.14234.pdf)
>  In this paper, architectures for interplanetary communications that feature the use of a data relay are investigated. In the considered "two-leg" architecture, a spacecraft orbiting the Earth, or in orbit at a Lagrange point, receives data from a deep space probe (leg-1) and relays them towards ground (leg-2). Different wireless technologies for the interplanetary link, namely, radio frequencies above the Ka band and optical frequencies, are considered. Moreover, the cases of transparent and regenerative relaying as well as different different orbital configurations are addressed, offering a thorough analysis of such systems from different viewpoints. Results show that, under certain constraints in terms of pointing accuracy and onboard antenna size, the adoption of a two-leg architecture can achieve the data rates supported by direct space-to-Earth link configurations with remarkably smaller ground station antennas.      
### 28.FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2205.14147.pdf)
>  To correct for breathing motion in PET imaging, an interpretable and unsupervised deep learning technique, FlowNet-PET, was constructed. The network was trained to predict the optical flow between two PET frames from different breathing amplitude ranges. As a result, the trained model groups different retrospectively-gated PET images together into a motion-corrected single bin, providing a final image with similar counting statistics as a non-gated image, but without the blurring effects that were initially observed. As a proof-of-concept, FlowNet-PET was applied to anthropomorphic digital phantom data, which provided the possibility to design robust metrics to quantify the corrections. When comparing the predicted optical flows to the ground truths, the median absolute error was found to be smaller than the pixel and slice widths, even for the phantom with a diaphragm movement of 21 mm. The improvements were illustrated by comparing against images without motion and computing the intersection over union (IoU) of the tumors as well as the enclosed activity and coefficient of variation (CoV) within the no-motion tumor volume before and after the corrections were applied. The average relative improvements provided by the network were 54%, 90%, and 76% for the IoU, total activity, and CoV, respectively. The results were then compared against the conventional retrospective phase binning approach. FlowNet-PET achieved similar results as retrospective binning, but only required one sixth of the scan duration. The code and data used for training and analysis has been made publicly available (<a class="link-external link-https" href="https://github.com/teaghan/FlowNet_PET" rel="external noopener nofollow">this https URL</a>).      
### 29.Noise analysis, error estimates, and Gamma Radiation Measurement for limited detector computerized tomography application  [ :arrow_down: ](https://arxiv.org/pdf/2205.14144.pdf)
>  Computed Tomography is one of the efficient and vital modalities of non-destructive techniques (NDT). Various factors influence the CT reconstruction result, including limited projection data, detector electronics optimization, background noise, detection noise, discretized nature of projection data, and many more. Radiation hardening and other aging factors that affect the operational settings may require recalibration of electronics parameters. Two well-known exercises are utilized with the motivation to improve reliability and accuracy in inverse recovery. The first exercise brute-forces an optimal candidate from the set of calibration methods for minimum error in inverse recovery. The second exercise, Kanpur Theorem-1 (KT-1) examines if optimal calibration sets electronics to impart minimum noise. The mutual conformity between statistics-derived CLT and Riemann integral transform-based KT-1 is shown first time using gamma radiation measurement. The analysis shows that measurement data with normal distribution inflicts the least noise in inverse recovery.      
### 30.Adapting Rapid Motor Adaptation for Bipedal Robots  [ :arrow_down: ](https://arxiv.org/pdf/2205.15299.pdf)
>  Recent advances in legged locomotion have enabled quadrupeds to walk on challenging terrains. However, bipedal robots are inherently more unstable and hence it's harder to design walking controllers for them. In this work, we leverage recent advances in rapid adaptation for locomotion control, and extend them to work on bipedal robots. Similar to existing works, we start with a base policy which produces actions while taking as input an estimated extrinsics vector from an adaptation module. This extrinsics vector contains information about the environment and enables the walking controller to rapidly adapt online. However, the extrinsics estimator could be imperfect, which might lead to poor performance of the base policy which expects a perfect estimator. In this paper, we propose A-RMA (Adapting RMA), which additionally adapts the base policy for the imperfect extrinsics estimator by finetuning it using model-free RL. We demonstrate that A-RMA outperforms a number of RL-based baseline controllers and model-based controllers in simulation, and show zero-shot deployment of a single A-RMA policy to enable a bipedal robot, Cassie, to walk in a variety of different scenarios in the real world beyond what it has seen during training. Videos and results at <a class="link-external link-https" href="https://ashish-kmr.github.io/a-rma/" rel="external noopener nofollow">this https URL</a>      
### 31.Personalized Acoustic Echo Cancellation for Full-duplex Communications  [ :arrow_down: ](https://arxiv.org/pdf/2205.15195.pdf)
>  Deep neural networks (DNNs) have shown promising results for acoustic echo cancellation (AEC). But the DNN-based AEC models let through all near-end speakers including the interfering speech. In light of recent studies on personalized speech enhancement, we investigate the feasibility of personalized acoustic echo cancellation (PAEC) in this paper for full-duplex communications, where background noise and interfering speakers may coexist with acoustic echoes. Specifically, we first propose a novel backbone neural network termed as gated temporal convolutional neural network (GTCNN) that outperforms state-of-the-art AEC models in performance. Speaker embeddings like d-vectors are further adopted as auxiliary information to guide the GTCNN to focus on the target speaker. A special case in PAEC is that speech snippets of both parties on the call are enrolled. Experimental results show that auxiliary information from either the near-end speaker or the far-end speaker can improve the DNN-based AEC performance. Nevertheless, there is still much room for improvement in the utilization of the finite-dimensional speaker embeddings.      
### 32.Vehicle Route Planning using Dynamically Weighted Dijkstra's Algorithm with Traffic Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2205.15190.pdf)
>  Traditional vehicle routing algorithms do not consider the changing nature of traffic. While implementations of Dijkstra's algorithm with varying weights exist, the weights are often changed after the outcome of algorithm is executed, which may not always result in the optimal route being chosen. Hence, this paper proposes a novel vehicle routing algorithm that improves upon Dijkstra's algorithm using a traffic prediction model based on the traffic flow in a road network. Here, Dijkstra's algorithm is adapted to be dynamic and time dependent using traffic flow theory principles during the planning stage itself. The model provides predicted traffic parameters and travel time across each edge of the road network at every time instant, leading to better routing results. The dynamic algorithm proposed here predicts changes in traffic conditions at each time step of planning to give the optimal forward-looking path. The proposed algorithm is verified by comparing it with conventional Dijkstra's algorithm on a graph with randomly simulated traffic, and is shown to predict the optimal route better with continuously changing traffic.      
### 33.Task-Prior Conditional Variational Auto-Encoder for Few-Shot Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.15014.pdf)
>  Transductive methods always outperform inductive methods in few-shot image classification scenarios. However, the existing few-shot methods contain a latent condition: the number of samples in each class is the same, which may be unrealistic. To cope with those cases where the query shots of each class are nonuniform (i.e. nonuniform few-shot learning), we propose a Task-Prior Conditional Variational Auto-Encoder model named TP-VAE, conditioned on support shots and constrained by a task-level prior regularization. Our method obtains high performance in the more challenging nonuniform few-shot scenarios. Moreover, our method outperforms the state-of-the-art in a wide range of standard few-shot image classification scenarios. Among them, the accuracy of 1-shot increased by about 3\%.      
### 34.On the Placement and Sustainability of Drone FSO Backhaul Relays  [ :arrow_down: ](https://arxiv.org/pdf/2205.15006.pdf)
>  We consider free-space optical (FSO) communication links for the backhaul connectivity of small cells (SCs) where a UAV with an FSO apparatus can serve as a backhaul relay node. We demonstrate how such drone relay stations (DRSs) can be deployed in a high-rise urban area in order to provide FSO line-of-sight (LOS) links that are unobstructed by buildings. Also, in our solution we consider the case where solar panels are mounted on DRSs such that placing the DRS in a sunny location is prioritized, and we show the gain in terms of number of required trips to recharge the UAV.      
### 35.Rethinking Saliency Map: An Context-aware Perturbation Method to Explain EEG-based Deep Learning Model  [ :arrow_down: ](https://arxiv.org/pdf/2205.14976.pdf)
>  Deep learning is widely used to decode the electroencephalogram (EEG) signal. However, there are few attempts to specifically investigate how to explain the EEG-based deep learning models. We conduct a review to summarize the existing works explaining the EEG-based deep learning model. Unfortunately, we find that there is no appropriate method to explain them. Based on the characteristic of EEG data, we suggest a context-aware perturbation method to generate a saliency map from the perspective of the raw EEG signal. Moreover, we also justify that the context information can be used to suppress the artifacts in the EEG-based deep learning model. In practice, some users might want a simple version of the explanation, which only indicates a few features as salient points. To this end, we propose an optional area limitation strategy to restrict the highlighted region. To validate our idea and make a comparison with the other methods, we select three representative EEG-based models to implement experiments on the emotional EEG dataset DEAP. The results of the experiments support the advantages of our method.      
### 36.Deep Learning Methods for Fingerprint-Based Indoor Positioning: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2205.14935.pdf)
>  Outdoor positioning systems based on the Global Navigation Satellite System have several shortcomings that have deemed their use for indoor positioning impractical. Location fingerprinting, which utilizes machine learning, has emerged as a viable method and solution for indoor positioning due to its simple concept and accurate performance. In the past, shallow learning algorithms were traditionally used in location fingerprinting. Recently, the research community started utilizing deep learning methods for fingerprinting after witnessing the great success and superiority these methods have over traditional/shallow machine learning algorithms. This paper provides a comprehensive review of deep learning methods in indoor positioning. First, the advantages and disadvantages of various fingerprint types for indoor positioning are discussed. The solutions proposed in the literature are then analyzed, categorized, and compared against various performance evaluation metrics. Since data is key in fingerprinting, a detailed review of publicly available indoor positioning datasets is presented. While incorporating deep learning into fingerprinting has resulted in significant improvements, doing so, has also introduced new challenges. These challenges along with the common implementation pitfalls are discussed. Finally, the paper is concluded with some remarks as well as future research trends.      
### 37.Deep Posterior Distribution-based Embedding for Hyperspectral Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2205.14887.pdf)
>  In this paper, we investigate the problem of hyperspectral (HS) image spatial super-resolution via deep learning. Particularly, we focus on how to embed the high-dimensional spatial-spectral information of HS images efficiently and effectively. Specifically, in contrast to existing methods adopting empirically-designed network modules, we formulate HS embedding as an approximation of the posterior distribution of a set of carefully-defined HS embedding events, including layer-wise spatial-spectral feature extraction and network-level feature aggregation. Then, we incorporate the proposed feature embedding scheme into a source-consistent super-resolution framework that is physically-interpretable, producing lightweight PDE-Net, in which high-resolution (HR) HS images are iteratively refined from the residuals between input low-resolution (LR) HS images and pseudo-LR-HS images degenerated from reconstructed HR-HS images via probability-inspired HS embedding. Extensive experiments over three common benchmark datasets demonstrate that PDE-Net achieves superior performance over state-of-the-art methods. Besides, the probabilistic characteristic of this kind of networks can provide the epistemic uncertainty of the network outputs, which may bring additional benefits when used for other HS image-based applications. The code will be publicly available at <a class="link-external link-https" href="https://github.com/jinnh/PDE-Net" rel="external noopener nofollow">this https URL</a>.      
### 38.Play it by Ear: Learning Skills amidst Occlusion through Audio-Visual Imitation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.14850.pdf)
>  Humans are capable of completing a range of challenging manipulation tasks that require reasoning jointly over modalities such as vision, touch, and sound. Moreover, many such tasks are partially-observed; for example, taking a notebook out of a backpack will lead to visual occlusion and require reasoning over the history of audio or tactile information. While robust tactile sensing can be costly to capture on robots, microphones near or on a robot's gripper are a cheap and easy way to acquire audio feedback of contact events, which can be a surprisingly valuable data source for perception in the absence of vision. Motivated by the potential for sound to mitigate visual occlusion, we aim to learn a set of challenging partially-observed manipulation tasks from visual and audio inputs. Our proposed system learns these tasks by combining offline imitation learning from a modest number of tele-operated demonstrations and online finetuning using human provided interventions. In a set of simulated tasks, we find that our system benefits from using audio, and that by using online interventions we are able to improve the success rate of offline imitation learning by ~20%. Finally, we find that our system can complete a set of challenging, partially-observed tasks on a Franka Emika Panda robot, like extracting keys from a bag, with a 70% success rate, 50% higher than a policy that does not use audio.      
### 39.Walle: An End-to-End, General-Purpose, and Large-Scale Production System for Device-Cloud Collaborative Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.14833.pdf)
>  To break the bottlenecks of mainstream cloud-based machine learning (ML) paradigm, we adopt device-cloud collaborative ML and build the first end-to-end and general-purpose system, called Walle, as the foundation. Walle consists of a deployment platform, distributing ML tasks to billion-scale devices in time; a data pipeline, efficiently preparing task input; and a compute container, providing a cross-platform and high-performance execution environment, while facilitating daily task iteration. Specifically, the compute container is based on Mobile Neural Network (MNN), a tensor compute engine along with the data processing and model execution libraries, which are exposed through a refined Python thread-level virtual machine (VM) to support diverse ML tasks and concurrent task execution. The core of MNN is the novel mechanisms of operator decomposition and semi-auto search, sharply reducing the workload in manually optimizing hundreds of operators for tens of hardware backends and further quickly identifying the best backend with runtime optimization for a computation graph. The data pipeline introduces an on-device stream processing framework to enable processing user behavior data at source. The deployment platform releases ML tasks with an efficient push-then-pull method and supports multi-granularity deployment policies. We evaluate Walle in practical e-commerce application scenarios to demonstrate its effectiveness, efficiency, and scalability. Extensive micro-benchmarks also highlight the superior performance of MNN and the Python thread-level VM. Walle has been in large-scale production use in Alibaba, while MNN has been open source with a broad impact in the community.      
### 40.Transient Behavior of Gossip Opinion Dynamics with Community Structure  [ :arrow_down: ](https://arxiv.org/pdf/2205.14784.pdf)
>  We study transient behavior of gossip opinion dynamics, in which agents randomly interact pairwise over a graph with community structure. We first study behavior of the model over a weighted graph with two communities. Edges within a community have identical weights different from edge weights between communities. A sharp phase transition is discovered: When edge weights within communities are larger than those between communities and those between regular and stubborn agents, most agents in the same community hold opinions close to the initial average opinion of that community with large probability, at an early stage of the process. However, if the difference between intra- and inter-community weights is small enough, most of the agents instead hold opinions close to everyone's initial average opinion at the early stage. In contrast, when the influence of stubborn agents is large enough, agent opinions settle quickly into their steady states. We then conduct numerical experiments to validate the theoretical results, and demonstrate extensions to multiple communities and stochastic block models, by providing two numerical examples. Different from the traditional asymptotic analysis in most opinion dynamics literature, the paper characterizes the influences of stubborn agents and community structure on the initial phase of the opinion evolution.      
### 41.Dynamic Control of Data-Intensive Services over Edge Computing Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.14735.pdf)
>  Next-generation distributed computing networks (e.g., edge and fog computing) enable the efficient delivery of delay-sensitive, compute-intensive applications by facilitating access to computation resources in close proximity to end users. Many of these applications (e.g., augmented/virtual reality) are also data-intensive: in addition to user-specific (live) data streams, they require access to (static) digital objects (e.g., image database) to complete the required processing tasks. When required objects are not available at the servers hosting the associated service functions, they must be fetched from other edge locations, incurring additional communication cost and latency. In such settings, overall service delivery performance shall benefit from jointly optimized decisions around (i) routing paths and processing locations for live data streams, together with (ii) cache selection and distribution paths for associated digital objects. In this paper, we address the problem of dynamic control of data-intensive services over edge cloud networks. We characterize the network stability region and design the first throughput-optimal control policy that coordinates processing and routing decisions for both live and static data-streams. Numerical results demonstrate the superior performance (e.g., throughput, delay, and resource consumption) obtained via the novel multi-pipeline flow control mechanism of the proposed policy, compared with state-of-the-art algorithms that lack integrated stream processing and data distribution control.      
### 42.Modeling Beats and Downbeats with a Time-Frequency Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2205.14701.pdf)
>  Transformer is a successful deep neural network (DNN) architecture that has shown its versatility not only in natural language processing but also in music information retrieval (MIR). In this paper, we present a novel Transformer-based approach to tackle beat and downbeat tracking. This approach employs SpecTNT (Spectral-Temporal Transformer in Transformer), a variant of Transformer that models both spectral and temporal dimensions of a time-frequency input of music audio. A SpecTNT model uses a stack of blocks, where each consists of two levels of Transformer encoders. The lower-level (or spectral) encoder handles the spectral features and enables the model to pay attention to harmonic components of each frame. Since downbeats indicate bar boundaries and are often accompanied by harmonic changes, this step may help downbeat modeling. The upper-level (or temporal) encoder aggregates useful local spectral information to pay attention to beat/downbeat positions. We also propose an architecture that combines SpecTNT with a state-of-the-art model, Temporal Convolutional Networks (TCN), to further improve the performance. Extensive experiments demonstrate that our approach can significantly outperform TCN in downbeat tracking while maintaining comparable result in beat tracking.      
### 43.IRS Aided MEC Systems with Binary Offloading: A Unified Framework for Dynamic IRS Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2205.14661.pdf)
>  In this paper, we develop a unified dynamic intelligent reflecting surface (IRS) beamforming framework to boost the sum computation rate of an IRS-aided mobile edge computing (MEC) system, where each device follows a binary offloading policy. Specifically, the task of each device has to be either executed locally or offloaded to MEC servers as a whole with the aid of given number of IRS beamforming vectors available. By flexibly controlling the number of IRS reconfiguration times, the system can achieve a balance between the performance and associated signalling overhead. We aim to maximize the sum computation rate by jointly optimizing the computational mode selection for each device, offloading time allocation, and IRS beamforming vectors across time. Since the resulting optimization problem is non-convex and NP-hard, there are generally no standard methods to solve it optimally. To tackle this problem, we first propose a penalty-based successive convex approximation algorithm, where all the associated variables in the inner-layer iterations are optimized simultaneously and the obtained solution is guaranteed to be locally optimal. Then, we further derive the offloading activation condition for each device by deeply exploiting the intrinsic structure of the original optimization problem. According to the offloading activation condition, a low-complexity algorithm based on the successive refinement method is proposed to obtain high-quality solutions, which is more appealing for practical systems with a large number of devices and IRS elements. Moreover, the optimal condition for the proposed low-complexity algorithm is revealed. Numerical results demonstrate the effectiveness of our proposed algorithms and also unveil the fundamental performance-cost tradeoff of the proposed dynamic IRS beamforming framework.      
### 44.Speaker Identification using Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.14649.pdf)
>  The audio data is increasing day by day throughout the globe with the increase of telephonic conversations, video conferences and voice messages. This research provides a mechanism for identifying a speaker in an audio file, based on the human voice biometric features like pitch, amplitude, frequency etc. We proposed an unsupervised learning model where the model can learn speech representation with limited dataset. Librispeech dataset was used in this research and we were able to achieve word error rate of 1.8.      
### 45.Aircraft and Differential Flatness  [ :arrow_down: ](https://arxiv.org/pdf/2205.14608.pdf)
>  We investigate apparent and intrinsic singularities of a flat model of aircrafts, illustrated with numerical simulations using Python and Maple. We consider failure situations and maneuvers for which apparent singularities of the previously known flat outputs may appear, making necessary to use some of the new flat outputs we consider. <br>Basically, the aircraft flat outputs are $x$, $y$, $z$, the coordinates of the gravity center, completed with any function of the sideslip angle $\beta$, the angle of attack $\alpha$, the bank angle $\mu$ and the thrust $F$. The choice of $\beta$ was previously used, but does not allow gravity-free flight, for which $\mu$ is the best choice, as well as for decrabe maneuver. The choice of $F$ is adapted for dead-stick landing conditions with $\beta\neq0$, such as forward slip maneuver. <br>This approach also allows to replace usual control with new controls in case of failures, e.g. differential thrust can be used in case of rudder failure. <br>Our results are illustrated by numerical simulations, using realistic non linear aerodynamics models. In a first stage, we investigate the ability of the flatness based control to reject perturbations. Since flatness in that case requires some model simplification, in a second stage, we focus on model errors and show that a suitable feed-back allows to keep trajectories with the complete real model close to the trajectories planned with the simplified one.      
### 46.Independent and Decentralized Learning in Markov Potential Games  [ :arrow_down: ](https://arxiv.org/pdf/2205.14590.pdf)
>  We propose a multi-agent reinforcement learning dynamics, and analyze its convergence properties in infinite-horizon discounted Markov potential games. We focus on the independent and decentralized setting, where players can only observe the realized state and their own reward in every stage. Players do not have knowledge of the game model, and cannot coordinate with each other. In each stage of our learning dynamics, players update their estimate of a perturbed Q-function that evaluates their total contingent payoff based on the realized one-stage reward in an asynchronous manner. Then, players independently update their policies by incorporating a smoothed optimal one-stage deviation strategy based on the estimated Q-function. A key feature of the learning dynamics is that the Q-function estimates are updated at a faster timescale than the policies. We prove that the policies induced by our learning dynamics converge to a stationary Nash equilibrium in Markov potential games with probability 1. Our results build on the theory of two timescale asynchronous stochastic approximation, and new analysis on the monotonicity of potential function along the trajectory of policy updates in Markov potential games.      
### 47.Exploiting Partial FDD Reciprocity for Beam Based Pilot Precoding and CSI Feedback in Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.14558.pdf)
>  Massive MIMO systems can achieve high spectrum and energy efficiency in downlink (DL) based on accurate estimate of channel state information (CSI). Existing works have developed learning-based DL CSI estimation that lowers uplink feedback overhead. One often overlooked problem is the limited number of DL pilots available for CSI estimation. One proposed solution leverages temporal CSI coherence by utilizing past CSI estimates and only sending CSI-reference symbols (CSI-RS) for partial arrays to preserve CSI recovery performance. Exploiting CSI correlations, FDD channel reciprocity is helpful to base stations with direct access to uplink CSI. In this work, we propose a new learning-based feedback architecture and a reconfigurable CSI-RS placement scheme to reduce DL CSI training overhead and to improve encoding efficiency of CSI feedback. Our results demonstrate superior performance in both indoor and outdoor scenarios by the proposed framework for CSI recovery at substantial reduction of computation power and storage requirements at UEs.      
### 48.Image Super-resolution with An Enhanced Group Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2205.14548.pdf)
>  CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal enhancement operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at <a class="link-external link-https" href="https://github.com/hellloxiaotian/ESRGCNN" rel="external noopener nofollow">this https URL</a>.      
### 49.SuperVoice: Text-Independent Speaker Verification Using Ultrasound Energy in Human Speech  [ :arrow_down: ](https://arxiv.org/pdf/2205.14496.pdf)
>  Voice-activated systems are integrated into a variety of desktop, mobile, and Internet-of-Things (IoT) devices. However, voice spoofing attacks, such as impersonation and replay attacks, in which malicious attackers synthesize the voice of a victim or simply replay it, have brought growing security concerns. Existing speaker verification techniques distinguish individual speakers via the spectrographic features extracted from an audible frequency range of voice commands. However, they often have high error rates and/or long delays. In this paper, we explore a new direction of human voice research by scrutinizing the unique characteristics of human speech at the ultrasound frequency band. Our research indicates that the high-frequency ultrasound components (e.g. speech fricatives) from 20 to 48 kHz can significantly enhance the security and accuracy of speaker verification. We propose a speaker verification system, SUPERVOICE that uses a two-stream DNN architecture with a feature fusion mechanism to generate distinctive speaker models. To test the system, we create a speech dataset with 12 hours of audio (8,950 voice samples) from 127 participants. In addition, we create a second spoofed voice dataset to evaluate its security. In order to balance between controlled recordings and real-world applications, the audio recordings are collected from two quiet rooms by 8 different recording devices, including 7 smartphones and an ultrasound microphone. Our evaluation shows that SUPERVOICE achieves 0.58% equal error rate in the speaker verification task, it only takes 120 ms for testing an incoming utterance, outperforming all existing speaker verification systems. Moreover, within 91 ms processing time, SUPERVOICE achieves 0% equal error rate in detecting replay attacks launched by 5 different loudspeakers.      
### 50.Feature Pyramid Attention based Residual Neural Network for Environmental Sound Classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.14411.pdf)
>  Environmental sound classification (ESC) is a challenging problem due to the unstructured spatial-temporal relations that exist in the sound signals. Recently, many studies have focused on abstracting features from convolutional neural networks while the learning of semantically relevant frames of sound signals has been overlooked. To this end, we present an end-to-end framework, namely feature pyramid attention network (FPAM), focusing on abstracting the semantically relevant features for ESC. We first extract the feature maps of the preprocessed spectrogram of the sound waveform by a backbone network. Then, to build multi-scale hierarchical features of sound spectrograms, we construct a feature pyramid representation of the sound spectrograms by aggregating the feature maps from multi-scale layers, where the temporal frames and spatial locations of semantically relevant frames are localized by FPAM. Specifically, the multiple features are first processed by a dimension alignment module. Afterward, the pyramid spatial attention module (PSA) is attached to localize the important frequency regions spatially with a spatial attention module (SAM). Last, the processed feature maps are refined by a pyramid channel attention (PCA) to localize the important temporal frames. To justify the effectiveness of the proposed FPAM, visualization of attention maps on the spectrograms has been presented. The visualization results show that FPAM can focus more on the semantic relevant regions while neglecting the noises. The effectiveness of the proposed methods is validated on two widely used ESC datasets: the ESC-50 and ESC-10 datasets. The experimental results show that the FPAM yields comparable performance to state-of-the-art methods. A substantial performance increase has been achieved by FPAM compared with the baseline methods.      
### 51.Topological phase estimation method for reparameterized periodic functions  [ :arrow_down: ](https://arxiv.org/pdf/2205.14390.pdf)
>  We consider a signal composed of several periods of a periodic function, of which we observe a noisy reparametrisation. The phase estimation problem consists of finding that reparametrisation, and, in particular, the number of observed periods. Existing methods are well-suited to the setting where the periodic function is known, or at least, simple. We consider the case when it is unknown and we propose an estimation method based on the shape of the signal. We use the persistent homology of sublevel sets of the signal to capture the temporal structure of its local extrema. We infer the number of periods in the signal by counting points in the persistence diagram and their multiplicities. Using the estimated number of periods, we construct an estimator of the reparametrisation. It is based on counting the number of sufficiently prominent local minima in the signal. This work is motivated by a vehicle positioning problem, on which we evaluated the proposed method.      
### 52.On stationary inflection points in step responses  [ :arrow_down: ](https://arxiv.org/pdf/2205.14372.pdf)
>  The step and impulse responses of a proper, rational transfer function are well-behaved analytic functions. We prove that such a response cannot have an inflection point such that the tangent at that point is parallel to the time-axis. Hence when a step or impulse response of a finite-dimensional LTI system crosses any given level, that crossing must be transversal, and can never be tangential.      
### 53.Insights from an Industrial Collaborative Assembly Project: Lessons in Research and Collaboration  [ :arrow_down: ](https://arxiv.org/pdf/2205.14340.pdf)
>  Significant progress in robotics reveals new opportunities to advance manufacturing. Next-generation industrial automation will require both integration of distinct robotic technologies and their application to challenging industrial environments. This paper presents lessons from a collaborative assembly project between three academic research groups and an industry partner. The goal of the project is to develop a flexible, safe, and productive manufacturing cell for sub-centimeter precision assembly. Solving this problem in a high-mix, low-volume production line motivates multiple research thrusts in robotics. This work identifies new directions in collaborative robotics for industrial applications and offers insight toward strengthening collaborations between institutions in academia and industry on the development of new technologies.      
### 54.On the Sample Complexity of Stabilizing Linear Systems via Policy Gradient Methods  [ :arrow_down: ](https://arxiv.org/pdf/2205.14335.pdf)
>  Stabilizing unknown dynamical systems with the direct use of data samples has drawn increasing attention in both control and machine learning communities. In this paper, we study the sample complexity of stabilizing linear time-invariant systems via Policy Gradient (PG) methods. Our analysis is built upon a discounted Linear Quadratic Regulator (LQR) framework which alternatively updates the policy and the discount factor of the LQR. In sharp contrast to the existing literature, we propose an explicit rule to adaptively adjust the discount factor by characterizing the stability margin using Lyapunov theory, which has independent interests of its own. We show that the number of iterations per discount factor is uniformly upper bounded, which enables us to prove the sample complexity of stabilizing linear systems via PG methods. Particularly, it only adds a coefficient logarithmic in the spectral radius of the state matrix to the sample complexity of solving LQR problems. We perform numerical experiments to verify our theoretical findings and empirically evaluate the effectiveness of our results on nonlinear systems.      
### 55.Speech Augmentation Based Unsupervised Learning for Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2205.14329.pdf)
>  In this paper, we investigated a speech augmentation based unsupervised learning approach for keyword spotting (KWS) task. KWS is a useful speech application, yet also heavily depends on the labeled data. We designed a CNN-Attention architecture to conduct the KWS task. CNN layers focus on the local acoustic features, and attention layers model the long-time dependency. To improve the robustness of KWS model, we also proposed an unsupervised learning method. The unsupervised loss is based on the similarity between the original and augmented speech features, as well as the audio reconstructing information. Two speech augmentation methods are explored in the unsupervised learning: speed and intensity. The experiments on Google Speech Commands V2 Dataset demonstrated that our CNN-Attention model has competitive results. Moreover, the augmentation based unsupervised learning could further improve the classification accuracy of KWS task. In our experiments, with augmentation based unsupervised learning, our KWS model achieves better performance than other unsupervised methods, such as CPC, APC, and MPC.      
### 56.Adaptive Activation Network For Low Resource Multilingual Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.14326.pdf)
>  Low resource automatic speech recognition (ASR) is a useful but thorny task, since deep learning ASR models usually need huge amounts of training data. The existing models mostly established a bottleneck (BN) layer by pre-training on a large source language, and transferring to the low resource target language. In this work, we introduced an adaptive activation network to the upper layers of ASR model, and applied different activation functions to different languages. We also proposed two approaches to train the model: (1) cross-lingual learning, replacing the activation function from source language to target language, (2) multilingual learning, jointly training the Connectionist Temporal Classification (CTC) loss of each language and the relevance of different languages. Our experiments on IARPA Babel datasets demonstrated that our approaches outperform the from-scratch training and traditional bottleneck feature based methods. In addition, combining the cross-lingual learning and multilingual learning together could further improve the performance of multilingual speech recognition.      
### 57.Is Lip Region-of-Interest Sufficient for Lipreading?  [ :arrow_down: ](https://arxiv.org/pdf/2205.14295.pdf)
>  Lip region-of-interest (ROI) is conventionally used for visual input in the lipreading task. Few works have adopted the entire face as visual input because lip-excluded parts of the face are usually considered to be redundant and irrelevant to visual speech recognition. However, faces contain much more detailed information than lips, such as speakers' head pose, emotion, identity etc. We argue that such information might benefit visual speech recognition if a powerful feature extractor employing the entire face is trained. In this work, we propose to adopt the entire face for lipreading with self-supervised learning. AV-HuBERT, an audio-visual multi-modal self-supervised learning framework, was adopted in our experiments. Our experimental results showed that adopting the entire face achieved 16% relative word error rate (WER) reduction on the lipreading task, compared with the baseline method using lip as visual input. Without self-supervised pretraining, the model with face input achieved a higher WER than that using lip input in the case of limited training data (30 hours), while a slightly lower WER when using large amount of training data (433 hours).      
### 58.Rethinking Bayesian Learning for Data Analysis: The Art of Prior and Inference in Sparsity-Aware Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2205.14283.pdf)
>  Sparse modeling for signal processing and machine learning has been at the focus of scientific research for over two decades. Among others, supervised sparsity-aware learning comprises two major paths paved by: a) discriminative methods and b) generative methods. The latter, more widely known as Bayesian methods, enable uncertainty evaluation w.r.t. the performed predictions. Furthermore, they can better exploit related prior information and naturally introduce robustness into the model, due to their unique capacity to marginalize out uncertainties related to the parameter estimates. Moreover, hyper-parameters associated with the adopted priors can be learnt via the training data. To implement sparsity-aware learning, the crucial point lies in the choice of the function regularizer for discriminative methods and the choice of the prior distribution for Bayesian learning. Over the last decade or so, due to the intense research on deep learning, emphasis has been put on discriminative techniques. However, a come back of Bayesian methods is taking place that sheds new light on the design of deep neural networks, which also establish firm links with Bayesian models and inspire new paths for unsupervised learning, such as Bayesian tensor decomposition. <br>The goal of this article is two-fold. First, to review, in a unified way, some recent advances in incorporating sparsity-promoting priors into three highly popular data modeling tools, namely deep neural networks, Gaussian processes, and tensor decomposition. Second, to review their associated inference techniques from different aspects, including: evidence maximization via optimization and variational inference methods. Challenges such as small data dilemma, automatic model structure search, and natural prediction uncertainty evaluation are also discussed. Typical signal processing and machine learning tasks are demonstrated.      
### 59.Towards Communication-Learning Trade-off for Federated Learning at the Network Edge  [ :arrow_down: ](https://arxiv.org/pdf/2205.14271.pdf)
>  In this letter, we study a wireless federated learning (FL) system where network pruning is applied to local users with limited resources. Although pruning is beneficial to reduce FL latency, it also deteriorates learning performance due to the information loss. Thus, a trade-off problem between communication and learning is raised. To address this challenge, we quantify the effects of network pruning and packet error on the learning performance by deriving the convergence rate of FL with a non-convex loss function. Then, closed-form solutions for pruning control and bandwidth allocation are proposed to minimize the weighted sum of FL latency and FL performance. Finally, numerical results demonstrate that 1) our proposed solution can outperform benchmarks in terms of cost reduction and accuracy guarantee, and 2) a higher pruning rate would bring less communication overhead but also worsen FL accuracy, which is consistent with our theoretical analysis.      
### 60.The Analysis of Optimization Algorithms, A Dissipativity Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.14264.pdf)
>  Optimization problems in engineering and applied mathematics are typically solved in an iterative fashion, by systematically adjusting the variables of interest until an adequate solution is found. The iterative algorithms that govern these systematic adjustments can be viewed as a control system. In control systems, the output in measured and the input is adjusted using feedback to drive the error to zero. Similarly, in iterative algorithms, the optimization objective is evaluated and the candidate solution is adjusted to drive it toward the optimal point. Choosing an algorithm that works well for a variety of optimization problems is akin to robust controller design. Just as dissipativity theory can be used to analyze the stability properties of control systems, it can also be used to analyze the convergence properties of iterative algorithms. By defining an appropriate notion of "energy" that dissipates with every iteration of the algorithm, the convergence properties of the algorithm can be characterized. This article formalizes the connection between iterative algorithms and control systems and shows through examples how dissipativity theory can be used to analyze the performance of many classes of optimization algorithms. This control-theoretic viewpoint enables the selection and tuning of optimization algorithms to be performed in an automated and systematic way.      
### 61.A comparison of Fourier and POD mode decomposition methods for high-speed Hall thruster video  [ :arrow_down: ](https://arxiv.org/pdf/2205.14207.pdf)
>  Hall thrusters are susceptible to large-amplitude plasma oscillations that impact thruster performance and lifetime and are also difficult to model. High-speed cameras are a popular tool to study these dynamics due to their spatial resolution and are a popular, nonintrusive complement to in-situ probes. High-speed video of thruster oscillations can be isolated (decomposed) into coherent structures (modes) with algorithms that help us better understand the evolution and interactions of each. This work provides an introduction, comparison, and step-by-step tutorial on established Fourier and newer Proper Orthogonal Decomposition (POD) algorithms as applied to high-speed video of the unshielded H6 6-kW laboratory model Hall thruster. From this dataset, both sets of algorithms identify and characterize $m=0$ and $m&gt;0$ modes in the discharge channel and cathode regions of the thruster plume, as well as mode hopping between the $m=3$ and $m=4$ rotating spokes in the channel. The Fourier methods are ideal for characterizing linear modal structures and also provide intuitive dispersion relationships. By contrast, the POD method tailors a basis set using energy minimization techniques that better captures the nonlinear nature of these structures and with a simpler implementation. Together, the Fourier and POD methods provide a more complete toolkit for studying Hall thruster plasma instabilities and mode dynamics. Specifically, we recommend first applying POD first to quickly identify the nature and location of global dynamics and then using Fourier methods to isolate dispersion plots and other wave-based physics.      
### 62.Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity  [ :arrow_down: ](https://arxiv.org/pdf/2205.14177.pdf)
>  Reconstructing perceived images from human brain activity monitored by functional magnetic resonance imaging (fMRI) is hard, especially for natural images. Existing methods often result in blurry and unintelligible reconstructions with low fidelity. In this study, we present a novel approach for enhanced image reconstruction, in which existing methods for object decoding and image reconstruction are merged together. This is achieved by conditioning the reconstructed image to its decoded image category using a class-conditional generative adversarial network and neural style transfer. The results indicate that our approach improves the semantic similarity of the reconstructed images and can be used as a general framework for enhanced image reconstruction.      
