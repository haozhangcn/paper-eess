# ArXiv eess --Wed, 18 May 2022
### 1.Harmonic analysis of the arctangent function regarding the angular error introduced by superimposed Fourier series for application in sine/cosine angle encoders  [ :arrow_down: ](https://arxiv.org/pdf/2205.08472.pdf)
>  We present a rigorous analytical method for harmonic analysis of the angular error of rotary and linear encoders with sine/cosine output signals in quadrature that are distorted by superimposed Fourier series. To calculate the angle from measured sine and cosine encoder channels in quadrature, the arctangent function is commonly used. The hence non-linear relation between raw signals and calculated angle -- often thought of as a black box -- complicates the estimation of the angular error and its harmonic decomposition. By means of a Taylor series expansion of the harmonic amplitudes, our method allows for quantification of the impact of harmonic signal distortions on the angular error in terms of harmonic order, magnitude and phase, including an upper bound on the remaining error term -- without numerical evaluation of the arctangent function. The same approximation is achieved with an intuitive geometric approximation in the complex plane, validating the results. Additionally, interaction effects between harmonics in the signals are considered by higher-order Taylor expansion. The approximations show an excellent agreement with the exact calculation in numerical examples even in case of large distortion amplitudes, leading to practicable estimates for the angular error decomposition.      
### 2.Assimilation of SAR-derived Flood Observations for Improving Fluvial Flood Forecast  [ :arrow_down: ](https://arxiv.org/pdf/2205.08471.pdf)
>  As the severity and occurrence of flood events tend to intensify with climate change, the need for flood forecasting capability increases. In this regard, the Flood Detection, Alert and rapid Mapping (FloodDAM) project, funded by Space for Climate Observatory initiatives, was set out to develop pre-operational tools dedicated to enabling quick responses in flood-prone areas, and to improve the reactivity of decision support systems. This work focuses on the assimilation of 2D flood extent data (expressed in terms of wet surface ratios) and in-situ water level data to improve the representation of the flood plain dynamics with a Telemac-2D model and an Ensemble Kalman Filter (EnKF). The EnKF control vector was composed friction coefficients and corrective parameter to the input forcing. It is then augmented with the water level state averaged over several floodplain zones. This work was conducted in the context of Observing System Simulation Experiments (OSSE) based on a real flood event occurred in January-February 2021 on the Garonne Marmandaise catchment. This allows to validate the observation operator associated to the wet surface ratio observations as well as the dual state-parameter sequential correction implemented in this work. The merits of assimilating SAR- derived flood plain data complementary to in-situ water level observations are shown in the control parameter and observation spaces with 1D and 2D assessment metrics. It was also shown that the correction of the hydraulic state significantly improved the flood dynamics, especially during the recession. This proof-of-concept study paves the way towards near-real-time flood forecast, making the most of remote sensing-derived flood observations.      
### 3.Application of Graph Based Features in Computer Aided Diagnosis for Histopathological Image Classification of Gastric Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2205.08467.pdf)
>  The gold standard for gastric cancer detection is gastric histopathological image analysis, but there are certain drawbacks in the existing histopathological detection and diagnosis. In this paper, based on the study of computer aided diagnosis system, graph based features are applied to gastric cancer histopathology microscopic image analysis, and a classifier is used to classify gastric cancer cells from benign cells. Firstly, image segmentation is performed, and after finding the region, cell nuclei are extracted using the k-means method, the minimum spanning tree (MST) is drawn, and graph based features of the MST are extracted. The graph based features are then put into the classifier for classification. In this study, different segmentation methods are compared in the tissue segmentation stage, among which are Level-Set, Otsu thresholding, watershed, SegNet, U-Net and Trans-U-Net segmentation; Graph based features, Red, Green, Blue features, Grey-Level Co-occurrence Matrix features, Histograms of Oriented Gradient features and Local Binary Patterns features are compared in the feature extraction stage; Radial Basis Function (RBF) Support Vector Machine (SVM), Linear SVM, Artificial Neural Network, Random Forests, k-NearestNeighbor, VGG16, and Inception-V3 are compared in the classifier stage. It is found that using U-Net to segment tissue areas, then extracting graph based features, and finally using RBF SVM classifier gives the optimal results with 94.29%.      
### 4.Nonlinear Waveform Inversion for Quantitative Ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2205.08461.pdf)
>  Due to its non-invasive and non-radiating nature, along with its low cost, ultrasound (US) imaging is widely used in medical applications. Typical B-mode US images have limited resolution and contrast and weak physical interpretation. Inverse US methods were developed to reconstruct the media's speed-of-sound (SoS) based on a linear acoustic model. However, the wave propagation in medical US is governed by nonlinear acoustics, which introduces more complex behaviors neglected in the linear model. In this work we propose a nonlinear waveform inversion (NWI) approach for quantitative US, that considers a nonlinear acoustics model to simultaneously reconstruct multiple material properties, including the medium's SoS, density, attenuation, and nonlinearity parameter. We thus broaden current inverse US approaches, such as the full waveform inversion (FWI) algorithm, by considering nonlinear media, and additional physical parameters. We represent the nonlinear acoustic model by means of a recurrent neural network, which enables us to apply advanced optimization algorithms borrowed from the deep learning toolbox and achieve more efficient reconstructions compared to the FWI method. We evaluate the performance of our approach on in-silico data and show that neglecting nonlinear effects may result in substantial degradation in the reconstruction, paving the way of NWI into clinical applications.      
### 5.The Deployment of IRS in UAV-Empowered 6G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.08423.pdf)
>  Intelligent reflecting surfaces (IRSs) with the ability to reconfigure inherent electromagnetic reflection and absorption characteristics in real-time provide unparalleled prospects to improve wireless connectivity in adverse circumstances. Unmanned aerial vehicles (UAV)-assisted wireless networks are evolved as a reliable solution to combat non-line of sight (NLoS) scenarios. Thereby, the IRS-empowered UAV-assisted cellular networks will be a significant role-player to improve the coverage and user experiences. The paper aimed to minimize the path loss and maximize the achievable data rate in IRS-UAV-assisted networks. In this context, the work analyzed path loss and achievable rate utilizing millimeter wave (mmWave) carrier considering the conventional UAV model and IRS-empowered UAV communication model. The research obtained that the IRSempowered UAV communications model can significantly minimize path loss and maximize the achievable data rate compared to the conventional UAV-assisted model.      
### 6.JUNO: Jump-Start Reinforcement Learning-based Node Selection for UWB Indoor Localization  [ :arrow_down: ](https://arxiv.org/pdf/2205.08422.pdf)
>  Ultra-Wideband (UWB) is one of the key technologies empowering the Internet of Thing (IoT) concept to perform reliable, energy-efficient, and highly accurate monitoring, screening, and localization in indoor environments. Performance of UWB-based localization systems, however, can significantly degrade because of Non Line of Sight (NLoS) connections between a mobile user and UWB beacons. To mitigate the destructive effects of NLoS connections, we target development of a Reinforcement Learning (RL) anchor selection framework that can efficiently cope with the dynamic nature of indoor environments. Existing RL models in this context, however, lack the ability to generalize well to be used in a new setting. Moreover, it takes a long time for the conventional RL models to reach the optimal policy. To tackle these challenges, we propose the Jump-start RL-based Uwb NOde selection (JUNO) framework, which performs real-time location predictions without relying on complex NLoS identification/mitigation methods. The effectiveness of the proposed JUNO framework is evaluated in term of the location error, where the mobile user moves randomly through an ultra-dense indoor environment with a high chance of establishing NLoS connections. Simulation results corroborate the effectiveness of the proposed framework in comparison to its state-of-the-art counterparts.      
### 7.Linear measurements from nonlinear sensors: identifying distortion with incidental noise  [ :arrow_down: ](https://arxiv.org/pdf/2205.08420.pdf)
>  Nonlinearity in many systems is heavily dependent on component variation and environmental factors such as temperature. This is often overcome by keeping signals close enough to the device's operating point that it appears approximately linear. But as the signal being measured becomes larger, the deviation from linearity increases, and the device's nonlinearity specification will be exceeded. This limits the range over which the device will produce directly useful measurements, often to far less than the device's safe range of operation.      
### 8.Human Emotion Classification based on EEG Signals Using Recurrent Neural Network And KNN  [ :arrow_down: ](https://arxiv.org/pdf/2205.08419.pdf)
>  In human contact, emotion is very crucial. Attributes like words, voice intonation, facial expressions, and kinesics can all be used to portray one's feelings. However, brain-computer interface (BCI) devices have not yet reached the level required for emotion interpretation. With the rapid development of machine learning algorithms, dry electrode techniques, and different real-world applications of the brain-computer interface for normal individuals, emotion categorization from EEG data has recently gotten a lot of attention. Electroencephalogram (EEG) signals are a critical resource for these systems. The primary benefit of employing EEG signals is that they reflect true emotion and are easily resolved by computer systems. In this work, EEG signals associated with good, neutral, and negative emotions were identified using channel selection preprocessing. However, researchers had a limited grasp of the specifics of the link between various emotional states until now. To identify EEG signals, we used discrete wavelet transform and machine learning techniques such as recurrent neural network (RNN) and k-nearest neighbor (kNN) algorithm. Initially, the classifier methods were utilized for channel selection. As a result, final feature vectors were created by integrating the features of EEG segments from these channels. Using the RNN and kNN algorithms, the final feature vectors with connected positive, neutral, and negative emotions were categorized independently. The classification performance of both techniques is computed and compared. Using RNN and kNN, the average overall accuracies were 94.844 % and 93.438 %, respectively.      
### 9.Fault Detection for Non-Condensing Boilers using Simulated Building Automation System Sensor Data  [ :arrow_down: ](https://arxiv.org/pdf/2205.08418.pdf)
>  Building performance has been shown to degrade significantly after commissioning, resulting in increased energy consumption and associated greenhouse gas emissions. Continuous Commissioning using existing sensor networks and IoT devices has the potential to minimize this waste by continually identifying system degradation and re-tuning control strategies to adapt to real building performance. Due to its significant contribution to greenhouse gas emissions, the performance of gas boiler systems for building heating is critical. A review of boiler performance studies has been used to develop a set of common faults and degraded performance conditions, which have been integrated into a MATLAB/Simulink emulator. This resulted in a labeled dataset with approximately 10,000 simulations of steady-state performance for each of 14 non-condensing boilers. The collected data is used for training and testing fault classification using K-nearest neighbour, Decision tree, Random Forest, and Support Vector Machines. The results show that the Support Vector Machines method gave the best prediction accuracy, consistently exceeding 90%, and generalization across multiple boilers is not possible due to low classification accuracy.      
### 10.Automated Mobility Context Detection with Inertial Signals  [ :arrow_down: ](https://arxiv.org/pdf/2205.08409.pdf)
>  Remote monitoring of motor functions is a powerful approach for health assessment, especially among the elderly population or among subjects affected by pathologies that negatively impact their walking capabilities. This is further supported by the continuous development of wearable sensor devices, which are getting progressively smaller, cheaper, and more energy efficient. The external environment and mobility context have an impact on walking performance, hence one of the biggest challenges when remotely analysing gait episodes is the ability to detect the context within which those episodes occurred. The primary goal of this paper is the investigation of context detection for remote monitoring of daily motor functions. We aim to understand whether inertial signals sampled with wearable accelerometers, provide reliable information to classify gait-related activities as either indoor or outdoor. We explore two different approaches to this task: (1) using gait descriptors and features extracted from the input inertial signals sampled during walking episodes, together with classic machine learning algorithms, and (2) treating the input inertial signals as time series data and leveraging end-to-end state-of-the-art time series classifiers. We directly compare the two approaches through a set of experiments based on data collected from 9 healthy individuals. Our results indicate that the indoor/outdoor context can be successfully derived from inertial data streams. We also observe that time series classification models achieve better accuracy than any other feature-based models, while preserving efficiency and ease of use.      
### 11.HoVer-Trans: Anatomy-aware HoVer-Transformer for ROI-free Breast Cancer Diagnosis in Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.08390.pdf)
>  Ultrasonography is an important routine examination for breast cancer diagnosis, due to its non-invasive, radiation-free and low-cost properties. However, it is still not the first-line screening test for breast cancer due to its inherent limitations. It would be a tremendous success if we can precisely diagnose breast cancer by breast ultrasound images (BUS). Many learning-based computer-aided diagnostic methods have been proposed to achieve breast cancer diagnosis/lesion classification. However, most of them require a pre-define ROI and then classify the lesion inside the ROI. Conventional classification backbones, such as VGG16 and ResNet50, can achieve promising classification results with no ROI requirement. But these models lack interpretability, thus restricting their use in clinical practice. In this study, we propose a novel ROI-free model for breast cancer diagnosis in ultrasound images with interpretable feature representations. We leverage the anatomical prior knowledge that malignant and benign tumors have different spatial relationships between different tissue layers, and propose a HoVer-Transformer to formulate this prior knowledge. The proposed HoVer-Trans block extracts the inter- and intra-layer spatial information horizontally and vertically. We conduct and release an open dataset GDPH&amp;GYFYY for breast cancer diagnosis in BUS. The proposed model is evaluated in three datasets by comparing with four CNN-based models and two vision transformer models via a five-fold cross validation. It achieves state-of-the-art classification performance with the best model interpretability.      
### 12.OFDM Joint Radar-Communications under Phase Noise: From Mitigation to Exploitation  [ :arrow_down: ](https://arxiv.org/pdf/2205.08376.pdf)
>  We consider the problem of monostatic radar sensing with OFDM joint radar-communications (JRC) systems in the presence of phase noise (PN) caused by oscillator imperfections. We begin by providing a rigorous statistical characterization of PN in the radar receiver over multiple OFDM symbols for free-running oscillators (FROs) and phase-locked loops (PLLs). Based on the delay-dependent PN covariance matrix, we derive the hybrid maximum-likelihood (ML)/maximum a-posteriori (MAP) estimator of the deterministic delay-Doppler parameters and the random PN, resulting in a challenging high-dimensional nonlinear optimization problem. To circumvent the nonlinearity of PN, we then develop an iterated small angle approximation (ISAA) algorithm that progressively refines delay-Doppler-PN estimates via closed-form updates of PN as a function of delay-Doppler at each iteration. Moreover, unlike existing approaches where PN is considered to be purely an impairment that has to be mitigated, we propose to exploit PN for range ambiguity resolution by capitalizing on its delay-dependent statistics (i.e., the range correlation effect), through the formulation of a parametric Toeplitz-block Toeplitz covariance matrix reconstruction problem. Simulation results indicate quick convergence of ISAA to the hybrid Cramér-Rao bound (CRB), as well as its remarkable performance gains over state-of-the-art benchmarks, for both FROs and PLLs under various operating conditions, while showing that the detrimental effect of PN can be turned into an advantage for sensing.      
### 13.Massive MIMO for Serving Federated Learning and Non-Federated Learning Users  [ :arrow_down: ](https://arxiv.org/pdf/2205.08328.pdf)
>  With its privacy preservation and communication efficiency, federated learning (FL) has emerged as a promising learning framework for beyond 5G wireless networks. It is anticipated that future wireless networks will jointly serve both FL and downlink non-FL user groups in the same time-frequency resource. While in the downlink of each FL iteration, both groups jointly receive data from the base station in the same time-frequency resource, the uplink of each FL iteration requires bidirectional communication to support uplink transmission for FL users and downlink transmission for non-FL users. To overcome this challenge, we present half-duplex (HD) and full-duplex (FD) communication schemes to serve both groups. More specifically, we adopt the massive multiple-input multiple-output technology and aim to maximize the minimum effective rate of non-FL users under a quality of service (QoS) latency constraint for FL users. Since the formulated problem is highly nonconvex, we propose a power control algorithm based on successive convex approximation to find a stationary solution. Numerical results show that the proposed solutions perform significantly better than the considered baselines schemes. Moreover, the FD-based scheme outperforms the HD-based scheme in scenarios where the self-interference is small or moderate and/or the size of FL model updates is large.      
### 14.Serving Federated Learning and Non-Federated Learning Users: A Massive MIMO Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.08307.pdf)
>  Federated learning (FL) with its data privacy protection and communication efficiency has been considered as a promising learning framework for beyond-5G/6G systems. We consider a scenario where a group of downlink non-FL users are jointly served with a group of FL users using massive multiple-input multiple-output technology. The main challenge is how to utilise the resource to optimally serve both FL and non-FL users. We propose a communication scheme that serves the downlink of the non-FL users (UEs) and the uplink of FL UEs in each half of the frequency band. We formulate an optimization problem for optimizing transmit power to maximize the minimum effective data rates for non-FL users, while guaranteeing a quality-of-service time of each FL communication round for FL users. Then, a successive convex approximation-based algorithm is proposed to solve the formulated problem. Numerical results confirm that our proposed scheme significantly outperforms the baseline scheme.      
### 15.Providing Location Information at Edge Networks: A Federated Learning-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.08292.pdf)
>  Recently, the development of mobile edge computing has enabled exhilarating edge artificial intelligence (AI) with fast response and low communication cost. The location information of edge devices is essential to support the edge AI in many scenarios, like smart home, intelligent transportation systems and integrated health care. Taking advantages of deep learning intelligence, the centralized machine learning (ML)-based positioning technique has received heated attention from both academia and industry. However, some potential issues, such as location information leakage and huge data traffic, limit its application. Fortunately, a newly emerging privacy-preserving distributed ML mechanism, named federated learning (FL), is expected to alleviate these concerns. In this article, we illustrate a framework of FL-based localization system as well as the involved entities at edge networks. Moreover, the advantages of such system are elaborated. On practical implementation of it, we investigate the field-specific issues associated with system-level solutions, which are further demonstrated over a real-word database. Moreover, future challenging open problems in this field are outlined.      
### 16.Multiscale reconstruction of porous media based on multiple dictionaries learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.08278.pdf)
>  Digital modeling of the microstructure is important for studying the physical and transport properties of porous media. Multiscale modeling for porous media can accurately characterize macro-pores and micro-pores in a large-FoV (field of view) high-resolution three-dimensional pore structure model. This paper proposes a multiscale reconstruction algorithm based on multiple dictionaries learning, in which edge patterns and micro-pore patterns from homology high-resolution pore structure are introduced into low-resolution pore structure to build a fine multiscale pore structure model. The qualitative and quantitative comparisons of the experimental results show that the results of multiscale reconstruction are similar to the real high-resolution pore structure in terms of complex pore geometry and pore surface morphology. The geometric, topological and permeability properties of multiscale reconstruction results are almost identical to those of the real high-resolution pore structures. The experiments also demonstrate the proposal algorithm is capable of multiscale reconstruction without regard to the size of the input. This work provides an effective method for fine multiscale modeling of porous media.      
### 17.CAS-Net: Conditional Atlas Generation and Brain Segmentation for Fetal MRI  [ :arrow_down: ](https://arxiv.org/pdf/2205.08239.pdf)
>  Fetal Magnetic Resonance Imaging (MRI) is used in prenatal diagnosis and to assess early brain development. Accurate segmentation of the different brain tissues is a vital step in several brain analysis tasks, such as cortical surface reconstruction and tissue thickness measurements. Fetal MRI scans, however, are prone to motion artifacts that can affect the correctness of both manual and automatic segmentation techniques. In this paper, we propose a novel network structure that can simultaneously generate conditional atlases and predict brain tissue segmentation, called CAS-Net. The conditional atlases provide anatomical priors that can constrain the segmentation connectivity, despite the heterogeneity of intensity values caused by motion or partial volume effects. The proposed method is trained and evaluated on 253 subjects from the developing Human Connectome Project (dHCP). The results demonstrate that the proposed method can generate conditional age-specific atlas with sharp boundary and shape variance. It also segment multi-category brain tissues for fetal MRI with a high overall Dice similarity coefficient (DSC) of $85.2\%$ for the selected 9 tissue labels.      
### 18.ROP inception: signal estimation with quadratic random sketching  [ :arrow_down: ](https://arxiv.org/pdf/2205.08225.pdf)
>  Rank-one projections (ROP) of matrices and quadratic random sketching of signals support several data processing and machine learning methods, as well as recent imaging applications, such as phase retrieval or optical processing units. In this paper, we demonstrate how signal estimation can be operated directly through such quadratic sketches--equivalent to the ROPs of the "lifted signal" obtained as its outer product with itself--without explicitly reconstructing that signal. Our analysis relies on showing that, up to a minor debiasing trick, the ROP measurement operator satisfies a generalised sign product embedding (SPE) property. In a nutshell, the SPE shows that the scalar product of a signal sketch with the "sign" of the sketch of a given pattern approximates the square of the projection of that signal on this pattern. This thus amounts to an insertion (an "inception") of a ROP model inside a ROP sketch. The effectiveness of our approach is evaluated in several synthetic experiments.      
### 19.Rate-Region Characterization and Channel Estimation for Cell-Free Symbiotic Radio Communications  [ :arrow_down: ](https://arxiv.org/pdf/2205.08220.pdf)
>  Cell-free massive MIMO and symbiotic radio communication have been recently proposed as the promising beyond fifth-generation (B5G) networking architecture and transmission technology, respectively. To reap the benefits of both, this paper studies cell-free symbiotic radio communication systems, where a number of cell-free access points (APs) cooperatively send primary information to a receiver, and simultaneously support the passive backscattering communication of the secondary backscatter device (BD). We first derive the achievable communication rates of the active primary user and passive secondary user under the assumption of perfect channel state information (CSI), based on which the transmit beamforming of the cellfree APs is optimized to characterize the achievable rate-region of cell-free symbiotic communication systems. Furthermore, to practically acquire the CSI of the active and passive channels, we propose an efficient channel estimation method based on two-phase uplink-training, and the achievable rate-region taking into account CSI estimation errors are further characterized. Simulation results are provided to show the effectiveness of our proposed beamforming and channel estimation methods.      
### 20.Communication-Free Shepherding Navigation with Multiple Steering Agents  [ :arrow_down: ](https://arxiv.org/pdf/2205.08155.pdf)
>  Swarm guidance addresses a challenging problem considering the navigation and control of a group of passive agents. To solve this problem, shepherding offers a bio-inspired technique of navigating such group of agents by using external steering agents with appropriately designed movement law. Although most shepherding researches are mainly based on the availability of centralized instructions, these assumptions are not realistic enough to solve some emerging application problems. Therefore, this paper presents a decentralized shepherding method where each steering agent makes movements based on its own observation without any inter-agent communication. Our numerical simulations confirm the effectiveness of the proposed method by showing its high success rate and low costs in various placement patterns. These advantages particularly improve with the increase in the number of steering agents.      
### 21.Formal verification of an industrial UML-like model using mCRL2 (extended version)  [ :arrow_down: ](https://arxiv.org/pdf/2205.08146.pdf)
>  Low-code development platforms are gaining popularity. Essentially, such platforms allow to shift from coding to graphical modeling, helping to improve quality and reduce development time. The Cordis SUITE is a low-code development platform that adopts the Unified Modeling Language (UML) to design complex machine-control applications. In this paper we introduce Cordis models and their semantics. To enable formal verification, we define an automatic translation of Cordis models to the process algebraic specification language mCRL2. As a proof of concept, we describe requirements of the control software of an industrial cylinder model developed by Cordis, and show how these can be verified using model checking. We show that our verification approach is effective to uncover subtle issues in the industrial model and its implementation.      
### 22.Brachial Plexus Nerve Trunk Segmentation Using Deep Learning: A Comparative Study with Doctors' Manual Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.08143.pdf)
>  Ultrasound-guided nerve block anesthesia (UGNB) is a high-tech visual nerve block anesthesia method that can observe the target nerve and its surrounding structures, the puncture needle's advancement, and local anesthetics spread in real-time. The key in UGNB is nerve identification. With the help of deep learning methods, the automatic identification or segmentation of nerves can be realized, assisting doctors in completing nerve block anesthesia accurately and efficiently. Here, we establish a public dataset containing 320 ultrasound images of brachial plexus (BP). Three experienced doctors jointly produce the BP segmentation ground truth and label brachial plexus trunks. We design a brachial plexus segmentation system (BPSegSys) based on deep learning. BPSegSys achieves experienced-doctor-level nerve identification performance in various experiments. We evaluate BPSegSys' performance in terms of intersection-over-union (IoU), a commonly used performance measure for segmentation experiments. Considering three dataset groups in our established public dataset, the IoU of BPSegSys are 0.5238, 0.4715, and 0.5029, respectively, which exceed the IoU 0.5205, 0.4704, and 0.4979 of experienced doctors. In addition, we show that BPSegSys can help doctors identify brachial plexus trunks more accurately, with IoU improvement up to 27%, which has significant clinical application value.      
### 23.Dual-Cross-Polarized GPR Measurement Method for Detection and Orientation Estimation of Shallowly Buried Elongated Object  [ :arrow_down: ](https://arxiv.org/pdf/2205.08142.pdf)
>  Detecting a shallowly buried and elongated object and estimating its orientation using a commonly adopted co-polarized GPR system is challenging due to the presence of strong ground clutter that masks the target reflection. A cross-polarized configuration can be used to suppress ground clutter and reveal the object reflection, but it suffers from inconsistent detection capability which significantly varies with different object orientations. To address this issue, we propose a dual-cross-polarized detection (DCPD) method which utilizes two cross-polarized antennas with a special arrangement to detect the object. The signals reflected by the object and collected by the two antennas are combined in a rotationally invariant manner to ensure both effective ground clutter suppression and consistent detection irrespective of the object orientation. In addition, we present a dual-cross-polarized orientation estimation (DCPOE) algorithm to estimate the object orientation from the two cross-polarized data. The proposed DCPOE algorithm is less affected by environmental noise and performs robust and accurate azimuth angle estimation. The effectiveness of the proposed techniques in the detection and orientation estimation and their advantages over the existing method have been demonstrated using experimental data. Comparison results show that the maximum and average errors are 22.3° and 10.9° for the Alford rotation algorithm, while those are 4.9° and 1.8° for the proposed DCPOE algorithm in the demonstrated shallowly buried object cases. The proposed techniques can be unified in a framework to facilitate the investigation and mapping of shallowly buried and elongated targets.      
### 24.Composing General Audio Representation by Fusing Multilayer Features of a Pre-trained Model  [ :arrow_down: ](https://arxiv.org/pdf/2205.08138.pdf)
>  Many application studies rely on audio DNN models pre-trained on a large-scale dataset as essential feature extractors, and they extract features from the last layers. In this study, we focus on our finding that the middle layer features of existing supervised pre-trained models are more effective than the late layer features for some tasks. We propose a simple approach to compose features effective for general-purpose applications, consisting of two steps: (1) calculating feature vectors along the time frame from middle/late layer outputs, and (2) fusing them. This approach improves the utility of frequency and channel information in downstream processes, and combines the effectiveness of middle and late layer features for different tasks. As a result, the feature vectors become effective for general purposes. In the experiments using VGGish, PANNs' CNN14, and AST on nine downstream tasks, we first show that each layer output of these models serves different tasks. Then, we demonstrate that the proposed approach significantly improves their performance and brings it to a level comparable to that of the state-of-the-art. In particular, the performance of the non-semantic speech (NOSS) tasks greatly improves, especially on Speech commands V2 with VGGish of +77.1 (14.3% to 91.4%).      
### 25.Learning to Remove Clutter in Real-World GPR Images Using Hybrid Data  [ :arrow_down: ](https://arxiv.org/pdf/2205.08135.pdf)
>  The clutter in the ground-penetrating radar (GPR) radargram disguises or distorts subsurface target responses, which severely affects the accuracy of target detection and identification. Existing clutter removal methods either leave residual clutter or deform target responses when facing complex and irregular clutter in the real-world radargram. To tackle the challenge of clutter removal in real scenarios, a clutter-removal neural network (CR-Net) trained on a large-scale hybrid dataset is presented in this study. The CR-Net integrates residual dense blocks into the U-Net architecture to enhance its capability in clutter suppression and target reflection restoration. The combination of the mean absolute error (MAE) loss and the multi-scale structural similarity (MS-SSIM) loss is used to effectively drive the optimization of the network. To train the proposed CR-Net to remove complex and diverse clutter in real-world radargrams, the first large-scale hybrid dataset named CLT-GPR dataset containing clutter collected by different GPR systems in multiple scenarios is built. The CLT-GPR dataset significantly improves the generalizability of the network to remove clutter in real-world GPR radargrams. Extensive experimental results demonstrate that the CR-Net achieves superior performance over existing methods in removing clutter and restoring target responses in diverse real-world scenarios. Moreover, the CR-Net with its end-to-end design does not require manual parameter tuning, making it highly suitable for automatically producing clutter-free radargrams in GPR applications. The CLT-GPR dataset and the code implemented in the paper can be found at <a class="link-external link-https" href="https://haihan-sun.github.io/GPR.html" rel="external noopener nofollow">this https URL</a>.      
### 26.Using artificial intelligence to detect chest X-rays with no significant findings in a primary health care setting in Oulu, Finland  [ :arrow_down: ](https://arxiv.org/pdf/2205.08123.pdf)
>  Objectives: To assess the use of artificial intelligence-based software in ruling out chest X-ray cases, with no significant findings in a primary health care setting. <br>Methods: In this retrospective study, a commercially available artificial intelligence (AI) software was used to analyse 10 000 chest X-rays of Finnish primary health care patients. In studies with a mismatch between an AI normal report and the original radiologist report, a consensus read by two board-certified radiologists was conducted to make the final diagnosis. <br>Results: After the exclusion of cases not meeting the study criteria, 9579 cases were analysed by AI. Of these cases, 4451 were considered normal in the original radiologist report and 4644 after the consensus reading. The number of cases correctly found nonsignificant by AI was 1692 (17.7% of all studies and 36.4% of studies with no significant findings). After the consensus read, there were nine confirmed false-negative studies. These studies included four cases of slightly enlarged heart size, four cases of slightly increased pulmonary opacification and one case with a small unilateral pleural effusion. This gives the AI a sensitivity of 99.8% (95% CI= 99.65-99.92) and specificity of 36.4 % (95% CI= 35.05-37.84) for recognising significant pathology on a chest X-ray. <br>Conclusions: AI was able to correctly rule out 36.4% of chest X-rays with no significant findings of primary health care patients, with a minimal number of false negatives that would lead to effectively no compromise on patient safety. No critical findings were missed by the software.      
### 27.Computerized Tomography Pulmonary Angiography Image Simulation using Cycle Generative Adversarial Network from Chest CT imaging in Pulmonary Embolism Patients  [ :arrow_down: ](https://arxiv.org/pdf/2205.08106.pdf)
>  The purpose of this research is to develop a system that generates simulated computed tomography pulmonary angiography (CTPA) images clinically for pulmonary embolism diagnoses. Nowadays, CTPA images are the gold standard computerized detection method to determine and identify the symptoms of pulmonary embolism (PE), although performing CTPA is harmful for patients and also expensive. Therefore, we aim to detect possible PE patients through CT images. The system will simulate CTPA images with deep learning models for the identification of PE patients' symptoms, providing physicians with another reference for determining PE patients. In this study, the simulated CTPA image generation system uses a generative antagonistic network to enhance the features of pulmonary vessels in the CT images to strengthen the reference value of the images and provide a basis for hospitals to judge PE patients. We used the CT images of 22 patients from National Cheng Kung University Hospital and the corresponding CTPA images as the training data for the task of simulating CTPA images and generated them using two sets of generative countermeasure networks. This study is expected to propose a new approach to the clinical diagnosis of pulmonary embolism, in which a deep learning network is used to assist in the complex screening process and to review the generated simulated CTPA images, allowing physicians to assess whether a patient needs to undergo detailed testing for CTPA, improving the speed of detection of pulmonary embolism and significantly reducing the number of undetected patients.      
### 28.Multi-Head Attention Neural Network for Smartphone Invariant Indoor Localization  [ :arrow_down: ](https://arxiv.org/pdf/2205.08069.pdf)
>  Smartphones together with RSSI fingerprinting serve as an efficient approach for delivering a low-cost and high-accuracy indoor localization solution. However, a few critical challenges have prevented the wide-spread proliferation of this technology in the public domain. One such critical challenge is device heterogeneity, i.e., the variation in the RSSI signal characteristics captured across different smartphone devices. In the real-world, the smartphones or IoT devices used to capture RSSI fingerprints typically vary across users of an indoor localization service. Conventional indoor localization solutions may not be able to cope with device-induced variations which can degrade their localization accuracy. We propose a multi-head attention neural network-based indoor localization framework that is resilient to device heterogeneity. An in-depth analysis of our proposed framework across a variety of indoor environments demonstrates up to 35% accuracy improvement compared to state-of-the-art indoor localization techniques.      
### 29.A Framework for CSI-Based Indoor Localization with 1D Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.08068.pdf)
>  Modern indoor localization techniques are essential to overcome the weak GPS coverage in indoor environments. Recently, considerable progress has been made in Channel State Information (CSI) based indoor localization with signal fingerprints. However, CSI signal patterns can be complicated in the large and highly dynamic indoor spaces with complex interiors, thus a solution for solving this issue is urgently needed to expand the applications of CSI to a broader indoor space. In this paper, we propose an end-to-end solution including data collection, pattern clustering, denoising, calibration and a lightweight one-dimensional convolutional neural network (1D CNN) model with CSI fingerprinting to tackle this problem. We have also created and plan to open source a CSI dataset with a large amount of data collected across complex indoor environments at Colorado State University. Experiments indicate that our approach achieves up to 68.5% improved performance (mean distance error) with minimal number of parameters, compared to the best-known deep machine learning and CSI-based indoor localization works.      
### 30.A Short Introduction to the Koopman Representation of Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.08048.pdf)
>  The Koopman representation is an infinite dimensional linear representation of linear or nonlinear dynamical systems. It represents the dynamics of output maps (aka observables), which are functions on the state space whose evaluation is interpreted as an output. Conceptually simple derivations and commentary on the Koopman representation are given. We emphasize an important duality between initial conditions and output maps of the original system, and those of the Koopman representation. This duality is an important consideration when this representation is used in data-driven applications such as the Dynamic Mode Decomposition (DMD) and its variants. The adjoint relation between the Koopman representation and the transfer operator of mass transport is also shown.      
### 31.Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data  [ :arrow_down: ](https://arxiv.org/pdf/2205.08014.pdf)
>  Building inclusive speech recognition systems is a crucial step towards developing technologies that speakers of all language varieties can use. Therefore, ASR systems must work for everybody independently of the way they speak. To accomplish this goal, there should be available data sets representing language varieties, and also an understanding of model configuration that is the most helpful in achieving robust understanding of all types of speech. However, there are not enough data sets for accented speech, and for the ones that are already available, more training approaches need to be explored to improve the quality of accented speech recognition. In this paper, we discuss recent progress towards developing more inclusive ASR systems, namely, the importance of building new data sets representing linguistic diversity, and exploring novel training approaches to improve performance for all users. We address recent directions within benchmarking ASR systems for accented speech, measure the effects of wav2vec 2.0 pre-training on accented speech recognition, and highlight corpora relevant for diverse ASR evaluations.      
### 32.Joint cardiac $T_1$ mapping and cardiac function estimation using a deep manifold framework  [ :arrow_down: ](https://arxiv.org/pdf/2205.07994.pdf)
>  In this work, we proposed a continuous-acquisition strategy using a gradient echo (GRE) inversion recovery sequence based on spiral trajectories to simultaneously obtain the $T_1$ mapping and CINE imaging. The acquisition is using a free-breathing and ungated fashion. An approach based on variational auto-encoder(VAE) is used for the motion estimation from the centered k-space data. The motion signal is then used to train a deep manifold reconstruction algorithm for image reconstruction. Once the network is trained, we can excite the latent vectors (the estimated motion signals and the contrast signal) in any way as we wanted to generate the image frames in the time series. We can estimate the $T_1$ mapping using the generated image frames where only contrast is varying. We can also generate the breath-hold CINE in different contrast.      
### 33.Flexible and curtailable resource activation in three-phase unbalanced distribution networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.07965.pdf)
>  The need for flexibility and curtailable resources is crucial for ensuring the healthy operation of future distribution networks (DN). In this work, we propose a network-state driven framework that distribution system operators (DSOs) can utilize for activating flexible and curtailable resources for alleviating network voltage and thermal issues, while accounting for network voltage and current imbalances. This approach assumes the availability of dynamic network state information and uses nodal sensitivities for calculating a flexibility activation signal (FAS). The signal design is motivated by volt-Var and volt-watt inverter control, and thus bounded. The FAS also considers network voltage and current imbalances and incentivizes activation of active and reactive power flexibilities for reducing imbalance in addition to mitigating voltage and thermal imbalances in a three-phase unbalanced distribution network. The FAS design resembles optimal power flow duals, often used as locational marginal prices. The gains associated with the imbalance component of the objective function of three-phase unbalanced resource activation (TPU-RA) is performed using Pareto optimality. A numerical case study is presented showing the efficacy of the proposed framework in avoiding network issues while reducing voltage unbalance factor by more than 80\%. Further, DN's flexibility needs are quantified for location and time of day.      
### 34.Power and Skew Reduction Using Resonant Energy Recycling in 14-nm FinFET Clocks  [ :arrow_down: ](https://arxiv.org/pdf/2205.07949.pdf)
>  As the demand for high-performance microprocessors increases, the circuit complexity and the rate of data transfer increases resulting in higher power consumption. We propose a clocking architecture that uses a series LC resonance and inductor matching technique to address this bottleneck. By employing pulsed resonance, the switching power dissipated is recycled back. The inductor matching technique aids in reducing the skew, increasing the robustness of the clock network. This new resonant architecture saves over 43% power and 91% skew clocking a range of 1--5 GHz, compared to a conventional primary-secondary flip-flop-based CMOS architecture.      
### 35.Constructing Trajectory and Predicting Estimated Time of Arrival for Long Distance Travelling Vessels: A Probability Density-based Scanning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.07945.pdf)
>  In this study, a probability density-based approach for constructing trajectories is proposed and validated through an typical use-case application: Estimated Time of Arrival (ETA) prediction given origin-destination pairs. The ETA prediction is based on physics and mathematical laws given by the extracted information of probability density-based trajectories constructed. The overall ETA prediction errors are about 0.106 days (i.e. 2.544 hours) on average with 0.549 days (i.e. 13.176 hours) standard deviation, and the proposed approach has an accuracy of 92.08% with 0.959 R-Squared value for overall trajectories between Singapore and Australia ports selected.      
### 36.Data-Driven Interpolation for Super-Scarce X-Ray Computed Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2205.07888.pdf)
>  We address the problem of reconstructing X-Ray tomographic images from scarce measurements by interpolating missing acquisitions using a self-supervised approach. To do so, we train shallow neural networks to combine two neighbouring acquisitions into an estimated measurement at an intermediate angle. This procedure yields an enhanced sequence of measurements that can be reconstructed using standard methods, or further enhanced using regularisation approaches. <br>Unlike methods that improve the sequence of acquisitions using an initial deterministic interpolation followed by machine-learning enhancement, we focus on inferring one measurement at once. This allows the method to scale to 3D, the computation to be faster and crucially, the interpolation to be significantly better than the current methods, when they exist. We also establish that a sequence of measurements must be processed as such, rather than as an image or a volume. We do so by comparing interpolation and up-sampling methods, and find that the latter significantly under-perform. <br>We compare the performance of the proposed method against deterministic interpolation and up-sampling procedures and find that it outperforms them, even when used jointly with a state-of-the-art projection-data enhancement approach using machine-learning. These results are obtained for 2D and 3D imaging, on large biomedical datasets, in both projection space and image space.      
### 37.Near out-of-distribution detection for low-resolution radar micro-Doppler signatures  [ :arrow_down: ](https://arxiv.org/pdf/2205.07869.pdf)
>  Near out-of-distribution detection (OOD) aims at discriminating semantically similar data points without the supervision required for classification. This paper puts forward an OOD use case for radar targets detection extensible to other kinds of sensors and detection scenarios. We emphasize the relevance of OOD and its specific supervision requirements for the detection of a multimodal, diverse targets class among other similar radar targets and clutter in real-life critical systems. We propose a comparison of deep and non-deep OOD methods on simulated low-resolution pulse radar micro-Doppler signatures, considering both a spectral and a covariance matrix input representation. The covariance representation aims at estimating whether dedicated second-order processing is appropriate to discriminate signatures. The potential contributions of labeled anomalies in training, self-supervised learning, contrastive learning insights and innovative training losses are discussed, and the impact of training set contamination caused by mislabelling is investigated.      
### 38.Primal-Dual UNet for Sparse View Cone Beam Computed Tomography Volume Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2205.07866.pdf)
>  In this paper, the Primal-Dual UNet for sparse view CT reconstruction is modified to be applicable to cone beam projections and perform reconstructions of entire volumes instead of slices. Experiments show that the PSNR of the proposed method is increased by 10dB compared to the direct FDK reconstruction and almost 3dB compared to the modified original Primal-Dual Network when using only 23 projections. The presented network is not optimized wrt. memory consumption or hyperparameters but merely serves as a proof of concept and is limited to low resolution projections and volumes.      
### 39.Susceptibility of Age of Gossip to Timestomping  [ :arrow_down: ](https://arxiv.org/pdf/2205.08510.pdf)
>  We consider a fully connected network consisting of a source that maintains the current version of a file, $n$ nodes that use asynchronous gossip mechanisms to disseminate fresh information in the network, and an adversary who infects the packets at a target node through data timestamp manipulation, with the intent to replace circulation of fresh packets with outdated packets in the network. We show that a single infected node increases the expected age of a fully connected network from $O(\log n)$ to $O(n)$. Further, we show that the optimal behavior for an adversary is to reset the timestamps of all outgoing packets to the current time and of all incoming packets to an outdated time. Additionally, if the adversary allows the infected node to accept a small fraction of incoming packets from the network, then a large network can manage to curb the spread of stale files coming from the infected node and pull the network age back to $O(\log n)$. Lastly, we show that if an infected node contacts only a single node instead of all nodes of the network, the system age can still be degraded to $O(n)$. These show that fully connected nature of a network can be both a benefit and a detriment for information freshness; full connectivity, while enabling fast dissemination of information, also enables fast dissipation of adversarial inputs.      
### 40.Design and Manufacture of Flexible Epidermal NFC Device for Electrochemical Sensing of Sweat  [ :arrow_down: ](https://arxiv.org/pdf/2205.08492.pdf)
>  Flexible and epidermal sensing devices are becoming vital to enable precision medicine and telemonitoring systems. The NFC (Near Field Communication) protocol is also becoming increasingly important for this application since it is embedded in most smartphones that can be used as pervasive and low-cost readers. Furthermore, the responder can be passive and can harvest enough power to perform electromagnetic sensing. Finally, the NFC coils are robust to bending and to the human body's presence. This contribution details the design of a new flexible device, including an electrochemical sensor communicating through the NFC protocol. A spiral NFC antenna is designed, and a manufactured prototype is experimentally tested to quantify the robustness to the inter-wearer variability and the bending. Lastly, the sensory data retrieval is validated by comparison with a portable potentiostat. The realized sensor can be comfortably worn and be easily read by smartphones independently from the wearer and from the point of application and could be used in future for estimating the user's psycho-physical health by analyzing the body's sweat.      
### 41.Dynamic Recognition of Speakers for Consent Management by Contrastive Embedding Replay  [ :arrow_down: ](https://arxiv.org/pdf/2205.08459.pdf)
>  Voice assistants record sound and can overhear conversations. Thus, a consent management mechanism is desirable such that users can express their wish to be recorded or not. Consent management can be implemented using speaker recognition; users that do not give consent enrol their voice and all further recordings of these users is subsequently not processed. Building speaker recognition based consent management is challenging due to the dynamic nature of the problem, required scalability for large number of speakers, and need for fast speaker recognition with high accuracy. This paper describes a speaker recognition based consent management system addressing the aforementioned challenges. A fully supervised batch contrastive learning is applied to learn the underlying speaker equivariance inductive bias during the training on the set of speakers noting recording dissent. Speakers that do not provide consent are grouped in buckets which are trained continuously. The embeddings are contrastively learned for speakers in their buckets during training and act later as a replay buffer for classification. The buckets are progressively registered during training and a novel multi-strided random sampling of the contrastive embedding replay buffer is proposed. Buckets are contrastively trained for a few steps only in each iteration and replayed for classification progressively leading to fast convergence. An algorithm for fast and dynamic registration and removal of speakers in buckets is described. The evaluation results show that the proposed approach provides the desired fast and dynamic solution for consent management and outperforms existing approaches in terms of convergence speed and adaptive capabilities as well as verification performance during inference.      
### 42.Utterance Weighted Multi-Dilation Temporal Convolutional Networks for Monaural Speech Dereverberation  [ :arrow_down: ](https://arxiv.org/pdf/2205.08455.pdf)
>  Speech dereverberation is an important stage in many speech technology applications. Recent work in this area has been dominated by deep neural network models. Temporal convolutional networks (TCNs) are deep learning models that have been proposed for sequence modelling in the task of dereverberating speech. In this work a weighted multi-dilation depthwise-separable convolution is proposed to replace standard depthwise-separable convolutions in TCN models. This proposed convolution enables the TCN to dynamically focus on more or less local information in its receptive field at each convolutional block in the network. It is shown that this weighted multi-dilation temporal convolutional network (WD-TCN) consistently outperforms the TCN across various model configurations and using the WD-TCN model is a more parameter efficient method to improve the performance of the model than increasing the number of convolutional blocks. The best performance improvement over the baseline TCN is 0.55 dB scale-invariant signal-to-distortion ratio (SISDR) and the best performing WD-TCN model attains 12.26 dB SISDR on the WHAMR dataset.      
### 43.Data-driven Driver Model for Speed Advisory Systems in Partially Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2205.08445.pdf)
>  Vehicle control algorithms exploiting connectivity and automation, such as Connected and Automated Vehicles (CAVs) or Advanced Driver Assistance Systems (ADAS), have the opportunity to improve energy savings. However, lower levels of automation involve a human-machine interaction stage, where the presence of a human driver affects the performance of the control algorithm in closed loop. This occurs for instance in the case of Eco-Driving control algorithms implemented as a velocity advisory system, where the driver is displayed an optimal speed trajectory to follow to reduce energy consumption. Achieving the control objectives relies on the human driver perfectly following the recommended speed. If the driver is unable to follow the recommended speed, a decline in energy savings and poor vehicle performance may occur. This warrants the creation of methods to model and forecast the response of a human driver when operating in the loop with a speed advisory system. <br>This work focuses on developing a sequence to sequence long-short term memory (LSTM)-based driver behavior model that models the interaction of the human driver to a suggested desired vehicle speed trajectory in real-world conditions. A driving simulator is used for data collection and training the driver model, which is then compared against the driving data and a deterministic model. Results show close proximity of the LSTM-based model with the driving data, demonstrating that the model can be adopted as a tool to design human-centered speed advisory systems.      
### 44.Simultaneous Multi-User MIMO Communications and Multi-Target Tracking with Full Duplex Radios  [ :arrow_down: ](https://arxiv.org/pdf/2205.08402.pdf)
>  In this paper, we present an Integrated Sensing and Communications (ISAC) system enabled by in-band Full Duplex (FD) radios, where a massive Multiple-Input Multiple-Output (MIMO) base station equipped with hybrid Analog and Digital (A/D) beamformers is communicating with multiple DownLink (DL) users, and simultaneously estimates via the same signaling waveforms the Direction of Arrival (DoA) as well as the range of radar targets randomly distributed within its coverage area. Capitalizing on a recent reduced-complexity FD hybrid A/D beamforming architecture, we devise a joint radar target tracking and DL data transmission protocol. An optimization framework for the joint design of the massive A/D beamformers and the Self-Interference (SI) cancellation unit, with the dual objective of maximizing the radar tracking accuracy and DL communication performance, is presented. Our simulation results at millimeter wave frequencies using 5G NR wideband waveforms, showcase the accuracy of the radar target tracking performance of the proposed system, which simultaneously offers increased sum rate compared with benchmark schemes.      
### 45.Full Duplex Massive MIMO Architectures: Recent Advances, Applications, and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2205.08393.pdf)
>  The increasingly demanding objectives for next generation wireless communications have spurred recent research activities on multi-antenna transceiver hardware architectures and relevant intelligent communication schemes. Among them belong the Full Duplex (FD) Multiple-Input Multiple-Output (MIMO) architectures, which offer the potential for simultaneous uplink and downlink operations in the entire frequency band. However, as the number of antenna elements increases, the interference signal leaking from the transmitter of the FD radio to its receiver becomes more severe. In this article, we present a unified FD massive MIMO architecture comprising analog and digital transmit and receive BeamForming (BF), as well as analog and digital SI cancellation, which can be jointly optimized for various performance objectives and complexity requirements. Performance evaluation results for applications of the proposed architecture to fully digital and hybrid analog and digital BF operations using recent algorithmic designs, as well as simultaneous communication of data and control signals are presented. It is shown that the proposed architecture, for both small and large numbers of antennas, enables improved spectral efficiency FD communications with fewer analog cancellation elements compared to various benchmark schemes. The article is concluded with a list of open challenges and research directions for future FD massive MIMO communication systems and their promising applications.      
### 46.A High-Voltage Characterisation Platform For Emerging Resistive Switching Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2205.08391.pdf)
>  Emerging memristor-based array architectures have been effectively employed in non-volatile memories and neuromorphic computing systems due to their density, scalability and capability of storing information. Nonetheless, to demonstrate a practical on-chip memristor-based system, it is essential to have the ability to apply large programming voltage ranges during the characterisation procedures for various memristor technologies. This work presents a 16x16 high voltage memristor characterisation array employing high voltage CMOS circuitry. The proposed system has a maximum programming range of $\pm22V$ to allow on-chip electroforming and I-V sweep. In addition, a Kelvin voltage sensing system is implemented to improve the readout accuracy for low memristance measurements. This work addresses the limitation of conventional CMOS-memristor platforms which can only operate at low voltages, thus limiting the characterisation range and integration options of memristor technologies.      
### 47.A Wide Dynamic Range Read-out System For Resistive Switching Technology  [ :arrow_down: ](https://arxiv.org/pdf/2205.08381.pdf)
>  The memristor, because of its controllability over a wide dynamic range of resistance, has emerged as a promising device for data storage and analog computation. A major challenge is the accurate measurement of memristance over a wide dynamic range. In this paper, a novel read-out circuit with feedback adjustment is proposed to measure and digitise input current in the range between 20nA and 2mA. The magnitude of the input currents is estimated by a 5-stage logarithmic current-to-voltage amplifier which scales a linear analog-to-digital converter. This way the least significant bit tracks the absolute input magnitude. This circuit is applicable to reading single memristor conductance, and is also preferable in analog computing where read-out accuracy is particularly critical. The circuits have been realized in Bipolar-CMOS-DMOS (BCD) Gen2 technology.      
### 48.A CMOS-based Characterisation Platform for Emerging RRAM Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2205.08379.pdf)
>  Mass characterisation of emerging memory devices is an essential step in modelling their behaviour for integration within a standard design flow for existing integrated circuit designers. This work develops a novel characterisation platform for emerging resistive devices with a capacity of up to 1 million devices on-chip. Split into four independent sub-arrays, it contains on-chip column-parallel DACs for fast voltage programming of the DUT. On-chip readout circuits with ADCs are also available for fast read operations covering 5-decades of input current (20nA to 2mA). This allows a device's resistance range to be between 1k$\Omega$ and 10M$\Omega$ with a minimum voltage range of $\pm$1.5V on the device.      
### 49.Automatic Velocity Picking Using Unsupervised Ensemble Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.08372.pdf)
>  In seismic data processing, accurate and efficient automatic velocity picking algorithms can significantly accelerate the processing, and the main branch is to use velocity spectra for velocity pickup. Recently, machine learning algorithms have been widely used in automatic spectrum picking. Even though deep learning methods can address the problem well in supervised cases, they are often accompanied by expensive computational costs and low interpretability. On the contrast, unsupervised learning methods based on the physical knowledge have great potential to efficiently resolve the task. In this paper, we propose an unsupervised ensemble learning (UEL) method to pick the root mean square (RMS) velocities on the spectrum. In particular, UEL utilizes the information of nearby velocity spectra and the nearest seed velocity curve to assist the selection of effective and reasonable velocity points. To increase the coherence of energy peaks, an information gain method is developed by local normalization. In addition, we designed the attention scale-space filter (ASSF) clustering method to incorporate the coherence information into the picking process. Experiments on three datasets demonstrate that compared to traditional clustering methods, UEL can recognize energy clusters better, especially with smaller blobs. Moreover, the injection of nearby spectra and interval velocity constraint in UEL significantly improves the robustness and accuracy of picking results.      
### 50.Applications of Reinforcement Learning in Deregulated Power Market: A Comprehensive Review  [ :arrow_down: ](https://arxiv.org/pdf/2205.08369.pdf)
>  The increasing penetration of renewable generations, along with the deregulation and marketization of power industry, promotes the transformation of power market operation paradigms. The optimal bidding strategy and dispatching methodology under these new paradigms are prioritized concerns for both market participants and power system operators, with obstacles of uncertain characteristics, computational efficiency, as well as requirements of hyperopic decision-making. To tackle these problems, the Reinforcement Learning (RL), as an emerging machine learning technique with advantages compared with conventional optimization tools, is playing an increasingly significant role in both academia and industry. This paper presents a comprehensive review of RL applications in deregulated power market operation including bidding and dispatching strategy optimization, based on more than 150 carefully selected literatures. For each application, apart from a paradigmatic summary of generalized methodology, in-depth discussions of applicability and obstacles while deploying RL techniques are also provided. Finally, some RL techniques that have great potentiality to be deployed in bidding and dispatching problems are recommended and discussed.      
### 51.Deep Supervised Information Bottleneck Hashing for Cross-modal Retrieval based Computer-aided Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2205.08365.pdf)
>  Mapping X-ray images, radiology reports, and other medical data as binary codes in the common space, which can assist clinicians to retrieve pathology-related data from heterogeneous modalities (i.e., hashing-based cross-modal medical data retrieval), provides a new view to promot computeraided diagnosis. Nevertheless, there remains a barrier to boost medical retrieval accuracy: how to reveal the ambiguous semantics of medical data without the distraction of superfluous information. To circumvent this drawback, we propose Deep Supervised Information Bottleneck Hashing (DSIBH), which effectively strengthens the discriminability of hash codes. Specifically, the Deep Deterministic Information Bottleneck (Yu, Yu, and Principe 2021) for single modality is extended to the cross-modal scenario. Benefiting from this, the superfluous information is reduced, which facilitates the discriminability of hash codes. Experimental results demonstrate the superior accuracy of the proposed DSIBH compared with state-of-the-arts in cross-modal medical data retrieval tasks.      
### 52.Topological Signal Processing using the Weighted Ordinal Partition Network  [ :arrow_down: ](https://arxiv.org/pdf/2205.08349.pdf)
>  One of the most important problems arising in time series analysis is that of bifurcation, or change point detection. That is, given a collection of time series over a varying parameter, when has the structure of the underlying dynamical system changed? For this task, we turn to the field of topological data analysis (TDA), which encodes information about the shape and structure of data. The idea of utilizing tools from TDA for signal processing tasks, known as topological signal processing (TSP), has gained much attention in recent years, largely through a standard pipeline that computes the persistent homology of the point cloud generated by the Takens' embedding. However, this procedure is limited by computation time since the simplicial complex generated in this case is large, but also has a great deal of redundant data. For this reason, we turn to a more recent method for encoding the structure of the attractor, which constructs an ordinal partition network (OPN) representing information about when the dynamical system has passed between certain regions of state space. The result is a weighted graph whose structure encodes information about the underlying attractor. Our previous work began to find ways to package the information of the OPN in a manner that is amenable to TDA; however, that work only used the network structure and did nothing to encode the additional weighting information. In this paper, we take the next step: building a pipeline to analyze the weighted OPN with TDA and showing that this framework provides more resilience to noise or perturbations in the system and improves the accuracy of the dynamic state detection.      
### 53.Nonlinear Model Identification and Observer Design for Thrust Estimation of Small-scale Turbojet Engines  [ :arrow_down: ](https://arxiv.org/pdf/2205.08330.pdf)
>  Jet-powered vertical takeoff and landing (VTOL) drones require precise thrust estimation to ensure adequate stability margins and robust maneuvering. Small-scale turbojets have become good candidates for powering heavy aerial drones. However, due to limited instrumentation available in these turbojets, estimating the precise thrust using classical techniques is not straightforward. In this paper, we present a methodology to accurately estimate the online thrust for the small-scale turbojets used on the iRonCub - an aerial humanoid robot. We use a grey-box method to capture the turbojet system dynamics with a nonlinear state-space model based on the data acquired from a custom engine test bench. This model is then used to design an extended Kalman filter that estimates the turbojet thrust only from the angular speed measurements. We exploited the parameter estimation algorithm to ensure that the EKF gives smooth and accurate estimates even at engine failures. The designed EKF was validated on the test bench where the mean absolute error in estimated thrust was found to be within 2% of rated peak thrust.      
### 54.NOMA-aided Joint Communication, Sensing, and Multi-tier Computing Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.08272.pdf)
>  A non-orthogonal multiple access (NOMA)-aided joint communication, sensing, and multi-tier computing (JCSMC) framework is proposed. In this framework, a multi-functional base station (BS) carries out target sensing, while providing edge computing services to the nearby users. To enhance the computation efficiency, the multi-tier computing structure is exploited, where the BS can further offload the computation tasks to a powerful Cloud server (CS). The potential benefits of employing NOMA in the proposed JCSMC framework are investigated, which can maximize the computation offloading capacity and suppress the inter-function interference. Based on the proposed framework, the transmit beamformer of the BS and computation resource allocation at the BS and the CS are jointly optimized to maximize the computation rate subject to the communication-computation causality and the sensing quality constraints. Both partial and binary computation offloading modes are considered: 1) For the partial offloading mode, a weighted minimum mean square error based alternating optimization algorithm is proposed to solve the corresponding non-convex optimization problem. It is proved that a KKT optimal solution can be obtained; 2) For the binary offloading mode, the resultant highly-coupled mixed-integer optimization problem is first transformed to an equivalent but more tractable form. Then, the reformulated problem is solved by utilizing the alternating direction method of multipliers approach to obtain a nearly optimal solution. Finally, numerical results verify the effectiveness of the proposed algorithms and the proposed NOMA-aided JCSMC framework      
### 55.Contact-less Material Probing with Distributed Sensors: Joint Sensing and Communication Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2205.08263.pdf)
>  The utilization of RF signals to probe material properties of objects is of huge interest both in academia as well as industry. To this end, a setup is investigated, in which a transmitter equipped with a two-dimensional multi-antenna array dispatches a signal, which hits objects in the environment and the reflections from the objects are captured by distributed sensors. The received signal at those sensors are then amplified and forwarded to a multiple antenna fusion center, which performs space-time post-processing in order to optimize the information extraction. In this process, optimal design of power allocation per object alongside sensors amplifications is of crucial importance. Here, the power allocation and sensors amplifications is jointly optimized, given maximum-ratio combining (MRC) at the fusion center. We formulate this challenge as a sum-power minimization under per-object SINR constraints, a sum-power constraint at the transmitter and individual power constraints at the sensors. Moreover, the advantage of deploying zero-forcing (ZF) and minimum mean-squared error (MMSE) at the fusion center is discussed. Asymptotic analysis is also provided for the case that large number of sensors are deployed in the sensing environment.      
### 56.Outage Analysis of Energy Efficiency in a Finite-Element-IRS Aided Communication System  [ :arrow_down: ](https://arxiv.org/pdf/2205.08242.pdf)
>  In this paper, we study the performance of an energy efficient wireless communication system, assisted by a finite-element-intelligent reflecting surface (IRS). With no instantaneous channel state information (CSI) at the transmitter, we characterize the system performance in terms of the outage probability (OP) of energy efficiency (EE). Depending upon the availability of line-of-sight (LOS) paths, we analyze the system for two different channel models, viz. Rician and Rayleigh. For an arbitrary number of IRS elements $(N)$, we derive the approximate closed-form solutions for the OP of EE, using Laguerre series and moment matching methods. The analytical results are validated using the Monte-Carlo simulations. Moreover, we also quantify the rate of convergence of the derived expressions to the central limit theorem (CLT) approximations using the \textit{Berry-Esseen} inequality. Further, we prove that the OP of EE is a strict pseudo-convex function of the transmit power and hence, has a unique global minimum. To obtain the optimal transmit power, we solve the OP of EE as a constrained optimization problem. To the best of our knowledge, the OP of EE as a performance metric, has never been previously studied in IRS-assisted wireless communication systems.      
### 57.Initial non-invasive in vivo sensing of the lung using time domain diffuse optics  [ :arrow_down: ](https://arxiv.org/pdf/2205.08211.pdf)
>  Non-invasive in vivo sensing of the lung with light would help diagnose and monitor pulmonary disorders (caused by e.g. COVID-19, emphysema, immature lung tissue in infants). We investigated the possibility to probe the lung with time domain diffuse optics, taking advantage of the increased depth (few cm) reached by photons detected after a long (few ns) propagation time. An initial study on 5 healthy volunteers included time-resolved broadband diffuse optical spectroscopy measurements at 3 cm source-detector distance over the 600-1100 nm range, and long-distance (6-9 cm) measurements at 820 nm performed during a breathing protocol. The interpretation of the in vivo data with a simplified homogeneous model yielded a maximum probing depth of 2.6-3.9 cm, suitable to reach the lung. Also, signal changes related to the inspiration act were observed, especially at high photon propagation times. Yet, intra- and inter-subject variability and inconsistencies, possibly alluring to competing scattering and absorption effects, prevented a simple interpretation. Aspects to be further investigated to gain a deeper insight are discussed.      
### 58.blob loss: instance imbalance aware loss functions for semantic segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.08209.pdf)
>  Deep convolutional neural networks have proven to be remarkably effective in semantic segmentation tasks. Most popular loss functions were introduced targeting improved volumetric scores, such as the Sorensen Dice coefficient. By design, DSC can tackle class imbalance; however, it does not recognize instance imbalance within a class. As a result, a large foreground instance can dominate minor instances and still produce a satisfactory Sorensen Dice coefficient. Nevertheless, missing out on instances will lead to poor detection performance. This represents a critical issue in applications such as disease progression monitoring. For example, it is imperative to locate and surveil small-scale lesions in the follow-up of multiple sclerosis patients. We propose a novel family of loss functions, nicknamed blob loss, primarily aimed at maximizing instance-level detection metrics, such as F1 score and sensitivity. Blob loss is designed for semantic segmentation problems in which the instances are the connected components within a class. We extensively evaluate a DSC-based blob loss in five complex 3D semantic segmentation tasks featuring pronounced instance heterogeneity in terms of texture and morphology. Compared to soft Dice loss, we achieve 5 percent improvement for MS lesions, 3 percent improvement for liver tumor, and an average 2 percent improvement for Microscopy segmentation tasks considering F1 score.      
### 59.Design of saturated boundary control for hyperbolic systems with in-domain disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2205.08194.pdf)
>  Boundary feedback control design is studied for 1D hyperbolic systems with an in-domain disturbance and a boundary feedback controller under the effect of actuator saturation. Nonlinear semigroup theory is used to prove well-posedness of mild solution pairs to the closed-loop system. Sufficient conditions in the form of dissipation functional inequalities are derived to establish global stability for the closed-loop system and $\mathcal{L}^2$-stability in presence of in-domain disturbances. The control design problem is then recast as an optimization problem over linear matrix inequality constraints. Numerical results are shown to validate the effectiveness of the proposed control design.      
### 60.SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual Speech Representation  [ :arrow_down: ](https://arxiv.org/pdf/2205.08180.pdf)
>  We propose the SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual Speech Representation learning framework. Unlike previous works on speech representation learning, which learns multilingual contextual speech embedding at the resolution of an acoustic frame (10-20ms), this work focuses on learning multimodal (speech-text) multilingual speech embedding at the resolution of a sentence (5-10s) such that the embedding vector space is semantically aligned across different languages. We combine state-of-the-art multilingual acoustic frame-level speech representation learning model XLS-R with the Language Agnostic BERT Sentence Embedding (LaBSE) model to create an utterance-level multimodal multilingual speech encoder SAMU-XLSR. Although we train SAMU-XLSR with only multilingual transcribed speech data, cross-lingual speech-text and speech-speech associations emerge in its learned representation space. To substantiate our claims, we use SAMU-XLSR speech encoder in combination with a pre-trained LaBSE text sentence encoder for cross-lingual speech-to-text translation retrieval, and SAMU-XLSR alone for cross-lingual speech-to-speech translation retrieval. We highlight these applications by performing several cross-lingual text and speech translation retrieval tasks across several datasets.      
### 61.A Novel K-Repetition Design for SCMA  [ :arrow_down: ](https://arxiv.org/pdf/2205.08149.pdf)
>  This work presents a novel K-Repetition based HARQ scheme for LDPC coded uplink SCMA by employing a network coding (NC) principle to encode different packets, where K-Repetition is an emerging technique (recommended in 3GPP Release 15) for enhanced reliability and reduced latency in future massive machine-type communication. Such a scheme is referred to as the NC aided K-repetition SCMA (NCK-SCMA). We introduce a joint iterative detection algorithm for improved detection of the data from the proposed LDPC coded NCKSCMA systems. Simulation results demonstrate the benefits of NCK-SCMA with higher throughput and improved reliability over the conventional K-Repetition SCMA.      
### 62.Forecasting Solar Power Generation on the basis of Predictive and Corrective Maintenance Activities  [ :arrow_down: ](https://arxiv.org/pdf/2205.08109.pdf)
>  Solar energy forecasting has seen tremendous growth in the last decade using historical time series collected from a weather station, such as weather variables wind speed and direction, solar radiance, and temperature. It helps in the overall management of solar power plants. However, the solar power plant regularly requires preventive and corrective maintenance activities that further impact energy production. This paper presents a novel work for forecasting solar power energy production based on maintenance activities, problems observed at a power plant, and weather data. The results accomplished on the datasets obtained from the 1MW solar power plant of PDEU (our university) that has generated data set with 13 columns as daily entries from 2012 to 2020. There are 12 structured columns and one unstructured column with manual text entries about different maintenance activities, problems observed, and weather conditions daily. The unstructured column is used to create a new feature column vector using Hash Map, flag words, and stop words. The final dataset comprises five important feature vector columns based on correlation and causality analysis.      
### 63.Robust Perception Architecture Design for Automotive Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.08067.pdf)
>  In emerging automotive cyber-physical systems (CPS), accurate environmental perception is critical to achieving safety and performance goals. Enabling robust perception for vehicles requires solving multiple complex problems related to sensor selection/ placement, object detection, and sensor fusion. Current methods address these problems in isolation, which leads to inefficient solutions. We present PASTA, a novel framework for global co-optimization of deep learning and sensing for dependable vehicle perception. Experimental results with the Audi-TT and BMW-Minicooper vehicles show how PASTA can find robust, vehicle-specific perception architecture solutions.      
### 64.Classification of anatomic structures in head and neck by CT-based radiomics  [ :arrow_down: ](https://arxiv.org/pdf/2205.08054.pdf)
>  Background and Purpose: Radiomics features are used to identify disease types and predict therapy outcomes. However, how the radiomics features are different among different anatomical structures has never been investigated. Hence, we analyzed the radiomics features of 22 anatomical structures in the head and neck area in CT images. Furthermore, we studied whether CT radiomics can classify anatomical structures of the head and neck using unsupervised machine-learning techniques. Materials and methods: We obtained IMRT/VMAT treatment planning data from 36 patients treated for head and neck cancers in a single institution. There were 1357 contours of more than 22 anatomical structures drawn on planning CTs. We calculated 174 radiomics features using the SIBEX program. First, we tested whether the radiomics features of anatomical structures were unique enough to classify all contours into 22 groups. We then developed a two-stage clustering technique to classify 22 anatomic structures into sub-groups with similar physiological or biological characteristics. Results: The heatmap of 174 radiomics features of 22 anatomical structures showed a distinct difference among tumors and other healthy structures. Radiomics features have allowed us to identify the eyes, lens, submandibular, pituitary glands, and thyroids with over 90% accuracy. The two-stage clustering of 22 structures resulted in six subgroups, which shared common characteristics such as fatty and bony tissues. Conclusions: We have shown that anatomical structures in head and neck tumors have distinguishable radiomics features. We could observe similarities of features among subgroups of the structures. The results suggest that CT radiomics can help distinguish the biological characteristics of head and neck lesions.      
### 65.Detection and Physical Interaction with Deformable Linear Objects  [ :arrow_down: ](https://arxiv.org/pdf/2205.08041.pdf)
>  Deformable linear objects (e.g., cables, ropes, and threads) commonly appear in our everyday lives. However, perception of these objects and the study of physical interaction with them is still a growing area. There have already been successful methods to model and track deformable linear objects. However, the number of methods that can automatically extract the initial conditions in non-trivial situations for these methods has been limited, and they have been introduced to the community only recently. On the other hand, while physical interaction with these objects has been done with ground manipulators, there have not been any studies on physical interaction and manipulation of the deformable linear object with aerial robots. <br>This workshop describes our recent work on detecting deformable linear objects, which uses the segmentation output of the existing methods to provide the initialization required by the tracking methods automatically. It works with crossings and can fill the gaps and occlusions in the segmentation and output the model desirable for physical interaction and simulation. Then we present our work on using the method for tasks such as routing and manipulation with the ground and aerial robots. We discuss our feasibility analysis on extending the physical interaction with these objects to aerial manipulation applications.      
### 66.Newton and interior-point methods for (constrained) nonconvex-nonconcave minmax optimization with stability guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2205.08038.pdf)
>  We address the problem of finding a local solution to a nonconvex-nonconcave minmax optimization using Newton type methods, including interior-point ones. We modify the Hessian matrix of these methods such that, at each step, the modified Newton update direction can be seen as the solution to a quadratic program that locally approximates the minmax problem. Moreover, we show that by selecting the modification in an appropriate way, the only stable points of the algorithm's iterations are local minmax points. Using numerical examples, we show that the computation time of our algorithm scales roughly linearly with the number of nonzero elements in the Hessian. For minmax control problems with per-stage costs, this generally leads to computation times that scale linearly with the horizon length.      
### 67.Perceptual Evaluation on Audio-visual Dataset of 360 Content  [ :arrow_down: ](https://arxiv.org/pdf/2205.08007.pdf)
>  To open up new possibilities to assess the multimodal perceptual quality of omnidirectional media formats, we proposed a novel open source 360 audiovisual (AV) quality dataset. The dataset consists of high-quality 360 video clips in equirectangular (ERP) format and higher-order ambisonic (4th order) along with the subjective scores. Three subjective quality experiments were conducted for audio, video, and AV with the procedures detailed in this paper. Using the data from subjective tests, we demonstrated that this dataset can be used to quantify perceived audio, video, and audiovisual quality. The diversity and discriminability of subjective scores were also analyzed. Finally, we investigated how our dataset correlates with various objective quality metrics of audio and video. Evidence from the results of this study implies that the proposed dataset can benefit future studies on multimodal quality evaluation of 360 content.      
### 68.Quality versus speed in energy demand prediction for district heating systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.07863.pdf)
>  In this paper, we consider energy demand prediction in district heating systems. Effective energy demand prediction is essential in combined heat power systems when offering electrical energy in competitive electricity markets. To address this problem, we propose two sets of algorithms: (1) a novel extension to the algorithm proposed by E. Dotzauer and (2) an autoregressive predictor based on hour-of-week adjusted linear regression on moving averages of energy consumption. These two methods are compared against state-of-the-art artificial neural networks. Energy demand predictor algorithms have various computational costs and prediction quality. While prediction quality is a widely used measure of predictor superiority, computational costs are less frequently analyzed and their impact is not so extensively studied. When predictor algorithms are constantly updated using new data, some computationally expensive forecasting methods may become inapplicable. The computational costs can be split into training and execution parts. The execution part is the cost paid when the already trained algorithm is applied to predict something. In this paper, we evaluate the above methods with respect to the quality and computational costs, both in the training and in the execution. The comparison is conducted on a real-world dataset from a district heating system in the northwest part of Poland.      
### 69.A Safety Assurable Human-Inspired Perception Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2205.07862.pdf)
>  Although artificial intelligence-based perception (AIP) using deep neural networks (DNN) has achieved near human level performance, its well-known limitations are obstacles to the safety assurance needed in autonomous applications. These include vulnerability to adversarial inputs, inability to handle novel inputs and non-interpretability. While research in addressing these limitations is active, in this paper, we argue that a fundamentally different approach is needed to address them. Inspired by dual process models of human cognition, where Type 1 thinking is fast and non-conscious while Type 2 thinking is slow and based on conscious reasoning, we propose a dual process architecture for safe AIP. We review research on how humans address the simplest non-trivial perception problem, image classification, and sketch a corresponding AIP architecture for this task. We argue that this architecture can provide a systematic way of addressing the limitations of AIP using DNNs and an approach to assurance of human-level performance and beyond. We conclude by discussing what components of the architecture may already be addressed by existing work and what remains future work.      
### 70.Functional2Structural: Cross-Modality Brain Networks Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2205.07854.pdf)
>  MRI-based modeling of brain networks has been widely used to understand functional and structural interactions and connections among brain regions, and factors that affect them, such as brain development and disease. Graph mining on brain networks may facilitate the discovery of novel biomarkers for clinical phenotypes and neurodegenerative diseases. Since brain networks derived from functional and structural MRI describe the brain topology from different perspectives, exploring a representation that combines these cross-modality brain networks is non-trivial. Most current studies aim to extract a fused representation of the two types of brain network by projecting the structural network to the functional counterpart. Since the functional network is dynamic and the structural network is static, mapping a static object to a dynamic object is suboptimal. However, mapping in the opposite direction is not feasible due to the non-negativity requirement of current graph learning techniques. Here, we propose a novel graph learning framework, known as Deep Signed Brain Networks (DSBN), with a signed graph encoder that, from an opposite perspective, learns the cross-modality representations by projecting the functional network to the structural counterpart. We validate our framework on clinical phenotype and neurodegenerative disease prediction tasks using two independent, publicly available datasets (HCP and OASIS). The experimental results clearly demonstrate the advantages of our model compared to several state-of-the-art methods.      
