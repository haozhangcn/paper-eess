# ArXiv eess --Mon, 9 May 2022
### 1.Multi-mode Tensor Train Factorization with Spatial-spectral Regularization for Remote Sensing Images Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2205.03380.pdf)
>  Tensor train (TT) factorization and corresponding TT rank, which can well express the low-rankness and mode correlations of higher-order tensors, have attracted much attention in recent years. However, TT factorization based methods are generally not sufficient to characterize low-rankness along each mode of third-order tensor. Inspired by this, we generalize the tensor train factorization to the mode-k tensor train factorization and introduce a corresponding multi-mode tensor train (MTT) rank. Then, we proposed a novel low-MTT-rank tensor completion model via multi-mode TT factorization and spatial-spectral smoothness regularization. To tackle the proposed model, we develop an efficient proximal alternating minimization (PAM) algorithm. Extensive numerical experiment results on visual data demonstrate that the proposed MTTD3R method outperforms compared methods in terms of visual and quantitative measures.      
### 2.On state-space representations of general discrete-time dynamical systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.03366.pdf)
>  In this paper we establish that every (deterministic) non-autonomous, discrete-time, causal, time invariant system has a state-space representation, and discuss its minimality.      
### 3.Human Tracking with mmWave Radars: a Deep Learning Approach with Uncertainty Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2205.03274.pdf)
>  mmWave radars have recently gathered significant attention as a means to track human movement within indoor environments. Widely adopted Kalman filter tracking methods experience performance degradation when the underlying movement is highly non-linear or presents long-term temporal dependencies. As a solution, in this article we design a convolutional-recurrent Neural Network (NN) that learns to accurately estimate the position and the velocity of the monitored subjects from high dimensional radar data. The NN is trained as a probabilistic model, utilizing a Gaussian negative log-likelihood loss function, obtaining explicit uncertainty estimates at its output, in the form of time-varying error covariance matrices. A thorough experimental assessment is conducted using a 77 GHz FMCW radar. The proposed architecture, besides allowing one to gauge the uncertainty in the tracking process, also leads to greatly improved performance against the best approaches from the literature, i.e., Kalman filtering, lowering the average error against the ground truth from 32.8 to 7.59 cm and from 56.8 to 14 cm/s in terms of position and velocity tracking, respectively.      
### 4.STEAM++ An Extensible End-To-End Framework for Developing IoT Data Processing Applications in the Fog  [ :arrow_down: ](https://arxiv.org/pdf/2205.03271.pdf)
>  IoT applications usually rely on cloud computing services to perform data analysis such as filtering, aggregation, classification, pattern detection, and prediction. When applied to specific domains, the IoT needs to deal with unique constraints. Besides the hostile environment such as vibration and electric-magnetic interference, resulting in malfunction, noise, and data loss, industrial plants often have Internet access restricted or unavailable, forcing us to design stand-alone fog and edge computing solutions. In this context, we present STEAM++, a lightweight and extensible framework for real-time data stream processing and decision-making in the network edge, targeting hardware-limited devices, besides proposing a micro-benchmark methodology for assessing embedded IoT applications. In real-case experiments in a semiconductor industry, we processed an entire data flow, from values sensing, processing and analyzing data, detecting relevant events, and finally, publishing results to a dashboard. On average, the application consumed less than 500kb RAM and 1.0% of CPU usage, processing up to 239 data packets per second and reducing the output data size to 14% of the input raw data size when notifying events.      
### 5.SPARCS: A Sparse Recovery Approach for Integrated Communication and Human Sensing in mmWave Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.03263.pdf)
>  A well established method to detect and classify human movements using Millimeter-Wave ( mmWave) devices is the time-frequency analysis of the small-scale Doppler effect (termed micro-Doppler) of the different body parts, which requires a regularly spaced and dense sampling of the Channel Impulse Response ( CIR). This is currently done in the literature either using special-purpose radar sensors, or interrupting communications to transmit dedicated sensing waveforms, entailing high overhead and channel utilization. In this work we present SPARCS, an integrated human sensing and communication solution for mmWave systems. SPARCS is the first method that reconstructs high quality signatures of human movement from irregular and sparse CIR samples, such as the ones obtained during communication traffic patterns. To accomplish this, we formulate the micro-Doppler extraction as a sparse recovery problem, which is critical to enable a smooth integration between communication and sensing. Moreover, if needed, our system can seamlessly inject short CIR estimation fields into the channel whenever communication traffic is absent or insufficient for the micro-Doppler extraction. SPARCS effectively leverages the intrinsic sparsity of the mmWave channel, thus drastically reducing the sensing overhead with respect to available approaches. We implemented SPARCS on an IEEE 802.11ay Software Defined Radio (SDR) platform working in the 60 GHz band, collecting standard-compliant CIR traces matching the traffic patterns of real WiFi access points. Our results show that the micro-Doppler signatures obtained by SPARCS enable a typical downstream application such as human activity recognition with more than 7 times lower overhead with respect to existing methods, while achieving better recognition performance.      
### 6.Integration of NOMA with Reflecting Intelligent Surfaces: A Multi-cell Optimization with SIC Decoding Errors  [ :arrow_down: ](https://arxiv.org/pdf/2205.03248.pdf)
>  Reflecting intelligent surfaces (RIS) has recently emerged as one of the promising technologies for achieving high energy and spectral efficiency in next-generation wireless networks. By using low-cost passive reflecting elements, RIS can smartly reconfigure the signal propagation to extend the wireless communication coverage. On the other side, Non-orthogonal multiple access (NOMA) has been proved as a key air interface technique for supporting massive connections over limited resources. This letter proposes a new optimization framework for the multicell RIS-NOMA network. In particular, we address the system spectral efficiency maximization with successive interference cancellation (SIC) decoding errors. The closed-form expressions of transmit power at the base station and power allocation coefficients of users are derived using Karush-Kuhn-Tucker conditions. Moreover, an efficient reflection matrix for RIS in each cell is designed using successive convex approximation and DC programming. Simulation results are provided to demonstrate the benefits of the proposed optimization in the multi-cell RISNOMA network.      
### 7.Electrocardiographic Deep Learning for Predicting Post-Procedural Mortality  [ :arrow_down: ](https://arxiv.org/pdf/2205.03242.pdf)
>  Background. Pre-operative risk assessments used in clinical practice are limited in their ability to identify risk for post-operative mortality. We hypothesize that electrocardiograms contain hidden risk markers that can help prognosticate post-operative mortality. Methods. In a derivation cohort of 45,969 pre-operative patients (age 59+- 19 years, 55 percent women), a deep learning algorithm was developed to leverage waveform signals from pre-operative ECGs to discriminate post-operative mortality. Model performance was assessed in a holdout internal test dataset and in two external hospital cohorts and compared with the Revised Cardiac Risk Index (RCRI) score. Results. In the derivation cohort, there were 1,452 deaths. The algorithm discriminates mortality with an AUC of 0.83 (95% CI 0.79-0.87) surpassing the discrimination of the RCRI score with an AUC of 0.67 (CI 0.61-0.72) in the held out test cohort. Patients determined to be high risk by the deep learning model's risk prediction had an unadjusted odds ratio (OR) of 8.83 (5.57-13.20) for post-operative mortality as compared to an unadjusted OR of 2.08 (CI 0.77-3.50) for post-operative mortality for RCRI greater than 2. The deep learning algorithm performed similarly for patients undergoing cardiac surgery with an AUC of 0.85 (CI 0.77-0.92), non-cardiac surgery with an AUC of 0.83 (0.79-0.88), and catherization or endoscopy suite procedures with an AUC of 0.76 (0.72-0.81). The algorithm similarly discriminated risk for mortality in two separate external validation cohorts from independent healthcare systems with AUCs of 0.79 (0.75-0.83) and 0.75 (0.74-0.76) respectively. Conclusion. The findings demonstrate how a novel deep learning algorithm, applied to pre-operative ECGs, can improve discrimination of post-operative mortality.      
### 8.Characterizing TMS-EEG perturbation indexes using signal energy: initial study on Alzheimer's Disease classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.03241.pdf)
>  Transcranial Magnetic Stimulation (TMS) combined with EEG recordings (TMS-EEG) has shown great potential in the study of the brain and in particular of Alzheimer's Disease (AD). In this study, we propose an automatic method of determining the duration of TMS induced perturbation of the EEG signal as a potential metric reflecting the brain's functional alterations. A preliminary study is conducted in patients with Alzheimer's disease (AD). Three metrics for characterizing the strength and duration of TMS evoked EEG (TEP) activity are proposed and their potential in identifying AD patients from healthy controls was investigated. A dataset of TMS-EEG recordings from 17 AD and 17 healthy controls (HC) was used in our analysis. A Random Forest classification algorithm was trained on the extracted TEP metrics and its performance is evaluated in a leave-one-subject-out cross-validation. The created model showed promising results in identifying AD patients from HC with an accuracy, sensitivity and specificity of 69.32%, 72.23% and 66.41%, respectively.      
### 9.A 2D-programmable and Scalable RIS Remotely Controlled via Digital Infrared Code  [ :arrow_down: ](https://arxiv.org/pdf/2205.03240.pdf)
>  Reconfigurable Intelligent Surfaces (RISs) are promising and relatively low-cost tools for improving signal propagation in wireless communications. An RIS assists a base station in optimizing the channel and maximizing its capacity by dynamically manipulating with reflected field. Typically, RISs are based on dynamically reconfigurable reflectarrays, i.e. two-dimensional arrays of passive patch antennas, individually switchable between two or more reflection phases. Different communication scenarios and environments require RISs to provide a different spatial resolution of reflected field patterns, which depends on the aperture dimensions and the number of patches. Here we demonstrate a 1-bit RIS for 5-GHz Wi-Fi band made by assembling together multiple independently operating building blocks all powered by the same DC source. Each block contains four separately phase-switchable patch antennas with varactor diodes and a common microcontroller extracting digital control commands from modulated infrared light illuminating the entire RIS. Such distributed light-sensitive controllers grant the possibility of scaling the aperture by adding or removing blocks without re-designing any control circuitry. Moreover, in the proposed RIS a full 2D phase encoding capability is achieved along with a robust remote infrared control.      
### 10.Multichannel Synthetic Preictal EEG Signals to Enhance the Prediction of Epileptic Seizures  [ :arrow_down: ](https://arxiv.org/pdf/2205.03239.pdf)
>  Epilepsy is a chronic neurological disorder affecting 1\% of people worldwide, deep learning (DL) algorithms-based electroencephalograph (EEG) analysis provides the possibility for accurate epileptic seizure (ES) prediction, thereby benefiting patients suffering from epilepsy. To identify the preictal region that precedes the onset of seizure, a large number of annotated EEG signals are required to train DL algorithms. However, the scarcity of seizure onsets leads to significant insufficiency of data for training the DL algorithms. To overcome this data insufficiency, in this paper, we propose a preictal artificial signal synthesis algorithm based on a generative adversarial network to generate synthetic multichannel EEG preictal samples. A high-quality single-channel architecture, determined by visual and statistical evaluations, is used to train the generators of multichannel samples. The effectiveness of the synthetic samples is evaluated by comparing the ES prediction performances without and with synthetic preictal sample augmentation. The leave-one-seizure-out cross validation ES prediction accuracy and corresponding area under the receiver operating characteristic curve evaluation improve from 73.0\% and 0.676 to 78.0\% and 0.704 by 10$\times$ synthetic sample augmentation, respectively. The obtained results indicate that synthetic preictal samples are effective for enhancing ES prediction performance.      
### 11.Ultra-sensitive Flexible Sponge-Sensor Array for Muscle Activities Detection and Human Limb Motion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2205.03238.pdf)
>  Human limb motion tracking and recognition plays an important role in medical rehabilitation training, lower limb assistance, prosthetics design for amputees, feedback control for assistive robots, etc. Lightweight wearable sensors, including inertial sensors, surface electromyography sensors, and flexible strain/pressure, are promising to become the next-generation human motion capture devices. Herein, we present a wireless wearable device consisting of a sixteen-channel flexible sponge-based pressure sensor array to recognize various human lower limb motions by detecting contours on the human skin caused by calf gastrocnemius muscle actions. Each sensing element is a round porous structure of thin carbon nanotube/polydimethylsiloxane nanocomposites with a diameter of 4 mm and thickness of about 400 {\mu}m. Three human subjects were recruited to perform ten different lower limb motions while wearing the developed device. The motion classification result with the support vector machine method shows a macro-recall of about 94.48% for all ten motions tested. This work demonstrates a portable wearable muscle activity detection device with a lower limb motion recognition application, which can be potentially used in assistive robot control, healthcare, sports monitoring, etc.      
### 12.A CNN Approach for 5G mmWave Positioning Using Beamformed CSI Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2205.03236.pdf)
>  The advent of Artificial Intelligence (AI) has impacted all aspects of human life. One of the concrete examples of AI impact is visible in radio positioning. In this article, for the first time we utilize the power of AI by training a Convolutional Neural Network (CNN) using 5G New Radio (NR) fingerprints consisting of beamformed Channel State Information (CSI). By observing CSI, it is possible to characterize the multipath channel between the transmitter and the receiver, and thus provide a good source of spatiotemporal data to find the position of a User Equipment (UE). We collect ray-tracing-based 5G NR CSI from an urban area. The CSI data of the signals from one Base Station (BS) is collected at the reference points with known positions to train a CNN. We evaluate our work by testing: a) the robustness of the trained network for estimating the positions for the new measurements on the same reference points and b) the accuracy of the CNN-based position estimation while the UE is on points other than the reference points. The results prove that our trained network for a specific urban environment can estimate the UE position with a minimum mean error of 0.98 m.      
### 13.Real Time On Sensor Gait Phase Detection with 0.5KB Deep Learning Model  [ :arrow_down: ](https://arxiv.org/pdf/2205.03234.pdf)
>  Gait phase detection with convolution neural network provides accurate classification but demands high computational cost, which inhibits real time low power on-sensor processing. This paper presents a segmentation based gait phase detection with a width and depth downscaled U-Net like model that only needs 0.5KB model size and 67K operations per second with 95.9% accuracy to be easily fitted into resource limited on sensor microcontroller.      
### 14.Side-aware Meta-Learning for Cross-Dataset Listener Diagnosis with Subjective Tinnitus  [ :arrow_down: ](https://arxiv.org/pdf/2205.03231.pdf)
>  With the development of digital technology, machine learning has paved the way for the next generation of tinnitus diagnoses. Although machine learning has been widely applied in EEG-based tinnitus analysis, most current models are dataset-specific. Each dataset may be limited to a specific range of symptoms, overall disease severity, and demographic attributes; further, dataset formats may differ, impacting model performance. This paper proposes a side-aware meta-learning for cross-dataset tinnitus diagnosis, which can effectively classify tinnitus in subjects of divergent ages and genders from different data collection processes. Owing to the superiority of meta-learning, our method does not rely on large-scale datasets like conventional deep learning models. Moreover, we design a subject-specific training process to assist the model in fitting the data pattern of different patients or healthy people. Our method achieves a high accuracy of 73.8\% in the cross-dataset classification. We conduct an extensive analysis to show the effectiveness of side information of ears in enhancing model performance and side-aware meta-learning in improving the quality of the learned features.      
### 15.Disentangled and Side-aware Unsupervised Domain Adaptation for Cross-dataset Subjective Tinnitus Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2205.03230.pdf)
>  EEG-based tinnitus classification is a valuable tool for tinnitus diagnosis, research, and treatments. Most current works are limited to a single dataset where data patterns are similar. But EEG signals are highly non-stationary, resulting in model's poor generalization to new users, sessions or datasets. Thus, designing a model that can generalize to new datasets is beneficial and indispensable. To mitigate distribution discrepancy across datasets, we propose to achieve Disentangled and Side-aware Unsupervised Domain Adaptation (DSUDA) for cross-dataset tinnitus diagnosis. A disentangled auto-encoder is developed to decouple class-irrelevant information from the EEG signals to improve the classifying ability. The side-aware unsupervised domain adaptation module adapts the class-irrelevant information as domain variance to a new dataset and excludes the variance to obtain the class-distill features for the new dataset classification. It also align signals of left and right ears to overcome inherent EEG pattern difference. We compare DSUDA with state-of-the-art methods, and our model achieves significant improvements over competitors regarding comprehensive evaluation criteria. The results demonstrate our model can successfully generalize to a new dataset and effectively diagnose tinnitus.      
### 16.Multi-core fiber enabled fading noise suppression in Ï•-OFDR based quantitative distributed vibration sensing  [ :arrow_down: ](https://arxiv.org/pdf/2205.03229.pdf)
>  Coherent fading has been regarded as a critical issue in phase-sensitive optical frequency domain reflectometry ({\phi}-OFDR) based distributed fiber-optic sensing. Here, we report on an approach for fading noise suppression in {\phi}-OFDR with multi-core fiber. By exploiting the independent nature of the randomness in the distribution of reflective index in each of the cores, the drastic phase fluctuations due to the fading phenomina can be effectively alleviated by applying weighted vectorial averaging for the Rayleigh backscattering traces from each of the cores with distinct fading distributions. With the consistent linear response with respect to external excitation of interest for each of the cores, demonstration for the propsoed {\phi}-OFDR with a commercial seven-core fiber has achieved highly sensitive quantitative distributed vibration sensing with about 2.2 nm length precision and 2 cm sensing resolution along the 500 m fiber, corresponding to a range resolution factor as high as about about 4E-5. Featuring long distance, high sensitivity, high resolution, and fading robustness, this approach has shown promising potentials in various sensing techniques for a wide range of practical scenarios.      
### 17.Multiple-access relay stations for long-haul fiber-optic radio frequency transfer  [ :arrow_down: ](https://arxiv.org/pdf/2205.03225.pdf)
>  We report on the realization of a long-haul radio frequency (RF) transfer scheme by using multiple-access relay stations (MARSs). The proposed scheme with independent link noise compensation for each fiber sub-link effectively solves the limitation of compensation bandwidth for long-haul transfer. The MARS can have the capability to share the same modulated optical signal for the front and rear fiber sub-links, simplifying the configuration at the repeater station and enabling the transfer system to have the multiple-access capability. At the same time, we for the first time theoretically model the effect of the MARS position on the fractional frequency instability of the fiber-optic RF transfer, demonstrating that the MARS position has little effect on system's performance when the ratio of the front and rear fiber sub-links is around $1:1$. We experimentally demonstrate a 1 GHz signal transfer by using one MARS connecting 260 and 280 km fiber links with the fractional frequency instabilities of less than $5.9\times10^{-14}$ at 1 s and $8.5\times10^{-17}$ at 10,000 s at the remote site and of $5.6\times10^{-14}$ and $6.6\times10^{-17}$ at the integration times of 1 s and 10,000 s at the MARS. The proposed scalable technique can arbitrarily add the same MARSs in the fiber link, which has great potential in realizing ultra-long-haul RF transfer.      
### 18.Internet of Things and Health Care in Pandemic COVID-19: System Requirements Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2205.03220.pdf)
>  Technology adoption in healthcare services has resulted in advancing care delivery services and improving the experiences of patients. This paper presents research that aims to find the important requirements for a remote monitoring system for patients with COVID-19. As this pandemic is growing more and more, there is a critical need for such systems. In this paper, the requirements and the value are determined for the proposed system, which integrates a smart bracelet that helps to signal patient vital signs. (376) participants completed the online quantitative survey. According to the study results, Most Healthcare Experts, (97.9%) stated that the automated wearable device is very useful, it plays an essential role in routine healthcare tasks (in early diagnosis, quarantine enforcement, and patient status monitoring), and it simplifies their routine healthcare activities. I addition, the main vital signs based on their expert opinion should include temperature (66% of participants) and oxygenation level (95% of participants). These findings are essential to any academic and industrial future efforts to develop these vital wearable systems. The future work will involve implementing the design based on the results of this study and use machine-learning algorithm to better detect the COVID-19 cases based on the monitoring of vital signs and symptoms.      
### 19.Modularized Bilinear Koopman Operator for Modeling and Predicting Transients of Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2205.03214.pdf)
>  Modularized Koopman Bilinear Form (M-KBF) is presented to model and predict the transient dynamics of microgrids in the presence of disturbances. As a scalable data-driven approach, M-KBF divides the identification and prediction of the high-dimensional nonlinear system into the individual study of subsystems; and thus, alleviating the difficulty of intensively handling high volume data and overcoming the curse of dimensionality. For each subsystem, Koopman bilinear form is applied to efficiently identify its model by developing eigenfunctions via the extended dynamic mode decomposition method with an eigenvalue-based order truncation. Extensive tests show that M-KBF can provide accurate transient dynamics prediction for the nonlinear microgrids and verify the plug-and-play modeling and prediction function, which offers a potent tool for identifying high-dimensional systems. The modularity feature of M-KBF enables the provision of fast and precise prediction for the microgrid operation and control, paving the way towards online applications.      
### 20.Hybrid Beamforming Design for Millimeter Wave Multiuser MIMO Systems with Dynamic Subarrays  [ :arrow_down: ](https://arxiv.org/pdf/2205.03206.pdf)
>  In this letter, we investigate the millimeter wave (mmWave) downlink multiuser multiple-input multiple-output (MU-MIMO) system, adopting the dynamic subarray architecture at the base station and considering the multi-stream communication for each user. Aiming at maximizing the system spectral efficiency, we propose a novel hybrid beamforming design. First, assuming no inter-user interference (IUI), we easily get the optimal fully-digital beamformers and combiners using the singular value decomposition of each user channel and the waterfilling algorithm. Then, based on the obtained fullydigital beamformers, we propose a Kuhn-Munkres algorithmassisted dynamic hybrid beamforming design, which guarantees that each radio-frequency chain is connected to at least one antenna. Finally, we propose to further project each obtained digital beamformer onto the null space of all the other equivalent user channels to cancel the IUI. Numerical results verify the superiority of our proposed hybrid beamforming design.      
### 21.Analysis of Load-Altering Attacks Against Power Grids: A Rare-Event Sampling Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.03201.pdf)
>  By manipulating tens of thousands of internet-of-things (IoT) enabled high-wattage electrical appliances (e.g., WiFi-controlled air-conditioners), large-scale load-altering attacks (LAAs) can cause severe disruptions to power grid operations. In this work, we present a rare-event sampling approach to identify LAAs that lead to critical network failure events (defined by the activation of a power grid emergency response (ER)). The proposed sampler is designed to "skip" over LAA instances that are of little interest (i.e., those that do not trigger network failure), thus significantly reducing the computational complexity in identifying the impactful LAAs. We perform extensive simulations of LAAs using the Kundur two-area system (KTAS) power network while employing the rare-event sampler. The results help us identify the victim nodes from which the attacker can launch the most impactful attacks and provide insights into how the spatial distribution of LAAs triggers the activation of ERs.      
### 22.Federated Channel Learning for Intelligent Reflecting Surfaces With Fewer Pilot Signals  [ :arrow_down: ](https://arxiv.org/pdf/2205.03196.pdf)
>  Channel estimation is a critical task in intelligent reflecting surface (IRS)-assisted wireless systems due to the uncertainties imposed by environment dynamics and rapid changes in the IRS configuration. To deal with these uncertainties, deep learning (DL) approaches have been proposed. Previous works consider centralized learning (CL) approach for model training, which entails the collection of the whole training dataset from the users at the base station (BS), hence introducing huge transmission overhead for data collection. To address this challenge, this paper proposes a federated learning (FL) framework to jointly estimate both direct and cascaded channels in IRS-assisted wireless systems. We design a single convolutional neural network trained on the local datasets of the users without sending them to the BS. We show that the proposed FL-based channel estimation approach requires approximately 60% fewer pilot signals and it exhibits 12 times lower transmission overhead than CL, while maintaining satisfactory performance close to CL. In addition, it provides lower estimation error than the state-of-the-art DL-based schemes.      
### 23.Linearly discounted economic MPC without terminal conditions for periodic optimal operation  [ :arrow_down: ](https://arxiv.org/pdf/2205.03118.pdf)
>  In this work, we study economic model predictive control (MPC) in situations where the optimal operating behavior is periodic. In such a setting, the performance of a plain economic MPC scheme without terminal conditions can generally be far from optimal even with arbitrarily long prediction horizons. Whereas there are modified economic MPC schemes that guarantee optimal performance, all of them are based on prior knowledge of the optimal period length or of the optimal periodic orbit itself. In contrast to these approaches, we propose to achieve optimality by multiplying the stage cost by a linear discount factor. This modification is not only easy to implement but also independent of any system- or cost-specific properties, making the scheme robust against online changes therein. Under standard dissipativity and controllability assumptions, we can prove that the resulting linearly discounted economic MPC without terminal conditions achieves optimal asymptotic average performance up to an error that vanishes with growing prediction horizons. Moreover, we can guarantee practical asymptotic stability of the optimal periodic orbit under slightly stronger assumptions. We complement these qualitative guarantees with a quantitative analysis of the transient and asymptotic average performance of the linearly discounted MPC scheme in a numerical simulation study.      
### 24.Quaternion-based attitude stabilization via discrete-time IDA-PBC  [ :arrow_down: ](https://arxiv.org/pdf/2205.03086.pdf)
>  In this paper, we propose a new sampled-data controller for stabilization of the attitude dynamics at a desired constant configuration. The design is based on discrete-time interconnection and damping assignment (IDA) passivity-based control (PBC) and the recently proposed Hamiltonian representation of discrete-time nonlinear dynamics. Approximate solutions are provided with simulations illustrating performances.      
### 25.Energy Efficient Over-the-Air Computation for Correlated Data in Wireless Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2205.03080.pdf)
>  Over-the-air computation (AirComp) enables efficient wireless data aggregation in sensor networks by simultaneous processing of calculation and communication. This paper proposes a novel precoding method for AirComp that incorporates statistical properties of sensing data, spatial correlation and heterogeneous data correlation. The design of the proposed precoding matrix requires no iterative processes so that it can be realized with low computational costs. Moreover, this method provides dimensionality reduction of sensing data to reduce communication costs per sensor. We evaluate performance of the proposed method in terms of various system parameters. The results show the superiority of the proposed method to conventional non-iterative methods in cases where the number of receive antennas at the aggregator is less than that of the total transmit antennas at the sensors.      
### 26.Fast and Arbitrary Beam Pattern Design for RIS-Assisted Terahertz Wireless Communication  [ :arrow_down: ](https://arxiv.org/pdf/2205.02999.pdf)
>  Reconfigurable intelligent surface (RIS) can assist terahertz wireless communication to restore the fragile line-of-sight links and facilitate beam steering. Arbitrary reflection beam patterns are desired to meet diverse requirements in different applications. This paper establishes relationship between RIS beam pattern design with two-dimensional finite impulse response filter design and proposes a fast non-iterative algorithm to solve the problem. Simulations show that the proposed method outperforms baseline method. Hence, it represents a promising solution for fast and arbitrary beam pattern design in RIS-assisted terahertz wireless communication.      
### 27.Age Minimization in Outdoor and Indoor Communications with Relay-aided Dual RIS  [ :arrow_down: ](https://arxiv.org/pdf/2205.02991.pdf)
>  In this paper, we investigate an outdoor and indoor wireless communication network with the assistance of a novel relay-aided double-sided reconfigurable intelligent surface (RIS). A scheduling problem is considered at the outdoor access point (AP) to minimize the sum of age of information (AoI). To serve the indoor users and further enhance the wireless link quality, a novel double-sided RIS with relay is utilized. Since the formulated problem is non-convex with highly-coupled variables, a successive convex approximation (SCA) based alternating optimization (AO) algorithm is proposed to solve it in an iterative manner. Finally, simulation results show the effectiveness and significant performance improvement in terms of AoI of the proposed algorithm compared with other benchmarks.      
### 28.A Deep Reinforcement Learning-based Sliding Mode Control Design for Partially-known Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.02975.pdf)
>  Presence of model uncertainties creates challenges for model-based control design, and complexity of the control design is further exacerbated when coping with nonlinear systems. This paper presents a sliding mode control (SMC) design approach for nonlinear systems with partially known dynamics by blending data-driven and model-based approaches. First, an SMC is designed for the available (nominal) model of the nonlinear system. The closed-loop state trajectory of the available model is used to build the desired trajectory for the partially known nonlinear system states. Next, a deep policy gradient method is used to cope with unknown parts of the system dynamics and adjust the sliding mode control output to achieve a desired state trajectory. The performance (and viability) of the proposed design approach is finally examined through numerical examples.      
### 29.An Incremental Negative Sequence Admittance Method for Fault Detection in Inverter-Based Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2205.02962.pdf)
>  Superimposed sequence quantities have been relied on for years to provide pure fault components for various applications in protection schemes. In more recent times, they have been employed in various solutions to the challenges introduced by integration of distributed generation in distribution systems. To improve the overall reliability of protection schemes deployed in such active distribution networks, this paper evaluates a new approach for detecting unbalanced faults using negative sequence quantities. A proposed superimposed negative sequence admittance element is validated using simulation tests on a modelled community microgrid. The performance of the method is tested for various fault scenarios in MATLAB/Simulink.      
### 30.Modelling Pre-fatigue, Low-velocity Impact and Fatigue behaviours of Composite Helicopter Tail Structures under Multipoint Coordinated Loading Spectrum  [ :arrow_down: ](https://arxiv.org/pdf/2205.02939.pdf)
>  This paper aims to numerically study the pre-fatigue, low-velocity impact (LVI) and fatigue progressive damage behaviours of a full-scale composite helicopter tail structure under multipoint coordinated loading spectrum. First, a fatigue progressive damage model (PDM) incorporating multiaxial fatigue residual strength degradation rule, fatigue failure criteria based on fatigue residual strength concept and sudden stiffness degradation rule was proposed. Then, an LVI progressive damage model for plain-weave (PW) and unidirectional (UD) composites was developed. Moreover, a full-process analysis algorithm with a reasonable damage transfer strategy for pre-fatigue, LVI and fatigue progressive damage analysis was proposed. Finally, a highly computational efficient and accurate full-scale global-local finite element (FE) model of helicopter tail structure was built to predict strain distribution under two flight working conditions, to predict LVI damage under impact loading, and to assess fatigue damage behaviours under multipoint coordinated loading spectrum. The numerical predictions agree well with test results from this work and literature data, indicating that the developed pre-fatigue, LVI, fatigue PDMs and algorithms, as well as the global-local FE modelling based on shell-to-solid coupling, can effectively analyse the impact damage tolerance of full-scale aircraft structures.      
### 31.Exponentially Stable Adaptive Optimal Control of Uncertain LTI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2205.02913.pdf)
>  A novel method of an adaptive linear quadratic (LQ) regulation of uncertain continuous linear time-invariant systems is proposed. Such an approach is based on the direct self-tuning regulators design framework and the exponentially stable adaptive control technique developed earlier by the authors. Unlike the known solutions, a procedure is proposed to obtain a non-overparametrized regression equation (RE) with respect to the unknown controller parameters from an initial RE of the LQ-based reference tracking control system. On the basis of such result, an adaptive law is proposed, which under mild regressor finite excitation condition provides monotonous convergence of the LQ-controller parameters to an adjustable set of their true values, which bound is defined only by the machine precision. Using the Lyapunov-based analysis, it is proved that the mentioned law guarantees the exponential stability of the closed-loop adaptive optimal control system. The simulation examples are provided to validate the theoretical contributions.      
### 32.A Deep Reinforcement Learning Framework for Rapid Diagnosis of Whole Slide Pathological Images  [ :arrow_down: ](https://arxiv.org/pdf/2205.02850.pdf)
>  The deep neural network is a research hotspot for histopathological image analysis, which can improve the efficiency and accuracy of diagnosis for pathologists or be used for disease screening. The whole slide pathological image can reach one gigapixel and contains abundant tissue feature information, which needs to be divided into a lot of patches in the training and inference stages. This will lead to a long convergence time and large memory consumption. Furthermore, well-annotated data sets are also in short supply in the field of digital pathology. Inspired by the pathologist's clinical diagnosis process, we propose a weakly supervised deep reinforcement learning framework, which can greatly reduce the time required for network inference. We use neural network to construct the search model and decision model of reinforcement learning agent respectively. The search model predicts the next action through the image features of different magnifications in the current field of view, and the decision model is used to return the predicted probability of the current field of view image. In addition, an expert-guided model is constructed by multi-instance learning, which not only provides rewards for search model, but also guides decision model learning by the knowledge distillation method. Experimental results show that our proposed method can achieve fast inference and accurate prediction of whole slide images without any pixel-level annotations.      
### 33.AdaTriplet: Adaptive Gradient Triplet Loss with Automatic Margin Learning for Forensic Medical Image Matching  [ :arrow_down: ](https://arxiv.org/pdf/2205.02849.pdf)
>  This paper tackles the challenge of forensic medical image matching (FMIM) using deep neural networks (DNNs). FMIM is a particular case of content-based image retrieval (CBIR). The main challenge in FMIM compared to the general case of CBIR, is that the subject to whom a query image belongs may be affected by aging and progressive degenerative disorders, making it difficult to match data on a subject level. CBIR with DNNs is generally solved by minimizing a ranking loss, such as Triplet loss (TL), computed on image representations extracted by a DNN from the original data. TL, in particular, operates on triplets: anchor, positive (similar to anchor) and negative (dissimilar to anchor). Although TL has been shown to perform well in many CBIR tasks, it still has limitations, which we identify and analyze in this work. In this paper, we introduce (i) the AdaTriplet loss -- an extension of TL whose gradients adapt to different difficulty levels of negative samples, and (ii) the AutoMargin method -- a technique to adjust hyperparameters of margin-based losses such as TL and our proposed loss dynamically. Our results are evaluated on two large-scale benchmarks for FMIM based on the Osteoarthritis Initiative and Chest X-ray-14 datasets. The codes allowing replication of this study have been made publicly available at \url{<a class="link-external link-https" href="https://github.com/Oulu-IMEDS/AdaTriplet" rel="external noopener nofollow">this https URL</a>}.      
### 34.Building Brains: Subvolume Recombination for Data Augmentation in Large Vessel Occlusion Detection  [ :arrow_down: ](https://arxiv.org/pdf/2205.02848.pdf)
>  Ischemic strokes are often caused by large vessel occlusions (LVOs), which can be visualized and diagnosed with Computed Tomography Angiography scans. As time is brain, a fast, accurate and automated diagnosis of these scans is desirable. Human readers compare the left and right hemispheres in their assessment of strokes. A large training data set is required for a standard deep learning-based model to learn this strategy from data. As labeled medical data in this field is rare, other approaches need to be developed. To both include the prior knowledge of side comparison and increase the amount of training data, we propose an augmentation method that generates artificial training samples by recombining vessel tree segmentations of the hemispheres or hemisphere subregions from different patients. The subregions cover vessels commonly affected by LVOs, namely the internal carotid artery (ICA) and middle cerebral artery (MCA). In line with the augmentation scheme, we use a 3D-DenseNet fed with task-specific input, fostering a side-by-side comparison between the hemispheres. Furthermore, we propose an extension of that architecture to process the individual hemisphere subregions. All configurations predict the presence of an LVO, its side, and the affected subregion. We show the effect of recombination as an augmentation strategy in a 5-fold cross validated ablation study. We enhanced the AUC for patient-wise classification regarding the presence of an LVO of all investigated architectures. For one variant, the proposed method improved the AUC from 0.73 without augmentation to 0.89. The best configuration detects LVOs with an AUC of 0.91, LVOs in the ICA with an AUC of 0.96, and in the MCA with 0.91 while accurately predicting the affected side.      
### 35.Segmentation with Super Images: A New 2D Perspective on 3D Medical Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2205.02847.pdf)
>  Deep learning is showing an increasing number of audience in medical imaging research. In the segmentation task of medical images, we oftentimes rely on volumetric data, and thus require the use of 3D architectures which are praised for their ability to capture more features from the depth dimension. Yet, these architectures are generally more ineffective in time and compute compared to their 2D counterpart on account of 3D convolutions, max pooling, up-convolutions, and other operations used in these networks. Moreover, there are limited to no 3D pretrained model weights, and pretraining is generally challenging. To alleviate these issues, we propose to cast volumetric data to 2D super images and use 2D networks for the segmentation task. The method processes the 3D image by stitching slices side-by-side to generate a super resolution image. While the depth information is lost, we expect that deep neural networks can still capture and learn these features. Our goal in this work is to introduce a new perspective when dealing with volumetric data, and test our hypothesis using vanilla networks. We hope that this approach, while achieving close enough results to 3D networks using only 2D counterparts, can attract more related research in the future, especially in medical image analysis since volumetric data is comparably limited.      
### 36.Invariant Content Synergistic Learning for Domain Generalization of Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2205.02845.pdf)
>  While achieving remarkable success for medical image segmentation, deep convolution neural networks (DCNNs) often fail to maintain their robustness when confronting test data with the novel distribution. To address such a drawback, the inductive bias of DCNNs is recently well-recognized. Specifically, DCNNs exhibit an inductive bias towards image style (e.g., superficial texture) rather than invariant content (e.g., object shapes). In this paper, we propose a method, named Invariant Content Synergistic Learning (ICSL), to improve the generalization ability of DCNNs on unseen datasets by controlling the inductive bias. First, ICSL mixes the style of training instances to perturb the training distribution. That is to say, more diverse domains or styles would be made available for training DCNNs. Based on the perturbed distribution, we carefully design a dual-branches invariant content synergistic learning strategy to prevent style-biased predictions and focus more on the invariant content. Extensive experimental results on two typical medical image segmentation tasks show that our approach performs better than state-of-the-art domain generalization methods.      
### 37.Generative Adversarial Network Based Synthetic Learning and a Novel Domain Relevant Loss Term for Spine Radiographs  [ :arrow_down: ](https://arxiv.org/pdf/2205.02843.pdf)
>  Problem: There is a lack of big data for the training of deep learning models in medicine, characterized by the time cost of data collection and privacy concerns. Generative adversarial networks (GANs) offer both the potential to generate new data, as well as to use this newly generated data, without inclusion of patients' real data, for downstream applications. <br>Approach: A series of GANs were trained and applied for a downstream computer vision spine radiograph abnormality classification task. Separate classifiers were trained with either access or no access to the original imaging. Trained GANs included a conditional StyleGAN2 with adaptive discriminator augmentation, a conditional StyleGAN2 with adaptive discriminator augmentation to generate spine radiographs conditional on lesion type, and using a novel clinical loss term for the generator a StyleGAN2 with adaptive discriminator augmentation conditional on abnormality (SpineGAN). Finally, a differential privacy imposed StyleGAN2 with adaptive discriminator augmentation conditional on abnormality was trained and an ablation study was performed on its differential privacy impositions. <br>Key Results: We accomplish GAN generation of synthetic spine radiographs without meaningful input for the first time from a literature review. We further demonstrate the success of synthetic learning for the spine domain with a downstream clinical classification task (AUC of 0.830 using synthetic data compared to AUC of 0.886 using the real data). Importantly, the introduction of a new clinical loss term for the generator was found to increase generation recall as well as accelerate model training. Lastly, we demonstrate that, in a limited size medical dataset, differential privacy impositions severely impede GAN training, finding that this is specifically due to the requirement for gradient perturbation with noise.      
### 38.InvNorm: Domain Generalization for Object Detection in Gastrointestinal Endoscopy  [ :arrow_down: ](https://arxiv.org/pdf/2205.02842.pdf)
>  Domain Generalization is a challenging topic in computer vision, especially in Gastrointestinal Endoscopy image analysis. Due to several device limitations and ethical reasons, current open-source datasets are typically collected on a limited number of patients using the same brand of sensors. Different brands of devices and individual differences will significantly affect the model's generalizability. Therefore, to address the generalization problem in GI(Gastrointestinal) endoscopy, we propose a multi-domain GI dataset and a light, plug-in block called InvNorm(Invertible Normalization), which could achieve a better generalization performance in any structure. Previous DG(Domain Generalization) methods fail to achieve invertible transformation, which would lead to some misleading augmentation. Moreover, these models would be more likely to lead to medical ethics issues. Our method utilizes normalizing flow to achieve invertible and explainable style normalization to address the problem. The effectiveness of InvNorm is demonstrated on a wide range of tasks, including GI recognition, GI object detection, and natural image recognition.      
### 39.Understanding Transfer Learning for Chest Radiograph Clinical Report Generation with Modified Transformer Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2205.02841.pdf)
>  The image captioning task is increasingly prevalent in artificial intelligence applications for medicine. One important application is clinical report generation from chest radiographs. The clinical writing of unstructured reports is time consuming and error-prone. An automated system would improve standardization, error reduction, time consumption, and medical accessibility. In this paper we demonstrate the importance of domain specific pre-training and propose a modified transformer architecture for the medical image captioning task. To accomplish this, we train a series of modified transformers to generate clinical reports from chest radiograph image input. These modified transformers include: a meshed-memory augmented transformer architecture with visual extractor using ImageNet pre-trained weights, a meshed-memory augmented transformer architecture with visual extractor using CheXpert pre-trained weights, and a meshed-memory augmented transformer whose encoder is passed the concatenated embeddings using both ImageNet pre-trained weights and CheXpert pre-trained weights. We use BLEU(1-4), ROUGE-L, CIDEr, and the clinical CheXbert F1 scores to validate our models and demonstrate competitive scores with state of the art models. We provide evidence that ImageNet pre-training is ill-suited for the medical image captioning task, especially for less frequent conditions (eg: enlarged cardiomediastinum, lung lesion, pneumothorax). Furthermore, we demonstrate that the double feature model improves performance for specific medical conditions (edema, consolidation, pneumothorax, support devices) and overall CheXbert F1 score, and should be further developed in future work. Such a double feature model, including both ImageNet pre-training as well as domain specific pre-training, could be used in a wide range of image captioning models in medicine.      
### 40.GAN Inversion for Data Augmentation to Improve Colonoscopy Lesion Classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.02840.pdf)
>  A major challenge in applying deep learning to medical imaging is the paucity of annotated data. This study demonstrates that synthetic colonoscopy images generated by Generative Adversarial Network (GAN) inversion can be used as training data to improve the lesion classification performance of deep learning models. This approach inverts pairs of images with the same label to a semantically rich &amp; disentangled latent space and manipulates latent representations to produce new synthetic images with the same label. We perform image modality translation (style transfer) between white light and narrowband imaging (NBI). We also generate realistic-looking synthetic lesion images by interpolating between original training images to increase the variety of lesion shapes in the training dataset. We show that these approaches outperform comparative colonoscopy data augmentation techniques without the need to re-train multiple generative models. This approach also leverages information from datasets that may not have been designed for the specific colonoscopy downstream task. E.g. using a bowel prep grading dataset for a polyp classification task. Our experiments show this approach can perform multiple colonoscopy data augmentations, which improve the downstream polyp classification performance over baseline and comparison methods by up to 6%.      
### 41.Age of Gossip in Ring Networks in the Presence of Jamming Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2205.03328.pdf)
>  We consider a system with a source which maintains the most current version of a file, and a ring network of $n$ user nodes that wish to acquire the latest version of the file. The source gets updated with newer file versions as a point process, and forwards them to the user nodes, which further forward them to their neighbors using a memoryless gossip protocol. We study the average version age of this network in the presence of $\tilde{n}$ jammers that disrupt inter-node communications. To this purpose, we construct an alternate system model of mini-rings and prove that the version age of the original model can be sandwiched between constant multiples of the version age of the alternate model. We show that when the number of jammers scales as a fractional power of the network size, i.e., $\tilde n= cn^\alpha$, the version age scales as $\sqrt{n}$ when $\alpha &lt; \frac{1}{2}$, and as $n^{\alpha}$ when $\alpha \geq \frac{1}{2}$. As the version age of a ring network without any jammers scales as $\sqrt{n}$, our result implies that the version age with gossiping is robust against up to $\sqrt{n}$ jammers in a ring network.      
### 42.Application of Clustering Algorithms for Dimensionality Reduction in Infrastructure Resilience Prediction Models  [ :arrow_down: ](https://arxiv.org/pdf/2205.03316.pdf)
>  Recent studies increasingly adopt simulation-based machine learning (ML) models to analyze critical infrastructure system resilience. For realistic applications, these ML models consider the component-level characteristics that influence the network response during emergencies. However, such an approach could result in a large number of features and cause ML models to suffer from the `curse of dimensionality'. We present a clustering-based method that simultaneously minimizes the problem of high-dimensionality and improves the prediction accuracy of ML models developed for resilience analysis in large-scale interdependent infrastructure networks. The methodology has three parts: (a) generation of simulation dataset, (b) network component clustering, and (c) dimensionality reduction and development of prediction models. First, an interdependent infrastructure simulation model simulates the network-wide consequences of various disruptive events. The component-level features are extracted from the simulated data. Next, clustering algorithms are used to derive the cluster-level features by grouping component-level features based on their topological and functional characteristics. Finally, ML algorithms are used to develop models that predict the network-wide impacts of disruptive events using the cluster-level features. The applicability of the method is demonstrated using an interdependent power-water-transport testbed. The proposed method can be used to develop decision-support tools for post-disaster recovery of infrastructure networks.      
### 43.Optimal Control as Variational Inference  [ :arrow_down: ](https://arxiv.org/pdf/2205.03279.pdf)
>  In this article we address the stochastic and risk sensitive optimal control problem probabilistically and decompose and solve the probabilistic models using principles from variational inference. We demonstrate how this culminates into two separate probabilistic inference procedures that allow to iteratively infer the deterministic optimal policy. More formally a sequence of belief policies, as a probabilistic proxy for the deterministic optimal policy, is specified through a fixed point iteration with the equilibrium point coinciding with the deterministic solution. These results re-establish the paradigm of Control as Inference, a concept explored and exploited originally by the Reinforcement Learning community anticipating deep rooted connections between optimal estimation and control. Although the Control as Inference paradigm already resulted in the development of several Reinforcement Learning algorithms, until now the underlying mechanism were only partially understood. For that very reason control as inference has not been well received by the control community. By exposing the underlying mechanism we aim to contribute to its general acceptance as a framework superseding optimal control. In order to exhibit its general relevance we discuss parallels with path integral control and discuss a wide range of possible applications.      
### 44.Calibration of the 5G-LENA System Level Simulator in 3GPP reference scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2205.03278.pdf)
>  Due to the rapid technology evolution and standardization activity in the mobile communication networks, there is the need for the research community to be able to develop, test and evaluate new and/or already xisting solutions before industrial or real-network implementation. As such, it is essential to have an open-source tool that provides an alternative solution to that of industrial proprietary simulators that are not available for public usage. ns-3 5G-LENA simulator is an end-to-end open-source NR system-level simulator that allows extensive research to be performed. However, it is of great importance to guarantee that the results obtained using the simulator can be comparable to that of industrial simulators and real networks. For this reason, calibrating the simulator based on 3GPP defined specifications is crucial. Based on the above, in this paper we calibrate the ns-3 5G-LENA simulator according to the 3GPP reference results for NR-based outdoor deployments. Moreover, we explore the REM feature provided by the simulator, to ease the calibration process and understand better the radio environment. Results show the resemblance of the simulator performance to that of simulators used as references by 3GPP.      
### 45.A rapid Power-iterative Root-MUSIC estimator for Massive/Ultra-massive MIMO Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2205.03269.pdf)
>  For a passive direction of arrival (DOA) measurement system using massive multiple input multiple output (MIMO), the complexity of the covariance matrix decompositionbased DOA measurement method is extremely high. To significantly reduce the computational complexity, two strategies are proposed. Firstly, a rapid power-iterative estimation of signal parameters via rotational invariance technique (RPI-ESPRIT) method is proposed, which not only reduces the complexity but also achieves good directional measurement results. However, the general complexity is still high. In order to further the complexity, a rapid power-iterative root Multiple Signal Classification (RPIRoot-MUSIC) method is proposed. Simulation results show that the two proposed methods outperform the classical DOA estimation method in terms of computational complexity. In particular, the lowest complexity achieved by the RPI-Root-MUSIC method is about two-order-magnitude lower than that of Root-MUSIC in terms of FLOP. In addition, it is verified that the initial vector and relative error have a substantial effect on the performance of computational complexity.      
### 46.Robustness of Neural Architectures for Audio Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2205.03268.pdf)
>  Traditionally, in Audio Recognition pipeline, noise is suppressed by the "frontend", relying on preprocessing techniques such as speech enhancement. However, it is not guaranteed that noise will not cascade into downstream pipelines. To understand the actual influence of noise on the entire audio pipeline, in this paper, we directly investigate the impact of noise on a different types of neural models without the preprocessing step. We measure the recognition performances of 4 different neural network models on the task of environment sound classification under the 3 types of noises: \emph{occlusion} (to emulate intermittent noise), \emph{Gaussian} noise (models continuous noise), and \emph{adversarial perturbations} (worst case scenario). Our intuition is that the different ways in which these models process their input (i.e. CNNs have strong locality inductive biases, which Transformers do not have) should lead to observable differences in performance and/ or robustness, an understanding of which will enable further improvements. We perform extensive experiments on AudioSet which is the largest weakly-labeled sound event dataset available. We also seek to explain the behaviors of different models through output distribution change and weight visualization.      
### 47.Musical Score Following and Audio Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2205.03247.pdf)
>  Real-time tracking of the position of a musical performance on a musical score, i.e. score following, can be useful in music practice, performance and production. Example applications of such technology include computer-aided accompaniment and automatic page turning. Score following is a challenging task, especially when considering deviations in performance data from the score stemming from mistakes or expressive choices. <br>In this project, the extensive research present in the field is first explored before two open-source evaluation testbenches for score following--one quantitative and the other qualitative--are introduced. A new way of obtaining quantitative testbench data is proposed, and the QualScofo dataset for qualitative benchmarking is introduced. Subsequently, three different score followers, each of a different class, are implemented. First, a beat-based follower for an interactive conductor application--the TuneApp Conductor--is created to demonstrate an entertaining application of score following. Then, an Approximate String Matching (ASM) non-real-time follower is implemented to complement the quantitative testbench and provide more technical background details of score following. Finally, a Constant Q-Transform (CQT) Dynamic Time Warping (DTW) score follower robust against major challenges in score following (such as polyphonic music and performance deviations) is outlined and implemented; it is shown that this CQT-based approach consistently and significantly outperforms a commonly used FFT-based approach in extracting audio features for score following.      
### 48.Atlas-powered deep learning (ADL) -- application to diffusion weighted MRI  [ :arrow_down: ](https://arxiv.org/pdf/2205.03210.pdf)
>  Deep learning has a great potential for estimating biomarkers in diffusion weighted magnetic resonance imaging (dMRI). Atlases, on the other hand, are a unique tool for modeling the spatio-temporal variability of biomarkers. In this paper, we propose the first framework to exploit both deep learning and atlases for biomarker estimation in dMRI. Our framework relies on non-linear diffusion tensor registration to compute biomarker atlases and to estimate atlas reliability maps. We also use nonlinear tensor registration to align the atlas to a subject and to estimate the error of this alignment. We use the biomarker atlas, atlas reliability map, and alignment error map, in addition to the dMRI signal, as inputs to a deep learning model for biomarker estimation. We use our framework to estimate fractional anisotropy and neurite orientation dispersion from down-sampled dMRI data on a test cohort of 70 newborn subjects. Results show that our method significantly outperforms standard estimation methods as well as recent deep learning techniques. Our method is also more robust to stronger measurement down-sampling factors. Our study shows that the advantages of deep learning and atlases can be synergistically combined to achieve unprecedented accuracy in biomarker estimation from dMRI data.      
### 49.Multicast-caching-aided On-demand Streaming with Optimal Network-wide Resource Consumption  [ :arrow_down: ](https://arxiv.org/pdf/2205.03189.pdf)
>  We consider a hybrid delivery scheme for streaming content, combining cache-enabled Orthogonal Multipoint Multicast (OMPMC) and on-demand Single-Point Unicast (SPUC) transmissions for heterogeneous networks. The OMPMC service transmits cached files through the whole network to interested users, and users not being satisfied by this service are assigned to the SPUC service to be individually served. The SPUC fetches the requested files from the core network and unicasts them to UEs using cellular beamforming transmissions. We optimize the delivery scheme to minimize the average resource consumption in the network. %multicast-aided optimal traffic offloading, the consumed resource of %the whole network is considered as a system performance. We formulate a constrained optimization problem over the cache placement and resource allocation of the OMPMC component, as well as the multi-user beamforming scheme of the SPUC component. We apply a path-following method to find the optimal traffic offloading solution. The solutions portray a contrast between the total amount of consumed resources and service outage probability. Simulation results show that the hybrid scheme provides a better tradeoff between the amount of network-wide consumed resources and the service outage probability, as compared to schemes from the literature.      
### 50.Event Concealment and Concealability Enforcement in Discrete Event Systems Under Partial Observation  [ :arrow_down: ](https://arxiv.org/pdf/2205.03170.pdf)
>  Inspired by privacy problems where the behavior of a system should not be revealed to an external curious observer, we investigate event concealment and concealability enforcement in discrete event systems modeled as non-deterministic finite automata under partial observation. Given a subset of secret events in a given system, concealability holds if the occurrence of all secret events remains hidden to a curious observer (an eavesdropper). A secret event is said to be (at least under some executions) unconcealable (inferable) if its occurrence can be indirectly determined with certainty after a finite number of observations. When concealability of a system does not hold (i.e., one or more secret events are unconcealable), we analyze how a defender, placed at the interface of the system with the eavesdropper, can be used to enforce concealability. The defender takes as input each observed event of the system and outputs a carefully modified event sequence (seen by the eavesdropper) using event deletion, insertion, or replacement. The defender is said to be C-enforceable if, following the occurrence of the secret events and regardless of subsequent activity generated by the system, it can always deploy a strategy to manipulate observations and conceal the events perpetually. We discuss systematic procedures to detect the presence of unconcealable secret events and verify C-Enforceability using techniques from state estimation and event diagnosis. We also propose a polynomial complexity construction for obtaining one necessary and one sufficient condition for C-Enforceability.      
### 51.Investigating and Explaining the Frequency Bias in Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2205.03154.pdf)
>  CNNs exhibit many behaviors different from humans, one of which is the capability of employing high-frequency components. This paper discusses the frequency bias phenomenon in image classification tasks: the high-frequency components are actually much less exploited than the low- and mid-frequency components. We first investigate the frequency bias phenomenon by presenting two observations on feature discrimination and learning priority. Furthermore, we hypothesize that (i) the spectral density, (ii) class consistency directly affect the frequency bias. Specifically, our investigations verify that the spectral density of datasets mainly affects the learning priority, while the class consistency mainly affects the feature discrimination.      
### 52.How to Minimize the Weighted Sum AoI in Two-Source Status Update Systems: OMA or NOMA?  [ :arrow_down: ](https://arxiv.org/pdf/2205.03143.pdf)
>  In this paper, the minimization of the weighted sum average age of information (AoI) in a two-source status update communication system is studied. Two independent sources send update packets to a common destination node in a time-slotted manner under the limit of maximum retransmission rounds. Different multiple access schemes, i.e., orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) are exploited here over a block-fading multiple access channel (MAC). Constrained Markov decision process (CMDP) problems are formulated to describe the AoI minimization problems considering both transmission schemes. The Lagrangian method is utilised to convert CMDP problems to unconstraint Markov decision process (MDP) problems and corresponding algorithms to derive the power allocation policies are obtained. On the other hand, for the case of unknown environments, two online reinforcement learning approaches considering both multiple access schemes are proposed to achieve near-optimal age performance. Numerical simulations validate the improvement of the proposed policy in terms of weighted sum AoI compared to the fixed power transmission policy, and illustrate that NOMA is more favorable in case of larger packet size.      
### 53.Ultrathin, high-speed, all-optical photoacoustic endomicroscopy probe for guiding minimally invasive surgery  [ :arrow_down: ](https://arxiv.org/pdf/2205.03122.pdf)
>  Photoacoustic (PA) endoscopy has shown significant potential for clinical diagnosis and surgical guidance. Multimode fibres (MMFs) are becoming increasing attractive for the development of miniature endoscopy probes owing to ultrathin size, low cost and diffraction-limited spatial resolution enabled by wavefront shaping. However, current MMF-based PA endomicroscopy probes are either limited by a bulky ultrasound detector or a low imaging speed which hindered their usability. In this work, we report the development of a highly miniaturised and high-speed PA endomicroscopy probe that is integrated within the cannula of a 20 gauge medical needle. This probe comprises a MMF for delivering the PA excitation light and a single-mode optical fibre with a plano-concave microresonator for ultrasound detection. Wavefront shaping with a digital micromirror device enabled rapid raster-scanning of a focused light spot at the distal end of the MMF for tissue interrogation. High-resolution PA imaging of mouse red blood cells covering an area 100 microns in diameter was achieved with the needle probe at ~3 frames per second. Mosaicing imaging was performed after fibre characterisation by translating the needle probe to enlarge the field-of-view in real-time. The developed ultrathin PA endomicroscopy probe is promising for guiding minimally invasive surgery by providing functional, molecular and microstructural information of tissue in real-time.      
### 54.Latency Guarantee for Ubiquitous Intelligence in 6G: A Network Calculus Approach  [ :arrow_down: ](https://arxiv.org/pdf/2205.03115.pdf)
>  With the gradual deployment of 5G and the continuous popularization of edge intelligence (EI), the explosive growth of data on the edge of the network has promoted the rapid development of 6G and ubiquitous intelligence (UbiI). This article aims to explore a new method for modeling latency guarantees for UbiI in 6G given 6G's extremely stochastic nature in terahertz (THz) environments, THz channel tail behavior, and delay distribution tail characteristics generated by the UBiI random component, and to find the optimal solution that minimizes the end-to-end (E2E) delay of UbiI. In this article, the arrival curve and service curve of network calculus can well characterize the stochastic nature of wireless channels, the tail behavior of wireless systems and the E2E service curve of network calculus can model the tail characteristic of the delay distribution in UbiI. Specifically, we first propose demands and challenges facing 6G, edge computing (EC), edge deep learning (DL), and UbiI. Then, we propose the hierarchical architecture, the network model, and the service delay model of the UbiI system based on network calculus. In addition, two case studies demonstrate the usefulness and effectiveness of the network calculus approach in analyzing and modeling the latency guarantee for UbiI in 6G. Finally, future open research issues regarding the latency guarantee for UbiI in 6G are outlined.      
### 55.Crop Type Identification for Smallholding Farms: Analyzing Spatial, Temporal and Spectral Resolutions in Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2205.03104.pdf)
>  The integration of the modern Machine Learning (ML) models into remote sensing and agriculture has expanded the scope of the application of satellite images in the agriculture domain. In this paper, we present how the accuracy of crop type identification improves as we move from medium-spatiotemporal-resolution (MSTR) to high-spatiotemporal-resolution (HSTR) satellite images. We further demonstrate that high spectral resolution in satellite imagery can improve prediction performance for low spatial and temporal resolutions (LSTR) images. The F1-score is increased by 7% when using multispectral data of MSTR images as compared to the best results obtained from HSTR images. Similarly, when crop season based time series of multispectral data is used we observe an increase of 1.2% in the F1-score. The outcome motivates further advancements in the field of synthetic band generation.      
### 56.Sound2Synth: Interpreting Sound via FM Synthesizer Parameters Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2205.03043.pdf)
>  Synthesizer is a type of electronic musical instrument that is now widely used in modern music production and sound design. Each parameters configuration of a synthesizer produces a unique timbre and can be viewed as a unique instrument. The problem of estimating a set of parameters configuration that best restore a sound timbre is an important yet complicated problem, i.e.: the synthesizer parameters estimation problem. We proposed a multi-modal deep-learning-based pipeline Sound2Synth, together with a network structure Prime-Dilated Convolution (PDC) specially designed to solve this problem. Our method achieved not only SOTA but also the first real-world applicable results on Dexed synthesizer, a popular FM synthesizer.      
### 57.Investigation of large-scale extended Granger causality (lsXGC) on synthetic functional MRI data  [ :arrow_down: ](https://arxiv.org/pdf/2205.03029.pdf)
>  It is a challenging research endeavor to infer causal relationships in multivariate observational time-series. Such data may be represented by graphs, where nodes represent time-series, and edges directed causal influence scores between them. If the number of nodes exceeds the number of temporal observations, conventional methods, such as standard Granger causality, are of limited value, because estimating free parameters of time-series predictors lead to underdetermined problems. A typical example for this situation is functional Magnetic Resonance Imaging (fMRI), where the number of nodal observations is large, usually ranging from $10^2$ to $10^5$ time-series, while the number of temporal observations is low, usually less than $10^3$. Hence, innovative approaches are required to address the challenges arising from such data sets. Recently, we have proposed the large-scale Extended Granger Causality (lsXGC) algorithm, which is based on augmenting a dimensionality-reduced representation of the system's state-space by supplementing data from the conditional source time-series taken from the original input space. Here, we apply lsXGC on synthetic fMRI data with known ground truth and compare its performance to state-of-the-art methods by leveraging the benefits of information-theoretic approaches. Our results suggest that the proposed lsXGC method significantly outperforms existing methods, both in diagnostic accuracy with Area Under the Receiver Operating Characteristic (AUROC = $0.849$ vs.~$[0.727, 0.762]$ for competing methods, $p&lt;\!10^{-8}$), and computation time ($3.4$ sec vs.~[$9.7$, $4.8 \times 10^3$] sec for competing methods) benchmarks, demonstrating the potential of lsXGC for analyzing large-scale networks in neuroimaging studies of the human brain.      
### 58.An Analysis of the Power Imbalance on the Uplink of Power-Domain NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2205.02981.pdf)
>  This paper analyzes the power imbalance factor on the uplink of a 2-user Power-domain NOMA system and reveals that the minimum value of the average error probability is achieved when the user signals are perfectly balanced in terms of power as in Multi-User MIMO with power control. The analytic result is obtained by analyzing the pairwise error probability and exploiting a symmetry property of the error events. This result is supported by computer simulations using the QPSK and 16QAM signal formats and uncorrelated Rayleigh fading channels. This finding leads to the questioning of the basic philosophy of Power-domain NOMA and suggests that the best strategy for uncorrelated channels is to perfectly balance the average signal powers received from the users and to use a maximum likelihood receiver for their detection.      
### 59.Learn-to-Race Challenge 2022: Benchmarking Safe Learning and Cross-domain Generalisation in Autonomous Racing  [ :arrow_down: ](https://arxiv.org/pdf/2205.02953.pdf)
>  We present the results of our autonomous racing virtual challenge, based on the newly-released Learn-to-Race (L2R) simulation framework, which seeks to encourage interdisciplinary research in autonomous driving and to help advance the state of the art on a realistic benchmark. Analogous to racing being used to test cutting-edge vehicles, we envision autonomous racing to serve as a particularly challenging proving ground for autonomous agents as: (i) they need to make sub-second, safety-critical decisions in a complex, fast-changing environment; and (ii) both perception and control must be robust to distribution shifts, novel road features, and unseen obstacles. Thus, the main goal of the challenge is to evaluate the joint safety, performance, and generalisation capabilities of reinforcement learning agents on multi-modal perception, through a two-stage process. In the first stage of the challenge, we evaluate an autonomous agent's ability to drive as fast as possible, while adhering to safety constraints. In the second stage, we additionally require the agent to adapt to an unseen racetrack through safe exploration. In this paper, we describe the new L2R Task 2.0 benchmark, with refined metrics and baseline approaches. We also provide an overview of deployment, evaluation, and rankings for the inaugural instance of the L2R Autonomous Racing Virtual Challenge (supported by Carnegie Mellon University, Arrival Ltd., AICrowd, Amazon Web Services, and Honda Research), which officially used the new L2R Task 2.0 benchmark and received over 20,100 views, 437 active participants, 46 teams, and 733 model submissions -- from 88 unique institutions, in 28 different countries. Finally, we release leaderboard results from the challenge and provide description of the two top-ranking approaches in cross-domain model transfer, across multiple sensor configurations and simulated races.      
### 60.Over-The-Air Federated Learning under Byzantine Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2205.02949.pdf)
>  Federated learning (FL) is a promising solution to enable many AI applications, where sensitive datasets from distributed clients are needed for collaboratively training a global model. FL allows the clients to participate in the training phase, governed by a central server, without sharing their local data. One of the main challenges of FL is the communication overhead, where the model updates of the participating clients are sent to the central server at each global training round. Over-the-air computation (AirComp) has been recently proposed to alleviate the communication bottleneck where the model updates are sent simultaneously over the multiple-access channel. However, simple averaging of the model updates via AirComp makes the learning process vulnerable to random or intended modifications of the local model updates of some Byzantine clients. In this paper, we propose a transmission and aggregation framework to reduce the effect of such attacks while preserving the benefits of AirComp for FL. For the proposed robust approach, the central server divides the participating clients randomly into groups and allocates a transmission time slot for each group. The updates of the different groups are then aggregated using a robust aggregation technique. We extend our approach to handle the case of non-i.i.d. local data, where a resampling step is added before robust aggregation. We analyze the convergence of the proposed approach for both cases of i.i.d. and non-i.i.d. data and demonstrate that the proposed algorithm converges at a linear rate to a neighborhood of the optimal solution. Experiments on real datasets are provided to confirm the robustness of the proposed approach.      
### 61.Region-free explicit model predictive control for linear systems on Hilbert spaces  [ :arrow_down: ](https://arxiv.org/pdf/2205.02881.pdf)
>  We extend explicit model predictive control (MPC) rigorously to linear distributed parameter systems (DPS). In a theoretical discussion on the foundations of explicit MPC with Hilbert-space optimization, we sort out some of the frequent misconceptions in the present explicit MPC literature. Based on our main result, and a result that it is enough to search among candidate active sets that satisfy the linear independence constraint qualification (LICQ), we give a novel active-set algorithm that implements very fast region-free explicit MPC for high-dimensional plants with a relatively long optimization horizon. If the Slater condition is met, then there exists an active set which characterizes optimality, and in this case the algorithm is guaranteed to find it in finite time. We use a Timoshenko beam with input and state constraints to demonstrate the efficacy of the proposed design and the capability of controlling a continuous-time hyperbolic PDE with a discrete-time explicit MPC controller.      
### 62.Generalized Reconfigurable Intelligent Surfaces: From Transmitting and Reflecting Modes to Single-, Group-, and Fully-Connected Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2205.02866.pdf)
>  Reconfigurable intelligent surfaces (RISs) are envisioned as a promising technology for future wireless communications. With various hardware realizations, RISs can work under different modes (reflective/transmissive/hybrid) or have different architectures (single-/group-/fully-connected). However, most existing research focused on either reflective RISs or single-connected hybrid RISs while there is lack of a comprehensive study for RISs unifying different modes/architectures. In this paper, we solve this issue by analyzing and proposing a general RIS-aided communication model which unifies the reflective/transmissive/hybrid modes and single-/group-/fullyconnected architectures. With the proposed model, we consider jointly designing the transmit precoder and RIS beamformer to maximize the sum-rate for RIS-aided systems. Leveraging fractional programming theory, the original sum-rate maximization problem is equivalently transformed into a multi-block optimization, which can be solved by block coordinate descent methods. We also provide simulation results to compare the performance of RISs with different modes/architectures. Compared with singleconnected hybrid RISs, fully- and group-connected hybrid RISs can increase the sum-rate by around 75% and 37% for Rayleigh fading channels.      
