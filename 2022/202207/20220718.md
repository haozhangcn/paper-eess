# ArXiv eess --Mon, 18 Jul 2022
### 1.Dual-space Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2207.07627.pdf)
>  Compressed sensing (CS) is a powerful method routinely employed to accelerate image acquisition. It is particularly suited to situations when the image under consideration is sparse but can be sampled in a basis where it is non-sparse. Here we propose an alternate CS regime in situations where the image can be sampled in two incoherent spaces simultaneously, with a special focus on image sampling in Fourier reciprocal spaces (e.g. real-space and k-space). Information is fed-forward from one space to the other, allowing new opportunities to efficiently solve the optimization problem at the heart of CS image reconstruction. We show that considerable gains in imaging acceleration are then possible over conventional CS. The technique provides enhanced robustness to noise, and is well suited to edge-detection problems. We envision applications for imaging collections of nanodiamond (ND) particles targeting specific regions in a volume of interest, exploiting the ability of lattice defects (NV centers) to allow ND particles to be imaged in reciprocal spaces simultaneously via optical fluorescence and 13C magnetic resonance imaging (MRI) respectively. Broadly this work suggests the potential to interface CS principles with hybrid sampling strategies to yield speedup in signal acquisition in many practical settings.      
### 2.Brain MRI study for glioma segmentation using convolutional neural networks and original post-processing techniques with low computational demand  [ :arrow_down: ](https://arxiv.org/pdf/2207.07622.pdf)
>  Gliomas are brain tumors composed of different highly heterogeneous histological subregions. Image analysis techniques to identify relevant tumor substructures have high potential for improving patient diagnosis, treatment and prognosis. However, due to the high heterogeneity of gliomas, the segmentation task is currently a major challenge in the field of medical image analysis. In the present work, the database of the Brain Tumor Segmentation (BraTS) Challenge 2018, composed of multimodal MRI scans of gliomas, was studied. A segmentation methodology based on the design and application of convolutional neural networks (CNNs) combined with original post-processing techniques with low computational demand was proposed. The post-processing techniques were the main responsible for the results obtained in the segmentations. The segmented regions were the whole tumor, the tumor core, and the enhancing tumor core, obtaining averaged Dice coefficients equal to 0.8934, 0.8376, and 0.8113, respectively. These results reached the state of the art in glioma segmentation determined by the winners of the challenge.      
### 3.CheXplaining in Style: Counterfactual Explanations for Chest X-rays using StyleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2207.07553.pdf)
>  Deep learning models used in medical image analysis are prone to raising reliability concerns due to their black-box nature. To shed light on these black-box models, previous works predominantly focus on identifying the contribution of input features to the diagnosis, i.e., feature attribution. In this work, we explore counterfactual explanations to identify what patterns the models rely on for diagnosis. Specifically, we investigate the effect of changing features within chest X-rays on the classifier's output to understand its decision mechanism. We leverage a StyleGAN-based approach (StyleEx) to create counterfactual explanations for chest X-rays by manipulating specific latent directions in their latent space. In addition, we propose EigenFind to significantly reduce the computation time of generated explanations. We clinically evaluate the relevancy of our counterfactual explanations with the help of radiologists. Our code is publicly available.      
### 4.The DKU-OPPO System for the 2022 Spoofing-Aware Speaker Verification Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2207.07510.pdf)
>  This paper describes our DKU-OPPO system for the 2022 Spoofing-Aware Speaker Verification (SASV) Challenge. First, we split the joint task into speaker verification (SV) and spoofing countermeasure (CM), these two tasks which are optimized separately. For ASV systems, four state-of-the-art methods are employed. For CM systems, we propose two methods on top of the challenge baseline to further improve the performance, namely Embedding Random Sampling Augmentation (ERSA) and One-Class Confusion Loss(OCCL). Second, we also explore whether SV embedding could help improve CM system performance. We observe a dramatic performance degradation of existing CM systems on the domain-mismatched Voxceleb2 dataset. Third, we compare different fusion strategies, including parallel score fusion and sequential cascaded systems. Compared to the 1.71% SASV-EER baseline, our submitted cascaded system obtains a 0.21% SASV-EER on the challenge official evaluation set.      
### 5.Computing Execution Times with eXecution Decision Diagrams in the Presence of Out-Of-Order Resources  [ :arrow_down: ](https://arxiv.org/pdf/2207.07481.pdf)
>  Worst-Case Execution Time (WCET) is a key component for the verification of critical real-time applications. Yet, even the simplest microprocessors implement pipelines with concurrently-accessed resources, such as the memory bus shared by fetch and memory stages. Although their in-order pipelines are, by nature, very deterministic, the bus can cause out-of-order accesses to the memory and, therefore, timing anomalies: local timing effects that can have global effects but that cannot be easily composed to estimate the global WCET. To cope with this situation, WCET analyses have to generate important over-estimations in order to preserve safety of the computed times or have to explicitly track all possible executions. In the latter case, the presence of out-of-order behavior leads to a combinatorial blowup of the number of pipeline states for which efficient state abstractions are difficult to design. This paper proposes instead a compact and exact representation of the timings in the pipeline, using eXecution Decision Diagram (XDD) [1]. We show how XDD can be used to model pipeline states all along the execution paths by leveraging the algebraic properties of XDD. This computational model allows to compute the exact temporal behavior at control flow graph level and is amenable to efficiently and precisely support WCET calculation in presence of out-of-order bus accesses. This model is finally experimented on the TACLe benchmark suite and we observe good performance making this approach appropriate for industrial applications.      
### 6.CKD-TransBTS: Clinical Knowledge-Driven Hybrid Transformer with Modality-Correlated Cross-Attention for Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2207.07370.pdf)
>  Brain tumor segmentation (BTS) in magnetic resonance image (MRI) is crucial for brain tumor diagnosis, cancer management and research purposes. With the great success of the ten-year BraTS challenges as well as the advances of CNN and Transformer algorithms, a lot of outstanding BTS models have been proposed to tackle the difficulties of BTS in different technical aspects. However, existing studies hardly consider how to fuse the multi-modality images in a reasonable manner. In this paper, we leverage the clinical knowledge of how radiologists diagnose brain tumors from multiple MRI modalities and propose a clinical knowledge-driven brain tumor segmentation model, called CKD-TransBTS. Instead of directly concatenating all the modalities, we re-organize the input modalities by separating them into two groups according to the imaging principle of MRI. A dual-branch hybrid encoder with the proposed modality-correlated cross-attention block (MCCA) is designed to extract the multi-modality image features. The proposed model inherits the strengths from both Transformer and CNN with the local feature representation ability for precise lesion boundaries and long-range feature extraction for 3D volumetric images. To bridge the gap between Transformer and CNN features, we propose a Trans&amp;CNN Feature Calibration block (TCFC) in the decoder. We compare the proposed model with five CNN-based models and six transformer-based models on the BraTS 2021 challenge dataset. Extensive experiments demonstrate that the proposed model achieves state-of-the-art brain tumor segmentation performance compared with all the competitors.      
### 7.Trainable Joint Bilateral Filters for Enhanced Prediction Stability in Low-dose CT  [ :arrow_down: ](https://arxiv.org/pdf/2207.07368.pdf)
>  Low-dose computed tomography (CT) denoising algorithms aim to enable reduced patient dose in routine CT acquisitions while maintaining high image quality. Recently, deep learning~(DL)-based methods were introduced, outperforming conventional denoising algorithms on this task due to their high model capacity. However, for the transition of DL-based denoising to clinical practice, these data-driven approaches must generalize robustly beyond the seen training data. We, therefore, propose a hybrid denoising approach consisting of a set of trainable joint bilateral filters (JBFs) combined with a convolutional DL-based denoising network to predict the guidance image. Our proposed denoising pipeline combines the high model capacity enabled by DL-based feature extraction with the reliability of the conventional JBF. The pipeline's ability to generalize is demonstrated by training on abdomen CT scans without metal implants and testing on abdomen scans with metal implants as well as on head CT data. When embedding two well-established DL-based denoisers (RED-CNN/QAE) in our pipeline, the denoising performance is improved by $10\,\%$/$82\,\%$ (RMSE) and $3\,\%$/$81\,\%$ (PSNR) in regions containing metal and by $6\,\%$/$78\,\%$ (RMSE) and $2\,\%$/$4\,\%$ (PSNR) on head CT data, compared to the respective vanilla model. Concluding, the proposed trainable JBFs limit the error bound of deep neural networks to facilitate the applicability of DL-based denoisers in low-dose CT pipelines.      
### 8.STRIKE-GOLDD 4.0: user-friendly, efficient analysis of structural identifiability and observability  [ :arrow_down: ](https://arxiv.org/pdf/2207.07346.pdf)
>  Structural identifiability and observability are desirable properties of systems biology models. Many software toolboxes have been developed for their analysis in the last decades. STRIKE-GOLDD is a generally applicable tool that can analyse non-linear, non-rational ODE models with unknown inputs. However, this generality comes at the expense of a lower computational efficiency than other tools. Here we present STRIKE-GOLDD 4.0, which includes a new algorithm, ProbObsTest, specifically designed for the analysis of rational models. ProbObsTest is significantly faster than the FISPO algorithm - which was already available in older versions of the toolbox - when applied to computationally expensive models. An important feature of both algorithms is their ability to analyse models with unknown inputs. Thus, their coexistence in the same toolbox provides a combination of general applicability and computational efficiency. STRIKE-GOLDD 4.0 is implemented as a free and open-source Matlab toolbox with a user-friendly graphical interface. It is available under a GPLv3 license and it can be downloaded from GitHub at <a class="link-external link-https" href="https://github.com/afvillaverde/strike-goldd" rel="external noopener nofollow">this https URL</a>.      
### 9.PoLyScribers: Joint Training of Vocal Extractor and Lyrics Transcriber for Polyphonic Music  [ :arrow_down: ](https://arxiv.org/pdf/2207.07336.pdf)
>  Lyrics transcription of polyphonic music is challenging as the background music affects lyrics intelligibility. Typically, lyrics transcription can be performed by a two step pipeline, i.e. singing vocal extraction frontend, followed by a lyrics transcriber decoder backend, where the frontend and backend are trained separately. Such a two step pipeline suffers from both imperfect vocal extraction and mismatch between frontend and backend. In this work, we propose novel end-to-end joint-training framework, that we call PoLyScribers, to jointly optimize the vocal extractor front-end and lyrics transcriber backend for lyrics transcription in polyphonic music. The experimental results show that our proposed joint-training model achieves substantial improvements over the existing approaches on publicly available test datasets.      
### 10.Computer Vision for Volunteer Cotton Detection in a Corn Field with UAS Remote Sensing Imagery and Spot Spray Applications  [ :arrow_down: ](https://arxiv.org/pdf/2207.07334.pdf)
>  To control boll weevil (Anthonomus grandis L.) pest re-infestation in cotton fields, the current practices of volunteer cotton (VC) (Gossypium hirsutum L.) plant detection in fields of rotation crops like corn (Zea mays L.) and sorghum (Sorghum bicolor L.) involve manual field scouting at the edges of fields. This leads to many VC plants growing in the middle of fields remain undetected that continue to grow side by side along with corn and sorghum. When they reach pinhead squaring stage (5-6 leaves), they can serve as hosts for the boll weevil pests. Therefore, it is required to detect, locate and then precisely spot-spray them with chemicals. In this paper, we present the application of YOLOv5m on radiometrically and gamma-corrected low resolution (1.2 Megapixel) multispectral imagery for detecting and locating VC plants growing in the middle of tasseling (VT) growth stage of cornfield. Our results show that VC plants can be detected with a mean average precision (mAP) of 79% and classification accuracy of 78% on images of size 1207 x 923 pixels at an average inference speed of nearly 47 frames per second (FPS) on NVIDIA Tesla P100 GPU-16GB and 0.4 FPS on NVIDIA Jetson TX2 GPU. We also demonstrate the application of a customized unmanned aircraft systems (UAS) for spot-spray applications based on the developed computer vision (CV) algorithm and how it can be used for near real-time detection and mitigation of VC plants growing in corn fields for efficient management of the boll weevil pests.      
### 11.On the Construction of Averaged Deep Denoisers for Image Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2207.07321.pdf)
>  Plug-and-Play (PnP) and Regularization by Denoising (RED) are recent paradigms for image reconstruction that can leverage the power of modern denoisers for image regularization. In particular, these algorithms have been shown to deliver state-of-the-art reconstructions using CNN denoisers. Since the regularization is performed in an ad-hoc manner in PnP and RED, understanding their convergence has been an active research area. Recently, it was observed in many works that iterate convergence of PnP and RED can be guaranteed if the denoiser is averaged or nonexpansive. However, integrating nonexpansivity with gradient-based learning is a challenging task -- checking nonexpansivity is known to be computationally intractable. Using numerical examples, we show that existing CNN denoisers violate the nonexpansive property and can cause the PnP iterations to diverge. In fact, algorithms for training nonexpansive denoisers either cannot guarantee nonexpansivity of the final denoiser or are computationally intensive. In this work, we propose to construct averaged (contractive) image denoisers by unfolding ISTA and ADMM iterations applied to wavelet denoising and demonstrate that their regularization capacity for PnP and RED can be matched with CNN denoisers. To the best of our knowledge, this is the first work to propose a simple framework for training provably averaged (contractive) denoisers using unfolding networks.      
### 12.Design of conformal antenna for antenna application  [ :arrow_down: ](https://arxiv.org/pdf/2207.07310.pdf)
>  The most challenging thing in the real world is communicating with aircraft, even though several communication technologies have been adopted for tracking and monitoring the aircraft there is no cent per cent efficiency, for the implementation of a conformal antenna for transmission and reception of the signal is preferred. In radio communication and avionics, a conformal antenna or conformal array is a flat radio antenna which is designed to conform to or follow some prescribed shape, for example, a curved conformal antenna is designed and is mounted on or embedded in a curved surface. The conformal antenna is a collection of a large number of smaller antennas (PAA) each one is connected to a phase shifter. The phased array antenna will have high directivity in the desired application. Conformal arrays are typically limited to high frequencies in the UHF or microwave range, where the wavelength of the waves is small enough that small antennas can be used. The main objective of this project is to embed this conformal antenna on the surface of the aircraft with increased gain. To implement the above-mentioned problem we are using CST microwave software. Conventional methods now used in aircraft are done by using the conformal antenna to save space and even military applications to be anonymous. The antenna stands to be an interface between the transmitter and the receiver. By working on the software and hardware features of antennas we can develop an antenna with better gain. By adopting better gain, the antenna will be more efficient. Thus by implementing this conformal antenna on the aircraft surface with an increased gain high degree of accuracy, clarity and effective communication link can be achieved.      
### 13.MIMO-DoAnet: Multi-channel Input and Multiple Outputs DoA Network with Unknown Number of Sound Sources  [ :arrow_down: ](https://arxiv.org/pdf/2207.07307.pdf)
>  Recent neural network based Direction of Arrival (DoA) estimation algorithms have performed well on unknown number of sound sources scenarios. These algorithms are usually achieved by mapping the multi-channel audio input to the single output (i.e. overall spatial pseudo-spectrum (SPS) of all sources), that is called MISO. However, such MISO algorithms strongly depend on empirical threshold setting and the angle assumption that the angles between the sound sources are greater than a fixed angle. To address these limitations, we propose a novel multi-channel input and multiple outputs DoA network called MIMO-DoAnet. Unlike the general MISO algorithms, MIMO-DoAnet predicts the SPS coding of each sound source with the help of the informative spatial covariance matrix. By doing so, the threshold task of detecting the number of sound sources becomes an easier task of detecting whether there is a sound source in each output, and the serious interaction between sound sources disappears during inference stage. Experimental results show that MIMO-DoAnet achieves relative 18.6% and absolute 13.3%, relative 34.4% and absolute 20.2% F1 score improvement compared with the MISO baseline system in 3, 4 sources scenes. The results also demonstrate MIMO-DoAnet alleviates the threshold setting problem and solves the angle assumption problem effectively.      
### 14.Towards Better Dermoscopic Image Feature Representation Learning for Melanoma Classification  [ :arrow_down: ](https://arxiv.org/pdf/2207.07303.pdf)
>  Deep learning-based melanoma classification with dermoscopic images has recently shown great potential in automatic early-stage melanoma diagnosis. However, limited by the significant data imbalance and obvious extraneous artifacts, i.e., the hair and ruler markings, discriminative feature extraction from dermoscopic images is very challenging. In this study, we seek to resolve these problems respectively towards better representation learning for lesion features. Specifically, a GAN-based data augmentation (GDA) strategy is adapted to generate synthetic melanoma-positive images, in conjunction with the proposed implicit hair denoising (IHD) strategy. Wherein the hair-related representations are implicitly disentangled via an auxiliary classifier network and reversely sent to the melanoma-feature extraction backbone for better melanoma-specific representation learning. Furthermore, to train the IHD module, the hair noises are additionally labeled on the ISIC2020 dataset, making it the first large-scale dermoscopic dataset with annotation of hair-like artifacts. Extensive experiments demonstrate the superiority of the proposed framework as well as the effectiveness of each component. The improved dataset publicly avaliable at <a class="link-external link-https" href="https://github.com/kirtsy/DermoscopicDataset" rel="external noopener nofollow">this https URL</a>.      
### 15.Robust Deep Compressive Sensing with Recurrent-Residual Structural Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2207.07301.pdf)
>  Existing deep compressive sensing (CS) methods either ignore adaptive online optimization or depend on costly iterative optimizer during reconstruction. This work explores a novel image CS framework with recurrent-residual structural constraint, termed as R$^2$CS-NET. The R$^2$CS-NET first progressively optimizes the acquired samplings through a novel recurrent neural network. The cascaded residual convolutional network then fully reconstructs the image from optimized latent representation. As the first deep CS framework efficiently bridging adaptive online optimization, the R$^2$CS-NET integrates the robustness of online optimization with the efficiency and nonlinear capacity of deep learning methods. Signal correlation has been addressed through the network architecture. The adaptive sensing nature further makes it an ideal candidate for color image CS via leveraging channel correlation. Numerical experiments verify the proposed recurrent latent optimization design not only fulfills the adaptation motivation, but also outperforms classic long short-term memory (LSTM) architecture in the same scenario. The overall framework demonstrates hardware implementation feasibility, with leading robustness and generalization capability among existing deep CS benchmarks.      
### 16.Direction-Aware Adaptive Online Neural Speech Enhancement with an Augmented Reality Headset in Real Noisy Conversational Environments  [ :arrow_down: ](https://arxiv.org/pdf/2207.07296.pdf)
>  This paper describes the practical response- and performance-aware development of online speech enhancement for an augmented reality (AR) headset that helps a user understand conversations made in real noisy echoic environments (e.g., cocktail party). One may use a state-of-the-art blind source separation method called fast multichannel nonnegative matrix factorization (FastMNMF) that works well in various environments thanks to its unsupervised nature. Its heavy computational cost, however, prevents its application to real-time processing. In contrast, a supervised beamforming method that uses a deep neural network (DNN) for estimating spatial information of speech and noise readily fits real-time processing, but suffers from drastic performance degradation in mismatched conditions. Given such complementary characteristics, we propose a dual-process robust online speech enhancement method based on DNN-based beamforming with FastMNMF-guided adaptation. FastMNMF (back end) is performed in a mini-batch style and the noisy and enhanced speech pairs are used together with the original parallel training data for updating the direction-aware DNN (front end) with backpropagation at a computationally-allowable interval. This method is used with a blind dereverberation method called weighted prediction error (WPE) for transcribing the noisy reverberant speech of a speaker, which can be detected from video or selected by a user's hand gesture or eye gaze, in a streaming manner and spatially showing the transcriptions with an AR technique. Our experiment showed that the word error rate was improved by more than 10 points with the run-time adaptation using only twelve minutes of observation.      
### 17.STEER: Beam Selection for Full-Duplex Millimeter Wave Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.07281.pdf)
>  Modern millimeter wave (mmWave) communication systems rely on beam alignment to deliver sufficient beamforming gain to close the link between devices. We present a novel beam selection methodology for multi-panel, full-duplex mmWave systems, which we call STEER, that delivers high beamforming gain while significantly reducing the full-duplex self-interference coupled between the transmit and receive beams. STEER does not necessitate changes to conventional beam alignment methodologies nor additional over-the-air feedback, making it compatible with existing cellular standards. Instead, STEER uses conventional beam alignment to identify the general directions beams should be steered, and then it makes use of a minimal number of self-interference measurements to jointly select transmit and receive beams that deliver high gain in these directions while coupling low self-interference. We implement STEER on an industry-grade 28 GHz phased array platform and use further simulation to show that full-duplex operation with beams selected by STEER can notably outperform both half-duplex and full-duplex operation with beams chosen via conventional beam selection. For instance, STEER can reliably reduce self-interference by more than 20 dB and improve SINR by more than 10 dB, compared to conventional beam selection. Our experimental results highlight that beam alignment can be used not only to deliver high beamforming gain in full-duplex mmWave systems but also to mitigate self-interference to levels near or below the noise floor, rendering additional self-interference cancellation unnecessary with STEER.      
### 18.Direction-Aware Joint Adaptation of Neural Speech Enhancement and Recognition in Real Multiparty Conversational Environments  [ :arrow_down: ](https://arxiv.org/pdf/2207.07273.pdf)
>  This paper describes noisy speech recognition for an augmented reality headset that helps verbal communication within real multiparty conversational environments. A major approach that has actively been studied in simulated environments is to sequentially perform speech enhancement and automatic speech recognition (ASR) based on deep neural networks (DNNs) trained in a supervised manner. In our task, however, such a pretrained system fails to work due to the mismatch between the training and test conditions and the head movements of the user. To enhance only the utterances of a target speaker, we use beamforming based on a DNN-based speech mask estimator that can adaptively extract the speech components corresponding to a head-relative particular direction. We propose a semi-supervised adaptation method that jointly updates the mask estimator and the ASR model at run-time using clean speech signals with ground-truth transcriptions and noisy speech signals with highly-confident estimated transcriptions. Comparative experiments using the state-of-the-art distant speech recognition system show that the proposed method significantly improves the ASR performance.      
### 19.Unrolled Optimization with Deep Learning-based Priors for Phaseless Inverse Scattering Problems  [ :arrow_down: ](https://arxiv.org/pdf/2207.07244.pdf)
>  Inverse scattering problems, such as those in electromagnetic imaging using phaseless data (PD-ISPs), involve imaging objects using phaseless measurements of wave scattering. Such inverse problems can be highly non-linear and ill-posed under extremely strong scattering conditions such as when the objects have very high permittivity or are large in size. In this work, we propose an end-to-end reconstruction framework using unrolled optimization with deep priors to solve PD-ISPs under very strong scattering conditions. We incorporate an approximate linear physics-based model into our optimization framework along with a deep learning-based prior and solve the resulting problem using an iterative algorithm which is unfolded into a deep network. This network not only learns data-driven regularization, but also overcomes the shortcomings of approximate linear models and learns non-linear features. More important, unlike existing PD-ISP methods, the proposed framework learns optimum values of all tunable parameters (including multiple regularization parameters) as a part of the framework. Results from simulations and experiments are shown for the use case of indoor imaging using 2.4 GHz phaseless Wi-Fi measurements, where the objects exhibit extremely strong scattering and low-absorption. Results show that the proposed framework outperforms existing model-driven and data-driven techniques by a significant margin and provides up to 20 times higher validity range.      
### 20.Adaptive Random Fourier Features Kernel LMS  [ :arrow_down: ](https://arxiv.org/pdf/2207.07236.pdf)
>  We propose the adaptive random Fourier features Gaussian kernel LMS (ARFF-GKLMS). Like most kernel adaptive filters based on stochastic gradient descent, this algorithm uses a preset number of random Fourier features to save computation cost. However, as an extra flexibility, it can adapt the inherent kernel bandwidth in the random Fourier features in an online manner. This adaptation mechanism allows to alleviate the problem of selecting the kernel bandwidth beforehand for the benefit of an improved tracking in non-stationary circumstances. Simulation results confirm that the proposed algorithm achieves a performance improvement in terms of convergence rate, error at steady-state and tracking ability over other kernel adaptive filters with preset kernel bandwidth.      
### 21.Multi-FEAT: Multi-Feature Edge AlignmenT for Targetless Camera-LiDAR Calibration  [ :arrow_down: ](https://arxiv.org/pdf/2207.07228.pdf)
>  The accurate environment perception of automobiles and UAVs (Unmanned Ariel Vehicles) relies on the precision of onboard sensors, which require reliable in-field calibration. This paper introduces a novel approach for targetless camera-LiDAR extrinsic calibration called Multi-FEAT (Multi-Feature Edge AlignmenT). Multi-FEAT uses the cylindrical projection model to transform the 2D(Camera)-3D(LiDAR) calibration problem into a 2D-2D calibration problem, and exploits various LiDAR feature information to supplement the sparse LiDAR point cloud boundaries. In addition, a feature matching function with a precision factor is designed to improve the smoothness of the solution space. The performance of the proposed Multi-FEAT algorithm is evaluated using the KITTI dataset, and our approach shows more reliable results, as compared with several existing targetless calibration methods. We summarize our results and present potential directions for future work.      
### 22.Energy Storage State-of-Charge Market Model  [ :arrow_down: ](https://arxiv.org/pdf/2207.07221.pdf)
>  This paper introduces and rationalizes a new model for bidding and clearing energy storage resources in wholesale energy markets. Charge and discharge bids in this model are dependent on the storage state-of-charge (SoC). In this setting, storage participants submit different bids for each SoC segment. The system operator monitors the storage SoC, and updates their bids accordingly in market clearings. Combined with an optimal bidding design algorithm using dynamic programming, our paper shows that the SoC segment model provides more accurate representations of the opportunity costs of energy storage compared to existing power-based bidding models, and captures the inherent nonlinear operational characteristics of energy storage. We benchmark the SoC segment model against an existing single-segment storage model in both price-taker and price-influencer simulations. The simulation results show that the proposed model improves profits by 10-60% and reduces system cost by 5% in comparison to the existing power-based bidding model, and helps reduce price volatilities.      
### 23.Passivity-based control of underactuated mechanical systems with Coulomb friction: Application to earthquake prevention  [ :arrow_down: ](https://arxiv.org/pdf/2207.07181.pdf)
>  Passivity property gives a sense of energy balance. The classical definitions and theorems of passivity in dynamical systems require time invariance and locally Lipschitz functions. However, these conditions are not met in many systems. A characteristic example is nonautonomous underactuated, discontinuous systems due to friction. This paper presents an extended result for the negative feedback connection of two passive nonautonomous systems with a set-valued right-hand side based on an invariance-like principle. Such extension is the base of a structural passivity-based control synthesis for underactuated mechanical systems with Coulomb friction. The first step consists in designing the control able to restore the passivity in the considered friction law, achieving stabilization of the system trajectories to a domain with zero velocities. Then, an integral action is included to improve the latter result and perform a tracking over a reference. At last, the control is designed considering (slow) dynamics in the actuation. These control objectives are obtained using fewer control inputs than degrees of freedom, as a result of the underactuated nature of the plant. The presented control strategy is implemented in an earthquake prevention scenario, where a mature seismogenic fault represents the considered frictional underactuated mechanical system. Simulations are performed to show how the seismic energy can be slowly dissipated by tracking a slow reference, thanks to fluid injection far from the fault, accounting also for the slow dynamics of the fluid's diffusion.      
### 24.Designing, Building, and Characterizing RF Switch-based Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2207.07121.pdf)
>  In this paper, we present our experience designing, prototyping, and empirically characterizing RF Switch-based Reconfigurable Intelligent Surfaces (RIS). Our RIS design comprises arrays of patch antennas, delay lines and programmable radio-frequency (RF) switches that enable passive 3D beamforming, i.e., without active RF components. We implement this design using PCB technology and low-cost electronic components, and thoroughly validate our prototype in a controlled environment with high spatial resolution codebooks. Finally, we make available a large dataset with a complete characterization of our RIS and present the costs associated with reproducing our design.      
### 25.Position Prediction as an Effective Pretraining Strategy  [ :arrow_down: ](https://arxiv.org/pdf/2207.07611.pdf)
>  Transformers have gained increasing popularity in a wide range of applications, including Natural Language Processing (NLP), Computer Vision and Speech Recognition, because of their powerful representational capacity. However, harnessing this representational capacity effectively requires a large amount of data, strong regularization, or both, to mitigate overfitting. Recently, the power of the Transformer has been unlocked by self-supervised pretraining strategies based on masked autoencoders which rely on reconstructing masked inputs, directly, or contrastively from unmasked content. This pretraining strategy which has been used in BERT models in NLP, Wav2Vec models in Speech and, recently, in MAE models in Vision, forces the model to learn about relationships between the content in different parts of the input using autoencoding related objectives. In this paper, we propose a novel, but surprisingly simple alternative to content reconstruction~-- that of predicting locations from content, without providing positional information for it. Doing so requires the Transformer to understand the positional relationships between different parts of the input, from their content alone. This amounts to an efficient implementation where the pretext task is a classification problem among all possible positions for each input token. We experiment on both Vision and Speech benchmarks, where our approach brings improvements over strong supervised training baselines and is comparable to modern unsupervised/self-supervised pretraining methods. Our method also enables Transformers trained without position embeddings to outperform ones trained with full position information.      
### 26.DOLPHINS: Dataset for Collaborative Perception enabled Harmonious and Interconnected Self-driving  [ :arrow_down: ](https://arxiv.org/pdf/2207.07609.pdf)
>  Vehicle-to-Everything (V2X) network has enabled collaborative perception in autonomous driving, which is a promising solution to the fundamental defect of stand-alone intelligence including blind zones and long-range perception. However, the lack of datasets has severely blocked the development of collaborative perception algorithms. In this work, we release DOLPHINS: Dataset for cOllaborative Perception enabled Harmonious and INterconnected Self-driving, as a new simulated large-scale various-scenario multi-view multi-modality autonomous driving dataset, which provides a ground-breaking benchmark platform for interconnected autonomous driving. DOLPHINS outperforms current datasets in six dimensions: temporally-aligned images and point clouds from both vehicles and Road Side Units (RSUs) enabling both Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) based collaborative perception; 6 typical scenarios with dynamic weather conditions make the most various interconnected autonomous driving dataset; meticulously selected viewpoints providing full coverage of the key areas and every object; 42376 frames and 292549 objects, as well as the corresponding 3D annotations, geo-positions, and calibrations, compose the largest dataset for collaborative perception; Full-HD images and 64-line LiDARs construct high-resolution data with sufficient details; well-organized APIs and open-source codes ensure the extensibility of DOLPHINS. We also construct a benchmark of 2D detection, 3D detection, and multi-view collaborative perception tasks on DOLPHINS. The experiment results show that the raw-level fusion scheme through V2X communication can help to improve the precision as well as to reduce the necessity of expensive LiDAR equipment on vehicles when RSUs exist, which may accelerate the popularity of interconnected self-driving vehicles. DOLPHINS is now available on <a class="link-external link-https" href="https://dolphins-dataset.net/" rel="external noopener nofollow">this https URL</a>.      
### 27.Mobile Keystroke Biometrics Using Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2207.07596.pdf)
>  Behavioural biometrics have proven to be effective against identity theft as well as be considered user-friendly authentication methods. One of the most popular traits in the literature is keystroke dynamics due to the large deployment of computers and mobile devices in our society. This paper focuses on improving keystroke biometric systems on the free-text scenario. This scenario is characterised as very challenging due to the uncontrolled text conditions, the influential of the user's emotional and physical state, and the in-use application. To overcome these drawbacks, methods based on deep learning such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have been proposed in the literature, outperforming traditional machine learning methods. However, these architectures still have aspects that need to be reviewed and improved. To the best of our knowledge, this is the first study that proposes keystroke biometric systems based on Transformers. The proposed Transformer architecture has achieved Equal Error Rate (EER) values of 3.84% in the popular Aalto mobile keystroke database using only 5 enrolment sessions, outperforming in large margin other state-of-the-art approaches in the literature.      
### 28.Outlier detection of vital sign trajectories from COVID-19 patients  [ :arrow_down: ](https://arxiv.org/pdf/2207.07572.pdf)
>  There is growing interest in continuous wearable vital sign sensors for monitoring patients remotely at home. These monitors are usually coupled to an alerting system, which is triggered when vital sign measurements fall outside a predefined normal range. Trends in vital signs, such as an increasing heart rate, are often indicative of deteriorating health, but are rarely incorporated into alerting systems. In this work, we present a novel outlier detection algorithm to identify such abnormal vital sign trends. We introduce a distance-based measure to compare vital sign trajectories. For each patient in our dataset, we split vital sign time series into 180 minute, non-overlapping epochs. We then calculated a distance between all pairs of epochs using the dynamic time warp distance. Each epoch was characterized by its mean pairwise distance (average link distance) to all other epochs, with large distances considered as outliers. We applied this method to a pilot dataset collected over 1561 patient-hours from 8 patients who had recently been discharged from hospital after contracting COVID-19. We show that outlier epochs correspond well with patients who were subsequently readmitted to hospital. We also show, descriptively, how epochs transition from normal to abnormal for one such patient.      
### 29.Low-bit Shift Network for End-to-End Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2207.07497.pdf)
>  Deep neural networks (DNN) have achieved impressive success in multiple domains. Over the years, the accuracy of these models has increased with the proliferation of deeper and more complex architectures. Thus, state-of-the-art solutions are often computationally expensive, which makes them unfit to be deployed on edge computing platforms. In order to mitigate the high computation, memory, and power requirements of inferring convolutional neural networks (CNNs), we propose the use of power-of-two quantization, which quantizes continuous parameters into low-bit power-of-two values. This reduces computational complexity by removing expensive multiplication operations and with the use of low-bit weights. ResNet is adopted as the building block of our solution and the proposed model is evaluated on a spoken language understanding (SLU) task. Experimental results show improved performance for shift neural network architectures, with our low-bit quantization achieving 98.76 \% on the test set which is comparable performance to its full-precision counterpart and state-of-the-art solutions.      
### 30.DeepSolar tracker: towards unsupervised assessment with open-source data of the accuracy of deep learning-based distributed PV mapping  [ :arrow_down: ](https://arxiv.org/pdf/2207.07466.pdf)
>  Photovoltaic (PV) energy is key to mitigating the current energy crisis. However, distributed PV generation, which amounts to half of the PV energy generation, makes it increasingly difficult for transmission system operators (TSOs) to balance the load and supply and avoid grid congestions. Indeed, in the absence of measurements, estimating the distributed PV generation is tough. In recent years, many remote sensing-based approaches have been proposed to map distributed PV installations. However, to be applicable in industrial settings, one needs to assess the accuracy of the mapping over the whole deployment area. We build on existing work to propose an automated PV registry pipeline. This pipeline automatically generates a dataset recording all distributed PV installations' location, area, installed capacity, and tilt angle. It only requires aerial orthoimagery and topological data, both of which are freely accessible online. In order to assess the accuracy of the registry, we propose an unsupervised method based on the {\it Registre national d'installation} (RNI), that centralizes all individual PV systems aggregated at communal level, enabling practitioners to assess the accuracy of the registry and eventually remove outliers. We deploy our model on 9 French {\it d√©partements} covering more than 50 000 square kilometers, providing the largest mapping of distributed PV panels with this level of detail to date. We then demonstrate how practitioners can use our unsupervised accuracy assessment method to assess the accuracy of the outputs. In particular, we show how it can easily identify outliers in the detections. Overall, our approach paves the way for a safer integration of deep learning-based pipelines for remote PV mapping. Code is available at {\tt <a class="link-external link-https" href="https://github.com/gabrielkasmi/dsfrance" rel="external noopener nofollow">this https URL</a>}.      
### 31.A 'one-size-fits-most' walking recognition method for smartphones, smartwatches, and wearable accelerometers  [ :arrow_down: ](https://arxiv.org/pdf/2207.07443.pdf)
>  The ubiquity of personal digital devices offers unprecedented opportunities to study human behavior. Current state-of-the-art methods quantify physical activity using 'activity counts,' a measure which overlooks specific types of physical activities. We proposed a walking recognition method for sub-second tri-axial accelerometer data, in which activity classification is based on the inherent features of walking: intensity, periodicity, and duration. We validated our method against 20 publicly available, annotated datasets on walking activity data collected at various body locations (thigh, waist, chest, arm, wrist). We demonstrated that our method can estimate walking periods with high sensitivity and specificity: average sensitivity ranged between 0.92 and 0.97 across various body locations, and average specificity for common daily activities was typically above 0.95. We also assessed the method's algorithmic fairness to demographic and anthropometric variables and measurement contexts (body location, environment). Finally, we have released our method as open-source software in MATLAB and Python.      
### 32.Continual Learning For On-Device Environmental Sound Classification  [ :arrow_down: ](https://arxiv.org/pdf/2207.07429.pdf)
>  Continuously learning new classes without catastrophic forgetting is a challenging problem for on-device environmental sound classification given the restrictions on computation resources (e.g., model size, running memory). To address this issue, we propose a simple and efficient continual learning method. Our method selects the historical data for the training by measuring the per-sample classification uncertainty. Specifically, we measure the uncertainty by observing how the classification probability of data fluctuates against the parallel perturbations added to the classifier embedding. In this way, the computation cost can be significantly reduced compared with adding perturbation to the raw data. Experimental results on the DCASE 2019 Task 1 and ESC-50 dataset show that our proposed method outperforms baseline continual learning methods on classification accuracy and computational efficiency, indicating our method can efficiently and incrementally learn new classes without the catastrophic forgetting problem for on-device environmental sound classification.      
### 33.PodcastMix: A dataset for separating music and speech in podcasts  [ :arrow_down: ](https://arxiv.org/pdf/2207.07403.pdf)
>  We introduce PodcastMix, a dataset formalizing the task of separating background music and foreground speech in podcasts. We aim at defining a benchmark suitable for training and evaluating (deep learning) source separation models. To that end, we release a large and diverse training dataset based on programatically generated podcasts. However, current (deep learning) models can incur into generalization issues, specially when trained on synthetic data. To target potential generalization issues, we release an evaluation set based on real podcasts for which we design objective and subjective tests. Out of our experiments with real podcasts, we find that current (deep learning) models may have generalization issues. Yet, these can perform competently, e.g., our best baseline separates speech with a mean opinion score of 3.84 (rating "overall separation quality" from 1 to 5). The dataset and baselines are accessible online.      
### 34.Multi-RAT IoT -- What's to Gain? An Energy-Monitoring Platform  [ :arrow_down: ](https://arxiv.org/pdf/2207.07371.pdf)
>  Multiple LPWANs have been rolled out to support the variety of IoT applications that are crucial to the ongoing digital transformation. These networks vary largely in terms of quality-of-service, throughput and energy-efficiency. To cover all LPWAN use-cases most optimally, multiple networks can be combined into a multiple radio access technology (multi-RAT) solution. In particular environmental monitoring in both smart city and remote landscapes. We present and share such a multi-RAT platform. To derive an accurate profile of the multi-RAT opportunities in various scenarios, in the-field network parameter are monitored. The platform collects per-packet energy-consumption, packet delivery ratio (PDR) and other parameters of LoRaWAN, NB-IoT and Sigfox. Our preliminary measurements demonstrate the validity of using a multi-RAT solution. For example, we illustrate the potential energy savings when adopting multi-RAT in various scenarios.      
### 35.A Simulation Study of Functional Electrical Stimulation for An Upper Limb Rehabilitation Robot using Iterative Learning Control (ILC) and Linear models  [ :arrow_down: ](https://arxiv.org/pdf/2207.07289.pdf)
>  A proportional iterative learning control (P-ILC) for linear models of an existing hybrid stroke rehabilitation scheme is implemented for elbow extension/flexion during a rehabilitative task. Owing to transient error growth problem of P-ILC, a learning derivative constraint controller was included to ensure that the controlled system does not exceed a predefined velocity limit at every trial. To achieve this, linear transfer function models of the robot end-effector interaction with a stroke subject (plant) and muscle response to stimulation controllers were developed. A straight-line point-point trajectory of 0 - 0.3 m range served as the reference task space trajectory for the plant, feedforward, and feedback stimulation controllers. At each trial, a SAT-based bounded error derivative ILC algorithm served as the learning constraint controller. Three control configurations were developed and simulated. The system performance was evaluated using the root means square error (RMSE) and normalized RMSE. At different ILC gains over 16 iterations, a displacement error of 0.0060 m was obtained when control configurations were combined.      
### 36.WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2207.07288.pdf)
>  Existing few-shot image generation approaches typically employ fusion-based strategies, either on the image or the feature level, to produce new images. However, previous approaches struggle to synthesize high-frequency signals with fine details, deteriorating the synthesis quality. To address this, we propose WaveGAN, a frequency-aware model for few-shot image generation. Concretely, we disentangle encoded features into multiple frequency components and perform low-frequency skip connections to preserve outline and structural information. Then we alleviate the generator's struggles of synthesizing fine details by employing high-frequency skip connections, thus providing informative frequency information to the generator. Moreover, we utilize a frequency L1-loss on the generated and real images to further impede frequency information loss. Extensive experiments demonstrate the effectiveness and advancement of our method on three datasets. Noticeably, we achieve new state-of-the-art with FID 42.17, LPIPS 0.3868, FID 30.35, LPIPS 0.5076, and FID 4.96, LPIPS 0.3822 respectively on Flower, Animal Faces, and VGGFace. GitHub: <a class="link-external link-https" href="https://github.com/kobeshegu/ECCV2022_WaveGAN" rel="external noopener nofollow">this https URL</a>      
### 37.Automating Geometric Proofs of Collision Avoidance with Active Corners  [ :arrow_down: ](https://arxiv.org/pdf/2207.07259.pdf)
>  Avoiding collisions between obstacles and vehicles such as cars, robots or aircraft is essential to the development of automation and autonomy. To simplify the problem, many collision avoidance algorithms and proofs consider vehicles to be a point mass, though the actual vehicles are not points. In this paper, we consider a convex polygonal vehicle with nonzero area traveling along a 2-dimensional trajectory. We derive an easily-checkable, quantifier-free formula to check whether a given obstacle will collide with the vehicle moving on the planned trajectory. We apply our method to two case studies of aircraft collision avoidance and study its performance.      
### 38.COOR-PLT: A hierarchical control model for coordinating adaptive platoons of connected and autonomous vehicles at signal-free intersections based on deep reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.07195.pdf)
>  Platooning and coordination are two implementation strategies that are frequently proposed for traffic control of connected and autonomous vehicles (CAVs) at signal-free intersections instead of using conventional traffic signals. However, few studies have attempted to integrate both strategies to better facilitate the CAV control at signal-free intersections. To this end, this study proposes a hierarchical control model, named COOR-PLT, to coordinate adaptive CAV platoons at a signal-free intersection based on deep reinforcement learning (DRL). COOR-PLT has a two-layer framework. The first layer uses a centralized control strategy to form adaptive platoons. The optimal size of each platoon is determined by considering multiple objectives (i.e., efficiency, fairness and energy saving). The second layer employs a decentralized control strategy to coordinate multiple platoons passing through the intersection. Each platoon is labeled with coordinated status or independent status, upon which its passing priority is determined. As an efficient DRL algorithm, Deep Q-network (DQN) is adopted to determine platoon sizes and passing priorities respectively in the two layers. The model is validated and examined on the simulator Simulation of Urban Mobility (SUMO). The simulation results demonstrate that the model is able to: (1) achieve satisfactory convergence performances; (2) adaptively determine platoon size in response to varying traffic conditions; and (3) completely avoid deadlocks at the intersection. By comparison with other control methods, the model manifests its superiority of adopting adaptive platooning and DRL-based coordination strategies. Also, the model outperforms several state-of-the-art methods on reducing travel time and fuel consumption in different traffic conditions.      
### 39.Audio-guided Album Cover Art Generation with Genetic Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2207.07162.pdf)
>  Over 60,000 songs are released on Spotify every day, and the competition for the listener's attention is immense. In that regard, the importance of captivating and inviting cover art cannot be underestimated, because it is deeply entangled with a song's character and the artist's identity, and remains one of the most important gateways to lead people to discover music. However, designing cover art is a highly creative, lengthy and sometimes expensive process that can be daunting, especially for non-professional artists. For this reason, we propose a novel deep-learning framework to generate cover art guided by audio features. Inspired by VQGAN-CLIP, our approach is highly flexible because individual components can easily be replaced without the need for any retraining. This paper outlines the architectural details of our models and discusses the optimization challenges that emerge from them. More specifically, we will exploit genetic algorithms to overcome bad local minima and adversarial examples. We find that our framework can generate suitable cover art for most genres, and that the visual features adapt themselves to audio feature changes. Given these results, we believe that our framework paves the road for extensions and more advanced applications in audio-guided visual generation tasks.      
