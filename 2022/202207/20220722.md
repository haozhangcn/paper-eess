# ArXiv eess --Fri, 22 Jul 2022
### 1.Discrete-Fresnel Domain Channel Estimation in OCDM-based Radar Systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.10521.pdf)
>  In recent years, orthogonal chirp-division multiplexing (OCDM) has been increasingly considered as an alternative multicarrier scheme, e.g., to orthogonal frequency-division multiplexing, in digital communication applications. Among reasons for thar are its demonstrated superior performance resulting from its robustness to impairments such as frequency selectivity of channels and intersymbol interference. Furthermore, the so-called unbiased channel estimation in the discrete-Fresnel domain has also been investigated for both communication and sensing systems, however without considering the effects of frequency shifts. This article investigates the suitability of the aforementioned discrete-Fresnel domain channel estimation in OCDM-based radar systems as an alternative to the correlation-based processing previously adopted, e.g., in the radar-communication (RadCom) literature, which yields high sidelobe level depending on the symbols modulated onto the orthogonal subchirps. In this context, a mathematical formulation for the aforementioned channel estimation approach is introduced. Additionally, extensions to multi-user/multiple-input multiple-output and RadCom operations are proposed. Finally, the performance of the proposed schemes is analyzed, and the presented discussion is supported by simulation and measurement results. In summary, all proposed OCDM-based schemes yield comparable radar sensing performance to their orthogonal frequency-division multiplexing counterpart, while achieving improved peak-to-average power ratio and, in the RadCom case, communication performance.      
### 2.The Unscented Transform Controller: a new model predictive control law for highly nonlinear systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.10496.pdf)
>  The Unscented Transform which is the basis of the Unscented Kalman Filter, UKF, is used here to develop a novel predictive controller for non-linear plants, called the Unscented Transform Controller, UTC. The UTC can be seen as the dual of the UKF, the same way as the LQG regulator and the Kalman Filter are related. The UTC is demonstrated on the control of complex maneuvers in free fall of a virtual skydiver the model of which was verified in wind tunnel and free fall experiments.      
### 3.Towards Confident Detection of Prostate Cancer using High Resolution Micro-ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2207.10485.pdf)
>  MOTIVATION: Detection of prostate cancer during transrectal ultrasound-guided biopsy is challenging. The highly heterogeneous appearance of cancer, presence of ultrasound artefacts, and noise all contribute to these difficulties. Recent advancements in high-frequency ultrasound imaging - micro-ultrasound - have drastically increased the capability of tissue imaging at high resolution. Our aim is to investigate the development of a robust deep learning model specifically for micro-ultrasound-guided prostate cancer biopsy. For the model to be clinically adopted, a key challenge is to design a solution that can confidently identify the cancer, while learning from coarse histopathology measurements of biopsy samples that introduce weak labels. METHODS: We use a dataset of micro-ultrasound images acquired from 194 patients, who underwent prostate biopsy. We train a deep model using a co-teaching paradigm to handle noise in labels, together with an evidential deep learning method for uncertainty estimation. We evaluate the performance of our model using the clinically relevant metric of accuracy vs. confidence. RESULTS: Our model achieves a well-calibrated estimation of predictive uncertainty with area under the curve of 88$\%$. The use of co-teaching and evidential deep learning in combination yields significantly better uncertainty estimation than either alone. We also provide a detailed comparison against state-of-the-art in uncertainty estimation.      
### 4.Deep Diffusion Models for Seismic Processing  [ :arrow_down: ](https://arxiv.org/pdf/2207.10451.pdf)
>  Seismic data processing involves techniques to deal with undesired effects that occur during acquisition and pre-processing. These effects mainly comprise coherent artefacts such as multiples, non-coherent signals such as electrical noise, and loss of signal information at the receivers that leads to incomplete traces. In the past years, there has been a remarkable increase of machine-learning-based solutions that have addressed the aforementioned issues. In particular, deep-learning practitioners have usually relied on heavily fine-tuned, customized discriminative algorithms. Although, these methods can provide solid results, they seem to lack semantic understanding of the provided data. Motivated by this limitation, in this work, we employ a generative solution, as it can explicitly model complex data distributions and hence, yield to a better decision-making process. In particular, we introduce diffusion models for three seismic applications: demultiple, denoising and interpolation. To that end, we run experiments on synthetic and on real data, and we compare the diffusion performance with standardized algorithms. We believe that our pioneer study not only demonstrates the capability of diffusion models, but also opens the door to future research to integrate generative models in seismic workflows.      
### 5.COBRA: Cpu-Only aBdominal oRgan segmentAtion  [ :arrow_down: ](https://arxiv.org/pdf/2207.10446.pdf)
>  Abdominal organ segmentation is a difficult and time-consuming task. To reduce the burden on clinical experts, fully-automated methods are highly desirable. Current approaches are dominated by Convolutional Neural Networks (CNNs) however the computational requirements and the need for large data sets limit their application in practice. By implementing a small and efficient custom 3D CNN, compiling the trained model and optimizing the computational graph: our approach produces high accuracy segmentations (Dice Similarity Coefficient (%): Liver: 97.3$\pm$1.3, Kidneys: 94.8$\pm$3.6, Spleen: 96.4$\pm$3.0, Pancreas: 80.9$\pm$10.1) at a rate of 1.6 seconds per image. Crucially, we are able to perform segmentation inference solely on CPU (no GPU required), thereby facilitating easy and widespread deployment of the model without specialist hardware.      
### 6.Stochastic Particle-Based Variational Bayesian Inference for Multi-band Radar Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2207.10427.pdf)
>  Multi-band fusion is an important technology to improve the radar sensing performance. In the multi-band radar sensing signal model, the associated likelihood function has oscillation phenomenon, which makes it difficult to obtain high-accuracy parameter estimation. To cope with this challenge, we divide the radar target parameter estimation into two stages of coarse estimation and refined estimation, where the coarse estimation is used to narrow down the search range for the refined estimation, and the refined estimation is based on the Bayesian approach to avoid the convergence to a bad local optimum of the likelihood function. Specifically, in the coarse estimation stage, we employ a root MUSIC algorithm to achieve initial estimation. Then, we apply the block stochastic successive convex approximation (SSCA) approach to derive a novel stochastic particle-based variational Bayesian inference (SPVBI) algorithm for the Bayesian estimation of the radar target parameters in the refined stage. Unlike the conventional particle-based VBI (PVBI) in which only the probability of each particle is optimized and the per-iteration computational complexity increases exponentially with the number of particles, the proposed SPVBI optimizes both the position and probability of each particle, and it adopts the block SSCA to significantly improve the sampling efficiency by averaging over iterations. As such, it is shown that the proposed SPVBI can achieve a better performance than the conventional PVBI with a much smaller number of particles and per-iteration complexity. Finally, extensive simulations verify the advantage of the proposed algorithm over various baseline algorithms.      
### 7.Detection and Mitigation of Corrupted Information in Distributed Model Predictive Control Based on Resource Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2207.10401.pdf)
>  In distributed predictive control structures, communication among agents is required to achieve a consensus and approach an optimal global behavior. Such negotiation mechanisms are sensitive to attacks on these exchanges. This paper proposes a monitoring scheme that detects and mitigates these attacks' effects in a resource allocation framework. The performance of the proposed method is illustrated through simulations of the temperature control of multiple rooms under power scarcity.      
### 8.Synthesizing Light Field Video from Monocular Video  [ :arrow_down: ](https://arxiv.org/pdf/2207.10357.pdf)
>  The hardware challenges associated with light-field(LF) imaging has made it difficult for consumers to access its benefits like applications in post-capture focus and aperture control. Learning-based techniques which solve the ill-posed problem of LF reconstruction from sparse (1, 2 or 4) views have significantly reduced the requirement for complex hardware. LF video reconstruction from sparse views poses a special challenge as acquiring ground-truth for training these models is hard. Hence, we propose a self-supervised learning-based algorithm for LF video reconstruction from monocular videos. We use self-supervised geometric, photometric and temporal consistency constraints inspired from a recent self-supervised technique for LF video reconstruction from stereo video. Additionally, we propose three key techniques that are relevant to our monocular video input. We propose an explicit disocclusion handling technique that encourages the network to inpaint disoccluded regions in a LF frame, using information from adjacent input temporal frames. This is crucial for a self-supervised technique as a single input frame does not contain any information about the disoccluded regions. We also propose an adaptive low-rank representation that provides a significant boost in performance by tailoring the representation to each input scene. Finally, we also propose a novel refinement block that is able to exploit the available LF image data using supervised learning to further refine the reconstruction quality. Our qualitative and quantitative analysis demonstrates the significance of each of the proposed building blocks and also the superior results compared to previous state-of-the-art monocular LF reconstruction techniques. We further validate our algorithm by reconstructing LF videos from monocular videos acquired using a commercial GoPro camera.      
### 9.Jointly Predicting Emotion, Age, and Country Using Pre-Trained Acoustic Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2207.10333.pdf)
>  In this paper, we demonstrated the benefit of using pre-trained model to extract acoustic embedding to jointly predict (multitask learning) three tasks: emotion, age, and native country. The pre-trained model was trained with wav2vec 2.0 large robust model on the speech emotion corpus. The emotion and age tasks were regression problems, while country prediction was a classification task. A single harmonic mean from three metrics was used to evaluate the performance of multitask learning. The classifier was a linear network with two independent layers and shared layers, including the output layers. This study explores multitask learning on different acoustic features (including the acoustic embedding extracted from a model trained on an affective speech dataset), seed numbers, batch sizes, and normalizations for predicting paralinguistic information from speech.      
### 10.Improved Generative Model for Weakly Supervised Chest Anomaly Localization via Pseudo-paired Registration with Bilaterally Symmetrical Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2207.10324.pdf)
>  Image translation based on a generative adversarial network (GAN-IT) is a promising method for precise localization of abnormal regions in chest X-ray images (AL-CXR). However, heterogeneous unpaired datasets undermine existing methods to extract key features and distinguish normal from abnormal cases, resulting in inaccurate and unstable AL-CXR. To address this problem, we propose an improved two-stage GAN-IT involving registration and data augmentation. For the first stage, we introduce an invertible deep-learning-based registration technique that virtually and reasonably converts unpaired data into paired data for learning registration maps. This novel approach achieves high registration performance. For the second stage, we apply data augmentation to diversify anomaly locations by swapping the left and right lung regions on the uniform registered frames, further improving the performance by alleviating imbalance in data distribution showing left and right lung lesions. Our method is intended for application to existing GAN-IT models, allowing existing architecture to benefit from key features for translation. By showing that the AL-CXR performance is uniformly improved when applying the proposed method, we believe that GAN-IT for AL-CXR can be deployed in clinical environments, even if learning data are scarce.      
### 11.Ensemble Learning for Efficient VVC Bitrate Ladder Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2207.10317.pdf)
>  Changing the encoding parameters, in particular the video resolution, is a common practice before transcoding. To this end, streaming and broadcast platforms benefit from so-called bitrate ladders to determine the optimal resolution for given bitrates. However, the task of determining the bitrate ladder can usually be challenging as, on one hand, so-called fit-for-all static ladders would waste bandwidth, and on the other hand, fully specialized ladders are often not affordable in terms of computational complexity. In this paper, we propose an ML-based scheme for predicting the bitrate ladder based on the content of the video. The baseline of our solution predicts the bitrate ladder using two constituent methods, which require no encoding passes. To further enhance the performance of the constituent methods, we integrate a conditional ensemble method to aggregate their decisions, with a negligibly limited number of encoding passes. The experiment, carried out on the optimized software encoder implementation of the VVC standard, called VVenC, shows significant performance improvement. When compared to static bitrate ladder, the proposed method can offer about 13% bitrate reduction in terms of BD-BR with a negligible additional computational overhead. Conversely, when compared to the fully specialized bitrate ladder method, the proposed method can offer about 86% to 92% complexity reduction, at cost the of only 0.8% to 0.9% coding efficiency drop in terms of BD-BR.      
### 12.Fundamental Limits and Optimization of Multiband Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2207.10306.pdf)
>  Multiband sensing is a promising technology that utilizes multiple non-contiguous frequency bands to achieve high-resolution target sensing. In this paper, we investigate the fundamental limits and optimization of multiband sensing, focusing on the fundamental limits associated with time delay. We first derive a Fisher information matrix (FIM) with a compact form using the Dirichlet kernel and then derive a closed-form expression of the Cramer-Rao bound (CRB) for the delay separation in a simplified case to reveal useful insights. Then, a metric called the statistical resolution limit (SRL) that provides a resolution limit is employed to investigate the fundamental limits of delay resolution. The fundamental limits of delay estimation are also investigated based on the CRB and Ziv-Zakai bound (ZZB). Based on the above derived fundamental limits, numerical results are presented to analyze the effect of frequency band apertures and phase distortions on the performance limits of the multiband sensing systems. We formulate an optimization problem to find the optimal system configuration in multiband sensing systems with the objective of minimizing the delay SRL. To solve this non-convex constrained problem, we propose an efficient alternating optimization (AO) algorithm which iteratively optimizes the variables using successive convex approximation (SCA) and one-dimensional search. Simulation results demonstrate the effectiveness of the proposed algorithm.      
### 13.Perspectives on distribution network flexible and curtailable resource activation and needs assessment  [ :arrow_down: ](https://arxiv.org/pdf/2207.10296.pdf)
>  A curtailable and flexible resource activation framework is proposed for solving distribution network (DN) voltage and thermal congestions. This framework utilizes network state in absence of such flexible or curtailable resources as an input for calculating flexibility activation signal (FAS). FAS design is motivated by volt-Var and volt-watt inverter control. The FAS has some similarities with optimal power flow duals, also referred to as locational marginal prices. These dual variables are active in case of network violations. FAS due to drooping design, corrects prior to any network limit violations. The nonlinear resource dispatch optimal power flow (RDOPF) is convexified using second-order cone (SOC) relaxations. Three case studies are performed, which are compared using performance indices proposed in this work. The first case study highlights the multi-objective nature of SOC relaxed RDOPF and provides a Pareto front tuning mechanism for reducing DN losses while also reducing the optimality gap of the SOC relaxed problem with respect to RDOPF. The second case study presents a methodology for evaluating temporal and locational flexibility needs assessment of a DN, which DSO's can utilize for flexibility planning. The last case study quantifies the impact of reactive power flexibility for a DN with varying load power factor. We observe that active power flexibility needs can be reduced by up to 50\% for DN with power factor of 0.8.      
### 14.Adversary Detection and Resilient Control for Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.10275.pdf)
>  This paper presents an adversary detection mechanism and a resilient control framework for multi-agent systems under spatiotemporal constraints. Safety in multi-agent systems is typically addressed under the assumption that all agents collaborate to ensure the forward invariance of a desired safe set. This work analyzes agent behaviors based on certain behavior metrics, and designs a proactive adversary detection mechanism based on the notion of the critical region for the system operation. In particular, the presented detection mechanism not only identifies adversarial agents, but also ensures all-time safety for intact agents. Then, based on the analysis and detection results, a resilient QP-based controller is presented to ensure safety and liveness constraints for intact agents. Simulation results validate the efficacy of the presented theoretical contributions.      
### 15.Can locational disparity of prosumer energy optimization due to inverter rules be limited?  [ :arrow_down: ](https://arxiv.org/pdf/2207.10248.pdf)
>  To mitigate issues related to growth of variable smart loads and distributed generation, distribution system operators (DSO) now make it binding for prosumers with inverters to operate under pre-set rules. In particular, the maximum active and reactive power set points for prosumers are based on local voltage measurements to ensure that inverter output does not cause voltage violations. However, such actions may restrict the range available for local energy management, thus reducing the profit which prosumer would otherwise have made. This work analyses the loss of arbitrage opportunity and ability to perform voltage regulation for active prosumers due to inverter operational rules and location along a radial distribution network (DN). We model the arbitrage opportunity as a linear programming based local control for load and energy storage output based on electricity price variations, while ensuring that active and reactive injection limits are respected at finer time scales. We observe that relative feeder location determines the effect of inverter rules on arbitrage profits, with more adverse losses for prosumers located farther away from the substation. Subsequently, we propose a hybrid control policy that helps minimize this locational discrepancy while regulating the nodal voltage. Case studies are presented using three identical prosumers located at different parts of a test network. We observe that the proposed hybrid policy reduces the locational disparity to less than 1.4\% between prosumers connected at the head and end of the feeder.      
### 16.Chance constrained day-ahead robust flexibility needs assessment for low voltage distribution network  [ :arrow_down: ](https://arxiv.org/pdf/2207.10234.pdf)
>  For market-based procurement of low voltage (LV) flexibility, DSOs identify the amount of flexibility needed for resolving probable distribution network (DN) voltage and thermal congestion. A framework is required to avoid over or under procurement of flexibility in the presence of uncertainty. To this end, we propose a scenario-based robust chance-constrained (CC) day-ahead flexibility needs assessment (FNA) framework. The CC level is analogous to the risk DSO is willing to take in flexibility planning. Multi-period optimal power flow is performed to calculate the amount of flexibility needed to avoid network issues. Flexibility is defined in terms of nodal power ramp-up and ramp-down and cumulative energy needs over a full day for each node. Future uncertainties are considered as multiple scenarios generated using multivariate Gaussian distribution and Cholesky decomposition. These scenarios are utilized to solve the flexibility needs assessment optimal power flow (FNA-OPF) problem. Zonal clustering of an LV feeder is performed using electrical distance as a measure and spatial partitioning. The FNA tool calculates ramp-up and ramp-down flexibility's power and energy requirements. Energy and power needs are often valued differently in many energy markets. We identify the marginal value of flexibility associated with energy and power needs separately. From numerical results for an LV feeder, it is observed that zonal flexibility needs assessment is more immune to uncertainty than nodal flexibility needs, making it more useful for DSOs to evaluate day-ahead flexibility procurement. We also propose a Pareto optimal mechanism for selecting CC level to reduce flexibility needs while reducing DN congestion.      
### 17.An IRS Backscatter Enabled Integrated Sensing, Communication and Computation System  [ :arrow_down: ](https://arxiv.org/pdf/2207.10219.pdf)
>  This paper proposes to leverage intelligent reflecting surface (IRS) backscatter to realize radio-frequency-chain-free uplink-transmissions (RFCF-UT). In this communication paradigm, IRS works as an information carrier, whose elements are capable of adjusting their amplitudes and phases to collaboratively portray an electromagnetic image like a dynamic quick response (QR) code, rather than a familiar reflection device, while a full-duplex base station (BS) is used as a scanner to collect and recognize the information on IRS. To elaborate it, an integrated sensing, communication and computation system as an example is presented, in which a dual-functional radar-communication BS simultaneously detects the target and collects the data from user equipments each connected to an IRS. Based on the established model, partial and binary data offloading strategies are respectively considered. By defining a performance metric named weighted throughput capacity (WTC), two maximization problems of WTC are formulated. According to the coupling degree of optimization variables in the objective function and the constraints, each optimization problem is firstly decomposed into two subproblems. Then, the methods of linear programming, fractional programming, integer programming and alternative optimization are developed to solve the subproblems. The simulation results demonstrate the achievable WTC of the considered system, thereby validating RFCF-UT.      
### 18.Flow-based Visual Quality Enhancer for Super-resolution Magnetic Resonance Spectroscopic Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2207.10181.pdf)
>  Magnetic Resonance Spectroscopic Imaging (MRSI) is an essential tool for quantifying metabolites in the body, but the low spatial resolution limits its clinical applications. Deep learning-based super-resolution methods provided promising results for improving the spatial resolution of MRSI, but the super-resolved images are often blurry compared to the experimentally-acquired high-resolution images. Attempts have been made with the generative adversarial networks to improve the image visual quality. In this work, we consider another type of generative model, the flow-based model, of which the training is more stable and interpretable compared to the adversarial networks. Specifically, we propose a flow-based enhancer network to improve the visual quality of super-resolution MRSI. Different from previous flow-based models, our enhancer network incorporates anatomical information from additional image modalities (MRI) and uses a learnable base distribution. In addition, we impose a guide loss and a data-consistency loss to encourage the network to generate images with high visual quality while maintaining high fidelity. Experiments on a 1H-MRSI dataset acquired from 25 high-grade glioma patients indicate that our enhancer network outperforms the adversarial networks and the baseline flow-based methods. Our method also allows visual quality adjustment and uncertainty estimation.      
### 19.Liver Segmentation using Turbolift Learning for CT and Cone-beam C-arm Perfusion Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2207.10167.pdf)
>  Model-based reconstruction employing the time separation technique (TST) was found to improve dynamic perfusion imaging of the liver using C-arm cone-beam computed tomography (CBCT). To apply TST using prior knowledge extracted from CT perfusion data, the liver should be accurately segmented from the CT scans. Reconstructions of primary and model-based CBCT data need to be segmented for proper visualisation and interpretation of perfusion maps. This research proposes Turbolift learning, which trains a modified version of the multi-scale Attention UNet on different liver segmentation tasks serially, following the order of the trainings CT, CBCT, CBCT TST - making the previous trainings act as pre-training stages for the subsequent ones - addressing the problem of limited number of datasets for training. For the final task of liver segmentation from CBCT TST, the proposed method achieved an overall Dice scores of 0.874$\pm$0.031 and 0.905$\pm$0.007 in 6-fold and 4-fold cross-validation experiments, respectively - securing statistically significant improvements over the model, which was trained only for that task. Experiments revealed that Turbolift not only improves the overall performance of the model but also makes it robust against artefacts originating from the embolisation materials and truncation artefacts. Additionally, in-depth analyses confirmed the order of the segmentation tasks. This paper shows the potential of segmenting the liver from CT, CBCT, and CBCT TST, learning from the available limited training data, which can possibly be used in the future for the visualisation and evaluation of the perfusion maps for the treatment evaluation of liver diseases.      
### 20.Trajectory PMB Filters for Extended Object Tracking Using Belief Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2207.10164.pdf)
>  In this paper, we propose a Poisson multi-Bernoulli (PMB) filter for extended object tracking (EOT), which directly estimates the set of object trajectories, using belief propagation (BP). The proposed filter propagates a PMB density on the posterior of sets of trajectories through the filtering recursions over time, where the PMB mixture (PMBM) posterior after the update step is approximated as a PMB. The efficient PMB approximation relies on several important theoretical contributions. First, we present a PMBM conjugate prior on the posterior of sets of trajectories for a generalized measurement model, in which each object generates an independent set of measurements. The PMBM density is a conjugate prior in the sense that both the prediction and the update steps preserve the PMBM form of the density. Second, we present a factor graph representation of the joint posterior of the PMBM set of trajectories and association variables for the Poisson spatial measurement model. Importantly, leveraging the PMBM conjugacy and the factor graph formulation enables an elegant treatment on undetected objects via a Poisson point process and efficient inference on sets of trajectories using BP, where the approximate marginal densities in the PMB approximation can be obtained without enumeration of different data association hypotheses. To achieve this, we present a particle-based implementation of the proposed filter, where smoothed trajectory estimates, if desired, can be obtained via single-object particle smoothing methods, and its performance for EOT with ellipsoidal shapes is evaluated in a simulation study.      
### 21.Multimodal Estimation of End Point Force During Quasi-dynamic and Dynamic Muscle Contractions Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.10154.pdf)
>  Accurate force/torque estimation is essential for applications such as powered exoskeletons, robotics, and rehabilitation. However, force/torque estimation under dynamic conditions is a challenging due to changing joint angles, force levels, muscle lengths, and movement speeds. We propose a novel method to accurately model the generated force under isotonic, isokinetic (quasi-dynamic), and fully dynamic conditions. Our solution uses a deep multimodal CNN to learn from multimodal EMG-IMU data and estimate the generated force for elbow flexion and extension, for both intra- and inter-subject schemes. The proposed deep multimodal CNN extracts representations from EMG (in time and frequency domains) and IMU (in time domain) and aggregates them to obtain an effective embedding for force estimation. We describe a new dataset containing EMG, IMU, and output force data, collected under a number of different experimental conditions, and use this dataset to evaluate our proposed method. The results show the robustness of our approach in comparison to other baseline methods as well as those in the literature, in different experimental setups and validation schemes. The obtained $R^2$ values are 0.91$\pm$0.034, 0.87$\pm$0.041, and 0.81$\pm$0.037 for the intra-subject and 0.81$\pm$0.048, 0.64$\pm$0.037, and 0.59$\pm$0.042 for the inter-subject scheme, during isotonic, isokinetic, and dynamic contractions, respectively. Additionally, our results indicate that force estimation improves significantly when the kinematic information (IMU data) is included. Average improvements of 13.95\%, 118.18\%, and 50.0\% (intra-subject) and 28.98\%, 41.18\%, and 137.93\% (inter-subject) for isotonic, isokinetic, and dynamic contractions respectively are achieved.      
### 22.Dynamic Load Altering EV Attacks Against Power Grid Frequency Control  [ :arrow_down: ](https://arxiv.org/pdf/2207.10129.pdf)
>  Driven by the necessity to combat climate change, Electric Vehicles (EV) are being deployed to take advantage of their ability in reducing emissions generated by the transportation sector. This deployment has left the power grid vulnerable to attacks through the EV infrastructure. This paper is written from an attackerś perspective and proposes a dynamic load altering strategy through manipulating EV charging to destabilize the grid. The attack is formulated based on feedback control theory, i.e., designing an attack based on Linear Matrix Inequalities (LMIs). After the stability metric and controller design have been established, we demonstrate our attack method against the Kundur 2 area grid. The attack scenario includes a cap of 200 MW EV load controlled by the attacker. However, the results show that even with this limitation, the attacker would be successful in pushing the grid toward instability and blackout.      
### 23.STOP: A dataset for Spoken Task Oriented Semantic Parsing  [ :arrow_down: ](https://arxiv.org/pdf/2207.10643.pdf)
>  End-to-end spoken language understanding (SLU) predicts intent directly from audio using a single model. It promises to improve the performance of assistant systems by leveraging acoustic information lost in the intermediate textual representation and preventing cascading errors from Automatic Speech Recognition (ASR). Further, having one unified model has efficiency advantages when deploying assistant systems on-device. However, the limited number of public audio datasets with semantic parse labels hinders the research progress in this area. In this paper, we release the Spoken Task-Oriented semantic Parsing (STOP) dataset, the largest and most complex SLU dataset to be publicly available. Additionally, we define low-resource splits to establish a benchmark for improving SLU when limited labeled data is available. Furthermore, in addition to the human-recorded audio, we are releasing a TTS-generated version to benchmark the performance for low-resource domain adaptation of end-to-end SLU systems. Initial experimentation show end-to-end SLU models performing slightly worse than their cascaded counterparts, which we hope encourages future work in this direction.      
### 24.A Dynamical Systems Algorithm for Clustering in Hyperspectral Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2207.10625.pdf)
>  In this paper we present a new dynamical systems algorithm for clustering in hyperspectral images. The main idea of the algorithm is that data points are pushed\' in the direction of increasing density and groups of pixels that end up in the same dense regions belong to the same class. This is essentially a numerical solution of the differential equation defined by the gradient of the density of data points on the data manifold. The number of classes is automated and the resulting clustering can be extremely accurate. In addition to providing a accurate clustering, this algorithm presents a new tool for understanding hyperspectral data in high dimensions. We evaluate the algorithm on the Urban (Available at <a class="link-external link-http" href="http://www.tec.ary.mil/Hypercube/" rel="external noopener nofollow">this http URL</a>) scene comparing performance against the k-means algorithm using pre-identified classes of materials as ground truth.      
### 25.Knowledge Transfer and Distillation from Autoregressive to Non-Autoregressive Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2207.10600.pdf)
>  Modern non-autoregressive~(NAR) speech recognition systems aim to accelerate the inference speed; however, they suffer from performance degradation compared with autoregressive~(AR) models as well as the huge model size issue. We propose a novel knowledge transfer and distillation architecture that leverages knowledge from AR models to improve the NAR performance while reducing the model's size. Frame- and sequence-level objectives are well-designed for transfer learning. To further boost the performance of NAR, a beam search method on Mask-CTC is developed to enlarge the search space during the inference stage. Experiments show that the proposed NAR beam search relatively reduces CER by over 5% on AISHELL-1 benchmark with a tolerable real-time-factor~(RTF) increment. By knowledge transfer, the NAR student who has the same size as the AR teacher obtains relative CER reductions of 8/16% on AISHELL-1 dev/test sets, and over 25% relative WER reductions on LibriSpeech test-clean/other sets. Moreover, the ~9x smaller NAR models achieve ~25% relative CER/WER reductions on both AISHELL-1 and LibriSpeech benchmarks with the proposed knowledge transfer and distillation.      
### 26.Surrey System for DCASE 2022 Task 5: Few-shot Bioacoustic Event Detection with Segment-level Metric Learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.10547.pdf)
>  Few-shot audio event detection is a task that detects the occurrence time of a novel sound class given a few examples. In this work, we propose a system based on segment-level metric learning for the DCASE 2022 challenge of few-shot bioacoustic event detection (task 5). We make better utilization of the negative data within each sound class to build the loss function, and use transductive inference to gain better adaptation on the evaluation set. For the input feature, we find the per-channel energy normalization concatenated with delta mel-frequency cepstral coefficients to be the most effective combination. We also introduce new data augmentation and post-processing procedures for this task. Our final system achieves an f-measure of 68.74 on the DCASE task 5 validation set, outperforming the baseline performance of 29.5 by a large margin. Our system is fully open-sourced at <a class="link-external link-https" href="https://github.com/haoheliu/DCASE_2022_Task_5" rel="external noopener nofollow">this https URL</a>.      
### 27.Neural Network Learning of Chemical Bond Representations in Spectral Indices and Features  [ :arrow_down: ](https://arxiv.org/pdf/2207.10530.pdf)
>  In this paper we investigate neural networks for classification in hyperspectral imaging with a focus on connecting the architecture of the network with the physics of the sensing and materials present. Spectroscopy is the process of measuring light reflected or emitted by a material as a function wavelength. Molecular bonds present in the material have vibrational frequencies which affect the amount of light measured at each wavelength. Thus the measured spectrum contains information about the particular chemical constituents and types of bonds. For example, chlorophyll reflects more light in the near-IR rage (800-900nm) than in the red (625-675nm) range, and this difference can be measured using a normalized vegetation difference index (NDVI), which is commonly used to detect vegetation presence, health, and type in imagery collected at these wavelengths. In this paper we show that the weights in a Neural Network trained on different vegetation classes learn to measure this difference in reflectance. We then show that a Neural Network trained on a more complex set of ten different polymer materials will learn spectral 'features' evident in the weights for the network, and these features can be used to reliably distinguish between the different types of polymers. Examination of the weights provides a human-interpretable understanding of the network.      
### 28.Multi-Event-Camera Depth Estimation and Outlier Rejection by Refocused Events Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2207.10494.pdf)
>  Event cameras are bio-inspired sensors that offer advantages over traditional cameras. They work asynchronously, sampling the scene with microsecond resolution and producing a stream of brightness changes. This unconventional output has sparked novel computer vision methods to unlock the camera's potential. We tackle the problem of event-based stereo 3D reconstruction for SLAM. Most event-based stereo methods try to exploit the camera's high temporal resolution and event simultaneity across cameras to establish matches and estimate depth. By contrast, we investigate how to estimate depth without explicit data association by fusing Disparity Space Images (DSIs) originated in efficient monocular methods. We develop fusion theory and apply it to design multi-camera 3D reconstruction algorithms that produce state-of-the-art results, as we confirm by comparing against four baseline methods and testing on a variety of available datasets.      
### 29.Room geometry blind inference based on the localization of real sound source and first order reflections  [ :arrow_down: ](https://arxiv.org/pdf/2207.10478.pdf)
>  The conventional room geometry blind inference techniques with acoustic signals are conducted based on the prior knowledge of the environment, such as the room impulse response (RIR) or the sound source position, which will limit its application under known scenarios. To solve this problem, we have proposed a room geometry reconstruction method in this paper by using the geometric relation between the direct signal and first-order reflections. In addition to the information of the compact microphone array itself, this method does not need any precognition of the environmental parameters. Besides, the learning-based DNN models are designed and used to improve the accuracy and integrity of the localization results of the direct source and first-order reflections. The direction of arrival (DOA) and time difference of arrival (TDOA) information of the direct and reflected signals are firstly estimated using the proposed DCNN and TD-CNN models, which have higher sensitivity and accuracy than the conventional methods. Then the position of the sound source is inferred by integrating the DOA, TDOA and array height using the proposed DNN model. After that, the positions of image sources and corresponding boundaries are derived based on the geometric relation. Experimental results of both simulations and real measurements verify the effectiveness and accuracy of the proposed techniques compared with the conventional methods under different reverberant environments.      
### 30.Fast Data Driven Estimation of Cluster Number in Multiplex Images using Embedded Density Outliers  [ :arrow_down: ](https://arxiv.org/pdf/2207.10469.pdf)
>  The usage of chemical imaging technologies is becoming a routine accompaniment to traditional methods in pathology. Significant technological advances have developed these next generation techniques to provide rich, spatially resolved, multidimensional chemical images. The rise of digital pathology has significantly enhanced the synergy of these imaging modalities with optical microscopy and immunohistochemistry, enhancing our understanding of the biological mechanisms and progression of diseases. Techniques such as imaging mass cytometry provide labelled multidimensional (multiplex) images of specific components used in conjunction with digital pathology techniques. These powerful techniques generate a wealth of high dimensional data that create significant challenges in data analysis. Unsupervised methods such as clustering are an attractive way to analyse these data, however, they require the selection of parameters such as the number of clusters. Here we propose a methodology to estimate the number of clusters in an automatic data-driven manner using a deep sparse autoencoder to embed the data into a lower dimensional space. We compute the density of regions in the embedded space, the majority of which are empty, enabling the high density regions to be detected as outliers and provide an estimate for the number of clusters. This framework provides a fully unsupervised and data-driven method to analyse multidimensional data. In this work we demonstrate our method using 45 multiplex imaging mass cytometry datasets. Moreover, our model is trained using only one of the datasets and the learned embedding is applied to the remaining 44 images providing an efficient process for data analysis. Finally, we demonstrate the high computational efficiency of our method which is two orders of magnitude faster than estimating via computing the sum squared distances as a function of cluster number.      
### 31.Deep Audio Waveform Prior  [ :arrow_down: ](https://arxiv.org/pdf/2207.10441.pdf)
>  Convolutional neural networks contain strong priors for generating natural looking images [1]. These priors enable image denoising, super resolution, and inpainting in an unsupervised manner. Previous attempts to demonstrate similar ideas in audio, namely deep audio priors, (i) use hand picked architectures such as harmonic convolutions, (ii) only work with spectrogram input, and (iii) have been used mostly for eliminating Gaussian noise [2]. In this work we show that existing SOTA architectures for audio source separation contain deep priors even when working with the raw waveform. Deep priors can be discovered by training a neural network to generate a single corrupted signal when given white noise as input. A network with relevant deep priors is likely to generate a cleaner version of the signal before converging on the corrupted signal. We demonstrate this restoration effect with several corruptions: background noise, reverberations, and a gap in the signal (audio inpainting).      
### 32.Integrating Terrestrial and Non-terrestrial Networks: 3D Opportunities and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2207.10385.pdf)
>  Integrating terrestrial and non-terrestrial networks has the potential of connecting the unconnected and enhancing the user experience for the already-connected, with technological and societal implications of the greatest long-term significance. A convergence of ground, air, and space wireless communications also represents a formidable endeavor for the mobile and satellite communications industries alike, as it entails defining and intelligently orchestrating a new 3D wireless network architecture. In this article, we present the key opportunities and challenges arising from this (r)evolution by presenting some of its disruptive use-cases and key building blocks, reviewing the relevant standardization activities, and pointing to open research problems. By considering two multi-operator paradigms, we also showcase how terrestrial networks could be efficiently re-engineered to cater for aerial services, or opportunistically complemented by non-terrestrial infrastructure to augment their current capabilities.      
### 33.CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2207.10345.pdf)
>  Despite breakthrough advances in image super-resolution (SR) with convolutional neural networks (CNNs), SR has yet to enjoy ubiquitous applications due to the high computational complexity of SR networks. Quantization is one of the promising approaches to solve this problem. However, existing methods fail to quantize SR models with a bit-width lower than 8 bits, suffering from severe accuracy loss due to fixed bit-width quantization applied everywhere. In this work, to achieve high average bit-reduction with less accuracy loss, we propose a novel Content-Aware Dynamic Quantization (CADyQ) method for SR networks that allocates optimal bits to local regions and layers adaptively based on the local contents of an input image. To this end, a trainable bit selector module is introduced to determine the proper bit-width and quantization level for each layer and a given local image patch. This module is governed by the quantization sensitivity that is estimated by using both the average magnitude of image gradient of the patch and the standard deviation of the input feature of the layer. The proposed quantization pipeline has been tested on various SR networks and evaluated on several standard benchmarks extensively. Significant reduction in computational complexity and the elevated restoration accuracy clearly demonstrate the effectiveness of the proposed CADyQ framework for SR. Codes are available at <a class="link-external link-https" href="https://github.com/Cheeun/CADyQ" rel="external noopener nofollow">this https URL</a>.      
### 34.A Survey on Leveraging Pre-trained Generative Adversarial Networks for Image Editing and Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2207.10309.pdf)
>  Generative adversarial networks (GANs) have drawn enormous attention due to the simple yet effective training mechanism and superior image generation quality. With the ability to generate photo-realistic high-resolution (e.g., $1024\times1024$) images, recent GAN models have greatly narrowed the gaps between the generated images and the real ones. Therefore, many recent works show emerging interest to take advantage of pre-trained GAN models by exploiting the well-disentangled latent space and the learned GAN priors. In this paper, we briefly review recent progress on leveraging pre-trained large-scale GAN models from three aspects, i.e., 1) the training of large-scale generative adversarial networks, 2) exploring and understanding the pre-trained GAN models, and 3) leveraging these models for subsequent tasks like image restoration and editing. More information about relevant methods and repositories can be found at <a class="link-external link-https" href="https://github.com/csmliu/pretrained-GANs" rel="external noopener nofollow">this https URL</a>.      
### 35.Frequency Permutation Subsets for Joint Radar and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2207.10303.pdf)
>  This paper focuses on waveform design for joint radar and communication systems and presents a new subset selection process to improve the communication error rate performance and global accuracy of radar sensing of the random stepped frequency permutation waveform. An optimal communication receiver based on integer programming is proposed to handle any subset of permutations followed by a more efficient sub-optimal receiver based on the Hungarian algorithm. Considering optimum maximum likelihood detection, the block error rate is analyzed under both additive white Gaussian noise and correlated Rician fading. We propose two methods to select a permutation subset with an improved block error rate and an efficient encoding scheme to map the information symbols to selected permutations under these subsets. From the radar perspective, the ambiguity function is analyzed with regards to the local and the global accuracy of target detection. Furthermore, a subset selection method to reduce the maximum sidelobe height is proposed by extending the properties of Costas arrays. Finally, the process of remapping the frequency tones to the symbol set used to generate permutations is introduced as a method to improve both the communication and radar performances of the selected permutation subset.      
### 36.Optimal Control of Multi-Agent Systems with Processing Delays  [ :arrow_down: ](https://arxiv.org/pdf/2207.10294.pdf)
>  In this article, we consider a cooperative control problem involving dynamically decoupled linear plants. The (output-feedback) controllers for each plant communicate with each other according to a fixed and known network topology, and each transmission incurs a fixed continuous-time processing delay. We provide an explicit closed-form expression for the optimal decentralized controller and its associated cost under these communication constraints and standard linear quadratic Gaussian (LQG) assumptions for the plants and cost function. We find the exact solution without discretizing or otherwise approximating the delays. We also present an implementation of each sub-controller that is efficiently computable, and is composed of standard finite-dimensional linear time-invariant (LTI) and finite impulse response (FIR) components, and has an intuitive observer-regulator architecture reminiscent of the classical separation principle.      
### 37.Multi Resolution Analysis (MRA) for Approximate Self-Attention  [ :arrow_down: ](https://arxiv.org/pdf/2207.10284.pdf)
>  Transformers have emerged as a preferred model for many tasks in natural langugage processing and vision. Recent efforts on training and deploying Transformers more efficiently have identified many strategies to approximate the self-attention matrix, a key module in a Transformer architecture. Effective ideas include various prespecified sparsity patterns, low-rank basis expansions and combinations thereof. In this paper, we revisit classical Multiresolution Analysis (MRA) concepts such as Wavelets, whose potential value in this setting remains underexplored thus far. We show that simple approximations based on empirical feedback and design choices informed by modern hardware and implementation challenges, eventually yield a MRA-based approach for self-attention with an excellent performance profile across most criteria of interest. We undertake an extensive set of experiments and demonstrate that this multi-resolution scheme outperforms most efficient self-attention proposals and is favorable for both short and long sequences. Code is available at \url{<a class="link-external link-https" href="https://github.com/mlpen/mra-attention" rel="external noopener nofollow">this https URL</a>}.      
### 38.An Evolutionary Game based Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier Detection for Wireless Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2207.10282.pdf)
>  Trustworthy and reliable data delivery is a challenging task in Wireless Sensor Networks (WSNs) due to unique characteristics and constraints. To acquire secured data delivery and address the conflict between security and energy, in this paper we present an evolutionary game based secure clustering protocol with fuzzy trust evaluation and outlier detection for WSNs. Firstly, a fuzzy trust evaluation method is presented to transform the transmission evidences into trust values while effectively alleviating the trust uncertainty. And then, a K-Means based outlier detection scheme is proposed to further analyze plenty of trust values obtained via fuzzy trust evaluation or trust recommendation. It can discover the commonalities and differences among sensor nodes while improving the accuracy of outlier detection. Finally, we present an evolutionary game based secure clustering protocol to achieve a trade-off between security assurance and energy saving for sensor nodes when electing for the cluster heads. A sensor node which failed to be the cluster head can securely choose its own head by isolating the suspicious nodes. Simulation results verify that our secure clustering protocol can effectively defend the network against the attacks from internal selfish or compromised nodes. Correspondingly, the timely data transfer rate can be improved significantly.      
### 39.Spatial Aware Multi-Task Learning Based Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2207.10229.pdf)
>  During the Covid, online meetings have become an indispensable part of our lives. This trend is likely to continue due to their convenience and broad reach. However, background noise from other family members, roommates, office-mates not only degrades the voice quality but also raises serious privacy issues. In this paper, we develop a novel system, called Spatial Aware Multi-task learning-based Separation (SAMS), to extract audio signals from the target user during teleconferencing. Our solution consists of three novel components: (i) generating fine-grained location embeddings from the user's voice and inaudible tracking sound, which contains the user's position and rich multipath information, (ii) developing a source separation neural network using multi-task learning to jointly optimize source separation and location, and (iii) significantly speeding up inference to provide a real-time guarantee. Our testbed experiments demonstrate the effectiveness of our approach      
### 40.Direct Localization in Underwater Acoustics via Convolutional Neural Networks: A Data-Driven Approach  [ :arrow_down: ](https://arxiv.org/pdf/2207.10222.pdf)
>  Direct localization (DLOC) methods, which use the observed data to localize a source at an unknown position in a one-step procedure, generally outperform their indirect two-step counterparts (e.g., using time-difference of arrivals). However, underwater acoustic DLOC methods require prior knowledge of the environment, and are computationally costly, hence slow. We propose, what is to the best of our knowledge, the first data-driven DLOC method. Inspired by classical and contemporary optimal model-based DLOC solutions, and leveraging the capabilities of convolutional neural networks (CNNs), we devise a holistic CNN-based solution. Our method includes a specifically-tailored input structure, architecture, loss function, and a progressive training procedure, which are of independent interest in the broader context of machine learning. We demonstrate that our method outperforms attractive alternatives, and asymptotically matches the performance of an oracle optimal model-based solution.      
### 41.Globally stable and locally optimal model predictive control using a softened initial state constraint -- extended version  [ :arrow_down: ](https://arxiv.org/pdf/2207.10216.pdf)
>  To address feasibility issues in model predictive control (MPC), most implementations relax hard state constraints using additional slack variables with a suitable penalty. We propose an alternative strategy for open-loop asymptotically/Lyapunov stable nonlinear systems by relaxing the initial state constraint with a suitable penalty. The proposed MPC framework is globally feasible, ensures (semi-)global asymptotic stability, and (approximately) recovers the closed-loop properties of the nominal MPC on the feasible set. The proposed framework can be naturally combined with a robust formulation to ensure robustness subject to bounded disturbances while retaining input-ot-state stability in case of arbitrarily large disturbances. We also show how the overall design can be simplified in case the nonlinear system is exponentially stable. In the special case of linear systems, the proposed MPC formulation reduces to a quadratic program and the offline design and online computational complexity is only marginally increased compared to anominal design. Benefits compared to classical soft contrained MPC formulations are demonstrated with numerical examples.      
### 42.Watermark-Based Code Construction for Finite-State Markov Channel with Synchronisation Errors  [ :arrow_down: ](https://arxiv.org/pdf/2207.10204.pdf)
>  With advancements in telecommunications, data transmission over increasingly harsher channels that produce synchronisation errors is inevitable. Coding schemes for such channels are available through techniques such as the Davey-MacKay watermark coding; however, this is limited to memoryless channel estimates. Memory must be accounted for to ensure a realistic channel approximation - similar to a Finite State Markov Chain or Fritchman Model. A novel code construction and decoder are developed to correct synchronisation errors while considering the channel's correlated memory effects by incorporating ideas from the watermark scheme and memory modelling. Simulation results show that the proposed code construction and decoder rival the first and second-order Davey-MacKay type watermark decoder and even perform slightly better when the inner-channel capacity is higher than 0.9. The proposed system and decoder may prove helpful in fields such as free-space optics and possibly molecular communication, where harsh channels are used for communication.      
### 43.AudioScopeV2: Audio-Visual Attention Architectures for Calibrated Open-Domain On-Screen Sound Separation  [ :arrow_down: ](https://arxiv.org/pdf/2207.10141.pdf)
>  We introduce AudioScopeV2, a state-of-the-art universal audio-visual on-screen sound separation system which is capable of learning to separate sounds and associate them with on-screen objects by looking at in-the-wild videos. We identify several limitations of previous work on audio-visual on-screen sound separation, including the coarse resolution of spatio-temporal attention, poor convergence of the audio separation model, limited variety in training and evaluation data, and failure to account for the trade off between preservation of on-screen sounds and suppression of off-screen sounds. We provide solutions to all of these issues. Our proposed cross-modal and self-attention network architectures capture audio-visual dependencies at a finer resolution over time, and we also propose efficient separable variants that are capable of scaling to longer videos without sacrificing much performance. We also find that pre-training the separation model only on audio greatly improves results. For training and evaluation, we collected new human annotations of onscreen sounds from a large database of in-the-wild videos (YFCC100M). This new dataset is more diverse and challenging. Finally, we propose a calibration procedure that allows exact tuning of on-screen reconstruction versus off-screen suppression, which greatly simplifies comparing performance between models with different operating points. Overall, our experimental results show marked improvements in on-screen separation performance under much more general conditions than previous methods with minimal additional computational complexity.      
### 44.World Robot Challenge 2020 -- Partner Robot: A Data-Driven Approach for Room Tidying with Mobile Manipulator  [ :arrow_down: ](https://arxiv.org/pdf/2207.10106.pdf)
>  Tidying up a household environment using a mobile manipulator poses various challenges in robotics, such as adaptation to large real-world environmental variations, and safe and robust deployment in the presence of humans.The Partner Robot Challenge in World Robot Challenge (WRC) 2020, a global competition held in September 2021, benchmarked tidying tasks in the real home environments, and importantly, tested for full system performances.For this challenge, we developed an entire household service robot system, which leverages a data-driven approach to adapt to numerous edge cases that occur during the execution, instead of classical manual pre-programmed <a class="link-external link-http" href="http://solutions.In" rel="external noopener nofollow">this http URL</a> this paper, we describe the core ingredients of the proposed robot system, including visual recognition, object manipulation, and motion planning. Our robot system won the second prize, verifying the effectiveness and potential of data-driven robot systems for mobile manipulation in home environments.      
