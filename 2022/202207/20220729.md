# ArXiv eess --Fri, 29 Jul 2022
### 1.Improving the Performance of Robust Control through Event-Triggered Learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.14252.pdf)
>  Robust controllers ensure stability in feedback loops designed under uncertainty but at the cost of performance. Model uncertainty in time-invariant systems can be reduced by recently proposed learning-based methods, thus improving the performance of robust controllers using data. However, in practice, many systems also exhibit uncertainty in the form of changes over time, e.g., due to weight shifts or wear and tear, leading to decreased performance or instability of the learning-based controller. We propose an event-triggered learning algorithm that decides when to learn in the face of uncertainty in the LQR problem with rare or slow changes. Our key idea is to switch between robust and learned controllers. For learning, we first approximate the optimal length of the learning phase via Monte-Carlo estimations using a probabilistic model. We then design a statistical test for uncertain systems based on the moment-generating function of the LQR cost. The test detects changes in the system under control and triggers re-learning when control performance deteriorates due to system changes. We demonstrate improved performance over a robust controller baseline in a numerical example.      
### 2.Dialogue Enhancement and Listening Effort in Broadcast Audio: A Multimodal Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2207.14240.pdf)
>  Dialogue enhancement (DE) plays a vital role in broadcasting, enabling the personalization of the relative level between foreground speech and background music and effects. DE has been shown to improve the quality of experience, intelligibility, and self-reported listening effort (LE). A physiological indicator of LE known from audiology studies is pupil size. The relation between pupil size and LE is typically studied using artificial sentences and background noises not encountered in broadcast content. This work evaluates the effect of DE on LE in a multimodal manner that includes pupil size (tracked by a VR headset) and real-world audio excerpts from TV. Under ideal listening conditions, 28 normal-hearing participants listened to 30 audio excerpts presented in random order and processed by conditions varying the relative level between foreground and background audio. One of these conditions employed a recently proposed source separation system to attenuate the background given the original mixture as the sole input. After listening to each excerpt, subjects were asked to repeat the heard sentence and self-report the LE. Mean pupil dilation and peak pupil dilation were analyzed and compared with the self-report and the word recall rate. The multimodal evaluation shows a consistent trend of decreasing LE along with decreasing background level. DE, also when enabled by source separation, significantly reduces the pupil size as well as the self-reported LE. This highlights the benefit of personalization functionalities at the user's end.      
### 3.Re-thinking and Re-labeling LIDC-IDRI for Robust Pulmonary Cancer Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2207.14238.pdf)
>  The LIDC-IDRI database is the most popular benchmark for lung cancer prediction. However, with subjective assessment from radiologists, nodules in LIDC may have entirely different malignancy annotations from the pathological ground truth, introducing label assignment errors and subsequent supervision bias during training. The LIDC database thus requires more objective labels for learning-based cancer prediction. Based on an extra small dataset containing 180 nodules diagnosed by pathological examination, we propose to re-label LIDC data to mitigate the effect of original annotation bias verified on this robust benchmark. We demonstrate in this paper that providing new labels by similar nodule retrieval based on metric learning would be an effective re-labeling strategy. Training on these re-labeled LIDC nodules leads to improved model performance, which is enhanced when new labels of uncertain nodules are added. We further infer that re-labeling LIDC is current an expedient way for robust lung cancer prediction while building a large pathological-proven nodule database provides the long-term solution.      
### 4.Construction of Multi-period TSO-DSO Flexibility Regions  [ :arrow_down: ](https://arxiv.org/pdf/2207.14203.pdf)
>  Active distribution networks (ADN) have grown considerably in recent years. Distributed energy resources present in ADNs can provide flexibility to the power system through TSO/DSO coordination, i.e., at the interface node (feeder) between the transmission and distribution network. This paper addresses the issue of calculating multi-period flexibility regions of the ADNs. Flexibility regions are tightly dependent between periods and conditioned on the actual deployment of such flexibilities in real-time. The existing state-of-the-art has not provided a robust methodology for building multi-period flexible regions. We present a new mathematical framework based on a non-iterative formulation that considers the multi-period flexibility boundary points in a single optimization problem. The proposed methodology is evaluated on IEEE standard test networks and compared with the most widely used methods in the literature.      
### 5.Channel Estimation for Reconfigurable Intelligent Surface-Assisted Cell-Free Communications  [ :arrow_down: ](https://arxiv.org/pdf/2207.14182.pdf)
>  Recent research has focused on reconfigurable intelligent surface (RIS)-assisted cell-free systems with the goal of enhancing coverage and lowering the cost of cell-free networks. However, current research makes the assumption that the perfect channel state information is known. Channel acquisition is, certainly, a difficulty in this case. This work is aimed at investigating RIS-assisted cell-free channel estimation. Toward this end, two unique characteristics are pointed out: 1) For all users, a common channel exists between the base station (BS) and the RIS; and 2) For all BSs, a common channel exists between the RIS and the user. Based on these two characteristics, cascaded and two-timescale channel estimation concerns are studied. Subsequently, two solutions for tackling with the two issues are presented respectively: a three-dimensional multiple measurement vector (3D-MMV)-based compressive sensing technique and a multi-BS cooperative pilot-reduced methodology. Finally, simulations illustrate the effectiveness of the schemes we have presented.      
### 6.Bayesian Optimization-Based Beam Alignment for MmWave MIMO Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.14174.pdf)
>  Due to the very narrow beam used in millimeter wave communication (mmWave), beam alignment (BA) is a critical issue. In this work, we investigate the issue of mmWave BA and present a novel beam alignment scheme on the basis of a machine learning strategy, Bayesian optimization (BO). In this context, we consider the beam alignment issue to be a black box function and then use BO to find the possible optimal beam pair. During the BA procedure, this strategy exploits information from the measured beam pairs to predict the best beam pair. In addition, we suggest a novel BO algorithm based on the gradient boosting regression tree model. The simulation results demonstrate the spectral efficiency performance of our proposed schemes for BA using three different surrogate models. They also demonstrate that the proposed schemes can achieve spectral efficiency with a small overhead when compared to the orthogonal match pursuit (OMP) algorithm and the Thompson sampling-based multi-armed bandit (TS-MAB) method.      
### 7.A Transformer-based Generative Adversarial Network for Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2207.14134.pdf)
>  Brain tumor segmentation remains a challenge in medical image segmentation tasks. With the application of transformer in various computer vision tasks, transformer blocks show the capability of learning long-distance dependency in global space, which is complementary with CNNs. In this paper, we proposed a novel transformer-based generative adversarial network to automatically segment brain tumors with multi-modalities MRI. Our architecture consists of a generator and a discriminator, which are trained in min-max game progress. The generator is based on a typical "U-shaped" encoder-decoder architecture, whose bottom layer is composed of transformer blocks with resnet. Besides, the generator is trained with deep supervision technology. The discriminator we designed is a CNN-based network with multi-scale $L_{1}$ loss, which is proved to be effective for medical semantic image segmentation. To validate the effectiveness of our method, we conducted experiments on BRATS2015 dataset, achieving comparable or better performance than previous state-of-the-art methods.      
### 8.Fast Compressive Channel Estimation for MmWave MIMO Hybrid Beamforming Systems  [ :arrow_down: ](https://arxiv.org/pdf/2207.14107.pdf)
>  Given the high degree of computational complexity of the channel estimation technique based on the conventional one-dimensional (1-D) compressive sensing (CS) framework employed in the hybrid beamforming architecture, this study proposes two low-complexity channel estimation strategies. One is two-stage CS, which exploits row-group sparsity to estimate angle-of-arrival (AoA) first and uses the conventional 1-D CS method to obtain angle-of-departure (AoD). The other is two-dimensional (2-D) CS, which utilizes a 2-D dictionary to reconstruct the 2-D sparse signal. To conduct a meaningful comparison of the three CS frameworks, i.e., 1-D, two-stage and 2-D CS, the orthogonal match pursuit (OMP) algorithm is employed as the basic algorithm and is expanded to two variants for the proposed frameworks. Analysis and simulations demonstrate that when the 1-D CS method is compared, two-stage CS has somewhat lower performance but significantly lower computational complexity, while 2-D CS is not only the same as 1-D CS in terms of performance but also slightly lower in computational complexity than two-stage CS.      
### 9.Low-complexity Sparse Array Synthesis Based on Off-grid Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2207.14103.pdf)
>  A novel sparse array synthesis method for non-uniform planar arrays is proposed, which belongs to compressive sensing (CS)-based systhesis. Particularly, we propose an off-grid refinement technique to simultaneously optimize the antenna element positions and excitations with a low complexity, in response to the antenna position optimization problem that is difficult for standard CS. More importantly, we take into account the minimum inter-element spacing constraint for ensuring the physically realizable solution. Specifically, the off-grid Orthogonal Match Pursuit (OMP) algorithm is first proposed with low complexity and then off-grid Look Ahead Orthogonal Match Pursuit (LAOMP) is designed with better synthesis performance but higher complexity. In addition, simulation results have shown the proposed schemes have more advantages in computational complexity and synthesis performances compared with the related method.      
### 10.Spotlight on nerves: Portable multispectral optoacoustic imaging of peripheral nerve vascularization and morphology  [ :arrow_down: ](https://arxiv.org/pdf/2207.13978.pdf)
>  Various morphological and functional parameters of peripheral nerves and their vascular supply are indicative of pathological changes due to injury or disease. Based on recent improvements in optoacoustic image quality, we explore the ability of multispectral optoacoustic tomography, in tandem with ultrasound imaging (OPUS), to investigate the vascular environment and morphology of peripheral nerves in vivo in a pilot study on healthy volunteers. We showcase the unique ability of optoacoustic imaging to visualize the vasa nervorum by observing intraneurial vessels in healthy nerves in vivo for the first time. In addition, we demonstrate that the label-free spectral optoacoustic contrast of the perfused connective tissue of peripheral nerves can be linked to the endogenous contrast of haemoglobin and collagen. We introduce metrics to analyze the composition of tissue based on its optoacoustic contrast and show that the high-resolution spectral contrast reveals specific differences between nervous tissue and reference tissue in the nerve's surrounding. We discuss how this showcased extraction of peripheral nerve characteristics using multispectral optoacoustic and ultrasound imaging can offer new insights into the pathophysiology of nerve damage and neuropathies, for example, in the context of diabetes.      
### 11.Extending RNN-T-based speech recognition systems with emotion and language classification  [ :arrow_down: ](https://arxiv.org/pdf/2207.13965.pdf)
>  Speech transcription, emotion recognition, and language identification are usually considered to be three different tasks. Each one requires a different model with a different architecture and training process. We propose using a recurrent neural network transducer (RNN-T)-based speech-to-text (STT) system as a common component that can be used for emotion recognition and language identification as well as for speech recognition. Our work extends the STT system for emotion classification through minimal changes, and shows successful results on the IEMOCAP and MELD datasets. In addition, we demonstrate that by adding a lightweight component to the RNN-T module, it can also be used for language identification. In our evaluations, this new classifier demonstrates state-of-the-art accuracy for the NIST-LRE-07 dataset.      
### 12.On a federated architecture for utilizing domain-specific descriptive models. (Poster)  [ :arrow_down: ](https://arxiv.org/pdf/2207.13952.pdf)
>  In a Systems Engineering setting, various models are produced using a variety of methods and tools. Focusing on a type of models -- called descriptive models -- which we shall describe, we argue that, while the clarity and precision of models are essential for their exchange and reuse, the way in which the data of these models are defined and the information conveyed is also essential for their (re) utilization -- e.g., for analysis or synthesis purposes. Category Theory has made it possible to link seemingly separate fields or domains, so that anything that can be rewritten in this framework benefits from a level of abstraction and a relational viewpoint -- essential to address complexity. We therefore take advantage of this framework to define a federated architecture for projecting and conveying these models without sacrificing clarity and precision. A federated architecture has two important advantages. On the one hand, it unifies these models from their structure; on the other hand, it allows a specific usage (instantiation or interpretation) of this structure within a business domain. We define the structure of these models as a symmetric multicategory. In particular, we rely on matrices over a semiring to define morphisms and their composition. The choice of matrices is intended to facilitate the application in practice.      
### 13.Accuracy of Real-Time Echo-Planar Imaging Phase Contrast MRI  [ :arrow_down: ](https://arxiv.org/pdf/2207.13950.pdf)
>  Compared with CINE phase contrast MRI (CINE-PC), echo-planar imaging phase contrast (EPI-PC) can achieve realtime quantification of blood flow, with lower SNR. In this study, the pulsating real model of the simulated cerebral vasculature was used to verify the accuracy of EPI-PC. The imaging time of EPI-PC was 62ms/image at 100*60 spatial resolution. The reconstructed EPI-PC flow curve was extracted by homemade post-processing software. After comparison with the CINE-PC flow curve, it was concluded that EPI-PC can provide an average flow with less than 3% error, and its flow curve will be similar to the CINE-PC flow curve in shape.      
### 14.Cerebro spinal fluid dynamic in front of cardiac and breathing influence  [ :arrow_down: ](https://arxiv.org/pdf/2207.13949.pdf)
>  It is still debated how breathing interacts with the CSF. New Phase contrast MRI sequence based on Echo Planar imaging (EPI-PC) can now produce continuously during minutes a velocity map, more or less every 100 ms. We did not found in the literature quantitative evaluation of the CSF stroke volume change during breathing. The aim of this work is to quantify CSF dynamics change in the aqueduct and in the spinal canal during the breathing and cardiac period using EPI-PC.      
### 15.A Unifying View on Blind Source Separation of Convolutive Mixtures based on Independent Component Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2207.13934.pdf)
>  In many daily-life scenarios, acoustic sources recorded in an enclosure can only be observed with other interfering sources. Hence, convolutive Blind Source Separation (BSS) is a central problem in audio signal processing. Methods based on Independent Component Analysis (ICA) are especially important in this field as they require only few and weak assumptions and allow for blindness regarding the original source signals and the acoustic propagation path. Most of the currently used algorithms belong to one of the following three families: Frequency Domain ICA (FD-ICA), Independent Vector Analysis (IVA), and TRIple-N Independent component analysis for CONvolutive mixtures (TRINICON). While the relation between ICA, FD-ICA and IVA becomes apparent due to their construction, the relation to TRINICON is not well established yet. This paper fills this gap by providing an in-depth treatment of the common building blocks of these algorithms and their differences, and thus provides a common framework for all considered algorithms.      
### 16.Morphological adjunctions represented by matrices in max-plus algebra for signal and image processing  [ :arrow_down: ](https://arxiv.org/pdf/2207.13926.pdf)
>  In discrete signal and image processing, many dilations and erosions can be written as the max-plus and min-plus product of a matrix on a vector. Previous studies considered operators on symmetrical, unbounded complete lattices, such as Cartesian powers of the completed real line. This paper focuses on adjunctions on closed hypercubes, which are the complete lattices used in practice to represent digital signals and images. We show that this constrains the representing matrices to be doubly-0-astic and we characterise the adjunctions that can be represented by them. A graph interpretation of the defined operators naturally arises from the adjacency relationship encoded by the matrices, as well as a max-plus spectral interpretation.      
### 17.Utterance-by-utterance overlap-aware neural diarization with Graph-PIT  [ :arrow_down: ](https://arxiv.org/pdf/2207.13888.pdf)
>  Recent speaker diarization studies showed that integration of end-to-end neural diarization (EEND) and clustering-based diarization is a promising approach for achieving state-of-the-art performance on various tasks. Such an approach first divides an observed signal into fixed-length segments, then performs {\it segment-level} local diarization based on an EEND module, and merges the segment-level results via clustering to form a final global diarization result. The segmentation is done to limit the number of speakers in each segment since the current EEND cannot handle a large number of speakers. In this paper, we argue that such an approach involving the segmentation has several issues; for example, it inevitably faces a dilemma that larger segment sizes increase both the context available for enhancing the performance and the number of speakers for the local EEND module to handle. To resolve such a problem, this paper proposes a novel framework that performs diarization without segmentation. However, it can still handle challenging data containing many speakers and a significant amount of overlapping speech. The proposed method can take an entire meeting for inference and perform {\it utterance-by-utterance} diarization that clusters utterance activities in terms of speakers. To this end, we leverage a neural network training scheme called Graph-PIT proposed recently for neural source separation. Experiments with simulated active-meeting-like data and CALLHOME data show the superiority of the proposed approach over the conventional methods.      
### 18.SuperVessel: Segmenting High-resolution Vessel from Low-resolution Retinal Image  [ :arrow_down: ](https://arxiv.org/pdf/2207.13882.pdf)
>  Vascular segmentation extracts blood vessels from images and serves as the basis for diagnosing various diseases, like ophthalmic diseases. Ophthalmologists often require high-resolution segmentation results for analysis, which leads to super-computational load by most existing methods. If based on low-resolution input, they easily ignore tiny vessels or cause discontinuity of segmented vessels. To solve these problems, the paper proposes an algorithm named SuperVessel, which gives out high-resolution and accurate vessel segmentation using low-resolution images as input. We first take super-resolution as our auxiliary branch to provide potential high-resolution detail features, which can be deleted in the test phase. Secondly, we propose two modules to enhance the features of the interested segmentation region, including an upsampling with feature decomposition (UFD) module and a feature interaction module (FIM) with a constraining loss to focus on the interested features. Extensive experiments on three publicly available datasets demonstrate that our proposed SuperVessel can segment more tiny vessels with higher segmentation accuracy IoU over 6%, compared with other state-of-the-art algorithms. Besides, the stability of SuperVessel is also stronger than other algorithms. We will release the code after the paper is published.      
### 19.Feature Extraction, Modulation and Recognition of Mixed Signal Based on SVM  [ :arrow_down: ](https://arxiv.org/pdf/2207.13881.pdf)
>  This paper introduces likelihood-based and feature-based modulation recognition methods. In the feature-based modulation simulation part, instantaneous feature, cyclic spectrum, high-order cumulants, and wavelet transform features are used as the entry point, and six digital signals including 2ASK, 4ASK, BPSK, QPSK, 2FSK and 4FSK are simulated, showing the difference of signals in multiple dimensions      
### 20.Real Image Restoration via Structure-preserving Complementarity Attention  [ :arrow_down: ](https://arxiv.org/pdf/2207.13879.pdf)
>  Since convolutional neural networks perform well in learning generalizable image priors from large-scale data, these models have been widely used in image denoising tasks. However, the computational complexity increases dramatically as well on complex model. In this paper, We propose a novel lightweight Complementary Attention Module, which includes a density module and a sparse module, which can cooperatively mine dense and sparse features for feature complementary learning to build an efficient lightweight architecture. Moreover, to reduce the loss of details caused by denoising, this paper constructs a gradient-based structure-preserving branch. We utilize gradient-based branches to obtain additional structural priors for denoising, and make the model pay more attention to image geometric details through gradient loss optimization.Based on the above, we propose an efficiently Unet structured network with dual branch, the visual results show that can effectively preserve the structural details of the original image, we evaluate benchmarks including SIDD and DND, where SCANet achieves state-of-the-art performance in PSNR and SSIM while significantly reducing computational cost.      
### 21.Unmatched Control Barrier Functions: Certainty Equivalence Adaptive Safety  [ :arrow_down: ](https://arxiv.org/pdf/2207.13873.pdf)
>  This work applies universal adaptive control to control barrier functions to achieve forward invariance of a safe set despite unmatched parametric uncertainties in a dynamical model. The approach combines two ideas. The first is to construct a family of control barrier functions that ensures the system is safe for all possible models. The second is to use online parameter adaption to methodically select a control barrier function and corresponding safety controller from the allowable set. While such a combination does not necessarily yield forward invariance without additional requirements on the barrier function, we show that such invariance can be established by simply adjusting the adaptation gain online. As a result, this work represents the first adaptive safety approach that successfully employs the certainty equivalence principle without sacrificing safety guarantees.      
### 22.Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network  [ :arrow_down: ](https://arxiv.org/pdf/2207.13868.pdf)
>  Ultrasound imaging plays an important role in the diagnosis of vascular lesions. Accurate segmentation of the vascular wall is important for the prevention, diagnosis and treatment of vascular diseases. However, existing methods have inaccurate localization of the vascular wall boundary. Segmentation errors occur in discontinuous vascular wall boundaries and dark boundaries. To overcome these problems, we propose a new boundary-delineation network (BDNet). We use the boundary refinement module to re-delineate the boundary of the vascular wall to obtain the correct boundary location. We designed the feature extraction module to extract and fuse multi-scale features and different receptive field features to solve the problem of dark boundaries and discontinuous boundaries. We use a new loss function to optimize the model. The interference of class imbalance on model optimization is prevented to obtain finer and smoother boundaries. Finally, to facilitate clinical applications, we design the model to be lightweight. Experimental results show that our model achieves the best segmentation results and significantly reduces memory consumption compared to existing models for the dataset.      
### 23.System Identification and Two-Degree-of-Freedom Control of Nonlinear, Viscoelastic Tissues  [ :arrow_down: ](https://arxiv.org/pdf/2207.13841.pdf)
>  Objective: This paper presents a force control scheme for brief isotonic holds in an isometrically contracted muscle tissue, with minimal overshoot and settling time to measure its shortening velocity, a key parameter of muscle function. Methods: A two-degree-of-freedom control configuration, formed by a feedback controller and a feedforward controller, is explored. The feedback controller is a proportional-integral controller and the feedforward controller is designed using the inverse of a control-oriented model of muscle tissue. A generalized linear model and a nonlinear model of muscle tissue are explored using input-output data and system identification techniques. The force control scheme is tested on equine airway smooth muscle and its robustness confirmed with murine flexor digitorum brevis muscle. Results: Performance and repeatability of the force control scheme as well as the number of inputs and level of supervision required from the user were assessed with a series of experiments. The force control scheme was able to fulfill the stated control objectives in most cases, including the requirements for settling time and overshoot. Conclusion: The proposed control scheme is shown to enable automation of force control for characterizing muscle mechanics with minimal user input required. Significance: This paper leverages an inversion-based feedforward controller based on a nonlinear physiological model in a system identification context that is superior to classic linear system identification. The control scheme can be used as a steppingstone for generalized control of nonlinear, viscoelastic materials.      
### 24.Extraction of Coronary Vessels in Fluoroscopic X-Ray Sequences Using Vessel Correspondence Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2207.13837.pdf)
>  We present a method to extract coronary vessels from fluoroscopic x-ray sequences. Given the vessel structure for the source frame, vessel correspondence candidates in the subsequent frame are generated by a novel hierarchical search scheme to overcome the aperture problem. Optimal correspondences are determined within a Markov random field optimization framework. Post-processing is performed to extract vessel branches newly visible due to the inflow of contrast agent. Quantitative and qualitative evaluation conducted on a dataset of 18 sequences demonstrates the effectiveness of the proposed method.      
### 25.3D-Morphomics, Morphological Features on CT scans for lung nodule malignancy diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2207.13830.pdf)
>  Pathologies systematically induce morphological changes, thus providing a major but yet insufficiently quantified source of observables for diagnosis. The study develops a predictive model of the pathological states based on morphological features (3D-morphomics) on Computed Tomography (CT) volumes. A complete workflow for mesh extraction and simplification of an organ's surface is developed, and coupled with an automatic extraction of morphological features given by the distribution of mean curvature and mesh energy. An XGBoost supervised classifier is then trained and tested on the 3D-morphomics to predict the pathological states. This framework is applied to the prediction of the malignancy of lung's nodules. On a subset of NLST database with malignancy confirmed biopsy, using 3D-morphomics only, the classification model of lung nodules into malignant vs. benign achieves 0.964 of AUC. Three other sets of classical features are trained and tested, (1) clinical relevant features gives an AUC of 0.58, (2) 111 radiomics gives an AUC of 0.976, (3) radiologist ground truth (GT) containing the nodule size, attenuation and spiculation qualitative annotations gives an AUC of 0.979. We also test the Brock model and obtain an AUC of 0.826. Combining 3D-morphomics and radiomics features achieves state-of-the-art results with an AUC of 0.978 where the 3D-morphomics have some of the highest predictive powers. As a validation on a public independent cohort, models are applied to the LIDC dataset, the 3D-morphomics achieves an AUC of 0.906 and the 3D-morphomics+radiomics achieves an AUC of 0.958, which ranks second in the challenge among deep models. It establishes the curvature distributions as efficient features for predicting lung nodule malignancy and a new method that can be applied directly to arbitrary computer aided diagnosis task.      
### 26.Nonlinear Three-Tank System Fault Detection and Isolation Using Differential Flatness  [ :arrow_down: ](https://arxiv.org/pdf/2207.13803.pdf)
>  Fault detection and isolation on hydraulic systems are very important to ensure safety and avoid disasters. In this paper, a fault detection and isolation method, based on the flatness property of nonlinear systems, is experimentally applied on the three-tank system, which is considered as a popular prototype of hydraulic systems. Specifically, fault indicators, called residues, are generated using flat output measurements, and for the purpose of fault isolation, a definition of the isolability is introduced. This definition allows the characterization of flat outputs that are useful for fault isolation. A sensitivity analysis is proposed in order to improve the robustness of the method. Multiplicative faults are considered on sensors and actuators.      
### 27.Deep Learning for Classification of Thyroid Nodules on Ultrasound: Validation on an Independent Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2207.13765.pdf)
>  Objectives: The purpose is to apply a previously validated deep learning algorithm to a new thyroid nodule ultrasound image dataset and compare its performances with radiologists. Methods: Prior study presented an algorithm which is able to detect thyroid nodules and then make malignancy classifications with two ultrasound images. A multi-task deep convolutional neural network was trained from 1278 nodules and originally tested with 99 separate nodules. The results were comparable with that of radiologists. The algorithm was further tested with 378 nodules imaged with ultrasound machines from different manufacturers and product types than the training cases. Four experienced radiologists were requested to evaluate the nodules for comparison with deep learning. Results: The Area Under Curve (AUC) of the deep learning algorithm and four radiologists were calculated with parametric, binormal estimation. For the deep learning algorithm, the AUC was 0.70 (95% CI: 0.64 - 0.75). The AUC of radiologists were 0.66 (95% CI: 0.61 - 0.71), 0.67 (95% CI:0.62 - 0.73), 0.68 (95% CI: 0.63 - 0.73), and 0.66 (95%CI: 0.61 - 0.71). Conclusion: In the new testing dataset, the deep learning algorithm achieved similar performances with all four radiologists.      
### 28.FleetPy: A Modular Open-Source Simulation Tool for Mobility On-Demand Services  [ :arrow_down: ](https://arxiv.org/pdf/2207.14246.pdf)
>  The market share of mobility on-demand (MoD) services strongly increased in recent years and is expected to rise even higher once vehicle automation is fully available. These services might reduce space consumption in cities as fewer parking spaces are required if private vehicle trips are replaced. If rides are shared additionally, occupancy related traffic efficiency is increased. Simulations help to identify the actual impact of MoD on a traffic system, evaluate new control algorithms for improved service efficiency and develop guidelines for regulatory measures. This paper presents the open-source agent-based simulation framework FleetPy. FleetPy (written in the programming language "Python") is explicitly developed to model MoD services in a high level of detail. It specially focuses on the modeling of interactions of users with operators while its flexibility allows the integration and embedding of multiple operators in the overall transportation system. Its modular structure ensures the transferabillity of previously developed elements and the selection of an appropriate level of modeling detail. This paper compares existing simulation frameworks for MoD services and highlights exclusive features of FleetPy. The upper level simulation flows are presented, followed by required input data for the simulation and the output data FleetPy produces. Additionally, the modules within FleetPy and high-level descriptions of current implementations are provided. Finally, an example showcase for Manhattan, NYC provides insights into the impacts of different modules for simulation flow, fleet optimization, traveler behavior and network representation.      
### 29.Optimization of Artificial Neural Networks models applied to the identification of images of asteroids' resonant arguments  [ :arrow_down: ](https://arxiv.org/pdf/2207.14181.pdf)
>  The asteroidal main belt is crossed by a web of mean-motion and secular resonances, that occur when there is a commensurability between fundamental frequencies of the asteroids and planets. Traditionally, these objects were identified by visual inspection of the time evolution of their resonant argument, which is a combination of orbital elements of the asteroid and the perturbing planet(s). Since the population of asteroids affected by these resonances is, in some cases, of the order of several thousand, this has become a taxing task for a human observer. Recent works used Convolutional Neural Networks (CNN) models to perform such task automatically. In this work, we compare the outcome of such models with those of some of the most advanced and publicly available CNN architectures, like the VGG, Inception and ResNet. The performance of such models is first tested and optimized for overfitting issues, using validation sets and a series of regularization techniques like data augmentation, dropout, and batch normalization. The three best-performing models were then used to predict the labels of larger testing databases containing thousands of images. The VGG model, with and without regularizations, proved to be the most efficient method to predict labels of large datasets. Since the Vera C. Rubin observatory is likely to discover up to four million new asteroids in the next few years, the use of these models might become quite valuable to identify populations of resonant minor bodies.      
### 30.Content-oriented learned image compression  [ :arrow_down: ](https://arxiv.org/pdf/2207.14168.pdf)
>  In recent years, with the development of deep neural networks, end-to-end optimized image compression has made significant progress and exceeded the classic methods in terms of rate-distortion performance. However, most learning-based image compression methods are unlabeled and do not consider image semantics or content when optimizing the model. In fact, human eyes have different sensitivities to different content, so the image content also needs to be considered. In this paper, we propose a content-oriented image compression method, which handles different kinds of image contents with different strategies. Extensive experiments show that the proposed method achieves competitive subjective results compared with state-of-the-art end-to-end learned image compression methods or classic methods.      
### 31.RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2207.14166.pdf)
>  The acquisition and evaluation of pavement surface data play an essential role in pavement condition evaluation. In this paper, an efficient and effective end-to-end network for automatic pavement crack segmentation, called RHA-Net, is proposed to improve the pavement crack segmentation accuracy. The RHA-Net is built by integrating residual blocks (ResBlocks) and hybrid attention blocks into the encoder-decoder architecture. The ResBlocks are used to improve the ability of RHA-Net to extract high-level abstract features. The hybrid attention blocks are designed to fuse both low-level features and high-level features to help the model focus on correct channels and areas of cracks, thereby improving the feature presentation ability of RHA-Net. An image data set containing 789 pavement crack images collected by a self-designed mobile robot is constructed and used for training and evaluating the proposed model. Compared with other state-of-the-art networks, the proposed model achieves better performance and the functionalities of adding residual blocks and hybrid attention mechanisms are validated in a comprehensive ablation study. Additionally, a light-weighted version of the model generated by introducing depthwise separable convolution achieves better a performance and a much faster processing speed with 1/30 of the number of U-Net parameters. The developed system can segment pavement crack in real-time on an embedded device Jetson TX2 (25 FPS). The video taken in real-time experiments is released at <a class="link-external link-https" href="https://youtu.be/3XIogk0fiG4" rel="external noopener nofollow">this https URL</a>.      
### 32.Evaluation of a Gaussian Mixture Model-based Channel Estimator using Measurement Data  [ :arrow_down: ](https://arxiv.org/pdf/2207.14150.pdf)
>  In this work, we use real-world data in order to evaluate and validate a machine learning (ML)-based algorithm for physical layer functionalities. Specifically, we apply a recently introduced Gaussian mixture model (GMM)-based algorithm in order to estimate uplink channels stemming from a measurement campaign. For this estimator, there is an initial (offline) training phase, where a GMM is fitted onto given channel (training) data. Thereafter, the fitted GMM is used for (online) channel estimation. Our experiments suggest that the GMM estimator learns the intrinsic characteristics of a given base station's whole radio propagation environment. Essentially, this ambient information is captured due to universal approximation properties of the initially fitted GMM. For a large enough number of GMM components, the GMM estimator was shown to approximate the (unknown) mean squared error (MSE)-optimal channel estimator arbitrarily well. In our experiments, the GMM estimator shows significant performance gains compared to approaches that are not able to capture the ambient information. To validate the claim that ambient information is learnt, we generate synthetic channel data using a state-of-the-art channel simulator and train the GMM estimator once on these and once on the real data, and we apply the estimator once to the synthetic and once to the real data. We then observe how providing suitable ambient information in the training phase beneficially impacts the later channel estimation performance.      
### 33.WiVelo: Fine-grained Walking Velocity Estimation for Wi-Fi Passive Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2207.14072.pdf)
>  Passive human tracking via Wi-Fi has been researched broadly in the past decade. Besides straight-forward anchor point localization, velocity is another vital sign adopted by the existing approaches to infer user trajectory. However, state-of-the-art Wi-Fi velocity estimation relies on Doppler-Frequency-Shift (DFS) which suffers from the inevitable signal noise incurring unbounded velocity errors, further degrading the tracking accuracy. In this paper, we present WiVelo\footnote{Code\&amp;datasets are available at \textit{<a class="link-external link-https" href="https://github.com/liecn/WiVelo" rel="external noopener nofollow">this https URL</a>\_SECON22}} that explores new spatial-temporal signal correlation features observed from different antennas to achieve accurate velocity estimation. First, we use subcarrier shift distribution (SSD) extracted from channel state information (CSI) to define two correlation features for direction and speed estimation, separately. Then, we design a mesh model calculated by the antennas' locations to enable a fine-grained velocity estimation with bounded direction error. Finally, with the continuously estimated velocity, we develop an end-to-end trajectory recovery algorithm to mitigate velocity outliers with the property of walking velocity continuity. We implement WiVelo on commodity Wi-Fi hardware and extensively evaluate its tracking accuracy in various environments. The experimental results show our median and 90\% tracking errors are 0.47~m and 1.06~m, which are half and a quarter of state-of-the-arts.      
### 34.Adaptive optimal $\ell_\infty$-induced robust stabilization of minimum phase SISO plant under bounded disturbance and coprime factor perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2207.14028.pdf)
>  This paper addresses the problem of optimal robust stabilization of a discrete-time minimum-phase plant in the framework of robust control theory in the $\ell_1$ setup and under poor a priori information. Coefficients of the transfer function of the plant nominal model with stable zeros are unknown and belong to a known bounded polyhedron in the space of coefficients. The gains of coprime factor perturbations of the plant and the upper bound of external disturbance are also unknown. The problem under consideration is to design adaptive controller that minimizes, with the prescribed accuracy, the worst-case asymptotic upper bound of the output. Solution of the problem is based on set-membership estimation of unknown parameters and treating the control criterion as the identification criterion. A hard nonconvex problem of on-line computation of optimal estimates is reduced, under additional nonrestrictive assumption, to a linear-fractional programming via a nonlinear transformation of estimated parameters. Despite the non-identifiability of the unknown parameters, the proposed adaptive controller guarantees, with the prescribed accuracy, the same optimal asymptotic upper bound of the output of adaptive system as the optimal controller for the plant with known parameters. In addition to the optimality of adaptive control, the proposed solution provides on-line verification/validation of current estimates and a priori assumptions.      
### 35.Online Inference for Mixture Model of Streaming Graph Signals with Non-White Excitation  [ :arrow_down: ](https://arxiv.org/pdf/2207.14019.pdf)
>  This paper considers a joint multi-graph inference and clustering problem for simultaneous inference of node centrality and association of graph signals with their graphs. We study a mixture model of filtered low pass graph signals with possibly non-white and low-rank excitation. While the mixture model is motivated from practical scenarios, it presents significant challenges to prior graph learning methods. As a remedy, we consider an inference problem focusing on the node centrality of graphs. We design an expectation-maximization (EM) algorithm with a unique low-rank plus sparse prior derived from low pass signal property. We propose a novel online EM algorithm for inference from streaming data. As an example, we extend the online algorithm to detect if the signals are generated from an abnormal graph. We show that the proposed algorithms converge to a stationary point of the maximum-a-posterior (MAP) problem. Numerical experiments support our analysis.      
### 36.Robot-Assisted Drilling on Curved Surfaces with Haptic Guidance under Adaptive Admittance Control  [ :arrow_down: ](https://arxiv.org/pdf/2207.13999.pdf)
>  Drilling a hole on a curved surface with a desired angle is prone to failure when done manually, due to the difficulties in drill alignment and also inherent instabilities of the task, potentially causing injury and fatigue to the workers. On the other hand, it can be impractical to fully automate such a task in real manufacturing environments because the parts arriving at an assembly line can have various complex shapes where drill point locations are not easily accessible, making automated path planning difficult. In this work, an adaptive admittance controller with 6 degrees of freedom is developed and deployed on a KUKA LBR iiwa 7 cobot such that the operator is able to manipulate a drill mounted on the robot with one hand comfortably and open holes on a curved surface with haptic guidance of the cobot and visual guidance provided through an AR interface. Real-time adaptation of the admittance damping provides more transparency when driving the robot in free space while ensuring stability during drilling. After the user brings the drill sufficiently close to the drill target and roughly aligns to the desired drilling angle, the haptic guidance module fine tunes the alignment first and then constrains the user movement to the drilling axis only, after which the operator simply pushes the drill into the workpiece with minimal effort. Two sets of experiments were conducted to investigate the potential benefits of the haptic guidance module quantitatively (Experiment I) and also the practical value of the proposed pHRI system for real manufacturing settings based on the subjective opinion of the participants (Experiment II).      
### 37.Photonic sampled and quantized analog-to-digital converters on thin-film lithium niobate platform  [ :arrow_down: ](https://arxiv.org/pdf/2207.13972.pdf)
>  In this paper, an on-chip photonic sampled and quantized analog-to-digital converter (ADC) on thin-film lithium niobate platform is experimentally demonstrated. Using two phase modulators as a sampler and a 5$\times$5 multimode interference (MMI) coupler as a quantizer, an 1 GHz sinusoidal analog input signal was successfully converted to a digitized output with a 20 GSample/s sampling rate. To evaluate the system performance, the quantization curves together with the transfer function of the ADC were measured. The experimental effective number of bits (ENOB) was 3.17 bit. The demonstrated device is capable of operating at a high frequency up to 70 GHz, making it a promising solution for on-chip ultra-high speed analog-to-digital conversion.      
### 38.Breast shape estimation and correction in CESM biopsy  [ :arrow_down: ](https://arxiv.org/pdf/2207.13917.pdf)
>  Description of purpose: Contrast-enhanced spectral mammography can be used to guide needle biopsies. However, in vertical approach the compressed breast is deformed generating a so-called bump in the paddle aperture, which may interfere with the visibility of contrast-uptakes. Local thickness estimation would provide an enhanced image quality of the recombined image, increasing the visibility of the contrast-uptakes to be targeted during the biopsy procedure. In this work we propose a method to estimate the shape of the breast bump in biopsy vertical approach. Materials and Methods: Our method consists on two steps: first, we compute a raw thickness which does not take into account the presence of contrast-uptakes; second, we use a physical model to separate the sparse iodine texture from the breast shape. This physical model is composed by a sum of Fourier components, describing the main shape of the bump, a series of low-order polynomials, describing the main compressed thickness, paddle tilt and deflection, and non-linear components describing the translation and rotation of the paddle aperture. A 3D object mimicking a bump was fabricated to test the pertinence of our shape model. Also, clinical images of 21 patients which followed CESM-guided biopsy were visually assessed. Results: Comparison between raw and final estimated thickness of our 3D test object shows an error standard deviation of 0.37 mm similar to the noise standard deviation equals to 0.32 mm. The visual assessment of clinical cases showed that the thickness correction removes the superimposed low-frequency pattern due to non-uniform thickness of the bump, improving the identification of the lesion to be targeted. Conclusion: The proposed method for thickness estimation is adapted to CESM-guided biopsies in vertical approach and it improves the identification of the contrast-uptakes that need to be targeted during the procedure.      
### 39.An Optimal Multi-UAV Deployment Model for UAV-assisted Smart Farming  [ :arrow_down: ](https://arxiv.org/pdf/2207.13884.pdf)
>  Next-generation wireless networks will deploy UAVs dynamically as aerial base stations (UAV-BSs) to boost the wireless network coverage in the out of reach areas. To provide an efficient service in stochastic environments, the optimal number of UAV-BSs, their locations, and trajectories must be specified appropriately for different scenarios. Such deployment requires an intelligent decision-making mechanism that can deal with various variables at different times. This paper proposes a multi UAV-BS deployment model for smart farming, formulated as a Multi-Criteria Decision Making (MCDM) method to find the optimal number of UAV-BSs to monitor animals' behavior. This model considers the effect of UAV-BSs' signal interference and path loss changes caused by users' mobility to maximize the system's efficiency. To avoid collision among UAV-BSs, we split the considered area into several clusters, each covered by a UAV-BS. Our simulation results suggest up to 11x higher deployment efficiency than the benchmark clustering algorithm.      
### 40.Model Predictive Control of Nonlinear Latent Force Models: A Scenario-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2207.13872.pdf)
>  Control of nonlinear uncertain systems is a common challenge in the robotics field. Nonlinear latent force models, which incorporate latent uncertainty characterized as Gaussian processes, carry the promise of representing such systems effectively, and we focus on the control design for them in this work. To enable the design, we adopt the state-space representation of a Gaussian process to recast the nonlinear latent force model and thus build the ability to predict the future state and uncertainty concurrently. Using this feature, a stochastic model predictive control problem is formulated. To derive a computational algorithm for the problem, we use the scenario-based approach to formulate a deterministic approximation of the stochastic optimization. We evaluate the resultant scenario-based model predictive control approach through a simulation study based on motion planning of an autonomous vehicle, which shows much effectiveness. The proposed approach can find prospective use in various other robotics applications.      
### 41.Robust Transmit Beamforming for Secure Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2207.13863.pdf)
>  This paper studies a downlink secure integrated sensing and communication (ISAC) system, in which a multi-antenna base station (BS) transmits confidential messages to a single-antenna communication user (CU) while performing sensing on targets that may act as suspicious eavesdroppers. To ensure the quality of target sensing while preventing their potential eavesdropping, the BS combines the transmit confidential information signals with additional dedicated sensing signals, which play a dual role of artificial noise (AN) for degrading the qualities of eavesdropping channels. Under this setup, we jointly design the transmit information and sensing beamforming, with the objective of minimizing the weighted sum of beampattern matching errors and cross-correlation patterns for sensing subject to secure communication constraints. The robust design takes into account the channel state information (CSI) imperfectness of the eavesdroppers in two practical CSI error scenarios. First, we consider the scenario with bounded CSI errors of eavesdroppers, in which the worst-case secrecy rate constraint is adopted to ensure secure communication performance. In this scenario, we present the optimal solution to the worst-case secrecy rate constrained sensing beampattern optimization problem, by adopting the techniques of S-procedure, semi-definite relaxation (SDR), and a one-dimensional (1D) search, for which the tightness of the SDR is rigorously proved. Next, we consider the scenario with Gaussian CSI errors of eavesdroppers, in which the secrecy outage probability constraint is adopted. In this scenario, we present an efficient algorithm to solve the more challenging secrecy outage-constrained sensing beampattern optimization problem, by exploiting the convex restriction technique based on the Bernstein-type inequality, together with the SDR and 1D search.      
### 42.One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares  [ :arrow_down: ](https://arxiv.org/pdf/2207.13853.pdf)
>  While deep neural networks are capable of achieving state-of-the-art performance in various domains, their training typically requires iterating for many passes over the dataset. However, due to computational and memory constraints and potential privacy concerns, storing and accessing all the data is impractical in many real-world scenarios where the data arrives in a stream. In this paper, we investigate the problem of one-pass learning, in which a model is trained on sequentially arriving data without retraining on previous datapoints. Motivated by the increasing use of overparameterized models, we develop Orthogonal Recursive Fitting (ORFit), an algorithm for one-pass learning which seeks to perfectly fit every new datapoint while changing the parameters in a direction that causes the least change to the predictions on previous datapoints. By doing so, we bridge two seemingly distinct algorithms in adaptive filtering and machine learning, namely the recursive least-squares (RLS) algorithm and orthogonal gradient descent (OGD). Our algorithm uses the memory efficiently by exploiting the structure of the streaming data via an incremental principal component analysis (IPCA). Further, we show that, for overparameterized linear models, the parameter vector obtained by our algorithm is what stochastic gradient descent (SGD) would converge to in the standard multi-pass setting. Finally, we generalize the results to the nonlinear setting for highly overparameterized models, relevant for deep learning. Our experiments show the effectiveness of the proposed method compared to the baselines.      
### 43.EEG2Mel: Reconstructing Sound from Brain Responses to Music  [ :arrow_down: ](https://arxiv.org/pdf/2207.13845.pdf)
>  Information retrieval from brain responses to auditory and visual stimuli has shown success through classification of song names and image classes presented to participants while recording EEG signals. Information retrieval in the form of reconstructing auditory stimuli has also shown some success, but here we improve on previous methods by reconstructing music stimuli well enough to be perceived and identified independently. Furthermore, deep learning models were trained on time-aligned music stimuli spectrum for each corresponding one-second window of EEG recording, which greatly reduces feature extraction steps needed when compared to prior studies. The NMED-Tempo and NMED-Hindi datasets of participants passively listening to full length songs were used to train and validate Convolutional Neural Network (CNN) regressors. The efficacy of raw voltage versus power spectrum inputs and linear versus mel spectrogram outputs were tested, and all inputs and outputs were converted into 2D images. The quality of reconstructed spectrograms was assessed by training classifiers which showed 81% accuracy for mel-spectrograms and 72% for linear spectrograms (10% chance accuracy). Lastly, reconstructions of auditory music stimuli were discriminated by listeners at an 85% success rate (50% chance) in a two-alternative match-to-sample task.      
### 44.Deep Learning-Based Acoustic Mosquito Detection in Noisy Conditions Using Trainable Kernels and Augmentations  [ :arrow_down: ](https://arxiv.org/pdf/2207.13843.pdf)
>  In this paper, we demonstrate a unique recipe to enhance the effectiveness of audio machine learning approaches by fusing pre-processing techniques into a deep learning model. Our solution accelerates training and inference performance by optimizing hyper-parameters through training instead of costly random searches to build a reliable mosquito detector from audio signals. The experiments and the results presented here are part of the MOS C submission of the ACM 2022 challenge. Our results outperform the published baseline by 212% on the unpublished test set. We believe that this is one of the best real-world examples of building a robust bio-acoustic system that provides reliable mosquito detection in noisy conditions.      
### 45.Distributional Actor-Critic Ensemble for Uncertainty-Aware Continuous Control  [ :arrow_down: ](https://arxiv.org/pdf/2207.13730.pdf)
>  Uncertainty quantification is one of the central challenges for machine learning in real-world applications. In reinforcement learning, an agent confronts two kinds of uncertainty, called epistemic uncertainty and aleatoric uncertainty. Disentangling and evaluating these uncertainties simultaneously stands a chance of improving the agent's final performance, accelerating training, and facilitating quality assurance after deployment. In this work, we propose an uncertainty-aware reinforcement learning algorithm for continuous control tasks that extends the Deep Deterministic Policy Gradient algorithm (DDPG). It exploits epistemic uncertainty to accelerate exploration and aleatoric uncertainty to learn a risk-sensitive policy. We conduct numerical experiments showing that our variant of DDPG outperforms vanilla DDPG without uncertainty estimation in benchmark tasks on robotic control and power-grid optimization.      
### 46.SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation  [ :arrow_down: ](https://arxiv.org/pdf/2207.13703.pdf)
>  End-to-end speech synthesis models directly convert the input characters into an audio representation (e.g., spectrograms). Despite their impressive performance, such models have difficulty disambiguating the pronunciations of identically spelled words. To mitigate this issue, a separate Grapheme-to-Phoneme (G2P) model can be employed to convert the characters into phonemes before synthesizing the audio. This paper proposes SoundChoice, a novel G2P architecture that processes entire sentences rather than operating at the word level. The proposed architecture takes advantage of a weighted homograph loss (that improves disambiguation), exploits curriculum learning (that gradually switches from word-level to sentence-level G2P), and integrates word embeddings from BERT (for further performance improvement). Moreover, the model inherits the best practices in speech recognition, including multi-task learning with Connectionist Temporal Classification (CTC) and beam search with an embedded language model. As a result, SoundChoice achieves a Phoneme Error Rate (PER) of 2.65% on whole-sentence transcription using data from LibriSpeech and Wikipedia. Index Terms grapheme-to-phoneme, speech synthesis, text-tospeech, phonetics, pronunciation, disambiguation.      
