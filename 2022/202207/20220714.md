# ArXiv eess --Thu, 14 Jul 2022
### 1.ProDiff: Progressive Fast Diffusion Model For High-Quality Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2207.06389.pdf)
>  Denoising diffusion probabilistic models (DDPMs) have recently achieved leading performances in many generative tasks. However, the inherited iterative sampling process costs hinder their applications to text-to-speech deployment. Through the preliminary study on diffusion model parameterization, we find that previous gradient-based TTS models require hundreds or thousands of iterations to guarantee high sample quality, which poses a challenge for accelerating sampling. In this work, we propose ProDiff, on progressive fast diffusion model for high-quality text-to-speech. Unlike previous work estimating the gradient for data density, ProDiff parameterizes the denoising model by directly predicting clean data to avoid distinct quality degradation in accelerating sampling. To tackle the model convergence challenge with decreased diffusion iterations, ProDiff reduces the data variance in the target site via knowledge distillation. Specifically, the denoising model uses the generated mel-spectrogram from an N-step DDIM teacher as the training target and distills the behavior into a new model with N/2 steps. As such, it allows the TTS model to make sharp predictions and further reduces the sampling time by orders of magnitude. Our evaluation demonstrates that ProDiff needs only 2 iterations to synthesize high-fidelity mel-spectrograms, while it maintains sample quality and diversity competitive with state-of-the-art models using hundreds of steps. ProDiff enables a sampling speed of 24x faster than real-time on a single NVIDIA 2080Ti GPU, making diffusion models practically applicable to text-to-speech synthesis deployment for the first time. Our extensive ablation studies demonstrate that each design in ProDiff is effective, and we further show that ProDiff can be easily extended to the multi-speaker setting. Audio samples are available at \url{<a class="link-external link-https" href="https://ProDiff.github.io/" rel="external noopener nofollow">this https URL</a>.}      
### 2.Tilt-then-Blur or Blur-then-Tilt? Clarifying the Atmospheric Turbulence Model  [ :arrow_down: ](https://arxiv.org/pdf/2207.06377.pdf)
>  Imaging at a long distance often requires advanced image restoration algorithms to compensate for the distortions caused by atmospheric turbulence. However, unlike many standard restoration problems such as deconvolution, the forward image formation model of the atmospheric turbulence does not have a simple expression. Thanks to the Zernike representation of the phase, one can show that the forward model is a combination of tilt (pixel shifting due to the linear phase terms) and blur (image smoothing due to the high order aberrations). <br>Confusions then arise between the ordering of the two operators. Should the model be tilt-then-blur, or blur-then-tilt? Some papers in the literature say that the model is tilt-then-blur, whereas more papers say that it is blur-then-tilt. This paper clarifies the differences between the two and discusses why the tilt-then-blur is the correct model. Recommendations are given to the research community.      
### 3.Left Ventricle Contouring of Apical Three-Chamber Views on 2D Echocardiography  [ :arrow_down: ](https://arxiv.org/pdf/2207.06330.pdf)
>  We propose a new method to automatically contour the left ventricle on 2D echocardiographic images. Unlike most existing segmentation methods, which are based on predicting segmentation masks, we focus at predicting the endocardial contour and the key landmark points within this contour (basal points and apex). This provides a representation that is closer to how experts perform manual annotations and hence produce results that are physiologically more plausible. <br>Our proposed method uses a two-headed network based on the U-Net architecture. One head predicts the 7 contour points, and the other head predicts a distance map to the contour. This approach was compared to the U-Net and to a point based approach, achieving performance gains of up to 30\% in terms of landmark localisation (&lt;4.5mm) and distance to the ground truth contour (&lt;3.5mm).      
### 4.Event-triggered Control of Port-Hamiltonian Systems under Time-delay Communication  [ :arrow_down: ](https://arxiv.org/pdf/2207.06327.pdf)
>  We study the problem of periodic event-triggered control of interconnected port-Hamiltonian systems subject to time-varying delays in their communication. In particular, we design a threshold parameter for the event-triggering condition, a sampling period, and a maximum allowable delay such that interconnected port-Hamiltonian control systems with periodic event-triggering mechanism under a time-delayed communication are able to achieve asymptotically stable behaviour. Simulation results are presented to validate the theory.      
### 5.SnapperGPS: Open Hardware for Energy-Efficient, Low-Cost Wildlife Location Tracking with Snapshot GNSS  [ :arrow_down: ](https://arxiv.org/pdf/2207.06310.pdf)
>  Location tracking with Global Navigation Satellite Systems (GNSS) such as the GPS is used in many applications, including the tracking of wild animals for research. Snapshot GNSS is a technique that only requires milliseconds of satellite signals to infer the position of a receiver. This is ideal for low-power applications such as animal tracking. However, there are few existing snapshot systems, none of which is open source. To address this, we developed SnapperGPS, a fully open-source, low-cost and low-power location tracking system designed for wildlife tracking. SnapperGPS comprises three parts, all of which are open-source: (i) a small, low-cost and low-power receiver; (ii) a web application to configure the receiver via USB; and (iii) a cloud-based platform for processing recorded data. This paper presents the hardware side of this project. The total component cost of the receiver is under $30, making it feasible for field work with restricted budgets and low recovery rates. The receiver records very short and low-resolution samples resulting in particularly low power consumption, outperforming existing systems. It can run for more than a year on a 40 mAh battery. We evaluated SnapperGPS in controlled static and dynamic tests in a semi-urban environment where it achieved median errors of 12 m. Additionally, SnapperGPS has already been deployed for two wildlife tracking studies on sea turtles and sea birds.      
### 6.Hitless memory-reconfigurable photonic reservoir computing architecture  [ :arrow_down: ](https://arxiv.org/pdf/2207.06245.pdf)
>  Reservoir computing is an analog bio-inspired computation model for efficiently processing time-dependent signals, the photonic implementations of which promise a combination of massive parallel information processing, low power consumption, and high speed operation. However, most implementations, especially for the case of time-delay reservoir computing (TDRC), require signal attenuation in the reservoir to achieve the desired system dynamics for a specific task, often resulting in large amounts of power being coupled outside of the system. We propose a novel TDRC architecture based on an asymmetric Mach-Zehnder interferometer (MZI) integrated in a resonant cavity which allows the memory capacity of the system to be tuned without the need for an optical attenuator block. Furthermore, this can be leveraged to find the optimal value for the specific components of the total memory capacity metric. We demonstrate this approach on the temporal bitwise XOR task and conclude that this way of memory capacity reconfiguration allows optimal performance to be achieved for memory-specific tasks.      
### 7.YOLO2U-Net: Detection-Guided 3D Instance Segmentation for Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2207.06215.pdf)
>  Microscopy imaging techniques are instrumental for characterization and analysis of biological structures. As these techniques typically render 3D visualization of cells by stacking 2D projections, issues such as out-of-plane excitation and low resolution in the $z$-axis may pose challenges (even for human experts) to detect individual cells in 3D volumes as these non-overlapping cells may appear as overlapping. In this work, we introduce a comprehensive method for accurate 3D instance segmentation of cells in the brain tissue. The proposed method combines the 2D YOLO detection method with a multi-view fusion algorithm to construct a 3D localization of the cells. Next, the 3D bounding boxes along with the data volume are input to a 3D U-Net network that is designed to segment the primary cell in each 3D bounding box, and in turn, to carry out instance segmentation of cells in the entire volume. The promising performance of the proposed method is shown in comparison with some current deep learning-based 3D instance segmentation methods.      
### 8.Domain adaptation strategies for cancer-independent detection of lymph node metastases  [ :arrow_down: ](https://arxiv.org/pdf/2207.06193.pdf)
>  Recently, large, high-quality public datasets have led to the development of convolutional neural networks that can detect lymph node metastases of breast cancer at the level of expert pathologists. Many cancers, regardless of the site of origin, can metastasize to lymph nodes. However, collecting and annotating high-volume, high-quality datasets for every cancer type is challenging. In this paper we investigate how to leverage existing high-quality datasets most efficiently in multi-task settings for closely related tasks. Specifically, we will explore different training and domain adaptation strategies, including prevention of catastrophic forgetting, for colon and head-and-neck cancer metastasis detection in lymph nodes. <br>Our results show state-of-the-art performance on both cancer metastasis detection tasks. Furthermore, we show the effectiveness of repeated adaptation of networks from one cancer type to another to obtain multi-task metastasis detection networks. Last, we show that leveraging existing high-quality datasets can significantly boost performance on new target tasks and that catastrophic forgetting can be effectively mitigated using regularization.      
### 9.Collaborative Quantization Embeddings for Intra-Subject Prostate MR Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2207.06189.pdf)
>  Image registration is useful for quantifying morphological changes in longitudinal MR images from prostate cancer patients. This paper describes a development in improving the learning-based registration algorithms, for this challenging clinical application often with highly variable yet limited training data. First, we report that the latent space can be clustered into a much lower dimensional space than that commonly found as bottleneck features at the deep layer of a trained registration network. Based on this observation, we propose a hierarchical quantization method, discretizing the learned feature vectors using a jointly-trained dictionary with a constrained size, in order to improve the generalisation of the registration networks. Furthermore, a novel collaborative dictionary is independently optimised to incorporate additional prior information, such as the segmentation of the gland or other regions of interest, in the latent quantized space. Based on 216 real clinical images from 86 prostate cancer patients, we show the efficacy of both the designed components. Improved registration accuracy was obtained with statistical significance, in terms of both Dice on gland and target registration error on corresponding landmarks, the latter of which achieved 5.46 mm, an improvement of 28.7\% from the baseline without quantization. Experimental results also show that the difference in performance was indeed minimised between training and testing data.      
### 10.Ultrawideband Antenna Systems Embedded into a Load Bearing Wall for Connected Buildings  [ :arrow_down: ](https://arxiv.org/pdf/2207.06185.pdf)
>  The importance of indoor mobile connectivity has increased during the last years, especially during the Covid-19 pandemic. In contrast, new energy-efficient buildings contain structures like low-emissive widows and multi-layered thermal insulations which all block radio signals effectively. To solve this problem with indoor connectivity, we study passive antenna systems embedded in walls of low-energy buildings. We provide analytical models of a load bearing wall along with numerical and empirical evaluations of ultrawideband back-to-back antenna spiral antenna system in terms of electromagnetic- and thermal insulation. The antenna systems are optimized to operate well when embedded into load bearing walls. Unit cell models of the antenna embedded load bearing wall, which are called {\it signal-transmissive walls} in this paper, are developed to analyze their electromagnetic and thermal insulation properties. We show that our signal-transmissive wall improves the electromagnetic transmission compared to a raw load bearing wall over a wide bandwidth of 3-8 GHz, covering most of the new radio frequency range 1 (NR FR1), without compromising the thermal insulation capability of the wall demanded by the building regulation.      
### 11.Gridless DOA Estimation with Multiple Frequencies  [ :arrow_down: ](https://arxiv.org/pdf/2207.06159.pdf)
>  Direction-of-arrival (DOA) estimation is widely applied in acoustic source localization. A multi-frequency model is suitable for characterizing the broadband structure in acoustic signals. In this paper, the continuous (gridless) DOA estimation problem with multiple frequencies is considered. This problem is formulated as an atomic norm minimization (ANM) problem. The ANM problem is equivalent to a semi-definite program (SDP) which can be solved by an off-the-shelf SDP solver. The dual certificate condition is provided to certify the optimality of the SDP solution so that the sources can be localized by finding the roots of a polynomial. We also construct the dual polynomial to satisfy the dual certificate condition and show that such a construction exists when the source amplitude has a uniform magnitude. In multi-frequency ANM, spatial aliasing of DOAs at higher frequencies can cause challenges. We discuss this issue extensively and propose a robust solution to combat aliasing. Numerical results support our theoretical findings and demonstrate the effectiveness of the proposed method.      
### 12.Multiview Contrastive Learning for Completely Blind Video Quality Assessment of User Generated Content  [ :arrow_down: ](https://arxiv.org/pdf/2207.06148.pdf)
>  Completely blind video quality assessment (VQA) refers to a class of quality assessment methods that do not use any reference videos, human opinion scores or training videos from the target database to learn a quality model. The design of this class of methods is particularly important since it can allow for superior generalization in performance across various datasets. We consider the design of completely blind VQA for user generated content. While several deep feature extraction methods have been considered in supervised and weakly supervised settings, such approaches have not been studied in the context of completely blind VQA. We bridge this gap by presenting a self-supervised multiview contrastive learning framework to learn spatio-temporal quality representations. In particular, we capture the common information between frame differences and frames by treating them as a pair of views and similarly obtain the shared representations between frame differences and optical flow. The resulting features are then compared with a corpus of pristine natural video patches to predict the quality of the distorted video. Detailed experiments on multiple camera captured VQA datasets reveal the superior performance of our method over other features when evaluated without training on human scores.      
### 13.MM-ALT: A Multimodal Automatic Lyric Transcription System  [ :arrow_down: ](https://arxiv.org/pdf/2207.06127.pdf)
>  Automatic lyric transcription (ALT) is a nascent field of study attracting increasing interest from both the speech and music information retrieval communities, given its significant application potential. However, ALT with audio data alone is a notoriously difficult task due to instrumental accompaniment and musical constraints resulting in degradation of both the phonetic cues and the intelligibility of sung lyrics. To tackle this challenge, we propose the MultiModal Automatic Lyric Transcription system (MM-ALT), together with a new dataset, N20EM, which consists of audio recordings, videos of lip movements, and inertial measurement unit (IMU) data of an earbud worn by the performing singer. We first adapt the wav2vec 2.0 framework from automatic speech recognition (ASR) to the ALT task. We then propose a video-based ALT method and an IMU-based voice activity detection (VAD) method. In addition, we put forward the Residual Cross Attention (RCA) mechanism to fuse data from the three modalities (i.e., audio, video, and IMU). Experiments show the effectiveness of our proposed MM-ALT system, especially in terms of noise robustness.      
### 14.SURIMI: Supervised Radio Map Augmentation with Deep Learning and a Generative Adversarial Network for Fingerprint-based Indoor Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2207.06120.pdf)
>  Indoor Positioning based on Machine Learning has drawn increasing attention both in the academy and the industry as meaningful information from the reference data can be extracted. Many researchers are using supervised, semi-supervised, and unsupervised Machine Learning models to reduce the positioning error and offer reliable solutions to the end-users. In this article, we propose a new architecture by combining Convolutional Neural Network (CNN), Long short-term memory (LSTM) and Generative Adversarial Network (GAN) in order to increase the training data and thus improve the position accuracy. The proposed combination of supervised and unsupervised models was tested in 17 public datasets, providing an extensive analysis of its performance. As a result, the positioning error has been reduced in more than 70% of them.      
### 15.DDPG Learning for Aerial RIS-Assisted MU-MISO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2207.06064.pdf)
>  This paper defines the problem of optimizing the downlink multi-user multiple input, single output (MU-MISO) sum-rate for ground users served by an aerial reconfigurable intelligent surface (ARIS) that acts as a relay to the terrestrial base station. The deep deterministic policy gradient (DDPG) is proposed to calculate the optimal active beamforming matrix at the base station and the phase shifts of the reflecting elements at the ARIS to maximize the data rate. Simulation results show the superiority of the proposed scheme when compared to deep Q-learning (DQL) and baseline approaches.      
### 16.Federated Learning for THz Channel Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2207.06017.pdf)
>  This paper addresses two major challenges in terahertz (THz) channel estimation: the beam-split phenomenon, i.e., beam misalignment because of frequency-independent analog beamformers, and computational complexity because of the usage of ultra-massive number of antennas to compensate propagation losses. Data-driven techniques are known to mitigate the complexity of this problem but usually require the transmission of the datasets from the users to a central server entailing huge communications overhead. In this work, we employ federated learning (FL), wherein the users transmit only the model parameters instead of the whole dataset, for THz channel estimation to improve the communications-efficiency. In order to accurately estimate the channel despite beam-split, we propose a beamspace support alignment technique without requiring additional hardware. Compared to the previous works, our method provides higher channel estimation accuracy as well as approximately $68$ times lower communications overhead.      
### 17.SATTS: Speaker Attractor Text to Speech, Learning to Speak by Learning to Separate  [ :arrow_down: ](https://arxiv.org/pdf/2207.06011.pdf)
>  The mapping of text to speech (TTS) is non-deterministic, letters may be pronounced differently based on context, or phonemes can vary depending on various physiological and stylistic factors like gender, age, accent, emotions, etc. Neural speaker embeddings, trained to identify or verify speakers are typically used to represent and transfer such characteristics from reference speech to synthesized speech. Speech separation on the other hand is the challenging task of separating individual speakers from an overlapping mixed signal of various speakers. Speaker attractors are high-dimensional embedding vectors that pull the time-frequency bins of each speaker's speech towards themselves while repelling those belonging to other speakers. In this work, we explore the possibility of using these powerful speaker attractors for zero-shot speaker adaptation in multi-speaker TTS synthesis and propose speaker attractor text to speech (SATTS). Through various experiments, we show that SATTS can synthesize natural speech from text from an unseen target speaker's reference signal which might have less than ideal recording conditions, i.e. reverberations or mixed with other speakers.      
### 18.Lippmann Photography: A Signal Processing Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2207.06004.pdf)
>  Lippmann (or interferential) photography is the first and only analog photography method that can capture the full color spectrum of a scene in a single take. This technique, invented more than a hundred years ago, records the colors by creating interference patterns inside the photosensitive plate. Lippmann photography provides a great opportunity to demonstrate several fundamental concepts in signal processing. Conversely, a signal processing perspective enables us to shed new light on the technique. In our previous work, we analyzed the spectra of historical Lippmann plates using our own mathematical model. In this paper, we provide the derivation of this model and validate it experimentally. We highlight new behaviors whose explanations were ignored by physicists to date. In particular, we show that the spectra generated by Lippmann plates are in fact distorted versions of the original spectra. We also show that these distortions are influenced by the thickness of the plate and the reflection coefficient of the reflective medium used in the capture of the photographs. We verify our model with extensive experiments on our own Lippmann photographs.      
### 19.Data-Driven Identification of Dynamic Quality Models in Drinking Water Networks  [ :arrow_down: ](https://arxiv.org/pdf/2207.05983.pdf)
>  Traditional control and monitoring of water quality in drinking water distribution networks (WDN) rely on mostly model- or toolbox-driven approaches, where the network topology and parameters are assumed to be known. In contrast, system identification (SysID) algorithms for generic dynamic system models seek to approximate such models using only input-output data without relying on network parameters. The objective of this paper is to investigate SysID algorithms for water quality model approximation. This research problem is challenging due to (i) complex water quality and reaction dynamics and (ii) the mismatch between the requirements of SysID algorithms and the properties of water quality dynamics. In this paper, we present the first attempt to identify water quality models in WDNs using only input-output experimental data and classical SysID methods without knowing any WDN parameters. Properties of water quality models are introduced, the ensuing challenges caused by these properties when identifying water quality models are discussed, and remedial solutions are given. Through case studies, we demonstrate the applicability of SysID algorithms, show the corresponding performance in terms of accuracy and computational time, and explore the possible factors impacting water quality model identification.      
### 20.A Simple Novel Global Optimization Algorithm and Its Performance on Some Benchmark Functions  [ :arrow_down: ](https://arxiv.org/pdf/2207.05953.pdf)
>  This paper propose a new frame work for finding global minima which we call optimization by cut. In each iteration, it takes some samples from the feasible region and evaluates the objective function at these points. Based on the observations it cuts off from the feasible region a subregion that is unlikely to contain a global minimum. The procedure is then repeated with the feasible region replaced by the remaining region until the remaining region is ``small'' enough. If a global minimum is kept in the remaining region of each iteration, then it can be located with an arbitrary precision. The frame work is surprisingly efficient in view of its simple form and can be applied to black-box functions since neither special structure nor derivative information is required. The performance of the proposed frame work is evaluated on some benchmark functions and the results show that it can find a global minimum rather quickly.      
### 21.Prediction of the motion of chest internal points using a recurrent neural network trained with real-time recurrent learning for latency compensation in lung cancer radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2207.05951.pdf)
>  During the radiotherapy treatment of patients with lung cancer, the radiation delivered to healthy tissue around the tumor needs to be minimized, which is difficult because of respiratory motion and the latency of linear accelerator systems. In the proposed study, we first use the Lucas-Kanade pyramidal optical flow algorithm to perform deformable image registration of chest computed tomography scan images of four patients with lung cancer. We then track three internal points close to the lung tumor based on the previously computed deformation field and predict their position with a recurrent neural network (RNN) trained using real-time recurrent learning (RTRL) and gradient clipping. The breathing data is quite regular, sampled at approximately 2.5Hz, and includes artificial drift in the spine direction. The amplitude of the motion of the tracked points ranged from 12.0mm to 22.7mm. Finally, we propose a simple method for recovering and predicting 3D tumor images from the tracked points and the initial tumor image based on a linear correspondence model and Nadaraya-Watson non-linear regression. The root-mean-square error, maximum error, and jitter corresponding to the RNN prediction on the test set were smaller than the same performance measures obtained with linear prediction and least mean squares (LMS). In particular, the maximum prediction error associated with the RNN, equal to 1.51mm, is respectively 16.1% and 5.0% lower than the maximum error associated with linear prediction and LMS. The average prediction time per time step with RTRL is equal to 119ms, which is less than the 400ms marker position sampling time. The tumor position in the predicted images appears visually correct, which is confirmed by the high mean cross-correlation between the original and predicted images, equal to 0.955.      
### 22.Cross-Age Speaker Verification: Learning Age-Invariant Speaker Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2207.05929.pdf)
>  Automatic speaker verification has achieved remarkable progress in recent years. However, there is little research on cross-age speaker verification (CASV) due to insufficient relevant data. In this paper, we mine cross-age test sets based on the VoxCeleb dataset and propose our age-invariant speaker representation(AISR) learning method. Since the VoxCeleb is collected from the YouTube platform, the dataset consists of cross-age data inherently. However, the meta-data does not contain the speaker age label. Therefore, we adopt the face age estimation method to predict the speaker age value from the associated visual data, then label the audio recording with the estimated age. We construct multiple Cross-Age test sets on VoxCeleb (Vox-CA), which deliberately select the positive trials with large age-gap. Also, the effect of nationality and gender is considered in selecting negative pairs to align with Vox-H cases. The baseline system performance drops from 1.939\% EER on the Vox-H test set to 10.419\% on the Vox-CA20 test set, which indicates how difficult the cross-age scenario is. Consequently, we propose an age-decoupling adversarial learning (ADAL) method to alleviate the negative effect of the age gap and reduce intra-class variance. Our method outperforms the baseline system by over 10\% related EER reduction on the Vox-CA20 test set. The source code and trial resources are available on <a class="link-external link-https" href="https://github.com/qinxiaoyi/Cross-Age_Speaker_Verification" rel="external noopener nofollow">this https URL</a>      
### 23.Online Target Speaker Voice Activity Detection for Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2207.05920.pdf)
>  This paper proposes an online target speaker voice activity detection system for speaker diarization tasks, which does not require a priori knowledge from the clustering-based diarization system to obtain the target speaker embeddings. First, we employ a ResNet-based front-end model to extract the frame-level speaker embeddings for each coming block of a signal. Next, we predict the detection state of each speaker based on these frame-level speaker embeddings and the previously estimated target speaker embedding. Then, the target speaker embeddings are updated by aggregating these frame-level speaker embeddings according to the predictions in the current block. We iteratively extract the results for each block and update the target speaker embedding until reaching the end of the signal. Experimental results show that the proposed method is better than the offline clustering-based diarization system on the AliMeeting dataset.      
### 24.A Cyclical Approach to Synthetic and Natural Speech Mismatch Refinement of Neural Post-filter for Low-cost Text-to-speech System  [ :arrow_down: ](https://arxiv.org/pdf/2207.05913.pdf)
>  Neural-based text-to-speech (TTS) systems achieve very high-fidelity speech generation because of the rapid neural network developments. However, the huge labeled corpus and high computation cost requirements limit the possibility of developing a high-fidelity TTS system by small companies or individuals. On the other hand, a neural vocoder, which has been widely adopted for the speech generation in neural-based TTS systems, can be trained with a relatively small unlabeled corpus. Therefore, in this paper, we explore a general framework to develop a neural post-filter (NPF) for low-cost TTS systems using neural vocoders. A cyclical approach is proposed to tackle the acoustic and temporal mismatches (AM and TM) of developing an NPF. Both objective and subjective evaluations have been conducted to demonstrate the AM and TM problems and the effectiveness of the proposed framework.      
### 25.Analytical stochastic macroscopic fundamental diagram driven by Wiener process  [ :arrow_down: ](https://arxiv.org/pdf/2207.05908.pdf)
>  The macroscopic fundamental diagram (MFD) is a powerful and popular tool that describes a network scale traffic operational state and serve as the plant model of perimeter control. As both the supply and the demand suffer from random disturbances, the traffic flow dynamics cannot be said to be deterministic. A stochastic MFD model can generate a stochastic evolution of the system state with desired distribution of aggregated variables is still lacking. A stochastic formulation of MFD, that considers the accumulation-dependent variations, is proposed to fill this gap. The model is based on the stochastic differential equation (SDE) theory. First, the exit flow variation is formulated as a Wiener-driven process, which admits the accumulation-of dependent variations. The stochastic MFD model is then constructed by combining the exit flow variations model. The solution of the system state is derived by the forward Fokker-Planck equation. The stability of the model is analyzed, and the parameters of a calibration method are provided. Several cases of the model are then tested. The results show that the model can be applied to different functional MFD forms, and the hysteresis and gridlock phenomenon is reproduced. The proposed MFD model can be used in the network analysis and control that considers the system's stochastic evolution.      
### 26.Hybrid Spatial-Temporal Entropy Modelling for Neural Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2207.05894.pdf)
>  For neural video codec, it is critical, yet challenging, to design an efficient entropy model which can accurately predict the probability distribution of the quantized latent representation. However, most existing video codecs directly use the ready-made entropy model from image codec to encode the residual or motion, and do not fully leverage the spatial-temporal characteristics in video. To this end, this paper proposes a powerful entropy model which efficiently captures both spatial and temporal dependencies. In particular, we introduce the latent prior which exploits the correlation among the latent representation to squeeze the temporal redundancy. Meanwhile, the dual spatial prior is proposed to reduce the spatial redundancy in a parallel-friendly manner. In addition, our entropy model is also versatile. Besides estimating the probability distribution, our entropy model also generates the quantization step at spatial-channel-wise. This content-adaptive quantization mechanism not only helps our codec achieve the smooth rate adjustment in single model but also improves the final rate-distortion performance by dynamic bit allocation. Experimental results show that, powered by the proposed entropy model, our neural codec can achieve 18.2% bitrate saving on UVG dataset when compared with H.266 (VTM) using the highest compression ratio configuration. It makes a new milestone in the development of neural video codec. The codes are at <a class="link-external link-https" href="https://github.com/microsoft/DCVC" rel="external noopener nofollow">this https URL</a>.      
### 27.Trajectory and Resource Optimization for UAV Synthetic Aperture Radar  [ :arrow_down: ](https://arxiv.org/pdf/2207.05891.pdf)
>  In this paper, we study the trajectory and resource optimization for lightweight rotary-wing unmanned aerial vehicles (UAVs) equipped with a synthetic aperture radar (SAR) system. The UAV's mission is to perform SAR imaging of a given area of interest (AoI). In this setup, real-time communication with a base station (BS) is required to facilitate live mission planning for the drone. For this purpose, a non-convex mixed-integer non-linear program (MINLP) is formulated such that the UAV resources and three-dimensional (3D) trajectory are jointly optimized for maximization of the drone radar ground coverage. We present a low-complexity sub-optimal algorithm based on successive convex approximation (SCA) for solving the problem, and perform a finite search to optimize the total distance traversed by the UAV for maximal coverage. We show that the proposed 3D trajectory planning achieves at least 70% improvement in radar ground coverage compared to benchmark schemes employing constant powers for communication or radar imaging. We also show that positioning the BS near the AoI can significantly improve the radar coverage of the UAV.      
### 28.Adaptive Diffusion Priors for Accelerated MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2207.05876.pdf)
>  Deep MRI reconstruction is commonly performed with conditional models that map undersampled data as input onto fully-sampled data as output. Conditional models perform de-aliasing under knowledge of the accelerated imaging operator, so they poorly generalize under domain shifts in the operator. Unconditional models are a powerful alternative that instead learn generative image priors to improve reliability against domain shifts. Recent diffusion models are particularly promising given their high representational diversity and sample quality. Nevertheless, projections through a static image prior can lead to suboptimal performance. Here we propose a novel MRI reconstruction, AdaDiff, based on an adaptive diffusion prior. To enable efficient image sampling, an adversarial mapper is introduced that enables use of large diffusion steps. A two-phase reconstruction is performed with the trained prior: a rapid-diffusion phase that produces an initial reconstruction, and an adaptation phase where the diffusion prior is updated to minimize reconstruction loss on acquired k-space data. Demonstrations on multi-contrast brain MRI clearly indicate that AdaDiff achieves superior performance to competing models in cross-domain tasks, and superior or on par performance in within-domain tasks.      
### 29.Fast Radix-32 Approximate DFTs for 1024-Beam Digital RF Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2207.05866.pdf)
>  The discrete Fourier transform (DFT) is widely employed for multi-beam digital beamforming. The DFT can be efficiently implemented through the use of fast Fourier transform (FFT) algorithms, thus reducing chip area, power consumption, processing time, and consumption of other hardware resources. This paper proposes three new hybrid DFT 1024-point DFT approximations and their respective fast algorithms. These approximate DFT (ADFT) algorithms have significantly reduced circuit complexity and power consumption compared to traditional FFT approaches while trading off a subtle loss in computational precision which is acceptable for digital beamforming applications in RF antenna implementations. ADFT algorithms have not been introduced for beamforming beyond $N = 32$, but this paper anticipates the need for massively large adaptive arrays for future 5G and 6G systems. Digital CMOS circuit designs for the ADFTs show the resulting improvements in both circuit complexity and power consumption metrics. Simulation results show similar or lower critical path delay with up to 48.5% lower chip area compared to a standard Cooley-Tukey FFT. The time-area and dynamic power metrics are reduced up to 66.0%. The 1024-point ADFT beamformers produce signal-to-noise ratio (SNR) gains between 29.2--30.1 dB, which is a loss of $\le$ 0.9 dB SNR gain compared to exact 1024-point DFT beamformers (worst case) realizable at using an FFT.      
### 30.On How to Not Prove Faulty Controllers Safe in Differential Dynamic Logic  [ :arrow_down: ](https://arxiv.org/pdf/2207.05854.pdf)
>  Cyber-physical systems are often safety-critical and their correctness is crucial, as in the case of automated driving. Using formal mathematical methods is one way to guarantee correctness. Though these methods have shown their usefulness, care must be taken as modeling errors might result in proving a faulty controller safe, which is potentially catastrophic in practice. This paper deals with two such modeling errors in differential dynamic logic. Differential dynamic logic is a formal specification and verification language for hybrid systems, which are mathematical models of cyber-physical systems. The main contribution is to prove conditions that when fulfilled, these two modeling errors cannot cause a faulty controller to be proven safe. The problems are illustrated with a real world example of a safety controller for automated driving, and it is shown that the formulated conditions have the intended effect both for a faulty and a correct controller. It is also shown how the formulated conditions aid in finding a loop invariant candidate to prove properties of hybrid systems with feedback loops. The results are proven using the interactive theorem prover KeYmaera X.      
### 31.Solving Bilevel Power System Problems Using Deep Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2207.05825.pdf)
>  Current state-of-the-art solution techniques for solving bilevel optimization problems either assume strong problem regularity criteria or are computationally intractable. In this paper we address power system problems of bilevel structure, commonly arising after the deregulation of the power industry. Such problems are predominantly solved by converting the lower-level problem into a set of equivalent constraints using the Karush-Kuhn-Tucker optimality conditions at an expense of binary variables. Furthermore, in case the lower-level problem is nonconvex, the strong duality does not hold rendering the single-level reduction techniques inapplicable. To overcome this, we propose an effective numerical scheme based on bypassing the lower level completely using an approximation function that replicates the relevant lower level effect on the upper level. The approximation function is constructed by training a deep convolutional neural network. The numerical procedure is run iteratively to enhance the accuracy. <br>As a case study, the proposed method is applied to a price-maker energy storage optimal bidding problem that considers an AC power flow-based market clearing in the lower level. The results indicate that greater actual profits are achieved as compared to the less accurate DC market representation.      
### 32.Subjective and Objective Quality Assessment of High-Motion Sports Videos at Low-Bitrates  [ :arrow_down: ](https://arxiv.org/pdf/2207.05798.pdf)
>  Videos often have to be transmitted and stored at low bitrates due to poor network connectivity during adaptive bitrate streaming. Designing optimal bitrate ladders that would select the perceptually-optimized resolution, frame-rate, and compression level for low-bitrate videos for adaptive streaming across the internet is therefore a task of great interest. Towards that end, we conducted the first large-scale study of medium and low-bitrate videos from live sports for two codecs (Elemental AVC and HEVC) and created the Amazon Prime Video Low-Bitrate Sports (APV LBS) dataset. The study involved 94 participants and 742 videos, with more than 23,000 human opinion scores collected in total. We analyzed the data obtained and we also conducted an extensive evaluation of objective Video Quality Assessment (VQA) algorithms and benchmarked their performance, and make recommendations on bitrate ladder design. We're making the metadata and VQA features available at <a class="link-external link-https" href="https://github.com/JoshuaEbenezer/lbmfr-public" rel="external noopener nofollow">this https URL</a>.      
### 33.Shape-Aware Masking for Inpainting in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2207.05787.pdf)
>  Inpainting has recently been proposed as a successful deep learning technique for unsupervised medical image model discovery. The masks used for inpainting are generally independent of the dataset and are not tailored to perform on different given classes of anatomy. In this work, we introduce a method for generating shape-aware masks for inpainting, which aims at learning the statistical shape prior. We hypothesize that although the variation of masks improves the generalizability of inpainting models, the shape of the masks should follow the topology of the organs of interest. Hence, we propose an unsupervised guided masking approach based on an off-the-shelf inpainting model and a superpixel over-segmentation algorithm to generate a wide range of shape-dependent masks. Experimental results on abdominal MR image reconstruction show the superiority of our proposed masking method over standard methods using square-shaped or dataset of irregular shape masks.      
### 34.Masked Autoencoders that Listen  [ :arrow_down: ](https://arxiv.org/pdf/2207.06405.pdf)
>  This paper studies a simple extension of image-based Masked Autoencoders (MAE) to self-supervised representation learning from audio spectrograms. Following the Transformer encoder-decoder design in MAE, our Audio-MAE first encodes audio spectrogram patches with a high masking ratio, feeding only the non-masked tokens through encoder layers. The decoder then re-orders and decodes the encoded context padded with mask tokens, in order to reconstruct the input spectrogram. We find it beneficial to incorporate local window attention in the decoder, as audio spectrograms are highly correlated in local time and frequency bands. We then fine-tune the encoder with a lower masking ratio on target datasets. Empirically, Audio-MAE sets new state-of-the-art performance on six audio and speech classification tasks, outperforming other recent models that use external supervised pre-training. The code and models will be at <a class="link-external link-https" href="https://github.com/facebookresearch/AudioMAE" rel="external noopener nofollow">this https URL</a>.      
### 35.Relationship Design for Socially Desirable Behavior in Static Games  [ :arrow_down: ](https://arxiv.org/pdf/2207.06392.pdf)
>  Interactions among multiple self-interested agents may not necessarily yield socially desirable behaviors. While static games offer a pragmatic model for such interactions, and modifying the utilities of the agents in such games provides a means toward achieving socially desirable behavior, manipulating the utilities is hard-if not impossible-after the system is deployed. We investigate an alternative means where each agent incorporates others' utilities into its own utility based on a relationship network, which characterizes how much one agent cares about another and hence the extent of their utility incorporation. We introduce the notion of a relationship game, a static game with a set of weighted relationship networks and a social cost function. The main problem we study is the design of the weight vector on the relationships such that the Nash equilibrium of the associated game is socially desirable. We propose an ordering-based exact method and a gradient-based approximate method to solve this problem. We show theoretically that the exact solution scales exponentially with the number of players. Empirical results show both methods are effective and scale exponentially, with the runtime of gradient-based solution growing slower.      
### 36.Iterative Linear Quadratic Optimization for Nonlinear Control: Differentiable Programming Algorithmic Templates  [ :arrow_down: ](https://arxiv.org/pdf/2207.06362.pdf)
>  We present the implementation of nonlinear control algorithms based on linear and quadratic approximations of the objective from a functional viewpoint. We present a gradient descent, a Gauss-Newton method, a Newton method, differential dynamic programming approaches with linear quadratic or quadratic approximations, various line-search strategies, and regularized variants of these algorithms. We derive the computational complexities of all algorithms in a differentiable programming framework and present sufficient optimality conditions. We compare the algorithms on several benchmarks, such as autonomous car racing using a bicycle model of a car. The algorithms are coded in a differentiable programming language in a publicly available package.      
### 37.Polyphonic sound event detection for highly dense birdsong scenes  [ :arrow_down: ](https://arxiv.org/pdf/2207.06349.pdf)
>  One hour before sunrise, one can experience the dawn chorus where birds from different species sing together. In this scenario, high levels of polyphony, as in the number of overlapping sound sources, are prone to happen resulting in a complex acoustic outcome. Sound Event Detection (SED) tasks analyze acoustic scenarios in order to identify the occurring events and their respective temporal information. However, highly dense scenarios can be hard to process and have not been studied in depth. Here we show, using a Convolutional Recurrent Neural Network (CRNN), how birdsong polyphonic scenarios can be detected when dealing with higher polyphony and how effectively this type of model can face a very dense scene with up to 10 overlapping birds. We found that models trained with denser examples (i.e., higher polyphony) learn at a similar rate as models that used simpler samples in their training set. Additionally, the model trained with the densest samples maintained a consistent score for all polyphonies, while the model trained with the least dense samples degraded as the polyphony increased. Our results demonstrate that highly dense acoustic scenarios can be dealt with using CRNNs. We expect that this study serves as a starting point for working on highly populated bird scenarios such as dawn chorus or other dense acoustic problems.      
### 38.Dynamic gNodeB Sleep Control for Energy-Conserving 5G Radio Access Network  [ :arrow_down: ](https://arxiv.org/pdf/2207.06309.pdf)
>  5G radio access network (RAN) is consuming much more energy than legacy RAN due to the denser deployments of gNodeBs (gNBs) and higher single-gNB power consumption. In an effort to achieve an energy-conserving RAN, this paper develops a dynamic on-off switching paradigm, where the ON/OFF states of gNBs can be dynamically configured according to the evolvements of the associated users. We formulate the dynamic sleep control for a cluster of gNBs as a Markov decision process (MDP) and analyze various switching policies to reduce the energy expenditure. The optimal policy of the MDP that minimizes the energy expenditure can be derived from dynamic programming, but the computation is expensive. To circumvent this issue, this paper puts forth a greedy policy and an index policy for gNB sleep control. When there is no constraint on the number of gNBs that can be turned off, we prove the dual-threshold structure of the greedy policy and analyze its connections with the optimal policy. Inspired by the dual-threshold structure and Whittle index, we develop an index policy by decoupling the original MDP into multiple one-dimensional MDPs -- the indexability of the decoupled MDP is proven and an algorithm to compute the index is proposed. Extensive simulation results verify that the index policy exhibits close-to-optimal performance in terms of the energy expenditure of the gNB cluster. As far as the computational complexity is concerned, on the other hand, the index policy is much more efficient than the optimal policy, which is computationally prohibitive when the number of gNBs is large.      
### 39.A comparison between PMBM Bayesian track initiation and labelled RFS adaptive birth  [ :arrow_down: ](https://arxiv.org/pdf/2207.06156.pdf)
>  This paper provides a comparative analysis between the adaptive birth model used in the labelled random finite set literature and the track initiation in the Poisson multi-Bernoulli mixture (PMBM) filter, with point-target models. The PMBM track initiation is obtained via Bayes' rule applied on the predicted PMBM density, and creates one Bernoulli component for each received measurement, representing that this measurement may be clutter or a detection from a new target. Adaptive birth mimics this procedure by creating a Bernoulli component for each measurement using a different rule to determine the probability of existence and a user-defined single-target density. This paper first provides an analysis of the differences that arise in track initiation based on isolated measurements. Then, it shows that adaptive birth underestimates the number of objects present in the surveillance area under common modelling assumptions. Finally, we provide numerical simulations to further illustrate the differences.      
### 40.Estimating the Power Consumption of Heterogeneous Devices when performing AI Inference  [ :arrow_down: ](https://arxiv.org/pdf/2207.06150.pdf)
>  Modern-day life is driven by electronic devices connected to the internet. The emerging research field of the Internet-of-Things (IoT) has become popular, just as there has been a steady increase in the number of connected devices - now over 50 billion. Since many of these devices are utilised to perform \gls*{cv} tasks, it is essential to understand their power consumption against performance. We report the power consumption profile and analysis of the NVIDIA Jetson Nano board while performing object classification. The authors present an extensive analysis regarding power consumption per frame and the output in frames per second (FPS) using YOLOv5 models. The results show that the YOLOv5n outperforms other YOLOV5 variants in terms of throughput (i.e. 12.34 fps) and low power consumption (i.e. 0.154 mWh/frame).      
### 41.A Personalised User Authentication System based on EEG Signals  [ :arrow_down: ](https://arxiv.org/pdf/2207.06109.pdf)
>  Conventional biometrics have been employed in high security user authentication systems for over 20 years now. However, some of these modalities face low security issues in common practice. Brain wave based user authentication has emerged as a promising alternative method, as it overcomes some of these drawbacks and allows for continuous user authentication. In the present study we address the problem of individual user variability, by proposing a data-driven Electroencephalography (EEG) based authentication method. We introduce machine learning techniques, in order to reveal the optimal classification algorithm that best fits the data of each individual user, in a fast and efficient manner. A set of 15 power spectral features (delta, theta, lower alpha, higher alpha, and alpha) is extracted from the three EEG channels. The results show that our approach can reliably grant or deny access to the user (mean accuracy 95,6%), while at the same time poses as a viable option for real time applications, as the total time of the training procedure was kept under one minute.      
### 42.Learnability Enhancement for Low-light Raw Denoising: Where Paired Real Data Meets Noise Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2207.06103.pdf)
>  Low-light raw denoising is an important and valuable task in computational photography where learning-based methods trained with paired real data are mainstream. However, the limited data volume and complicated noise distribution have constituted a learnability bottleneck for paired real data, which limits the denoising performance of learning-based methods. To address this issue, we present a learnability enhancement strategy to reform paired real data according to noise modeling. Our strategy consists of two efficient techniques: shot noise augmentation (SNA) and dark shading correction (DSC). Through noise model decoupling, SNA improves the precision of data mapping by increasing the data volume and DSC reduces the complexity of data mapping by reducing the noise complexity. Extensive results on the public datasets and real imaging scenarios collectively demonstrate the state-of-the-art performance of our method.      
### 43.A construction-free coordinate-descent augmented-Lagrangian method for embedded linear MPC based on ARX models  [ :arrow_down: ](https://arxiv.org/pdf/2207.06098.pdf)
>  This paper proposes an efficient algorithm for solving linear MPC problems based on autoregressive with exogenous terms (ARX) input-output models. Rather than converting the ARX model in state-space form and rely on classical linear MPC methods, we propose an algorithm that directly uses the ARX model to build and solve the MPC problem in a very efficient way. A main feature of the approach is that it completely avoids the online construction step, which makes it very attractive when the ARX model adapted recursively at runtime. The solution algorithm relies on a coordinate-descent augmented Lagrangian (CDAL) method previously proposed by the authors, that we adapt here to exploit the special structure of ARX-based MPC. The implementation of the resulting CDAL-ARX algorithm is matrix-free and library-free, and hence amenable for deployment in industrial embedded platforms. We show the efficiency of CDAL-ARX in a numerical example, also in comparison with MPC implementations based on state-space models and general-purpose quadratic programming solvers.      
### 44.On Merging Feature Engineering and Deep Learning for Diagnosis, Risk-Prediction and Age Estimation Based on the 12-Lead ECG  [ :arrow_down: ](https://arxiv.org/pdf/2207.06096.pdf)
>  Objective: Machine learning techniques have been used extensively for 12-lead electrocardiogram (ECG) analysis. For physiological time series, deep learning (DL) superiority to feature engineering (FE) approaches based on domain knowledge is still an open question. Moreover, it remains unclear whether combining DL with FE may improve performance. Methods: We considered three tasks intending to address these research gaps: cardiac arrhythmia diagnosis (multiclass-multilabel classification), atrial fibrillation risk prediction (binary classification), and age estimation (regression). We used an overall dataset of 2.3M 12-lead ECG recordings to train the following models for each task: i) a random forest taking the FE as input was trained as a classical machine learning approach; ii) an end-to-end DL model; and iii) a merged model of FE+DL. Results: FE yielded comparable results to DL while necessitating significantly less data for the two classification tasks and it was outperformed by DL for the regression task. For all tasks, merging FE with DL did not improve performance over DL alone. Conclusion: We found that for traditional 12-lead ECG based diagnosis tasks DL did not yield a meaningful improvement over FE, while it improved significantly the nontraditional regression task. We also found that combining FE with DL did not improve over DL alone which suggests that the FE were redundant with the features learned by DL. Significance: Our findings provides important recommendations on what machine learning strategy and data regime to chose with respect to the task at hand for the development of new machine learning models based on the 12-lead ECG.      
### 45.Introducing $$-lifting for Learning Nonlinear Pulse Shaping in Coherent Optical Communication  [ :arrow_down: ](https://arxiv.org/pdf/2207.06089.pdf)
>  Pulse shaping for coherent optical fiber communication has been an active area of research for the past decade. Most of the early schemes are based on classic Nyquist pulse shaping that was originally intended for linear channels. The best known classic scheme, the split digital back-propagation (DBP), uses joint pre-distortion and post equalization and hence, a nonlinear transmitter (TX); it, however, suffers from spectral broadening on the fiber due to the Kerr-effect. With the advent of deep learning in communications, it has been realized that an Autoencoder can learn to communicate efficiently over the optical fiber channel, jointly optimizing geometric constellations and pulse shaping - while also taking into account linear and nonlinear impairments such as chromatic dispersion and Kerr-nonlinearity. E.g., <a class="link-https" data-arxiv-id="2006.15027" href="https://arxiv.org/abs/2006.15027">arXiv:2006.15027</a> shows how an Autoencoder can learn to mitigate spectral broadening due to the Kerr-effect using a trainable linear TX. In this paper, we extend this linear architectural template to a scalable nonlinear pulse shaping consisting of a Convolutional Neural Network at both transmitter and receiver. By introducing a novel $\gamma$-lifting training procedure tailored to the nonlinear optical fiber channel, we achieve stable Autoencoder convergence to pulse shapes reaching information rates outperforming the classic split DBP reference at high input powers.      
### 46.Controllable and Lossless Non-Autoregressive End-to-End Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2207.06088.pdf)
>  Some recent studies have demonstrated the feasibility of single-stage neural text-to-speech, which does not need to generate mel-spectrograms but generates the raw waveforms directly from the text. Single-stage text-to-speech often faces two problems: a) the one-to-many mapping problem due to multiple speech variations and b) insufficiency of high frequency reconstruction due to the lack of supervision of ground-truth acoustic features during training. To solve the a) problem and generate more expressive speech, we propose a novel phoneme-level prosody modeling method based on a variational autoencoder with normalizing flows to model underlying prosodic information in speech. We also use the prosody predictor to support end-to-end expressive speech synthesis. Furthermore, we propose the dual parallel autoencoder to introduce supervision of the ground-truth acoustic features during training to solve the b) problem enabling our model to generate high-quality speech. We compare the synthesis quality with state-of-the-art text-to-speech systems on an internal expressive English dataset. Both qualitative and quantitative evaluations demonstrate the superiority and robustness of our method for lossless speech generation while also showing a strong capability in prosody modeling.      
### 47.Safe learning LQR of linear dynamics with multiplicative noise  [ :arrow_down: ](https://arxiv.org/pdf/2207.06062.pdf)
>  Control of linear dynamics with multiplicative noise naturally introduces robustness against dynamical uncertainty. Moreover, many physical systems are subject to multiplicative disturbances. In this work we show how these dynamics can be identified from state trajectories. The least-squares scheme enables exploitation of prior information and comes with practical data-driven confidence bounds and sample complexity guarantees. We complement this scheme with an associated control synthesis procedure for LQR which robustifies against distributional uncertainty, guaranteeing stability with high probability and converging to the true optimum at a rate inversely proportional with the sample count. Throughout we exploit the underlying multi-linear problem structure through tensor algebra and completely positive operators. The scheme is validated through numerical experiments.      
### 48.Subband-based Generative Adversarial Network for Non-parallel Many-to-many Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2207.06057.pdf)
>  Voice conversion is to generate a new speech with the source content and a target voice style. In this paper, we focus on one general setting, i.e., non-parallel many-to-many voice conversion, which is close to the real-world scenario. As the name implies, non-parallel many-to-many voice conversion does not require the paired source and reference speeches and can be applied to arbitrary voice transfer. In recent years, Generative Adversarial Networks (GANs) and other techniques such as Conditional Variational Autoencoders (CVAEs) have made considerable progress in this field. However, due to the sophistication of voice conversion, the style similarity of the converted speech is still unsatisfactory. Inspired by the inherent structure of mel-spectrogram, we propose a new voice conversion framework, i.e., Subband-based Generative Adversarial Network for Voice Conversion (SGAN-VC). SGAN-VC converts each subband content of the source speech separately by explicitly utilizing the spatial characteristics between different subbands. SGAN-VC contains one style encoder, one content encoder, and one decoder. In particular, the style encoder network is designed to learn style codes for different subbands of the target speaker. The content encoder network can capture the content information on the source speech. Finally, the decoder generates particular subband content. In addition, we propose a pitch-shift module to fine-tune the pitch of the source speaker, making the converted tone more accurate and explainable. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on VCTK Corpus and AISHELL3 datasets both qualitatively and quantitatively, whether on seen or unseen data. Furthermore, the content intelligibility of SGAN-VC on unseen data even exceeds that of StarGANv2-VC with ASR network assistance.      
### 49.Abnormality Detection and Localization Schemes using Molecular Communication Systems: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2207.06032.pdf)
>  Abnormality, defined as any abnormal feature in the system, may occur in different areas such as healthcare, medicine, cyber security, industry, etc. The detection and localization of the abnormality have been studied widely in wireless sensor networks literature where the sensors use electromagnetic waves for communication. Due to their invasiveness, bio-incompatibility, and high energy consumption for some applications, molecular communication (MC) has been introduced as an alternative approach, which enables promising systems for abnormality detection and localization. In this paper, we overview the MC-based abnormality detection and localization schemes. To do this, we propose a general MC system for abnormality detection and localization to encompass the most related works. The general MC-based abnormality detection and localization system consists of multiple tiers for sensing the abnormality and communication between different agents in the system. We describe different abnormality recognition methods, which can be used by the sensors to obtain information about the abnormality. Further, we describe the functional units of the sensors and different sensor features. We explain different interfaces for connecting the internal and external communication networks and generally model the sensing and communication channels. We formulate the abnormality detection and localization problem using MC systems and present a general framework for the externally-controllable localization systems. We categorize the MC-based abnormality detection schemes based on the sensor mobility, cooperative detection, and cooperative sensing/activation. We classify the localization approaches based on the sensor mobility and propulsion mechanisms. Finally, we provide the ongoing challenges and future research directions to realize and develop MC-based systems for detection and localization of the abnormality.      
### 50.Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2207.06020.pdf)
>  This paper focuses on designing a noise-robust end-to-end Audio-Visual Speech Recognition (AVSR) system. To this end, we propose Visual Context-driven Audio Feature Enhancement module (V-CAFE) to enhance the input noisy audio speech with a help of audio-visual correspondence. The proposed V-CAFE is designed to capture the transition of lip movements, namely visual context and to generate a noise reduction mask by considering the obtained visual context. Through context-dependent modeling, the ambiguity in viseme-to-phoneme mapping can be refined for mask generation. The noisy representations are masked out with the noise reduction mask resulting in enhanced audio features. The enhanced audio features are fused with the visual features and taken to an encoder-decoder model composed of Conformer and Transformer for speech recognition. We show the proposed end-to-end AVSR with the V-CAFE can further improve the noise-robustness of AVSR. The effectiveness of the proposed method is evaluated in noisy speech recognition and overlapped speech recognition experiments using the two largest audio-visual datasets, LRS2 and LRS3.      
### 51.Text-driven Emotional Style Control and Cross-speaker Style Transfer in Neural TTS  [ :arrow_down: ](https://arxiv.org/pdf/2207.06000.pdf)
>  Expressive text-to-speech has shown improved performance in recent years. However, the style control of synthetic speech is often restricted to discrete emotion categories and requires training data recorded by the target speaker in the target style. In many practical situations, users may not have reference speech recorded in target emotion but still be interested in controlling speech style just by typing text description of desired emotional style. In this paper, we propose a text-based interface for emotional style control and cross-speaker style transfer in multi-speaker TTS. We propose the bi-modal style encoder which models the semantic relationship between text description embedding and speech style embedding with a pretrained language model. To further improve cross-speaker style transfer on disjoint, multi-style datasets, we propose the novel style loss. The experimental results show that our model can generate high-quality expressive speech even in unseen style.      
### 52.Second Moment Polytopic Systems: Generalization of Uncertain Stochastic Linear Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2207.05922.pdf)
>  This paper presents a new paradigm to stabilize uncertain stochastic linear systems. Herein, second moment polytopic (SMP) systems are proposed that generalize systems with both uncertainty and randomness. The SMP systems are characterized by second moments of the stochastic system matrices and the uncertain parameters. Further, a fundamental theory for guaranteeing stability of the SMP systems is established. It is challenging to analyze the SMP systems owing to both the uncertainty and randomness. An idea to overcome this difficulty is to expand the SMP systems and exclude the randomness. Because the expanded systems contain only the uncertainty, their stability can be analyzed via robust stability theory. The stability of the expanded systems is equivalent to statistical stability of the SMP systems. These facts provide sufficient conditions for the stability of the SMP systems as linear matrix inequalities (MIs). In controller design for the SMP systems, the linear MIs reduce to cubic MIs whose solutions correspond to feedback gains. The cubic MIs are transformed into simpler quadratic MIs that can be solved using optimization techniques. Moreover, solving such non-convex MIs is relaxed into the iteration of a convex optimization. Solutions to the iterative optimization provide feedback gains that stabilize the SMP systems. As demonstrated here, the SMP systems represent linear dynamics with uncertain mean and covariance and other existing systems such as independently identically distributed dynamics and random polytopes. Finally, a numerical simulation shows the effectiveness of the proposed method.      
### 53.Safe Human-Robot Collaborative Transportation via Trust-Driven Role Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2207.05896.pdf)
>  We study a human-robot collaborative transportation task in presence of obstacles. The task for each agent is to carry a rigid object to a common target position, while safely avoiding obstacles and satisfying the compliance and actuation constraints of the other agent. Human and robot do not share the local view of the environment. The human policy either assists the robot when they deem the robot actions safe based on their perception of the environment, or actively leads the task. Using estimated human inputs, the robot plans a trajectory for the transported object by solving a constrained finite time optimal control problem. Sensors on the robot measure the inputs applied by the human. The robot then appropriately applies a weighted combination of the human's applied and its own planned inputs, where the weights are chosen based on the robot's trust value on its estimates of the human's inputs. This allows for a dynamic leader-follower role adaptation of the robot throughout the task. Furthermore, under a low value of trust, if the robot approaches any obstacle potentially unknown to the human, it triggers a safe stopping policy, maintaining safety of the system and signaling a required change in the human's intent. With experimental results, we demonstrate the efficacy of the proposed approach.      
### 54.Control Allocation for Hybrid Coulomb Spacecraft Formations  [ :arrow_down: ](https://arxiv.org/pdf/2207.05881.pdf)
>  This paper proposes an algorithm which can be used in hybrid Coulomb spacecraft formations to minimize propellant by maximizing the amount of force that is generated by Coulomb forces. This problem is difficult due to the nonlinearities inherent in Coulomb's law. The problem is posed as a series of matrix rank minimization problems which can be solved efficiently using a trace heuristic. A numerical example is provided which shows that, using the proposed control allocation algorithm, the amount of propellant required to perform a reconfiguration maneuver is reduced by approximately 40% compared to using solely thrusters.      
### 55.Flexible Ramping Product Procurement in Day-Ahead Markets  [ :arrow_down: ](https://arxiv.org/pdf/2207.05880.pdf)
>  This article puts forward a methodology for procuring flexible ramping products (FRPs) in the day-ahead market (DAM). The proposed methodology comprises two market passes, the first of which employs a stochastic unit commitment (SUC) model that explicitly evaluates the uncertainty and the intra-hourly and inter-hourly variability of net load so as to minimize the expected total operating cost. The second pass clears the DAM while imposing FRP requirements. The cornerstone of our work is to set the FRP requirements at levels that drive the DAM decisions toward the optimal SUC decisions. Our methodology provides an economic underpinning for the stipulated FRP requirements, and it brings forth DAM awards that reduce the costs toward the expected total cost under SUC, while conforming to the chief DAM design principles. By preemptively considering the dispatch costs before awarding FRPs, it can further avert unexpectedly high costs that could result with the deployment of procured FRPs. We conduct numerical studies and lay out the relative merits of the proposed methodology vis--vis selected benchmarks based on various evaluation metrics.      
### 56.Interaction-aware Decision-making for Automated Vehicles using Social Value Orientation  [ :arrow_down: ](https://arxiv.org/pdf/2207.05853.pdf)
>  Motion control algorithms in the presence of pedestrians are critical for the development of safe and reliable Autonomous Vehicles (AVs). Traditional motion control algorithms rely on manually designed decision-making policies which neglect the mutual interactions between AVs and pedestrians. On the other hand, recent advances in Deep Reinforcement Learning allow for the automatic learning of policies without manual designs. To tackle the problem of decision-making in the presence of pedestrians, the authors introduce a framework based on Social Value Orientation and Deep Reinforcement Learning (DRL) that is capable of generating decision-making policies with different driving styles. The policy is trained using state-of-the-art DRL algorithms in a simulated environment. A novel computationally-efficient pedestrian model that is suitable for DRL training is also introduced. We perform experiments to validate our framework and we conduct a comparative analysis of the policies obtained with two different model-free Deep Reinforcement Learning Algorithms. Simulations results show how the developed model exhibits natural driving behaviours, such as short-stopping, to facilitate the pedestrian's crossing.      
### 57.Compactly Restrictable Metric Policy Optimization Problems  [ :arrow_down: ](https://arxiv.org/pdf/2207.05850.pdf)
>  We study policy optimization problems for deterministic Markov decision processes (MDPs) with metric state and action spaces, which we refer to as Metric Policy Optimization Problems (MPOPs). Our goal is to establish theoretical results on the well-posedness of MPOPs that can characterize practically relevant continuous control systems. To do so, we define a special class of MPOPs called Compactly Restrictable MPOPs (CR-MPOPs), which are flexible enough to capture the complex behavior of robotic systems but specific enough to admit solutions using dynamic programming methods such as value iteration. We show how to arrive at CR-MPOPs using forward-invariance. We further show that our theoretical results on CR-MPOPs can be used to characterize feedback linearizable control affine systems.      
### 58.NEC: Speaker Selective Cancellation via Neural Enhanced Ultrasound Shadowing  [ :arrow_down: ](https://arxiv.org/pdf/2207.05848.pdf)
>  In this paper, we propose NEC (Neural Enhanced Cancellation), a defense mechanism, which prevents unauthorized microphones from capturing a target speaker's voice. Compared with the existing scrambling-based audio cancellation approaches, NEC can selectively remove a target speaker's voice from a mixed speech without causing interference to others. Specifically, for a target speaker, we design a Deep Neural Network (DNN) model to extract high-level speaker-specific but utterance-independent vocal features from his/her reference audios. When the microphone is recording, the DNN generates a shadow sound to cancel the target voice in real-time. Moreover, we modulate the audible shadow sound onto an ultrasound frequency, making it inaudible for humans. By leveraging the non-linearity of the microphone circuit, the microphone can accurately decode the shadow sound for target voice cancellation. We implement and evaluate NEC comprehensively with 8 smartphone microphones in different settings. The results show that NEC effectively mutes the target speaker at a microphone without interfering with other users' normal conversations.      
### 59.On Partial Adoption of Vehicle-to-Vehicle Communication: When Should Cars Warn Each Other of Hazards?  [ :arrow_down: ](https://arxiv.org/pdf/2207.05846.pdf)
>  The emerging technology of Vehicle-to-Vehicle (V2V) communication over vehicular ad hoc networks promises to improve road safety by allowing vehicles to autonomously warn each other of road hazards. However, research on other transportation information systems has shown that informing only a subset of drivers of road conditions may have a perverse effect of increasing congestion. In the context of a simple (yet novel) model of V2V hazard information sharing, we ask whether partial adoption of this technology can similarly lead to undesirable outcomes. In our model, drivers individually choose how recklessly to behave as a function of information received from other V2V-enabled cars, and the resulting aggregate behavior influences the likelihood of accidents (and thus the information propagated by the vehicular network). We fully characterize the game-theoretic equilibria of this model. Our model indicates that for a wide range of our parameter space, V2V information sharing surprisingly increases the equilibrium frequency of accidents relative to no V2V information sharing, and that it may increase equilibrium social cost as well.      
### 60.Exploiting Social Graph Networks for Emotion Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2207.05820.pdf)
>  Emotion prediction plays an essential role in mental health and emotion-aware computing. The complex nature of emotion resulting from its dependency on a person's physiological health, mental state, and his surroundings makes its prediction a challenging task. In this work, we utilize mobile sensing data to predict happiness and stress. In addition to a person's physiological features, we also incorporate the environment's impact through weather and social network. To this end, we leverage phone data to construct social networks and develop a machine learning architecture that aggregates information from multiple users of the graph network and integrates it with the temporal dynamics of data to predict emotion for all the users. The construction of social networks does not incur additional cost in terms of EMAs or data collection from users and doesn't raise privacy concerns. We propose an architecture that automates the integration of a user's social network affect prediction, is capable of dealing with the dynamic distribution of real-life social networks, making it scalable to large-scale networks. Our extensive evaluation highlights the improvement provided by the integration of social networks. We further investigate the impact of graph topology on model's performance.      
### 61.Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for Low-Resource Devices  [ :arrow_down: ](https://arxiv.org/pdf/2207.05784.pdf)
>  This work introduces BRILLsson, a novel binary neural network-based representation learning model for a broad range of non-semantic speech tasks. We train the model with knowledge distillation from a large and real-valued TRILLsson model with only a fraction of the dataset used to train TRILLsson. The resulting BRILLsson models are only 2MB in size with a latency less than 8ms, making them suitable for deployment in low-resource devices such as wearables. We evaluate BRILLsson on eight benchmark tasks (including but not limited to spoken language identification, emotion recognition, heath condition diagnosis, and keyword spotting), and demonstrate that our proposed ultra-light and low-latency models perform as well as large-scale models.      
### 62.Robust and efficient computation of retinal fractal dimension through deep approximation  [ :arrow_down: ](https://arxiv.org/pdf/2207.05757.pdf)
>  A retinal trait, or phenotype, summarises a specific aspect of a retinal image in a single number. This can then be used for further analyses, e.g. with statistical methods. However, reducing an aspect of a complex image to a single, meaningful number is challenging. Thus, methods for calculating retinal traits tend to be complex, multi-step pipelines that can only be applied to high quality images. This means that researchers often have to discard substantial portions of the available data. We hypothesise that such pipelines can be approximated with a single, simpler step that can be made robust to common quality issues. We propose Deep Approximation of Retinal Traits (DART) where a deep neural network is used predict the output of an existing pipeline on high quality images from synthetically degraded versions of these images. We demonstrate DART on retinal Fractal Dimension (FD) calculated by VAMPIRE, using retinal images from UK Biobank that previous work identified as high quality. Our method shows very high agreement with FD VAMPIRE on unseen test images (Pearson r=0.9572). Even when those images are severely degraded, DART can still recover an FD estimate that shows good agreement with FD VAMPIRE obtained from the original images (Pearson r=0.8817). This suggests that our method could enable researchers to discard fewer images in the future. Our method can compute FD for over 1,000img/s using a single GPU. We consider these to be very encouraging initial results and hope to develop this approach into a useful tool for retinal analysis.      
### 63.Towards Highly Expressive Machine Learning Models of Non-Melanoma Skin Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2207.05749.pdf)
>  Pathologists have a rich vocabulary with which they can describe all the nuances of cellular morphology. In their world, there is a natural pairing of images and words. Recent advances demonstrate that machine learning models can now be trained to learn high-quality image features and represent them as discrete units of information. This enables natural language, which is also discrete, to be jointly modelled alongside the imaging, resulting in a description of the contents of the imaging. Here we present experiments in applying discrete modelling techniques to the problem domain of non-melanoma skin cancer, specifically, histological images of Intraepidermal Carcinoma (IEC). Implementing a VQ-GAN model to reconstruct high-resolution (256x256) images of IEC images, we trained a sequence-to-sequence transformer to generate natural language descriptions using pathologist terminology. Combined with the idea of interactive concept vectors available by using continuous generative methods, we demonstrate an additional angle of interpretability. The result is a promising means of working towards highly expressive machine learning systems which are not only useful as predictive/classification tools, but also means to further our scientific understanding of disease.      
