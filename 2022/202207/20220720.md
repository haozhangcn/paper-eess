# ArXiv eess --Wed, 20 Jul 2022
### 1.Unrolled algorithms for group synchronization  [ :arrow_down: ](https://arxiv.org/pdf/2207.09418.pdf)
>  The group synchronization problem involves estimating a collection of group elements from noisy measurements of their pairwise ratios. This task is a key component in many computational problems, including the molecular reconstruction problem in single-particle cryo-electron microscopy (cryo-EM). The standard methods to estimate the group elements are based on iteratively applying linear and non-linear operators. Motivated by the structural similarity to deep neural networks, we adopt the concept of algorithm unrolling, where training data is used to optimize the algorithm. We design unrolled algorithms for several group synchronization instances, including synchronization over the group of 3-D rotations: the synchronization problem in cryo-EM. We also apply a similar approach to the multi-reference alignment problem. We show by numerical experiments that the unrolling strategy outperforms existing synchronization algorithms in a wide variety of scenarios.      
### 2.Image Synthesis with Disentangled Attributes for Chest X-Ray Nodule Augmentation and Detection  [ :arrow_down: ](https://arxiv.org/pdf/2207.09389.pdf)
>  Lung nodule detection in chest X-ray (CXR) images is common to early screening of lung cancers. Deep-learning-based Computer-Assisted Diagnosis (CAD) systems can support radiologists for nodule screening in CXR. However, it requires large-scale and diverse medical data with high-quality annotations to train such robust and accurate CADs. To alleviate the limited availability of such datasets, lung nodule synthesis methods are proposed for the sake of data augmentation. Nevertheless, previous methods lack the ability to generate nodules that are realistic with the size attribute desired by the detector. To address this issue, we introduce a novel lung nodule synthesis framework in this paper, which decomposes nodule attributes into three main aspects including shape, size, and texture, respectively. A GAN-based Shape Generator firstly models nodule shapes by generating diverse shape masks. The following Size Modulation then enables quantitative control on the diameters of the generated nodule shapes in pixel-level granularity. A coarse-to-fine gated convolutional Texture Generator finally synthesizes visually plausible nodule textures conditioned on the modulated shape masks. Moreover, we propose to synthesize nodule CXR images by controlling the disentangled nodule attributes for data augmentation, in order to better compensate for the nodules that are easily missed in the detection task. Our experiments demonstrate the enhanced image quality, diversity, and controllability of the proposed lung nodule synthesis framework. We also validate the effectiveness of our data augmentation on greatly improving nodule detection performance.      
### 3.Day-ahead Schedule Considering the Participation of Electric Vehicles in Primary Frequency Response  [ :arrow_down: ](https://arxiv.org/pdf/2207.09330.pdf)
>  The insertion of renewable sources in power systems may cause a decrease in the system's equivalent inertia, which result in the instability of the power system. On the other hand, energy storage systems have proven to be an effective tool to increase the flexibility in the operation of energy systems, which may favor integrating renewable energy sources. In this way, plug-in electric vehicle (PEVs) batteries can be used as storages when such vehicles are parked and connected to the grid. In this work, the contribution of PEVs to primary frequency response is analyzed in systems dominated by renewable sources. A day-ahead scheduling model is developed considering PEVs groups can actively participate in electricity markets, supporting day-ahead reserve capacity and providing primary frequency response. The proposed model is implemented in the distribution system of the Federal University of AmapÃ¡.      
### 4.Towards Trustworthy Healthcare AI: Attention-Based Feature Learning for COVID-19 Screening With Chest Radiography  [ :arrow_down: ](https://arxiv.org/pdf/2207.09312.pdf)
>  Building AI models with trustworthiness is important especially in regulated areas such as healthcare. In tackling COVID-19, previous work uses convolutional neural networks as the backbone architecture, which has shown to be prone to over-caution and overconfidence in making decisions, rendering them less trustworthy -- a crucial flaw in the context of medical imaging. In this study, we propose a feature learning approach using Vision Transformers, which use an attention-based mechanism, and examine the representation learning capability of Transformers as a new backbone architecture for medical imaging. Through the task of classifying COVID-19 chest radiographs, we investigate into whether generalization capabilities benefit solely from Vision Transformers' architectural advances. Quantitative and qualitative evaluations are conducted on the trustworthiness of the models, through the use of "trust score" computation and a visual explainability technique. We conclude that the attention-based feature learning approach is promising in building trustworthy deep learning models for healthcare.      
### 5.Adaptive Testing for Connected and Automated Vehicles with Sparse Control Variates in Overtaking Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2207.09259.pdf)
>  Testing and evaluation is a critical step in the development and deployment of connected and automated vehicles (CAVs). Due to the black-box property and various types of CAVs, how to test and evaluate CAVs adaptively remains a major challenge. Many approaches have been proposed to adaptively generate testing scenarios during the testing process. However, most existing approaches cannot be applied to complex scenarios, where the variables needed to define such scenarios are high dimensional. Towards filling this gap, the adaptive testing with sparse control variates method is proposed in this paper. Instead of adaptively generating testing scenarios, our approach evaluates CAVs' performances by adaptively utilizing the testing results. Specifically, each testing result is adjusted using multiple linear regression techniques based on control variates. As the regression coefficients can be adaptively optimized for the CAV under test, using the adjusted results can reduce the estimation variance, compared with using the testing results directly. To overcome the high dimensionality challenge, sparse control variates are utilized only for the critical variables of testing scenarios. To validate the proposed method, the high-dimensional overtaking scenarios are investigated, and the results demonstrate that our approach can further accelerate the evaluation process by about 30 times.      
### 6.Reconfigurable Plug-and-play Distributed Model Predictive Control for Reference Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2207.09233.pdf)
>  A plug-and-play (PnP) algorithm is proposed for varying-topology networks and combined with distributed model predictive control (MPC) so that such networks can track piecewise constant references. The proposed scheme allows various subsystems to occasionally join and leave the network while preserving asymptotic stability and recursive feasibility. This scheme is composed of two main phases which run whenever a PnP request is received. In the redesign phase, passivity-based control is used to guarantee that asymptotic stability of the network is maintained under the MPC scheme. In the transition phase, reconfigurable terminal ingredients are used to ensure that the distributed MPC scheme is initially feasible after the PnP operation. The effectiveness of the proposed scheme is evaluated by applying it to a network of mass-spring-damper systems and comparing it to a benchmark PnP algorithm. It is found that the developed redesign phase results in faster PnP operations. In addition, the developed transition phase adds more flexibility to the PnP operation by accepting more requests.      
### 7.Do uHear? Validation of uHear App for Preliminary Screening of Hearing Ability in Soundscape Studies  [ :arrow_down: ](https://arxiv.org/pdf/2207.09221.pdf)
>  Studies involving soundscape perception often exclude participants with hearing loss to prevent impaired perception from affecting experimental results. Participants are typically screened with pure tone audiometry, the "gold standard" for identifying and quantifying hearing loss at specific frequencies, and excluded if a study-dependent threshold is not met. However, procuring professional audiometric equipment for soundscape studies may be cost-ineffective, and manually performing audiometric tests is labour-intensive. Moreover, testing requirements for soundscape studies may not require sensitivities and specificities as high as that in a medical diagnosis setting. Hence, in this study, we investigate the effectiveness of the uHear app, an iOS application, as an affordable and automatic alternative to a conventional audiometer in screening participants for hearing loss for the purpose of soundscape studies or listening tests in general. Based on audiometric comparisons with the audiometer of 163 participants, the uHear app was found to have high precision (98.04%) when using the World Health Organization (WHO) grading scheme for assessing normal hearing. Precision is further improved (98.69%) when all frequencies assessed with the uHear app is considered in the grading, which lends further support to this cost-effective, automated alternative to screen for normal hearing.      
### 8.Online Computation of Terminal Ingredients in Distributed Model Predictive Control for Reference Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2207.09216.pdf)
>  A distributed model predictive control scheme is developed for tracking piecewise constant references where the terminal set is reconfigured online, whereas the terminal controller is computed offline. Unlike many standard existing schemes, this scheme yields large feasible regions without performing offline centralized computations. Although the resulting optimal control problem (OCP) is a semidefinite program (SDP), an SDP scalability method based on diagonal dominance is used to approximate the derived SDP by a second-order cone program. The OCPs of the proposed scheme and its approximation are amenable to distributed optimization. Both schemes are evaluated using a power network example and compared to a scheme where the terminal controller is reconfigured online as well. It is found that fixing the terminal controller results in better performance, noticeable reduction in computational cost and similar feasible region compared to the case in which this controller is reconfigured online.      
### 9.A Multi-Stage Framework for the 2022 Multi-Structure Segmentation for Renal Cancer Treatment  [ :arrow_down: ](https://arxiv.org/pdf/2207.09165.pdf)
>  Three-dimensional (3D) kidney parsing on computed tomography angiography (CTA) images is of great clinical significance. Automatic segmentation of kidney, renal tumor, renal vein and renal artery benefits a lot on surgery-based renal cancer treatment. In this paper, we propose a new nnhra-unet network, and use a multi-stage framework which is based on it to segment the multi-structure of kidney and participate in the KiPA2022 challenge.      
### 10.GAFX: A General Audio Feature eXtractor  [ :arrow_down: ](https://arxiv.org/pdf/2207.09145.pdf)
>  Most machine learning models for audio tasks are dealing with a handcrafted feature, the spectrogram. However, it is still unknown whether the spectrogram could be replaced with deep learning based features. In this paper, we answer this question by comparing the different learnable neural networks extracting features with a successful spectrogram model and proposed a General Audio Feature eXtractor (GAFX) based on a dual U-Net (GAFX-U), ResNet (GAFX-R), and Attention (GAFX-A) modules. We design experiments to evaluate this model on the music genre classification task on the GTZAN dataset and perform a detailed ablation study of different configurations of our framework and our model GAFX-U, following the Audio Spectrogram Transformer (AST) classifier achieves competitive performance.      
### 11.Using Neural Networks by Modelling Semi-Active Shock Absorber  [ :arrow_down: ](https://arxiv.org/pdf/2207.09141.pdf)
>  A permanently increasing number of on-board automotive control systems requires new approaches to their digital mapping that improves functionality in terms of adaptability and robustness as well as enables their easier on-line software update. As it can be concluded from many recent studies, various methods applying neural networks (NN) can be good candidates for relevant digital twin (DT) tools in automotive control system design, for example, for controller parameterization and condition monitoring. However, the NN-based DT has strong requirements to an adequate amount of data to be used in training and design. In this regard, the paper presents an approach, which demonstrates how the regression tasks can be efficiently handled by the modeling of a semi-active shock absorber within the DT framework. The approach is based on the adaptation of time series augmentation techniques to the stationary data that increases the variance of the latter. Such a solution gives a background to elaborate further data engineering methods for the data preparation of sophisticated databases.      
### 12.Nonlinear Model Predictive Control Framework For Cooperative Three-Agent Target Defense Game  [ :arrow_down: ](https://arxiv.org/pdf/2207.09136.pdf)
>  This paper presents cooperative target defense guidance strategies using nonlinear model predictive control (NMPC) framework for a target-attacker-defender (TAD) game. The TAD game consists of an attacker and a cooperative target-defender pair. The attacker's objective is to capture the target, whereas the target-defender team acts together such that the defender can intercept the attacker and ensure target survival. We assume that the cooperative target-defender pair do not have perfect knowledge of the attacker states, and hence the states are estimated using an Extended Kalman Filter (EKF). The capture analysis based on the Apollonius circles is performed to identify the target survival regions. The efficacy of the NMPC-based solution is evaluated through extensive numerical simulations. The results show that the NMPC-based solution offers robustness to the different unknown attacker models and has better performance than CLOS and A-CLOS based strategies.      
### 13.Towards a Low-SWaP 1024-beam Digital Array: A 32-beam Sub-system at 5.8 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2207.09054.pdf)
>  Millimeter wave communications require multibeam beamforming in order to utilize wireless channels that suffer from obstructions, path loss, and multi-path effects. Digital multibeam beamforming has maximum degrees of freedom compared to analog phased arrays. However, circuit complexity and power consumption are important constraints for digital multibeam systems. A low-complexity digital computing architecture is proposed for a multiplication-free 32-point linear transform that approximates multiple simultaneous RF beams similar to a discrete Fourier transform (DFT). Arithmetic complexity due to multiplication is reduced from the FFT complexity of $\mathcal{O}(N\: \log N)$ for DFT realizations, down to zero, thus yielding a 46% and 55% reduction in chip area and dynamic power consumption, respectively, for the $N=32$ case considered. The paper describes the proposed 32-point DFT approximation targeting a 1024-beams using a 2D array, and shows the multiplierless approximation and its mapping to a 32-beam sub-system consisting of 5.8 GHz antennas that can be used for generating 1024 digital beams without multiplications. Real-time beam computation is achieved using a Xilinx FPGA at 120 MHz bandwidth per beam. Theoretical beam performance is compared with measured RF patterns from both a fixed-point FFT as well as the proposed multiplier-free algorithm and are in good agreement.      
### 14.Discovering novel systemic biomarkers in photos of the external eye  [ :arrow_down: ](https://arxiv.org/pdf/2207.08998.pdf)
>  External eye photos were recently shown to reveal signs of diabetic retinal disease and elevated HbA1c. In this paper, we evaluate if external eye photos contain information about additional systemic medical conditions. We developed a deep learning system (DLS) that takes external eye photos as input and predicts multiple systemic parameters, such as those related to the liver (albumin, AST); kidney (eGFR estimated using the race-free 2021 CKD-EPI creatinine equation, the urine ACR); bone &amp; mineral (calcium); thyroid (TSH); and blood count (Hgb, WBC, platelets). Development leveraged 151,237 images from 49,015 patients with diabetes undergoing diabetic eye screening in 11 sites across Los Angeles county, CA. Evaluation focused on 9 pre-specified systemic parameters and leveraged 3 validation sets (A, B, C) spanning 28,869 patients with and without diabetes undergoing eye screening in 3 independent sites in Los Angeles County, CA, and the greater Atlanta area, GA. We compared against baseline models incorporating available clinicodemographic variables (e.g. age, sex, race/ethnicity, years with diabetes). Relative to the baseline, the DLS achieved statistically significant superior performance at detecting AST&gt;36, calcium&lt;8.6, eGFR&lt;60, Hgb&lt;11, platelets&lt;150, ACR&gt;=300, and WBC&lt;4 on validation set A (a patient population similar to the development sets), where the AUC of DLS exceeded that of the baseline by 5.2-19.4%. On validation sets B and C, with substantial patient population differences compared to the development sets, the DLS outperformed the baseline for ACR&gt;=300 and Hgb&lt;11 by 7.3-13.2%. Our findings provide further evidence that external eye photos contain important biomarkers of systemic health spanning multiple organ systems. Further work is needed to investigate whether and how these biomarkers can be translated into clinical impact.      
### 15.Multi-Source AoI-Constrained Resource Minimization under HARQ: Heterogeneous Sampling Processes  [ :arrow_down: ](https://arxiv.org/pdf/2207.08996.pdf)
>  We consider a multi-source hybrid automatic repeat request (HARQ) based system, where a transmitter sends status update packets of random arrival (i.e., uncontrollable sampling) and generate-atwill (i.e., controllable sampling) sources to a destination through an error-prone channel. We develop transmission scheduling policies to minimize the average number of transmissions subject to an average age of information (AoI) constraint. First, we consider known environment (i.e., known system statistics) and develop a near-optimal deterministic transmission policy and a low-complexity dynamic transmission (LC-DT) policy. The former policy is derived by casting the main problem into a constrained Markov decision process (CMDP) problem, which is then solved using the Lagrangian relaxation, relative value iteration algorithm, and bisection. The LC-DT policy is developed via the drift-plus-penalty (DPP) method by transforming the main problem into a sequence of per-slot problems. Finally, we consider unknown environment and devise a learning-based transmission policy by relaxing the CMDP problem into an MDP problem using the DPP method and then adopting the deep Q-learning algorithm. Numerical results show that the proposed policies achieve near-optimal performance and illustrate the benefits of HARQ in status updating.      
### 16.Superficial White Matter Analysis: An Efficient Point-cloud-based Deep Learning Framework with Supervised Contrastive Learning for Consistent Tractography Parcellation across Populations and dMRI Acquisitions  [ :arrow_down: ](https://arxiv.org/pdf/2207.08975.pdf)
>  Diffusion MRI tractography is an advanced imaging technique that enables in vivo mapping of the brain's white matter connections. White matter parcellation classifies tractography streamlines into clusters or anatomically meaningful tracts. It enables quantification and visualization of whole-brain tractography. Currently, most parcellation methods focus on the deep white matter (DWM), whereas fewer methods address the superficial white matter (SWM) due to its complexity. We propose a novel two-stage deep-learning-based framework, Superficial White Matter Analysis (SupWMA), that performs an efficient and consistent parcellation of 198 SWM clusters from whole-brain tractography. A point-cloud-based network is adapted to our SWM parcellation task, and supervised contrastive learning enables more discriminative representations between plausible streamlines and outliers for SWM. We train our model on a large-scale tractography dataset including streamline samples from labeled SWM clusters and anatomically implausible streamline samples, and we perform testing on six independently acquired datasets of different ages and health conditions (including neonates and patients with space-occupying brain tumors). Compared to several state-of-the-art methods, SupWMA obtains highly consistent and accurate SWM parcellation results on all datasets, showing good generalization across the lifespan in health and disease. In addition, the computational speed of SupWMA is much faster than other methods.      
### 17.Pareto Optimal Strategies for Event Triggered Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2207.08971.pdf)
>  Although resource-limited networked autonomous systems must be able to efficiently and effectively accomplish tasks, better conservation of resources often results in worse task performance. We specifically address the problem of finding strategies for managing measurement communication costs between agents. A well understood technique for trading off communication costs with estimation accuracy is event triggering (ET), where measurements are only communicated when useful, e.g., when Kalman filter innovations exceed some threshold. In the absence of measurements, agents can use implicit information to achieve results almost as well as when explicit data is always communicated. However, there are no methods for setting this threshold with formal guarantees on task performance. We fill this gap by developing a novel belief space discretization technique to abstract a continuous space dynamics model for ET estimation to a discrete Markov decision process, which scalably accommodates threshold-sensitive ET estimator error covariances. We then apply an existing probabilistic trade-off analysis tool to find the set of all optimal trade-offs between resource consumption and task performance. From this set, an ET threshold selection strategy is extracted. Simulated results show our approach identifies non-trivial trade-offs between performance and energy savings, with only modest computational effort.      
### 18.Proposal and Description of a Test System with Wind, Hydro and Fossil Fuel Power Plants for Static Analyses  [ :arrow_down: ](https://arxiv.org/pdf/2207.08897.pdf)
>  This article presents and describes a 229 bus test system that includes wind, hydro and fossil fuel power plants. It represents the Northeast subsystem of the Brazilian Interconnected Power System (BIPS). The test system supplies a load of 4.17 GW, being 13% powered by wind farms, which is the current wind power penetration level of the BIPS. The data comprehends different load levels based on the typical load behavior and typical capacity factors of wind, hydro and fossil fuel plants, as well as the capacity of transmission and sub-transmission lines, transformers, and the adopted structure for the test system. The data is compiled considering models and operating scenarios of the BIPS, and allow performing studies of static voltage stability, sensitivity of voltage stability margin considering the wind farms, and multi-objective optimization considering market constraints. The results of the simulations with the test system indicate the consistency of their data structure and its applicability to different studies of electric power systems.      
### 19.Efficient Ordered-Transmission Based Distributed Detection under Data Falsification Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2207.08870.pdf)
>  In distributed detection systems, energy-efficient ordered transmission (EEOT) schemes are able to reduce the number of transmissions required to make a final decision. In this work, we investigate the effect of data falsification attacks on the performance of EEOT-based systems. We derive the probability of error for an EEOT-based system under attack and find an upper bound (UB) on the expected number of transmissions required to make the final decision. Moreover, we tighten this UB by solving an optimization problem via integer programming (IP). We also obtain the FC's optimal threshold which guarantees the optimal detection performance of the EEOT-based system. Numerical and simulation results indicate that it is possible to reduce transmissions while still ensuring the quality of the decision with an appropriately designed threshold.      
### 20.Human-to-Robot Imitation in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2207.09450.pdf)
>  We approach the problem of learning by watching humans in the wild. While traditional approaches in Imitation and Reinforcement Learning are promising for learning in the real world, they are either sample inefficient or are constrained to lab settings. Meanwhile, there has been a lot of success in processing passive, unstructured human data. We propose tackling this problem via an efficient one-shot robot learning algorithm, centered around learning from a third-person perspective. We call our method WHIRL: In-the-Wild Human Imitating Robot Learning. WHIRL extracts a prior over the intent of the human demonstrator, using it to initialize our agent's policy. We introduce an efficient real-world policy learning scheme that improves using interactions. Our key contributions are a simple sampling-based policy optimization approach, a novel objective function for aligning human and robot videos as well as an exploration method to boost sample efficiency. We show one-shot generalization and success in real-world settings, including 20 different manipulation tasks in the wild. Videos and talk at <a class="link-external link-https" href="https://human2robot.github.io" rel="external noopener nofollow">this https URL</a>      
### 21.Computer Vision to the Rescue: Infant Postural Symmetry Estimation from Incongruent Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2207.09352.pdf)
>  Bilateral postural symmetry plays a key role as a potential risk marker for autism spectrum disorder (ASD) and as a symptom of congenital muscular torticollis (CMT) in infants, but current methods of assessing symmetry require laborious clinical expert assessments. In this paper, we develop a computer vision based infant symmetry assessment system, leveraging 3D human pose estimation for infants. Evaluation and calibration of our system against ground truth assessments is complicated by our findings from a survey of human ratings of angle and symmetry, that such ratings exhibit low inter-rater reliability. To rectify this, we develop a Bayesian estimator of the ground truth derived from a probabilistic graphical model of fallible human raters. We show that the 3D infant pose estimation model can achieve 68% area under the receiver operating characteristic curve performance in predicting the Bayesian aggregate labels, compared to only 61% from a 2D infant pose estimation model and 60% from a 3D adult pose estimation model, highlighting the importance of 3D poses and infant domain knowledge in assessing infant body symmetry. Our survey analysis also suggests that human ratings are susceptible to higher levels of bias and inconsistency, and hence our final 3D pose-based symmetry assessment system is calibrated but not directly supervised by Bayesian aggregate human ratings, yielding higher levels of consistency and lower levels of inter-limb assessment bias.      
### 22.Online Dynamics Learning for Predictive Control with an Application to Aerial Robots  [ :arrow_down: ](https://arxiv.org/pdf/2207.09344.pdf)
>  In this work, we consider the task of improving the accuracy of dynamic models for model predictive control (MPC) in an online setting. Even though prediction models can be learned and applied to model-based controllers, these models are often learned offline. In this offline setting, training data is first collected and a prediction model is learned through an elaborated training procedure. After the model is trained to a desired accuracy, it is then deployed in a model predictive controller. However, since the model is learned offline, it does not adapt to disturbances or model errors observed during deployment. To improve the adaptiveness of the model and the controller, we propose an online dynamics learning framework that continually improves the accuracy of the dynamic model during deployment. We adopt knowledge-based neural ordinary differential equations (KNODE) as the dynamic models, and use techniques inspired by transfer learning to continually improve the model accuracy. We demonstrate the efficacy of our framework with a quadrotor robot, and verify the framework in both simulations and physical experiments. Results show that the proposed approach is able to account for disturbances that are possibly time-varying, while maintaining good trajectory tracking performance.      
### 23.A coherence parameter characterizing generative compressed sensing with Fourier measurements  [ :arrow_down: ](https://arxiv.org/pdf/2207.09340.pdf)
>  In Bora et al. (2017), a mathematical framework was developed for compressed sensing guarantees in the setting where the measurement matrix is Gaussian and the signal structure is the range of a generative neural network (GNN). The problem of compressed sensing with GNNs has since been extensively analyzed when the measurement matrix and/or network weights follow a subgaussian distribution. We move beyond the subgaussian assumption, to measurement matrices that are derived by sampling uniformly at random rows of a unitary matrix (including subsampled Fourier measurements as a special case). Specifically, we prove the first known restricted isometry guarantee for generative compressed sensing with subsampled isometries, and provide recovery bounds with nearly order-optimal sample complexity, addressing an open problem of Scarlett et al. (2022, p. 10). Recovery efficacy is characterized by the coherence, a new parameter, which measures the interplay between the range of the network and the measurement matrix. Our approach relies on subspace counting arguments and ideas central to high-dimensional probability. Furthermore, we propose a regularization strategy for training GNNs to have favourable coherence with the measurement operator. We provide compelling numerical simulations that support this regularized training strategy: our strategy yields low coherence networks that require fewer measurements for signal recovery. This, together with our theoretical results, supports coherence as a natural quantity for characterizing generative compressed sensing with subsampled isometries.      
### 24.Uncertainty in Contrastive Learning: On the Predictability of Downstream Performance  [ :arrow_down: ](https://arxiv.org/pdf/2207.09336.pdf)
>  The superior performance of some of today's state-of-the-art deep learning models is to some extent owed to extensive (self-)supervised contrastive pretraining on large-scale datasets. In contrastive learning, the network is presented with pairs of positive (similar) and negative (dissimilar) datapoints and is trained to find an embedding vector for each datapoint, i.e., a representation, which can be further fine-tuned for various downstream tasks. In order to safely deploy these models in critical decision-making systems, it is crucial to equip them with a measure of their uncertainty or reliability. However, due to the pairwise nature of training a contrastive model, and the lack of absolute labels on the output (an abstract embedding vector), adapting conventional uncertainty estimation techniques to such models is non-trivial. In this work, we study whether the uncertainty of such a representation can be quantified for a single datapoint in a meaningful way. In other words, we explore if the downstream performance on a given datapoint is predictable, directly from its pre-trained embedding. We show that this goal can be achieved by directly estimating the distribution of the training data in the embedding space and accounting for the local consistency of the representations. Our experiments show that this notion of uncertainty for an embedding vector often strongly correlates with its downstream accuracy.      
### 25.Multi-parametric Analysis for Mixed Integer Linear Programming: An Application to Transmission Planning and Congestion Control  [ :arrow_down: ](https://arxiv.org/pdf/2207.09325.pdf)
>  Enhancing existing transmission lines is a useful tool to combat transmission congestion and guarantee transmission security with increasing demand and boosting the renewable energy source. This study concerns the selection of lines whose capacity should be expanded and by how much from the perspective of independent system operator (ISO) to minimize the system cost with the consideration of transmission line constraints and electricity generation and demand balance conditions, and incorporating ramp-up and startup ramp rates, shutdown ramp rates, ramp-down rate limits and minimum up and minimum down times. For that purpose, we develop the ISO unit commitment and economic dispatch model and show it as a right-hand side uncertainty multiple parametric analysis for the mixed integer linear programming (MILP) problem. We first relax the binary variable to continuous variables and employ the Lagrange method and Karush-Kuhn-Tucker conditions to obtain optimal solutions (optimal decision variables and objective function) and critical regions associated with active and inactive constraints. Further, we extend the traditional branch and bound method for the large-scale MILP problem by determining the upper bound of the problem at each node, then comparing the difference between the upper and lower bounds and reaching the approximate optimal solution within the decision makers' tolerated error range. In additional, the objective function's first derivative on the parameters of each line is used to inform the selection of lines to ease congestion and maximize social welfare. Finally, the amount of capacity upgrade will be chosen by balancing the cost-reduction rate of the objective function on parameters and the cost of the line upgrade. Our findings are supported by numerical simulation and provide transmission line planners with decision-making guidance.      
### 26.Content-aware Scalable Deep Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2207.09313.pdf)
>  To more efficiently address image compressed sensing (CS) problems, we present a novel content-aware scalable network dubbed CASNet which collectively achieves adaptive sampling rate allocation, fine granular scalability and high-quality reconstruction. We first adopt a data-driven saliency detector to evaluate the importances of different image regions and propose a saliency-based block ratio aggregation (BRA) strategy for sampling rate allocation. A unified learnable generating matrix is then developed to produce sampling matrix of any CS ratio with an ordered structure. Being equipped with the optimization-inspired recovery subnet guided by saliency information and a multi-block training scheme preventing blocking artifacts, CASNet jointly reconstructs the image blocks sampled at various sampling rates with one single model. To accelerate training convergence and improve network robustness, we propose an SVD-based initialization scheme and a random transformation enhancement (RTE) strategy, which are extensible without introducing extra parameters. All the CASNet components can be combined and learned end-to-end. We further provide a four-stage implementation for evaluation and practical deployments. Experiments demonstrate that CASNet outperforms other CS networks by a large margin, validating the collaboration and mutual supports among its components and strategies. Codes are available at <a class="link-external link-https" href="https://github.com/Guaishou74851/CASNet" rel="external noopener nofollow">this https URL</a>.      
### 27.Quantum Feature Extraction for THz Multi-Layer Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2207.09285.pdf)
>  A learning-based THz multi-layer imaging has been recently used for contactless three-dimensional (3D) positioning and encoding. We show a proof-of-concept demonstration of an emerging quantum machine learning (QML) framework to deal with depth variation, shadow effect, and double-sided content recognition, through an experimental validation.      
### 28.Machine-learning applied to classify flow-induced sound parameters from simulated human voice  [ :arrow_down: ](https://arxiv.org/pdf/2207.09265.pdf)
>  Disorders of voice production have severe effects on the quality of life of the affected individuals. A simulation approach is used to investigate the cause-effect chain in voice production showing typical characteristics of voice such as sub-glottal pressure and of functional voice disorders as glottal closure insufficiency and left-right asymmetry. Therewith, 24 different voice configurations are simulated in a parameter study using a previously published hybrid aeroacoustic simulation model. Based on these 24 simulation configurations, selected acoustic parameters (HNR, CPP, ...) at simulation evaluation points are correlated with these simulation configuration details to derive characteristic insight in the flow-induced sound generation of human phonation based on simulation results. Recently, several institutions studied experimental data, of flow and acoustic properties and correlated it with healthy and disordered voice signals. Upon this, the study is a next step towards a detailed dataset definition, the dataset is small, but the definition of relevant characteristics are precise based on the existing simulation methodology of simVoice. The small datasets are studied by correlation analysis, and a Support Vector Machine classifier with RBF kernel is used to classify the representations. With the use of Linear Discriminant Analysis the dimensions of the individual studies are visualized. This allows to draw correlations and determine the most important features evaluated from the acoustic signals in front of the mouth. The GC type can be best discriminated based on CPP and boxplot visualizations. Furthermore and using the LDA-dimensionality-reduced feature space, one can best classify subglottal pressure with 91.7\% accuracy, independent of healthy or disordered voice simulation parameters.      
### 29.Image Super-Resolution with Deep Dictionary  [ :arrow_down: ](https://arxiv.org/pdf/2207.09228.pdf)
>  Since the first success of Dong et al., the deep-learning-based approach has become dominant in the field of single-image super-resolution. This replaces all the handcrafted image processing steps of traditional sparse-coding-based methods with a deep neural network. In contrast to sparse-coding-based methods, which explicitly create high/low-resolution dictionaries, the dictionaries in deep-learning-based methods are implicitly acquired as a nonlinear combination of multiple convolutions. One disadvantage of deep-learning-based methods is that their performance is degraded for images created differently from the training dataset (out-of-domain images). We propose an end-to-end super-resolution network with a deep dictionary (SRDD), where a high-resolution dictionary is explicitly learned without sacrificing the advantages of deep learning. Extensive experiments show that explicit learning of high-resolution dictionary makes the network more robust for out-of-domain test images while maintaining the performance of the in-domain test images.      
### 30.VoloGAN: Adversarial Domain Adaptation for Synthetic Depth Data  [ :arrow_down: ](https://arxiv.org/pdf/2207.09204.pdf)
>  We present VoloGAN, an adversarial domain adaptation network that translates synthetic RGB-D images of a high-quality 3D model of a person, into RGB-D images that could be generated with a consumer depth sensor. This system is especially useful to generate high amount training data for single-view 3D reconstruction algorithms replicating the real-world capture conditions, being able to imitate the style of different sensor types, for the same high-end 3D model database. The network uses a CycleGAN framework with a U-Net architecture for the generator and a discriminator inspired by SIV-GAN. We use different optimizers and learning rate schedules to train the generator and the discriminator. We further construct a loss function that considers image channels individually and, among other metrics, evaluates the structural similarity. We demonstrate that CycleGANs can be used to apply adversarial domain adaptation of synthetic 3D data to train a volumetric video generator model having only few training samples.      
### 31.Realistic sources, receivers and walls improve the generalisability of virtually-supervised blind acoustic parameter estimators  [ :arrow_down: ](https://arxiv.org/pdf/2207.09133.pdf)
>  Blind acoustic parameter estimation consists in inferring the acoustic properties of an environment from recordings of unknown sound sources. Recent works in this area have utilized deep neural networks trained either partially or exclusively on simulated data, due to the limited availability of real annotated measurements. In this paper, we study whether a model purely trained using a fast image-source room impulse response simulator can generalize to real data. We present an ablation study on carefully crafted simulated training sets that account for different levels of realism in source, receiver and wall responses. The extent of realism is controlled by the sampling of wall absorption coefficients and by applying measured directivity patterns to microphones and sources. A state-of-the-art model trained on these datasets is evaluated on the task of jointly estimating the room's volume, total surface area, and octave-band reverberation times from multiple, multichannel speech recordings. Results reveal that every added layer of simulation realism at train time significantly improves the estimation of all quantities on real signals.      
### 32.Explainable Human-in-the-loop Dynamic Data-Driven Digital Twins  [ :arrow_down: ](https://arxiv.org/pdf/2207.09106.pdf)
>  Digital Twins (DT) are essentially Dynamic Data-driven models that serve as real-time symbiotic "virtual replicas" of real-world systems. DT can leverage fundamentals of Dynamic Data-Driven Applications Systems (DDDAS) bidirectional symbiotic sensing feedback loops for its continuous updates. Sensing loops can consequently steer measurement, analysis and reconfiguration aimed at more accurate modelling and analysis in DT. The reconfiguration decisions can be autonomous or interactive, keeping human-in-the-loop. The trustworthiness of these decisions can be hindered by inadequate explainability of the rationale, and utility gained in implementing the decision for the given situation among alternatives. Additionally, different decision-making algorithms and models have varying complexity, quality and can result in different utility gained for the model. The inadequacy of explainability can limit the extent to which humans can evaluate the decisions, often leading to updates which are unfit for the given situation, erroneous, compromising the overall accuracy of the model. The novel contribution of this paper is an approach to harnessing explainability in human-in-the-loop DDDAS and DT systems, leveraging bidirectional symbiotic sensing feedback. The approach utilises interpretable machine learning and goal modelling to explainability, and considers trade-off analysis of utility gained. We use examples from smart warehousing to demonstrate the approach.      
### 33.Secure Intelligent Reflecting Surface Aided Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2207.09095.pdf)
>  In this paper, an intelligent reflecting surface (IRS) is leveraged to enhance the physical layer security of an integrated sensing and communication (ISAC) system in which the IRS is deployed to not only assist the downlink communication for multiple users, but also create a virtual line-of-sight (LoS) link for target sensing. In particular, we consider a challenging scenario where the target may be a suspicious eavesdropper that potentially intercepts the communication-user information transmitted by the base station (BS). We investigate the joint design of the phase shifts at the IRS and the communication as well as radar beamformers at the BS to maximize the sensing beampattern gain towards the target, subject to the maximum information leakage to the eavesdropping target and the minimum signal-to-interference-plus-noise ratio (SINR) required by users. Based on the availability of perfect channel state information (CSI) of all involved user links and the accurate target location at the BS, two scenarios are considered and two different optimization algorithms are proposed. For the ideal scenario where the CSI of the user links and the target location are perfectly known at the BS, a penalty-based algorithm is proposed to obtain a high-quality solution. In particular, the beamformers are obtained with a semi-closed-form solution using Lagrange duality and the IRS phase shifts are solved for in closed form by applying the majorization-minimization (MM) method. On the other hand, for the more practical scenario where the CSI is imperfect and the target location is uncertain, a robust algorithm based on the $\cal S$-procedure and sign-definiteness approaches is proposed. Simulation results demonstrate the effectiveness of the proposed scheme in achieving a trade-off between the communication quality and the sensing quality.      
### 34.Actor-Critic based Improper Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.09090.pdf)
>  We consider an improper reinforcement learning setting where a learner is given $M$ base controllers for an unknown Markov decision process, and wishes to combine them optimally to produce a potentially new controller that can outperform each of the base ones. This can be useful in tuning across controllers, learnt possibly in mismatched or simulated environments, to obtain a good controller for a given target environment with relatively few trials. <br>Towards this, we propose two algorithms: (1) a Policy Gradient-based approach; and (2) an algorithm that can switch between a simple Actor-Critic (AC) based scheme and a Natural Actor-Critic (NAC) scheme depending on the available information. Both algorithms operate over a class of improper mixtures of the given controllers. For the first case, we derive convergence rate guarantees assuming access to a gradient oracle. For the AC-based approach we provide convergence rate guarantees to a stationary point in the basic AC case and to a global optimum in the NAC case. Numerical results on (i) the standard control theoretic benchmark of stabilizing an cartpole; and (ii) a constrained queueing task show that our improper policy optimization algorithm can stabilize the system even when the base policies at its disposal are unstable.      
### 35.An Intelligent Trust Cloud Management Method for Secure Clustering in 5G enabled Internet of Medical Things  [ :arrow_down: ](https://arxiv.org/pdf/2207.09057.pdf)
>  5G edge computing enabled Internet of Medical Things (IoMT) is an efficient technology to provide decentralized medical services while Device-to-device (D2D) communication is a promising paradigm for future 5G networks. To assure secure and reliable communication in 5G edge computing and D2D enabled IoMT systems, this paper presents an intelligent trust cloud management method. Firstly, an active training mechanism is proposed to construct the standard trust clouds. Secondly, individual trust clouds of the IoMT devices can be established through fuzzy trust inferring and recommending. Thirdly, a trust classification scheme is proposed to determine whether an IoMT device is malicious. Finally, a trust cloud update mechanism is presented to make the proposed trust management method adaptive and intelligent under an open wireless medium. Simulation results demonstrate that the proposed method can effectively address the trust uncertainty issue and improve the detection accuracy of malicious devices.      
### 36.Capabilities, Limitations and Challenges of Style Transfer with CycleGANs: A Study on Automatic Ring Design Generation  [ :arrow_down: ](https://arxiv.org/pdf/2207.08989.pdf)
>  Rendering programs have changed the design process completely as they permit to see how the products will look before they are fabricated. However, the rendering process is complicated and takes a significant amount of time, not only in the rendering itself but in the setting of the scene as well. Materials, lights and cameras need to be set in order to get the best quality results. Nevertheless, the optimal output may not be obtained in the first render. This all makes the rendering process a tedious process. Since Goodfellow et al. introduced Generative Adversarial Networks (GANs) in 2014 [1], they have been used to generate computer-assigned synthetic data, from non-existing human faces to medical data analysis or image style transfer. GANs have been used to transfer image textures from one domain to another. However, paired data from both domains was needed. When Zhu et al. introduced the CycleGAN model, the elimination of this expensive constraint permitted transforming one image from one domain into another, without the need for paired data. This work validates the applicability of CycleGANs on style transfer from an initial sketch to a final render in 2D that represents a 3D design, a step that is paramount in every product design process. We inquiry the possibilities of including CycleGANs as part of the design pipeline, more precisely, applied to the rendering of ring designs. Our contribution entails a crucial part of the process as it allows the customer to see the final product before buying. This work sets a basis for future research, showing the possibilities of GANs in design and establishing a starting point for novel applications to approach crafts design.      
### 37.Layered Cost-Map-Based Traffic Management for Multiple Automated Mobile Robots via a Data Distribution Service  [ :arrow_down: ](https://arxiv.org/pdf/2207.08902.pdf)
>  This letter proposes traffic management for multiple automated mobile robots (AMRs) based on a layered cost map. Multiple AMRs communicate via a data distribution service (DDS), which is shared by topics in the same DDS domain. The cost of each layer is manipulated by topics. The traffic management server in the domain sends or receives topics to each of AMRs. Using the layered cost map, the new concept of prohibition filter, lane filter, fleet layer, and region filter are proposed and implemented. The prohibition filter can help a user set an area that would prohibit an AMR from trespassing. The lane filter can help set one-way directions based on an angle image. The fleet layer can help AMRs share their locations via the traffic management server. The region filter requests for or receives an exclusive area, which can be occupied by only one AMR, from the traffic management server. All the layers are experimentally validated with real-world AMRs. Each area can be configured with user-defined images or text-based parameter files.      
### 38.Learning multi-robot coordination from demonstrations  [ :arrow_down: ](https://arxiv.org/pdf/2207.08892.pdf)
>  This paper develops a Distributed Differentiable Dynamic Game (DDDG) framework, which enables learning multi-robot coordination from demonstrations. We represent multi-robot coordination as a dynamic game, where the behavior of a robot is dictated by its own dynamics and objective that also depends on others' behavior. The coordination thus can be adapted by tuning the objective and dynamics of each robot. The proposed DDDG enables each robot to automatically tune its individual dynamics and objectives in a distributed manner by minimizing the mismatch between its trajectory and demonstrations. This process requires a new distributed design of the forward-pass, where all robots collaboratively seek Nash equilibrium behavior, and a backward-pass, where gradients are propagated via the communication graph. We test the DDDG in simulation with a team of quadrotors given different task configurations. The results demonstrate the capability of DDDG for learning multi-robot coordination from demonstrations      
### 39.Contrastive Environmental Sound Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2207.08825.pdf)
>  Machine hearing of the environmental sound is one of the important issues in the audio recognition domain. It gives the machine the ability to discriminate between the different input sounds that guides its decision making. In this work we exploit the self-supervised contrastive technique and a shallow 1D CNN to extract the distinctive audio features (audio representations) without using any explicit annotations.We generate representations of a given audio using both its raw audio waveform and spectrogram and evaluate if the proposed learner is agnostic to the type of audio input. We further use canonical correlation analysis (CCA) to fuse representations from the two types of input of a given audio and demonstrate that the fused global feature results in robust representation of the audio signal as compared to the individual representations. The evaluation of the proposed technique is done on both ESC-50 and UrbanSound8K. The results show that the proposed technique is able to extract most features of the environmental audio and gives an improvement of 12.8% and 0.9% on the ESC-50 and UrbanSound8K datasets respectively.      
### 40.Audio Input Generates Continuous Frames to Synthesize Facial Video Using Generative Adiversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2207.08813.pdf)
>  This paper presents a simple method for speech videos generation based on audio: given a piece of audio, we can generate a video of the target face speaking this audio. We propose Generative Adversarial Networks (GAN) with cut speech audio input as condition and use Convolutional Gate Recurrent Unit (GRU) in generator and discriminator. Our model is trained by exploiting the short audio and the frames in this duration. For training, we cut the audio and extract the face in the corresponding frames. We designed a simple encoder and compare the generated frames using GAN with and without GRU. We use GRU for temporally coherent frames and the results show that short audio can produce relatively realistic output results.      
