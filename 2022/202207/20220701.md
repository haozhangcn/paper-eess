# ArXiv eess --Fri, 1 Jul 2022
### 1.Asymmetry Disentanglement Network for Interpretable Acute Ischemic Stroke Infarct Segmentation in Non-Contrast CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2206.15445.pdf)
>  Accurate infarct segmentation in non-contrast CT (NCCT) images is a crucial step toward computer-aided acute ischemic stroke (AIS) assessment. In clinical practice, bilateral symmetric comparison of brain hemispheres is usually used to locate pathological abnormalities. Recent research has explored asymmetries to assist with AIS segmentation. However, most previous symmetry-based work mixed different types of asymmetries when evaluating their contribution to AIS. In this paper, we propose a novel Asymmetry Disentanglement Network (ADN) to automatically separate pathological asymmetries and intrinsic anatomical asymmetries in NCCTs for more effective and interpretable AIS segmentation. ADN first performs asymmetry disentanglement based on input NCCTs, which produces different types of 3D asymmetry maps. Then a synthetic, intrinsic-asymmetry-compensated and pathology-asymmetry-salient NCCT volume is generated and later used as input to a segmentation network. The training of ADN incorporates domain knowledge and adopts a tissue-type aware regularization loss function to encourage clinically-meaningful pathological asymmetry extraction. Coupled with an unsupervised 3D transformation network, ADN achieves state-of-the-art AIS segmentation performance on a public NCCT dataset. In addition to the superior performance, we believe the learned clinically-interpretable asymmetry maps can also provide insights towards a better understanding of AIS assessment. Our code is available at <a class="link-external link-https" href="https://github.com/nihaomiao/MICCAI22_ADN" rel="external noopener nofollow">this https URL</a>.      
### 2.Challenges and Opportunities in Multi-device Speech Processing  [ :arrow_down: ](https://arxiv.org/pdf/2206.15432.pdf)
>  We review current solutions and technical challenges for automatic speech recognition, keyword spotting, device arbitration, speech enhancement, and source localization in multidevice home environments to provide context for the INTERSPEECH 2022 special session, "Challenges and opportunities for signal processing and machine learning for multiple smart devices". We also identify the datasets needed to support these research areas. Based on the review and our research experience in the multi-device domain, we conclude with an outlook on the future evolution      
### 3.Ensemble CNN models for Covid-19 Recognition and Severity Perdition From 3D CT-scan  [ :arrow_down: ](https://arxiv.org/pdf/2206.15431.pdf)
>  Since the appearance of Covid-19 in late 2019, Covid-19 has become an active research topic for the artificial intelligence (AI) community. One of the most interesting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging is the most informative tool about this disease. This work is part of the 2nd COV19D competition, where two challenges are set: Covid-19 Detection and Covid-19 Severity Detection from the CT-scans. For Covid-19 detection from CT-scans, we proposed an ensemble of 2D Convolution blocks with Densenet-161 models. Here, each 2D convolutional block with Densenet-161 architecture is trained separately and in testing phase, the ensemble model is based on the average of their probabilities. On the other hand, we proposed an ensemble of Convolutional Layers with Inception models for Covid-19 severity detection. In addition to the Convolutional Layers, three Inception variants were used, namely Inception-v3, Inception-v4 and Inception-Resnet. Our proposed approaches outperformed the baseline approach in the validation data of the 2nd COV19D competition by 11% and 16% for Covid-19 detection and Covid-19 severity detection, respectively.      
### 4.Few-Shot Cross-Lingual TTS Using Transferable Phoneme Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2206.15427.pdf)
>  This paper studies a transferable phoneme embedding framework that aims to deal with the cross-lingual text-to-speech (TTS) problem under the few-shot setting. Transfer learning is a common approach when it comes to few-shot learning since training from scratch on few-shot training data is bound to overfit. Still, we find that the naive transfer learning approach fails to adapt to unseen languages under extremely few-shot settings, where less than 8 minutes of data is provided. We deal with the problem by proposing a framework that consists of a phoneme-based TTS model and a codebook module to project phonemes from different languages into a learned latent space. Furthermore, by utilizing phoneme-level averaged self-supervised learned features, we effectively improve the quality of synthesized speeches. Experiments show that using 4 utterances, which is about 30 seconds of data, is enough to synthesize intelligible speech when adapting to an unseen language using our framework.      
### 5.Sub-8-Bit Quantization Aware Training for 8-Bit Neural Network Accelerator with On-Device Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.15408.pdf)
>  We present a novel sub-8-bit quantization-aware training (S8BQAT) scheme for 8-bit neural network accelerators. Our method is inspired from Lloyd-Max compression theory with practical adaptations for a feasible computational overhead during training. With the quantization centroids derived from a 32-bit baseline, we augment training loss with a Multi-Regional Absolute Cosine (MRACos) regularizer that aggregates weights towards their nearest centroid, effectively acting as a pseudo compressor. Additionally, a periodically invoked hard compressor is introduced to improve the convergence rate by emulating runtime model weight quantization. We apply S8BQAT on speech recognition tasks using Recurrent Neural NetworkTransducer (RNN-T) architecture. With S8BQAT, we are able to increase the model parameter size to reduce the word error rate by 4-16% relatively, while still improving latency by 5%.      
### 6.Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2206.15400.pdf)
>  In this paper, we propose a novel end-to-end user-defined keyword spotting method that utilizes linguistically corresponding patterns between speech and text sequences. Unlike previous approaches requiring speech keyword enrollment, our method compares input queries with an enrolled text keyword sequence. To place the audio and text representations within a common latent space, we adopt an attention-based cross-modal matching approach that is trained in an end-to-end manner with monotonic matching loss and keyword classification loss. We also utilize a de-noising loss for the acoustic embedding network to improve robustness in noisy environments. Additionally, we introduce the LibriPhrase dataset, a new short-phrase dataset based on LibriSpeech for efficiently training keyword spotting models. Our proposed method achieves competitive results on various evaluation sets compared to other single-modal and cross-modal baselines.      
### 7.Acoustic Room Compensation Using Local PCA-based Room Average PSD Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2206.15356.pdf)
>  Acoustic room compensation techniques, which allow a sound reproduction system to counteract undesired alteration to the sound scene due to excessive room resonances, have been widely studied. Extensive efforts have been reported to enlarge the region over which room equalization is effective and to contrast variations of room transfer functions in space. A speaker-tuning technology "Trueplay" allows users to compensate for undesired room effects over an extended listening area based on a spatially averaged power spectral density (PSD) of the room, which is conventionally measured using microphones on portable devices when users move around the room. In this work, we propose a novel system that leverages the measurement of the speaker echo path self-response to predict the room average PSD using a local PCA based approach. Experimental results confirm the effectiveness of the proposed estimation method, which further leads to a room compensation filter design that achieves a good sound similarity compared to the reference system with the ground-truth room average PSD while outperforming other systems that do not leverage the proposed estimator.      
### 8.Solar Power Smoothing in a Nanogrid Testbed  [ :arrow_down: ](https://arxiv.org/pdf/2206.15323.pdf)
>  High penetration of solar power introduces new challenges in the operation of distribution systems. Considering the highly volatile nature of solar power output due to changes in cloud coverage, maintaining the power balance and operating within ramp rate limits can be an issue. Great benefits can be brought to the grid by smoothing solar power output at individual sites equipped with flexible resources such as electrical vehicles and battery storage systems. This paper proposes several approaches to a solar smoothing application by utilizing battery storage and EV charging control in a "Nanogrid" testbed located at a utility in Florida. The control algorithms focus on both real-time application and predictive control depending on forecasts. The solar smoothing models are then compared using real data from the Nanogrid site to present the effectiveness of the proposed models and compare their results. Furthermore, the control methods are applied to the Orlando Utilities Commission (OUC) Nanogrid to confirm the simulation results.      
### 9.Performance Analysis of Optimized Versatile Video Coding Software Decoders on Embedded Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2206.15311.pdf)
>  In recent years, the global demand for high-resolution videos and the emergence of new multimedia applications have created the need for a new video coding standard. Hence, in July 2020 the Versatile Video Coding (VVC) standard was released providing up to 50% bit-rate saving for the same video quality compared to its predecessor High Efficiency Video Coding (HEVC). However, this bit-rate saving comes at the cost of a high computational complexity, particularly for live applications and on resource-constraint embedded devices. This paper presents two optimized VVC software decoders, named OpenVVC and Versatile Video deCoder (VVdeC), designed for low resources platforms. They exploit optimization techniques such as data level parallelism using Single Instruction Multiple Data (SIMD) instructions and functional level parallelism using frame, tile and slice-based parallelisms. Furthermore, a comparison in terms of decoding run time, energy and memory consumption between the two decoders is presented while targeting two different resource-constraint embedded devices. The results showed that both decoders achieve real-time decoding of Full High definition (FHD) resolution over the first platform using 8 cores and High-definition (HD) real-time decoding for the second platform using only 4 cores with comparable results in terms of average consumed energy: around 26 J and 15 J for the 8 cores and 4 cores embedded platforms, respectively. Regarding the memory usage, OpenVVC showed better results with less average maximum memory consumed during run time compared to VVdeC.      
### 10.Exposing and addressing the fragility of neural networks in digital pathology  [ :arrow_down: ](https://arxiv.org/pdf/2206.15274.pdf)
>  Neural networks have achieved impressive results in many medical imaging tasks but often perform substantially worse on out-of-distribution datasets originating from different medical centres or patient cohorts. Evaluating this lack of ability to generalise and address the underlying problem are the two main challenges in developing neural networks intended for clinical practice. <br>In this study, we develop a new method for evaluating neural network models' ability to generalise by generating a large number of distribution-shifted datasets, which can be used to thoroughly investigate their robustness to variability encountered in clinical practice. Compared to external validation, \textit{shifted evaluation} can provide explanations for why neural networks fail on a given dataset, thus offering guidance on how to improve model robustness. With shifted evaluation, we demonstrate that neural networks, trained with state-of-the-art methods, are highly fragile to even small distribution shifts from training data, and in some cases lose all discrimination ability. <br>To address this fragility, we develop an augmentation strategy, explicitly designed to increase neural networks' robustness to distribution shifts. \texttt{StrongAugment} is evaluated with large-scale, heterogeneous histopathology data including five training datasets from two tissue types, 274 distribution-shifted datasets and 20 external datasets from four countries. Neural networks trained with \texttt{StrongAugment} retain similar performance on all datasets, even with distribution shifts where networks trained with current state-of-the-art methods lose all discrimination ability. We recommend using strong augmentation and shifted evaluation to train and evaluate all neural networks intended for clinical practice.      
### 11.Localizing the Recurrent Laryngeal Nerve via Ultrasound with a Bayesian Shape Framework  [ :arrow_down: ](https://arxiv.org/pdf/2206.15254.pdf)
>  Tumor infiltration of the recurrent laryngeal nerve (RLN) is a contraindication for robotic thyroidectomy and can be difficult to detect via standard laryngoscopy. Ultrasound (US) is a viable alternative for RLN detection due to its safety and ability to provide real-time feedback. However, the tininess of the RLN, with a diameter typically less than 3mm, poses significant challenges to the accurate localization of the RLN. In this work, we propose a knowledge-driven framework for RLN localization, mimicking the standard approach surgeons take to identify the RLN according to its surrounding organs. We construct a prior anatomical model based on the inherent relative spatial relationships between organs. Through Bayesian shape alignment (BSA), we obtain the candidate coordinates of the center of a region of interest (ROI) that encloses the RLN. The ROI allows a decreased field of view for determining the refined centroid of the RLN using a dual-path identification network, based on multi-scale semantic information. Experimental results indicate that the proposed method achieves superior hit rates and substantially smaller distance errors compared with state-of-the-art methods.      
### 12.Implicit U-Net for volumetric medical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.15217.pdf)
>  U-Net has been the go-to architecture for medical image segmentation tasks, however computational challenges arise when extending the U-Net architecture to 3D images. We propose the Implicit U-Net architecture that adapts the efficient Implicit Representation paradigm to supervised image segmentation tasks. By combining a convolutional feature extractor with an implicit localization network, our implicit U-Net has 40% less parameters than the equivalent U-Net. Moreover, we propose training and inference procedures to capitalize sparse predictions. When comparing to an equivalent fully convolutional U-Net, Implicit U-Net reduces by approximately 30% inference and training time as well as training memory footprint while achieving comparable results in our experiments with two different abdominal CT scan datasets.      
### 13.The (de)biasing effect of GAN-based augmentation methods on skin lesion images  [ :arrow_down: ](https://arxiv.org/pdf/2206.15182.pdf)
>  New medical datasets are now more open to the public, allowing for better and more extensive research. Although prepared with the utmost care, new datasets might still be a source of spurious correlations that affect the learning process. Moreover, data collections are usually not large enough and are often unbalanced. One approach to alleviate the data imbalance is using data augmentation with Generative Adversarial Networks (GANs) to extend the dataset with high-quality images. GANs are usually trained on the same biased datasets as the target data, resulting in more biased instances. This work explored unconditional and conditional GANs to compare their bias inheritance and how the synthetic data influenced the models. We provided extensive manual data annotation of possibly biasing artifacts on the well-known ISIC dataset with skin lesions. In addition, we examined classification models trained on both real and synthetic data with counterfactual bias explanations. Our experiments showed that GANs inherited biases and sometimes even amplified them, leading to even stronger spurious correlations. Manual data annotation and synthetic images are publicly available for reproducible scientific research.      
### 14.A Medical Image Fusion Method based on MDLatLRRv2  [ :arrow_down: ](https://arxiv.org/pdf/2206.15179.pdf)
>  Since MDLatLRR only considers detailed parts (salient features) of input images extracted by latent low-rank representation (LatLRR), it doesn't use base parts (principal features) extracted by LatLRR effectively. Therefore, we proposed an improved multi-level decomposition method called MDLatLRRv2 which effectively analyzes and utilizes all the image features obtained by LatLRR. Then we apply MDLatLRRv2 to medical image fusion. The base parts are fused by average strategy and the detail parts are fused by nuclear-norm operation. The comparison with the existing methods demonstrates that the proposed method can achieve state-of-the-art fusion performance in objective and subjective assessment.      
### 15.InsMix: Towards Realistic Generative Data Augmentation for Nuclei Instance Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2206.15134.pdf)
>  Nuclei Segmentation from histology images is a fundamental task in digital pathology analysis. However, deep-learning-based nuclei segmentation methods often suffer from limited annotations. This paper proposes a realistic data augmentation method for nuclei segmentation, named InsMix, that follows a Copy-Paste-Smooth principle and performs morphology-constrained generative instance augmentation. Specifically, we propose morphology constraints that enable the augmented images to acquire luxuriant information about nuclei while maintaining their morphology characteristics (e.g., geometry and location). To fully exploit the pixel redundancy of the background and improve the model's robustness, we further propose a background perturbation method, which randomly shuffles the background patches without disordering the original nuclei distribution. To achieve contextual consistency between original and template instances, a smooth-GAN is designed with a foreground similarity encoder (FSE) and a triplet loss. We validated the proposed method on two datasets, i.e., Kumar and CPS datasets. Experimental results demonstrate the effectiveness of each component and the superior performance achieved by our method to the state-of-the-art methods.      
### 16.Model-based vs Data-driven Estimation of Vehicle Sideslip Angle and Benefits of Tyre Force Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2206.15119.pdf)
>  This paper provides a comprehensive comparison of model-based and data-driven approaches and analyses the benefits of using measured tyre forces for vehicle sideslip angle estimation. The model-based approaches are based on an extended Kalman filter and an unscented Kalman filter, in which the measured tyre forces are utilised in the observation model. An adaptive covariance matrix is introduced to minimise the tyre model mismatch during evasive manoeuvres. For data-driven approaches, feed forward and recurrent neural networks are evaluated. Both approaches use the standard inertial measurement unit and the tyre force measurements as inputs. Using the large-scale experimental dataset of 216 manoeuvres, we demonstrate a significant improvement in accuracy using data-driven vs. model-based approaches. Tyre force measurements improve the performance of both model-based and data-driven approaches, especially in the non-linear regime of tyres.      
### 17.A Two-Stage Bayesian Optimisation for Automatic Tuning of an Unscented Kalman Filter for Vehicle Sideslip Angle Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2206.15115.pdf)
>  This paper presents a novel methodology to auto-tune an Unscented Kalman Filter (UKF). It involves using a Two-Stage Bayesian Optimisation (TSBO), based on a t-Student Process to optimise the process noise parameters of a UKF for vehicle sideslip angle estimation. Our method minimises performance metrics, given by the average sum of the states' and measurement' estimation error for various vehicle manoeuvres covering a wide range of vehicle behaviour. The predefined cost function is minimised through a TSBO which aims to find a location in the feasible region that maximises the probability of improving the current best solution. Results on an experimental dataset show the capability to tune the UKF in 79.9% less time than using a genetic algorithm (GA) and the overall capacity to improve the estimation performance in an experimental test dataset of 9.9% to the current state-of-the-art GA.      
### 18.A perspective on Attitude Control Issues and Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2206.15077.pdf)
>  This paper reviews the attitude control problems for rigid-body systems, starting from the attitude representation for rigid body kinematics. Highly redundant rotation matrix defines the attitude orientation globally and uniquely by 9 parameters, which is the most fundamental one, without any singularities; minimum 3-parameter Euler angles or (modified) Rodrigues parameters define the attitude orientation neither globally nor uniquely, but the former exhibits kinematical singularity and Gimbal lock, while the latter two exhibit geometrical singularity; once-redundant axis-angle or unit quaternion globally define the attitude rotation but not uniquely using 4 parameters, but the former is not appropriate to define very small or very large rotations, while the latter shows unwinding phenomenon despite of the reduced computation burden. In addition, we explore the relationships among those attitude representations, including the connections among Gimbal lock, unwinding phenomenon and a nowhere dense set of zero Lebesgue measure. Based on attitude representations, we analyze different attitude control laws, almost global control and global attitude control, nominal and general robustness, as well as the technique tools.      
### 19.Custom Pretrainings and Adapted 3D-ConvNeXt Architecture for COVID Detection and Severity Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.15073.pdf)
>  Since COVID strongly affects the respiratory system, lung CT scans can be used for the analysis of a patients health. We introduce an neural network for the prediction of the severity of lung damage and the detection of infection using three-dimensional CT-scans. Therefore, we adapt the recent ConvNeXt model to process three-dimensional data. Furthermore, we introduce different pretraining methods specifically adjusted to improve the models ability to handle three-dimensional CT-data. In order to test the performance of our model, we participate in the 2nd COV19D Competition for severity prediction and infection detection.      
### 20.PVT-COV19D: Pyramid Vision Transformer for COVID-19 Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2206.15069.pdf)
>  With the outbreak of COVID-19, a large number of relevant studies have emerged in recent years. We propose an automatic COVID-19 diagnosis framework based on lung CT scan images, the PVT-COV19D. In order to accommodate the different dimensions of the image input, we first classified the images using Transformer models, then sampled the images in the dataset according to normal distribution, and fed the sampling results into the modified PVTv2 model for training. A large number of experiments on the COV19-CT-DB dataset demonstrate the effectiveness of the proposed method.      
### 21.Data-and-Knowledge Dual-Driven Automatic Modulation Recognition for Wireless Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2206.15035.pdf)
>  Automatic modulation classification is of crucial importance in wireless communication networks. Deep learning based automatic modulation classification schemes have attracted extensive attention due to the superior accuracy. However, the data-driven method relies on a large amount of training samples and the classification accuracy is poor in the low signal-to-noise radio (SNR). In order to tackle these problems, a novel data-and-knowledge dual-driven automatic modulation classification scheme based on radio frequency machine learning is proposed by exploiting the attribute features of different modulations. The visual model is utilized to extract visual features. The attribute learning model is used to learn the attribute semantic representations. The transformation model is proposed to convert the attribute representation into the visual space. Extensive simulation results demonstrate that our proposed automatic modulation classification scheme can achieve better performance than the benchmark schemes in terms of the classification accuracy, especially in the low SNR. Moreover, the confusion among high-order modulations is reduced by using our proposed scheme compared with other traditional schemes.      
### 22.The Edge of Disaster: A Battle Between Autonomous Racing and Safety  [ :arrow_down: ](https://arxiv.org/pdf/2206.15012.pdf)
>  Where agents must act while on the limits of a vehicle's capability in order to set competitive lap times. This places the agent on a knife's edge, with a very small margin between success and loss of control. Pushing towards this limit leads to a practical tension: we want agents to explore the limitations of vehicle control to maximise speed, but inadvertently going past that limit and losing control can cause irreparable damage to the vehicle itself. We provide a model predictive control (MPC) baseline that is able to, in a single lap, safely adapt to an unseen racetrack and achieve competitive lap times. Our approaches efficacy is demonstrated in simulation using the Learn To Race Challenge's environment and metrics.      
### 23.TTS-by-TTS 2: Data-selective augmentation for neural speech synthesis using ranking support vector machine with variational autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2206.14984.pdf)
>  Recent advances in synthetic speech quality have enabled us to train text-to-speech (TTS) systems by using synthetic corpora. However, merely increasing the amount of synthetic data is not always advantageous for improving training efficiency. Our aim in this study is to selectively choose synthetic data that are beneficial to the training process. In the proposed method, we first adopt a variational autoencoder whose posterior distribution is utilized to extract latent features representing acoustic similarity between the recorded and synthetic corpora. By using those learned features, we then train a ranking support vector machine (RankSVM) that is well known for effectively ranking relative attributes among binary classes. By setting the recorded and synthetic ones as two opposite classes, RankSVM is used to determine how the synthesized speech is acoustically similar to the recorded data. Then, synthetic TTS data, whose distribution is close to the recorded data, are selected from large-scale synthetic corpora. By using these data for retraining the TTS model, the synthetic quality can be significantly improved. Objective and subjective evaluation results show the superiority of the proposed method over the conventional methods.      
### 24.A Dynamic Subarray Structure in Reconfigurable Intelligent Surfaces for TeraHertz Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.14968.pdf)
>  Reconfigurable Intelligent Surface (RIS) has become a popular technology to improve the capability of a THz multiuser Multi-input multi-output (MIMO) communication system. THz wave characteristics, on the other hand, restrict THz beam coverage on RIS when using a uniform planar array (UPA) antenna. In this study, we propose a dynamic RIS subarray structure to improve the performance of a THz MIMO communication system. In more details, an RIS is divided into several RIS subarrays according to the number of users. Each RIS subarray is paired with a user and only reflects beams to the corresponding user. Based on the structure of RIS, we first propose a weighted minimum mean square error - RIS local search (WMMSE-LS) scheme, which requires that each RIS element has limited phase shifts. To improve the joint beamforming performance, we further develop an adaptive Block Coordinate Descent(BCD)-aided algorithm, an iterative optimization method. Numerical results demonstrate the effectiveness of the dynamic RIS subarray structure and the adaptive BCD-aided joint beamforming scheme and also show the merit of our proposed system.      
### 25.Improving Visual Speech Enhancement Network by Learning Audio-visual Affinity with Multi-head Attention  [ :arrow_down: ](https://arxiv.org/pdf/2206.14964.pdf)
>  Audio-visual speech enhancement system is regarded as one of promising solutions for isolating and enhancing speech of desired speaker. Typical methods focus on predicting clean speech spectrum via a naive convolution neural network based encoder-decoder architecture, and these methods a) are not adequate to use data fully, b) are unable to effectively balance audio-visual features. The proposed model alleviates these drawbacks by a) applying a model that fuses audio and visual features layer by layer in encoding phase, and that feeds fused audio-visual features to each corresponding decoder layer, and more importantly, b) introducing a 2-stage multi-head cross attention (MHCA) mechanism to infer audio-visual speech enhancement for balancing the fused audio-visual features and eliminating irrelevant features. This paper proposes attentional audio-visual multi-layer feature fusion model, in which MHCA units are applied to feature mapping at every layer of decoder. The proposed model demonstrates the superior performance of the network against the state-of-the-art models.      
### 26.GLD-Net: Improving Monaural Speech Enhancement by Learning Global and Local Dependency Features with GLD Block  [ :arrow_down: ](https://arxiv.org/pdf/2206.14962.pdf)
>  For monaural speech enhancement, contextual information is important for accurate speech estimation. However, commonly used convolution neural networks (CNNs) are weak in capturing temporal contexts since they only build blocks that process one local neighborhood at a time. To address this problem, we learn from human auditory perception to introduce a two-stage trainable reasoning mechanism, referred as global-local dependency (GLD) block. GLD blocks capture long-term dependency of time-frequency bins both in global level and local level from the noisy spectrogram to help detecting correlations among speech part, noise part, and whole noisy input. What is more, we conduct a monaural speech enhancement network called GLD-Net, which adopts encoder-decoder architecture and consists of speech object branch, interference branch, and global noisy branch. The extracted speech feature at global-level and local-level are efficiently reasoned and aggregated in each of the branches. We compare the proposed GLD-Net with existing state-of-art methods on WSJ0 and DEMAND dataset. The results show that GLD-Net outperforms the state-of-the-art methods in terms of PESQ and STOI.      
### 27.CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for Colonoscopy  [ :arrow_down: ](https://arxiv.org/pdf/2206.14951.pdf)
>  Automated analysis of optical colonoscopy (OC) video frames (to assist endoscopists during OC) is challenging due to variations in color, lighting, texture, and specular reflections. Previous methods either remove some of these variations via preprocessing (making pipelines cumbersome) or add diverse training data with annotations (but expensive and time-consuming). We present CLTS-GAN, a new deep learning model that gives fine control over color, lighting, texture, and specular reflection synthesis for OC video frames. We show that adding these colonoscopy-specific augmentations to the training data can improve state-of-the-art polyp detection/segmentation methods as well as drive next generation of OC simulators for training medical students. The code and pre-trained models for CLTS-GAN are available on Computational Endoscopy Platform GitHub (<a class="link-external link-https" href="https://github.com/nadeemlab/CEP" rel="external noopener nofollow">this https URL</a>).      
### 28.Paving the Way Towards Mobile IAB: Problems, Solutions and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2206.14946.pdf)
>  Deploying access and backhaul as wireless links, a.k.a. integrated access and backhaul (IAB), is envisioned as a viable approach to enable flexible and dense networks. Even further, mobile IAB (mIAB) is a candidate solution to enhance the connectivity of user equipments (UEs) moving together. In this context, different of other works from the literature, the present work overviews the basis for the deployment of mIAB by presenting: 1) the current status of IAB standardization in the fifth generation (5G) new radio (NR); 2) a new taxonomy for state-of-the-art works regarding fixed IAB and mIAB; 3) an extensive performance analysis of mIAB based on simulation results; and 4) open challenges and potential future prospects of mIAB. Specifically, the proposed taxonomy classifies IAB works according to different perspectives and categorizes mIAB works according to the type of mobility. For each type of mobility, the main studied topics are presented. Regarding the performance evaluation, we consider an urban macro scenario where mIAB nodes are deployed in buses in order to improve the passengers connection. The results show that, compared to other network architectures, the deployment of mIAB nodes remarkably improves the passengers throughput and latency in both downlink and uplink.      
### 29.Physics-Inspired Unsupervised Classification for Region of Interest in X-Ray Ptychography  [ :arrow_down: ](https://arxiv.org/pdf/2206.14940.pdf)
>  X-ray ptychography allows for large fields to be imaged at high resolution at the cost of additional computational expense due to the large volume of data. Given limited information regarding the object, the acquired data often has an excessive amount of information that is outside the region of interest (RoI). In this work we propose a physics-inspired unsupervised learning algorithm to identify the RoI of an object using only diffraction patterns from a ptychography dataset before committing computational resources to reconstruction. Obtained diffraction patterns that are automatically identified as not within the RoI are filtered out, allowing efficient reconstruction by focusing only on important data within the RoI while preserving image quality.      
### 30.Identifying and Combating Bias in Segmentation Networks by leveraging multiple resolutions  [ :arrow_down: ](https://arxiv.org/pdf/2206.14919.pdf)
>  Exploration of bias has significant impact on the transparency and applicability of deep learning pipelines in medical settings, yet is so far woefully understudied. In this paper, we consider two separate groups for which training data is only available at differing image resolutions. For group H, available images and labels are at the preferred high resolution while for group L only deprecated lower resolution data exist. We analyse how this resolution-bias in the data distribution propagates to systematically biased predictions for group L at higher resolutions. Our results demonstrate that single-resolution training settings result in significant loss of volumetric group differences that translate to erroneous segmentations as measured by DSC and subsequent classification failures on the low resolution group. We further explore how training data across resolutions can be used to combat this systematic bias. Specifically, we investigate the effect of image resampling, scale augmentation and resolution independence and demonstrate that biases can effectively be reduced with multi-resolution approaches.      
### 31.CIRDataset: A large-scale Dataset for Clinically-Interpretable lung nodule Radiomics and malignancy prediction  [ :arrow_down: ](https://arxiv.org/pdf/2206.14903.pdf)
>  Spiculations/lobulations, sharp/curved spikes on the surface of lung nodules, are good predictors of lung cancer malignancy and hence, are routinely assessed and reported by radiologists as part of the standardized Lung-RADS clinical scoring criteria. Given the 3D geometry of the nodule and 2D slice-by-slice assessment by radiologists, manual spiculation/lobulation annotation is a tedious task and thus no public datasets exist to date for probing the importance of these clinically-reported features in the SOTA malignancy prediction algorithms. As part of this paper, we release a large-scale Clinically-Interpretable Radiomics Dataset, CIRDataset, containing 956 radiologist QA/QC'ed spiculation/lobulation annotations on segmented lung nodules from two public datasets, LIDC-IDRI (N=883) and LUNGx (N=73). We also present an end-to-end deep learning model based on multi-class Voxel2Mesh extension to segment nodules (while preserving spikes), classify spikes (sharp/spiculation and curved/lobulation), and perform malignancy prediction. Previous methods have performed malignancy prediction for LIDC and LUNGx datasets but without robust attribution to any clinically reported/actionable features (due to known hyperparameter sensitivity issues with general attribution schemes). With the release of this comprehensively-annotated CIRDataset and end-to-end deep learning baseline, we hope that malignancy prediction methods can validate their explanations, benchmark against our baseline, and provide clinically-actionable insights. Dataset, code, pretrained models, and docker containers are available at <a class="link-external link-https" href="https://github.com/nadeemlab/CIR" rel="external noopener nofollow">this https URL</a>.      
### 32.iEmoTTS: Toward Robust Cross-Speaker Emotion Transfer and Control for Speech Synthesis based on Disentanglement between Prosody and Timbre  [ :arrow_down: ](https://arxiv.org/pdf/2206.14866.pdf)
>  The capability of generating speech with specific type of emotion is desired for many applications of human-computer interaction. Cross-speaker emotion transfer is a common approach to generating emotional speech when speech with emotion labels from target speakers is not available for model training. This paper presents a novel cross-speaker emotion transfer system, named iEmoTTS. The system is composed of an emotion encoder, a prosody predictor, and a timbre encoder. The emotion encoder extracts the identity of emotion type as well as the respective emotion intensity from the mel-spectrogram of input speech. The emotion intensity is measured by the posterior probability that the input utterance carries that emotion. The prosody predictor is used to provide prosodic features for emotion transfer. The timber encoder provides timbre-related information for the system. Unlike many other studies which focus on disentangling speaker and style factors of speech, the iEmoTTS is designed to achieve cross-speaker emotion transfer via disentanglement between prosody and timbre. Prosody is considered as the main carrier of emotion-related speech characteristics and timbre accounts for the essential characteristics for speaker identification. Zero-shot emotion transfer, meaning that speech of target speakers are not seen in model training, is also realized with iEmoTTS. Extensive experiments of subjective evaluation have been carried out. The results demonstrate the effectiveness of iEmoTTS as compared with other recently proposed systems of cross-speaker emotion transfer. It is shown that iEmoTTS can produce speech with designated emotion type and controllable emotion intensity. With appropriate information bottleneck capacity, iEmoTTS is able to effectively transfer emotion information to a new speaker. Audio samples are publicly available\footnote{<a class="link-external link-https" href="https://patrick-g-zhang.github.io/iemotts/" rel="external noopener nofollow">this https URL</a>}.      
### 33.Two-Stage COVID19 Classification Using BERT Features  [ :arrow_down: ](https://arxiv.org/pdf/2206.14861.pdf)
>  We propose an automatic COVID1-19 diagnosis framework from lung CT-scan slice images using double BERT feature extraction. In the first BERT feature extraction, A 3D-CNN is first used to extract CNN internal feature maps. Instead of using the global average pooling, a late BERT temporal pooing is used to aggregate the temporal information in these feature maps, followed by a classification layer. This 3D-CNN-BERT classification network is first trained on sampled fixed number of slice images from every original CT scan volume. In the second stage, the 3D-CNN-BERT embedding features are extracted on all slice images of every CT scan volume, and these features are averaged into a fixed number of segments. Then another BERT network is used to aggregate these multiple features into a single feature followed by another classification layer. The classification results of both stages are combined to generate final outputs. On the validation dataset, we achieve macro F1 score of 0.9164.      
### 34.Deep Reinforcement Learning for Small Bowel Path Tracking using Different Types of Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2206.14847.pdf)
>  Small bowel path tracking is a challenging problem considering its many folds and contact along its course. For the same reason, it is very costly to achieve the ground-truth (GT) path of the small bowel in 3D. In this work, we propose to train a deep reinforcement learning tracker using datasets with different types of annotations. Specifically, we utilize CT scans that have only GT small bowel segmentation as well as ones with the GT path. It is enabled by designing a unique environment that is compatible for both, including a reward definable even without the GT path. The performed experiments proved the validity of the proposed method. The proposed method holds a high degree of usability in this problem by being able to utilize the scans with weak annotations, and thus by possibly reducing the required annotation cost.      
### 35.Volume-Independent Music Matching by Frequency Spectrum Comparison  [ :arrow_down: ](https://arxiv.org/pdf/2206.15426.pdf)
>  Often, I hear a piece of music and wonder what the name of the piece is. Indeed, there are applications such as Shazam app that provides music matching. However, the limitations of those apps are that the same piece performed by the same musician cannot be identified if it is not the same recording. Shazam identifies the recording of it, not the music. This is because Shazam matches the variation in volume, not the frequencies of the sound. This research attempts to match music the way humans understand it: by the frequency spectrum of music, not the volume variation. Essentially, the idea is to precompute the frequency spectrums of all the music in the database, then take the unknown piece and try to match its frequency spectrum against every segment of every music in the database. I did it by matching the frequency spectrum of the unknown piece to our database by sliding the window by 0.1 seconds and calculating the error by taking Absolute value, normalizing the audio, subtracting the normalized arrays, and taking the sum of absolute differences. The segment that shows the least error is considered the candidate for the match. The matching performance proved to be dependent on the complexity of the music. Matching simple music, such as single note pieces, was successful. However, more complex pieces, such as Chopins Ballade 4, were not successful, that is, the algorithm could not produce low error values in any of the music in the database. I suspect that it has to do with having too many notes: mismatches in the higher harmonics added up to a significant amount of errors, which swamps the calculations.      
### 36.Implicit Neural Spatial Filtering for Multichannel Source Separation in the Waveform Domain  [ :arrow_down: ](https://arxiv.org/pdf/2206.15423.pdf)
>  We present a single-stage casual waveform-to-waveform multichannel model that can separate moving sound sources based on their broad spatial locations in a dynamic acoustic scene. We divide the scene into two spatial regions containing, respectively, the target and the interfering sound sources. The model is trained end-to-end and performs spatial processing implicitly, without any components based on traditional processing or use of hand-crafted spatial features. We evaluate the proposed model on a real-world dataset and show that the model matches the performance of an oracle beamformer followed by a state-of-the-art single-channel enhancement network.      
### 37.Neural Annotation Refinement: Development of a New 3D Dataset for Adrenal Gland Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2206.15328.pdf)
>  The human annotations are imperfect, especially when produced by junior practitioners. Multi-expert consensus is usually regarded as golden standard, while this annotation protocol is too expensive to implement in many real-world projects. In this study, we propose a method to refine human annotation, named Neural Annotation Refinement (NeAR). It is based on a learnable implicit function, which decodes a latent vector into represented shape. By integrating the appearance as an input of implicit functions, the appearance-aware NeAR fixes the annotation artefacts. Our method is demonstrated on the application of adrenal gland analysis. We first show that the NeAR can repair distorted golden standards on a public adrenal gland segmentation dataset. Besides, we develop a new Adrenal gLand ANalysis (ALAN) dataset with the proposed NeAR, where each case consists of a 3D shape of adrenal gland and its diagnosis label (normal vs. abnormal) assigned by experts. We show that models trained on the shapes repaired by the NeAR can diagnose adrenal glands better than the original ones. The ALAN dataset will be open-source, with 1,594 shapes for adrenal gland diagnosis, which serves as a new benchmark for medical shape analysis. Code and dataset are available at <a class="link-external link-https" href="https://github.com/M3DV/NeAR" rel="external noopener nofollow">this https URL</a>.      
### 38.Designs, Motion Mechanism, Motion Coordination, and Communication of Bionic Robot Fishes: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2206.15304.pdf)
>  In the last few years, there have been many new developments and significant accomplishments in the research of bionic robot fishes. However, in terms of swimming performance, existing bionic robot fishes lag far behind fish, prompting researchers to constantly develop innovative designs of various bionic robot fishes. In this paper, the latest designs of robot fishes are presented in detail, distinguished by the propulsion mode. New robot fishes mainly include soft robot fishes and rigid-soft coupled robot fishes. The latest progress in the study of the swimming mechanism is analyzed on the basis of summarizing the main swimming theories of fish. The current state-of-the-art research in the new field of motion coordination and communication of multiple robot fishes is summarized. The general research trend in robot fishes is to utilize more efficient and robust methods to best mimic real fish while exhibiting superior swimming performance. The current challenges and potential future research directions are discussed. Various methods are needed to narrow the gap in swimming performance between robot fishes and fish. This paper is a first step to bring together roboticists and marine biologists interested in learning state-of-the-art research on bionic robot fishes.      
### 39.A Distributed Massive MIMO Channel Sounder for "Big CSI Data"-driven Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2206.15302.pdf)
>  A distributed massive MIMO channel sounder for acquiring large CSI datasets, dubbed DICHASUS, is presented. The measured data has potential applications in the study of various machine learning algorithms for user localization, JCAS, channel charting, enabling massive MIMO in FDD operation, and many others. The proposed channel sounder architecture is distinct from similar previous designs in that each individual single-antenna receiver is completely autonomous, enabling arbitrary, spatially distributed antenna deployments, and offering virtually unlimited scalability in the number of antennas. Optionally, extracted channel coefficient vectors can be tagged with ground truth position data, obtained either through a GNSS receiver (for outdoor operation) or through various indoor positioning techniques.      
### 40.Design and Motion Planning for a Reconfigurable Robotic Base  [ :arrow_down: ](https://arxiv.org/pdf/2206.15298.pdf)
>  A robotic platform for mobile manipulation needs to satisfy two contradicting requirements for many real-world applications: A compact base is required to navigate through cluttered indoor environments, while the support needs to be large enough to prevent tumbling or tip over, especially during fast manipulation operations with heavy payloads or forceful interaction with the environment. This paper proposes a novel robot design that fulfills both requirements through a versatile footprint. It can reconfigure its footprint to a narrow configuration when navigating through tight spaces and to a wide stance when manipulating heavy objects. Furthermore, its triangular configuration allows for high-precision tasks on uneven ground by preventing support switches. A model predictive control strategy is presented that unifies planning and control for simultaneous navigation, reconfiguration, and manipulation. It converts task-space goals into whole-body motion plans for the new robot. The proposed design has been tested extensively with a hardware prototype. The footprint reconfiguration allows to almost completely remove manipulation-induced vibrations. The control strategy proves effective in both lab experiment and during a real-world construction task.      
### 41.Sonification as a Reliable Alternative to Conventional Visual Surgical Navigation  [ :arrow_down: ](https://arxiv.org/pdf/2206.15291.pdf)
>  Despite the undeniable advantages of image-guided surgical assistance systems in terms of accuracy, such systems have not yet fully met surgeons' needs or expectations regarding usability, time efficiency, and their integration into the surgical workflow. On the other hand, perceptual studies have shown that presenting independent but causally correlated information via multimodal feedback involving different sensory modalities can improve task performance. This article investigates an alternative method for computer-assisted surgical navigation, introduces a novel sonification methodology for navigated pedicle screw placement, and discusses advanced solutions based on multisensory feedback. The proposed method comprises a novel sonification solution for alignment tasks in four degrees of freedom based on frequency modulation (FM) synthesis. We compared the resulting accuracy and execution time of the proposed sonification method with visual navigation, which is currently considered the state of the art. We conducted a phantom study in which 17 surgeons executed the pedicle screw placement task in the lumbar spine, guided by either the proposed sonification-based or the traditional visual navigation method. The results demonstrated that the proposed method is as accurate as the state of the art while decreasing the surgeon's need to focus on visual navigation displays instead of the natural focus on surgical tools and targeted anatomy during task execution.      
### 42.R-MelNet: Reduced Mel-Spectral Modeling for Neural TTS  [ :arrow_down: ](https://arxiv.org/pdf/2206.15276.pdf)
>  This paper introduces R-MelNet, a two-part autoregressive architecture with a frontend based on the first tier of MelNet and a backend WaveRNN-style audio decoder for neural text-to-speech synthesis. Taking as input a mixed sequence of characters and phonemes, with an optional audio priming sequence, this model produces low-resolution mel-spectral features which are interpolated and used by a WaveRNN decoder to produce an audio waveform. Coupled with half precision training, R-MelNet uses under 11 gigabytes of GPU memory on a single commodity GPU (NVIDIA 2080Ti). We detail a number of critical implementation details for stable half precision training, including an approximate, numerically stable mixture of logistics attention. Using a stochastic, multi-sample per step inference scheme, the resulting model generates highly varied audio, while enabling text and audio based controls to modify output waveforms. Qualitative and quantitative evaluations of an R-MelNet system trained on a single speaker TTS dataset demonstrate the effectiveness of our approach.      
### 43.libACA, pyACA, and ACA-Code: Audio Content Analysis in 3 Languages  [ :arrow_down: ](https://arxiv.org/pdf/2206.15219.pdf)
>  The three packages libACA, pyACA, and ACA-Code provide reference implementations for basic approaches and algorithms for the analysis of musical audio signals in three different languages: C++, Python, and Matlab. All three packages cover the same algorithms, such as extraction of low level audio features, fundamental frequency estimation, as well as simple approaches to chord recognition, musical key detection, and onset detection. In addition, it implementations of more generic algorithms useful in audio content analysis such as dynamic time warping and the Viterbi algorithm are provided. The three packages thus provide a practical cross-language and cross-platform reference to students and engineers implementing audio analysis algorithms and enable implementation-focused learning of algorithms for audio content analysis and music information retrieval.      
### 44.Privacy-preserving household load forecasting based on non-intrusive load monitoring: A federated deep learning approach  [ :arrow_down: ](https://arxiv.org/pdf/2206.15192.pdf)
>  Load forecasting is very essential in the analysis and grid planning of power systems. For this reason, we first propose a household load forecasting method based on federated deep learning and non-intrusive load monitoring (NILM). For all we know, this is the first research on federated learning (FL) in household load forecasting based on NILM. In this method, the integrated power is decomposed into individual device power by non-intrusive load monitoring, and the power of individual appliances is predicted separately using a federated deep learning model. Finally, the predicted power values of individual appliances are aggregated to form the total power prediction. Specifically, by separately predicting the electrical equipment to obtain the predicted power, it avoids the error caused by the strong time dependence in the power signal of a single device. And in the federated deep learning prediction model, the household owners with the power data share the parameters of the local model instead of the local power data, guaranteeing the privacy of the household user data. The case results demonstrate that the proposed approach provides a better prediction effect than the traditional methodology that directly predicts the aggregated signal as a whole. In addition, experiments in various federated learning environments are designed and implemented to validate the validity of this methodology.      
### 45.An Evaluation of Three-Stage Voice Conversion Framework for Noisy and Reverberant Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2206.15155.pdf)
>  This paper presents a new voice conversion (VC) framework capable of dealing with both additive noise and reverberation, and its performance evaluation. There have been studied some VC researches focusing on real-world circumstances where speech data are interfered with background noise and reverberation. To deal with more practical conditions where no clean target dataset is available, one possible approach is zero-shot VC, but its performance tends to degrade compared with VC using sufficient amount of target speech data. To leverage large amount of noisy-reverberant target speech data, we propose a three-stage VC framework based on denoising process using a pretrained denoising model, dereverberation process using a dereverberation model, and VC process using a nonparallel VC model based on a variational autoencoder. The experimental results show that 1) noise and reverberation additively cause significant VC performance degradation, 2) the proposed method alleviates the adverse effects caused by both noise and reverberation, and significantly outperforms the baseline directly trained on the noisy-reverberant speech data, and 3) the potential degradation introduced by the denoising and dereverberation still causes noticeable adverse effects on VC performance.      
### 46.AI for CSI Feedback Enhancement in 5G-Advanced and 6G  [ :arrow_down: ](https://arxiv.org/pdf/2206.15132.pdf)
>  The 3rd Generation Partnership Project has started the study of Release 18 in 2021. Artificial intelligence (AI)-native air interface is one of the key features of Release 18, where AI for channel state information (CSI) feedback enhancement is selected as the representative use case. This article provides a comprehensive overview of AI for CSI feedback enhancement in 5G-Advanced and 6G. The scope of the AI for CSI feedback enhancement in 5G-Advanced, including overhead reduction, accuracy improvement, and channel prediction, is first presented and discussed. Then, three representative frameworks of AI-enabled CSI feedback, including one-sided implicit feedback, two-sided autoencoder-based implicit feedback, and two-sided explicit feedback, are introduced and compared. Finally, the considerations in the standardization of AI for CSI feedback enhancement, especially focusing on evaluation, complexity, collaboration, generalization, information sharing, joint design with channel prediction, and reciprocity, have been identified and discussed. This article provides a guideline for the standardization study of the AI-based CSI feedback enhancement.      
### 47.A Constructive Heuristic Algorithm for 3D Bin Packing of Irregular Shaped Items  [ :arrow_down: ](https://arxiv.org/pdf/2206.15116.pdf)
>  The three-dimensional bin packing problem (3D-BPP) plays an important role in city logistics and manufacturing environments, due to its direct relevance to operational cost. Most existing literature have investigated the conventional 3D-BPP, in which the shape of items are typically considered as regular shapes, e.g., rectangular-shaped rigid boxes or cylindrical-shaped containers. However, 3D-BPP for non-rectangular shaped items are quite common in varies delivery schemes, especially in fresh food delivery, and few published studies focusing on these issues. In this paper, we address a novel 3D-BPP variant in which the shape changing factor of non-rectangular and deformable items is incorporated to further enhance the loading efficiency and reduce the operational cost of related companies. Motivated by the compression process of item-loading, we propose a constructive heuristic (i.e., an improved dynamic-volume-based packing algorithm) to solve the studied problem. Experimental results over a set of randomly generated instances reveal that considering shape changing factor is indeed able to achieve higher space utilization than that of conventional schemes, thereby has potential to save packaging and delivering cost, as well as enhance operation efficiency.      
### 48.Learning-Aided Beam Prediction in mmWave MU-MIMO Systems for High-Speed Railway  [ :arrow_down: ](https://arxiv.org/pdf/2206.15095.pdf)
>  The problem of beam alignment and tracking in high mobility scenarios such as high-speed railway (HSR) becomes extremely challenging, since large overhead cost and significant time delay are introduced for fast time-varying channel estimation. To tackle this challenge, we propose a learning-aided beam prediction scheme for HSR networks, which predicts the beam directions and the channel amplitudes within a period of future time with fine time granularity, using a group of observations. Concretely, we transform the problem of high-dimensional beam prediction into a two-stage task, i.e., a low-dimensional parameter estimation and a cascaded hybrid beamforming operation. In the first stage, the location and speed of a certain terminal are estimated by maximum likelihood criterion, and a data-driven data fusion module is designed to improve the final estimation accuracy and robustness. Then, the probable future beam directions and channel amplitudes are predicted, based on the HSR scenario priors including deterministic trajectory, motion model, and channel model. Furthermore, we incorporate a learnable non-linear mapping module into the overall beam prediction to allow non-linear tracks. Both of the proposed learnable modules are model-based and have a good interpretability. Compared to the existing beam management scheme, the proposed beam prediction has (near) zero overhead cost and time delay. Simulation results verify the effectiveness of the proposed scheme.      
### 49.Learnable Model-Driven Performance Prediction and Optimization for Imperfect MIMO System: Framework and Application  [ :arrow_down: ](https://arxiv.org/pdf/2206.15072.pdf)
>  State-of-the-art schemes for performance analysis and optimization of multiple-input multiple-output systems generally experience degradation or even become invalid in dynamic complex scenarios with unknown interference and channel state information (CSI) uncertainty. To adapt to the challenging settings and better accomplish these network auto-tuning tasks, we propose a generic learnable model-driven framework in this paper. To explain how the proposed framework works, we consider regularized zero-forcing precoding as a usage instance and design a light-weight neural network for refined prediction of sum rate and detection error based on coarse model-driven approximations. Then, we estimate the CSI uncertainty on the learned predictor in an iterative manner and, on this basis, optimize the transmit regularization term and subsequent receive power scaling factors. A deep unfolded projected gradient descent based algorithm is proposed for power scaling, which achieves favorable trade-off between convergence rate and robustness.      
### 50.Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems  [ :arrow_down: ](https://arxiv.org/pdf/2206.15067.pdf)
>  This paper proposes an effective emotional text-to-speech (TTS) system with a pre-trained language model (LM)-based emotion prediction method. Unlike conventional systems that require auxiliary inputs such as manually defined emotion classes, our system directly estimates emotion-related attributes from the input text. Specifically, we utilize generative pre-trained transformer (GPT)-3 to jointly predict both an emotion class and its strength in representing emotions coarse and fine properties, respectively. Then, these attributes are combined in the emotional embedding space and used as conditional features of the TTS model for generating output speech signals. Consequently, the proposed system can produce emotional speech only from text without any auxiliary inputs. Furthermore, because the GPT-3 enables to capture emotional context among the consecutive sentences, the proposed method can effectively handle the paragraph-level generation of emotional speech.      
### 51.Learning-Based Near-Orthogonal Superposition Code for MIMO Short Message Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2206.15065.pdf)
>  Massive machine type communication (mMTC) has attracted new coding schemes optimized for reliable short message transmission. In this paper, a novel deep learning-based near-orthogonal superposition (NOS) coding scheme is proposed to transmit short messages in multiple-input multiple-output (MIMO) channels for mMTC applications. In the proposed MIMO-NOS scheme, a neural network-based encoder is optimized via end-to-end learning with a corresponding neural network-based detector/decoder in a superposition-based auto-encoder framework including a MIMO channel. The proposed MIMO-NOS encoder spreads the information bits to multiple near-orthogonal high dimensional vectors to be combined (superimposed) into a single vector and reshaped for the space-time transmission. For the receiver, we propose a novel looped K-best tree-search algorithm with cyclic redundancy check (CRC) assistance to enhance the error correcting ability in the block-fading MIMO channel. Simulation results show the proposed MIMO-NOS scheme outperforms maximum likelihood (ML) MIMO detection combined with a polar code with CRC-assisted list decoding by 1-2 dB in various MIMO systems for short (32-64 bit) message transmission.      
### 52.FeaRLESS: Feature Refinement Loss for Ensembling Self-Supervised Learning Features in Robust End-to-end Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2206.15056.pdf)
>  Self-supervised learning representations (SSLR) have resulted in robust features for downstream tasks in many fields. Recently, several SSLRs have shown promising results on automatic speech recognition (ASR) benchmark corpora. However, previous studies have only shown performance for solitary SSLRs as an input feature for ASR models. In this study, we propose to investigate the effectiveness of diverse SSLR combinations using various fusion methods within end-to-end (E2E) ASR models. In addition, we will show there are correlations between these extracted SSLRs. As such, we further propose a feature refinement loss for decorrelation to efficiently combine the set of input features. For evaluation, we show that the proposed 'FeaRLESS learning features' perform better than systems without the proposed feature refinement loss for both the WSJ and Fearless Steps Challenge (FSC) corpora.      
### 53.A Hierarchical Robust Control Strategy for Decentralized Signal-Free Intersection Management  [ :arrow_down: ](https://arxiv.org/pdf/2206.14986.pdf)
>  The development of connected and automated vehicles (CAVs) is the key to improve urban mobility safety and efficiency. This paper focuses on the cooperative vehicle management at a signal-free intersection with consideration of vehicle modeling uncertainties and sensor measurement disturbances. The problem is approached by a hierarchical robust control strategy (HRCS) in a decentralized traffic coordination framework where optimal control and tube-based robust model predictive control (RMPC) methods are designed to hierarchically solve the optimal crossing order and the velocity trajectories of a group of CAVs in terms of energy consumption and throughput. To capture the energy consumption of each vehicle, their powertrain system is modeled in line with an electric drive system. With a suitable relaxation and spatial modeling approach, the optimization problems in HRCS can be formulated as convex second-order cone programs (SOCPs), which provide unique and computationally efficient solution. A rigorous proof of the equivalence between the convexified and the original problems is also provided. Simulation results illustrate the effectiveness and robustness of HRCS and reveal the impact of traffic density on the control solution. The study of the Pareto optimal solutions for the energy-time objective shows that a minor reduction in journey time can considerably reduce energy consumption, which emphasizes the necessity of optimizing their trade-off. Finally, the numerical comparisons carried out for different prediction horizons and sampling intervals provide insight into the control design.      
### 54.Semi-Supervised Generative Adversarial Network for Stress Detection Using Partially Labeled Physiological Data  [ :arrow_down: ](https://arxiv.org/pdf/2206.14976.pdf)
>  Physiological measurements involves observing variables that attribute to the normative functioning of human systems and subsystems directly or indirectly. The measurements can be used to detect affective states of a person with aims such as improving human-computer interactions. There are several methods of collecting physiological data, but wearable sensors are a common, non-invasive tool for accurate readings. However, valuable information is hard to extract from the raw physiological data, especially for affective state detection. Machine Learning techniques are used to detect the affective state of a person through labeled physiological data. A clear problem with using labeled data is creating accurate labels. An expert is needed to analyze a form of recording of participants and mark sections with different states such as stress and calm. While expensive, this method delivers a complete dataset with labeled data that can be used in any number of supervised algorithms. An interesting question arises from the expensive labeling: how can we reduce the cost while maintaining high accuracy? Semi-Supervised learning (SSL) is a potential solution to this problem. These algorithms allow for machine learning models to be trained with only a small subset of labeled data (unlike unsupervised which use no labels). They provide a way of avoiding expensive labeling. This paper compares a fully supervised algorithm to a SSL on the public WESAD (Wearable Stress and Affect Detection) Dataset for stress detection. This paper shows that Semi-Supervised algorithms are a viable method for inexpensive affective state detection systems with accurate results.      
### 55.Decision Forest Based EMG Signal Classification with Low Volume Dataset Augmented with Random Variance Gaussian Noise  [ :arrow_down: ](https://arxiv.org/pdf/2206.14947.pdf)
>  Electromyography signals can be used as training data by machine learning models to classify various gestures. We seek to produce a model that can classify six different hand gestures with a limited number of samples that generalizes well to a wider audience while comparing the effect of our feature extraction results on model accuracy to other more conventional methods such as the use of AR parameters on a sliding window across the channels of a signal. We appeal to a set of more elementary methods such as the use of random bounds on a signal, but desire to show the power these methods can carry in an online setting where EMG classification is being conducted, as opposed to more complicated methods such as the use of the Fourier Transform. To augment our limited training data, we used a standard technique, known as jitter, where random noise is added to each observation in a channel wise manner. Once all datasets were produced using the above methods, we performed a grid search with Random Forest and XGBoost to ultimately create a high accuracy model. For human computer interface purposes, high accuracy classification of EMG signals is of particular importance to their functioning and given the difficulty and cost of amassing any sort of biomedical data in a high volume, it is valuable to have techniques that can work with a low amount of high-quality samples with less expensive feature extraction methods that can reliably be carried out in an online application.      
