# ArXiv eess --Fri, 4 Sep 2020
### 1.Knowing What to Listen to: Early Attention for Deep Speech Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.01822.pdf)
>  Deep learning techniques have considerably improved speech processing in recent years. Speech representations extracted by deep learning models are being used in a wide range of tasks such as speech recognition, speaker recognition, and speech emotion recognition. Attention models play an important role in improving deep learning models. However current attention mechanisms are unable to attend to fine-grained information items. In this paper we propose the novel Fine-grained Early Frequency Attention (FEFA) for speech signals. This model is capable of focusing on information items as small as frequency bins. We evaluate the proposed model on two popular tasks of speaker recognition and speech emotion recognition. Two widely used public datasets, VoxCeleb and IEMOCAP, are used for our experiments. The model is implemented on top of several prominent deep models as backbone networks to evaluate its impact on performance compared to the original networks and other related work. Our experiments show that by adding FEFA to different CNN architectures, performance is consistently improved by substantial margins, even setting a new state-of-the-art for the speaker recognition task. We also tested our model against different levels of added noise showing improvements in robustness and less sensitivity compared to the backbone networks.      
### 2.CNN-Based Ultrasound Image Reconstruction for Ultrafast Displacement Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2009.01816.pdf)
>  Thanks to its capability of acquiring full-view frames at multiple kilohertz, ultrafast ultrasound imaging unlocked the analysis of rapidly changing physical phenomena in the human body, with pioneering applications such as ultrasensitive flow imaging in the cardiovascular system or shear-wave elastography. The accuracy achievable with these motion estimation techniques is strongly contingent upon two contradictory requirements: a high quality of consecutive frames and a high frame rate. Indeed, the image quality can usually be improved by increasing the number of steered ultrafast acquisitions, but at the expense of a reduced frame rate and possible motion artifacts. To achieve accurate motion estimation at uncompromised frame rates and immune to motion artifacts, the proposed approach relies on single ultrafast acquisitions to reconstruct high-quality frames and on only two consecutive frames to obtain 2-D displacement estimates. To this end, we deployed a convolutional neural network-based image reconstruction method combined with a speckle tracking algorithm based on cross-correlation. Numerical and in vivo experiments, conducted in the context of plane-wave imaging, demonstrate that the proposed approach is capable of estimating displacements in regions where the presence of side lobe and grating lobe artifacts prevents any displacement estimation with a state-of-the-art technique that rely on conventional delay-and-sum beamforming. The proposed approach may therefore unlock the full potential of ultrafast ultrasound, in applications such as ultrasensitive cardiovascular motion and flow analysis or shear-wave elastography.      
### 3.Limited View Tomographic Reconstruction Using a Deep Recurrent Framework with Residual Dense Spatial-Channel Attention Network and Sinogram Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2009.01782.pdf)
>  Limited view tomographic reconstruction aims to reconstruct a tomographic image from a limited number of sinogram or projection views arising from sparse view or limited angle acquisitions that reduce radiation dose or shorten scanning time. However, such a reconstruction suffers from high noise and severe artifacts due to the incompleteness of sinogram. To derive quality reconstruction, previous state-of-the-art methods use UNet-like neural architectures to directly predict the full view reconstruction from limited view data; but these methods leave the deep network architecture issue largely intact and cannot guarantee the consistency between the sinogram of the reconstructed image and the acquired sinogram, leading to a non-ideal reconstruction. In this work, we propose a novel recurrent reconstruction framework that stacks the same block multiple times. The recurrent block consists of a custom-designed residual dense spatial-channel attention network. Further, we develop a sinogram consistency layer interleaved in our recurrent framework in order to ensure that the sampled sinogram is consistent with the sinogram of the intermediate outputs of the recurrent blocks. We evaluate our methods on two datasets. Our experimental results on AAPM Low Dose CT Grand Challenge datasets demonstrate that our algorithm achieves a consistent and significant improvement over the existing state-of-the-art neural methods on both limited angle reconstruction (over 5dB better in terms of PSNR) and sparse view reconstruction (about 4dB better in term of PSNR). In addition, our experimental results on Deep Lesion datasets demonstrate that our method is able to generate high-quality reconstruction for 8 major lesion types.      
### 4.HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2009.01776.pdf)
>  High-fidelity singing voices usually require higher sampling rate (e.g., 48kHz) to convey expression and emotion. However, higher sampling rate causes the wider frequency band and longer waveform sequences and throws challenges for singing voice synthesis (SVS) in both frequency and time domains. Conventional SVS systems that adopt small sampling rate cannot well address the above challenges. In this paper, we develop HiFiSinger, an SVS system towards high-fidelity singing voice. HiFiSinger consists of a FastSpeech based acoustic model and a Parallel WaveGAN based vocoder to ensure fast training and inference and also high voice quality. To tackle the difficulty of singing modeling caused by high sampling rate (wider frequency band and longer waveform), we introduce multi-scale adversarial training in both the acoustic model and vocoder to improve singing modeling. Specifically, 1) To handle the larger range of frequencies caused by higher sampling rate, we propose a novel sub-frequency GAN (SF-GAN) on mel-spectrogram generation, which splits the full 80-dimensional mel-frequency into multiple sub-bands and models each sub-band with a separate discriminator. 2) To model longer waveform sequences caused by higher sampling rate, we propose a multi-length GAN (ML-GAN) for waveform generation to model different lengths of waveform sequences with separate discriminators. 3) We also introduce several additional designs and findings in HiFiSinger that are crucial for high-fidelity voices, such as adding F0 (pitch) and V/UV (voiced/unvoiced flag) as acoustic features, choosing an appropriate window/hop size for mel-spectrogram, and increasing the receptive field in vocoder for long vowel modeling. Experiment results show that HiFiSinger synthesizes high-fidelity singing voices with much higher quality: 0.32/0.44 MOS gain over 48kHz/24kHz baseline and 0.83 MOS gain over previous SVS systems.      
### 5.Intra-Utterance Similarity Preserving Knowledge Distillation for Audio Tagging  [ :arrow_down: ](https://arxiv.org/pdf/2009.01759.pdf)
>  Knowledge Distillation (KD) is a popular area of research for reducing the size of large models while still maintaining good performance. The outputs of larger teacher models are used to guide the training of smaller student models. Given the repetitive nature of acoustic events, we propose to leverage this information to regulate the KD training for Audio Tagging. This novel KD method, "Intra-Utterance Similarity Preserving KD" (IUSP), shows promising results for the audio tagging task. It is motivated by the previously published KD method: "Similarity Preserving KD" (SP). However, instead of preserving the pairwise similarities between inputs within a mini-batch, our method preserves the pairwise similarities between the frames of a single input utterance. Our proposed KD method, IUSP, shows consistent improvements over SP across student models of different sizes on the DCASE 2019 Task 5 dataset for audio tagging. There is a 27.1% to 122.4% percent increase in improvement of micro AUPRC over the baseline relative to SP's improvement of over the baseline.      
### 6.Model-Free Design of Control Systems over Wireless Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2009.01751.pdf)
>  Wireless control systems replace traditional wired communication with wireless networks to exchange information between actuators, plants and sensors. In this scenario, plants can be controlled remotely by closing their control loops over a wireless channel. Wireless networks, however, are noisy and subject to packet losses, while control systems are usually designed under the assumption that communication between components is fast and reliable. Proper design of the control policy governing the operation of the plants, as well as proper allocation of (limited) communication resources across plants sharing that communication network is then critical to achieve good performance. The resulting problem of co-designing control-aware resource allocation policies and communication-aware controllers, however, is challenging due to its infinite dimensionality and need for explicit knowledge of the plants and wireless network models. To overcome those challenges, we leverage actor-critic reinforcement learning algorithms to propose a model-free approach to the design of wireless control systems. The proposed approach relies on estimates of the current plants states and wireless channel conditions to compute control signals and assign resources used to send that control actuation information back to the plants. Numerical experiments show the strong performance of learned policies over baseline solutions.      
### 7.VddNet: Vine Disease Detection Network Based on Multispectral Images and Depth Map  [ :arrow_down: ](https://arxiv.org/pdf/2009.01708.pdf)
>  Early detection of vine disease is important to avoid spread of virus or fungi. Disease propagation can lead to a huge loss of grape production and disastrous economic consequences, therefore the problem represents a challenge for the precision farming. In this paper, we present a new system for vine disease detection. The article contains two contributions: the first one is an automatic orthophotos registration method from multispectral images acquired with an unmanned aerial vehicle (UAV). The second one is a new deep learning architecture called VddNet (Vine Disease Detection Network). The proposed architecture is assessed by comparing it with the most known architectures: SegNet, U-Net, DeepLabv3+ and PSPNet. The deep learning architectures were trained on multispectral data and depth map information. The results of the proposed architecture show that the VddNet architecture achieves higher scores than the base line methods. Moreover, this study demonstrates that the proposed system has many advantages compared to methods that directly use the UAV images.      
### 8.A free web service for fast COVID-19 classification of chest X-Ray images  [ :arrow_down: ](https://arxiv.org/pdf/2009.01657.pdf)
>  The coronavirus outbreak became a major concern for society worldwide. Technological innovation and ingenuity are essential to fight COVID-19 pandemic and bring us one step closer to overcome it. Researchers over the world are working actively to find available alternatives in different fields, such as the Healthcare System, pharmaceutic, health prevention, among others. With the rise of artificial intelligence (AI) in the last 10 years, IA-based applications have become the prevalent solution in different areas because of its higher capability, being now adopted to help combat against COVID-19. This work provides a fast detection system of COVID-19 characteristics in X-Ray images based on deep learning (DL) techniques. This system is available as a free web deployed service for fast patient classification, alleviating the high demand for standards method for COVID-19 diagnosis. It is constituted of two deep learning models, one to differentiate between X-Ray and non-X-Ray images based on Mobile-Net architecture, and another one to identify chest X-Ray images with characteristics of COVID-19 based on the DenseNet architecture. For real-time inference, it is provided a pair of dedicated GPUs, which reduce the computational time. The whole system can filter out non-chest X-Ray images, and detect whether the X-Ray presents characteristics of COVID-19, highlighting the most sensitive regions.      
### 9.Deep Learning Based Antenna Selection for Channel Extrapolation in FDD Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2009.01653.pdf)
>  In massive multiple-input multiple-output (MIMO) systems, the large number of antennas would bring a great challenge for the acquisition of the accurate channel state information, especially in the frequency division duplex mode. To overcome the bottleneck of the limited number of radio links in hybrid beamforming, we utilize the neural networks (NNs) to capture the inherent connection between the uplink and downlink channel data sets and extrapolate the downlink channels from a subset of the uplink channel state information. We study the antenna subset selection problem in order to achieve the best channel extrapolation and decrease the data size of NNs. The probabilistic sampling theory is utilized to approximate the discrete antenna selection as a continuous and differentiable function, which makes the back propagation of the deep learning feasible. Then, we design the proper off-line training strategy to optimize both the antenna selection pattern and the extrapolation NNs. Finally, numerical results are presented to verify the effectiveness of our proposed massive MIMO channel extrapolation algorithm.      
### 10.Parameter retrieval methods in ptychography  [ :arrow_down: ](https://arxiv.org/pdf/2009.01652.pdf)
>  We present a parameter retrieval method which combines ptychography and additional prior knowledge about the object. The proposed method is applied to two applications: (1) parameter retrieval of small particles from Fourier ptychographic dark field measurements; (2) parameter retrieval of retangule with real-space ptychography. The influence of Poisson noise is discussed in the second part of the paper. The CramÃ©r Rao Lower Bound in both two applications is computed and Monte Carlo analysis is used to verify the calculated lower bound. With the computation results we report the lower bound for various noise levels and the correlation of particles in Application 1. For Application 2 the correlation of parameters of the rectangule is discussed.      
### 11.Dynamics Compensation in Observation of Abstract Linear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.01643.pdf)
>  This is the second part of four series papers, aiming at the problem of sensor dynamics compensation for abstract linear systems. Two major issues are addressed. The first one is about the sensor dynamics compensation in system observation and the second one is on the disturbance dynamics compensation in output regulation for linear system. Both of them can be described by the problem of state observation for an abstract cascade system. We consider these two apparently different problems from the same abstract linear system point of view. A new scheme of the observer design for the abstract cascade system is developed and the exponential convergence of the observation error is established. It is shown that the error based observer design in the problem of output regulation can be converted into a sensor dynamics compensation problem by the well known regulator equations. As a result, a tracking error based observer for output regulation problem is designed by exploiting the developed method. As applications, the ordinary differential equations (ODEs) with output time-delay and an unstable heat equation with ODE sensor dynamics are fully investigated to validate the theoretical results. The numerical simulations for the unstable heat system are carried out to validate the proposed method visually.      
### 12.Deep Learning Optimized Sparse Antenna Activation for Reconfigurable Intelligent Surface Assisted Communication  [ :arrow_down: ](https://arxiv.org/pdf/2009.01607.pdf)
>  To capture the communications gain of the massive radiating elements with low power cost, the conventional reconfigurable intelligent surface (RIS) usually works in passive mode. However, due to the cascaded channel structure and the lack of signal processing ability, it is difficult for RIS to obtain the individual channel state information and optimize the beamforming vector. In this paper, we add signal processing units for a few antennas at RIS to partially acquire the channels. To solve the crucial active antenna selection problem, we construct an active antenna selection network that utilizes the probabilistic sampling theory to select the optimal locations of these active antennas. With this active antenna selection network, we further design two deep learning (DL) based schemes, i.e., the channel extrapolation scheme and the beam searching scheme, to enable the RIS communication system. The former utilizes the selection network and a convolutional neural network to extrapolate the full channels from the partial channels received by the active RIS antennas, while the latter adopts a fully-connected neural network to achieve the direct mapping between the partial channels and the optimal beamforming vector with maximal transmission rate. Simulation results are provided to demonstrate the effectiveness of the designed DL-based schemes.      
### 13.Heightmap Reconstruction of Macula on Color Fundus Images Using Conditional Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.01601.pdf)
>  For medical diagnosis based on retinal images, a clear understanding of 3D structure is often required but due to the 2D nature of images captured, we cannot infer that information. However, by utilizing 3D reconstruction methods, we can construct the 3D structure of the macula area on fundus images which can be helpful for diagnosis and screening of macular disorders. Recent approaches have used shading information for 3D reconstruction or heightmap prediction but their output was not accurate since they ignored the dependency between nearby pixels. Additionally, other methods were dependent on the availability of more than one image of the eye which is not available in practice. In this paper, we use conditional generative adversarial networks (cGANs) to generate images that contain height information of the macula area on a fundus image. Results using our dataset show a 0.6077 improvement in Structural Similarity Index (SSIM) and 0.071 improvements in Mean Squared Error (MSE) metric over Shape from Shading (SFS) method. Additionally, Qualitative studies also indicate that our method outperforms recent approaches.      
### 14.Multimodal brain tumor classification  [ :arrow_down: ](https://arxiv.org/pdf/2009.01592.pdf)
>  Cancer is a complex disease that provides various types of information depending on the scale of observation. While most tumor diagnostics are performed by observing histopathological slides, radiology images should yield additional knowledge towards the efficacy of cancer diagnostics. This work investigates a deep learning method combining whole slide images and magnetic resonance images to classify tumors. Experiments are prospectively conducted on the 2020 Computational Precision Medicine challenge, in a 3-classes unbalanced classification task. We report cross-validation (resp. validation) balanced-accuracy, kappa and f1 of 0.913, 0.897 and 0.951 (resp. 0.91, 0.90 and 0.94). The complete code of the method is open-source at XXXX. Those include histopathological data pre-processing, and can therefore be used off-the-shelf for other histopathological and/or radiological classification.      
### 15.Fundus Image Analysis for Age Related Macular Degeneration: ADAM-2020 Challenge Report  [ :arrow_down: ](https://arxiv.org/pdf/2009.01548.pdf)
>  Age related macular degeneration (AMD) is one of the major causes for blindness in the elderly population. In this report, we propose deep learning based methods for retinal analysis using color fundus images for computer aided diagnosis of AMD. We leverage the recent state of the art deep networks for building a single fundus image based AMD classification pipeline. We also propose methods for the other directly relevant and auxiliary tasks such as lesions detection and segmentation, fovea detection and optic disc segmentation. We propose the use of generative adversarial networks (GANs) for the tasks of segmentation and detection. We also propose a novel method of fovea detection using GANs.      
### 16.Volume Control of Low-Cost Ventilator with Automatic Set-Point Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2009.01530.pdf)
>  This paper considers the control design for a low-cost ventilator that is based on a manual resuscitator bag (also known as AmbuBag) to pump air into the lungs of a patient who is physically unable to breathe. First, it experimentally shows that for accurately tracking tidal volumes, the controller needs to be adapted to the individual patient and the different configurations, e.g., hardware or operation modes. Second, it proposes a set-point adaptation algorithm that uses sensor measurements of a flow meter to automatically adapt the controller to the setup at hand. Third, it experimentally shows that such an adaptive solution improves the performance of the ventilator for various setups. One objective of this paper is to increase awareness of the need for feedback control using sensor measurements in low-cost ventilator solutions in order to automatically adapt to the specific scenario.      
### 17.Voice Conversion by Cascading Automatic Speech Recognition and Text-to-Speech Synthesis with Prosody Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2009.01475.pdf)
>  With the development of automatic speech recognition (ASR) and text-to-speech synthesis (TTS) technique, it's intuitive to construct a voice conversion system by cascading an ASR and TTS system. In this paper, we present a ASR-TTS method for voice conversion, which used iFLYTEK ASR engine to transcribe the source speech into text and a Transformer TTS model with WaveNet vocoder to synthesize the converted speech from the decoded text. For the TTS model, we proposed to use a prosody code to describe the prosody information other than text and speaker information contained in speech. A prosody encoder is used to extract the prosody code. During conversion, the source prosody is transferred to converted speech by conditioning the Transformer TTS model with its code. Experiments were conducted to demonstrate the effectiveness of our proposed method. Our system also obtained the best naturalness and similarity in the mono-lingual task of Voice Conversion Challenge 2020.      
### 18.Designing the Waveform Bandwidth and Time Duration of Automotive Radars for Better Collision Warning Performance  [ :arrow_down: ](https://arxiv.org/pdf/2009.01437.pdf)
>  Automotive radar is a key component in an ADAS. The increasing number of radars implemented in vehicles makes interference between them a noteworthy issue. One method of interference mitigation is to limit the TBP of radar waveforms. However, the problems of how much TBP is necessary and how to optimally utilize the limited TBP have not been addressed. We take CWS as an example and propose a method of designing the radar waveform parameters oriented by the performance of CWS We propose a metric to quantify the CWS performance and study how the radar waveform parameters (bandwidth and duration) influence this metric. Then, the waveform parameters are designed with a limit on the TBP to optimize the system performance. Numerical results show that the proposed design outperforms the state-of-the-art parameter settings in terms of system performance and resource or energy efficiency.      
### 19.Mononizing Binocular Videos  [ :arrow_down: ](https://arxiv.org/pdf/2009.01424.pdf)
>  This paper presents the idea ofmono-nizingbinocular videos and a frame-work to effectively realize it. Mono-nize means we purposely convert abinocular video into a regular monocular video with the stereo informationimplicitly encoded in a visual but nearly-imperceptible form. Hence, wecan impartially distribute and show the mononized video as an ordinarymonocular video. Unlike ordinary monocular videos, we can restore from itthe original binocular video and show it on a stereoscopic display. To start,we formulate an encoding-and-decoding framework with the pyramidal de-formable fusion module to exploit long-range correspondences between theleft and right views, a quantization layer to suppress the restoring artifacts,and the compression noise simulation module to resist the compressionnoise introduced by modern video codecs. Our framework is self-supervised,as we articulate our objective function with loss terms defined on the input:a monocular term for creating the mononized video, an invertibility termfor restoring the original video, and a temporal term for frame-to-framecoherence. Further, we conducted extensive experiments to evaluate ourgenerated mononized videos and restored binocular videos for diverse typesof images and 3D movies. Quantitative results on both standard metrics anduser perception studies show the effectiveness of our method.      
### 20.Deep Residual Learning for Channel Estimation in Intelligent Reflecting Surface-Assisted Multi-User Communications  [ :arrow_down: ](https://arxiv.org/pdf/2009.01423.pdf)
>  Channel estimation is one of the main tasks in realizing practical intelligent reflecting surface-assisted multi-user communication (IRS-MC) systems. However, different from traditional communication systems, an IRS-MC system generally involves a cascaded channel with a sophisticated statistical distribution. In this case, the optimal minimum mean square error (MMSE) estimator requires the calculation of a multidimensional integration which is intractable to be implemented in practice. To further improve the channel estimation performance, in this paper, we model the channel estimation as a denoising problem and adopt a deep residual learning (DReL) approach to implicitly learn the residual noise for recovering the channel coefficients from the noisy pilot-based observations. To this end, we first develop a versatile DReL-based channel estimation framework where a deep residual network (DRN)-based MMSE estimator is derived in terms of Bayesian philosophy. As a realization of the developed DReL framework, a convolutional neural network (CNN)-based DRN (CDRN) is then proposed for channel estimation in IRS-MC systems, in which a CNN denoising block equipped with an element-wise subtraction structure is specifically designed to exploit both the spatial features of the noisy channel matrices and the additive nature of the noise simultaneously. In particular, an explicit expression of the proposed CDRN is derived and analyzed in terms of Bayesian estimation to characterize its properties theoretically. Finally, simulation results demonstrate that the performance of the proposed method approaches that of the optimal MMSE estimator requiring the availability of the prior probability density function of channel.      
### 21.Application of Transformer Impedance Correction Tables in Power Flow Studies  [ :arrow_down: ](https://arxiv.org/pdf/2009.01382.pdf)
>  Phase Shifting Transformers (PST) are used to control or block certain flows of real power through phase angle regulation across the device. Its functionality is crucial to special situations such as eliminating loop flow through an area and balancing real power flow between parallel paths. Impedance correction tables are used to model that the impedance of phase shifting transformers often vary as a function of their phase angle shift. The focus of this paper is to consider the modeling errors if the impact of this changing impedance is ignored. The simulations are tested through different scenarios using a 37-bus test case and a 10,000-bus synthetic power grid. The results verify the important role of impedance correction factor to get more accurate and optimal power solutions.      
### 22.SAGRNN: Self-Attentive Gated RNN for Binaural Speaker Separation with Interaural Cue Preservation  [ :arrow_down: ](https://arxiv.org/pdf/2009.01381.pdf)
>  Most existing deep learning based binaural speaker separation systems focus on producing a monaural estimate for each of the target speakers, and thus do not preserve the interaural cues, which are crucial for human listeners to perform sound localization and lateralization. In this study, we address talker-independent binaural speaker separation with interaural cues preserved in the estimated binaural signals. Specifically, we extend a newly-developed gated recurrent neural network for monaural separation by additionally incorporating self-attention mechanisms and dense connectivity. We develop an end-to-end multiple-input multiple-output system, which directly maps from the binaural waveform of the mixture to those of the speech signals. The experimental results show that our proposed approach achieves significantly better separation performance than a recent binaural separation approach. In addition, our approach effectively preserves the interaural cues, which improves the accuracy of sound localization.      
### 23.Soft thresholding schemes for multiple signal classification algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2009.01379.pdf)
>  Multiple signal classification algorithm (MUSICAL) exploits temporal fluctuations in fluorescence intensity to perform super-resolution microscopy by computing the value of a super-resolving indicator function across a fine sample grid. A key step in the algorithm is the separation of the measurements into signal and noise subspaces, based on a single user-specified parameter called the threshold. The resulting image is strongly sensitive to this parameter and the subjectivity arising from multiple practical factors makes it difficult to determine the right rule of selection. We address this issue by proposing soft thresholding schemes derived from a new generalized framework for indicator function design. We show that the new schemes significantly alleviate the subjectivity and sensitivity of hard thresholding while retaining the super-resolution ability. We also evaluate the trade-off between resolution and contrast and the out-of-focus light rejection using the various indicator functions. Through this, we create significant new insights into the use and further optimization of MUSICAL for a wide range of practical scenarios.      
### 24.Clustering Millimeter Wave Propagation Channels with Watershed Transformation  [ :arrow_down: ](https://arxiv.org/pdf/2009.01375.pdf)
>  A clustering method based on image processing is proposed in this paper. It is used to identify clusters in 2D representations of propagation channels. The approach uses operations such as watershed segmentation and is particularly well suited for clustering directional channels obtained by beam-steering at millimeter-wave. This situation occurs for instance with electronic beam-steering using analog antenna arrays during beam training process or during channel modeling measurements using either electronic or mechanical beam-steering. In particular, the proposed technique is used here to cluster two-dimensional power angular spectrum maps. The proposed clustering is unsupervised and is well suited to preserve the shape of clusters, which is useful to obtain more accurate descriptions of channel spatial properties. The approach is found to outperform approaches based on K-Power-Means in terms of accuracy as well as computational resources. The technique is assessed in simulation using IEEE 802.11ad channel model and in measurement using experiments conducted at 60 GHz in an indoor environment.      
### 25.Real Image Super Resolution Via Heterogeneous Model using GP-NAS  [ :arrow_down: ](https://arxiv.org/pdf/2009.01371.pdf)
>  With advancement in deep neural network (DNN), recent state-of-the-art (SOTA) image superresolution (SR) methods have achieved impressive performance using deep residual network with dense skip connections. While these models perform well on benchmark dataset where low-resolution (LR) images are constructed from high-resolution (HR) references with known blur kernel, real image SR is more challenging when both images in the LR-HR pair are collected from real cameras. Based on existing dense residual networks, a Gaussian process based neural architecture search (GP-NAS) scheme is utilized to find candidate network architectures using a large search space by varying the number of dense residual blocks, the block size and the number of features. A suite of heterogeneous models with diverse network structure and hyperparameter are selected for model-ensemble to achieve outstanding performance in real image SR. The proposed method won the first place in all three tracks of the AIM 2020 Real Image Super-Resolution Challenge.      
### 26.Agent-level optimal LQG control of dynamically decoupled systems with processing delays  [ :arrow_down: ](https://arxiv.org/pdf/2009.01365.pdf)
>  We consider the problem of controlling a set of dynamically decoupled plants where the plants' subcontrollers communicate with each other according to a fixed and known network topology. We assume the communication to be instantaneous but there is a fixed processing delay associated with incoming transmissions. We provide explicit closed-form expressions for the optimal decentralized controller under these communication constraints and using standard LQG assumptions for the plants and cost function. Although this problem is convex, it is challenging due to the irrationality of continuous-time delays and the decentralized information-sharing pattern. We show that the optimal subcontrollers each have an observer-regulator architecture containing LTI and FIR blocks and we characterize the signals that subcontrollers should transmit to each other across the network.      
### 27.Strategic Policymaking for Implementing Renewable Portfolio Standards: A Tri-level Optimization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.01336.pdf)
>  Appropriately designed renewable support policies can play a leading role in promoting renewable expansions and contribute to low emission goals. Meanwhile, ill-designed policies may distort electricity markets, put power utilities and generation companies on an unlevel playing field and, in turn, cause inefficiencies. This paper proposes a framework to optimize policymaking for renewable energy sources, while incorporating conflicting interests and objectives of different stakeholders. We formulate a tri-level optimization problem where each level represents a different entity: a state regulator, a power utility and a wholesale electricity market. To solve this tri-level problem, we exploit optimality conditions and develop a modification of the Column-and-Cut Generation (C&amp;CG) algorithm that generates cuts for bilinear terms. The case study based on the ISO New England 8-zone test system reveals different policy trade-offs that policymakers face under different decarbonization goals and implementation scenarios.      
### 28.When Image Decomposition Meets Deep Learning: A Novel Infrared and Visible Image Fusion Method  [ :arrow_down: ](https://arxiv.org/pdf/2009.01315.pdf)
>  Infrared and visible image fusion, as a hot topic in image processing and image enhancement, aims to produce fused images retaining the detail texture information in visible images and the thermal radiation information in infrared images. In this paper, we propose a novel two-stream auto-encoder (AE) based fusion network. The core idea is that the encoder decomposes an image into base and detail feature maps with low- and high-frequency information, respectively, and that the decoder is responsible for the original image reconstruction. To this end, a well-designed loss function is established to make the base/detail feature maps similar/dissimilar. In the test phase, base and detail feature maps are respectively merged via a fusion module, and the fused image is recovered by the decoder. Qualitative and quantitative results demonstrate that our method can generate fusion images containing highlighted targets and abundant detail texture information with strong reproducibility and meanwhile superior than the state-of-the-art (SOTA) approaches.      
### 29.Convolutional Speech Recognition with Pitch and Voice Quality Features  [ :arrow_down: ](https://arxiv.org/pdf/2009.01309.pdf)
>  The effects of adding pitch and voice quality features such as jitter and shimmer to a state-of-the-art CNN model for Automatic Speech Recognition are studied in this work. Pitch features have been previously used for improving classical HMM and DNN baselines, while jitter and shimmer parameters have proven to be useful for tasks like speaker or emotion recognition. Up to our knowledge, this is the first work combining such pitch and voice quality features with modern convolutional architectures, showing improvements up to 2% absolute WER points, for the publicly available Spanish Common Voice dataset. Particularly, our work combines these features with mel-frequency spectral coefficients (MFSCs) to train a convolutional architecture with Gated Linear Units (Conv GLUs). Such models have shown to yield small word error rates, while being very suitable for parallel processing for online streaming recognition use cases. We have added pitch and voice quality functionality to Facebook's wav2letter speech recognition framework, and we provide with such code and recipes to the community, to carry on with further experiments. Besides, to the best of our knowledge, our Spanish Common Voice recipe is the first public Spanish recipe for wav2letter.      
### 30.Detecting Parkinson's Disease from Speech-task in an accessible and interpretable manner  [ :arrow_down: ](https://arxiv.org/pdf/2009.01231.pdf)
>  Every nine minutes a person is diagnosed with Parkinson's Disease (PD) in the United States. However, studies have shown that between 25 and 80\% of individuals with Parkinson's Disease (PD) remain undiagnosed. An online, in the wild audio recording application has the potential to help screen for the disease if risk can be accurately assessed. In this paper, we collect data from 726 unique subjects (262 PD and 464 Non-PD) uttering the "quick brown fox jumps over the lazy dog ...." to conduct automated PD assessment. We extracted both standard acoustic features and deep learning based embedding features from the speech data and trained several machine learning algorithms on them. Our models achieved 0.75 AUC by modeling the standard acoustic features through the XGBoost model. We also provide explanation behind our model's decision and show that it is focusing mostly on the widely used MFCC features and a subset of dysphonia features previously used for detecting PD from verbal phonation task.      
### 31.Physics-Consistent Data-driven Waveform Inversion with Adaptive Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2009.01807.pdf)
>  Seismic full-waveform inversion (FWI) is a nonlinear computational imaging technique that can provide detailed estimates of subsurface geophysical properties. Solving the FWI problem can be challenging due to its ill-posedness and high computational cost. In this work, we develop a new hybrid computational approach to solve FWI that combines physics-based models with data-driven methodologies. In particular, we develop a data augmentation strategy that can not only improve the representativity of the training set but also incorporate important governing physics into the training process and therefore improve the inversion accuracy. To validate the performance, we apply our method to synthetic elastic seismic waveform data generated from a subsurface geologic model built on a carbon sequestration site at Kimberlina, California. We compare our physics-consistent data-driven inversion method to both purely physics-based and purely data-driven approaches and observe that our method yields higher accuracy and greater generalization ability.      
### 32.Multidisciplinary Design Optimization of Reusable Launch Vehicles for Different Propellants and Objectives  [ :arrow_down: ](https://arxiv.org/pdf/2009.01664.pdf)
>  Identifying the optimal design of a new launch vehicle is most important since design decisions made in the early development phase limit the vehicles' later performance and determines the associated costs. Reusing the first stage via retro-propulsive landing increases the complexity even more. Therefore, we develop an optimization framework for partially reusable launch vehicles, which enables multidisciplinary design studies. The framework contains suitable mass estimates of all essential subsystems and a routine to calculate the needed propellant for the ascent and landing maneuvers. For design optimization, the framework can be coupled with a genetic algorithm. The overall goal is to reveal the implications of different propellant combinations and objective functions on the launcher's optimal design for various mission scenarios. The results show that the optimization objective influences the most suitable propellant choice and the overall launcher design, concerning staging, weight, size, and rocket engine parameters. In terms of gross lift-off weight, liquid hydrogen seems to be favorable. When optimizing for a minimum structural mass or an expandable structural mass, hydrocarbon-based solutions show better results. Finally, launch vehicles using a hydrocarbon fuel in the first stage and liquid hydrogen in the upper stage are an appealing alternative, combining both fuels' benefits.      
### 33.Deep Learning-based Initialization of Iterative Reconstruction for Breast Tomosynthesis  [ :arrow_down: ](https://arxiv.org/pdf/2009.01538.pdf)
>  Reconstruction of digital breast tomosynthesis is a challenging problem due to the limited angle data available in such systems. Due to memory limitations, deep learning-based methods can help improve these reconstructions, but can not (yet) attain sufficiently high resolution. In addition to this practical issue, questions remain on the possibility of such models introducing 'ghost' information from the training data that is not compatible with the projection data. To take advantage of some of the benefits of deep learning-based reconstructions while avoiding these limitations, we propose to use the low resolution deep learning-based reconstruction as an initialization of a regular high resolution iterative method. <br>The network was trained using digital phantoms, some based on a mathematical model and some derived from patient dedicated breast CT scans. The output of this network was then used as initialization for 10 000 iterations of MLTR for nine patient based phantoms that were not included in the training. The same nine cases were also reconstructed without any initialization for comparison. <br>The reconstructions including initialization were found to reach a lower mean squared error than those without, and visual inspection found much improved retrieval of the breast outline and depiction of the skin, confirming that adding the deep learning-based initialization adds valuable information to the reconstruction.      
### 34.End-to-End Learning of Neuromorphic Wireless Systems for Low-Power Edge Artificial Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2009.01527.pdf)
>  This paper introduces a novel "all-spike" low-power solution for remote wireless inference that is based on neuromorphic sensing, Impulse Radio (IR), and Spiking Neural Networks (SNNs). In the proposed system, event-driven neuromorphic sensors produce asynchronous time-encoded data streams that are encoded by an SNN, whose output spiking signals are pulse modulated via IR and transmitted over general frequence-selective channels; while the receiver's inputs are obtained via hard detection of the received signals and fed to an SNN for classification. We introduce an end-to-end training procedure that treats the cascade of encoder, channel, and decoder as a probabilistic SNN-based autoencoder that implements Joint Source-Channel Coding (JSCC). The proposed system, termed NeuroJSCC, is compared to conventional synchronous frame-based and uncoded transmissions in terms of latency and accuracy. The experiments confirm that the proposed end-to-end neuromorphic edge architecture provides a promising framework for efficient and low-latency remote sensing, communication, and inference.      
### 35.DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.01502.pdf)
>  The Internet of Vehicles (IoV) enables real-time data exchange among vehicles and roadside units and thus provides a promising solution to alleviate traffic jams in the urban area. Meanwhile, better traffic management via efficient traffic light control can benefit the IoV as well by enabling a better communication environment and decreasing the network load. As such, IoV and efficient traffic light control can formulate a virtuous cycle. Edge computing, an emerging technology to provide low-latency computation capabilities at the edge of the network, can further improve the performance of this cycle. However, while the collected information is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for edge-empowered IoV. To this end, we propose a Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits the ubiquity of the IoV to accelerate the collection of traffic data and its interpretation towards alleviating congestion and providing better traffic light control. DRLE operates within the coverage of the edge servers and uses aggregated data from neighboring edge servers to provide city-scale traffic light control. DRLE decomposes the highly complex problem of large area control. into a decentralized multi-agent problem. We prove its global optima with concrete mathematical reasoning. The proposed decentralized reinforcement learning algorithm running at each edge node adapts the traffic lights in real time. We conduct extensive evaluations and demonstrate the superiority of this approach over several state-of-the-art algorithms.      
### 36.Noise-Aware Texture-Preserving Low-Light Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2009.01385.pdf)
>  A simple and effective low-light image enhancement method based on a noise-aware texture-preserving retinex model is proposed in this work. The new method, called NATLE, attempts to strike a balance between noise removal and natural texture preservation through a low-complexity solution. Its cost function includes an estimated piece-wise smooth illumination map and a noise-free texture-preserving reflectance map. Afterwards, illumination is adjusted to form the enhanced image together with the reflectance map. Extensive experiments are conducted on common low-light image enhancement datasets to demonstrate the superior performance of NATLE.      
### 37.Change Point Detection by Cross-Entropy Maximization  [ :arrow_down: ](https://arxiv.org/pdf/2009.01358.pdf)
>  Many offline unsupervised change point detection algorithms rely on minimizing a penalized sum of segment-wise costs. We extend this framework by proposing to minimize a sum of discrepancies between segments. In particular, we propose to select the change points so as to maximize the cross-entropy between successive segments, balanced by a penalty for introducing new change points. We propose a dynamic programming algorithm to solve this problem and analyze its complexity. Experiments on two challenging datasets demonstrate the advantages of our method compared to three state-of-the-art approaches.      
### 38.How Effective is Model Predictive Control in Real-Time Water Quality Regulation? State-Space Modeling and Scalable Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.01298.pdf)
>  Real-time water quality control (WQC) in water distribution networks (WDN), the problem of regulating disinfectant levels, is challenging due to lack of (i) a proper control-oriented modeling considering complicated components (junctions, reservoirs, tanks, pipes, pumps, and valves) for water quality modeling and (ii) a corresponding scalable control algorithm that performs realtime water quality regulation. In this paper, we solve the WQC problem by (a) proposing a novel state-space representation of the WQC problem that provides explicit relationship between inputs (chlorine dosage at booster stations) and states/outputs (chlorine concentrations in the entire network) and (b) designing a highly scalable model predictive control (MPC) algorithm that showcases fast response time and resilience against some sources of uncertainty.      
### 39.Proposed Efficient Design for Unmanned Surface Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2009.01284.pdf)
>  Recently worldwide interest is growing toward commercial, military or scientific Unmanned Surface Vehicle (USV) and hence there is required to develop their guidance, navigation, and control (GNC) systems. Real USVs are a relatively new advent, so the drawbacks of each model will be modified during the time. The proposition of an environmentally friendly as well as high efficient USV's design are the main purposes of this paper to guide future researches. Power management between renewable sources and storage units is considered. Furthermore, suitable and modern sensors are applied for state estimation and environmental perception. Technical requirements relate to guidance and control methods are provided to achieve the highest performance in the environment. Also, the hull structure and its material are important factors that are considered in this paper.      
### 40.Clustering of Nonnegative Data and an Application to Matrix Completion  [ :arrow_down: ](https://arxiv.org/pdf/2009.01279.pdf)
>  In this paper, we propose a simple algorithm to cluster nonnegative data lying in disjoint subspaces. We analyze its performance in relation to a certain measure of correlation between said subspaces. We use our clustering algorithm to develop a matrix completion algorithm which can outperform standard matrix completion algorithms on data matrices satisfying certain natural conditions.      
### 41.Robust simultaneous stabilization and decoupling of unstable adversely coupled uncertain resource constraints plants of a nano air vehicle  [ :arrow_down: ](https://arxiv.org/pdf/1905.00324.pdf)
>  The plants of nano air vehicles (NAVs) are generally unstable, adversely coupled, and uncertain. Besides, the autopilot hardware of a NAV has limited sensing and computational capabilities. Hence, these vehicles need a single controller referred to as Robust Simultaneously Stabilizing Decoupling (RSSD) output feedback controller that achieves simultaneous stabilization, desired decoupling, robustness, and performance for a finite set of unstable multi-input-multi-output adversely coupled uncertain plants. To synthesize a RSSD output feedback controller, a new method that is based on a central plant is proposed in this paper. Given a finite set of plants for simultaneous stabilization, we considered a plant in this set that has the smallest maximum $v-$gap metric as the central plant. Following this, the sufficient condition for the existence of a simultaneous stabilizing controller associated with such a plant is described. The decoupling feature is then appended to this controller using the properties of the eigenstructure assignment method. <br>Afterward, the sufficient conditions for the existence of a RSSD output feedback controller are obtained. Using these sufficient conditions, a new optimization problem for the synthesis of a RSSD output feedback controller is formulated. To solve this optimization problem, a new genetic algorithm based offline iterative algorithm is developed. The effectiveness of this iterative algorithm is then demonstrated by generating a RSSD controller for a fixed-wing nano air vehicle. The performance of this controller is validated through numerical and hardware-in-the-loop simulations.      
