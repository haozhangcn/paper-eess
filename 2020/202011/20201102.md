# ArXiv eess --Mon, 2 Nov 2020
### 1.Audio Dequantization Using (Co)Sparse (Non)Convex Methods  [ :arrow_down: ](https://arxiv.org/pdf/2010.16386.pdf)
>  The paper deals with the hitherto neglected topic of audio dequantization. It reviews the state-of-the-art sparsity-based approaches and proposes several new methods. Convex as well as non-convex approaches are included, and all the presented formulations come in both the synthesis and analysis variants. The experiments evaluate the methods using the signal-to-distortion ratio (SDR) and PEMO-Q, a perceptually motivated metric. The analysis variants of convex approaches turn out to give the best results.      
### 2.Development and Evaluation of a Deep Neural Network for Histologic Classification of Renal Cell Carcinoma on Biopsy and Surgical Resection Slides  [ :arrow_down: ](https://arxiv.org/pdf/2010.16380.pdf)
>  Renal cell carcinoma (RCC) is the most common renal cancer in adults. The histopathologic classification of RCC is essential for diagnosis, prognosis, and management of patients. Reorganization and classification of complex histologic patterns of RCC on biopsy and surgical resection slides under a microscope remains a heavily specialized, error-prone, and time-consuming task for pathologists. In this study, we developed a deep neural network model that can accurately classify digitized surgical resection slides and biopsy slides into five related classes: clear cell RCC, papillary RCC, chromophobe RCC, renal oncocytoma, and normal. In addition to the whole-slide classification pipeline, we visualized the identified indicative regions and features on slides for classification by reprocessing patch-level classification results to ensure the explainability of our diagnostic model. We evaluated our model on independent test sets of 78 surgical resection whole slides and 79 biopsy slides from our tertiary medical institution, and 69 randomly selected surgical resection slides from The Cancer Genome Atlas (TCGA) database. The average area under the curve (AUC) of our classifier on the internal resection slides, internal biopsy slides, and external TCGA slides is 0.98, 0.98 and 0.99, respectively. Our results suggest that the high generalizability of our approach across different data sources and specimen types. More importantly, our model has the potential to assist pathologists by (1) automatically pre-screening slides to reduce false-negative cases, (2) highlighting regions of importance on digitized slides to accelerate diagnosis, and (3) providing objective and accurate diagnosis as the second opinion.      
### 3.Interpreting glottal flow dynamics for detecting COVID-19 from voice  [ :arrow_down: ](https://arxiv.org/pdf/2010.16318.pdf)
>  In the pathogenesis of COVID-19, impairment of respiratory functions is often one of the key symptoms. Studies show that in these cases, voice production is also adversely affected -- vocal fold oscillations are asynchronous, asymmetrical and more restricted during phonation. This paper proposes a method that analyzes the differential dynamics of the glottal flow waveform (GFW) during voice production to identify features in them that are most significant for the detection of COVID-19 from voice. Since it is hard to measure this directly in COVID-19 patients, we infer it from recorded speech signals and compare it to the GFW computed from physical model of phonation. For normal voices, the difference between the two should be minimal, since physical models are constructed to explain phonation under assumptions of normalcy. Greater differences implicate anomalies in the bio-physical factors that contribute to the correctness of the physical model, revealing their significance indirectly. Our proposed method uses a CNN-based 2-step attention model that locates anomalies in time-feature space in the difference of the two GFWs, allowing us to infer their potential as discriminative features for classification. The viability of this method is demonstrated using a clinically curated dataset of COVID-19 positive and negative subjects.      
### 4.Single Channel MMWave FMCW Radar for 2D Target Localization  [ :arrow_down: ](https://arxiv.org/pdf/2010.16292.pdf)
>  In this paper, we present a 2D target localization method using two low cost and compact Mellimeter Wave Frequency Modulated Continuous Wave (MMW-FMCW) radars. To create a 2D map we exploit the bilateration method followed by a multi-target tracking block to remove the ghost targets. <br>Finally, we present experimental results based on the data gathered from two FMCW radars operating at $\rm 79 \;GHz$.      
### 5.DeepRx MIMO: Convolutional MIMO Detection with Learned Multiplicative Transformations  [ :arrow_down: ](https://arxiv.org/pdf/2010.16283.pdf)
>  Recently, deep learning has been proposed as a potential technique for improving the physical layer performance of radio receivers. Despite the large amount of encouraging results, most works have not considered spatial multiplexing in the context of multiple-input and multiple-output (MIMO) receivers. In this paper, we present a deep learning-based MIMO receiver architecture that consists of a ResNet-based convolutional neural network, also known as DeepRx, combined with a so-called transformation layer, all trained together. We propose two novel alternatives for the transformation layer: a maximal ratio combining-based transformation, or a fully learned transformation. The former relies more on expert knowledge, while the latter utilizes learned multiplicative layers. Both proposed transformation layers are shown to clearly outperform the conventional baseline receiver, especially with sparse pilot configurations. To the best of our knowledge, these are some of the first results showing such high performance for a fully learned MIMO receiver.      
### 6.Resolving Kirchhoff's laws for state-estimator design of Li-ion battery packs connected in parallel  [ :arrow_down: ](https://arxiv.org/pdf/2010.16264.pdf)
>  A state-space model for Li-ion battery packs with parallel connected cells is introduced. The key feature of this model is an explicit solution to Kirchhoff's laws for parallel connected packs, which expresses the branch currents directly in terms of the model's states, applied current and cell resistances. This avoids the need to solve these equations numerically. To illustrate the potential of the proposed model for pack-level control and estimation, a state-estimator is introduced for the nonlinear parallel pack model. By exploiting the system structure seen in the solution to Kirchhoff's laws, algebraic conditions for the observer gains are obtained that guarantee convergence of the estimator's error. Error convergence is demonstrated through an argument based upon Aizerman's conjecture. It is hoped that the insight brought by this model formulation will allow the wealth of results developed for series connected packs to be applied to those with parallel connections.      
### 7.Joint Transceiver Design Based on Dictionary Learning Algorithm for SCMA  [ :arrow_down: ](https://arxiv.org/pdf/2010.16213.pdf)
>  With the explosively increasing demands on the network capacity, throughput and number of connected wireless devices, massive connectivity is an urgent problem for the next generation wireless communications. In this paper, we propose a grant-free access protocol for massive connectivity that utilizes a large number of antennas in a base station (BS) and is expected to be widely deployed in cellular networks. The scheme consists of a sparse structure in sparse code multiple access (SCMA) and receiver processing based on dictionary learning (DL). A large number of devices can transmit data without any scheduling process. Unlike existing schemes, whose signal schedulings require a lot of overhead, the scheduling overhead required by the proposed scheme is negligible, which is attractive for resource utilization and transmission power efficiency. The numerical results show that the proposed scheme has promising performance in massive connectivity scenario of cellular networks.      
### 8.Distributed Kuramoto Self-Synchronization of Vehicle Speed Trajectories in Traffic Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.16200.pdf)
>  This paper presents a distributed synchronization strategy for connected and automated vehicles in traffic networks. The strategy considers vehicles traveling from one intersection to the next as waves. The phase angle and frequency of each wave map to its position and velocity, respectively. The goal is to synchronize traffic such that intersecting traffic waves are out of phase at every intersection. This ensures the safe collective navigation of intersections. Vehicles share their phase angles through the V2X infrastructure, and synchronize these angles using the Kuramoto equation. This is a classical model for the self-synchronization of coupled oscillators. The mapping between phase and location for vehicles on different roads is designed such that Kuramoto synchronization ensures safe intersection navigation. Each vehicle uses a constrained optimal control policy to achieve its desired target Kuramoto phase at the upcoming intersection. The overall outcome is a distributed traffic synchronization algorithm that simultaneously tackles two challenges traditionally addressed independently, namely: coordinating crossing at an individual intersection, and harmonizing traffic flow between adjacent intersections. Simulation studies highlight the positive impact of this strategy on fuel consumption and traffic delay time, compared to a network with traditional traffic light timing.      
### 9.Automatic Myocardial Infarction Evaluation from Delayed-Enhancement Cardiac MRI using Deep Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.16198.pdf)
>  In this paper, we propose a new deep learning framework for an automatic myocardial infarction evaluation from clinical information and delayed enhancement-MRI (DE-MRI). The proposed framework addresses two tasks. The first task is automatic detection of myocardial contours, the infarcted area, the no-reflow area, and the left ventricular cavity from a short-axis DE-MRI series. It employs two segmentation neural networks. The first network is used to segment the anatomical structures such as the myocardium and left ventricular cavity. The second network is used to segment the pathological areas such as myocardial infarction, myocardial no-reflow, and normal myocardial region. The segmented myocardium region from the first network is further used to refine the second network's pathological segmentation results. The second task is to automatically classify a given case into normal or pathological from clinical information with or without DE-MRI. A cascaded support vector machine (SVM) is employed to classify a given case from its associated clinical information. The segmented pathological areas from DE-MRI are also used for the classification task. We evaluated our method on the 2020 EMIDEC MICCAI challenge dataset. It yielded an average Dice index of 0.93 and 0.84, respectively, for the left ventricular cavity and the myocardium. The classification from using only clinical information yielded 80% accuracy over five-fold cross-validation. Using the DE-MRI, our method can classify the cases with 93.3% accuracy. These experimental results reveal that the proposed method can automatically evaluate the myocardial infarction.      
### 10.Reset band for mitigatation of quantization induced performance degradation  [ :arrow_down: ](https://arxiv.org/pdf/2010.16191.pdf)
>  Reset control has emerged as a viable alternative to popular PID, capable of outperforming and overcoming the linear limitations. However, in motion control systems, quantization can cause severe performance degradation. This paper investigates this degradation in practical systems and re-purposes the reset band condition in order to mitigate the same. Numerical simulations have been conducted on a mass based positioning system to analyze the cause of the quantization induced performance degradation. Moreover, a performance and robustness analysis was performed with the proposed solution. Finally, novel tuning guidelines are provided for estimating the required reset band parameter. Additionally, practical experiments have been conducted on a high precision motion system for validation. The experiments show by example that the reset band can reduce the error in the problematic region by up to 285% and hence shows the need and effectiveness of the proposed solution.      
### 11.Adaptive Feedforward Control For Reset Feedback Control Systems -- Application in Precision Motion Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.16189.pdf)
>  This paper presents a novel adaptive feedforward controller design for reset control systems. The combination of feedforward and reset feedback control promises high performance as the feedforward guarantees reference tracking, while the non-linear feedback element rejects disturbances. To overcome inevitable model mismatches, the feedforward controller adapts to increase precision in reference tracking. Where linear existing adaptive feedforward controllers do not guarantee convergence in the presence of reset, this work presents a novel adaptive law based on converging and diverging regions of adaptation to achieve good tracking. Experimental results demonstrate the claimed advantage of the novel method.      
### 12.Range-Doppler Information and Doppler Scattering Information in Multipulse Radar  [ :arrow_down: ](https://arxiv.org/pdf/2010.16178.pdf)
>  In this paper, the general radar measurement probfilems of determining range, Doppler frequency and scatteringproperties parameters are investigated from the viewpoint of Shannons information theory. We adopt the mutual information to evaluate the accuracy of the classification and estimation. The range-Doppler information is examined under the condition that the target is of radial velocity. Its asymptotic upper bound and the corresponding entropy error (EE) are further formulated theoretically. Additionally, the Doppler scattering information induced by targets random motion characteristics is discussed. From the derivation, it is concluded that the Doppler scattering information depends on the eigenvalues of the target scattering correlation matrix. Especially in the case where the pulse interval is larger than targets coherence time, we can find that the formula of the Doppler scattering information is similar to Shannons channel capacity equation, indicating the inherent consistency between the communication theory and radar field. Numerical simulations of these information contents are presented to confirm our theoretical observations. The relationship between the information content and signal-to-noise ratio (SNR) reflects the changes in information acquisition efficiency of a radar system, providing guidance for system designers.      
### 13.Chance-Constrained OPF in Droop-Controlled Microgrids with Power Flow Routers  [ :arrow_down: ](https://arxiv.org/pdf/2010.16170.pdf)
>  High penetration of renewable generation poses great challenge to power system operation due to its uncertain nature. In droop-controlled microgrids, the voltage volatility induced by renewable uncertainties is aggravated by the high droop gains. This paper proposes a chance-constrained optimal power flow (CC-OPF) problem with power flow routers (PFRs) to better regulate the voltage profile in microgrids. PFR refer to a general type of network-side controller that brings more flexibility to the power network. Comparing with the normal CC-OPF that relies on power injection flexibility only, the proposed model introduces a new dimension of control from power network to enhance system performance under renewable uncertainties. Since the inclusion of PFRs complicates the problem and makes common solvers no longer apply directly, we design an iterative solution algorithm. For the subproblem in each iteration, chance constraints are transformed into equivalent deterministic ones via sensitivity analysis, so that the subproblem can be efficiently solved by the convex relaxation method. The proposed method is verified on the modified IEEE 33-bus system and the results show that PFRs make a significant contribution to mitigating the voltage volatility and make the system operate in a more economic and secure way.      
### 14.Assessment of mobility deficit and treatment efficacy in adhesive capsulitis by measurement of kinematic parameters using IMU sensors  [ :arrow_down: ](https://arxiv.org/pdf/2010.16169.pdf)
>  There is a growing research interest towards the use of wireless IMU sensors to assess disability, monitor progress and provide feedback to patients on range of motion and movement performance during upper body rehabilitation. The quality of movement in patients with adhesive capsulitis and relative treatment efficacy has not yet been studied using inertial and magnetic sensors. The aim of this study was to investigate the possibility to quantitatively evaluate capsulate-related deficit versus healthy controls and to assess treatment efficacy by measurement of shoulder kinematic parameters with ISEO protocol using inertial and magnetic measurement system technology. We enrolled 6 patients with adhesive capsulitis (AC) who underwent the experimental assessment by using a set of wireless IMU sensors at the baseline (T0) and after the 15 one-hour individual sessions of physiotherapy (T1). The range of motion in elevation, abduction and the scapulohumeral rhythm kinematic parameters were extracted from measurements performed in enrolled AC patients and in 7 healthy controls. The results of this preliminary study showed that proposed approach based on measurement of shoulder kinematic parameters with ISEO protocol using IMU wireless sensors can be useful in mobility deficit assessment of patients with adhesive capsulitis, as well as for monitoring of treatment efficacy and its further personalization.      
### 15.Integrated real-time supervisory management for off-normal-event handling and feedback control of tokamak plasmas  [ :arrow_down: ](https://arxiv.org/pdf/2010.16145.pdf)
>  For long-pulse tokamaks, one of the main challenges in control strategy is to simultaneously reach multiple control objectives and to robustly handle in real-time (RT) unexpected events (off-normal-events -- ONEs) with a limited set of actuators. We have developed in our previous work a generic architecture of the plasma control system (PCS) including a supervisor and an actuator manager to deal with these issues. We present in this paper recent developments of real-time decision-making by the supervisor to switch between different control scenarios (normal, backup, shutdown, disruption mitigation, etc.) during the discharge, based on off-normal-event states. We first standardize the evaluation of ONEs and thereby simplify significantly the supervisor decision logic, as well as facilitate the modifications and extensions of ONE states in the future. The whole PCS has been implemented on the TCV tokamak, applied to disruption avoidance with density limit experiments, demonstrating the excellent capabilities of the new RT integrated strategy.      
### 16.Beamforming for measurements under disturbed propagation conditions using numerically calculated Green's functions  [ :arrow_down: ](https://arxiv.org/pdf/2010.16140.pdf)
>  Beamforming methods for sound source localization are usually based on free-field Green's functions to model the sound propagation between source and microphone. This assumption is known to be incorrect for many industrial applications and the beamforming results can suffer from this inconsistency regarding both, accuracy of source power estimation, and accuracy of source localisation. The aim of this paper is to investigate whether the use of numerically calculated Green's functions can improve the results of beamforming measurements. <br>The current test cases of numerical and experimental investigations consists of sources placed in a short rectangular duct. The measurement is performed outside the duct in a semi-anechoic chamber. A typical example for this kind of installation is a fan with a heat exchanger. <br>The Green's functions for this test case are calculated numerically using the boundary element method. These tailored Green's functions are used to calculate the corresponding beamforming steering vectors. The weighting of the Green's functions in the steering vectors has a decisive influence on the beamforming results. A generalization of the common steering vector formulations is given based on two scalars. It is shown that arbitrary differentiable Green's functions can be used to find the correct source position or source power level by using the appropriate steering vector formulations. <br>Beamforming measurements are performed using a loudspeaker as a reference source at different positions in the heat exchanger duct. The measurements are evaluated in the frequency domain and by means of different validation criteria it can be shown that the results with the numerical calculated Green's function are improved compared to free field beamforming especially at low frequencies.      
### 17.Comparison of Speaker Role Recognition and Speaker Enrollment Protocol for conversational Clinical Interviews  [ :arrow_down: ](https://arxiv.org/pdf/2010.16131.pdf)
>  Conversations between a clinician and a patient, in natural conditions, are valuable sources of information for medical follow-up. The automatic analysis of these dialogues could help extract new language markers and speed-up the clinicians' reports. Yet, it is not clear which speech processing pipeline is the most performing to detect and identify the speaker turns, especially for individuals with speech and language disorders. Here, we proposed a split of the data that allows conducting a comparative evaluation of speaker role recognition and speaker enrollment methods to solve this task. We trained end-to-end neural network architectures to adapt to each task and evaluate each approach under the same metric. Experimental results are reported on naturalistic clinical conversations between Neuropsychologist and Interviewees, at different stages of Huntington's disease. We found that our Speaker Role Recognition model gave the best performances. In addition, our study underlined the importance of retraining models with in-domain data. Finally, we observed that results do not depend on the demographics of the Interviewee, highlighting the clinical relevance of our methods.      
### 18.Fixed-state Log-MAP detection for intensity-modulation and direct-detection optical systems over dispersion-uncompensated links  [ :arrow_down: ](https://arxiv.org/pdf/2010.16127.pdf)
>  In this paper, an optimized detection using log-maximum a posteriori estimation with a fixed number of surviving states (fixed-state Log-MAP) is proposed for a C-band 64-Gbit/s intensity-modulation and direct-detection (IM/DD) on-off keying (OOK) system over a 100-km dispersion-uncompensated link. For dispersion-uncompensated links, maximum likelihood sequence estimation (MLSE) is usually employed to deal with the severe inter-symbol interference (ISI) caused by chromatic dispersion. However, MLSE has an exponential increase in computational complexity and state storage with an increase in memory length, which overloads the computing resources and internal storage space of the hardware. Compared to MLSE, the fixed-state Log-MAP decreases the computational complexity and state storage from an exponential order of memory length to a linear order of surviving states. The memory length of fixed-state Log-MAP is no longer limited by computing resources and storage resources of the hardware, which has the potential to compensate larger ISI. The experimental results show that the optimal receiver sensitivity using fixed-state Log-MAP detection has a 2-dB improvement compared to that using MLSE. In conclusion, the fixed-state Log-MAP detection shows potential for practical IM/DD optical systems over dispersion-uncompensated links.      
### 19.Interference Reduction in Virtual Cell Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.16100.pdf)
>  Virtual cell optimization clusters cells into neighborhoods and performs optimized resource allocation over each neighborhood. In prior works we proposed resource allocation schemes to mitigate the interference caused by transmissions in the same virtual cell. This work aims at mitigating both the interference caused by the transmissions of users in the same virtual cell and the interference between transmissions in different virtual cells. We propose a resource allocation technique that reduces the number of users that cannot achieve their constant guaranteed bit rate, i.e., the "unsatisfied users", in an uplink virtual cell system with cooperative decoding. The proposed scheme requires only the knowledge of the number of users each base station serves and relies on creating the interference graph between base stations at the edges of virtual cells. Allocation of frequency bands to users is based on the number of users each base station would serve in a non cooperative setup. We evaluate the performance of our scheme for a mmWave system. Our numerical results show that our scheme decreases the number of users in the system whose rate falls below the guaranteed rate, set to $128$Kpbs, $256$Kpbs or $512$Kpbs, when compared with our previously proposed optimization methods.      
### 20.HHAR-net: Hierarchical Human Activity Recognition using Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.16052.pdf)
>  Activity recognition using built-in sensors in smart and wearable devices provides great opportunities to understand and detect human behavior in the wild and gives a more holistic view of individuals' health and well being. Numerous computational methods have been applied to sensor streams to recognize different daily activities. However, most methods are unable to capture different layers of activities concealed in human behavior. Also, the performance of the models starts to decrease with increasing the number of activities. This research aims at building a hierarchical classification with Neural Networks to recognize human activities based on different levels of abstraction. We evaluate our model on the Extrasensory dataset; a dataset collected in the wild and containing data from smartphones and smartwatches. We use a two-level hierarchy with a total of six mutually exclusive labels namely, "lying down", "sitting", "standing in place", "walking", "running", and "bicycling" divided into "stationary" and "non-stationary". The results show that our model can recognize low-level activities (stationary/non-stationary) with 95.8% accuracy and overall accuracy of 92.8% over six labels. This is 3% above our best performing baseline.      
### 21.NILM as a regression versus classification problem: the importance of thresholding  [ :arrow_down: ](https://arxiv.org/pdf/2010.16050.pdf)
>  Non-Intrusive Load Monitoring (NILM) aims to predict the status or consumption of domestic appliances in a household only by knowing the aggregated power load. NILM can be formulated as regression problem or most often as a classification problem. Most datasets gathered by smart meters allow to define naturally a regression problem, but the corresponding classification problem is a derived one, since it requires a conversion from the power signal to the status of each device by a thresholding method. We treat three different thresholding methods to perform this task, discussing their differences on various devices from the UK-DALE dataset. We analyze the performance of deep learning state-of-the-art architectures on both the regression and classification problems, introducing criteria to select the most convenient thresholding method.      
### 22.Millimeter-wave Multi-mode Circular Antenna Array for Uni-cast Multi-cast and OAM Communication  [ :arrow_down: ](https://arxiv.org/pdf/2010.16049.pdf)
>  This paper investigates multi-mode and orbital angular momentum (OAM) mode data transmission techniques by a using a circular antenna array, operating at 28 GHz. The classical mode excitation of the latter is modified such that in the horizontal plane the antenna array operates as multimode transmitter (i.e., it provides broad- , uni- and/or multi-cast transmission), while in the vertical direction OAM transmission occurs: this dual-functionality by a single antenna-array at 28 GHz is presented for the first time. Specifically, it can transmit/receive in either broad-, uni-, multi-cast mode in the horizontal plane and also, it is capable of generating up to 15 spatially orthogonal OAM modes in the vertical direction. The proposed circular array is designed using twelve, low-complexity, multi-layer microstrip patch antennas with high radiation efficiency. It was tested through full electromagnetic analysis in terms of impedance matching, mutual coupling and radiation pattern. It was, also, fabricated and measured: good agreement between simulated and measurement results was observed. The proposed antenna array is perfect candidate for high spectral efficiency data transmission for 5G and beyond wireless applications.      
### 23.CT-CAPS: Feature Extraction-based Automated Framework for COVID-19 Disease Identification from Chest CT Scans using Capsule Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.16043.pdf)
>  The global outbreak of the novel corona virus (COVID-19) disease has drastically impacted the world and led to one of the most challenging crisis across the globe since World War II. The early diagnosis and isolation of COVID-19 positive cases are considered as crucial steps towards preventing the spread of the disease and flattening the epidemic curve. Chest Computed Tomography (CT) scan is a highly sensitive, rapid, and accurate diagnostic technique that can complement Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Recently, deep learning-based models, mostly based on Convolutional Neural Networks (CNN), have shown promising diagnostic results. CNNs, however, are incapable of capturing spatial relations between image instances and require large datasets. Capsule Networks, on the other hand, can capture spatial relations, require smaller datasets, and have considerably fewer parameters. In this paper, a Capsule network framework, referred to as the "CT-CAPS", is presented to automatically extract distinctive features of chest CT scans. These features, which are extracted from the layer before the final capsule layer, are then leveraged to differentiate COVID-19 from Non-COVID cases. The experiments on our in-house dataset of 307 patients show the state-of-the-art performance with the accuracy of 90.8%, sensitivity of 94.5%, and specificity of 86.0%.      
### 24.COVID-FACT: A Fully-Automated Capsule Network-based Framework for Identification of COVID-19 Cases from Chest CT scans  [ :arrow_down: ](https://arxiv.org/pdf/2010.16041.pdf)
>  The newly discovered Corona virus Disease 2019 (COVID-19) has been globally spreading and causing hundreds of thousands of deaths around the world as of its first emergence in late 2019. Computed tomography (CT) scans have shown distinctive features and higher sensitivity compared to other diagnostic tests, in particular the current gold standard, i.e., the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Current deep learning-based algorithms are mainly developed based on Convolutional Neural Networks (CNNs) to identify COVID-19 pneumonia cases. CNNs, however, require extensive data augmentation and large datasets to identify detailed spatial relations between image instances. Furthermore, existing algorithms utilizing CT scans, either extend slice-level predictions to patient-level ones using a simple thresholding mechanism or rely on a sophisticated infection segmentation to identify the disease. In this paper, we propose a two-stage fully-automated CT-based framework for identification of COVID-19 positive cases referred to as the "COVID-FACT". COVID-FACT utilizes Capsule Networks, as its main building blocks and is, therefore, capable of capturing spatial information. In particular, to make the proposed COVID-FACT independent from sophisticated segmentation of the area of infection, slices demonstrating infection are detected at the first stage and the second stage is responsible for classifying patients into COVID and non-COVID cases. COVID-FACT detects slices with infection, and identifies positive COVID-19 cases using an in-house CT scan dataset, containing COVID-19, community acquired pneumonia, and normal cases. Based on our experiments, COVID-FACT achieves an accuracy of 90.82%, a sensitivity of 94.55%, a specificity of 86.04%, and an Area Under the Curve (AUC) of 0.98, while depending on far less supervision and annotation, in comparison to its counterparts.      
### 25.FLANNEL: Focal Loss Based Neural Network Ensemble for COVID-19 Detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.16039.pdf)
>  To test the possibility of differentiating chest x-ray images of COVID-19 against other pneumonia and healthy patients using deep neural networks. We construct the X-ray imaging data from two publicly available sources, which include 5508 chest x-ray images across 2874 patients with four classes: normal, bacterial pneumonia, non-COVID-19 viral pneumonia, and COVID-19. To identify COVID-19, we propose a Focal Loss Based Neural Ensemble Network (FLANNEL), a flexible module to ensemble several convolutional neural network (CNN) models and fuse with a focal loss for accurate COVID-19 detection on class imbalance data. FLANNEL consistently outperforms baseline models on COVID-19 identification task in all metrics. Compared with the best baseline, FLANNEL shows a higher macro-F1 score with 6% relative increase on Covid-19 identification task where it achieves 0.7833(0.07) in Precision, 0.8609(0.03) in Recall, and 0.8168(0.03) F1 score.      
### 26.Adversarial defense for deep speaker recognition using hybrid adversarial training  [ :arrow_down: ](https://arxiv.org/pdf/2010.16038.pdf)
>  Deep neural network based speaker recognition systems can easily be deceived by an adversary using minuscule imperceptible perturbations to the input speech samples. These adversarial attacks pose serious security threats to the speaker recognition systems that use speech biometric. To address this concern, in this work, we propose a new defense mechanism based on a hybrid adversarial training (HAT) setup. In contrast to existing works on countermeasures against adversarial attacks in deep speaker recognition that only use class-boundary information by supervised cross-entropy (CE) loss, we propose to exploit additional information from supervised and unsupervised cues to craft diverse and stronger perturbations for adversarial training. Specifically, we employ multi-task objectives using CE, feature-scattering (FS), and margin losses to create adversarial perturbations and include them for adversarial training to enhance the robustness of the model. We conduct speaker recognition experiments on the Librispeech dataset, and compare the performance with state-of-the-art projected gradient descent (PGD)-based adversarial training which employs only CE objective. The proposed HAT improves adversarial accuracy by absolute 3.29% and 3.18% for PGD and Carlini-Wagner (CW) attacks respectively, while retaining high accuracy on benign examples.      
### 27.Considerations in the Automatic Development of Electric Grid Restoration Plans  [ :arrow_down: ](https://arxiv.org/pdf/2010.16035.pdf)
>  Power system restoration is a highly complex task that must be performed in a timely manner following a blackout. It is crucial to have the capability of developing a reliable restoration plan that can be adjusted quickly to different system conditions. This paper introduces a framework of an automated process that creates a restoration plan for a given power system. The required input includes the original system data under normal operating conditions and the status of the resources in the system that can be used for restoration. With a set of criteria to select as an option, the presented process can produce a restoration sequence in terms of which generator, load, branches, and breakers to close until a stopping criterion is met. The algorithm of the restoration process is described, and its application to a synthetic 200-bus case provides a restoration sequence from blackstart generating units to critical loads first and then to the rest of the system without violating any limits for frequency, voltage and branch loading.      
### 28.Mixed-Integer Optimization for Bio-Inspired Robust Power Network Design  [ :arrow_down: ](https://arxiv.org/pdf/2010.16033.pdf)
>  Power systems are susceptible to natural threats including hurricanes and floods. Modern power grids are also increasingly threatened by cyber attacks. Existing approaches that help improve power system security and resilience may not be sufficient; this is evidenced by the continued challenge to supply energy to all customers during severe events. This paper presents an approach to address this challenge through bio-inspired power system network design to improve system reliability and resilience against disturbances. Inspired by naturally robust ecosystems, this paper considers the optimal ecological robustness that recognizes a unique balance between pathway efficiency and redundancy to ensure the survivability against disruptive events for given networks. This paper presents an approach that maximizes ecological robustness in transmission network design by formulating a mixed-integer nonlinear programming optimization problem with power system constraints. The results show the increase of the optimized power system's robustness and the improved reliability with less violations under N-x contingencies.      
### 29.PIINET: A 360-degree Panoramic Image Inpainting Network Using a Cube Map  [ :arrow_down: ](https://arxiv.org/pdf/2010.16003.pdf)
>  Inpainting has been continuously studied in the field of computer vision. As artificial intelligence technology developed, deep learning technology was introduced in inpainting research, helping to improve performance. Currently, the input target of an inpainting algorithm using deep learning has been studied from a single image to a video. However, deep learning-based inpainting technology for panoramic images has not been actively studied. We propose a 360-degree panoramic image inpainting method using generative adversarial networks (GANs). The proposed network inputs a 360-degree equirectangular format panoramic image converts it into a cube map format, which has relatively little distortion and uses it as a training network. Since the cube map format is used, the correlation of the six sides of the cube map should be considered. Therefore, all faces of the cube map are used as input for the whole discriminative network, and each face of the cube map is used as input for the slice discriminative network to determine the authenticity of the generated image. The proposed network performed qualitatively better than existing single-image inpainting algorithms and baseline algorithms.      
### 30.Guaranteeing Safety of Learned Perception Modules via Measurement-Robust Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2010.16001.pdf)
>  Modern nonlinear control theory seeks to develop feedback controllers that endow systems with properties such as safety and stability. The guarantees ensured by these controllers often rely on accurate estimates of the system state for determining control actions. In practice, measurement model uncertainty can lead to error in state estimates that degrades these guarantees. In this paper, we seek to unify techniques from control theory and machine learning to synthesize controllers that achieve safety in the presence of measurement model uncertainty. We define the notion of a Measurement-Robust Control Barrier Function (MR-CBF) as a tool for determining safe control inputs when facing measurement model uncertainty. Furthermore, MR-CBFs are used to inform sampling methodologies for learning-based perception systems and quantify tolerable error in the resulting learned models. We demonstrate the efficacy of MR-CBFs in achieving safety with measurement model uncertainty on a simulated Segway system.      
### 31.Spline-Based Adaptive Cancellation of Even-Order Intermodulation Distortions in LTE-A/5G RF Transceivers  [ :arrow_down: ](https://arxiv.org/pdf/2010.15998.pdf)
>  Radio frequency transceivers operating in in-band full-duplex or frequency-division duplex mode experience strong transmitter leakage. Combined with receiver nonlinearities, this causes intermodulation products in the baseband (BB), possibly with higher power than the desired receive signal. In order to restore the receiver signal-to-noise ratio in such scenarios, we propose two novel digital self-interference cancellation approaches based on spline interpolation. Both employ a Wiener structure, thereby matching the BB model of the intermodulation effect. Unlike most state-of-the-art spline-based adaptive learning schemes, we allow for complex-valued in- and output signals. The optimization of the model parameters is based on the stochastic gradient descent concept, where the convergence is supported by an appropriate step-size normalization. Additionally, we provide further extensions that facilitate a hardware implementation and improve the performance consistency for correlated input data. In a realistic interference scenario, the proposed algorithms clearly outperform the IM2LMS, a state-of-the-art algorithm with comparable complexity specifically tailored to second-order intermodulation distortions. The high flexiblity of the spline interpolation allows the spline Wiener models to get close to the kernel recursive least squares algorithm at less than 0.5 % of the arithmetic operations.      
### 32.AutoAtlas: Neural Network for 3D Unsupervised Partitioning and Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.15987.pdf)
>  We present a novel neural network architecture called AutoAtlas for fully unsupervised partitioning and representation learning of 3D brain Magnetic Resonance Imaging (MRI) volumes. AutoAtlas consists of two neural network components: one that performs multi-label partitioning based on local texture in the volume and a second that compresses the information contained within each partition. We train both of these components simultaneously by optimizing a loss function that is designed to promote accurate reconstruction of each partition, while encouraging spatially smooth and contiguous partitioning, and discouraging relatively small partitions. We show that the partitions adapt to the subject specific structural variations of brain tissue while consistently appearing at similar spatial locations across subjects. AutoAtlas also produces very low dimensional features that represent local texture of each partition. We demonstrate prediction of metadata associated with each subject using the derived feature representations and compare the results to prediction using features derived from FreeSurfer anatomical parcellation. Since our features are intrinsically linked to distinct partitions, we can then map values of interest, such as partition-specific feature importance scores onto the brain for visualization.      
### 33.Transfer Learning improves MI BCI models classification accuracy in Parkinson's disease patients  [ :arrow_down: ](https://arxiv.org/pdf/2010.15899.pdf)
>  Motor-Imagery based BCI (MI-BCI) neurorehabilitation can improve locomotor ability and reduce the deficit symptoms in Parkinson's Disease patients. Advanced Motor-Imagery BCI methods are needed to overcome the accuracy and time-related MI BCI calibration challenges in such patients. In this study, we proposed a Multi-session FBCSP (msFBCSP) based on inter-session transfer learning and we investigated its performance compared to the single-session based FBSCP. The main result of this study is the significantly improved accuracy obtained by proposed msFBCSP compared to single-session FBCSP in PD patients (median 81.3%, range 41.2-100.0% vs median 61.1%, range 25.0-100.0%, respectively; p&lt;0.001). In conclusion, this study proposes a transfer learning-based multi-session based FBCSP approach which allowed to significantly improve calibration accuracy in MI BCI performed on PD patients.      
### 34.Identification of Ischemic Heart Disease by using machine learning technique based on parameters measuring Heart Rate Variability  [ :arrow_down: ](https://arxiv.org/pdf/2010.15893.pdf)
>  The diagnosis of heart diseases is a difficult task generally addressed by an appropriate examination of patients clinical data. Recently, the use of heart rate variability (HRV) analysis as well as of some machine learning algorithms, has proved to be a valuable support in the diagnosis process. However, till now, ischemic heart disease (IHD) has been diagnosed on the basis of Artificial Neural Networks (ANN) applied only to signs, symptoms and sequential ECG and coronary angiography, an invasive tool, while could be probably identified in a non-invasive way by using parameters extracted from HRV, a signal easily obtained from the ECG. In this study, 18 non-invasive features (age, gender, left ventricular ejection fraction and 15 obtained from HRV) of 243 subjects (156 normal subjects and 87 IHD patients) were used to train and validate a series of several ANN, different for number of input and hidden nodes. The best result was obtained using 7 input parameters and 7 hidden nodes with an accuracy of 98.9% and 82% for the training and validation dataset, respectively.      
### 35.Ink Marker Segmentation in Histopathology Images Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.15865.pdf)
>  Due to the recent advancements in machine vision, digital pathology has gained significant attention. Histopathology images are distinctly rich in visual information. The tissue glass slide images are utilized for disease diagnosis. Researchers study many methods to process histopathology images and facilitate fast and reliable diagnosis; therefore, the availability of high-quality slides becomes paramount. The quality of the images can be negatively affected when the glass slides are ink-marked by pathologists to delineate regions of interest. As an example, in one of the largest public histopathology datasets, The Cancer Genome Atlas (TCGA), approximately $12\%$ of the digitized slides are affected by manual delineations through ink markings. To process these open-access slide images and other repositories for the design and validation of new methods, an algorithm to detect the marked regions of the images is essential to avoid confusing tissue pixels with ink-colored pixels for computer methods. In this study, we propose to segment the ink-marked areas of pathology patches through a deep network. A dataset from $79$ whole slide images with $4,305$ patches was created and different networks were trained. Finally, the results showed an FPN model with the EffiecentNet-B3 as the backbone was found to be the superior configuration with an F1 score of $94.53\%$.      
### 36.Three-dimensional coherent Bragg imaging of rotating nanoparticles  [ :arrow_down: ](https://arxiv.org/pdf/2010.16374.pdf)
>  Bragg Coherent Diffraction Imaging (BCDI) is a powerful strain imaging tool, often limited by beam-induced sample instability for small particles and high power densities. Here, we devise and validate an adapted diffraction volume assembly algorithm, capable of recovering three-dimensional datasets from particles undergoing uncontrolled and unknown rotations. We apply the method to gold nanoparticles which rotate under the influence of a focused coherent X-ray beam, retrieving their three-dimensional shapes and strain fields. The results show that the sample instability problem can be overcome, enabling the use of fourth generation synchrotron sources for BCDI to their full potential.      
### 37.Phoneme Based Neural Transducer for Large Vocabulary Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.16368.pdf)
>  To join the advantages of classical and end-to-end approaches for speech recognition, we present a simple, novel and competitive approach for phoneme-based neural transducer modeling. Different alignment label topologies are compared and word-end-based phoneme label augmentation is proposed to improve performance. Utilizing the local dependency of phonemes, we adopt a simplified neural network structure and a straightforward integration with the external word-level language model to preserve the consistency of seq-to-seq modeling. We also present a simple, stable and efficient training procedure using frame-wise cross-entropy loss. A phonetic context size of one is shown to be sufficient for the best performance. A simplified scheduled sampling approach is applied for further improvement. We also briefly compare different decoding approaches. The overall performance of our best model is comparable to state-of-the-art results for the TED-LIUM Release 2 and Switchboard corpora.      
### 38.Robust Quadrupedal Locomotion on Sloped Terrains: A Linear Policy Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.16342.pdf)
>  In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch $2$. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to external pushes and terrain slope variations. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach.      
### 39.DeepWay: a Deep Learning Estimator for Unmanned Ground Vehicle Global Path Planning  [ :arrow_down: ](https://arxiv.org/pdf/2010.16322.pdf)
>  Agriculture 3.0 and 4.0 have gradually introduced service robotics and automation into several agricultural processes, mostly improving crops quality and seasonal yield. Row-based crops are the perfect settings to test and deploy smart machines capable of monitoring and manage the harvest. In this context, global path planning is essential either for ground or aerial vehicles, and it is the starting point for every type of mission plan. Nevertheless, little attention has been currently given to this problem by the research community and global path planning automation is still far to be solved. In order to generate a viable path for an autonomous machine, the presented research proposes a feature learning fully convolutional model capable of estimating waypoints given an occupancy grid map. In particular, we apply the proposed data-driven methodology to the specific case of row-based crops with the general objective to generate a global path able to cover the extension of the crop completely. Extensive experimentation with a custom made synthetic dataset and real satellite-derived images of different scenarios have proved the effectiveness of our methodology and demonstrated the feasibility of an end-to-end and completely autonomous global path planner.      
### 40.Robust Localization in Wireless Networks From Corrupted Signals  [ :arrow_down: ](https://arxiv.org/pdf/2010.16297.pdf)
>  We address the problem of timing-based localization in wireless networks, when an unknown fraction of data is corrupted by nonideal signal conditions. While timing-based techniques enable accurate localization, they are also sensitive to such corrupted data. We develop a robust method that is applicable to a range of localization techniques, including time-of-arrival, time-difference-of-arrival and time-difference in schedule-based transmissions. The method is nonparametric and requires only an upper bound on the fraction of corrupted data, thus obviating distributional assumptions of the corrupting noise distribution. The robustness of the method is demonstrated in numerical experiments.      
### 41.How Does Performance Scale with Antenna Number for Extremely Large-Scale MIMO?  [ :arrow_down: ](https://arxiv.org/pdf/2010.16232.pdf)
>  Extremely large-scale multiple-input multiple-output (XL-MIMO) communications correspond to systems whose antenna size is so large that conventional assumptions, such as uniform plane wave (UPW) impingement, are no longer valid. This paper studies the channel modelling and performance analysis of XL-MIMO communication based on the generic spherical wavefront propagation model. First, for the single-user uplink/downlink communication with the optimal maximum ratio combining/transmission (MRC/MRT), we rigorously derive a new closed-form expression for the resulting signal-to-noise ratio (SNR), which includes the conventional SNR expression based on UPW assumption as a special case. Our result shows that instead of scaling linearly with the base station (BS) antenna number $M$, the SNR with the more generic spherical wavefront model increases with $M$ with diminishing return, governed by a new parameter called angular span. One important finding from our derivation is the necessity to introduce a new distance criterion, termed critical distance, to complement the classical Rayleigh distance for separating the near- and far-field propagation regions. While Rayleigh distance is based on the phase difference across array elements and hence depends on the electrical size of the antenna, the critical distance cares about the amplitude/power difference and only depends on its physical size. We then extend the study to the multi-user XL-MIMO communication system, for which we demonstrate that inter-user interference (IUI) can be mitigated not just by angle separation, but also by distance separation along the same direction. This offers one new degree of freedom (DoF) for interference suppression with XL-MIMO.      
### 42.Multiplicative Updates for NMF with $$-Divergences under Disjoint Equality Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2010.16223.pdf)
>  Nonnegative matrix factorization (NMF) is the problem of approximating an input nonnegative matrix, $V$, as the product of two smaller nonnegative matrices, $W$ and $H$. In this paper, we introduce a general framework to design multiplicative updates (MU) for NMF based on $\beta$-divergences ($\beta$-NMF) with disjoint equality constraints, and with penalty terms in the objective function. By disjoint, we mean that each variable appears in at most one equality constraint. Our MU satisfy the set of constraints after each update of the variables during the optimization process, while guaranteeing that the objective function decreases monotonically. We showcase this framework on three NMF models, and show that it competes favorably the state of the art: (1)~$\beta$-NMF with sum-to-one constraints on the columns of $H$, (2) minimum-volume $\beta$-NMF with sum-to-one constraints on the columns of $W$, and (3) sparse $\beta$-NMF with $\ell_2$-norm constraints on the columns of $W$.      
### 43.HOI Analysis: Integrating and Decomposing Human-Object Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2010.16219.pdf)
>  Human-Object Interaction (HOI) consists of human, object and implicit interaction/verb. Different from previous methods that directly map pixels to HOI semantics, we propose a novel perspective for HOI learning in an analytical manner. In analogy to Harmonic Analysis, whose goal is to study how to represent the signals with the superposition of basic waves, we propose the HOI Analysis. We argue that coherent HOI can be decomposed into isolated human and object. Meanwhile, isolated human and object can also be integrated into coherent HOI again. Moreover, transformations between human-object pairs with the same HOI can also be easier approached with integration and decomposition. As a result, the implicit verb will be represented in the transformation function space. In light of this, we propose an Integration-Decomposition Network (IDN) to implement the above transformations and achieve state-of-the-art performance on widely-used HOI detection benchmarks. Code is available at <a class="link-external link-https" href="https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network)" rel="external noopener nofollow">this https URL</a>.      
### 44.Statistical Analysis of Signal-Dependent Noise: Application in Blind Localization of Image Splicing Forgery  [ :arrow_down: ](https://arxiv.org/pdf/2010.16211.pdf)
>  Visual noise is often regarded as a disturbance in image quality, whereas it can also provide a crucial clue for image-based forensic tasks. Conventionally, noise is assumed to comprise an additive Gaussian model to be estimated and then used to reveal anomalies. However, for real sensor noise, it should be modeled as signal-dependent noise (SDN). In this work, we apply SDN to splicing forgery localization tasks. Through statistical analysis of the SDN model, we assume that noise can be modeled as a Gaussian approximation for a certain brightness and propose a likelihood model for a noise level function. By building a maximum a posterior Markov random field (MAP-MRF) framework, we exploit the likelihood of noise to reveal the alien region of spliced objects, with a probability combination refinement strategy. To ensure a completely blind detection, an iterative alternating method is adopted to estimate the MRF parameters. Experimental results demonstrate that our method is effective and provides a comparative localization performance.      
### 45.Pattern-matching Unit for Medical Applications  [ :arrow_down: ](https://arxiv.org/pdf/2010.16207.pdf)
>  We explore the application of concepts developed in High Energy Physics (HEP) for advanced medical data analysis. <br>Our study case is a problem with high social impact: clinically-feasible Magnetic Resonance Fingerprinting (MRF). MRF is a new, quantitative, imaging technique that replaces multiple qualitative Magnetic Resonance Imaging (MRI) exams with a single, reproducible measurement for increased sensitivity and efficiency. A fast acquisition is followed by a pattern matching (PM) task, where signal responses are matched to entries from a dictionary of simulated, physically-feasible responses, yielding multiple tissue parameters simultaneously. Each pixel signal response in the volume is compared through scalar products with all dictionary entries to choose the best measurement reproduction. MRF is limited by the PM processing time, which scales exponentially with the dictionary dimensionality, i.e. with the number of tissue parameters to be reconstructed. We developed for HEP a powerful, compact, embedded system, optimized for extremely fast PM. This system executes real-time tracking for online event selection in the HEP experiments, exploiting maximum parallelism and pipelining. Track reconstruction is executed in two steps. The Associative Memory (AM) ASIC first implements a PM algorithm by recognizing track candidates at low resolution. The second step, which is implemented into FPGAs (Field Programmable Gate Arrays), refines the AM output finding the track parameters at full resolution. <br>We propose to use this system to perform MRF, to achieve clinically reasonable reconstruction time. This paper proposes an adaptation of the HEP system for medical imaging and shows some preliminary results.      
### 46.AudVowelConsNet: A Phoneme-Level Based Deep CNN Architecture for Clinical Depression Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2010.16201.pdf)
>  Depression is a common and serious mood disorder that negatively affects the patient's capacity of functioning normally in daily tasks. Speech is proven to be a vigorous tool in depression diagnosis. Research in psychiatry concentrated on performing fine-grained analysis on word-level speech components contributing to the manifestation of depression in speech and revealed significant variations at the phoneme-level in depressed speech. On the other hand, research in Machine Learning-based automatic recognition of depression from speech focused on the exploration of various acoustic features for the detection of depression and its severity level. Few have focused on incorporating phoneme-level speech components in automatic assessment systems. In this paper, we propose an Artificial Intelligence (AI) based application for clinical depression recognition and assessment from speech. We investigate the acoustic characteristics of phoneme units, specifically vowels and consonants for depression recognition via Deep Learning. We present and compare three spectrogram-based Deep Neural Network architectures, trained on phoneme consonant and vowel units and their fusion respectively. Our experiments show that the deep learned consonant-based acoustic characteristics lead to better recognition results than vowel-based ones. The fusion of vowel and consonant speech characteristics through a deep network significantly outperforms the single space networks as well as the state-of-art deep learning approaches on the DAIC-WOZ database.      
### 47.End-to-end Animal Image Matting  [ :arrow_down: ](https://arxiv.org/pdf/2010.16188.pdf)
>  Extracting accurate foreground animals from natural animal images benefits many downstream applications such as film production and augmented reality. However, the various appearance and furry characteristics of animals challenge existing matting methods, which usually require extra user inputs such as trimap or scribbles. To resolve these problems, we study the distinct roles of semantics and details for image matting and decompose the task into two parallel sub-tasks: high-level semantic segmentation and low-level details matting. Specifically, we propose a novel Glance and Focus Matting network (GFM), which employs a shared encoder and two separate decoders to learn both tasks in a collaborative manner for end-to-end animal image matting. Besides, we establish a novel Animal Matting dataset (AM-2k) containing 2,000 high-resolution natural animal images from 20 categories along with manually labeled alpha mattes. Furthermore, we investigate the domain gap issue between composite images and natural images systematically by conducting comprehensive analyses of various discrepancies between foreground and background images. We find that a carefully designed composition route RSSN that aims to reduce the discrepancies can lead to a better model with remarkable generalization ability. Comprehensive empirical studies on AM-2k demonstrate that GFM outperforms state-of-the-art methods and effectively reduces the generalization error.      
### 48.Deep Speaker Vector Normalization with Maximum Gaussianality Training  [ :arrow_down: ](https://arxiv.org/pdf/2010.16148.pdf)
>  Deep speaker embedding represents the state-of-the-art technique for speaker recognition. A key problem with this approach is that the resulting deep speaker vectors tend to be irregularly distributed. In previous research, we proposed a deep normalization approach based on a new discriminative normalization flow (DNF) model, by which the distributions of individual speakers are arguably transformed to homogeneous Gaussians. This normalization was demonstrated to be effective, but despite this remarkable success, we empirically found that the latent codes produced by the DNF model are generally neither homogeneous nor Gaussian, although the model has assumed so. In this paper, we argue that this problem is largely attributed to the maximum-likelihood (ML) training criterion of the DNF model, which aims to maximize the likelihood of the observations but not necessarily improve the Gaussianality of the latent codes. We therefore propose a new Maximum Gaussianality (MG) training approach that directly maximizes the Gaussianality of the latent codes. Our experiments on two data sets, SITW and CNCeleb, demonstrate that our new MG training approach can deliver much better performance than the previous ML training, and exhibits improved domain generalizability, particularly with regard to cosine scoring.      
### 49.Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.16119.pdf)
>  Panoptic segmentation is posed as a new popular test-bed for the state-of-the-art holistic scene understanding methods with the requirement of simultaneously segmenting both foreground things and background stuff. The state-of-the-art panoptic segmentation network exhibits high structural complexity in different network components, i.e. backbone, proposal-based foreground branch, segmentation-based background branch, and feature fusion module across branches, which heavily relies on expert knowledge and tedious trials. In this work, we propose an efficient, cooperative and highly automated framework to simultaneously search for all main components including backbone, segmentation branches, and feature fusion module in a unified panoptic segmentation pipeline based on the prevailing one-shot Network Architecture Search (NAS) paradigm. Notably, we extend the common single-task NAS into the multi-component scenario by taking the advantage of the newly proposed intra-modular search space and problem-oriented inter-modular search space, which helps us to obtain an optimal network architecture that not only performs well in both instance segmentation and semantic segmentation tasks but also be aware of the reciprocal relations between foreground things and background stuff classes. To relieve the vast computation burden incurred by applying NAS to complicated network architectures, we present a novel path-priority greedy search policy to find a robust, transferrable architecture with significantly reduced searching overhead. Our searched architecture, namely Auto-Panoptic, achieves the new state-of-the-art on the challenging COCO and ADE20K benchmarks. Moreover, extensive experiments are conducted to demonstrate the effectiveness of path-priority policy and transferability of Auto-Panoptic across different datasets. Codes and models are available at: <a class="link-external link-https" href="https://github.com/Jacobew/AutoPanoptic" rel="external noopener nofollow">this https URL</a>.      
### 50.Mixed platoon control of automated and human-driven vehicles at a signalized intersection: dynamical analysis and optimal control  [ :arrow_down: ](https://arxiv.org/pdf/2010.16105.pdf)
>  The emergence of Connected and Automated Vehicles (CAVs) promises better traffic mobility for future transportation systems. Existing research mostly focused on fully-autonomous scenarios, while the potential of CAV control at a mixed traffic intersection where human-driven vehicles (HDVs) also exist has been less explored. This paper proposes a notion of "1+n" mixed platoon, consisting of one leading CAV and n following HDVs, and formulates a platoon-based optimal control framework for CAV control at a signalized intersection. Based on the linearized dynamics model of the "1+n" mixed platoon, fundamental properties including stability and controllability are under rigorous theoretical analysis. Then, a constrained optimal control framework is established, aiming at improving the global traffic efficiency and fuel consumption at the intersection via direct control of the CAV. A hierarchical event-triggered algorithm is also designed for practical implementation of the optimal control method between adjacent mixed platoons when approaching the intersection. Extensive numerical simulations at multiple traffic volumes and market penetration rates validate the greater benefits of the mixed platoon based method, compared with traditional trajectory optimization methods for one single CAV.      
### 51.LIFI: Towards Linguistically Informed Frame Interpolation  [ :arrow_down: ](https://arxiv.org/pdf/2010.16078.pdf)
>  In this work, we explore a new problem of frame interpolation for speech videos. Such content today forms the major form of online communication. We try to solve this problem by using several deep learning video generation algorithms to generate the missing frames. We also provide examples where computer vision models despite showing high performance on conventional non-linguistic metrics fail to accurately produce faithful interpolation of speech. With this motivation, we provide a new set of linguistically-informed metrics specifically targeted to the problem of speech videos interpolation. We also release several datasets to test computer vision video generation models of their speech understanding.      
### 52.CNN based Multistage Gated Average Fusion (MGAF) for Human Action Recognition Using Depth and Inertial Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2010.16073.pdf)
>  Convolutional Neural Network (CNN) provides leverage to extract and fuse features from all layers of its architecture. However, extracting and fusing intermediate features from different layers of CNN structure is still uninvestigated for Human Action Recognition (HAR) using depth and inertial sensors. To get maximum benefit of accessing all the CNN's layers, in this paper, we propose novel Multistage Gated Average Fusion (MGAF) network which extracts and fuses features from all layers of CNN using our novel and computationally efficient Gated Average Fusion (GAF) network, a decisive integral element of MGAF. At the input of the proposed MGAF, we transform the depth and inertial sensor data into depth images called sequential front view images (SFI) and signal images (SI) respectively. These SFI are formed from the front view information generated by depth data. CNN is employed to extract feature maps from both input modalities. GAF network fuses the extracted features effectively while preserving the dimensionality of fused feature as well. The proposed MGAF network has structural extensibility and can be unfolded to more than two modalities. Experiments on three publicly available multimodal HAR datasets demonstrate that the proposed MGAF outperforms the previous state of the art fusion methods for depth-inertial HAR in terms of recognition accuracy while being computationally much more efficient. We increase the accuracy by an average of 1.5 percent while reducing the computational cost by approximately 50 percent over the previous state of the art.      
### 53.T-vectors: Weakly Supervised Speaker Identification Using Hierarchical Transformer Model  [ :arrow_down: ](https://arxiv.org/pdf/2010.16071.pdf)
>  Identifying multiple speakers without knowing where a speaker's voice is in a recording is a challenging task. This paper proposes a hierarchical network with transformer encoders and memory mechanism to address this problem. The proposed model contains a frame-level encoder and segment-level encoder, both of them make use of the transformer encoder block. The multi-head attention mechanism in the transformer structure could better capture different speaker properties when the input utterance contains multiple speakers. The memory mechanism used in the frame-level encoders can build a recurrent connection that better capture long-term speaker features. The experiments are conducted on artificial datasets based on the Switchboard Cellular part1 (SWBC) and Voxceleb1 datasets. In different data construction scenarios (Concat and Overlap), the proposed model shows better performance comparaing with four strong baselines, reaching 13.3% and 10.5% relative improvement compared with H-vectors and S-vectors. The use of memory mechanism could reach 10.6% and 7.7% relative improvement compared with not using memory mechanism.      
### 54.Multimodal Metric Learning for Tag-based Music Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2010.16030.pdf)
>  Tag-based music retrieval is crucial to browse large-scale music libraries efficiently. Hence, automatic music tagging has been actively explored, mostly as a classification task, which has an inherent limitation: a fixed vocabulary. On the other hand, metric learning enables flexible vocabularies by using pretrained word embeddings as side information. Also, metric learning has already proven its suitability for cross-modal retrieval tasks in other domains (e.g., text-to-image) by jointly learning a multimodal embedding space. In this paper, we investigate three ideas to successfully introduce multimodal metric learning for tag-based music retrieval: elaborate triplet sampling, acoustic and cultural music information, and domain-specific word embeddings. Our experimental results show that the proposed ideas enhance the retrieval system quantitatively, and qualitatively. Furthermore, we release the MSD500, a subset of the Million Song Dataset (MSD) containing 500 cleaned tags, 7 manually annotated tag categories, and user taste profiles.      
### 55.Latent Space Oddity: Exploring Latent Spaces to Design Guitar Timbres  [ :arrow_down: ](https://arxiv.org/pdf/2010.15989.pdf)
>  We introduce a novel convolutional network architecture with an interpretable latent space for modeling guitar amplifiers. Leveraging domain knowledge of popular amplifiers spanning a range of styles, the proposed system intuitively combines or subtracts characteristics of different amplifiers, allowing musicians to design entirely new guitar timbres.      
### 56.An Efficient QAM Detection via Nonlinear Post-distortion for SC-FDE Transmission under PA Impairments with Memory  [ :arrow_down: ](https://arxiv.org/pdf/2010.15940.pdf)
>  In this paper, we propose a novel receiver structure for single carrier transmission with frequency domain equalization (FDE) that is exposed to power amplifier (PA) nonlinearities. A two stage approach is adopted, in which linear communication channel is equalized at first stage and it is followed by a post-distortion unit where nonlinear distortion is reduced. In literature, there are some techniques that are proposed for the memoryless compensation of nonlinear distortion together with FDE. However, in this study, we show that even if a memoryless nonlinearity is utilized, received signal is impaired by nonlinear inter-symbol interference (ISI). Therefore, we propose a class of post-distortion techniques, which use neighbouring received symbols to supress the nonlinear interference. Two different, post-distortion techniques, namely Gaussian process regression (GPR) and neural network (NN) based post-distorters, are considered. In addition, a receiver structure, combining outputs of fractional delayed bank of FDE's, is proposed to overcome performance degradation problem of FDE for highly frequency selective channels under nonlinear distortion. Performance of the proposed techniques are compared with that of the state-of-the-art techniques in terms of bit error rate (BER) and achievable information rate (AIR) metrics via simulations. Simulation results demonstrate that GPR and NN based post-distortion methods outperform state-of-the-art techniques. Lastly, it is observed that proposed receiver architecture performs very close to linear system with the help of proposed fractionally delayed FDE bank.      
### 57.Perception Matters: Exploring Imperceptible and Transferable Anti-forensics for GAN-generated Fake Face Imagery Detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.15886.pdf)
>  Recently, generative adversarial networks (GANs) can generate photo-realistic fake facial images which are perceptually indistinguishable from real face photos, promoting research on fake face detection. Though fake face forensics can achieve high detection accuracy, their anti-forensic counterparts are less investigated. Here we explore more \textit{imperceptible} and \textit{transferable} anti-forensics for fake face imagery detection based on adversarial attacks. Since facial and background regions are often smooth, even small perturbation could cause noticeable perceptual impairment in fake face images. Therefore it makes existing adversarial attacks ineffective as an anti-forensic method. Our perturbation analysis reveals the intuitive reason of the perceptual degradation issue when directly applying existing attacks. We then propose a novel adversarial attack method, better suitable for image anti-forensics, in the transformed color domain by considering visual perception. Simple yet effective, the proposed method can fool both deep learning and non-deep learning based forensic detectors, achieving higher attack success rate and significantly improved visual quality. Specially, when adversaries consider imperceptibility as a constraint, the proposed anti-forensic method can improve the average attack success rate by around 30\% on fake face images over two baseline attacks. \textit{More imperceptible} and \textit{more transferable}, the proposed method raises new security concerns to fake face imagery detection. We have released our code for public use, and hopefully the proposed method can be further explored in related forensic applications as an anti-forensic benchmark.      
### 58.Acoustic Correlates of the Voice Qualifiers: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2010.15869.pdf)
>  Our voices are as distinctive as our faces and fingerprints. There is a spectrum of non-disjoint traits that make our voices unique and identifiable, such as the fundamental frequency, the intensity, and most interestingly the quality of the speech. Voice quality refers to the characteristic features of an individual's voice. Previous research has from time-to-time proven the ubiquity of voice quality in making different paralinguistic inferences. These inferences range from identifying personality traits, to health conditions and beyond. In this manuscript, we first map the paralinguistic voice qualifiers to their acoustic correlates in the light of the previous research and literature. We also determine the openSMILE correlates one could possibly use to measure those correlates. In the second part, we give a set of example paralinguistic inferences that can be made using different acoustic and perceptual voice quality features.      
### 59.Low-Rank Matrix Recovery with Scaled Subgradient Methods: Fast and Robust Convergence Without the Condition Number  [ :arrow_down: ](https://arxiv.org/pdf/2010.13364.pdf)
>  Many problems in data science can be treated as estimating a low-rank matrix from highly incomplete, sometimes even corrupted, observations. One popular approach is to resort to matrix factorization, where the low-rank matrix factors are optimized via first-order methods over a smooth loss function, such as the residual sum of squares. While tremendous progresses have been made in recent years, the natural smooth formulation suffers from two sources of ill-conditioning, where the iteration complexity of gradient descent scales poorly both with the dimension as well as the condition number of the low-rank matrix. Moreover, the smooth formulation is not robust to corruptions. In this paper, we propose scaled subgradient methods to minimize a family of nonsmooth and nonconvex formulations -- in particular, the residual sum of absolute errors -- which is guaranteed to converge at a fast rate that is almost dimension-free and independent of the condition number, even in the presence of corruptions. We illustrate the effectiveness of our approach when the observation operator satisfies certain mixed-norm restricted isometry properties, and derive state-of-the-art performance guarantees for a variety of problems such as robust low-rank matrix sensing and quadratic sampling.      
### 60.Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent  [ :arrow_down: ](https://arxiv.org/pdf/2005.08898.pdf)
>  Low-rank matrix estimation is a canonical problem that finds numerous applications in signal processing, machine learning and imaging science. A popular approach in practice is to factorize the matrix into two compact low-rank factors, and then optimize these factors directly via simple iterative methods such as gradient descent and alternating minimization. Despite nonconvexity, recent literatures have shown that these simple heuristics in fact achieve linear convergence when initialized properly for a growing number of problems of interest. However, upon closer examination, existing approaches can still be computationally expensive especially for ill-conditioned matrices: the convergence rate of gradient descent depends linearly on the condition number of the low-rank matrix, while the per-iteration cost of alternating minimization is often prohibitive for large matrices. The goal of this paper is to set forth a competitive algorithmic approach dubbed Scaled Gradient Descent (ScaledGD) which can be viewed as pre-conditioned or diagonally-scaled gradient descent, where the pre-conditioners are adaptive and iteration-varying with a minimal computational overhead. With tailored variants for low-rank matrix sensing, robust principal component analysis and matrix completion, we theoretically show that ScaledGD achieves the best of both worlds: it converges linearly at a rate independent of the condition number of the low-rank matrix similar as alternating minimization, while maintaining the low per-iteration cost of gradient descent. Our analysis is also applicable to general loss functions that are restricted strongly convex and smooth over low-rank matrices. To the best of our knowledge, ScaledGD is the first algorithm that provably has such properties over a wide range of low-rank matrix estimation tasks.      
