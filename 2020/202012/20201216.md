# ArXiv eess --Wed, 16 Dec 2020
### 1.A Methodology for Quantifying Flexibility in a fleet of Diverse DERs  [ :arrow_down: ](https://arxiv.org/pdf/2012.08464.pdf)
>  This paper addresses the question: how many distributed energy resources (DERs) are needed to provide $\pm1$MW of flexibility over a number of hours? For this purpose, a metric based on an ISO's own performance score is proposed. Then, a systematic procedure is presented and validated that makes use of either a simulator or the solution to an optimization problem based on a nominal analytical formulation to get flexibility in terms of kW-per-device. Furthermore, simulation-based analysis indicates that flexibility from different DER fleets adds linearly, that is, the total flexibility provided by a mixture of different DER types can be obtained as a convex combination of their individual kW-per-device flexibility. The proposed methodology is validated on ($i$) a centralized coordinator and ($ii$) a device driven DER coordination scheme called packetized energy management (PEM). Furthermore, the effect of heterogeneity as well as PEM specific parameters such as packet length and mean time-to-request on flexibility is also quantified.      
### 2.Model-Based Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.08405.pdf)
>  Signal processing, communications, and control have traditionally relied on classical statistical modeling techniques. Such model-based methods utilize mathematical formulations that represent the underlying physics, prior information and additional domain knowledge. Simple classical models are useful but sensitive to inaccuracies and may lead to poor performance when real systems display complex or dynamic behavior. On the other hand, purely data-driven approaches that are model-agnostic are becoming increasingly popular as datasets become abundant and the power of modern deep learning pipelines increases. Deep neural networks (DNNs) use generic architectures which learn to operate from data, and demonstrate excellent performance, especially for supervised problems. However, DNNs typically require massive amounts of data and immense computational resources, limiting their applicability for some signal processing scenarios. We are interested in hybrid techniques that combine principled mathematical models with data-driven systems to benefit from the advantages of both approaches. Such model-based deep learning methods exploit both partial domain knowledge, via mathematical structures designed for specific problems, as well as learning from limited data. In this article we survey the leading approaches for studying and designing model-based deep learning systems. We divide hybrid model-based/data-driven systems into categories based on their inference mechanism. We provide a comprehensive review of the leading approaches for combining model-based algorithms with deep learning in a systematic manner, along with concrete guidelines and detailed signal processing oriented examples from recent literature. Our aim is to facilitate the design and study of future systems on the intersection of signal processing and machine learning that incorporate the advantages of both domains.      
### 3.GAP-net for Snapshot Compressive Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2012.08364.pdf)
>  Snapshot compressive imaging (SCI) systems aim to capture high-dimensional ($\ge3$D) images in a single shot using 2D detectors. SCI devices include two main parts: a hardware encoder and a software decoder. The hardware encoder typically consists of an (optical) imaging system designed to capture {compressed measurements}. The software decoder on the other hand refers to a reconstruction algorithm that retrieves the desired high-dimensional signal from those measurements. In this paper, using deep unfolding ideas, we propose an SCI recovery algorithm, namely GAP-net, which unfolds the generalized alternating projection (GAP) algorithm. At each stage, GAP-net passes its current estimate of the desired signal through a trained convolutional neural network (CNN). The CNN operates as a denoiser that projects the estimate back to the desired signal space. For the GAP-net that employs trained auto-encoder-based denoisers, we prove a probabilistic global convergence result. Finally, we investigate the performance of GAP-net in solving video SCI and spectral SCI problems. In both cases, GAP-net demonstrates competitive performance on both synthetic and real data. In addition to having high accuracy and high speed, we show that GAP-net is flexible with respect to signal modulation implying that a trained GAP-net decoder can be applied in different systems. Our code is at <a class="link-external link-https" href="https://github.com/mengziyi64/ADMM-net" rel="external noopener nofollow">this https URL</a>.      
### 4.Do not repeat these mistakes -- a critical appraisal of applications of explainable artificial intelligence for image based COVID-19 detection  [ :arrow_down: ](https://arxiv.org/pdf/2012.08333.pdf)
>  The sudden outbreak and uncontrolled spread of COVID-19 disease is one of the most important global problems today. In a short period of time, it has led to the development of many deep neural network models for COVID-19 detection with modules for explainability. In this work, we carry out a systematic analysis of various aspects of proposed models. Our analysis revealed numerous mistakes made at different stages of data acquisition, model development, and explanation construction. In this work, we overview the approaches proposed in the surveyed ML articles and indicate typical errors emerging from the lack of deep understanding of the radiography domain. We present the perspective of both: experts in the field - radiologists, and deep learning engineers dealing with model explanations. The final result is a proposed a checklist with the minimum conditions to be met by a reliable COVID-19 diagnostic model.      
### 5.Multiple Sclerosis Lesion Segmentation -- A Survey of Supervised CNN-Based Methods  [ :arrow_down: ](https://arxiv.org/pdf/2012.08317.pdf)
>  Lesion segmentation is a core task for quantitative analysis of MRI scans of Multiple Sclerosis patients. The recent success of deep learning techniques in a variety of medical image analysis applications has renewed community interest in this challenging problem and led to a burst of activity for new algorithm development. In this survey, we investigate the supervised CNN-based methods for MS lesion segmentation. We decouple these reviewed works into their algorithmic components and discuss each separately. For methods that provide evaluations on public benchmark datasets, we report comparisons between their results.      
### 6.Empirical Evaluation of Typical Sparse Fast Fourier Transform Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2012.08238.pdf)
>  Computing the Sparse Fast Fourier Transform(sFFT) of a K-sparse signal of size N has emerged as a critical topic for a long time. The sFFT algorithms decrease the runtime and sampling complexity by taking advantage of the signal inherent characteristics that a large number of signals are sparse in the frequency domain. More than ten sFFT algorithms have been proposed, which can be classified into many types according to filter, framework, method of location, method of estimation. In this paper, the technology of these algorithms is completely analyzed in theory. The performance ofthem is thoroughly tested and verified in practice. The theoretical analysis includes thefollowing contents: five operations of signal, three methods of frequency bucketization, five methods of location, four methods of estimation, two problems caused by bucketization, three methods to solve these two problems, four algorithmic frameworks. All the above technologies and methods are introduced in detail and examples are given to illustrate the above research. After theoretical research, we make experiments for computing the signals of different SNR, N , K by a standard testing platform and record the run time, percentage of the signal sampled and L0 , L1 , L2 error with eight different sFFT algorithms. The result of experiments satisfies the inferences obtained in theory.      
### 7.F0-based Gammatone Filtering for Intelligibility Gain of Acoustic Noisy Signals  [ :arrow_down: ](https://arxiv.org/pdf/2012.08227.pdf)
>  This paper proposes a time-domain method to improve speech intelligibility in noisy scenarios. In the proposed approach, a series of Gammatone filters are adopted to detect the harmonic components of speech. The filters outputs are amplified to emphasize the first harmonics, reducing the masking effects of acoustic noises. The proposed GTFF0 solution and two baseline techniques are examined considering four background noises with different non-stationarity degrees. Three intelligibility measures (ESTOI, ESII and ASIIST) are adopted for objective evaluation. The experiments results show that the proposed scheme leads to expressive speech intelligibility gain when compared to the competing approaches. Furthermore, the PESQ and WSS objective scores demonstrate that the proposed technique also provides interesting quality improvement.      
### 8.Fast-Convergent Dynamics for Distributed Resource Allocation Over Time-Varying Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.08181.pdf)
>  In this paper, distributed dynamics are deployed to solve resource allocation over time-varying multi-agent networks. The state of each agent represents the amount of resources used/produced at that agent while the total amount of resources is fixed. The idea is to optimally allocate the resources among the group of agents by reducing the total cost functions subject to fixed amount of total resources. The information of each agent is restricted to its own state and cost function and those of its immediate neighbors. This is motivated by distributed applications such as in mobile edge-computing, economic dispatch over smart grids, and multi-agent coverage control. The non-Lipschitz dynamics proposed in this work shows fast convergence as compared to the linear and some nonlinear solutions in the literature. Further, the multi-agent network connectivity is more relaxed in this paper. To be more specific, the proposed dynamics even reaches optimal solution over time-varying disconnected undirected networks as far as the union of these networks over some bounded non-overlapping time-intervals includes a spanning-tree. The proposed convergence analysis can be applied for similar 1st-order resource allocation nonlinear dynamics. We provide simulations to verify our results.      
### 9.A Maximum-Likelihood-based Multi-User LoRa Receiver Implemented in GNU Radio  [ :arrow_down: ](https://arxiv.org/pdf/2012.08173.pdf)
>  LoRa is a popular low-power wide-area network (LPWAN) technology that uses spread-spectrum to achieve long-range connectivity and resilience to noise and interference. For energy efficiency reasons, LoRa adopts a pure ALOHA access scheme, which leads to reduced network throughput due to packet collisions at the gateways. To alleviate this issue, in this paper we analyze and implement a LoRa receiver that is able to decode LoRa packets from two interfering users. Our main contribution is a two-user detector derived in a maximum-likelihood fashion using a detailed interference model. As the complexity of the maximum-likelihood sequence estimation is prohibitive, a complexity-reduction technique is introduced to enable a practical implementation of the proposed two-user detector. This detector has been implemented along with an interference-robust synchronization algorithm on the GNU Radio Software-Defined-Radio (SDR) platform. The SDR implementation shows the effectiveness of the proposed method and also allows its experimental evaluation. Measurements indicate that our detector inherently leverages the time offset between the two colliding users to separate and demodulate their contributions.      
### 10.On simplification of Dual-Youla approach for closed-loop identification  [ :arrow_down: ](https://arxiv.org/pdf/2012.08165.pdf)
>  The dual Youla method for closed loop identification is known to have several practically important merits. Namely, it provides an accurate plant model irrespective of noise models, and fits inherently to handle unstable plants by using coprime factorization. In addition, the method is empirically robust against the uncertainty of the controller knowledge. However, use of coprime factorization may cause a big barrier against industrial applications. This paper shows how to derive a simplified version of the method which identifies the plant itself without coprime factorization, while enjoying all the merits of the dual Youla method. This simplified version turns out to be identical to the stabilized prediction error method which was proposed by the authors recently. Detailed simulation results are given to demonstrate the above merits.      
### 11.Frozen-to-Paraffin: Categorization of Histological Frozen Sections by the Aid of Paraffin Sections and Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.08158.pdf)
>  In contrast to paraffin sections, frozen sections can be quickly generated during surgical interventions. This procedure allows surgeons to wait for histological findings during the intervention to base intra-operative decisions on the outcome of the histology. However, compared to paraffin sections, the quality of frozen sections is typically lower, leading to a higher ratio of miss-classification. In this work, we investigated the effect of the section type on automated decision support approaches for classification of thyroid cancer. This was enabled by a data set consisting of pairs of sections for individual patients. Moreover, we investigated, whether a frozen-to-paraffin translation could help to optimize classification scores. Finally, we propose a specific data augmentation strategy to deal with a small amount of training data and to increase classification accuracy even further.      
### 12.Experiment design for impulse response identification with signal matrix models  [ :arrow_down: ](https://arxiv.org/pdf/2012.08126.pdf)
>  This paper formulates an input design approach for impulse response identification in the context of implicit model representations recently used as basis for many data-driven simulation and control methods. Precisely, the FIR model considered consists of a linear combination of the columns of a data matrix. An optimal combination for the case of noisy data was recently proposed using a maximum likelihood approach, and the objective here is to optimize the input entries of the data matrix such that the mean-square error matrix of the estimate is minimized. A least-norm problem is derived, which is shown to solve all the classic A-, D-, and E- optimality criteria typically considered in the experiment design literature. Numerical results finally showcase the improved estimation fit achieved with the optimized input.      
### 13.LSTM-based Space Occupancy Prediction towards Efficient Building Energy Management  [ :arrow_down: ](https://arxiv.org/pdf/2012.08114.pdf)
>  Energy consumed in buildings takes significant portions of the total global energy usage. A large amount of building energy is used for heating, cooling, ventilation, and air-conditioning (HVAC). However, compared to its importance, building energy management systems nowadays are limited in controlling HVAC based on simple rule-based control (RBC) technologies. The ability to design systems that can efficiently manage HVAC can reduce energy usage and greenhouse gas emissions, and, all in all, it can help us to mitigate climate change. This paper proposes predictive time-series models of occupancy patterns using LSTM. Prediction signal for future room occupancy status on the next time span (e.g., next 30 minutes) can be directly used to operate HVAC. For example, based on the prediction and considering the time for cooling or heating, HVAC can be turned on before the room is being used (e.g., turn on 10 minutes earlier). Also, based on the next room empty prediction timing, HVAC can be turned off earlier, and it can help us increase the efficiency of HVAC while not decreasing comfort. We demonstrate our approach's capabilities using real-world energy data collected from multiple rooms of a university building. We show that LSTM's room occupancy prediction based HVAC control could save energy usage by 50% compared to conventional RBC based control.      
### 14.Hybrid NOMA for Future Radio Access: Design, Potentials and Limitations  [ :arrow_down: ](https://arxiv.org/pdf/2012.08106.pdf)
>  Next-generation internet of things (IoT) applications need trillions of low-powered wireless mobile devices to connect with each other having ultra-reliability and low-latency. Non-orthogonal multiple access (NOMA) is a promising technology to address massive connectivity for 5G and beyond by accommodating several users within the same orthogonal resource block. Therefore, this article explores hybrid NOMA (HNOMA) for massive multiple access in the uplink scenarios due to its higher spectral efficiency. The HNOMA includes both power domain and code domain NOMA method due to diverse channel conditions in practice. We highlight that polar coded based data transmission can achieve higher reliability and lower latency in HNOMA-based wireless networks. Further, at the base station (BS), channel state information (CSI) of each link is not perfectly available or very complex to estimate due to non-orthogonal links. Therefore, we analyze and review the performance of uplink based system involving HNOMA transmission in the presence of imperfect CSI. Furthermore, we summarize some key technical challenges as well as their potential solutions in futuristic IoT applications using HNOMA transmission. Finally, we offer some design guidelines for HNOMA-based systems using deep learning approach to implement adaptive and efficient wireless networks.      
### 15.A Locational Marginal Pricing Mechanism for Uncertainty Management Based on Improved Multi-Ellipsoidal Uncertainty Set  [ :arrow_down: ](https://arxiv.org/pdf/2012.08091.pdf)
>  Large-scale integration of renewable energy sources (RES) brings huge challenges to the power system. A cost-effective reserve deployment and uncertainty pricing mechanism are critical to deal with the uncertainty and variability of RES. To this end, this paper proposes a novel locational marginal pricing mechanism in day-ahead market for managing uncertainties from RES. Firstly, an improved multi-ellipsoidal uncertainty set (IMEUS) considering the temporal correlation and conditional correlation of wind power forecast is formulated to better capture the uncertainty of wind power. The dimension of each ellipsoidal subset is optimized based on a comprehensive evaluation index to reduce the invalid region without large loss of modeling accuracy, so as to reduce the conservatism. Then, an IMEUS-based robust unit commitment (RUC) model and a robust economic dispatch (RED) model are established for the day-ahead market clearing. Both the reserve cost and ramping constraints are considered in the overall dispatch process. Furthermore, based on the Langrangian function of the RED model, a new locational marginal pricing mechanism is developed. The uncertainty locational marginal price (ULMP) is introduced to charge the RES for its uncertainties and reward the generators who provide reserve to mitigate uncertainties. The new pricing mechanism can provide effective price signals to incentivize the uncertainty management in the day-ahead market. Finally, the effectiveness of the proposed methods is verified via numerous simulations on the PJM 5-bus system and IEEE 118-bus system.      
### 16.Laser Phase Noise Tolerance of Uniform and Probabilistically-shaped QAM Signals for High Spectral Efficiency Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.08078.pdf)
>  We numerically and experimentally investigate the laser phase noise tolerance of probabilistically shaped (PS) and uniformly shaped (US) quadrature amplitude modulation (QAM) signals. In the simulations, we compare PS-64QAM to US-16QAM, PS-256QAM to US-64QAM, and PS-1024QAM to US-256QAM under the same information rate (IR). We confirm that a sufficient shaping gain is observed with narrow linewidth lasers, whereas degradation of the shaping gain is clearly observed when large phase noise and high order modulation formats are assumed. In our experiments, we compare polarization-division-multiplexed (PDM) 16-GBd PS-1024QAM and US-256QAM under the same IR using lasers with 0.1-kHz and 40-kHz linewidths. For carrier phase recovery (CPR), we employ a pilot-assisted digital phase locked loop. Results reveal that PS-1024QAM achieves high performance with the 0.1 kHz-laser or &gt; 5% pilot ratio, whereas US-256QAM outperforms PS-1024QAM when lasers with 40-kHz linewidth and &lt; 5% pilot ratio are used. We also evaluate the pilot ratio dependency of the required optical signal-to-noise ratio at the forward error correction limit and the achievable information rate. Additionally, we compare the performance of two types of CPR updating schemes: updating phase estimation at only the pilot symbol or at all symbols.      
### 17.Wiener-Hammerstein model and its learning for nonlinear digital pre-distortion of optical transmitters  [ :arrow_down: ](https://arxiv.org/pdf/2012.08046.pdf)
>  We present a simple nonlinear digital pre-distortion (DPD) of optical transmitter components, which consists of concatenated blocks of a finite impulse response (FIR) filter, a memoryless nonlinear function and another FIR filter. The model is a Wiener-Hammerstein (WH) model and has essentially the same structure as neural networks or multilayer perceptions. This awareness enables one to achieve complexity-efficient DPD owing to the model-aware structure and exploit the well-developed optimization scheme in the machine learning field. The effectiveness of the method is assessed by electrical and optical back-to-back (B2B) experiments, and the results show that the WH DPD offers a 0.52-dB gain in signal-to-noise ratio (SNR) and 6.0-dB gain in optical modulator output power at a fixed SNR over linear-only DPD.      
### 18.Preventive and Active Safety Applications  [ :arrow_down: ](https://arxiv.org/pdf/2012.08031.pdf)
>  Road vehicle safety systems can be broadly classified into the two categories of passive and active systems. The aim of passive safety systems is to reduce risk of injury to the occupants of the vehicle during and after an accident like a crash or rollover. Passive safety systems include the design of safety restraints, design for crashworthiness, seat belts and air bags. In contrast to passive systems, the aim in active safety is to prevent an accident from occurring in the first place. As such, it makes sense to call them preventive systems also. Here, the concentration is on preventive and active safety systems. The current state of the art in some key preventive and active safety systems is presented in this paper, wherein the various techniques used are also explained briefly. In some cases, the presentation is complemented with results obtained in the research group of the author. A road map of expected future developments in the area of preventive and safety applications is also presented.      
### 19.Interpolation and Gap Filling of Landsat Reflectance Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2012.07987.pdf)
>  Products derived from a single multispectral sensor are hampered by a limited spatial, spectral or temporal resolutions. Image fusion in general and downscaling/blending in particular allow to combine different multiresolution datasets. We present here an optimal interpolation approach to generate smoothed and gap-free time series of Landsat reflectance data. We fuse MODIS (moderate-resolution imaging spectroradiometer) and Landsat data globally using the Google Earth Engine (GEE) platform. The optimal interpolator exploits GEE ability to ingest large amounts of data (Landsat climatologies) and uses simple linear operations that scale easily in the cloud. The approach shows very good results in practice, as tested over five sites with different vegetation types and climatic characteristics in the contiguous US.      
### 20.Physics-Aware Gaussian Processes in Remote Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2012.07986.pdf)
>  Earth observation from satellite sensory data poses challenging problems, where machine learning is currently a key player. In recent years, Gaussian Process (GP) regression has excelled in biophysical parameter estimation tasks from airborne and satellite observations. GP regression is based on solid Bayesian statistics and generally yields efficient and accurate parameter estimates. However, GPs are typically used for inverse modeling based on concurrent observations and in situ measurements only. Very often a forward model encoding the well-understood physical relations between the state vector and the radiance observations is available though and could be useful to improve predictions and understanding. In this work, we review three GP models that respect and learn the physics of the underlying processes in the context of both forward and inverse modeling. After reviewing the traditional application of GPs for parameter retrieval, we introduce a Joint GP (JGP) model that combines in situ measurements and simulated data in a single GP model. Then, we present a latent force model (LFM) for GP modeling that encodes ordinary differential equations to blend data-driven modeling and physical constraints of the system governing equations. The LFM performs multi-output regression, adapts to the signal characteristics, is able to cope with missing data in the time series, and provides explicit latent functions that allow system analysis and evaluation. Finally, we present an Automatic Gaussian Process Emulator (AGAPE) that approximates the forward physical model using concepts from Bayesian optimization and at the same time builds an optimally compact look-up-table for inversion. We give empirical evidence of the performance of these models through illustrative examples of vegetation monitoring and atmospheric modeling.      
### 21.A silicon photonics feed-forward neural network for nonlinear distortion mitigation in an optical link  [ :arrow_down: ](https://arxiv.org/pdf/2012.07981.pdf)
>  We design and model a single-layer, passive, all-optical silicon photonics neural network to mitigate optical link nonlinearities. The network nodes are formed by silicon microring resonators whose transfer function has been experimentally measured. Both the transmitted amplitude and phase maps of the nonlinear response of the microrings are parametrized as a function of the wavelength and of the signal power to form tunable activation functions of the single nodes in the complex valued network. Training of the network is achieved by a particle swarm optimizer which selects the complex weights and the activation functions. We demonstrate that a single feed-forward layer with a single node perceptron is effective in compensating linear and nonlinear distortions over a broad range of signal-to-noise-ratio and propagation lengths. We propose to implement this simple neuronal network as an optical link transparent layer to correct signal distortions.      
### 22.Invariant Feature Learning for Sensor-based Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2012.07963.pdf)
>  Wearable sensor-based human activity recognition (HAR) has been a research focus in the field of ubiquitous and mobile computing for years. In recent years, many deep models have been applied to HAR problems. However, deep learning methods typically require a large amount of data for models to generalize well. Significant variances caused by different participants or diverse sensor devices limit the direct application of a pre-trained model to a subject or device that has not been seen before. To address these problems, we present an invariant feature learning framework (IFLF) that extracts common information shared across subjects and devices. IFLF incorporates two learning paradigms: 1) meta-learning to capture robust features across seen domains and adapt to an unseen one with similarity-based data selection; 2) multi-task learning to deal with data shortage and enhance overall performance via knowledge sharing among different subjects. Experiments demonstrated that IFLF is effective in handling both subject and device diversion across popular open datasets and an in-house dataset. It outperforms a baseline model of up to 40% in test accuracy.      
### 23.Towards broader generalization of deep learning methods for multiple sclerosis lesion segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2012.07950.pdf)
>  Recently, segmentation methods based on Convolutional Neural Networks (CNNs) showed promising performance in automatic Multiple Sclerosis (MS) lesions segmentation. These techniques have even outperformed human experts in controlled evaluation condition. However state-of-the-art approaches trained to perform well on highly-controlled datasets fail to generalize on clinical data from unseen datasets. Instead of proposing another improvement of the segmentation accuracy, we propose a novel method robust to domain shift and performing well on unseen datasets, called DeepLesionBrain (DLB). This generalization property results from three main contributions. First, DLB is based on a large ensemble of compact 3D CNNs. This ensemble strategy ensures a robust prediction despite the risk of generalization failure of some individual networks. Second, DLB includes a new image quality data augmentation to reduce dependency to training data specificity (e.g., acquisition protocol). Finally, to learn a more generalizable representation of MS lesions, we propose a hierarchical specialization learning (HSL). HSL is performed by pre-training a generic network over the whole brain, before using its weights as initialization to locally specialized networks. By this end, DLB learns both generic features extracted at global image level and specific features extracted at local image level. At the time of publishing this paper, DLB is among the Top 3 performing published methods on ISBI Challenge while using only half of the available modalities. DLB generalization has also been compared to other state-of-the-art approaches, during cross-dataset experiments on MSSEG'16, ISBI challenge, and in-house datasets. DLB improves the segmentation performance and generalization over classical techniques, and thus proposes a robust approach better suited for clinical practice.      
### 24.PyPhase -- a Python package for X-ray phase imaging  [ :arrow_down: ](https://arxiv.org/pdf/2012.07942.pdf)
>  X-ray propagation-based imaging techniques are well-established at synchrotron radiation and laboratory sources. However, most reconstruction algorithms for such image modalities, also known as phase retrieval algorithms, have been developed specifically for one instrument by and for experts, making the development and spreading of the use of such techniques difficult. Here, we present PyPhase, a free and open-source package for propagation-based near-field phase reconstructions, which is distributed under the CeCILL license. PyPhase implements some of the most popular phase-retrieval algorithms in a highly-modular framework supporting the deployment on large-scale computing facilities. This makes the integration, the development of new phase-retrieval algorithms, and the deployment on different computing infrastructures straight-forward. To demonstrate its capabilities and simplicity, we present its application to data acquired at synchrotron MAX~IV (Lund, Sweden).      
### 25.Motion Adaptive Deblurring with Single-Photon Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2012.07931.pdf)
>  Single-photon avalanche diodes (SPADs) are a rapidly developing image sensing technology with extreme low-light sensitivity and picosecond timing resolution. These unique capabilities have enabled SPADs to be used in applications like LiDAR, non-line-of-sight imaging and fluorescence microscopy that require imaging in photon-starved scenarios. In this work we harness these capabilities for dealing with motion blur in a passive imaging setting in low illumination conditions. Our key insight is that the data captured by a SPAD array camera can be represented as a 3D spatio-temporal tensor of photon detection events which can be integrated along arbitrary spatio-temporal trajectories with dynamically varying integration windows, depending on scene motion. We propose an algorithm that estimates pixel motion from photon timestamp data and dynamically adapts the integration windows to minimize motion blur. Our simulation results show the applicability of this algorithm to a variety of motion profiles including translation, rotation and local object motion. We also demonstrate the real-world feasibility of our method on data captured using a 32x32 SPAD camera.      
### 26.Decision-Making Algorithms for Learning and Adaptation with Application to COVID-19 Data  [ :arrow_down: ](https://arxiv.org/pdf/2012.07844.pdf)
>  This work focuses on the development of a new family of decision-making algorithms for adaptation and learning, which are specifically tailored to decision problems and are constructed by building up on first principles from decision theory. A key observation is that estimation and decision problems are structurally different and, therefore, algorithms that have proven successful for the former need not perform well when adjusted for decision problems. We propose a new scheme, referred to as BLLR (barrier log-likelihood ratio algorithm) and demonstrate its applicability to real-data from the COVID-19 pandemic in Italy. The results illustrate the ability of the design tool to track the different phases of the outbreak.      
### 27.Towards an Adaptive Dynamic Mode Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2012.07834.pdf)
>  Dynamic Mode Decomposition (DMD) is a data based modeling tool that identifies a matrix to map a quantity at some time instant to the same quantity in future. We design a new version which we call Adaptive Dynamic Mode Decomposition (ADMD) that utilizes time delay coordinates, projection methods and filters as per the nature of the data to create a model for the available problem. Filters are very effective in reducing the rank of high-dimensional dataset. We have incorporated 'discrete Fourier transform' and 'augmented lagrangian multiplier' as filters in our method. The proposed ADMD is tested on several datasets of varying complexities and its performance appears to be promising.      
### 28.Spectral Methods for Data Science: A Statistical Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2012.08496.pdf)
>  Spectral methods have emerged as a simple yet surprisingly effective approach for extracting information from massive, noisy and incomplete data. In a nutshell, spectral methods refer to a collection of algorithms built upon the eigenvalues (resp. singular values) and eigenvectors (resp. singular vectors) of some properly designed matrices constructed from data. A diverse array of applications have been found in machine learning, data science, and signal processing. Due to their simplicity and effectiveness, spectral methods are not only used as a stand-alone estimator, but also frequently employed to initialize other more sophisticated algorithms to improve performance. <br>While the studies of spectral methods can be traced back to classical matrix perturbation theory and methods of moments, the past decade has witnessed tremendous theoretical advances in demystifying their efficacy through the lens of statistical modeling, with the aid of non-asymptotic random matrix theory. This monograph aims to present a systematic, comprehensive, yet accessible introduction to spectral methods from a modern statistical perspective, highlighting their algorithmic implications in diverse large-scale applications. In particular, our exposition gravitates around several central questions that span various applications: how to characterize the sample efficiency of spectral methods in reaching a target level of statistical accuracy, and how to assess their stability in the face of random noise, missing data, and adversarial corruptions? In addition to conventional $\ell_2$ perturbation analysis, we present a systematic $\ell_{\infty}$ and $\ell_{2,\infty}$ perturbation theory for eigenspace and singular subspaces, which has only recently become available owing to a powerful "leave-one-out" analysis framework.      
### 29.Optimal ROC Curves from Score Variable Threshold Tests  [ :arrow_down: ](https://arxiv.org/pdf/2012.08391.pdf)
>  The Receiver Operating Characteristic (ROC) is a well-established representation of the tradeoff between detection and false alarm probabilities in binary hypothesis testing. In many practical contexts ROC's are generated by thresholding a measured score variable -- applying score variable threshold tests (SVT's). In many cases the resulting curve is different from the likelihood ratio test (LRT) ROC and is therefore not Neyman-Pearson optimal. While it is well-understood that concavity is a necessary condition for an ROC to be Neyman-Pearson optimal, this paper establishes that it is also a sufficient condition in the case where the ROC was generated using SVT's. It further defines a constructive procedure by which the LRT ROC can be generated from a non-concave SVT ROC, without requiring explicit knowledge of the conditional PDF's of the score variable. If the conditional PDF's are known, the procedure implicitly provides a way of redesigning the test so that it is equivalent to an LRT.      
### 30.Driving and Routing Game for Autonomous Vehicles on a Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.08388.pdf)
>  This paper aims to answer the research question as to optimal design of decision-making processes for autonomous vehicles (AVs), including dynamical selection of driving velocity and route choices on a transportation network. Dynamic traffic assignment (DTA) has been widely used to model travelers' route choice or/and departure-time choice and predict dynamic traffic flow evolution in the short term. However, the existing DTA models do not explicitly describe one's selection of driving velocity on a road link. Driving velocity choice may not be crucial for modeling the movement of human drivers but it is a must-have control to maneuver AVs. In this paper, we aim to develop a game-theoretic model to solve for AVs' optimal driving strategies of velocity control in the interior of a road link and route choice at a junction node. To this end, we will first reinterpret the DTA problem as an N-car differential game and show that this game can be tackled with a general mean field game-theoretic framework. The developed mean field game is challenging to solve because of the forward and backward structure for velocity control and the complementarity conditions for route choice. An efficient algorithm is developed to address these challenges. The model and the algorithm are illustrated in on Braess networks. We first compare the LWR based DTA model with the proposed game and find that the driving and routing control navigates AVs with overall lower costs. We then compare the total travel cost without and with the middle link and find that the Braess paradox may still arise under certain conditions.      
### 31.QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech Classification  [ :arrow_down: ](https://arxiv.org/pdf/2012.08312.pdf)
>  Hate speech, quite common in the age of social media, at times harmless but can also cause mental trauma to someone or even riots in communities. Image of a religious symbol with derogatory comment or video of a man abusing a particular community, all become hate speech with its every modality (such as text, image, and audio) contributing towards it. Models based on a particular modality of hate speech post on social media are not useful, rather, we need models like multi-modal fusion models that consider both image and text while classifying hate speech. Text-image fusion models are heavily parameterized, hence we propose a quaternion neural network-based model having additional fusion components for each pair of modalities. The model is tested on the MMHS150K twitter dataset for hate speech classification. The model shows an almost 75% reduction in parameters and also benefits us in terms of storage space and training time while being at par in terms of performance as compared to its real counterpart.      
### 32.BiSNN: Training Spiking Neural Networks with Binary Weights via Bayesian Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.08300.pdf)
>  Artificial Neural Network (ANN)-based inference on battery-powered devices can be made more energy-efficient by restricting the synaptic weights to be binary, hence eliminating the need to perform multiplications. An alternative, emerging, approach relies on the use of Spiking Neural Networks (SNNs), biologically inspired, dynamic, event-driven models that enhance energy efficiency via the use of binary, sparse, activations. In this paper, an SNN model is introduced that combines the benefits of temporally sparse binary activations and of binary weights. Two learning rules are derived, the first based on the combination of straight-through and surrogate gradient techniques, and the second based on a Bayesian paradigm. Experiments validate the performance loss with respect to full-precision implementations, and demonstrate the advantage of the Bayesian paradigm in terms of accuracy and calibration.      
### 33.Moment dynamics and observer design for a class of quasilinear quantum stochastic systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.08212.pdf)
>  This paper is concerned with a class of open quantum systems whose dynamic variables have an algebraic structure, similar to that of the Pauli matrices pertaining to finite-level systems. The system interacts with external bosonic fields, and its Hamiltonian and coupling operators depend linearly on the system variables. This results in a Hudson-Parthasarathy quantum stochastic differential equation (QSDE) whose drift and dispersion terms are affine and linear functions of the system variables. The quasilinearity of the QSDE leads to tractable dynamics of mean values and higher-order multi-point moments of the system variables driven by vacuum input fields. This allows for the closed-form computation of the quasi-characteristic function of the invariant quantum state of the system and infinite-horizon asymptotic growth rates for a class of cost functionals. The tractability of the moment dynamics is also used for mean square optimal Luenberger observer design in a measurement-based filtering problem for a quasilinear quantum plant, which leads to a Kalman-like quantum filter.      
### 34.Machine Learning for MU-MIMO Receive Processing in OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.08177.pdf)
>  Machine learning (ML) starts to be widely used to enhance the performance of multi-user multiple-input multiple-output (MU-MIMO) receivers. However, it is still unclear if such methods are truly competitive with respect to conventional methods in realistic scenarios and under practical constraints. In addition to enabling accurate signal reconstruction on realistic channel models, MU-MIMO receive algorithms must allow for easy adaptation to a varying number of users without the need for retraining. In contrast to existing work, we propose an ML-enhanced MU-MIMO receiver that builds on top of a conventional linear minimum mean squared error (LMMSE) architecture. It preserves the interpretability and scalability of the LMMSE receiver, while improving its accuracy in two ways. First, convolutional neural networks (CNNs) are used to compute an approximation of the second-order statistics of the channel estimation error which are required for accurate equalization. Second, a CNN-based demapper jointly processes a large number of orthogonal frequency-division multiplexing (OFDM) symbols and subcarriers, which allows it to compute better log likelihood ratios (LLRs) by compensating for channel aging. The resulting architecture can be used in the up- and downlink and is trained in an end-to-end manner, removing the need for hard-to-get perfect channel state information (CSI) during the training phase. Simulation results demonstrate consistent performance improvements over the baseline which are especially pronounced in high mobility scenarios.      
### 35.Automatic Speech Verification Spoofing Detection  [ :arrow_down: ](https://arxiv.org/pdf/2012.08095.pdf)
>  Automatic speech verification (ASV) is the technology to determine the identity of a person based on their voice. While being convenient for identity verification, we should aim for the highest system security standard given that it is the safeguard of valuable digital assets. Bearing this in mind, we follow the setup in ASVSpoof 2019 competition to develop potential countermeasures that are robust and efficient. Two metrics, EER and t-DCF, will be used for system evaluation.      
### 36.Product Graph Learning from Multi-domain Data with Sparsity and Rank Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2012.08090.pdf)
>  In this paper, we focus on learning product graphs from multi-domain data. We assume that the product graph is formed by the Cartesian product of two smaller graphs, which we refer to as graph factors. We pose the product graph learning problem as the problem of estimating the graph factor Laplacian matrices. To capture local interactions in data, we seek sparse graph factors and assume a smoothness model for data. We propose an efficient iterative solver for learning sparse product graphs from data. We then extend this solver to infer multi-component graph factors with applications to product graph clustering by imposing rank constraints on the graph Laplacian matrices. Although working with smaller graph factors is computationally more attractive, not all graphs may readily admit an exact Cartesian product factorization. To this end, we propose efficient algorithms to approximate a graph by a nearest Cartesian product of two smaller graphs. The efficacy of the developed framework is demonstrated using several numerical experiments on synthetic data and real data.      
### 37.Operating Characteristics for Binary Hypothesis Testing in Quantum Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.08081.pdf)
>  Receiver operating characteristics (ROCs) are a well-established representation of the tradeoff between detection and false alarm probabilities in classical binary hypothesis testing. We use classical ROCs as motivation for two types of operating characteristics for binary hypothesis testing in quantum systems -- decision operating characteristics (QDOCs) and measurement operating characteristics (QMOCs). Both are described in the context of a framework we propose that encompasses the typical formulations of binary hypothesis testing in both the classical and quantum scenarios. We interpret Helstrom's well-known result regarding discrimination between two quantum density operators with minimum probability of error in this framework. We also present a generalization of previous results regarding the correspondence between classical Parseval frames and quantum measurements. The derivation naturally leads to a constructive procedure for generating many different measurements besides Helstrom's optimal measurement, some standard and others non-standard, that achieve minimum probability of error.      
### 38.An exact solution in Markov decision process with multiplicative rewards as a general framework  [ :arrow_down: ](https://arxiv.org/pdf/2012.08074.pdf)
>  We develop an exactly solvable framework of Markov decision process with a finite horizon, and continuous state and action spaces. We first review the exact solution of conventional linear quadratic regulation with a linear transition and a Gaussian noise, whose optimal policy does not depend on the Gaussian noise, which is an undesired feature in the presence of significant noises. It motivates us to investigate exact solutions which depend on noise. To do so, we generalize the reward accumulation to be a general binary commutative and associative operation. By a new multiplicative accumulation, we obtain an exact solution of optimization assuming linear transitions with a Gaussian noise and the optimal policy is noise dependent in contrast to the additive accumulation. Furthermore, we also show that the multiplicative scheme is a general framework that covers the additive one with an arbitrary precision, which is a model-independent principle.      
### 39.Template Matching with Ranks  [ :arrow_down: ](https://arxiv.org/pdf/2012.07937.pdf)
>  We consider the problem of matching a template to a noisy signal. Motivated by some recent proposals in the signal processing literature, we suggest a rank-based method and study its asymptotic properties using some well-established techniques in empirical process theory combined with HÃ¡jek's projection method. The resulting estimator of the shift is shown to achieve a parametric rate of convergence and to be asymptotically normal. Some numerical simulations corroborate these findings.      
