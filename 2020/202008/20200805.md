# ArXiv eess --Wed, 5 Aug 2020
### 1.Radar Adaptive Detection Architectures for Heterogeneous Environments  [ :arrow_down: ](https://arxiv.org/pdf/2008.01711.pdf)
>  In this paper, four adaptive radar architectures for target detection in heterogeneous Gaussian environments are devised. The first architecture relies on a cyclic optimization exploiting the Maximum Likelihood Approach in the original data domain, whereas the second detector is a function of transformed data which are normalized with respect to their energy and with the unknown parameters estimated through an Expectation-Maximization-based alternate procedure. The remaining two architectures are obtained by suitably combining the estimation procedures and the detector structures previously devised. Performance analysis, conducted on both simulated and measured data, highlights that the architecture working in the transformed domain guarantees the constant false alarm rate property with respect to the interference power variations and a limited detection loss with respect to the other detectors, whose detection thresholds nevertheless are very sensitive to the interference power.      
### 2.MIRNet: Learning Multiple Identity Representations in Overlapped Speech  [ :arrow_down: ](https://arxiv.org/pdf/2008.01698.pdf)
>  Many approaches exist for deriving a single speaker's identity information from speech by recognizing consistent characteristics of acoustic parameters. However, it is challenging to determine identity information when there are multiple concurrent speakers in a speech signal. In this paper, we propose a novel deep speaker representation strategy that can reliably extract multiple speaker identities from overlapped speech. We design a network that can extract a high-level embedding containing the identity information of each speaker from a given mixture. Unlike conventional approaches that need reference acoustic features for training, our proposed algorithm only requires the speaker identity labels for the overlapped speech segments. We demonstrate the effectiveness of our algorithm in a speaker verification task and a speech separation system conditioned on the target speaker embeddings obtained through the proposed method.      
### 3.FDTD-Based Diffuse Scattering and Transmission Models for Ray-Tracing of Millimeter-Wave Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.01688.pdf)
>  At millimeter-wave frequencies, diffuse scattering from rough surfaces is an important propagation mechanism. Including this mechanism in radio propagation modeling tools,such as ray-tracing, is a key step towards realizing accurate propagation models for 5G and beyond systems. We propose a two-stage solution to this problem. First, we model reflection and transmission through rough slabs, such as doors, walls and windows with the FDTD method. Our results indicate the influence of roughness and whether this influence is measurable, either reducing the magnitude of the reflected and transmitted waves, or (most importantly) generating diffuse scattering components. In the latter case, the surface effectively acts as a secondary source, whose pattern is computed by full-wave analysis. Then, this pattern is embedded in a ray-tracer, enabling the computation and tracing of diffuse scattering field components. We demonstrate this approach in the ray-tracing analysis of a 28 GHz indoor environment.      
### 4.Classification-Aided Multitarget Tracking Using the Sum-Product Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2008.01667.pdf)
>  Multitarget tracking (MTT) is a challenging task that aims at estimating the number of targets and their states from measurements of the target states provided by one or multiple sensors. Additional information, such as imperfect estimates of target classes provided by a classifier, can facilitate the target-measurement association and thus improve MTT performance. In this letter, we describe how a recently proposed MTT framework based on the sum-product algorithm can be extended to efficiently exploit class information. The effectiveness of the proposed approach is demonstrated by simulation results.      
### 5.Towards Deep Clustering of Human Activities from Wearables  [ :arrow_down: ](https://arxiv.org/pdf/2008.01659.pdf)
>  Our ability to exploit low-cost wearable sensing modalities for critical human behaviour and activity monitoring applications in health and wellness is reliant on supervised learning regimes; here, deep learning paradigms have proven extremely successful in learning activity representations from annotated data. However, the costly work of gathering and annotating sensory activity datasets is labor-intensive, time consuming and not scalable to large volumes of data. While existing unsupervised remedies of deep clustering leverage network architectures and optimization objectives that are tailored for static image datasets, deep architectures to uncover cluster structures from raw sequence data captured by on-body sensors remains largely unexplored. In this paper, we develop an unsupervised end-to-end learning strategy for the fundamental problem of human activity recognition (HAR) from wearables. Through extensive experiments, including comparisons with existing methods, we show the effectiveness of our approach to jointly learn unsupervised representations for sensory data and generate cluster assignments with strong semantic correspondence to distinct human activities.      
### 6.Inverse Mechano-Electrical Reconstruction of Cardiac Excitation Wave Patterns from Mechanical Deformation using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.01640.pdf)
>  The inverse mechano-electrical problem in cardiac electrophysiology is the attempt to reconstruct electrical excitation or action potential wave patterns from the heart's mechanical deformation that occurs in response to electrical excitation. Because heart muscle cells contract upon electrical excitation due to the excitation-contraction coupling mechanism, the resulting deformation of the heart should reflect macroscopic action potential wave phenomena. However, whether the relationship between macroscopic electrical and mechanical phenomena is well-defined and furthermore unique enough to be utilized for an inverse imaging technique, in which mechanical activation mapping is used as a surrogate for electrical mapping, has yet to be determined. Here, we provide a numerical proof-of-principle that deep learning can be used to solve the inverse mechano-electrical problem. We trained a convolutional autoencoder neural network to learn the complex relationship between electrical excitation, active stress, and tissue deformation, and consequently used the network to predict or reconstruct electrical excitation wave patterns from mechanical deformation in two- and three-dimensional elastic excitable media. We demonstrate that even complicated three-dimensional electrical excitation wave phenomena, such as scroll waves and their vortex filaments, can be computed with very high reconstruction accuracies from mechanical deformation using autoencoder neural networks, and we provide a comparison with results that were obtained previously with a physics- or knowledge-based approach.      
### 7.Land Use and Land Cover Classification using a Human Group based Particle Swarm Optimization Algorithm with a LSTM classifier on hybrid-pre-processing Remote Sensing Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.01635.pdf)
>  Land use and land cover (LULC) classification using remote sensing imagery plays a vital role in many environment modeling and land use inventories. In this study, a hybrid feature optimization algorithm along with a deep learning classifier is proposed to improve performance of LULC classification, helping to predict wildlife habitat, deteriorating environmental quality, haphazard, etc. LULC classification is assessed using Sat 4, Sat 6 and Eurosat datasets. After the selection of remote sensing images, normalization and histogram equalization methods are used to improve the quality of the images. Then, a hybrid optimization is accomplished by using the Local Gabor Binary Pattern Histogram Sequence (LGBPHS), the Histogram of Oriented Gradient (HOG) and Haralick texture features, for the feature extraction from the selected images. The benefits of this hybrid optimization are a high discriminative power and invariance to color and grayscale images. Next, a Human Group based Particle Swarm Optimization (PSO) algorithm is applied to select the optimal features, whose benefits are fast convergence rate and easy to implement. After selecting the optimal feature values, a Long Short Term Memory (LSTM) network is utilized to classify the LULC classes. Experimental results showed that the Human Group based PSO algorithm with a LSTM classifier effectively well differentiates the land use and land cover classes in terms of classification accuracy, recall and precision. A minimum of 0.01% and a maximum of 2.56% improvement in accuracy is achieved compared to the existing models GoogleNet, VGG, AlexNet, ConvNet, when the proposed method is applied.      
### 8.Finite-Time Model-Learning Based L1-Simplex For Integrated TCS and ABS  [ :arrow_down: ](https://arxiv.org/pdf/2008.01627.pdf)
>  This paper proposes an $\mathcal{L}_{1}$-Simplex architecture with finite-time model learning to address safe autonomous velocity regulation for vehicles driving in dynamic and unforeseen environments. To guarantee the reliability of autonomous vehicles, an $\mathcal{L}_{1}$ adaptive controller, which compensates for uncertainties and disturbances, is employed by the Simplex architecture as a verified safe controller to tolerate concurrent software and physical failures. Meanwhile, safe switching controller is incorporated into Simplex to achieve the safe velocity tracking through integration of the traction control system (TCS) and anti-lock braking system (ABS). Specifically, the vehicle's velocity asymptotically tracks its provided references that vary with driving environments, while restricts its wheel slip to safe sets to prevent slipping and sliding. Due to the high dependence of the vehicle dynamics on the operational environment, Simplex leverages finite-time model learning to timely learn and update the vehicle model for $\mathcal{L}_{1}$ adaptive controller, when any deviation from the safety envelope or the uncertainty measurement threshold occurs in unforeseen driving environments. Simulations demonstrate the effectiveness of the proposed $\mathcal{L}_{1}$-Simplex with model learning in different scenarios.      
### 9.Glucose-Insulin Dynamical Model for Type 2 Diabetic Patients  [ :arrow_down: ](https://arxiv.org/pdf/2008.01614.pdf)
>  In this paper, a literature review is made for the current models of glucose-insulin dynamics of type 2 diabetes patients. Afterwards, a model is proposed by combining and modifying some of the available models in literature. Finally, a simulation study is provided to discuss the modified model. The model is proposed as a candidate to be validated with real patients data in the future.      
### 10.Performance Evaluation of OTFS Over Measured V2V Channels at 60 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2008.01586.pdf)
>  This paper presents an analysis of the Orthogonal Time Frequency Space (OTFS) modulation scheme when applied to realistic vehicular channel situations. OTFS modulates symbols in delay-Doppler domain, hoping to exploit diversity in both. The penalty for doing this is the requirement of complex interference cancellation equalizers, as this domain incurs a strong amount of intercarrier and intersymbol interference. We conduct this analysis using measured millimeter wave vehicular channels, and we assume typical physical layer settings for a performance analysis. Our results show that there is a challenging trade-off between channel conditions that are easy to equalize and channel conditions that allow OFTS to exploit the two-dimensional diversity. In the first case we observe a good overall performance that is barely enhanced by employing OTFS. In the second case performance gain through OTFS is visible, yet with a bad overall performance.      
### 11.Automatic Dataset Builder for Machine Learning Applications to Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2008.01578.pdf)
>  Nowadays the use of Machine Learning (ML) algorithms is spreading in the field of Remote Sensing, with applications ranging from detection and classification of land use and monitoring to the prediction of many natural or anthropic phenomena of interest. One main limit of their employment is related to the need for a huge amount of data for training the neural network, chosen for the specific application, and the resulting computational weight and time required to collect the necessary data. In this letter the architecture of an innovative tool, enabling researchers to create in an automatic way suitable datasets for AI (Artificial Intelligence) applications in the EO (Earth Observation) context, is presented. Two versions of the architecture have been implemented and made available on Git-Hub, with a specific Graphical User Interface (GUI) for non-expert users.      
### 12.Multi-Slice Fusion for Sparse-View and Limited-Angle 4D CT Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2008.01567.pdf)
>  Inverse problems spanning four or more dimensions such as space, time and other independent parameters have become increasingly important. State-of-the-art 4D reconstruction methods use model based iterative reconstruction (MBIR), but depend critically on the quality of the prior modeling. Recently, plug-and-play (PnP) methods have been shown to be an effective way to incorporate advanced prior models using state-of-the-art denoising algorithms. However, state-of-the-art denoisers such as BM4D and deep convolutional neural networks (CNNs) are primarily available for 2D or 3D images and extending them to higher dimensions is difficult due to algorithmic complexity and the increased difficulty of effective training. <br>In this paper, we present multi-slice fusion, a novel algorithm for 4D reconstruction, based on the fusion of multiple low-dimensional denoisers. Our approach uses multi-agent consensus equilibrium (MACE), an extension of plug-and-play, as a framework for integrating the multiple lower-dimensional models. We apply our method to 4D cone-beam X-ray CT reconstruction for non destructive evaluation (NDE) of samples that are dynamically moving during acquisition. We implement multi-slice fusion on distributed, heterogeneous clusters in order to reconstruct large 4D volumes in reasonable time and demonstrate the inherent parallelizable nature of the algorithm. We present simulated and real experimental results on sparse-view and limited-angle CT data to demonstrate that multi-slice fusion can substantially improve the quality of reconstructions relative to traditional methods, while also being practical to implement and train.      
### 13.Adversarial Radar Inference: Inverse Tracking, Identifying Cognition and Designing Smart Interference  [ :arrow_down: ](https://arxiv.org/pdf/2008.01559.pdf)
>  This paper considers three inter-related adversarial inference problems involving cognitive radars. We first discuss inverse tracking of the radar to estimate the adversary's estimate of us based on the radar's actions and calibrate the radar's sensing accuracy. Second, using revealed preference from microeconomics, we formulate a non-parametric test to identify if the cognitive radar is a constrained utility maximizer with signal processing constraints. We consider two radar functionalities, namely, beam allocation and waveform design, with respect to which the cognitive radar is assumed to maximize its utility and construct a set-valued estimator for the radar's utility function. Finally, we discuss how to engineer interference at the physical layer level to confuse the radar which forces it to change its transmit waveform. The levels of abstraction range from smart interference design based on Wiener filters (at the pulse/waveform level), inverse Kalman filters at the tracking level and revealed preferences for identifying utility maximization at the systems level.      
### 14.A Reinforcement Learning Method For Power Suppliers' Strategic Bidding with Insufficient Information  [ :arrow_down: ](https://arxiv.org/pdf/2008.01552.pdf)
>  Power suppliers can exercise market power to gain higher profit. However, this becomes difficult when external information is extremely rare. To get a promising performance in an extremely incomplete information market environment, a novel model-free reinforcement learning algorithm based on the Learning Automata (LA) is proposed in this paper. Besides, this paper analyses the rationality and convergence of the algorithm in case studies based on the Cournot market model.      
### 15.GenCos' Behaviors Modeling Based on Q Learning Improved by Dichotomy  [ :arrow_down: ](https://arxiv.org/pdf/2008.01536.pdf)
>  Q learning is widely used to simulate the behaviors of generation companies (GenCos) in an electricity market. However, existing Q learning method usually requires numerous iterations to converge, which is time-consuming and inefficient in practice. To enhance the calculation efficiency, a novel Q learning algorithm improved by dichotomy is proposed in this paper. This method modifies the update process of the Q table by dichotomizing the state space and the action space step by step. Simulation results in a repeated Cournot game show the effectiveness of the proposed algorithm.      
### 16."This is Houston. Say again, please". The Behavox system for the Apollo-11 Fearless Steps Challenge (phase II)  [ :arrow_down: ](https://arxiv.org/pdf/2008.01504.pdf)
>  We describe the speech activity detection (SAD), speaker diarization (SD), and automatic speech recognition (ASR) experiments conducted by the Behavox team for the Interspeech 2020 Fearless Steps Challenge (FSC-2). A relatively small amount of labeled data, a large variety of speakers and channel distortions, specific lexicon and speaking style resulted in high error rates on the systems which involved this data. In addition to approximately 36 hours of annotated NASA mission recordings, the organizers provided a much larger but unlabeled 19k hour Apollo-11 corpus that we also explore for semi-supervised training of ASR acoustic and language models, observing more than 17% relative word error rate improvement compared to training on the FSC-2 data only. We also compare several SAD and SD systems to approach the most difficult tracks of the challenge (track 1 for diarization and ASR), where long 30-minute audio recordings are provided for evaluation without segmentation or speaker information. For all systems, we report substantial performance improvements compared to the FSC-2 baseline systems, and achieved a first-place ranking for SD and ASR and fourth-place for SAD in the challenge.      
### 17.Dynamic Resource Optimization for Decentralized Estimation in Energy Harvesting IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01498.pdf)
>  We study decentralized estimation of time-varying signals at a fusion center, when energy harvesting sensors transmit sampled data over rate-constrained links. We propose dynamic strategies to select radio parameters, sampling set, and harvested energy at each node, with the aim of estimating a time-varying signal while ensuring: i) accuracy of the recovery procedure, and ii) stability of the batteries around a prescribed operating level. The approach is based on stochastic optimization tools, which enable adaptive optimization without the need of apriori knowledge of the statistics of radio channels and energy arrivals processes. Numerical results validate the proposed approach for decentralized signal estimation under communication and energy constraints typical of Internet of Things (IoT) scenarios.      
### 18.Synthesis of Sensor Deception Attacks at the Supervisory Layer of Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.01497.pdf)
>  We study the security of Cyber-Physical Systems (CPS) in the context of the supervisory control layer. Specifically, we propose a general model of a CPS attacker in the framework of discrete event systems and investigate the problem of synthesizing an attack strategy for a given feedback control system. Our model captures a class of deception attacks, where the attacker has the ability to hijack a subset of sensor readings and mislead the supervisor, with the goal of inducing the system into an undesirable state. We utilize a game-like discrete transition structure, called Insertion-Deletion Attack structure (IDA), to capture the interaction between the supervisor and the environment (which includes the system and the attacker). We show how to use IDAs to synthesize three different types of successful stealthy attacks, i.e., attacks that avoid detection from the supervisor and cause damage to the system.      
### 19.Generic identifiability of subnetworks in a linear dynamic network: the full measurement case  [ :arrow_down: ](https://arxiv.org/pdf/2008.01495.pdf)
>  Identifiability conditions for single or multiple modules in a dynamic network specify under which conditions the considered modules can be uniquely recovered from measurements of node signals and external excitation signals. Conditions for generic identifiability of multiple modules, i.e. a subnetwork, are developed for the situation that all node signals are accessible and excitation of the network is provided by both measured excitation signals and unmeasured disturbance inputs. Additionally, the network model set is allowed to contain non-parametrized modules that are fixed, and e.g. reflect modules of which the dynamics are known to the user. The conditions take the form of path-based conditions on the graph of the network model set. Based on these conditions, synthesis results are formulated for allocating external excitation signals to achieve generic identifiability of particular subnetworks. In case of having a sufficient number of measured external excitation signals, the formulated results give rise to a generalized indirect type of identification algorithm that requires only the measurement of a subset of the node signals in the network.      
### 20.Terahertz Line-Of-Sight MIMO Communication: Theory and Practical Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2008.01482.pdf)
>  A relentless trend in wireless communications is the hunger for bandwidth, and fresh bandwidth is only to be found at ever-higher frequencies. While 5G systems are seizing the mmWave band, the attention of researchers is shifting already to the terahertz range. In that distant land of tiny wavelengths, antenna arrays can serve for more than power-enhancing beamforming. Defying lower-frequency wisdom, spatial multiplexing becomes feasible even in line-of-sight conditions. This paper reviews the underpinnings of this phenomenon, and it surveys recent results on the ensuing information-theoretic capacity. Reconfigurable array architectures are put forth that can closely approach such capacity, practical challenges are discussed, and supporting experimental evidence is presented.      
### 21.Reliability and Battery Lifetime Improvement for IoT Networks: Challenges and AI-powered solutions  [ :arrow_down: ](https://arxiv.org/pdf/2008.01414.pdf)
>  Towards realizing an intelligent networked society, enabling low-cost low-energy connectivity for things, also known as Internet of Things (IoT), is of crucial importance. While the existing wireless access networks require centralized signaling for managing network resources, this approach is of less interest for future generations of wireless networks due to the energy consumption in such signaling and the expected increase in the number of IoT devices. Then, in this work we investigate leveraging machine learning for distributed control of IoT communications. Towards this end, first we investigate low-complex learning schemes which are applicable to resource-constrained IoT communications. Then, we propose a lightweight learning scheme which enables the IoT devices to adapt their communication parameters to the environment. Further, we investigate analytical expressions presenting performance of a centralized control scheme for adapting communication parameters of IoT devices, and compare the results with the results from the proposed distributed learning approach. The simulation results confirm that the reliability and energy efficiency of IoT communications could be significantly improved by leveraging the proposed learning approach.      
### 22.Deep Parallel MRI Reconstruction Network Without Coil Sensitivities  [ :arrow_down: ](https://arxiv.org/pdf/2008.01410.pdf)
>  We propose a novel deep neural network architecture by mapping the robust proximal gradient scheme for fast image reconstruction in parallel MRI (pMRI) with regularization function trained from data. The proposed network learns to adaptively combine the multi-coil images from incomplete pMRI data into a single image with uniform contrast, which is then passed to a nonlinear encoder to efficiently extract sparse features of the image. Unlike most of existing deep image reconstruction networks, our network does not require knowledge of sensitivity maps, which are notoriously difficult to estimate and have been a major bottleneck of image reconstruction in real-world pMRI applications. The experimental results demonstrate the promising performance of our method on a variety of pMRI imaging data sets.      
### 23.Optimization-driven Hierarchical Learning Framework for Wireless Powered Backscatter-aided Relay Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.01366.pdf)
>  In this paper, we employ multiple wireless-powered relays to assist information transmission from a multi-antenna access point to a single-antenna receiver. The wireless relays can operate in either the passive mode via backscatter communications or the active mode via RF communications, depending on their channel conditions and energy states. We aim to maximize the overall throughput by jointly optimizing the access point's beamforming and the relays' radio modes and operating parameters. Due to the non-convex and combinatorial structure, we develop a novel optimization-driven hierarchical deep deterministic policy gradient (H-DDPG) approach to adapt the beamforming and relay strategies dynamically. The optimization-driven H-DDPG algorithm firstly decomposes the binary relay mode selection into the outer-loop deep Q-network (DQN) algorithm and then optimizes the continuous beamforming and relaying parameters by using the inner-loop DDPG algorithm. Secondly, to improve the learning efficiency, we integrate the model-based optimization into the DDPG framework by providing a better-informed target estimation for DNN training. Simulation results reveal that these two special designs ensure a more stable learning and achieve a higher reward performance, up to nearly 20%, compared to the conventional DDPG approach.      
### 24.Two-Stage Deep Learning for Accelerated 3D Time-of-Flight MRA without Matched Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.01362.pdf)
>  Time-of-flight magnetic resonance angiography (TOF-MRA) is one of the most widely used non-contrast MR imaging methods to visualize blood vessels, but due to the 3-D volume acquisition highly accelerated acquisition is necessary. Accordingly, high quality reconstruction from undersampled TOF-MRA is an important research topic for deep learning. However, most existing deep learning works require matched reference data for supervised training, which are often difficult to obtain. By extending the recent theoretical understanding of cycleGAN from the optimal transport theory, here we propose a novel two-stage unsupervised deep learning approach, which is composed of the multi-coil reconstruction network along the coronal plane followed by a multi-planar refinement network along the axial plane. Specifically, the first network is trained in the square-root of sum of squares (SSoS) domain to achieve high quality parallel image reconstruction, whereas the second refinement network is designed to efficiently learn the characteristics of highly-activated blood flow using double-headed max-pool discriminator. Extensive experiments demonstrate that the proposed learning process without matched reference exceeds performance of state-of-the-art compressed sensing (CS)-based method and provides comparable or even better results than supervised learning approaches.      
### 25.Intra-class variation reduction of speaker representation in disentanglement framework  [ :arrow_down: ](https://arxiv.org/pdf/2008.01348.pdf)
>  In this paper, we propose an effective training strategy to ex-tract robust speaker representations from a speech signal. Oneof the key challenges in speaker recognition tasks is to learnlatent representations or embeddings containing solely speakercharacteristic information in order to be robust in terms of intra-speaker variations. By modifying the network architecture togenerate both speaker-related and speaker-unrelated representa-tions, we exploit a learning criterion which minimizes the mu-tual information between these disentangled embeddings. Wealso introduce an identity change loss criterion which utilizes areconstruction error to different utterances spoken by the samespeaker. Since the proposed criteria reduce the variation ofspeaker characteristics caused by changes in background envi-ronment or spoken content, the resulting embeddings of eachspeaker become more consistent. The effectiveness of the pro-posed method is demonstrated through two tasks; disentangle-ment performance, and improvement of speaker recognition ac-curacy compared to the baseline model on a benchmark dataset,VoxCeleb1. Ablation studies also show the impact of each cri-terion on overall performance.      
### 26.Identification and Correction of False Data Injection Attacks against AC State Estimation using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.01330.pdf)
>  recent literature has proposed various detection and identification methods for FDIAs, but few studies have focused on a solution that would prevent such attacks from occurring. However, great strides have been made using deep learning to detect attacks. Inspired by these advancements, we have developed a new methodology for not only identifying AC FDIAs but, more importantly, for correction as well. Our methodology utilizes a Long-Short Term Memory Denoising Autoencoder (LSTM-DAE) to correct attacked-estimated states based on the attacked measurements. The method was evaluated using the IEEE 30 system, and the experiments demonstrated that the proposed method was successfully able to identify the corrupted states and correct them with high accuracy.      
### 27.Minimizing Electricity Cost through Smart Lighting Control for Indoor Plant Factories  [ :arrow_down: ](https://arxiv.org/pdf/2008.01325.pdf)
>  Smart plant factories incorporate sensing technology, actuators and control algorithms to automate processes, reducing the cost of production while improving crop yield many times over that of traditional farms. This paper investigates the growth of lettuce (Lactuca Sativa) in a smart farming setup when exposed to red and blue light-emitting diode (LED) horticulture lighting. An image segmentation method based on K-means clustering is used to identify the size of the plant at each stage of growth, and the growth of the plant modelled in a feed forward network. Finally, an optimization algorithm based on the plant growth model is proposed to find the optimal lighting schedule for growing lettuce with respect to dynamic electricity pricing. Genetic algorithm was utilized to find solutions to the optimization problem. When compared to a baseline in a simulation setting, the schedules proposed by the genetic algorithm can achieved between 40-52% savings in energy costs, and up to a 6% increase in leaf area.      
### 28.A User Guide to Low-Pass Graph Signal Processing and its Applications  [ :arrow_down: ](https://arxiv.org/pdf/2008.01305.pdf)
>  The notion of graph filters can be used to define generative models for graph data. In fact, the data obtained from many examples of network dynamics may be viewed as the output of a graph filter. With this interpretation, classical signal processing tools such as frequency analysis have been successfully applied with analogous interpretation to graph data, generating new insights for data science. What follows is a user guide on a specific class of graph data, where the generating graph filters are low-pass, i.e., the filter attenuates contents in the higher graph frequencies while retaining contents in the lower frequencies. Our choice is motivated by the prevalence of low-pass models in application domains such as social networks, financial markets, and power systems. We illustrate how to leverage properties of low-pass graph filters to learn the graph topology or identify its community structure; efficiently represent graph data through sampling, recover missing measurements, and de-noise graph data; the low-pass property is also used as the baseline to detect anomalies.      
### 29.Weakly Supervised Construction of ASR Systems with Massive Video Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.01300.pdf)
>  Building Automatic Speech Recognition (ASR) systems from scratch is significantly challenging, mostly due to the time-consuming and financially-expensive process of annotating a large amount of audio data with transcripts. Although several unsupervised pre-training models have been proposed, applying such models directly might still be sub-optimal if more labeled, training data could be obtained without a large cost. In this paper, we present a weakly supervised framework for constructing ASR systems with massive video data. As videos often contain human-speech audios aligned with subtitles, we consider videos as an important knowledge source, and propose an effective approach to extract high-quality audios aligned with transcripts from videos based on Optical Character Recognition (OCR). The underlying ASR model can be fine-tuned to fit any domain-specific target training datasets after weakly supervised pre-training. Extensive experiments show that our framework can easily produce state-of-the-art results on six public datasets for Mandarin speech recognition.      
### 30.Guaranteed Phase &amp; Topology Identification in Three Phase Distribution Grids  [ :arrow_down: ](https://arxiv.org/pdf/2008.01255.pdf)
>  We present a method for joint phase identification and topology recovery from voltage measurements in unbalanced three phase radial networks. By recovering phases and topology jointly, we make use of all three phase measurements and can handle networks where some buses have only a subset of three phases. Our method is theoretically justified by a novel linearized formulation of unbalanced three phase power flow and makes precisely defined and reasonable assumptions on line impedances and load statistics. We connect our approach to the heuristics of prior work to explain why they often succeed. We validate our method on three IEEE test networks simulated under realistic conditions in OpenDSS, comparing our performance to the state of the art. In addition to providing a new method for phase and topology recovery, our intuitively structured linearized model will provide a foundation for future work in this and other applications.      
### 31.Graph Signal Processing and Deep Learning: Convolution, Pooling, and Topology  [ :arrow_down: ](https://arxiv.org/pdf/2008.01247.pdf)
>  Deep learning, particularly convolutional neural networks (CNNs), have yielded rapid, significant improvements in computer vision and related domains. But conventional deep learning architectures perform poorly when data have an underlying graph structure, as in social, biological, and many other domains. This paper explores 1)how graph signal processing (GSP) can be used to extend CNN components to graphs in order to improve model performance; and 2)how to design the graph CNN architecture based on the topology or structure of the data graph.      
### 32.Fully Decentralized Reinforcement Learning-based Control of Photovoltaics in Distribution Grids for Joint Provision of Real and Reactive Power  [ :arrow_down: ](https://arxiv.org/pdf/2008.01231.pdf)
>  In this paper, we introduce a new framework to address the problem of voltage regulation in unbalanced distribution grids with deep photovoltaic penetration. Both real and reactive power setpoints are explicitly controlled at each solar panel smart inverter, and the objective is to simultaneously minimize system-wide voltage deviation and maximize solar power output. We formulate the problem as a Markov decision process (MDP) with continuous action spaces and use proximal policy optimization (PPO), a reinforcement learning (RL)-based approach, to solve it, without the need for any forecast or explicit knowledge of network topology or line parameters. By representing the system in a quasi-steady state manner, and by carefully formulating the MDP, we reduce the complexity of the problem and allow for fully decentralized (communication-free) policies, all of which make the trained policies much more practical and interpretable. Numerical simulations on a 240-node unbalanced distribution grid, based off of a real network in Midwest U.S., are used to validate the proposed framework and RL approach.      
### 33.Short-Term Reliability Evaluation of Generating Systems Using Fixed-Effort Generalized Splitting  [ :arrow_down: ](https://arxiv.org/pdf/2008.01230.pdf)
>  The short-term reliability evaluation techniques provide a rational approach for risk-informed decision making during power system operation. The existing reliability assessment techniques involve large computational burden and therefore are not directly applicable for short-term reliability evaluation during system operation. To this end, this paper presents a computationally-efficient approach for short-term reliability evaluation of wind-integrated generating systems. The proposed approach makes use of the fixed-effort generalized splitting (FEGS) technique, which is a variant of importance splitting. To realize the implementation of FEGS, a discrete version of component-wise Metropolis-Hastings (MH) algorithm for Markov Chain Monte-Carlo (MCMC) is also presented. Besides, the proposed FEGS approach is extended to take the uncertainties of wind generation and load demand into account. The simulation results indicate that, in comparison to crude Monte-Carlo simulation (CMCS), the proposed approach is able to evaluate short-term reliability indices with a low computational burden. Moreover, further simulation results indicate the impacts of uncertainties of wind generation and load demand on short-term reliability indices.      
### 34.Configuration Learning in Underwater Optical Links  [ :arrow_down: ](https://arxiv.org/pdf/2008.01221.pdf)
>  A new research problem named configuration learning is described in this work. A novel algorithm is proposed to address the configuration learning problem. The configuration learning problem is defined to be the optimization of the Machine Learning (ML) classifier to maximize the ML performance metric optimizing the transmitter configuration in the signal processing/communication systems. Specifically, this configuration learning problem is investigated in an underwater optical communication system with signal processing performance metric of the physical-layer communication throughput. A novel algorithm is proposed to perform the configuration learning by alternating optimization of key design parameters and switching between several Recurrent Neural Network (RNN) classifiers dependant on the learning objective. The proposed ML algorithm is validated with the datasets of an underwater optical communication system and is compared with competing ML algorithms. Performance results indicate that the proposal outperforms the competing algorithms for binary and multi-class configuration learning in underwater optical communication datasets. The proposed configuration learning framework can be further investigated and applied to a broad range of topics in signal processing and communications.      
### 35.Xilinx RF-SoC-based Digital Multi-Beam Array Processors for 28/60~GHz Wireless Testbeds  [ :arrow_down: ](https://arxiv.org/pdf/2008.01220.pdf)
>  Emerging wireless applications such as 5G cellular, large intelligent surfaces (LIS), and holographic massive MIMO require antenna array processing at mm-wave frequencies with large numbers of independent digital transceivers. This paper summarizes the authors' recent progress on the design and testing of 28 GHz and 60 GHz fully-digital array processing platforms based on wideband reconfigurable FPGA-based software-defined radios (SDRs). The digital baseband and microwave interfacing aspects of the SDRs are implemented on single-chip RF system-on-chip (RF-SoC) processors from Xilinx. Two versions of the RF-SoC technology (ZCU-111 and ZCU-1275) were used to implement fully-digital real-time array processors at 28~GHz (realizing 4 parallel beams with 0.8 GHz bandwidth per beam) and 60~GHz (realizing 4 parallel beams with 1.8~GHz bandwidth per beam). Dielectric lenslet arrays fed by a digital phased-array feed (PAF) located on the focal plane are proposed for further increasing antenna array gain.      
### 36.Hardware Accelerator for Adversarial Attacks on Deep Learning Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01219.pdf)
>  Recent studies identify that Deep learning Neural Networks (DNNs) are vulnerable to subtle perturbations, which are not perceptible to human visual system but can fool the DNN models and lead to wrong outputs. A class of adversarial attack network algorithms has been proposed to generate robust physical perturbations under different circumstances. These algorithms are the first efforts to move forward secure deep learning by providing an avenue to train future defense networks, however, the intrinsic complexity of them prevents their broader usage. <br>In this paper, we propose the first hardware accelerator for adversarial attacks based on memristor crossbar arrays. Our design significantly improves the throughput of a visual adversarial perturbation system, which can further improve the robustness and security of future deep learning systems. Based on the algorithm uniqueness, we propose four implementations for the adversarial attack accelerator ($A^3$) to improve the throughput, energy efficiency, and computational efficiency.      
### 37.Generalisable Cardiac Structure Segmentation via Attentional and Stacked Image Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2008.01216.pdf)
>  Tackling domain shifts in multi-centre and multi-vendor data sets remains challenging for cardiac image segmentation. In this paper, we propose a generalisable segmentation framework for cardiac image segmentation in which multi-centre, multi-vendor, multi-disease datasets are involved. A generative adversarial networks with an attention loss was proposed to translate the images from existing source domains to a target domain, thus to generate good-quality synthetic cardiac structure and enlarge the training set. A stack of data augmentation techniques was further used to simulate real-world transformation to boost the segmentation performance for unseen domains.We achieved an average Dice score of 90.3% for the left ventricle, 85.9% for the myocardium, and 86.5% for the right ventricle on the hidden validation set across four vendors. We show that the domain shifts in heterogeneous cardiac imaging datasets can be drastically reduced by two aspects: 1) good-quality synthetic data by learning the underlying target domain distribution, and 2) stacked classical image processing techniques for data augmentation.      
### 38.A Passive STAR Microwave Circuit for 1-3 GHz Self-Interference Cancellation  [ :arrow_down: ](https://arxiv.org/pdf/2008.01203.pdf)
>  Simultaneous transmit and receive (STAR) allows full-duplex operation of a radio, which leads to doubled capacity for a given bandwidth. A circulator with high-isolation between transmit and receive ports, and low-loss from the antenna to receive port is typically required for achieving STAR. Conventional circulators do not offer wideband performance. Although wideband circulators have been proposed using parametric, switched delay-line/capacitor, and N-path filter techniques using custom integrated circuits, these magnet-free devices have non-linearity, noise, aliasing, and switching noise injection issues. In this paper, a STAR front-end based on passive linear microwave circuit is proposed. Here, a dummy antenna located inside a miniature RF-silent absorption chamber allows circulator-free STAR using simple COTS components. The proposed approach is highly-linear, free from noise, does not require switching or parametric modulation circuits, and has virtually unlimited bandwidth only set by the performance of COTS passive microwave components. The trade-off is relatively large size of the miniature RF-shielded chamber, making this suitable for base-station side applications. Preliminary results show the measured performance of Tx/Rx isolation between 25-60 dB in the 1.0-3.0 GHz range, and 50-60 dB for the 2.4-2.7 GHz range.      
### 39.Generative Adversarial Networks for Synthesizing InSAR Patches  [ :arrow_down: ](https://arxiv.org/pdf/2008.01184.pdf)
>  Generative Adversarial Networks (GANs) have been employed with certain success for image translation tasks between optical and real-valued SAR intensity imagery. Applications include aiding interpretability of SAR scenes with their optical counterparts by artificial patch generation and automatic SAR-optical scene matching. The synthesis of artificial complex-valued InSAR image stacks asks for, besides good perceptual quality, more stringent quality metrics like phase noise and phase coherence. This paper provides a signal processing model of generative CNN structures, describes effects influencing those quality metrics and presents a mapping scheme of complex-valued data to given CNN structures based on popular Deep Learning frameworks.      
### 40.A Spectral Energy Distance for Parallel Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.01160.pdf)
>  Speech synthesis is an important practical generative modeling problem that has seen great progress over the last few years, with likelihood-based autoregressive neural models now outperforming traditional concatenative systems. A downside of such autoregressive models is that they require executing tens of thousands of sequential operations per second of generated audio, making them ill-suited for deployment on specialized deep learning hardware. Here, we propose a new learning method that allows us to train highly parallel models of speech, without requiring access to an analytical likelihood function. Our approach is based on a generalized energy distance between the distributions of the generated and real audio. This spectral energy distance is a proper scoring rule with respect to the distribution over magnitude-spectrograms of the generated waveform audio and offers statistical consistency guarantees. The distance can be calculated from minibatches without bias, and does not involve adversarial learning, yielding a stable and consistent method for training implicit generative models. Empirically, we achieve state-of-the-art generation quality among implicit generative models, as judged by the recently-proposed cFDSD metric. When combining our method with adversarial techniques, we also improve upon the recently-proposed GAN-TTS model in terms of Mean Opinion Score as judged by trained human evaluators.      
### 41.Effects of Turbulence Induced Scattering on Underwater Optical Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.01152.pdf)
>  This paper presents a comprehensive description of the relative effect of optical underwater turbulence in combination with absorption and scattering. Turbulence induced scattering is shown to cause and increase both spatial and temporal spreading at the receiver plane. It is also demonstrated that the relative impact of turbulence on a received signal is lower in a highly scattering channel. Received intensity distributions are presented confirming that fluctuations in received power from this method follow the commonly used Log-Normal fading model. The impact of turbulence induced scattering on maximum achievable data rate in the underwater channel is investigated.      
### 42.3D B-mode ultrasound speckle reduction using deep learning for 3D registration applications  [ :arrow_down: ](https://arxiv.org/pdf/2008.01147.pdf)
>  Ultrasound (US) speckles are granular patterns which can impede image post-processing tasks, such as image segmentation and registration. Conventional filtering approaches are commonly used to remove US speckles, while their main drawback is long run-time in a 3D scenario. Although a few studies were conducted to remove 2D US speckles using deep learning, to our knowledge, there is no study to perform speckle reduction of 3D B-mode US using deep learning. In this study, we propose a 3D dense U-Net model to process 3D US B-mode data from a clinical US system. The model's results were applied to 3D registration. We show that our deep learning framework can obtain similar suppression and mean preservation index (1.066) on speckle reduction when compared to conventional filtering approaches (0.978), while reducing the runtime by two orders of magnitude. Moreover, it is found that the speckle reduction using our deep learning model contributes to improving the 3D registration performance. The mean square error of 3D registration on 3D data using 3D U-Net speckle reduction is reduced by half compared to that with speckles.      
### 43.Energy-aware Graph Job Allocation in Software Defined Air-Ground Integrated Vehicular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01144.pdf)
>  The software defined air-ground integrated vehicular (SD-AGV) networks have emerged as a promising paradigm, which realize the flexible on-ground resource sharing to support innovative applications for UAVs with heavy computational overhead. In this paper, we investigate a vehicular cloud-assisted graph job allocation problem in SD-AGV networks, where the computation-intensive jobs carried by UAVs, and the vehicular cloud are modeled as graphs. To map each component of the graph jobs to a feasible vehicle, while achieving the trade-off among minimizing UAVs' job completion time, energy consumption, and the data exchange cost among vehicles, we formulate the problem as a mixed-integer non-linear programming problem, which is Np-hard. Moreover, the constraint associated with preserving job structures poses addressing the subgraph isomorphism problem, that further complicates the algorithm design. Motivated by which, we propose an efficient decoupled approach by separating the template (feasible mappings between components and vehicles) searching from the transmission power allocation. For the former, we present an efficient algorithm of searching for all the subgraph isomorphisms with low computation complexity. For the latter, we introduce a power allocation algorithm by applying convex optimization techniques. Extensive simulations demonstrate that the proposed approach outperforms the benchmark methods considering various problem sizes.      
### 44.Probabilistic Conformance for Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.01135.pdf)
>  Conformance is a key concept in the analysis of cyber-physical systems (CPS). It indicates that two models simultaneously satisfy the same specifications of interest practically so that the result of analyzing one model automatically transfers to the other. In this paper, we propose a new concept of probabilistic conformance for CPS, extending previous study to the probabilistic domain. It is defined by the approximately equal satisfaction probabilities for a given parameterized signal temporal logic specification. Then we propose the first statistical verification method for probabilistic conformance of temporal logic specifications for grey-box CPS. To this end, we introduce a novel extended Kolmogorov-Smirnov test that can check approximately equal of two probability distributions for any desired confidence level (&lt; 1). We apply our technique to verify the probabilistic conformance of: (1) the startup time of the widely-used full and simplified models of the Toyota Powertrain system, (2) the settling time of lane-keeping controllers based on model predictive control and neural network (NN)-based lane-keeping controllers of different sizes for an autonomous car, and (3) the maximal deviation of DC voltage between the full and simplified models of a power grid system.      
### 45.Sub-Pixel Back-Projection Network For Lightweight Single Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2008.01116.pdf)
>  Convolutional neural network (CNN)-based methods have achieved great success for single-image superresolution (SISR). However, most models attempt to improve reconstruction accuracy while increasing the requirement of number of model parameters. To tackle this problem, in this paper, we study reducing the number of parameters and computational cost of CNN-based SISR methods while maintaining the accuracy of super-resolution reconstruction performance. To this end, we introduce a novel network architecture for SISR, which strikes a good trade-off between reconstruction quality and low computational complexity. Specifically, we propose an iterative back-projection architecture using sub-pixel convolution instead of deconvolution layers. We evaluate the performance of computational and reconstruction accuracy for our proposed model with extensive quantitative and qualitative evaluations. Experimental results reveal that our proposed method uses fewer parameters and reduces the computational cost while maintaining reconstruction accuracy against state-of-the-art SISR methods over well-known four SR benchmark datasets. Code is available at "<a class="link-external link-https" href="https://github.com/supratikbanerjee/SubPixel-BackProjection_SuperResolution" rel="external noopener nofollow">this https URL</a>".      
### 46.Self-attention encoding and pooling for speaker recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.01077.pdf)
>  The computing power of mobile devices limits the end-user applications in terms of storage size, processing, memory and energy consumption. These limitations motivate researchers for the design of more efficient deep models. On the other hand, self-attention networks based on Transformer architecture have attracted remarkable interests due to their high parallelization capabilities and strong performance on a variety of Natural Language Processing (NLP) applications. Inspired by the Transformer, we propose a tandem Self-Attention Encoding and Pooling (SAEP) mechanism to obtain a discriminative speaker embedding given non-fixed length speech utterances. SAEP is a stack of identical blocks solely relied on self-attention and position-wise feed-forward networks to create vector representation of speakers. This approach encodes short-term speaker spectral features into speaker embeddings to be used in text-independent speaker verification. We have evaluated this approach on both VoxCeleb1 &amp; 2 datasets. The proposed architecture is able to outperform the baseline x-vector, and shows competitive performance to some other benchmarks based on convolutions, with a significant reduction in model size. It employs 94%, 95%, and 73% less parameters compared to ResNet-34, ResNet-50, and x-vector, respectively. This indicates that the proposed fully attention based architecture is more efficient in extracting time-invariant features from speaker utterances.      
### 47.Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy Blind Deconvolution  [ :arrow_down: ](https://arxiv.org/pdf/2008.01724.pdf)
>  We investigate the effectiveness of convex relaxation and nonconvex optimization in solving bilinear systems of equations (a.k.a. blind deconvolution under a subspace model). Despite the wide applicability, the theoretical understanding about these two paradigms remains largely inadequate in the presence of noise. The current paper makes two contributions by demonstrating that: (1) convex relaxation achieves minimax-optimal statistical accuracy vis--vis random noise, and (2) a two-stage nonconvex algorithm attains minimax-optimal accuracy within a logarithmic number of iterations. Both results improve upon the state-of-the-art results by some factors that scale polynomially in the problem dimension.      
### 48.Applying Incremental Deep Neural Networks-based Posture Recognition Model for Injury Risk Assessment in Construction  [ :arrow_down: ](https://arxiv.org/pdf/2008.01679.pdf)
>  Monitoring awkward postures is a proactive prevention for Musculoskeletal Disorders (MSDs)in construction. Machine Learning (ML) models have shown promising results for posture recognition from Wearable Sensors. However, further investigations are needed concerning: i) Incremental Learning (IL), where trained models adapt to learn new postures and control the forgetting of learned postures; ii) MSDs assessment with recognized postures. This study proposed an incremental Convolutional Long Short-Term Memory (CLN) model, investigated effective IL strategies, and evaluated MSDs assessment using recognized postures. Tests with nine workers showed the CLN model with shallow convolutional layers achieved high recognition performance (F1 Score) under personalized (0.87) and generalized (0.84) modeling. Generalized shallow CLN model under Many-to-One IL scheme can balance the adaptation (0.73) and forgetting of learnt subjects (0.74). MSDs assessment using postures recognized from incremental CLN model had minor difference with ground-truth, which demonstrates the high potential for automated MSDs monitoring in construction.      
### 49.Deep Multi-modality Soft-decoding of Very Low Bit-rate Face Videos  [ :arrow_down: ](https://arxiv.org/pdf/2008.01652.pdf)
>  We propose a novel deep multi-modality neural network for restoring very low bit rate videos of talking heads. Such video contents are very common in social media, teleconferencing, distance education, tele-medicine, etc., and often need to be transmitted with limited bandwidth. The proposed CNN method exploits the correlations among three modalities, video, audio and emotion state of the speaker, to remove the video compression artifacts caused by spatial down sampling and quantization. The deep learning approach turns out to be ideally suited for the video restoration task, as the complex non-linear cross-modality correlations are very difficult to model analytically and explicitly. The new method is a video post processor that can significantly boost the perceptual quality of aggressively compressed talking head videos, while being fully compatible with all existing video compression standards.      
### 50.Text-based classification of interviews for mental health -- juxtaposing the state of the art  [ :arrow_down: ](https://arxiv.org/pdf/2008.01543.pdf)
>  Currently, the state of the art for classification of psychiatric illness is based on audio-based classification. This thesis aims to design and evaluate a state of the art text classification network on this challenge. The hypothesis is that a well designed text-based approach poses a strong competition against the state-of-the-art audio based approaches. Dutch natural language models are being limited by the scarcity of pre-trained monolingual NLP models, as a result Dutch natural language models have a low capture of long range semantic dependencies over sentences. For this issue, this thesis presents belabBERT, a new Dutch language model extending the RoBERTa[15] architecture. belabBERT is trained on a large Dutch corpus (+32GB) of web crawled texts. After this thesis evaluates the strength of text-based classification, a brief exploration is done, extending the framework to a hybrid text- and audio-based classification. The goal of this hybrid framework is to show the principle of hybridisation with a very basic audio-classification network. The overall goal is to create the foundations for a hybrid psychiatric illness classification, by proving that the new text-based classification is already a strong stand-alone solution.      
### 51.A Study on Effects of Implicit and Explicit Language Model Information for DBLSTM-CTC Based Handwriting Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.01532.pdf)
>  Deep Bidirectional Long Short-Term Memory (D-BLSTM) with a Connectionist Temporal Classification (CTC) output layer has been established as one of the state-of-the-art solutions for handwriting recognition. It is well known that the DBLSTM trained by using a CTC objective function will learn both local character image dependency for character modeling and long-range contextual dependency for implicit language modeling. In this paper, we study the effects of implicit and explicit language model information for DBLSTM-CTC based handwriting recognition by comparing the performance of using or without using an explicit language model in decoding. It is observed that even using one million lines of training sentences to train the DBLSTM, using an explicit language model is still helpful. To deal with such a large-scale training problem, a GPU-based training tool has been developed for CTC training of DBLSTM by using a mini-batch based epochwise Back Propagation Through Time (BPTT) algorithm.      
### 52.Throughput Maximization in Uncooperative Spectrum Sharing Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01528.pdf)
>  Throughput-optimal transmission scheduling in wireless networks has been a well considered problem in the literature, and the method for achieving optimality, MaxWeight scheduling, has been known for several decades. This algorithm achieves optimality by adaptively scheduling transmissions relative to each user's stochastic traffic demands. To implement the method, users must report their queue backlogs to the network controller and must rapidly respond to the resulting resource allocations. However, many currently-deployed wireless systems are not able to perform these tasks and instead expect to occupy a fixed assignment of resources. To accommodate these limitations, adaptive scheduling algorithms need to interactively estimate these uncooperative users' queue backlogs and make scheduling decisions to account for their predicted behavior. In this work, we address the problem of scheduling with uncooperative legacy systems by developing algorithms to accomplish these tasks. We begin by formulating the problem of inferring the uncooperative systems' queue backlogs as a partially observable Markov decision process and proceed to show how our resulting learning algorithms can be successfully used in a queue-length-based scheduling policy. Our theoretical analysis characterizes the throughput-stability region of the network and is verified using simulation results.      
### 53.Expressive TTS Training with Frame and Style Reconstruction Loss  [ :arrow_down: ](https://arxiv.org/pdf/2008.01490.pdf)
>  We propose a novel training strategy for Tacotron-based text-to-speech (TTS) system to improve the expressiveness of speech. One of the key challenges in prosody modeling is the lack of reference that makes explicit modeling difficult. The proposed technique doesn't require prosody annotations from training data. It doesn't attempt to model prosody explicitly either, but rather encodes the association between input text and its prosody styles using a Tacotron-based TTS framework. Our proposed idea marks a departure from the style token paradigm where prosody is explicitly modeled by a bank of prosody embeddings. The proposed training strategy adopts a combination of two objective functions: 1) frame level reconstruction loss, that is calculated between the synthesized and target spectral features; 2) utterance level style reconstruction loss, that is calculated between the deep style features of synthesized and target speech. The proposed style reconstruction loss is formulated as a perceptual loss to ensure that utterance level speech style is taken into consideration during training. Experiments show that the proposed training strategy achieves remarkable performance and outperforms a state-of-the-art baseline in both naturalness and expressiveness. To our best knowledge, this is the first study to incorporate utterance level perceptual quality as a loss function into Tacotron training for improved expressiveness.      
### 54.Guiding CNNs towards Relevant Concepts by Multi-task and Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.01478.pdf)
>  The opaqueness of deep learning limits its deployment in critical application scenarios such as cancer grading in medical images. In this paper, a framework for guiding CNN training is built on top of successful existing techniques of hard parameter sharing, with the main goal of explicitly introducing expert knowledge in the training objectives. The learning process is guided by identifying concepts that are relevant or misleading for the task. Relevant concepts are encouraged to appear in the representation through multi-task learning. Undesired and misleading concepts are discouraged by a gradient reversal operation. In this way, a shift in the deep representations can be corrected to match the clinicians' assumptions. The application on breast lymph nodes histopathology data from the Camelyon challenge shows a significant increase in the generalization performance on unseen patients (from 0.839 to 0.864 average AUC, $\text{p-value} = 0,0002$) when the internal representations are controlled by prior knowledge regarding the acquisition center and visual features of the tissue. The code will be shared for reproducibility on our GitHub repository.      
### 55.SimRIS Channel Simulator for Reconfigurable Intelligent Surfaces in Future Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01448.pdf)
>  While the researchers have set their sights on future wireless networks of 2030, communications through reconfigurable intelligent surfaces (RISs) appears as one of the potential enabling technologies for 6G wireless networking. This article aims to shed light on the potential use-cases of RISs in future wireless systems by means of a novel channel modeling methodology as well as a new software tool for RIS-empowered millimeter-wave communication systems. It is shown by the open-source, user-friendly, and widely applicable \textit{SimRIS Channel Simulator}, whose 2.0 version is proposed and goes online by this article, that RISs will provide substantial improvements under certain use-cases and communication environments from an information theoretical perspective. Potential future research directions are also discussed to bridge the gap between the theory and practice of RIS-empowered systems towards their standardization for 6G wireless networks.      
### 56.Automatic Composition of Guitar Tabs by Transformers and Groove Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2008.01431.pdf)
>  Deep learning algorithms are increasingly developed for learning to compose music in the form of MIDI files. However, whether such algorithms work well for composing guitar tabs, which are quite different from MIDIs, remain relatively unexplored. To address this, we build a model for composing fingerstyle guitar tabs with Transformer-XL, a neural sequence model architecture. With this model, we investigate the following research questions. First, whether the neural net generates note sequences with meaningful note-string combinations, which is important for the guitar but not other instruments such as the piano. Second, whether it generates compositions with coherent rhythmic groove, crucial for fingerstyle guitar music. And, finally, how pleasant the composed music is in comparison to real, human-made compositions. Our work provides preliminary empirical evidence of the promise of deep learning for tab composition, and suggests areas for future study.      
### 57.MSDPN: Monocular Depth Prediction with Partial Laser Observation using Multi-stage Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.01405.pdf)
>  In this study, a deep-learning-based multi-stage network architecture called Multi-Stage Depth Prediction Network (MSDPN) is proposed to predict a dense depth map using a 2D LiDAR and a monocular camera. Our proposed network consists of a multi-stage encoder-decoder architecture and Cross Stage Feature Aggregation (CSFA). The proposed multi-stage encoder-decoder architecture alleviates the partial observation problem caused by the characteristics of a 2D LiDAR, and CSFA prevents the multi-stage network from diluting the features and allows the network to learn the inter-spatial relationship between features better. Previous works use sub-sampled data from the ground truth as an input rather than actual 2D LiDAR data. In contrast, our approach trains the model and conducts experiments with a physically-collected 2D LiDAR dataset. To this end, we acquired our own dataset called KAIST RGBD-scan dataset and validated the effectiveness and the robustness of MSDPN under realistic conditions. As verified experimentally, our network yields promising performance against state-of-the-art methods. Additionally, we analyzed the performance of different input methods and confirmed that the reference depth map is robust in untrained scenarios.      
### 58.Neural Granular Sound Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.01393.pdf)
>  Granular sound synthesis is a popular audio generation technique based on rearranging sequences of small waveform windows. In order to control the synthesis, all grains in a given corpus are analyzed through a set of acoustic descriptors. This provides a representation reflecting some form of local similarities across the grains. However, the quality of this grain space is bound by that of the descriptors. Its traversal is not continuously invertible to signal and does not render any structured temporality. We demonstrate that generative neural networks can implement granular synthesis while alleviating most of its shortcomings. We efficiently replace its audio descriptor basis by a probabilistic latent space learned with a Variational Auto-Encoder. A major advantage of our proposal is that the resulting grain space is invertible, meaning that we can continuously synthesize sound when traversing its dimensions. It also implies that original grains are not stored for synthesis. To learn structured paths inside this latent space, we add a higher-level temporal embedding trained on arranged grain sequences. The model can be applied to many types of libraries, including pitched notes or unpitched drums and environmental noises. We experiment with the common granular synthesis processes and enable new ones.      
### 59.Timbre latent space: exploration and creative aspects  [ :arrow_down: ](https://arxiv.org/pdf/2008.01370.pdf)
>  Recent studies show the ability of unsupervised models to learn invertible audio representations using Auto-Encoders. They enable high-quality sound synthesis but a limited control since the latent spaces do not disentangle timbre properties. The emergence of disentangled representations was studied in Variational Auto-Encoders (VAEs), and has been applied to audio. Using an additional perceptual regularization can align such latent representation with the previously established multi-dimensional timbre spaces, while allowing continuous inference and synthesis. Alternatively, some specific sound attributes can be learned as control variables while unsupervised dimensions account for the remaining features. New possibilities for timbre manipulations are enabled with generative neural networks, although the exploration and the creative use of their representations remain little. The following experiments are led in cooperation with two composers and propose new creative directions to explore latent sound synthesis of musical timbres, using specifically designed interfaces (Max/MSP, Pure Data) or mappings for descriptor-based synthesis.      
### 60.The Jazz Transformer on the Front Line: Exploring the Shortcomings of AI-composed Music through Quantitative Measures  [ :arrow_down: ](https://arxiv.org/pdf/2008.01307.pdf)
>  This paper presents the Jazz Transformer, a generative model that utilizes a neural sequence model called the Transformer-XL for modeling lead sheets of Jazz music. Moreover, the model endeavors to incorporate structural events present in the Weimar Jazz Database (WJazzD) for inducing structures in the generated music. While we are able to reduce the training loss to a low value, our listening test suggests however a clear gap between the average ratings of the generated and real compositions. We therefore go one step further and conduct a series of computational analysis of the generated compositions from different perspectives. This includes analyzing the statistics of the pitch class, grooving, and chord progression, assessing the structureness of the music with the help of the fitness scape plot, and evaluating the model's understanding of Jazz music through a MIREX-like continuation prediction task. Our work presents in an analytical manner why machine-generated music to date still falls short of the artwork of humanity, and sets some goals for future work on automatic composition to further pursue.      
### 61.Music SketchNet: Controllable Music Generation via Factorized Representations of Pitch and Rhythm  [ :arrow_down: ](https://arxiv.org/pdf/2008.01291.pdf)
>  Drawing an analogy with automatic image completion systems, we propose Music SketchNet, a neural network framework that allows users to specify partial musical ideas guiding automatic music generation. We focus on generating the missing measures in incomplete monophonic musical pieces, conditioned on surrounding context, and optionally guided by user-specified pitch and rhythm snippets. First, we introduce SketchVAE, a novel variational autoencoder that explicitly factorizes rhythm and pitch contour to form the basis of our proposed model. Then we introduce two discriminative architectures, SketchInpainter and SketchConnector, that in conjunction perform the guided music completion, filling in representations for the missing measures conditioned on surrounding context and user-specified snippets. We evaluate SketchNet on a standard dataset of Irish folk music and compare with models from recent works. When used for music completion, our approach outperforms the state-of-the-art both in terms of objective metrics and subjective listening tests. Finally, we demonstrate that our model can successfully incorporate user-specified snippets during the generation process.      
### 62.Safety design concepts for statistical machine learning components toward accordance with functional safety standards  [ :arrow_down: ](https://arxiv.org/pdf/2008.01263.pdf)
>  In recent years, curial incidents and accidents have been reported due to un-intended control caused by misjudgment of statistical machine learning (SML), which include deep learning. The international functional safety standards for Electric/Electronic/Programmable (E/E/P) systems have been widely spread to improve safety. However, most of them do not recom-mended to use SML in safety critical systems so far. In practical the new concepts and methods are urgently required to enable SML to be safely used in safety critical systems. In this paper, we organize five kinds of technical safety concepts (TSCs) for SML components toward accordance with functional safety standards. We discuss not only quantitative evaluation criteria, but also development process based on XAI (eXplainable Artificial Intelligence) and Automotive SPICE to improve explainability and reliability in development phase. Fi-nally, we briefly compare the TSCs in cost and difficulty, and expect to en-courage further discussion in many communities and domain.      
### 63.Multi-Class 3D Object Detection Within Volumetric 3D Computed Tomography Baggage Security Screening Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2008.01218.pdf)
>  Automatic detection of prohibited objects within passenger baggage is important for aviation security. X-ray Computed Tomography (CT) based 3D imaging is widely used in airports for aviation security screening whilst prior work on automatic prohibited item detection focus primarily on 2D X-ray imagery. These works have proven the possibility of extending deep convolutional neural networks (CNN) based automatic prohibited item detection from 2D X-ray imagery to volumetric 3D CT baggage security screening imagery. However, previous work on 3D object detection in baggage security screening imagery focused on the detection of one specific type of objects (e.g., either {\it bottles} or {\it handguns}). As a result, multiple models are needed if more than one type of prohibited item is required to be detected in practice. In this paper, we consider the detection of multiple object categories of interest using one unified framework. To this end, we formulate a more challenging multi-class 3D object detection problem within 3D CT imagery and propose a viable solution (3D RetinaNet) to tackle this problem. To enhance the performance of detection we investigate a variety of strategies including data augmentation and varying backbone networks. Experimentation carried out to provide both quantitative and qualitative evaluations of the proposed approach to multi-class 3D object detection within 3D CT baggage security screening imagery. Experimental results demonstrate the combination of the 3D RetinaNet and a series of favorable strategies can achieve a mean Average Precision (mAP) of 65.3\% over five object classes (i.e. {\it bottles, handguns, binoculars, glock frames, iPods}). The overall performance is affected by the poor performance on {\it glock frames} and {\it iPods} due to the lack of data and their resemblance with the baggage clutter.      
### 64.Mixup-CAM: Weakly-supervised Semantic Segmentation via Uncertainty Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2008.01201.pdf)
>  Obtaining object response maps is one important step to achieve weakly-supervised semantic segmentation using image-level labels. However, existing methods rely on the classification task, which could result in a response map only attending on discriminative object regions as the network does not need to see the entire object for optimizing the classification loss. To tackle this issue, we propose a principled and end-to-end train-able framework to allow the network to pay attention to other parts of the object, while producing a more complete and uniform response map. Specifically, we introduce the mixup data augmentation scheme into the classification network and design two uncertainty regularization terms to better interact with the mixup strategy. In experiments, we conduct extensive analysis to demonstrate the proposed method and show favorable performance against state-of-the-art approaches.      
### 65.Weakly-Supervised Semantic Segmentation via Sub-category Exploration  [ :arrow_down: ](https://arxiv.org/pdf/2008.01183.pdf)
>  Existing weakly-supervised semantic segmentation methods using image-level annotations typically rely on initial responses to locate object regions. However, such response maps generated by the classification network usually focus on discriminative object parts, due to the fact that the network does not need the entire object for optimizing the objective function. To enforce the network to pay attention to other parts of an object, we propose a simple yet effective approach that introduces a self-supervised task by exploiting the sub-category information. Specifically, we perform clustering on image features to generate pseudo sub-categories labels within each annotated parent class, and construct a sub-category objective to assign the network to a more challenging task. By iteratively clustering image features, the training process does not limit itself to the most discriminative object parts, hence improving the quality of the response maps. We conduct extensive analysis to validate the proposed method and show that our approach performs favorably against the state-of-the-art approaches.      
### 66.Control Interface for Hands-free Navigation of Standing Mobility Vehicles based on Upper-Body Natural Movements  [ :arrow_down: ](https://arxiv.org/pdf/2008.01181.pdf)
>  In this paper, we propose and evaluate a novel human-machine interface (HMI) for controlling a standing mobility vehicle or person carrier robot, aiming for a hands-free control through upper-body natural postures derived from gaze tracking while walking. We target users with lower-body impairment with remaining upper-body motion capabilities. The developed HMI bases on a sensing array for capturing body postures; an intent recognition algorithm for continuous mapping of body motions to robot control space; and a personalizing system for multiple body sizes and shapes. We performed two user studies: first, an analysis of the required body muscles involved in navigating with the proposed control; and second, an assessment of the HMI compared with a standard joystick through quantitative and qualitative metrics in a narrow circuit task. We concluded that the main user control contribution comes from Rectus Abdominis and Erector Spinae muscle groups at different levels. Finally, the comparative study showed that a joystick still outperforms the proposed HMI in usability perceptions and controllability metrics, however, the smoothness of user control was similar in jerk and fluency. Moreover, users' perceptions showed that hands-free control made it more anthropomorphic, animated, and even safer.      
### 67.Weakly Supervised Multi-Organ Multi-Disease Classification of Body CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2008.01158.pdf)
>  We designed a multi-organ, multi-label disease classification algorithm for computed tomography (CT) scans using case-level labels from radiology text reports. A rule-based algorithm extracted 19,255 disease labels from reports of 13,667 body CT scans from 12,092 subjects. A 3D DenseVNet was trained to segment 3 organ systems: lungs/pleura, liver/gallbladder, and kidneys. From patches guided by segmentations, a 3D convolutional neural network provided multi-label disease classification for normality versus four common diseases per organ. The process was tested on 2,158 CT volumes with 2,875 manually obtained labels. Manual validation of the rulebased labels confirmed 91 to 99% accuracy. Results were characterized using the receiver operating characteristic area under the curve (AUC). Classification AUCs for lungs/pleura labels were as follows: atelectasis 0.77 (95% confidence intervals 0.74 to 0.81), nodule 0.65 (0.61 to 0.69), emphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89 (0.87 to 0.91). For liver/gallbladder, AUCs were: stone 0.62 (0.56 to 0.67), lesion 0.73 (0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and normal 0.82 (0.78 to 0.85). For kidneys, AUCs were: stone 0.83 (0.79 to 0.87), atrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to 0.73), and normal 0.79 (0.75 to 0.83). In conclusion, by using automated extraction of disease labels from radiology reports, we created a weakly supervised, multi-organ, multi-disease classifier that can be easily adapted to efficiently leverage massive amounts of unannotated data associated with medical images.      
### 68.A method for assessing the spatiotemporal resolution of Structured Illumination Microscopy (SIM)  [ :arrow_down: ](https://arxiv.org/pdf/2008.01146.pdf)
>  A method is proposed for assessing the temporal resolution of Structured Illumination Microscopy (SIM), by tracking the amplitude of different spatial frequency components over time, and comparing them to a temporally-oscillating ground-truth. This method is used to gain insight into the performance limits of SIM, along with alternative reconstruction techniques (termed 'rolling SIM') that claim to improve temporal resolution. Results show that the temporal resolution of SIM varies considerably between low and high spatial frequencies, and that, despite being used in several high profile papers and commercial microscope software, rolling SIM provides no increase in temporal resolution over conventional SIM.      
