# ArXiv eess --Mon, 10 Aug 2020
### 1.Investigation of Speaker-adaptation methods in Transformer based ASR  [ :arrow_down: ](https://arxiv.org/pdf/2008.03247.pdf)
>  End-to-end models are fast replacing conventional hybrid models in automatic speech recognition. A transformer is a sequence-to-sequence framework solely based on attention, that was initially applied to machine translation task. This end-to-end framework has been shown to give promising results when used for automatic speech recognition as well. In this paper, we explore different ways of incorporating speaker information while training a transformer-based model to improve its performance. We present speaker information in the form of speaker embeddings for each of the speakers. Two broad categories of speaker embeddings are used: (i)fixed embeddings, and (ii)learned embeddings. We experiment using speaker embeddings learned along with the model training, as well as one-hot vectors and x-vectors. Using these different speaker embeddings, we obtain an average relative improvement of 1% to 3% in the token error rate. We report results on the NPTEL lecture database. NPTEL is an open-source e-learning portal providing content from top Indian universities.      
### 2.Dissipativity verification with guarantees for polynomial systems from noisy input-state data  [ :arrow_down: ](https://arxiv.org/pdf/2008.03231.pdf)
>  In this paper, we investigate the verification of dissipativity properties for polynomial systems without explicit knowledge of a model but directly from noise-corrupted measurements. Contrary to most data-driven approaches for nonlinear systems, we determine dissipativity properties over infinite time horizon using input-state data. To this end, we propose two characterizations of the noise that affects the system and deduce from each characterization a data-based set-membership representation of the ground-truth system. Each representation then serves as a framework to derive computationally attractive conditions to verify dissipativity properties with rigorous guarantees from noise-corrupted data using SOS optimization.      
### 3.Autonomous Six-Degree-of-Freedom Spacecraft Docking Maneuvers via Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03215.pdf)
>  A policy for six-degree-of-freedom docking maneuvers is developed through reinforcement learning and implemented as a feedback control law. Reinforcement learning provides a potential framework for robust, autonomous maneuvers in uncertain environments with low on-board computational cost. Specifically, proximal policy optimization is used to produce a docking policy that is valid over a portion of the six-degree-of-freedom state-space while striving to minimize performance and control costs. Experiments using the simulated Apollo transposition and docking maneuver exhibit the policy's capabilities and provide a comparison with standard optimal control techniques. Furthermore, specific challenges and work-arounds, as well as a discussion on the benefits and disadvantages of reinforcement learning for docking policies, are discussed to facilitate future research. As such, this work will serve as a foundation for further investigation of learning-based control laws for spacecraft proximity operations in uncertain environments.      
### 4.6G Wireless Systems: Vision, Requirements, Challenges, Insights, and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2008.03213.pdf)
>  Mobile communications have been undergoing a generational change every ten years or so. However, the time difference between the so-called "G's" is also decreasing. While fifth-generation (5G) systems are becoming a commercial reality, there is already significant interest in systems beyond 5G - which we refer to as the sixth-generation (6G) of wireless systems. In contrast to the many published papers on the topic, we take a top-down approach to 6G. We present a holistic discussion of 6G systems beginning with the lifestyle and societal changes driving the need for next generation networks, to the technical requirements needed to enable 6G applications, through to the challenges, as well as possibilities for practically realizable system solutions across all layers of the Open Systems Interconnection stack. Since many of the 6G applications will need access to an order-of-magnitude more spectrum, utilization of frequencies between 100 GHz and 1 THz becomes of paramount importance. We comprehensively characterize the limitations that must be overcome to realize working systems in these bands; and provide a unique perspective on the physical, as well as higher layer challenges relating to the design of next generation core networks, new modulation and coding methods, novel multiple access techniques, antenna arrays, wave propagation, radio-frequency transceiver design, as well as real-time signal processing. We rigorously discuss the fundamental changes required in the core networks of the future, such as the redesign or significant reduction of the transport architecture that serves as a major source of latency. While evaluating the strengths and weaknesses of key technologies, we differentiate what may be practically achievable over the next decade, relative to what is possible in theory. For each discussed system aspect, we present concrete research challenges.      
### 5.In-Depth DCT Coefficient Distribution Analysis for First Quantization Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03206.pdf)
>  The exploitation of traces in JPEG double compressed images is of utter importance for investigations. Properly exploiting such insights, First Quantization Estimation (FQE) could be performed in order to obtain source camera model identification (CMI) and therefore reconstruct the history of a digital image. In this paper, a method able to estimate the first quantization factors for JPEG double compressed images is presented, employing a mixed statistical and Machine Learning approach. The presented solution is demonstrated to work without any a-priori assumptions about the quantization matrices. Experimental results and comparisons with the state-of-the-art show the goodness of the proposed technique.      
### 6.Multi-Task Driven Explainable Diagnosis of COVID-19 using Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.03205.pdf)
>  With increasing number of COVID-19 cases globally, all the countries are ramping up the testing numbers. While the RT-PCR kits are available in sufficient quantity in several countries, others are facing challenges with limited availability of testing kits and processing centers in remote areas. This has motivated researchers to find alternate methods of testing which are reliable, easily accessible and faster. Chest X-Ray is one of the modalities that is gaining acceptance as a screening modality. Towards this direction, the paper has two primary contributions. Firstly, we present the COVID-19 Multi-Task Network which is an automated end-to-end network for COVID-19 screening. The proposed network not only predicts whether the CXR has COVID-19 features present or not, it also performs semantic segmentation of the regions of interest to make the model explainable. Secondly, with the help of medical professionals, we manually annotate the lung regions of 9000 frontal chest radiographs taken from ChestXray-14, CheXpert and a consolidated COVID-19 dataset. Further, 200 chest radiographs pertaining to COVID-19 patients are also annotated for semantic segmentation. This database will be released to the research community.      
### 7.Automatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2008.03193.pdf)
>  Speech sound disorder (SSD) refers to the developmental disorder in which children encounter persistent difficulties in correctly pronouncing words. Assessment of SSD has been relying largely on trained speech and language pathologists (SLPs). With the increasing demand for and long-lasting shortage of SLPs, automated assessment of speech disorder becomes a highly desirable approach to assisting clinical work. This paper describes a study on automatic detection of phonological errors in Cantonese speech of kindergarten children, based on a newly collected large speech corpus. The proposed approach to speech error detection involves the use of a Siamese recurrent autoencoder, which is trained to learn the similarity and discrepancy between phone segments in the embedding space. Training of the model requires only speech data from typically developing (TD) children. To distinguish disordered speech from typical one, cosine distance between the embeddings of the test segment and the reference segment is computed. Different model architectures and training strategies are experimented. Results on detecting the 6 most common consonant errors demonstrate satisfactory performance of the proposed model, with the average precision value from 0.82 to 0.93.      
### 8.CUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2008.03188.pdf)
>  This paper describes the design and development of CUCHILD, a large-scale Cantonese corpus of child speech. The corpus contains spoken words collected from 1,986 child speakers aged from 3 to 6 years old. The speech materials include 130 words of 1 to 4 syllables in length. The speakers cover both typically developing (TD) children and children with speech disorder. The intended use of the corpus is to support scientific and clinical research, as well as technology development related to child speech assessment. The design of the corpus, including selection of words, participants recruitment, data acquisition process, and data pre-processing are described in detail. The results of acoustical analysis are presented to illustrate the properties of child speech. Potential applications of the corpus in automatic speech recognition, phonological error detection and speaker diarization are also discussed.      
### 9.Applying Speech Tempo-Derived Features, BoAW and Fisher Vectors to Detect Elderly Emotion and Speech in Surgical Masks  [ :arrow_down: ](https://arxiv.org/pdf/2008.03183.pdf)
>  The 2020 INTERSPEECH Computational Paralinguistics Challenge (ComParE) consists of three Sub-Challenges, where the tasks are to identify the level of arousal and valence of elderly speakers, determine whether the actual speaker wearing a surgical mask, and estimate the actual breathing of the speaker. In our contribution to the Challenge, we focus on the Elderly Emotion and the Mask sub-challenges. Besides utilizing standard or close-to-standard features such as ComParE functionals, Bag-of-Audio-Words and Fisher vectors, we exploit that emotion is related to the velocity of speech (i.e. speech rate). To utilize this, we perform phone-level recognition using an ASR system, and extract features from the output such as articulation tempo, speech tempo, and various attributes measuring the amount of pauses. We also hypothesize that wearing a surgical mask makes the speaker feel uneasy, leading to a slower speech rate and more hesitations; hence, we experiment with the same features in the Mask sub-challenge as well. Although this theory was not justified by the experimental results on the Mask Sub-Challenge, in the Elderly Emotion Sub-Challenge we got significantly improved arousal and valence values with this feature type both on the development set and in cross-validation.      
### 10.Privacy-Preserving Dynamic Average Consensus via State Decomposition: Case Study on Multi-Robot Formation Control  [ :arrow_down: ](https://arxiv.org/pdf/2008.03182.pdf)
>  In this paper, the problem of privacy preservation in the continuous-time dynamic average consensus is addressed by using a state decomposition scheme. We first show that for a conventional dynamic average consensus algorithm, the external eavesdropper can successfully wiretap the reference signals of each local agent. Then, to provide privacy protection against the eavesdropper, a state decomposition scheme is proposed. The main idea of the proposed scheme is to decompose the original state of each agent into two sub-states. One of the two sub-states succeeds the role of the original state in inter-node interactions, while the other sub-state is invisible to other neighboring agents and only communicates with the first sub-state of the same agent. The new reference signals for the two sub-states can be constructed randomly under certain constraints, which ensures that the convergence properties of the consensus algorithm can be retained. Theoretical analysis shows that under the state decomposition scheme, the eavesdropper cannot discover the private reference signals of each agent with any guaranteed accuracy. Moreover, the proposed privacy-preserving consensus algorithm is successfully applied to solve a formation control problem for multiple nonholonomic mobile robots. Numerical simulation is provided to demonstrate the effectiveness of the proposed approach.      
### 11.Deep Q-Network Based Dynamic Movement Strategy in a UAV-Assisted Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.03162.pdf)
>  Unmanned aerial vehicle (UAV)-assisted communications is a promising solution to improve the performance of future wireless networks, where UAVs are deployed as base stations for enhancing the quality of service (QoS) provided to ground users when traditional terrestrial base stations are unavailable or not sufficient. An effective framework is proposed in this paper to manage the dynamic movement of multiple unmanned aerial vehicles (UAVs) in response to ground user mobility, with the objective to maximize the sum data rate of the ground users. First, we discuss the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAVs. Then a deep Q-network (DQN) based method is proposed to adjust the locations of UAVs to maximize the sum data rate of the user equipment (UE). Finally, simulation results show that the proposed method is capable of adjusting UAV locations in a real-time condition to improve the QoS of the entire network.      
### 12.Ultrasound-based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.03152.pdf)
>  For articulatory-to-acoustic mapping using deep neural networks, typically spectral and excitation parameters of vocoders have been used as the training targets. However, vocoding often results in buzzy and muffled final speech quality. Therefore, in this paper on ultrasound-based articulatory-to-acoustic conversion, we use a flow-based neural vocoder (WaveGlow) pre-trained on a large amount of English and Hungarian speech data. The inputs of the convolutional neural network are ultrasound tongue images. The training target is the 80-dimensional mel-spectrogram, which results in a finer detailed spectral representation than the previously used 25-dimensional Mel-Generalized Cepstrum. From the output of the ultrasound-to-mel-spectrogram prediction, WaveGlow inference results in synthesized speech. We compare the proposed WaveGlow-based system with a continuous vocoder which does not use strict voiced/unvoiced decision when predicting F0. The results demonstrate that during the articulatory-to-acoustic mapping experiments, the WaveGlow neural vocoder produces significantly more natural synthesized speech than the baseline system. Besides, the advantage of WaveGlow is that F0 is included in the mel-spectrogram representation, and it is not necessary to predict the excitation separately.      
### 13.Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss  [ :arrow_down: ](https://arxiv.org/pdf/2008.03149.pdf)
>  Deep neural network with dual-path bi-directional long short-term memory (BiLSTM) block has been proved to be very effective in sequence modeling, especially in speech separation. This work investigates how to extend dual-path BiLSTM to result in a new state-of-the-art approach, called TasTas, for multi-talker monaural speech separation (a.k.a cocktail party problem). TasTas introduces two simple but effective improvements, one is an iterative multi-stage refinement scheme, and the other is to correct the speech with imperfect separation through a loss of speaker identity consistency between the separated speech and original speech, to boost the performance of dual-path BiLSTM based networks. TasTas takes the mixed utterance of two speakers and maps it to two separated utterances, where each utterance contains only one speaker's voice. Our experiments on the notable benchmark WSJ0-2mix data corpus result in 20.55dB SDR improvement, 20.35dB SI-SDR improvement, 3.69 of PESQ, and 94.86\% of ESTOI, which shows that our proposed networks can lead to big performance improvement on the speaker separation task. We have open sourced our re-implementation of the DPRNN-TasNet here (<a class="link-external link-https" href="https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" rel="external noopener nofollow">this https URL</a>), and our TasTas is realized based on this implementation of DPRNN-TasNet, it is believed that the results in this paper can be reproduced with ease.      
### 14.Image Transformation Network for Privacy-Preserving Deep Neural Networks and Its Security Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03143.pdf)
>  We propose a transformation network for generating visually-protected images for privacy-preserving DNNs. The proposed transformation network is trained by using a plain image dataset so that plain images are transformed into visually protected ones. Conventional perceptual encryption methods have a weak visual-protection performance and some accuracy degradation in image classification. In contrast, the proposed network enables us not only to strongly protect visual information but also to maintain the image classification accuracy that using plain images achieves. In an image classification experiment, the proposed network is demonstrated to strongly protect visual information on plain images without any performance degradation under the use of CIFAR datasets. In addition, it is shown that the visually protected images are robust against a DNN-based attack, called inverse transformation network attack (ITN-Attack) in an experiment.      
### 15.On the Potential of Extending Aircraft Service Time Using a Fatigue Damage Index  [ :arrow_down: ](https://arxiv.org/pdf/2008.03138.pdf)
>  Aircraft structures experience various kinds of loads over their entire lifetime, leading to fatigue and ultimately structural failure. In order to avoid structural failures during operation, the maximum number of flight cycles and flight hours is regulated by laws ensuring continued airworthiness. However, since every flight impacts the aircraft differently, not all airframes have been equally stressed at the time of decommissioning. Therefore, a new retirement criterion based on the fatigue damage index (FDI) is proposed. The criterion takes into account that aircraft are differently operated and thus enables an individual decommissioning of aircraft without compromising its safety. Based on aircraft sample data covering 95% of the Airbus A320 fleet over two years, the enhanced decommissioning criterion is estimated to significantly extend the average aircraft service life. The impact varies within the fleet, depending on the experienced seat load factors, cruise altitudes, and taxi times considered for the individual aircraft during operation. While seat load factors and flight altitudes significantly affect the defined FDI, the influence of taxi times is only minor. Based on the estimated increase in aircraft service life, the paper at hand motivates that for service life extensions, the FDI shall be considered as the limit of validity in the regulatory framework governing the decommissioning of aircraft.      
### 16.A Machine of Few Words -- Interactive Speaker Recognition with Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03127.pdf)
>  Speaker recognition is a well known and studied task in the speech processing domain. It has many applications, either for security or speaker adaptation of personal devices. In this paper, we present a new paradigm for automatic speaker recognition that we call Interactive Speaker Recognition (ISR). In this paradigm, the recognition system aims to incrementally build a representation of the speakers by requesting personalized utterances to be spoken in contrast to the standard text-dependent or text-independent schemes. To do so, we cast the speaker recognition task into a sequential decision-making problem that we solve with Reinforcement Learning. Using a standard dataset, we show that our method achieves excellent performance while using little speech signal amounts. This method could also be applied as an utterance selection mechanism for building speech synthesis systems.      
### 17.QoS-Compliant 3D Deployment Optimization Strategy for UAV Base Stations  [ :arrow_down: ](https://arxiv.org/pdf/2008.03125.pdf)
>  Unmanned aerial vehicle (UAV) is being integrated as an active element in 5G and beyond networks. Because of its flexibility and mobility, UAV base stations (UAV-BSs) can be deployed according to the ground user distributions and their quality of service (QoS) requirement. Although there has been quite some prior research on the UAV deployment, no work has studied this problem in a 3 dimensional (3D) setting and taken into account the UAV-BS capacity limit and the quality of service (QoS) requirements of ground users. Therefore, in this paper, we focus on the problem of deploying UAV-BSs to provide satisfactory wireless communication services, with the aim to maximize the total number of covered user equipment (UE) subject to user data rate requirements and UAV-BSs' capacity limit. First, we model the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAV-BSs in both horizontal and vertical dimensions which has not been considered in previous works. Unlike the conventional UAV deployment problem formulation, the 3D deployment problem is decoupled into a 2D horizontal placement and altitude determination connected by path loss requirement and minimization. Then, we propose a novel genetic algorithm (GA) based 2D placement approach in which UAV-BSs are placed to have maximum coverage of the users with consideration of data rate distribution. Finally, numerical and simulation results show that the proposed approach has enabled a better coverage percentage comparing with other schemes.      
### 18.Super-relaxation of space-time-quantized ensemble of energy loads  [ :arrow_down: ](https://arxiv.org/pdf/2008.03118.pdf)
>  Ensembles of thermostatically controlled loads (TCL) provide a significant demand response reserve for the system operator to balance power grids. However, this also results in the parasitic synchronization of individual devices within the ensemble leading to long post-demand-response oscillations in the integrated energy consumption of the ensemble. The synchronization is eventually destructed by fluctuations, thus leading to the (pre-demand response) steady state; however, this natural desynchronization, or relaxation to a statistically steady-state is too long. A resolution of this problem consists in measuring the ensemble's instantaneous consumption and using it as a feedback to stochastic switching of the ensemble's devices between on- and off- states. It was recently shown with a simplified continuous-time model that carefully tuned nonlinear feedback results in a fast relaxation of the ensemble energy consumption -- coined super-relaxation. Since both state information and control signals are discrete, the actual TCL devices operation is space-time quantized, and this must be considered for realistic TCL ensemble modelling. Here, assuming that states are characterized by a temperature (quantifying comfort) and the air conditioner regime (on, off), we construct a discrete model based on the probabilistic description of state transitions. We demonstrate that super-relaxation holds in such a more realistic setting, and that while it is stable against randomness in the stochastic matrix of the quantized model, it remains sensitive to the time discretization scheme. Aiming to achieve a balance between super-relaxation and customer's comfort, we analyze the dependence of super-relaxation on details of the space-time quantization, and provide a simple analytical criterion to avoid undesirable oscillations in consumption.      
### 19.Incremental Text to Speech for Neural Sequence-to-Sequence Models using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03096.pdf)
>  Modern approaches to text to speech require the entire input character sequence to be processed before any audio is synthesised. This latency limits the suitability of such models for time-sensitive tasks like simultaneous interpretation. Interleaving the action of reading a character with that of synthesising audio reduces this latency. However, the order of this sequence of interleaved actions varies across sentences, which raises the question of how the actions should be chosen. We propose a reinforcement learning based framework to train an agent to make this decision. We compare our performance against that of deterministic, rule-based systems. Our results demonstrate that our agent successfully balances the trade-off between the latency of audio generation and the quality of synthesised audio. More broadly, we show that neural sequence-to-sequence models can be adapted to run in an incremental manner.      
### 20.Pretraining Techniques for Sequence-to-Sequence Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2008.03088.pdf)
>  Sequence-to-sequence (seq2seq) voice conversion (VC) models are attractive owing to their ability to convert prosody. Nonetheless, without sufficient data, seq2seq VC models can suffer from unstable training and mispronunciation problems in the converted speech, thus far from practical. To tackle these shortcomings, we propose to transfer knowledge from other speech processing tasks where large-scale corpora are easily available, typically text-to-speech (TTS) and automatic speech recognition (ASR). We argue that VC models initialized with such pretrained ASR or TTS model parameters can generate effective hidden representations for high-fidelity, highly intelligible converted speech. We apply such techniques to recurrent neural network (RNN)-based and Transformer based models, and through systematical experiments, we demonstrate the effectiveness of the pretraining scheme and the superiority of Transformer based models over RNN-based models in terms of intelligibility, naturalness, and similarity.      
### 21.Peking Opera Synthesis via Duration Informed Attention Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.03029.pdf)
>  Peking Opera has been the most dominant form of Chinese performing art since around 200 years ago. A Peking Opera singer usually exhibits a very strong personal style via introducing improvisation and expressiveness on stage which leads the actual rhythm and pitch contour to deviate significantly from the original music score. This inconsistency poses a great challenge in Peking Opera singing voice synthesis from a music score. In this work, we propose to deal with this issue and synthesize expressive Peking Opera singing from the music score based on the Duration Informed Attention Network (DurIAN) framework. To tackle the rhythm mismatch, Lagrange multiplier is used to find the optimal output phoneme duration sequence with the constraint of the given note duration from music score. As for the pitch contour mismatch, instead of directly inferring from music score, we adopt a pseudo music score generated from the real singing and feed it as input during training. The experiments demonstrate that with the proposed system we can synthesize Peking Opera singing voice with high-quality timbre, pitch and expressiveness.      
### 22.Disentangled speaker and nuisance attribute embedding for robust speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.03024.pdf)
>  Over the recent years, various deep learning-based embedding methods have been proposed and have shown impressive performance in speaker verification. However, as in most of the classical embedding techniques, the deep learning-based methods are known to suffer from severe performance degradation when dealing with speech samples with different conditions (e.g., recording devices, emotional states). In this paper, we propose a novel fully supervised training method for extracting a speaker embedding vector disentangled from the variability caused by the nuisance attributes. The proposed framework was compared with the conventional deep learning-based embedding methods using the RSR2015 and VoxCeleb1 dataset. Experimental results show that the proposed approach can extract speaker embeddings robust to channel and emotional variability.      
### 23.DurIAN-SC: Duration Informed Attention Network based Singing Voice Conversion System  [ :arrow_down: ](https://arxiv.org/pdf/2008.03009.pdf)
>  Singing voice conversion is converting the timbre in the source singing to the target speaker's voice while keeping singing content the same. However, singing data for target speaker is much more difficult to collect compared with normal speech <a class="link-external link-http" href="http://data.In" rel="external noopener nofollow">this http URL</a> this paper, we introduce a singing voice conversion algorithm that is capable of generating high quality target speaker's singing using only his/her normal speech data. First, we manage to integrate the training and conversion process of speech and singing into one framework by unifying the features used in standard speech synthesis system and singing synthesis system. In this way, normal speech data can also contribute to singing voice conversion training, making the singing voice conversion system more robust especially when the singing database is small.Moreover, in order to achieve one-shot singing voice conversion, a speaker embedding module is developed using both speech and singing data, which provides target speaker identify information during conversion. Experiments indicate proposed sing conversion system can convert source singing to target speaker's high-quality singing with only 20 seconds of target speaker's enrollment speech data.      
### 24.The Ensemble Method for Thorax Diseases Classification  [ :arrow_down: ](https://arxiv.org/pdf/2008.03008.pdf)
>  A common problem found in real-word medical image classification is the inherent imbalance of the positive and negative patterns in the dataset where positive patterns are usually rare. Moreover, in the classification of multiple classes with neural network, a training pattern is treated as a positive pattern in one output node and negative in all the remaining output nodes. In this paper, the weights of a training pattern in the loss function are designed based not only on the number of the training patterns in the class but also on the different nodes where one of them treats this training pattern as positive and the others treat it as negative. We propose a combined approach of weights calculation algorithm for deep network training and the training optimization from the state-of-the-art deep network architecture for thorax diseases classification problem. Experimental results on the Chest X-Ray image dataset demonstrate that this new weighting scheme improves classification performances, also the training optimization from the EfficientNet improves the performance furthermore. We compare the ensemble method with several performances from the previous study of thorax diseases classifications to provide the fair comparisons against the proposed method.      
### 25.Hybrid Subject Correlation Analysis Mehod for Enhancing SSVEP-Based BCIs  [ :arrow_down: ](https://arxiv.org/pdf/2008.03002.pdf)
>  In this study, an advanced CCA based algorithm called hybrid subject correlation analysis (HSCA) was proposed to improve the performance of the brain-computer interface based on steady state visual evoked potential (SSVEP). In the existing CCA based extension methods, one type of method uses the training data from the same person as the testing set belongs to (called the specific subject training data) to construct a stimulus target template, such as ITCCA [13]. Another type of method uses the transfer learning method to construct a stimulus target template with the help of other subjects' training data (called the independent subject training data). The first type of method is more accurate, but it will lead to multiple experiment trials for each subject, which may cause problems such as user fatigue. The second type of method uses the training data of other subjects, and each subject does not need to train multiple times. But the accuracy may be affected because of subject differences. The proposed HSCA method combines the training data of specific subject and independent subject at the same time, which helps to solve the drawbacks of the two types of methods. In order to test the universality and superiority of this method, this study selected two different datasets for performance evaluation. The results of detection accuracy and information transmission rate showed that the HSCA method will significantly improve the performance of the SSVEP-based brain-computer interface, especially under the condition of a short time window (data length). This shows the great potential of this method in the application of SSVEP-based brain-computer interfaces.      
### 26.NuI-Go: Recursive Non-Local Encoder-Decoder Network for Retinal Image Non-Uniform Illumination Removal  [ :arrow_down: ](https://arxiv.org/pdf/2008.02984.pdf)
>  Retinal images have been widely used by clinicians for early diagnosis of ocular diseases. However, the quality of retinal images is often clinically unsatisfactory due to eye lesions and imperfect imaging process. One of the most challenging quality degradation issues in retinal images is non-uniform which hinders the pathological information and further impairs the diagnosis of ophthalmologists and computer-aided <a class="link-external link-http" href="http://analysis.To" rel="external noopener nofollow">this http URL</a> address this issue, we propose a non-uniform illumination removal network for retinal image, called NuI-Go, which consists of three Recursive Non-local Encoder-Decoder Residual Blocks (NEDRBs) for enhancing the degraded retinal images in a progressive manner. Each NEDRB contains a feature encoder module that captures the hierarchical feature representations, a non-local context module that models the context information, and a feature decoder module that recovers the details and spatial dimension. Additionally, the symmetric skip-connections between the encoder module and the decoder module provide long-range information compensation and reuse. Extensive experiments demonstrate that the proposed method can effectively remove the non-uniform illumination on retinal images while well preserving the image details and color. We further demonstrate the advantages of the proposed method for improving the accuracy of retinal vessel segmentation.      
### 27.Dual Convolutional Neural Networks for BreastMass Segmentation and Diagnosis inMammography  [ :arrow_down: ](https://arxiv.org/pdf/2008.02957.pdf)
>  Deep convolutional neural networks (CNNs) have emerged as a new paradigm for Mammogram diagnosis. Contemporary CNN-based computer-aided-diagnosis (CAD) for breast cancer directly extract latent features from input mammogram image and ignore the importance of morphological features. {In this paper, we introduce a novel deep learning framework for mammogram image processing, which computes mass segmentation and simultaneously predict diagnosis results.} Specifically, our method is constructed in a dual-path architecture that solves the mapping in a dual-problem manner, with an additional consideration of important shape and boundary knowledge. One path called the Locality Preserving Learner (LPL), is devoted to hierarchically extracting and exploiting intrinsic features of the input. Whereas the other path, called the Conditional Graph Learner (CGL) focuses on generating geometrical features via modeling pixel-wise image to mask correlations. By integrating the two learners, both the semantics and structure are well preserved and the component learning paths in return complement each other, contributing an improvement to the mass segmentation and cancer classification problem at the same time. We evaluated our method on two most used public mammography datasets, DDSM and INbreast. Experimental results show that \dcn achieves the best mammography segmentation (in both high and low resolution) and classification simultaneously, outperforming recent state-of-the-art models.      
### 28.Fast Identification of Saturated Cut-sets using Graph Search Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2008.02951.pdf)
>  When multiple outages occur in rapid succession, it is important to know quickly if the power transfer capability of different interconnections (or cut-sets) of the power network are limited. The algorithm developed in this paper identifies such limited cut-sets very fast, thereby enhancing the real-time situational awareness of power system operators. The significance of the proposed approach is described using the IEEE 39-bus test system, while its computational benefits are demonstrated using relatively large test-cases containing thousands of buses. The results indicate that the proposed network analysis can estimate the impact of an outage on any cut-set of the system and screen out the cut-set that gets saturated by the largest margin, very quickly.      
### 29.Multi-speaker Text-to-speech Synthesis Using Deep Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2008.02950.pdf)
>  Multi-speaker speech synthesis is a technique for modeling multiple speakers' voices with a single model. Although many approaches using deep neural networks (DNNs) have been proposed, DNNs are prone to overfitting when the amount of training data is limited. We propose a framework for multi-speaker speech synthesis using deep Gaussian processes (DGPs); a DGP is a deep architecture of Bayesian kernel regressions and thus robust to overfitting. In this framework, speaker information is fed to duration/acoustic models using speaker codes. We also examine the use of deep Gaussian process latent variable models (DGPLVMs). In this approach, the representation of each speaker is learned simultaneously with other model parameters, and therefore the similarity or dissimilarity of speakers is considered efficiently. We experimentally evaluated two situations to investigate the effectiveness of the proposed methods. In one situation, the amount of data from each speaker is balanced (speaker-balanced), and in the other, the data from certain speakers are limited (speaker-imbalanced). Subjective and objective evaluation results showed that both the DGP and DGPLVM synthesize multi-speaker speech more effective than a DNN in the speaker-balanced situation. We also found that the DGPLVM outperforms the DGP significantly in the speaker-imbalanced situation.      
### 30.Mean Field Game and Decentralized Intelligent Adaptive Pursuit Evasion Strategy for Massive Multi-Agent System under Uncertain Environment  [ :arrow_down: ](https://arxiv.org/pdf/2008.02940.pdf)
>  In this paper, a novel decentralized intelligent adaptive optimal strategy has been developed to solve the pursuit-evasion game for massive Multi-Agent Systems (MAS) under uncertain environment. Existing strategies for pursuit-evasion games are neither efficient nor practical for large population multi-agent system due to the notorious "Curse of dimensionality" and communication limit while the agent population is large. To overcome these challenges, the emerging mean field game theory is adopted and further integrated with reinforcement learning to develop a novel decentralized intelligent adaptive strategy with a new type of adaptive dynamic programing architecture named the Actor-Critic-Mass (ACM). Through online approximating the solution of the coupled mean field equations, the developed strategy can obtain the optimal pursuit-evasion policy even for massive MAS under uncertain environment. In the proposed ACM learning based strategy, each agent maintains five neural networks, which are 1) the critic neural network to approximate the solution of the HJI equation for each individual agent; 2) the mass neural network to estimate the population density function (i.e., mass) of the group; 3) the actor neural network to approximate the decentralized optimal strategy, and 4) two more neural networks are designed to estimate the opponents' group mass as well as the optimal cost function. Eventually, a comprehensive numerical simulation has been provided to demonstrate the effectiveness of the designed strategy.      
### 31.Privacy-Preserved Collaborative Estimation for Networked Vehicles with Application to Road Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2008.02928.pdf)
>  Road information such as road profile and traffic density have been widely used in intelligent vehicle systems to improve road safety, ride comfort, and fuel economy. However, vehicle heterogeneity and parameter uncertainty make it extremely difficult for a single vehicle to accurately and reliably measure such information. In this work, we propose a unified framework for learning-based collaborative estimation to fuse local road estimation from a fleet of connected heterogeneous vehicles. The collaborative estimation scheme exploits the sequential measurements made by multiple vehicles traversing the same road segment and let these vehicles relay a learning signal to iteratively refine local estimations. Given that the privacy of individual vehicles' identity must be protected in collaborative estimation, we directly incorporate privacy-protection design into the collaborative estimation design and establish a unified framework for privacy-preserving collaborative estimation. Different from patching conventional privacy mechanisms like differential privacy which will compromise algorithmic accuracy or homomorphic encryption which will incur heavy communication/computational overhead, we leverage the dynamical properties of collective estimation to enable inherent privacy protection without sacrificing accuracy or significantly increasing communication/computation overhead. Numerical simulations confirm the effectiveness and efficiency of our proposed framework.      
### 32.On the Application of Error Backpropagation to the Background Calibration of Time Interleaved ADC for Digital Communication Receivers  [ :arrow_down: ](https://arxiv.org/pdf/2008.02914.pdf)
>  This paper introduces a backpropagation-based technique for the calibration of the mismatch errors of time-interleaved analog to digital converters (TI-ADCs). This technique is applicable to digital receivers such as those used in coherent optical communications. The error at the slicer of the receiver is processed using a modified version of the well known backpropagation algorithm from machine learning. The processed slicer error can be directly applied to compensate the TI-ADC mismatch errors with an adaptive equalizer, or it can be used to digitally estimate and correct said mismatch errors using analog techniques such as delay cells and programmable gain amplifiers (PGA). The main advantages of the technique proposed here compared to prior art are its robustness, its speed of convergence, and the fact that it always works in background mode, independently of the oversampling factor and the properties of the input signal, as long as the receiver converges. Moreover, this technique enables the joint compensation of impairments not addressed by traditional TI-ADC calibration techniques, such as I/Q skew in quadrature modulation receivers. Simulations are presented to demonstrate the effectiveness of the technique, and low complexity implementation options are discussed.      
### 33.Demand Response For Residential Uses: A Data Analytics Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.02908.pdf)
>  In the Smart Grid environment, the advent of intelligent measuring devices facilitates monitoring appliance electricity consumption. This data can be used in applying Demand Response (DR) in residential houses through data analytics, and developing data mining techniques. In this research, we introduce a smart system foundation that is applied to user's disaggregated power consumption data. This system encourages the users to apply DR by changing their behaviour of using heavier operation modes to lighter modes, and by encouraging users to shift their usages to off-peak hours. First, we apply Cross Correlation (XCORR) to detect times of the occurrences when an appliance is being used. We then use The Dynamic Time Warping (DTW) to recognize the operation mode used.      
### 34.Respiratory Sound Classification Using Long-Short Term Memory  [ :arrow_down: ](https://arxiv.org/pdf/2008.02900.pdf)
>  Developing a reliable sound detection and recognition system offers many benefits and has many useful applications in different industries. This paper examines the difficulties that exist when attempting to perform sound classification as it relates to respiratory disease classification. Some methods which have been employed such as independent component analysis and blind source separation are examined. Finally, an examination on the use of deep learning and long short-term memory networks is performed in order to identify how such a task can be implemented.      
### 35.A Transfer Learning Method for Speech Emotion Recognition from Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.02863.pdf)
>  This paper presents a transfer learning method in speech emotion recognition based on a Time-Delay Neural Network (TDNN) architecture. A major challenge in the current speech-based emotion detection research is data scarcity. The proposed method resolves this problem by applying transfer learning techniques in order to leverage data from the automatic speech recognition (ASR) task for which ample data is available. Our experiments also show the advantage of speaker-class adaptation modeling techniques by adopting identity-vector (i-vector) based features in addition to standard Mel-Frequency Cepstral Coefficient (MFCC) features.[1] We show the transfer learning models significantly outperform the other methods without pretraining on ASR. The experiments performed on the publicly available IEMOCAP dataset which provides 12 hours of motional speech data. The transfer learning was initialized by using the Ted-Lium v.2 speech dataset providing 207 hours of audio with the corresponding transcripts. We achieve the highest significantly higher accuracy when compared to state-of-the-art, using five-fold cross validation. Using only speech, we obtain an accuracy 71.7% for anger, excitement, sadness, and neutrality emotion content.      
### 36.Confidence-guided Lesion Mask-based Simultaneous Synthesis of Anatomic and Molecular MR Images in Patients with Post-treatment Malignant Gliomas  [ :arrow_down: ](https://arxiv.org/pdf/2008.02859.pdf)
>  Data-driven automatic approaches have demonstrated their great potential in resolving various clinical diagnostic dilemmas in neuro-oncology, especially with the help of standard anatomic and advanced molecular MR images. However, data quantity and quality remain a key determinant of, and a significant limit on, the potential of such applications. In our previous work, we explored synthesis of anatomic and molecular MR image network (SAMR) in patients with post-treatment malignant glioms. Now, we extend it and propose Confidence Guided SAMR (CG-SAMR) that synthesizes data from lesion information to multi-modal anatomic sequences, including T1-weighted (T1w), gadolinium enhanced T1w (Gd-T1w), T2-weighted (T2w), and fluid-attenuated inversion recovery (FLAIR), and the molecular amide proton transfer-weighted (APTw) sequence. We introduce a module which guides the synthesis based on confidence measure about the intermediate results. Furthermore, we extend the proposed architecture for unsupervised synthesis so that unpaired data can be used for training the network. Extensive experiments on real clinical data demonstrate that the proposed model can perform better than the state-of-theart synthesis methods.      
### 37.Grid-aware Distributed Model Predictive Control of Heterogeneous Resources in a Distribution Network: Theory and Experimental Validation  [ :arrow_down: ](https://arxiv.org/pdf/2008.02848.pdf)
>  In this paper, we propose and experimentally validate a scheduling and control framework for distributed energy resources (DERs) that achieves to track a day-ahead dispatch plan of a distribution network hosting controllable and stochastic heterogeneous resources while respecting the local grid constraints on nodal voltages and lines ampacities. The framework consists of two algorithmic layers. In the first one (day-ahead scheduling), we determine an aggregated dispatch plan. In the second layer (real-time control), a distributed model predictive control (MPC) determines the active and reactive power set-points of the DERs so that their aggregated contribution tracks the dispatch plan while obeying to DERs operational constraints as well as the grids ones. The proposed framework is experimentally validated on a real-scale microgrid that reproduces the network specifications of the CIGRE microgrid benchmark system.      
### 38.Unsupervised Cross-Domain Singing Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2008.02830.pdf)
>  We present a wav-to-wav generative model for the task of singing voice conversion from any identity. Our method utilizes both an acoustic model, trained for the task of automatic speech recognition, together with melody extracted features to drive a waveform-based generator. The proposed generative architecture is invariant to the speaker's identity and can be trained to generate target singers from unlabeled training data, using either speech or singing sources. The model is optimized in an end-to-end fashion without any manual supervision, such as lyrics, musical notes or parallel samples. The proposed approach is fully-convolutional and can generate audio in real-time. Experiments show that our method significantly outperforms the baseline methods while generating convincingly better audio samples than alternative attempts.      
### 39.SafePILCO: a software tool for safe and data-efficient policy synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.03273.pdf)
>  SafePILCO is a software tool for safe and data-efficient policy search with reinforcement learning. It extends the known PILCO algorithm, originally written in MATLAB, to support safe learning. We provide a Python implementation and leverage existing libraries that allow the codebase to remain short and modular, which is appropriate for wider use by the verification, reinforcement learning, and control communities.      
### 40.ESPRESSO: Entropy and ShaPe awaRe timE-Series SegmentatiOn for processing heterogeneous sensor data  [ :arrow_down: ](https://arxiv.org/pdf/2008.03230.pdf)
>  Extracting informative and meaningful temporal segments from high-dimensional wearable sensor data, smart devices, or IoT data is a vital preprocessing step in applications such as Human Activity Recognition (HAR), trajectory prediction, gesture recognition, and lifelogging. In this paper, we propose ESPRESSO (Entropy and ShaPe awaRe timE-Series SegmentatiOn), a hybrid segmentation model for multi-dimensional time-series that is formulated to exploit the entropy and temporal shape properties of time-series. ESPRESSO differs from existing methods that focus upon particular statistical or temporal properties of time-series exclusively. As part of model development, a novel temporal representation of time-series $WCAC$ was introduced along with a greedy search approach that estimate segments based upon the entropy metric. ESPRESSO was shown to offer superior performance to four state-of-the-art methods across seven public datasets of wearable and wear-free sensing. In addition, we undertake a deeper investigation of these datasets to understand how ESPRESSO and its constituent methods perform with respect to different dataset characteristics. Finally, we provide two interesting case-studies to show how applying ESPRESSO can assist in inferring daily activity routines and the emotional state of humans.      
### 41.Convolutional neural network based deep-learning architecture for intraprostatic tumour contouring on PSMA PET images in patients with primary prostate cancer  [ :arrow_down: ](https://arxiv.org/pdf/2008.03201.pdf)
>  Accurate delineation of the intraprostatic gross tumour volume (GTV) is a prerequisite for treatment approaches in patients with primary prostate cancer (PCa). Prostate-specific membrane antigen positron emission tomography (PSMA-PET) may outperform MRI in GTV detection. However, visual GTV delineation underlies interobserver heterogeneity and is time consuming. The aim of this study was to develop a convolutional neural network (CNN) for automated segmentation of intraprostatic tumour (GTV-CNN) in PSMA-PET. <br>Methods: The CNN (3D U-Net) was trained on [68Ga]PSMA-PET images of 152 patients from two different institutions and the training labels were generated manually using a validated technique. The CNN was tested on two independent internal (cohort 1: [68Ga]PSMA-PET, n=18 and cohort 2: [18F]PSMA-PET, n=19) and one external (cohort 3: [68Ga]PSMA-PET, n=20) test-datasets. Accordance between manual contours and GTV-CNN was assessed with Dice-Srensen coefficient (DSC). Sensitivity and specificity were calculated for the two internal test-datasets by using whole-mount histology. <br>Results: Median DSCs for cohorts 1-3 were 0.84 (range: 0.32-0.95), 0.81 (range: 0.28-0.93) and 0.83 (range: 0.32-0.93), respectively. Sensitivities and specificities for GTV-CNN were comparable with manual expert contours: 0.98 and 0.76 (cohort 1) and 1 and 0.57 (cohort 2), respectively. Computation time was around 6 seconds for a standard dataset. <br>Conclusion: The application of a CNN for automated contouring of intraprostatic GTV in [68Ga]PSMA- and [18F]PSMA-PET images resulted in a high concordance with expert contours and in high sensitivities and specificities in comparison with histology reference. This robust, accurate and fast technique may be implemented for treatment concepts in primary PCa. The trained model and the study's source code are available in an open source repository.      
### 42.A Study on Visual Perception of Light Field Content  [ :arrow_down: ](https://arxiv.org/pdf/2008.03195.pdf)
>  The effective design of visual computing systems depends heavily on the anticipation of visual attention, or saliency. While visual attention is well investigated for conventional 2D images and video, it is nevertheless a very active research area for emerging immersive media. In particular, visual attention of light fields (light rays of a scene captured by a grid of cameras or micro lenses) has only recently become a focus of research. As they may be rendered and consumed in various ways, a primary challenge that arises is the definition of what visual perception of light field content should be. In this work, we present a visual attention study on light field content. We conducted perception experiments displaying them to users in various ways and collected corresponding visual attention data. Our analysis highlights characteristics of user behaviour in light field imaging applications. The light field data set and attention data are provided with this paper.      
### 43.Generative Adversarial Network-Based Sinogram Super-Resolution for Computed Tomography Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.03142.pdf)
>  Compared with the conventional 1*1 acquisition mode of projection in computed tomography (CT) image reconstruction, the 2*2 acquisition mode improves the collection efficiency of the projection and reduces the X-ray exposure time. However, the collected projection based on the 2*2 acquisition mode has low resolution (LR) and the reconstructed image quality is poor, thus limiting the use of this mode in CT imaging systems. In this study, a novel sinogram-super-resolution generative adversarial network (SSR-GAN) model is proposed to obtain high-resolution (HR) sinograms from LR sinograms, thereby improving the reconstruction image quality under the 2*2 acquisition mode. The proposed generator is based on the residual network for LR sinogram feature extraction and super-resolution (SR) sinogram generation. A relativistic discriminator is designed to render the network capable of obtaining more realistic SR sinograms. Moreover, we combine the cycle consistency loss, sinogram domain loss, and reconstruction image domain loss in the total loss function to supervise SR sinogram generation. Then, a trained model can be obtained by inputting the paired LR/HR sinograms into the network. Finally, the classic FBP reconstruction algorithm is used for CT image reconstruction based on the generated SR sinogram. The qualitative and quantitative results of evaluations on digital and real data illustrate that the proposed model not only obtains clean SR sinograms from noisy LR sinograms but also outperforms its counterparts.      
### 44.Design Space Exploration of Power Delivery For Advanced Packaging Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2008.03124.pdf)
>  In this paper, a design space exploration of power delivery networks is performed for multi-chip 2.5-D and 3-D IC technologies. The focus of the paper is the effective placement of the voltage regulator modules (VRMs) for power supply noise (PSN) suppression. Multiple on-package VRM configurations have been analyzed and compared. Additionally, 3D IC chip-on-VRM and backside-of-the-package VRM configurations are studied. From the PSN perspective, the 3D IC chip-on-VRM case suppresses the PSN the most even with high current density hotspots. The paper also studies the impact of different parameters such as VRM-chip distance on the package, on-chip decoupling capacitor density, etc. on the PSN.      
### 45.Joint Uplink-and-Downlink Optimization of 3D UAV Swarm Deployment for Wireless-Powered NB-IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.02993.pdf)
>  This paper investigates a full-duplex orthogonal-frequency-division multiple access (OFDMA) based multiple unmanned aerial vehicles (UAVs)-enabled wireless-powered Internet-of-Things (IoT) networks. In this paper, a swarm of UAVs is first deployed in three dimensions (3D) to simultaneously charge all devices, i.e., a downlink (DL) charging period, and then flies to new locations within this area to collect information from scheduled devices in several epochs via OFDMA due to potential limited number of channels available in Narrow Band IoT, i.e., an uplink (UL) communication period. To maximize the UL throughput of IoT devices, we jointly optimizes the UL-and-DL 3D deployment of the UAV swarm, including the device-UAV association, the scheduling order, and the UL-DL time allocation. In particular, the DL energy harvesting (EH) threshold of devices and the UL signal decoding threshold of UAVs are taken into consideration when studying the problem. Besides, both line-of-sight (LoS) and non-line-of-sight (NLoS) channel models are studied depending on the position of sensors and UAVs. The influence of the potential limited channels issue in NB-IoT is also considered by studying the IoT scheduling policy. Two scheduling policies, a near-first (NF) policy and a far-first (FF) policy, are studied. It is shown that the NF scheme outperforms FF scheme in terms of sum throughput maximization; whereas FF scheme outperforms NF scheme in terms of system fairness.      
### 46.Predicting Visual Importance Across Graphic Design Types  [ :arrow_down: ](https://arxiv.org/pdf/2008.02912.pdf)
>  This paper introduces a Unified Model of Saliency and Importance (UMSI), which learns to predict visual importance in input graphic designs, and saliency in natural images, along with a new dataset and applications. Previous methods for predicting saliency or visual importance are trained individually on specialized datasets, making them limited in application and leading to poor generalization on novel image classes, while requiring a user to know which model to apply to which input. UMSI is a deep learning-based model simultaneously trained on images from different design classes, including posters, infographics, mobile UIs, as well as natural images, and includes an automatic classification module to classify the input. This allows the model to work more effectively without requiring a user to label the input. We also introduce Imp1k, a new dataset of designs annotated with importance information. We demonstrate two new design interfaces that use importance prediction, including a tool for adjusting the relative importance of design elements, and a tool for reflowing designs to new aspect ratios while preserving visual importance. The model, code, and importance dataset are available at <a class="link-external link-https" href="https://predimportance.mit.edu" rel="external noopener nofollow">this https URL</a> .      
### 47.Evaluating computational models of infant phonetic learning across languages  [ :arrow_down: ](https://arxiv.org/pdf/2008.02888.pdf)
>  In the first year of life, infants' speech perception becomes attuned to the sounds of their native language. Many accounts of this early phonetic learning exist, but computational models predicting the attunement patterns observed in infants from the speech input they hear have been lacking. A recent study presented the first such model, drawing on algorithms proposed for unsupervised learning from naturalistic speech, and tested it on a single phone contrast. Here we study five such algorithms, selected for their potential cognitive relevance. We simulate phonetic learning with each algorithm and perform tests on three phone contrasts from different languages, comparing the results to infants' discrimination patterns. The five models display varying degrees of agreement with empirical observations, showing that our approach can help decide between candidate mechanisms for early phonetic learning, and providing insight into which aspects of the models are critical for capturing infants' perceptual development.      
### 48.Performance of Underwater Wireless Optical Communications in Presents of Cascaded Mixture Exponential-Generalized Gamma Turbulence  [ :arrow_down: ](https://arxiv.org/pdf/2008.02868.pdf)
>  Underwater wireless optical communication is one of the critical technologies for buoy-based high-speed cross-sea surface communication, where the communication nodes are vertically deployed. Due to the vertically inhomogeneous nature of the underwater environment, seawater is usually vertically divided into multiple layers with different parameters that reflect the real environment. In this work, we consider a generalized UWOC channel model that contains$N$ layers. To capture the effects of air bubbles and temperature gradients on channel statistics, we model each layer by a mixture Exponential-Generalized Gamma(EGG) distribution. We derive the PDF and CDF of the end-to-end SNR in exact closed-form. Then, unified BER and outage expressions using OOK and BPSK are also derived. The performance and behavior of common vertical underwater optical communication scenarios are thoroughly analyzed through the appropriate selection of parameters. All the derived expressions are verified via Monte Carlo simulations.      
### 49.Improving Explainability of Image Classification in Scenarios with Class Overlap: Application to COVID-19 and Pneumonia  [ :arrow_down: ](https://arxiv.org/pdf/2008.02866.pdf)
>  Trust in predictions made by machine learning models is increased if the model generalizes well on previously unseen samples and when inference is accompanied by cogent explanations of the reasoning behind predictions. In the image classification domain, generalization can also be assessed through accuracy, sensitivity, and specificity, and one measure to assess explainability is how well the model localizes the object of interest within an image. However, in multi-class settings, both generalization and explanation through localization are degraded when available training data contains features with significant overlap between classes. We propose a method to enhance explainability of image classification through better localization by mitigating the model uncertainty induced by class overlap. Our technique performs discriminative localization on images that contain features with significant class overlap, without explicitly training for localization. Our method is particularly promising in real-world class overlap scenarios, such as COVID19 vs pneumonia, where expertly labeled data for localization is not available. This can be useful for early, rapid, and trustworthy screening for COVID-19.      
### 50.Semantic Complexity in End-to-End Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2008.02858.pdf)
>  End-to-end spoken language understanding (SLU) models are a class of model architectures that predict semantics directly from speech. Because of their input and output types, we refer to them as speech-to-interpretation (STI) models. Previous works have successfully applied STI models to targeted use cases, such as recognizing home automation commands, however no study has yet addressed how these models generalize to broader use cases. In this work, we analyze the relationship between the performance of STI models and the difficulty of the use case to which they are applied. We introduce empirical measures of dataset semantic complexity to quantify the difficulty of the SLU tasks. We show that near-perfect performance metrics for STI models reported in the literature were obtained with datasets that have low semantic complexity values. We perform experiments where we vary the semantic complexity of a large, proprietary dataset and show that STI model performance correlates with our semantic complexity measures, such that performance increases as complexity values decrease. Our results show that it is important to contextualize an STI model's performance with the complexity values of its training dataset to reveal the scope of its applicability.      
### 51.Iterative Pre-Conditioning for Expediting the Gradient-Descent Method: The Distributed Linear Least-Squares Problem  [ :arrow_down: ](https://arxiv.org/pdf/2008.02856.pdf)
>  This paper considers the multi-agent linear least-squares problem in a server-agent network. In this problem, the system comprises multiple agents, each having a set of local data points, that are connected to a server. The goal for the agents is to compute a linear mathematical model that optimally fits the collective data points held by all the agents, without sharing their individual local data points. This goal can be achieved, in principle, using the server-agent variant of the traditional iterative gradient-descent method. The gradient-descent method converges linearly to a solution, and its rate of convergence is lower bounded by the conditioning of the agents' collective data points. If the data points are ill-conditioned, the gradient-descent method may require a large number of iterations to converge. <br>We propose an iterative pre-conditioning technique that mitigates the deleterious effect of the conditioning of data points on the rate of convergence of the gradient-descent method. We rigorously show that the resulting pre-conditioned gradient-descent method, with the proposed iterative pre-conditioning, achieves superlinear convergence when the least-squares problem has a unique solution. In general, the convergence is linear with improved rate of convergence in comparison to the traditional gradient-descent method and the state-of-the-art accelerated gradient-descent methods. We further illustrate the improved rate of convergence of our proposed algorithm through experiments on different real-world least-squares problems in both noise-free and noisy computation environment.      
### 52.Ultrasound-based Silent Speech Interface Built on a Continuous Vocoder  [ :arrow_down: ](https://arxiv.org/pdf/1906.09885.pdf)
>  Recently it was shown that within the Silent Speech Interface (SSI) field, the prediction of F0 is possible from Ultrasound Tongue Images (UTI) as the articulatory input, using Deep Neural Networks for articulatory-to-acoustic mapping. Moreover, text-to-speech synthesizers were shown to produce higher quality speech when using a continuous pitch estimate, which takes non-zero pitch values even when voicing is not present. Therefore, in this paper on UTI-based SSI, we use a simple continuous F0 tracker which does not apply a strict voiced / unvoiced decision. Continuous vocoder parameters (ContF0, Maximum Voiced Frequency and Mel-Generalized Cepstrum) are predicted using a convolutional neural network, with UTI as input. The results demonstrate that during the articulatory-to-acoustic mapping experiments, the continuous F0 is predicted with lower error, and the continuous vocoder produces slightly more natural synthesized speech than the baseline vocoder using standard discontinuous F0.      
