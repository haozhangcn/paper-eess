# ArXiv eess --Tue, 4 Aug 2020
### 1.Finite-time Control of Discrete-time Positive Linear Systems via Convex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2008.01024.pdf)
>  In this paper, we study a class of finite-time control problems for discrete-time positive linear systems with time-varying state parameters. Although several interesting control problems appearing in population biology, economics, and network epidemiology can be described as the class of finite-time control problems, an efficient solution to the control problem has not been yet found in the literature. In this paper, we propose an optimization framework for solving the class of finite-time control problems via convex optimization. We illustrate the effectiveness of the proposed method by numerical simulation in the context of dynamical product development processes.      
### 2.Modular End-to-end Automatic Speech Recognition Framework for Acoustic-to-word Model  [ :arrow_down: ](https://arxiv.org/pdf/2008.00953.pdf)
>  End-to-end (E2E) systems have played a more and more important role in automatic speech recognition (ASR) and achieved great performance. However, E2E systems recognize output word sequences directly with the input acoustic feature, which can only be trained on limited acoustic data. The extra text data is widely used to improve the results of traditional artificial neural network-hidden Markov model (ANN-HMM) hybrid systems. The involving of extra text data to standard E2E ASR systems may break the E2E property during decoding. In this paper, a novel modular E2E ASR system is proposed. The modular E2E ASR system consists of two parts: an acoustic-to-phoneme (A2P) model and a phoneme-to-word (P2W) model. The A2P model is trained on acoustic data, while extra data including large scale text data can be used to train the P2W model. This additional data enables the modular E2E ASR system to model not only the acoustic part but also the language part. During the decoding phase, the two models will be integrated and act as a standard acoustic-to-word (A2W) model. In other words, the proposed modular E2E ASR system can be easily trained with extra text data and decoded in the same way as a standard E2E ASR system. Experimental results on the Switchboard corpus show that the modular E2E model achieves better word error rate (WER) than standard A2W models.      
### 3.FaultFace: Deep Convolutional Generative Adversarial Network (DCGAN) based Ball-Bearing Failure Detection Method  [ :arrow_down: ](https://arxiv.org/pdf/2008.00930.pdf)
>  Failure detection is employed in the industry to improve system performance and reduce costs due to unexpected malfunction events. So, a good dataset of the system is desirable for designing an automated failure detection system. However, industrial process datasets are unbalanced and contain little information about failure behavior due to the uniqueness of these events and the high cost for running the system just to get information about the undesired behaviors. For this reason, performing correct training and validation of automated failure detection methods is challenging. This paper proposes a methodology called FaultFace for failure detection on Ball-Bearing joints for rotational shafts using deep learning techniques to create balanced datasets. The FaultFace methodology uses 2D representations of vibration signals denominated faceportraits obtained by time-frequency transformation techniques. From the obtained faceportraits, a Deep Convolutional Generative Adversarial Network is employed to produce new faceportraits of the nominal and failure behaviors to get a balanced dataset. A Convolutional Neural Network is trained for fault detection employing the balanced dataset. The FaultFace methodology is compared with other deep learning techniques to evaluate its performance in for fault detection with unbalanced datasets. Obtained results show that FaultFace methodology has a good performance for failure detection for unbalanced datasets.      
### 4.Automated Segmentation of Brain Gray Matter Nuclei on Quantitative Susceptibility Mapping Using Deep Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.00901.pdf)
>  Abnormal iron accumulation in the brain subcortical nuclei has been reported to be correlated to various neurodegenerative diseases, which can be measured through the magnetic susceptibility from the quantitative susceptibility mapping (QSM). To quantitively measure the magnetic susceptibility, the nuclei should be accurately segmented, which is a tedious task for clinicians. In this paper, we proposed a double-branch residual-structured U-Net (DB-ResUNet) based on 3D convolutional neural network (CNN) to automatically segment such brain gray matter nuclei. To better tradeoff between segmentation accuracy and the memory efficiency, the proposed DB-ResUNet fed image patches with high resolution and the patches with low resolution but larger field of view into the local and global branches, respectively. Experimental results revealed that by jointly using QSM and T$_\text{1}$ weighted imaging (T$_\text{1}$WI) as inputs, the proposed method was able to achieve better segmentation accuracy over its single-branch counterpart, as well as the conventional atlas-based method and the classical 3D-UNet structure. The susceptibility values and the volumes were also measured, which indicated that the measurements from the proposed DB-ResUNet are able to present high correlation with values from the manually annotated regions of interest.      
### 5.Speaker dependent articulatory-to-acoustic mapping using real-time MRI of the vocal tract  [ :arrow_down: ](https://arxiv.org/pdf/2008.00889.pdf)
>  Articulatory-to-acoustic (forward) mapping is a technique to predict speech using various articulatory acquisition techniques (e.g. ultrasound tongue imaging, lip video). Real-time MRI (rtMRI) of the vocal tract has not been used before for this purpose. The advantage of MRI is that it has a high `relative' spatial resolution: it can capture not only lingual, labial and jaw motion, but also the velum and the pharyngeal region, which is typically not possible with other techniques. In the current paper, we train various DNNs (fully connected, convolutional and recurrent neural networks) for articulatory-to-speech conversion, using rtMRI as input, in a speaker-specific way. We use two male and two female speakers of the USC-TIMIT articulatory database, each of them uttering 460 sentences. We evaluate the results with objective (Normalized MSE and MCD) and subjective measures (perceptual test) and show that CNN-LSTM networks are preferred which take multiple images as input, and achieve MCD scores between 2.8-4.5 dB. In the experiments, we find that the predictions of speaker `m1' are significantly weaker than other speakers. We show that this is caused by the fact that 74% of the recordings of speaker `m1' are out of sync.      
### 6.Intensity-only Mode Decomposition on Multimode Fibers using a Densely Connected Convolutional Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.00864.pdf)
>  The use of multimode fibers offers advantages in the field of communication technology in terms of transferable information density and information security. For applications using physical layer security or mode division multiplexing, the complex transmission matrix must be known. To measure the transmission matrix, the individual modes of the multimode fiber are excited sequentially at the input and a mode decomposition is performed at the output. Mode decomposition is usually performed using digital holography, which requires the provision of a reference wave and leads to high efforts. To overcome these drawbacks, a neural network is proposed, which performs mode decomposition with intensity-only camera recordings of the multimode fiber facet. Due to the high computational complexity of the problem, this approach was usually limited to a number of 6 modes. In this work, it could be shown for the first time that by using a DenseNet with 121 layers it is possible to break through the hurdle of 6 modes. The advancement is demonstrated by a mode decomposition with 10 modes experimentally. The training process is based on synthetic data. The proposed method is quantitatively compared to the conventional approach with digital holography. In addition, it is shown that the network can perform mode decomposition on a 55-mode fiber, which also supports modes unknown to the neural network. The smart detection using a DenseNet opens new ways for the application of multimode fibers in optical communication networks for physical layer security.      
### 7.Retinal Image Segmentation with a Structure-Texture Demixing Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.00817.pdf)
>  Retinal image segmentation plays an important role in automatic disease diagnosis. This task is very challenging because the complex structure and texture information are mixed in a retinal image, and distinguishing the information is difficult. Existing methods handle texture and structure jointly, which may lead biased models toward recognizing textures and thus results in inferior segmentation performance. To address it, we propose a segmentation strategy that seeks to separate structure and texture components and significantly improve the performance. To this end, we design a structure-texture demixing network (STD-Net) that can process structures and textures differently and better. Extensive experiments on two retinal image segmentation tasks (i.e., blood vessel segmentation, optic disc and cup segmentation) demonstrate the effectiveness of the proposed method.      
### 8.Evolving Multi-Resolution Pooling CNN for Monaural Singing Voice Separation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00816.pdf)
>  Monaural Singing Voice Separation (MSVS) is a challenging task and has been studied for decades. Deep neural networks (DNNs) are the current state-of-the-art methods for MSVS. However, the existing DNNs are often designed manually, which is time-consuming and error-prone. In addition, the network architectures are usually pre-defined, and not adapted to the training data. To address these issues, we introduce a Neural Architecture Search (NAS) method to the structure design of DNNs for MSVS. Specifically, we propose a new multi-resolution Convolutional Neural Network (CNN) framework for MSVS namely Multi-Resolution Pooling CNN (MRP-CNN), which uses various-size pooling operators to extract multi-resolution features. Based on the NAS, we then develop an evolving framework namely Evolving MRP-CNN (E-MRP-CNN), by automatically searching the effective MRP-CNN structures using genetic algorithms, optimized in terms of a single-objective considering only separation performance, or multi-objective considering both the separation performance and the model complexity. The multi-objective E-MRP-CNN gives a set of Pareto-optimal solutions, each providing a trade-off between separation performance and model complexity. Quantitative and qualitative evaluations on the MIR-1K and DSD100 datasets are used to demonstrate the advantages of the proposed framework over several recent baselines.      
### 9.Differential Reflecting Modulation for Reconfigurable Intelligent Surface Based Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.00815.pdf)
>  Reconfigurable intelligent surface (RIS) based communications have emerged as a new paradigm. This letter proposes a differential reflecting modulation (DRM) scheme for RIS based communication systems. In DRM, information bits are jointly carried by the activation permutations of the reflecting patterns and the phases of the transmitted signals, leading to that DRM can work without any channel state information (CSI) at the transmitter, RIS or receiver. In other words, DRM can release the intricate and resource-consuming channel estimation in the transmission process. Simulation results show that the proposed DRM pays an acceptable SNR penalty compared to non-differential modulation with coherent detection.      
### 10.Multi-Scale Deep Compressive Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.00802.pdf)
>  Recently, deep learning-based compressive imaging (DCI) has surpassed the conventional compressive imaging in reconstruction quality and faster running time. While multi-scale has shown superior performance over single-scale, research in DCI has been limited to single-scale sampling. Despite training with single-scale images, DCI tends to favor low-frequency components similar to the conventional multi-scale sampling, especially at low subrate. From this perspective, it would be easier for the network to learn multi-scale features with a multi-scale sampling architecture. In this work, we proposed a multi-scale deep compressive imaging (MS-DCI) framework which jointly learns to decompose, sample, and reconstruct images at multi-scale. A three-phase end-to-end training scheme was introduced with an initial and two enhance reconstruction phases to demonstrate the efficiency of multi-scale sampling and further improve the reconstruction performance. We analyzed the decomposition methods (including Pyramid, Wavelet, and Scale-space), sampling matrices, and measurements and showed the empirical benefit of MS-DCI which consistently outperforms both conventional and deep learning-based approaches.      
### 11.MusiCoder: A Universal Music-Acoustic Encoder Based on Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2008.00781.pdf)
>  Music annotation has always been one of the critical topics in the field of Music Information Retrieval (MIR). Traditional models use supervised learning for music annotation tasks. However, as supervised machine learning approaches increase in complexity, the increasing need for more annotated training data can often not be matched with available data. Moreover, over-reliance on labeled data when training supervised learning models can lead to unexpected results and open vulnerabilities for adversarial attacks. In this paper, a new self-supervised music acoustic representation learning approach named MusiCoder is proposed. Inspired by the success of BERT, MusiCoder builds upon the architecture of self-attention bidirectional transformers. Two pre-training objectives, including Contiguous Frames Masking (CFM) and Contiguous Channels Masking (CCM), are designed to adapt BERT-like masked reconstruction pre-training to continuous acoustic frame domain. The performance of MusiCoder is evaluated in two downstream music annotation tasks. The results show that MusiCoder outperforms the state-of-the-art models in both music genre classification and auto-tagging tasks. The effectiveness of MusiCoder indicates a great potential of a new self-supervised learning approach to understand music: first apply masked reconstruction tasks to pre-train a transformer-based model with massive unlabeled music acoustic data, and then finetune the model on specific downstream tasks with labeled data.      
### 12.One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2008.00768.pdf)
>  We introduce an approach to multilingual speech synthesis which uses the meta-learning concept of contextual parameter generation and produces natural-sounding multilingual speech using more languages and less training data than previous approaches. Our model is based on Tacotron 2 with a fully convolutional input text encoder whose weights are predicted by a separate parameter generator network. To boost voice cloning, the model uses an adversarial speaker classifier with a gradient reversal layer that removes speaker-specific information from the encoder. <br>We arranged two experiments to compare our model with baselines using various levels of cross-lingual parameter sharing, in order to evaluate: (1) stability and performance when training on low amounts of data, (2) pronunciation accuracy and voice quality of code-switching synthesis. For training, we used the CSS10 dataset and our new small dataset based on Common Voice recordings in five languages. Our model is shown to effectively share information across languages and according to a subjective evaluation test, it produces more natural and accurate code-switching speech than the baselines.      
### 13.Structure and Automatic Segmentation of Dhrupad Vocal Bandish Audio  [ :arrow_down: ](https://arxiv.org/pdf/2008.00756.pdf)
>  A Dhrupad vocal concert comprises a composition section that is interspersed with improvised episodes of increased rhythmic activity involving the interaction between the vocals and the percussion. Tracking the changing rhythmic density, in relation to the underlying metric tempo of the piece, thus facilitates the detection and labeling of the improvised sections in the concert structure. This work concerns the automatic detection of the musically relevant rhythmic densities as they change in time across the bandish (composition) performance. An annotated dataset of Dhrupad bandish concert sections is presented. We investigate a CNN-based system, trained to detect local tempo relationships, and follow it with temporal smoothing. We also employ audio source separation as a pre-processing step to the detection of the individual surface densities of the vocals and the percussion. This helps us obtain the complete musical description of the concert sections in terms of capturing the changing rhythmic interaction of the two performers.      
### 14.Unsupervised Discovery of Recurring Speech Patterns Using Probabilistic Adaptive Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2008.00731.pdf)
>  Unsupervised spoken term discovery (UTD) aims at finding recurring segments of speech from a corpus of acoustic speech data. One potential approach to this problem is to use dynamic time warping (DTW) to find well-aligning patterns from the speech data. However, automatic selection of initial candidate segments for the DTW-alignment and detection of "sufficiently good" alignments among those require some type of pre-defined criteria, often operationalized as threshold parameters for pair-wise distance metrics between signal representations. In the existing UTD systems, the optimal hyperparameters may differ across datasets, limiting their applicability to new corpora and truly low-resource scenarios. In this paper, we propose a novel probabilistic approach to DTW-based UTD named as PDTW. In PDTW, distributional characteristics of the processed corpus are utilized for adaptive evaluation of alignment quality, thereby enabling systematic discovery of pattern pairs that have similarity what would be expected by coincidence. We test PDTW on Zero Resource Speech Challenge 2017 datasets as a part of 2020 implementation of the challenge. The results show that the system performs consistently on all five tested languages using fixed hyperparameters, clearly outperforming the earlier DTW-based system in terms of coverage of the detected patterns.      
### 15.On the Resolution Probability of Conditional and Unconditional Maximum Likelihood DoA Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00726.pdf)
>  After decades of research in Direction of Arrival (DoA) estimation, today Maximum Likelihood (ML) algorithms still provide the best performance in terms of resolution capabilities. At the cost of a multidimensional search, ML algorithms achieve a significant reduction of the outlier production mechanism in the threshold region, where the number of snapshots per antenna and/or the signal to noise ratio (SNR) are low. The objective of this paper is to characterize the resolution capabilities of ML algorithms in the threshold region. Both conditional and unconditional versions of the ML algorithms are investigated in the asymptotic regime where both the number of antennas and the number of snapshots are large but comparable in magnitude. By using random matrix theory techniques, the finite dimensional distributions of both cost functions are shown to be Gaussian distributed in this asymptotic regime, and a closed form expression of the corresponding asymptotic covariance matrices is provided. These results allow to characterize the asymptotic behavior of the resolution probability, which is defined as the probability that the cost function evaluated at the true DoAs is smaller than the values that it takes at the positions of the other asymptotic local minima.      
### 16.Multimodal Semi-supervised Learning Framework for Punctuation Prediction in Conversational Speech  [ :arrow_down: ](https://arxiv.org/pdf/2008.00702.pdf)
>  In this work, we explore a multimodal semi-supervised learning approach for punctuation prediction by learning representations from large amounts of unlabelled audio and text data. Conventional approaches in speech processing typically use forced alignment to encoder per frame acoustic features to word level features and perform multimodal fusion of the resulting acoustic and lexical representations. As an alternative, we explore attention based multimodal fusion and compare its performance with forced alignment based fusion. Experiments conducted on the Fisher corpus show that our proposed approach achieves ~6-9% and ~3-4% absolute improvement (F1 score) over the baseline BLSTM model on reference transcripts and ASR outputs respectively. We further improve the model robustness to ASR errors by performing data augmentation with N-best lists which achieves up to an additional ~2-6% improvement on ASR outputs. We also demonstrate the effectiveness of semi-supervised learning approach by performing ablation study on various sizes of the corpus. When trained on 1 hour of speech and text data, the proposed model achieved ~9-18% absolute improvement over baseline model.      
### 17.Asynchronous Periodic Distributed Event-Triggered Frequency Control of Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2008.00694.pdf)
>  In this paper, we introduce a distributed secondary frequency control scheme for an islanded ac microgrid under event-triggered communication. An integral type event-triggered mechanism is proposed by which each distributed generator (DG) asynchronously and periodically checks its triggering condition and determines whether to update its control inputs and broadcast its states to neighboring DGs. In contrast to existing event-triggered strategies on secondary control of microgrids, under the proposed sampled-data based event-triggered mechanism, DGs need not be synchronized to a common clock and each individual DG checks its triggering condition periodically, relying on its own clock. Furthermore, the proposed method efficiently reduces communication and computation complexity. We provide sufficient conditions under which all DGs' frequencies asymptotically converge to the common reference frequency value. Finally, effectiveness of our proposed method is verified by simulating different scenarios on a well-established islanded ac microgrid benchmark in the MATLAB/Simulink environment.      
### 18.A robust but easily implementable remote control for quadrotors: Experimental acrobatic flight tests  [ :arrow_down: ](https://arxiv.org/pdf/2008.00681.pdf)
>  Experimental flight tests are reported about quadrotors UAVs via a recent model-free control (MFC) strategy, which is easily implementable. We show that it is possible to achieve acrobatic rate control of the UAV, which is beyond the previous standard. The same remote controller is tested on two physical vehicles without any re-tuning. It produces in both cases low tracking error. We show that MFC is robust even when the quadrotor is highly damaged. A video footage can be found at: <a class="link-external link-https" href="https://youtu.be/wtSLalA4szc" rel="external noopener nofollow">this https URL</a>      
### 19.Reinforcement Solver for H-infinity Filter with Bounded Noise  [ :arrow_down: ](https://arxiv.org/pdf/2008.00674.pdf)
>  H-infinity filter has been widely applied in engineering field, but copping with bounded noise is still an open problem and difficult to solve. This paper considers the H-infinity filtering problem for linear system with bounded process and measurement noise. The problem is first formulated as a zero-sum game where the dynamic of estimation error is non-affine with respect to filter gain and measurement noise. A nonquadratic Hamilton-Jacobi-Isaacs (HJI) equation is then derived by employing a nonquadratic cost to characterize bounded noise, which is extremely difficult to solve due to its non-affine and nonlinear properties. Next, a reinforcement learning algorithm based on gradient descent method which can handle nonlinearity is proposed to update the gain of reinforcement filter, where measurement noise is fixed to tackle non-affine property and increase the convexity of Hamiltonian. Two examples demonstrate the convergence and effectiveness of the proposed algorithm.      
### 20.Frequency-Domain Signal Processing for Spectrally-Enhanced CP-OFDM Waveforms in 5G New Radio  [ :arrow_down: ](https://arxiv.org/pdf/2008.00672.pdf)
>  Orthogonal frequency-division multiplexing (OFDM) has been selected as the basis for the fifth-generation new radio (5G-NR) waveform developments. However, effective signal processing tools are needed for enhancing the OFDM spectrum in various advanced transmission scenarios. In earlier work, we have shown that fast-convolution (FC) processing is a very flexible and efficient tool for filtered-OFDM signal generation and receiver-side subband filtering, e.g., for the mixed-numerology scenarios of the 5G-NR. FC filtering approximates linear convolution through effective fast Fourier transform (FFT)-based circular convolutions using partly overlapping processing blocks. However, with the continuous overlap-and-save and overlap-and-add processing models with fixed block-size and fixed overlap, the FC-processing blocks cannot be aligned with all OFDM symbols of a transmission frame. Furthermore, 5G-NR numerology does not allow to use transform lengths shorter than 128 because this would lead to non-integer cyclic prefix (CP) lengths. In this article, we present new FC-processing schemes which solve the mentioned limitations. These schemes are based on dynamically adjusting the overlap periods and extrapolating the CP samples, which make it possible to align the FC blocks with each OFDM symbol, even in case of variable CP lengths. This reduces complexity and latency, e.g., in mini-slot transmissions and, as an example, allows to use 16-point transforms in case of a 12-subcarrier-wide subband allocation, greatly reducing the implementation complexity. On the receiver side, the proposed scheme makes it possible to effectively combine cascaded inverse and forward FFT units in FC-filtered OFDM processing. Transform decomposition is used to simplify these computations. Very extensive set of numerical results is also provided, in terms of radio-link performance and associated processing complexity.      
### 21.TutorNet: Towards Flexible Knowledge Distillation for End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.00671.pdf)
>  In recent years, there has been a great deal of research in developing end-to-end speech recognition models, which enable simplifying the traditional pipeline and achieving promising results. Despite their remarkable performance improvements, end-to-end models typically require expensive computational cost to show successful performance. To reduce this computational burden, knowledge distillation (KD), which is a popular model compression method, has been used to transfer knowledge from a deep and complex model (teacher) to a shallower and simpler model (student). Previous KD approaches have commonly designed the architecture of the student model by reducing the width per layer or the number of layers of the teacher model. This structural reduction scheme might limit the flexibility of model selection since the student model structure should be similar to that of the given teacher. To cope with this limitation, we propose a new KD method for end-to-end speech recognition, namely TutorNet, that can transfer knowledge across different types of neural networks at the hidden representation-level as well as the output-level. For concrete realizations, we firstly apply representation-level knowledge distillation (RKD) during the initialization step, and then apply the softmax-level knowledge distillation (SKD) combined with the original task learning. When the student is trained with RKD, we make use of frame weighting that points out the frames to which the teacher model pays more attention. Through a number of experiments on LibriSpeech dataset, it is verified that the proposed method not only distills the knowledge between networks with different topologies but also significantly contributes to improving the word error rate (WER) performance of the distilled student. Interestingly, TutorNet allows the student model to surpass its teacher's performance in some particular cases.      
### 22.Learning Intonation Pattern Embeddings for Arabic Dialect Identification  [ :arrow_down: ](https://arxiv.org/pdf/2008.00667.pdf)
>  This article presents a full end-to-end pipeline for Arabic Dialect Identification (ADI) using intonation patterns and acoustic representations. Recent approaches to language and dialect identification use linguistic-aware deep architectures that are able to capture phonetic differences amongst languages and dialects. Specifically, in ADI tasks, different combinations of linguistic features and acoustic representations have been successful with deep learning models. The approach presented in this article uses intonation patterns and hybrid residual and bidirectional LSTM networks to learn acoustic embeddings with no additional linguistic information. Results of the experiments show that intonation patterns for Arabic dialects provide sufficient information to achieve state-of-the-art results on the VarDial 17 ADI dataset, outperforming single-feature systems. The pipeline presented is robust to data sparsity, in contrast to other deep learning approaches that require large quantities of data. We conjecture on the importance of sufficient information as a criterion for optimality in a deep learning ADI task, and more generally, its application to acoustic modeling problems. Small intonation patterns, when sufficient in an information-theoretic sense, allow deep learning architectures to learn more accurate speech representations.      
### 23.Self-evolving ghost imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.00648.pdf)
>  Ghost imaging can capture 2D images with a point detector instead of an array sensor. It therefore offers a solution to the challenge of building area format sensors in wavebands where such sensors are difficult and expensive to produce and opens up new imaging modalities due to high-performance single-pixel detectors. Traditionally, ghost imaging retrieves the image of an object offline, by correlating measured light intensities and applied illuminating patterns. Here we present a feedback-based approach for online updating of the imaging result that can bypass post-processing, termed self-evolving ghost imaging (SEGI). We introduce a genetic algorithm to optimize the illumination patterns in real-time to match the objects shape according to the measured total light intensity. We theoretically and experimentally demonstrate this concept for static and dynamic imaging. This method opens new perspectives for real-time ghost imaging in applications such as remote sensing (e.g. machine vision, LiDAR systems in autonomous vehicles) and biological imaging.      
### 24.Multiscale assay of unlabeled neurite dynamics using phase imaging with computational specificity (PICS)  [ :arrow_down: ](https://arxiv.org/pdf/2008.00626.pdf)
>  Primary neuronal cultures have been widely used to study neuronal morphology, neurophysiology, neurodegenerative processes, and molecular mechanism of synaptic plasticity underlying learning and memory. Yet, the unique behavioral properties of neurons make them challenging to study - with phenotypic differences expressed as subtle changes in neuronal arborization rather than easy to assay features such as cell count. The need to analyze morphology, growth, and intracellular transport has motivated the development of increasingly sophisticated microscopes and image analysis techniques. Due to its high-contrast, high-specificity output, many assays rely on confocal fluorescence microscopy, genetic methods, or antibody staining techniques. These approaches often limit the ability to measure quantitatively dynamic activity such as intracellular transport and growth. In this work, we describe a method for label-free live-cell cell imaging with antibody staining specificity by estimating the associated fluorescent signals via quantitative phase imaging and deep convolutional neural networks. This computationally inferred fluorescence image is then used to generate a semantic segmentation map, annotating subcellular compartments of live unlabeled neural cultures. These synthetic fluorescence maps were further applied to study the time-lapse development of hippocampal neurons, highlighting the relationships between the cellular dry mass production and the dynamic transport activity within the nucleus and neurites. Our implementation provides a high-throughput strategy to analyze neural network arborization dynamically, with high specificity and without the typical phototoxicity and photobleaching limitations associated with fluorescent markers.      
### 25.BlueFMCW: Random Frequency Hopping Radar for Mitigation of Interference and Spoofing  [ :arrow_down: ](https://arxiv.org/pdf/2008.00624.pdf)
>  Traffic safety is the foremost value that automotive radar systems aim to pursue. Unlike in mobile communication systems, the literature for radar systems did not adequately address inter-radar interference and security threats such as jamming and spoofing, which in turn threatens the traffic safety. In this context, we introduce a novel frequency-modulated continuous-wave (FMCW) radar scheme (namely, BlueFMCW) that mitigates both interference and spoofing signals. BlueFMCW randomly hops frequency to avoid interference and spoofing signals. Our phase alignment algorithm is capable of removing the phase discontinuity while combining the beat signals from the randomly-hopped chirps, and thereby radar's resolution is not compromised. The simulation results show that BlueFMCW can efficiently mitigate the interference and spoofing signals in various scenarios without paying its resolution.      
### 26.Audiovisual Speech Synthesis using Tacotron2  [ :arrow_down: ](https://arxiv.org/pdf/2008.00620.pdf)
>  Audiovisual speech synthesis is the problem of synthesizing a talking face while maximizing the coherency of the acoustic and visual speech. In this paper, we propose and compare two audiovisual speech synthesis systems for 3D face models. The first system is the AVTacotron2, which is an end-to-end text-to-audiovisual speech synthesizer based on the Tacotron2 architecture. AVTacotron2 converts a sequence of phonemes representing the sentence to synthesize into a sequence of acoustic features and the corresponding controllers of a face model. The output acoustic features are used to condition a WaveRNN to reconstruct the speech waveform, and the output facial controllers are used to generate the corresponding video of the talking face. The second audiovisual speech synthesis system is modular, where acoustic speech is synthesized from text using the traditional Tacotron2. The reconstructed acoustic speech signal is then used to drive the facial controls of the face model using an independently trained audio-to-facial-animation neural network. We further condition both the end-to-end and modular approaches on emotion embeddings that encode the required prosody to generate emotional audiovisual speech. We analyze the performance of the two systems and compare them to the ground truth videos using subjective evaluation tests. The end-to-end and modular systems are able to synthesize close to human-like audiovisual speech with mean opinion scores (MOS) of 4.1 and 3.9, respectively, compared to a MOS of 4.1 for the ground truth generated from professionally recorded videos. While the end-to-end system gives a better overall quality, the modular approach is more flexible and the quality of acoustic speech and visual speech synthesis is almost independent of each other.      
### 27.A Novel Physics-based Channel Model for Reconfigurable Intelligent Surface-assisted Multi-user Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.00619.pdf)
>  The reconfigurable intelligent surface (RIS) is one of the promising technologies contributing to the next generation smart radio environment. A novel physics-based RIS channel model is proposed. Particularly, we consider the RIS and the scattering environment as a whole by studying the signal's multipath propagation, as well as the radiation pattern of the RIS. The model suggests that the RIS-assisted wireless channel can be approximated by a Rician distribution. Analytical expressions are derived for the shape factor and the scale factor of the distribution. For the case of continuous phase shifts, the distribution depends on the number of elements of the RIS and the observing direction of the receiver. For the case of continuous phase shifts, the distribution further depends on the quantization level of the RIS phase error. The scaling law of the average received power is obtained from the scale factor of the distribution. For the application scenarios where RIS functions as an anomalous reflector, we investigate the performance of single RIS-assisted multiple access networks for time-division multiple access (TDMA), frequency-division multiple access (FDMA) and non-orthogonal multiple access (NOMA). Closed-form expressions for the outage probability of the proposed channel model are derived. It is proved that a constant diversity order exists, which is independent of the number of RIS elements. Simulation results are presented to confirm that the proposed model applies effectively to the phased-array implemented RISs.      
### 28.Multitask learning for instrument activation aware music source separation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00616.pdf)
>  Music source separation is a core task in music information retrieval which has seen a dramatic improvement in the past years. Nevertheless, most of the existing systems focus exclusively on the problem of source separation itself and ignore the utilization of other~---possibly related---~MIR tasks which could lead to additional quality gains. In this work, we propose a novel multitask structure to investigate using instrument activation information to improve source separation performance. Furthermore, we investigate our system on six independent instruments, a more realistic scenario than the three instruments included in the widely-used MUSDB dataset, by leveraging a combination of the MedleyDB and Mixing Secrets datasets. The results show that our proposed multitask model outperforms the baseline Open-Unmix model on the mixture of Mixing Secrets and MedleyDB dataset while maintaining comparable performance on the MUSDB dataset.      
### 29.Exploiting Deep Sentential Context for Expressive End-to-End Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.00613.pdf)
>  Attention-based seq2seq text-to-speech systems, especially those use self-attention networks (SAN), have achieved state-of-art performance. But an expressive corpus with rich prosody is still challenging to model as 1) prosodic aspects, which span across different sentential granularities and mainly determine acoustic expressiveness, are difficult to quantize and label and 2) the current seq2seq framework extracts prosodic information solely from a text encoder, which is easily collapsed to an averaged expression for expressive contents. In this paper, we propose a context extractor, which is built upon SAN-based text encoder, to sufficiently exploit the sentential context over an expressive corpus for seq2seq-based TTS. Our context extractor first collects prosodic-related sentential context information from different SAN layers and then aggregates them to learn a comprehensive sentence representation to enhance the expressiveness of the final generated speech. Specifically, we investigate two methods of context aggregation: 1) direct aggregation which directly concatenates the outputs of different SAN layers, and 2) weighted aggregation which uses multi-head attention to automatically learn contributions for different SAN layers. Experiments on two expressive corpora show that our approach can produce more natural speech with much richer prosodic variations, and weighted aggregation is more superior in modeling expressivity.      
### 30.The Rate-Distortion-Accuracy Tradeoff: JPEG Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2008.00605.pdf)
>  Handling digital images is almost always accompanied by a lossy compression in order to facilitate efficient transmission and storage. This introduces an unavoidable tension between the allocated bit-budget (rate) and the faithfulness of the resulting image to the original one (distortion). An additional complicating consideration is the effect of the compression on recognition performance by given classifiers (accuracy). This work aims to explore this rate-distortion-accuracy tradeoff. As a case study, we focus on the design of the quantization tables in the JPEG compression standard. We offer a novel optimal tuning of these tables via continuous optimization, leveraging a differential implementation of both the JPEG encoder-decoder and an entropy estimator. This enables us to offer a unified framework that considers the interplay between rate, distortion and classification accuracy. In all these fronts, we report a substantial boost in performance by a simple and easily implemented modification of these tables.      
### 31.Detection of COVID-19 from Chest X-rays using Deep Learning: Comparing COGNEX VisionPro Deep Learning 1.0 Software with Open Source Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.00597.pdf)
>  The COVID-19 pandemic has been having a severe and catastrophic effect on humankind and is being considered the most crucial health calamity of the century. One of the best methods of detecting COVID-19 is from radiological images, namely X-rays and Computed Tomography or CT scan images. Many companies and educational organizations have come together during this crisis and created various Deep Learning models for the effective diagnosis of COVID-19 from chest radiography images. For example, the University of Waterloo, along with Darwin AI, has designed its Deep Learning model COVID-Net and created a dataset called COVIDx, consisting of 13,975 images. In this study, COGNEXs Deep Learning Software-VisionPro Deep Learning is used to classify these Chest X-rays from the COVIDx dataset. The results are compared with the results of COVID-Net and various other state of the art Deep Learning models from the open-source community. Deep Learning tools are often referred to as black boxes because humans cannot interpret how or why a model is classifying an image into a particular class. This problem is addressed by testing VisionPro Deep Learning with two settings, firstly by selecting the entire image, that is, selecting the entire image as the Region of Interest-ROI, and secondly by segmenting the lungs in the first step, and then doing the classification step on the segmented lungs only, instead of using the entire image. VisionPro Deep Learning results-on the entire image as the ROI it achieves an overall F-score of 94.0 percent, and on the segmented lungs, it gets an F-score of 95.3 percent, which is at par or better than COVID-Net and other state of the art open-source Deep Learning models.      
### 32.Generating Minimum-Snap Quadrotor Trajectories Really Fast  [ :arrow_down: ](https://arxiv.org/pdf/2008.00595.pdf)
>  We propose an algorithm for generating minimum-snap trajectories for quadrotors with linear computational complexity with respect to the number of segments in the spline trajectory. Our algorithm is numerically stable for large numbers of segments and is able to generate trajectories of more than $500,000$ segments. The computational speed and numerical stability of our algorithm makes it suitable for real-time generation of very large scale trajectories. We demonstrate the performance of our algorithm and compare it to existing methods, in which it is both faster and able to calculate larger trajectories than state-of-the-art. We also show the feasibility of the trajectories experimentally with a long quadrotor flight.      
### 33.Signal Processing on Directed Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2008.00586.pdf)
>  This paper provides an overview of the current landscape of signal processing (SP) on directed graphs (digraphs). Directionality is inherent to many real-world (information, transportation, biological) networks and it should play an integral role in processing and learning from network data. We thus lay out a comprehensive review of recent advances in SP on digraphs, offering insights through comparisons with results available for undirected graphs, discussing emerging directions, establishing links with related areas in machine learning and causal inference in statistics, as well as illustrating their practical relevance to timely applications. To this end, we begin by surveying (orthonormal) signal representations and their graph frequency interpretations based on novel measures of signal variation for digraphs. We then move on to filtering, a central component in deriving a comprehensive theory of SP on digraphs. Indeed, through the lens of filter-based generative signal models, we explore a unified framework to study inverse problems (e.g., sampling and deconvolution on networks), statistical analysis of random signals, and topology inference of digraphs from nodal observations.      
### 34.All-Digital FPGA-based DAC with None or Few External Components  [ :arrow_down: ](https://arxiv.org/pdf/2008.00572.pdf)
>  One of the many limitations with the mixed-signal design is physically testing circuit ideas. While it is easier to test digital circuits with FPGAs, this can not be done usually with mixed-signal circuits. Although some FPGAs have built-in analog-to-digital and digital-to-analog converters, regular commercial FPGAs development boards and low-cost FPGAs lack built-in data converters. Here we introduce an all-digital FPGA-based DAC, which is one of the main blocks to enable mixed-signal experiments. The DAC can be synthesized entirely in an FPGA and does not require the use of external components. Furthermore, and to extend its range of applications, a discussion regarding the proposed DAC's problems and possible solutions is presented. Experimental demonstration of a 4-bit and a 5-bit DAC corroborate the theoretical analysis developed in this work. This work also suggests a scheme which includes few external resistors to improve the linearity (DNL$\leq$0.25LSB and an INL$\leq$0.5LSB), and the power consumption (5X improvement over the standalone configuration).      
### 35.Adaptive Compressive Sampling for Mid-infrared Spectroscopic Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.00566.pdf)
>  Fourier transform infrared (FTIR) spectroscopy enables label-free molecular identification and quantification of biological specimens. The resolution of diffraction limited FTIR imaging is poor due to the long optical wavelengths (2.5{\mu}m to 12.5{\mu}m)used and this is particularly limiting in biomedical imaging. Photothermal imaging overcomes this diffraction limit by using a multimodal pump/probe approach. However, these measurements require approximately 1 s per spectrum, making them impractical for large samples. This paper introduces an adaptive compressive sampling technique to dramatically reduce hyperspectral data acquisition time by utilizing both spectral and spatial sparsity. This method identifies the most informative spatial and spectral features and integrates a fast tensor completion algorithm to reconstruct megapixel-scale images and demonstrates speed advantages over FTIR imaging      
### 36.Cross-Domain Adaptation of Spoken Language Identification for Related Languages: The Curious Case of Slavic Languages  [ :arrow_down: ](https://arxiv.org/pdf/2008.00545.pdf)
>  State-of-the-art spoken language identification (LID) systems, which are based on end-to-end deep neural networks, have shown remarkable success not only in discriminating between distant languages but also between closely-related languages or even different spoken varieties of the same language. However, it is still unclear to what extent neural LID models generalize to speech samples with different acoustic conditions due to domain shift. In this paper, we present a set of experiments to investigate the impact of domain mismatch on the performance of neural LID systems for a subset of six Slavic languages across two domains (read speech and radio broadcast) and examine two low-level signal descriptors (spectral and cepstral features) for this task. Our experiments show that (1) out-of-domain speech samples severely hinder the performance of neural LID models, and (2) while both spectral and cepstral features show comparable performance within-domain, spectral features show more robustness under domain mismatch. Moreover, we apply unsupervised domain adaptation to minimize the discrepancy between the two domains in our study. We achieve relative accuracy improvements that range from 9% to 77% depending on the diversity of acoustic conditions in the source domain.      
### 37.Modelling, Controllability and Gait Design for a Spherical Flexible Swimmer  [ :arrow_down: ](https://arxiv.org/pdf/2008.00505.pdf)
>  This paper discusses modelling, controllability and gait design for a spherical flexible swimmer. We first present a kinematic model of a low Reynolds number spherical flexible swimming mechanism with periodic surface deformations in the radial and azimuthal directions. The model is then converted to a finite dimensional driftless, affine-in-control principal kinematic form by representing the surface deformations as a linear combination of finitely many Legendre polynomials. A controllability analysis is then done for this swimmer to conclude that the swimmer is locally controllable on $\mathbb{R}^3$ for certain combinations of the Legendre polynomials. The rates of the coefficients of the polynomials are considered as the control inputs for surface deformation. Finally, the Abelian nature of the structure group of the swimmer's configuration space is exploited to synthesize a curvature based gait for the spherical flexile swimmer and a rigid-link swimmer.      
### 38.Multi-level Wavelet-based Generative Adversarial Network for Perceptual Quality Enhancement of Compressed Video  [ :arrow_down: ](https://arxiv.org/pdf/2008.00499.pdf)
>  The past few years have witnessed fast development in video quality enhancement via deep learning. Existing methods mainly focus on enhancing the objective quality of compressed video while ignoring its perceptual quality. In this paper, we focus on enhancing the perceptual quality of compressed video. Our main observation is that enhancing the perceptual quality mostly relies on recovering high-frequency sub-bands in wavelet domain. Accordingly, we propose a novel generative adversarial network (GAN) based on multi-level wavelet packet transform (WPT) to enhance the perceptual quality of compressed video, which is called multi-level wavelet-based GAN (MW-GAN). In MW-GAN, we first apply motion compensation with a pyramid architecture to obtain temporal information. Then, we propose a wavelet reconstruction network with wavelet-dense residual blocks (WDRB) to recover the high-frequency details. In addition, the adversarial loss of MW-GAN is added via WPT to further encourage high-frequency details recovery for video frames. Experimental results demonstrate the superiority of our method.      
### 39.Selection of Robust Digital Communication Techniques for the Vehicle to Vehicle Communication  [ :arrow_down: ](https://arxiv.org/pdf/2008.00450.pdf)
>  V2V, Vehicle to Vehicle communication has become one of the key features in achieving complete autonomy for self-driving vehicles. We use digital communication as a backbone to deliver a vehicle to vehicle communication. The primary building blocks of a digital communication system are source coding, error correction and detection, and channel coding. Choosing optimal techniques for each block plays a significant role in the performance of the entire communication system. Five Source coding techniques, three Error control, and Channel coding techniques, respectively, have been considered for the implementation. The methods were evaluated based on different comparison parameters for each of the building blocks. Based on the obtained result, the robust techniques were chosen for our application.      
### 40.Uplink Achievable Rate of Intelligent Reflecting Surface-Aided Millimeter-Wave Communications with Low-Resolution ADC and Phase Noise  [ :arrow_down: ](https://arxiv.org/pdf/2008.00437.pdf)
>  In this paper, we derive the uplink achievable rate expression of intelligent reflecting surface (IRS)-aided millimeter-wave (mmWave) systems, taking into account the phase noise at IRS and the quantization error at base stations (BSs). We show that the performance is limited only by the resolution of analog-digital converters (ADCs) at BSs when the number of IRS reflectors grows without bound. On the other hand, if BSs have ideal ADCs, the performance loss caused by IRS phase noise is a constant. Finally, our results validate the feasibility of using low-precision hardware at the IRS when BSs are equipped with low-resolution ADCs.      
### 41.Contact Classification in COVID-19 Tracing  [ :arrow_down: ](https://arxiv.org/pdf/2008.00431.pdf)
>  The present paper addresses the task of reliably identifying critical contacts by using COVID-19 tracing apps. A reliable classification is crucial to ensure a high level of protection, and at the same time to prevent many people from being sent to quarantine by the app. Tracing apps are based on the capabilities of current smartphones to enable a broadest possible availability. Existing capabilities of smartphones include the exchange of Bluetooth Low Energy (BLE) signals and of audio signals, as well as the use of gyroscopes and magnetic sensors. The Bluetooth power measurements, which are often used today, may be complemented by audio ranging and attitude estimation in the future. Smartphones are worn in different ways, often in pockets and bags, which makes the propagation of signals and thus the classification rather unpredictable. Relying on the cooperation of users to wear their phones hanging from their neck would change the situation considerably. In this case the performance, achievable with BLE and audio measurements, becomes predictable. Our analysis identifies parameters that result in accurate warnings, at least within the scope of validity of the models. A significant reduction of the spreading of the disease can then be achieved by the apps, without causing many people to unduly go to quarantine. The present paper is the first of three papers which analyze the situation in some detail.      
### 42.Multiobjective Backstepping Controller for Parallel Buck Converter  [ :arrow_down: ](https://arxiv.org/pdf/2008.00428.pdf)
>  A backstepping controller is designed for a system of parallel buck converters sharing load. Controller objective is to ensure proper current sharing and output voltage regulation. The designed controller is successfully tested for both constant load and sudden change in loading conditions.      
### 43.Multi-target tracking with an adaptive $-$GLMB filter  [ :arrow_down: ](https://arxiv.org/pdf/2008.00413.pdf)
>  Abstract In multi-target tracking, targets can appear and disappear in the surveillance region, randomly varying the number of targets and their locations throughout the tracking process. Moreover, apart from measurement noise, observations of the targets are corrupted by misdetections, and false alarms. Therefore, prior information such as the target birth locations, amount of measurement clutter (false alarms) produced by the sensor, and the probability of detection targets have to be taken into account to model the multi-target system as realistic as possible. In general, such information is not available. As a result, the tracking algorithms have to be supplied with intuitive guesses of these values, which usually results in inferior performances. Therefore, accurate inference of these parameters is paramount for achieving acceptable tracking performance in practice. In this paper, we propose a plug-and-play multi-target tracking algorithm based on the recent $\delta$-Generalized Labeled Multi-Bernoulli $\delta$-GLMB) filter which remove the guess work in determining the parameters of the target birth process, the detection probability, and clutter rate online. The simulation results of a tracking scenario with targets having linear and nonlinear motion models prove the efficacy of the proposed algorithm.      
### 44.MAGIC: Manifold and Graph Integrative Convolutional Network for Low-Dose CT Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2008.00406.pdf)
>  Low-dose computed tomography (LDCT) scans, which can effectively alleviate the radiation problem, will degrade the imaging quality. In this paper, we propose a novel LDCT reconstruction network that unrolls the iterative scheme and performs in both image and manifold spaces. Because patch manifolds of medical images have low-dimensional structures, we can build graphs from the manifolds. Then, we simultaneously leverage the spatial convolution to extract the local pixel-level features from the images and incorporate the graph convolution to analyze the nonlocal topological features in manifold space. The experiments show that our proposed method outperforms both the quantitative and qualitative aspects of state-of-the-art methods. In addition, aided by a projection loss component, our proposed method also demonstrates superior performance for semi-supervised learning. The network can remove most noise while maintaining the details of only 10% (40 slices) of the training data labeled.      
### 45.Millimeter-Wave Angle Estimation of Multiple Targets Using Space-Time Modulation and Interferometric Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2008.00356.pdf)
>  A new method of angle estimation of multiple targets using a distributed interferometric antenna array and wideband space-time modulation is presented in this work. Interferometric array measurements of angle of arrival are generally ambiguous in the presence of one or more targets. We propose a new method of mitigating ambiguities in interferometric measurements by multiplying the angle pseudo-spectra from multiple antenna baselines, resulting in detections at only the angles of the targets. Using a single linear frequency modulated (LFM) transmitter and a receive interferometric array with $N$ elements we show a simple and computationally efficient technique to estimate the angle of up to $\mathcal{O}(N^2)$ targets. We describe the theory behind the technique, present detailed simulations, and an experimental verification using a three-element millimeter-wave measurement system.      
### 46.A Micro-PMU Placement Scheme for Distribution Systems Considering Practical Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2008.00354.pdf)
>  This paper presents an innovative approach to micro-phasor measurement unit (micro-PMU) placement in unbalanced distribution networks. The methodology accounts for the presence of single-and-two-phase laterals and acknowledges the fact that observing one phase in a distribution circuit does not translate to observing the other phases. Other practical constraints such as presence of distributed loads, unknown regulator/ transformer tap ratios, zero-injection phases (ZIPs), modern smart meters, and multiple switch configurations are also incorporated. The proposed micro-PMU placement problem is solved using integer linear programming (ILP), guaranteeing optimality of results. The uniqueness of the developed algorithm is that it not only minimizes the micro-PMU installations, but also identifies the minimum number of phases that must be monitored by them.      
### 47.DCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2008.00264.pdf)
>  Speech enhancement has benefited from the success of deep learning in terms of intelligibility and perceptual quality. Conventional time-frequency (TF) domain methods focus on predicting TF-masks or speech spectrum, via a naive convolution neural network (CNN) or recurrent neural network (RNN). Some recent studies use complex-valued spectrogram as a training target but train in a real-valued network, predicting the magnitude and phase component or real and imaginary part, respectively. Particularly, convolution recurrent network (CRN) integrates a convolutional encoder-decoder (CED) structure and long short-term memory (LSTM), which has been proven to be helpful for complex targets. In order to train the complex target more effectively, in this paper, we design a new network structure simulating the complex-valued operation, called Deep Complex Convolution Recurrent Network (DCCRN), where both CNN and RNN structures can handle complex-valued operation. The proposed DCCRN models are very competitive over other previous networks, either on objective or subjective metric. With only 3.7M parameters, our DCCRN models submitted to the Interspeech 2020 Deep Noise Suppression (DNS) challenge ranked first for the real-time-track and second for the non-real-time track in terms of Mean Opinion Score (MOS).      
### 48.Deep Reinforcement Learning Based Mobile Edge Computing for Intelligent Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2008.00250.pdf)
>  In this paper, we investigate mobile edge computing (MEC) networks for intelligent internet of things (IoT), where multiple users have some computational tasks assisted by multiple computational access points (CAPs). By offloading some tasks to the CAPs, the system performance can be improved through reducing the latency and energy consumption, which are the two important metrics of interest in the MEC networks. We devise the system by proposing the offloading strategy intelligently through the deep reinforcement learning algorithm. In this algorithm, Deep Q-Network is used to automatically learn the offloading decision in order to optimize the system performance, and a neural network (NN) is trained to predict the offloading action, where the training data is generated from the environmental system. Moreover, we employ the bandwidth allocation in order to optimize the wireless spectrum for the links between the users and CAPs, where several bandwidth allocation schemes are proposed. In further, we use the CAP selection in order to choose one best CAP to assist the computational tasks from the users. Simulation results are finally presented to show the effectiveness of the proposed reinforcement learning offloading strategy. In particular, the system cost of latency and energy consumption can be reduced significantly by the proposed deep reinforcement learning based algorithm.      
### 49.Exploring Multi-Scale Feature Propagation and Communication for Image Super Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2008.00239.pdf)
>  Multi-scale techniques have achieved great success in a wide range of computer vision tasks. However, while this technique is incorporated in existing works, there still lacks a comprehensive investigation on variants of multi-scale convolution in image super resolution. In this work, we present a unified formulation over widely-used multi-scale structures. With this framework, we systematically explore the two factors of multi-scale convolution -- feature propagation and cross-scale communication. Based on the investigation, we propose a generic and efficient multi-scale convolution unit -- Multi-Scale cross-Scale Share-weights convolution (MS$^3$-Conv). Extensive experiments demonstrate that the proposed MS$^3$-Conv can achieve better SR performance than the standard convolution with less parameters and computational cost. Beyond quantitative analysis, we comprehensively study the visual quality, which shows that MS$^3$-Conv behave better to recover high-frequency details.      
### 50.UAV Relay-Assisted Emergency Communications in IoT Networks: Resource Allocation and Trajectory Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2008.00218.pdf)
>  In this paper, a UAV is deployed as a flying base station to collect data from time-constrained IoT devices and then transfer the data to a ground gateway (GW). In general, the latency constraint at IoT users and the limited storage capacity of UAV highly hinder practical applications of UAV-assisted IoT networks. In this paper, full-duplex (FD) technique is adopted at the UAV to overcome these challenges. In addition, half-duplex (HD) scheme for UAV-based relaying is also considered to provide a comparative study between two modes. In this context, we aim at maximizing the number of served IoT devices by jointly optimizing bandwidth and power allocation, as well as the UAV trajectory, while satisfying the requested timeout (RT) requirement of each device and the UAV's limited storage capacity. The formulated optimization problem is troublesome to solve due to its non-convexity and combinatorial nature. Toward appealing applications, we first relax binary variables into continuous values and transform the original problem into a more computationally tractable form. By leveraging inner approximation framework, we derive newly approximated functions for non-convex parts and then develop a simple yet efficient iterative algorithm for its solutions. Next, we attempt to maximize the total throughput subject to the number of served IoT devices. Finally, numerical results show that the proposed algorithms significantly outperform benchmark approaches in terms of the number of served IoT devices and the amount of collected data.      
### 51.Neural ODE with Temporal Convolution and Time Delay Neural Networks for Small-Footprint Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2008.00209.pdf)
>  In this paper, we propose neural network models based on the neural ordinary differential equation (NODE) for small-footprint keyword spotting (KWS). We present techniques to apply NODE to KWS that make it possible to adopt Batch Normalization to NODE-based network and to reduce the number of computations during inference. Finally, we show that the number of model parameters of the proposed model is smaller by 68% than that of the conventional KWS model.      
### 52.Score-informed Networks for Music Performance Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2008.00203.pdf)
>  The assessment of music performances in most cases takes into account the underlying musical score being performed. While there have been several automatic approaches for objective music performance assessment (MPA) based on extracted features from both the performance audio and the score, deep neural network-based methods incorporating score information into MPA models have not yet been investigated. In this paper, we introduce three different models capable of score-informed performance assessment. These are (i) a convolutional neural network that utilizes a simple time-series input comprising of aligned pitch contours and score, (ii) a joint embedding model which learns a joint latent space for pitch contours and scores, and (iii) a distance matrix-based convolutional neural network which utilizes patterns in the distance matrix between pitch contours and musical score to predict assessment ratings. Our results provide insights into the suitability of different architectures and input representations and demonstrate the benefits of score-informed models as compared to score-independent models.      
### 53.Singer Identification Using Convolutional Acoustic Motif Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2008.00198.pdf)
>  Flamenco singing is characterized by pitch instability, micro-tonal ornamentations, large vibrato ranges, and a high degree of melodic variability. These musical features make the automatic identification of flamenco singers a difficult computational task. In this article we present an end-to-end pipeline for flamenco singer identification based on acoustic motif embeddings. In the approach taken, the fundamental frequency obtained directly from the raw audio signal is approximated. This approximation reduces the high variability of the audio signal and allows for small melodic patterns to be discovered using a sequential pattern mining technique, thus creating a dictionary of motifs. Several acoustic features are then used to extract fixed length embeddings of variable length motifs by using convolutional architectures. We test the quality of the embeddings in a flamenco singer identification task, comparing our approach with previous deep learning architectures, and study the effect of motivic patterns and acoustic features in the identification task. Results indicate that motivic patterns play a crucial role in identifying flamenco singers by minimizing the size of the signal to be learned, discarding information that is not relevant in the identification task. The deep learning architecture presented outperforms denser models used in large-scale audio classification problems.      
### 54.Joint Generative Learning and Super-Resolution For Real-World Camera-Screen Degradation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00195.pdf)
>  In real-world single image super-resolution (SISR) task, the low-resolution image suffers more complicated degradations, not only downsampled by unknown kernels. However, existing SISR methods are generally studied with the synthetic low-resolution generation such as bicubic interpolation (BI), which greatly limits their performance. Recently, some researchers investigate real-world SISR from the perspective of the camera and smartphone. However, except the acquisition equipment, the display device also involves more complicated degradations. In this paper, we focus on the camera-screen degradation and build a real-world dataset (Cam-ScreenSR), where HR images are original ground truths from the previous DIV2K dataset and corresponding LR images are camera-captured versions of HRs displayed on the screen. We conduct extensive experiments to demonstrate that involving more real degradations is positive to improve the generalization of SISR models. Moreover, we propose a joint two-stage model. Firstly, the downsampling degradation GAN(DD-GAN) is trained to model the degradation and produces more various of LR images, which is validated to be efficient for data augmentation. Then the dual residual channel attention network (DuRCAN) learns to recover the SR image. The weighted combination of L1 loss and proposed Laplacian loss are applied to sharpen the high-frequency edges. Extensive experimental results in both typical synthetic and complicated real-world degradations validate the proposed method outperforms than existing SOTA models with less parameters, faster speed and better visual results. Moreover, in real captured photographs, our model also delivers best visual quality with sharper edge, less artifacts, especially appropriate color enhancement, which has not been accomplished by previous methods.      
### 55.Impact and Implementation of Reserved Lanes for Automated Driving on Signalized Urban Arterials  [ :arrow_down: ](https://arxiv.org/pdf/2008.00170.pdf)
>  An automated vehicle refers to a vehicle that can achieve a safe movement on a roadway facility without the influence of a human driver. With emerging trend of the connected vehicle concept over the past decade, numerous state-of-the-art applications focusing on automated vehicle-based intersection control have been proposed. The main purpose of this study is to estimate and evaluate impact of designated lanes for automated vehicles and recommend some viable lane configuration scenarios for signalized urban arterials. The automated driving was simulated in PTV Vissim using trajectory-driven control strategy. The concept evaluation through microsimulation reveals significant mobility improvements compared to operational scenario without lane reservation. Findings imply that for signalized corridors observed in this study, total travel time reductions are ranging from 5.1% to 19.4% depending on C/AV market penetration, and test-bed configuration parameters.      
### 56.Byzantine-Resilient Distributed Hypothesis Testing With Time-Varying Network Topology  [ :arrow_down: ](https://arxiv.org/pdf/2008.00164.pdf)
>  We study the problem of distributed hypothesis testing over a network of mobile agents. Each agent follows a planned trajectory and makes noisy local observations whose distribution is conditioned on the unknown true hypothesis (out of a finite set of candidate hypotheses) and the agent's current location. Due to the limited communication and sensing ranges, the mobile agent team induces a communication graph with a time-varying topology and needs to collaboratively detect the true hypothesis. In particular, we consider a scenario where there exists an unknown subset of compromised agents that may deliberately share altered information to undermine the team objective. We propose two distributed algorithms where each agent maintains and updates two sets of beliefs, namely local and actual beliefs. In both algorithms, at every time step, each agent shares its actual belief with other agents within its communication range, makes a local observation, and updates its local belief as a function of its local observation and local belief. Then both algorithms can use the shared information to update actual beliefs under certain conditions. One requires receiving a certain number of shared beliefs at each time instant; the other accumulates shared beliefs over time and updates after the number of shared beliefs exceeds a prescribed threshold. Otherwise, both algorithms rely on the agent's current local belief and actual beliefs to update the new actual belief. We prove under mild assumptions that the actual belief for every non-compromised agent converges almost surely to the true hypothesis. We guarantee this convergence without requiring that the underlying time-varying network topology is connected. We illustrate and compare the proposed algorithms with a simulation of a team of unmanned aerial vehicles aiming to classify adversarial agents among themselves.      
### 57.To Achieve Security and High Spectrum Efficiency: A New Transmission System Based on Faster-than-Nyquist and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.00162.pdf)
>  With the rapid development of various services in wireless communications, spectrum resource has become increasingly valuable. Faster-than-Nyquist (FTN) signaling, which was proposed in the 1970s, has been a promising paradigm to improve the spectrum utilization. In this paper, we try to apply FTN into secure communications and propose a secure and high-spectrum-efficiency transmission system based on FTN and deep learning (DL). In the proposed system, the hopping symbol packing ratio with random values makes it difficult for the eavesdropper to obtain the accurate symbol rate and inter-symbol interference (ISI). While the receiver can use the blind estimation to choose the true parameters with the aid of DL. The results show that without the accurate symbol packing ratio, the eavesdropper will suffer from severe performance degradation. As a result, the system can achieve a secure transmission with a higher spectrum efficiency. Also, we propose a simplified symbol packing ratio estimation which has bee employed in our proposed system. Results show that the proposed simplified estimation achieves nearly the same performance as the original structure while its complexity has been greatly reduced.      
### 58.Diabetic Retinopathy Diagnosis based on Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.00148.pdf)
>  Diabetic Retinopathy DR is a popular disease for many people as a result of age or the diabetic, as a result, it can cause blindness. therefore, diagnosis of this disease especially in the early time can prevent its effect for a lot of patients. To achieve this diagnosis, eye retina must be examined continuously. Therefore, computer-aided tools can be used in the field based on computer vision techniques. Different works have been performed using various machine learning techniques. Convolutional Neural Network is one of the promise methods, so it was for Diabetic Retinopathy detection in this paper. Also, the proposed work contains visual enhancement in the pre-processing phase, then the CNN model is trained to be able for recognition and classification phase, to diagnosis the healthy and unhealthy retina image. Three public dataset DiaretDB0, DiaretDB1 and DrimDB were used in practical testing. The implementation of this work based on Matlab- R2019a, deep learning toolbox and deep network designer to design the architecture of the convolutional neural network and train it. The results were evaluated to different metrics; accuracy is one of them. The best accuracy that was achieved: for DiaretDB0 is 100%, DiaretDB1 is 99.495% and DrimDB is 97.55%.      
### 59.Neural text-to-speech with a modeling-by-generation excitation vocoder  [ :arrow_down: ](https://arxiv.org/pdf/2008.00132.pdf)
>  This paper proposes a modeling-by-generation (MbG) excitation vocoder for a neural text-to-speech (TTS) system. Recently proposed neural excitation vocoders can realize qualified waveform generation by combining a vocal tract filter with a WaveNet-based glottal excitation generator. However, when these vocoders are used in a TTS system, the quality of synthesized speech is often degraded owing to a mismatch between training and synthesis steps. Specifically, the vocoder is separately trained from an acoustic model front-end. Therefore, estimation errors of the acoustic model are inevitably boosted throughout the synthesis process of the vocoder back-end. To address this problem, we propose to incorporate an MbG structure into the vocoder's training process. In the proposed method, the excitation signal is extracted by the acoustic model's generated spectral parameters, and the neural vocoder is then optimized not only to learn the target excitation's distribution but also to compensate for the estimation errors occurring from the acoustic model. Furthermore, as the generated spectral parameters are shared in the training and synthesis steps, their mismatch conditions can be reduced effectively. The experimental results verify that the proposed system provides high-quality synthetic speech by achieving a mean opinion score of 4.57 within the TTS framework.      
### 60.CorrSigNet: Learning CORRelated Prostate Cancer SIGnatures from Radiology and Pathology Images for Improved Computer Aided Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2008.00119.pdf)
>  Magnetic Resonance Imaging (MRI) is widely used for screening and staging prostate cancer. However, many prostate cancers have subtle features which are not easily identifiable on MRI, resulting in missed diagnoses and alarming variability in radiologist interpretation. Machine learning models have been developed in an effort to improve cancer identification, but current models localize cancer using MRI-derived features, while failing to consider the disease pathology characteristics observed on resected tissue. In this paper, we propose CorrSigNet, an automated two-step model that localizes prostate cancer on MRI by capturing the pathology features of cancer. First, the model learns MRI signatures of cancer that are correlated with corresponding histopathology features using Common Representation Learning. Second, the model uses the learned correlated MRI features to train a Convolutional Neural Network to localize prostate cancer. The histopathology images are used only in the first step to learn the correlated features. Once learned, these correlated features can be extracted from MRI of new patients (without histopathology or surgery) to localize cancer. We trained and validated our framework on a unique dataset of 75 patients with 806 slices who underwent MRI followed by prostatectomy surgery. We tested our method on an independent test set of 20 prostatectomy patients (139 slices, 24 cancerous lesions, 1.12M pixels) and achieved a per-pixel sensitivity of 0.81, specificity of 0.71, AUC of 0.86 and a per-lesion AUC of $0.96 \pm 0.07$, outperforming the current state-of-the-art accuracy in predicting prostate cancer using MRI.      
### 61.Relational Teacher Student Learning with Neural Label Embedding for Device Adaptation in Acoustic Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2008.00110.pdf)
>  In this paper, we propose a domain adaptation framework to address the device mismatch issue in acoustic scene classification leveraging upon neural label embedding (NLE) and relational teacher student learning (RTSL). Taking into account the structural relationships between acoustic scene classes, our proposed framework captures such relationships which are intrinsically device-independent. In the training stage, transferable knowledge is condensed in NLE from the source domain. Next in the adaptation stage, a novel RTSL strategy is adopted to learn adapted target models without using paired source-target data often required in conventional teacher student learning. The proposed framework is evaluated on the DCASE 2018 Task1b data set. Experimental results based on AlexNet-L deep classification models confirm the effectiveness of our proposed approach for mismatch situations. NLE-alone adaptation compares favourably with the conventional device adaptation and teacher student based adaptation techniques. NLE with RTSL further improves the classification accuracy.      
### 62.An Acoustic Segment Model Based Segment Unit Selection Approach to Acoustic Scene Classification with Partial Utterances  [ :arrow_down: ](https://arxiv.org/pdf/2008.00107.pdf)
>  In this paper, we propose a sub-utterance unit selection framework to remove acoustic segments in audio recordings that carry little information for acoustic scene classification (ASC). Our approach is built upon a universal set of acoustic segment units covering the overall acoustic scene space. First, those units are modeled with acoustic segment models (ASMs) used to tokenize acoustic scene utterances into sequences of acoustic segment units. Next, paralleling the idea of stop words in information retrieval, stop ASMs are automatically detected. Finally, acoustic segments associated with the stop ASMs are blocked, because of their low indexing power in retrieval of most acoustic scenes. In contrast to building scene models with whole utterances, the ASM-removed sub-utterances, i.e., acoustic utterances without stop acoustic segments, are then used as inputs to the AlexNet-L back-end for final classification. On the DCASE 2018 dataset, scene classification accuracy increases from 68%, with whole utterances, to 72.1%, with segment selection. This represents a competitive accuracy without any data augmentation, and/or ensemble strategy. Moreover, our approach compares favourably to AlexNet-L with attention.      
### 63.Back-propagation through Signal Temporal Logic Specifications: Infusing Logical Structure into Gradient-Based Methods  [ :arrow_down: ](https://arxiv.org/pdf/2008.00097.pdf)
>  This paper presents a technique, named STLCG, to compute the quantitative semantics of Signal Temporal Logic (STL) formulas using computation graphs. STLCG provides a platform which enables the incorporation of logical specifications into robotics problems that benefit from gradient-based solutions. Specifically, STL is a powerful and expressive formal language that can specify spatial and temporal properties of signals generated by both continuous and hybrid systems. The quantitative semantics of STL provide a robustness metric, i.e., how much a signal satisfies or violates an STL specification. In this work, we devise a systematic methodology for translating STL robustness formulas into computation graphs. With this representation, and by leveraging off-the-shelf automatic differentiation tools, we are able to back-propagate through STL robustness formulas and hence enable a natural and easy-to-use integration with many gradient-based approaches used in robotics. We demonstrate, through examples stemming from various robotics applications, that STLCG is versatile, computationally efficient, and capable of injecting human-domain knowledge into the problem formulation.      
### 64.No-Reference Video Quality Assessment Using Space-Time Chips  [ :arrow_down: ](https://arxiv.org/pdf/2008.00031.pdf)
>  We propose a new model for no-reference video quality assessment (VQA) based on the natural statistics of space-time chips of videos. Space-time chips (ST-chips) are a new, quality-aware feature space which we define as space-time localized cuts of video data in directions that are determined by the local motion flow. We use parametrized statistical fits to the statistics of space-time chips to characterize quality, and show that the parameters from these models are affected by distortion and can hence be used to objectively predict the quality of videos. The proposed method, which we tentatively call ChipQA, is agnostic to the types of distortion affecting the video, and is based on identifying and quantifying deviations from the expected statistics of natural, undistorted ST-chips in order to predict video quality. We train and test our resulting model on several large VQA databases and show that our model achieves high correlation against human judgments of video quality and is competitive with state-of-the-art models.      
### 65.Chance Constrained Policy Optimization for Process Control and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2008.00030.pdf)
>  Chemical process optimization and control are affected by 1) plant-model mismatch, 2) process disturbances, and 3) constraints for safe operation. Reinforcement learning by policy optimization would be a natural way to solve this due to its ability to address stochasticity, plant-model mismatch, and directly account for the effect of future uncertainty and its feedback in a proper closed-loop manner; all without the need of an inner optimization loop. One of the main reasons why reinforcement learning has not been considered for industrial processes (or almost any engineering application) is that it lacks a framework to deal with safety critical constraints. Present algorithms for policy optimization use difficult-to-tune penalty parameters, fail to reliably satisfy state constraints or present guarantees only in expectation. We propose a chance constrained policy optimization (CCPO) algorithm which guarantees the satisfaction of joint chance constraints with a high probability - which is crucial for safety critical tasks. This is achieved by the introduction of constraint tightening (backoffs), which are computed simultaneously with the feedback policy. Backoffs are adjusted with Bayesian optimization using the empirical cumulative distribution function of the probabilistic constraints, and are therefore self-tuned. This results in a general methodology that can be imbued into present policy optimization algorithms to enable them to satisfy joint chance constraints with high probability. We present case studies that analyze the performance of the proposed approach.      
### 66.Convolutional Autoencoders for Lossy Light Field Compression  [ :arrow_down: ](https://arxiv.org/pdf/2008.00027.pdf)
>  Expansion and reduction of a neural network's width has well known properties in terms of the entropy of the propagating information. When carefully stacked on top of one another, an encoder network and a decoder network produce an autoencoder, often used in compression. Using this architecture, we develop an efficient method of encoding and decoding 4D Light Field data, with a substantial compression factor at a minimal loss in quality. Our best results managed to achieve a compression of 48.6x, with a PSNR of 29.46 dB and a SSIM of 0.8104. Computations of the encoder and decoder can be run in real time, with average computation times of 1.62s and 1.81s respectively, and the entire network occupies a reasonable 584MB by today's storage standards.      
### 67.Extrapolation of Bandlimited Multidimensional Signals from Continuous Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2008.00026.pdf)
>  Conventional sampling and interpolation commonly rely on discrete measurements. In this paper, we develop a theoretical framework for extrapolation of signals in higher dimensions from knowledge of the continuous waveform on bounded high-dimensional regions. In particular, we propose an iterative method to reconstruct bandlimited multidimensional signals based on truncated versions of the original signal to bounded regions---herein referred to as continuous measurements. In the proposed method, the reconstruction is performed by iterating on a convex combination of region-limiting and bandlimiting operations. We show that this iteration consists of a firmly nonexpansive operator and prove strong convergence for multidimensional bandlimited signals. In order to improve numerical stability, we introduce a regularized iteration and show its connection to Tikhonov regularization. The method is illustrated numerically for two-dimensional signals.      
### 68.Towards Leveraging End-of-Life Tools as an Asset: Value Co-Creation based on Deep Learning in the Machining Industry  [ :arrow_down: ](https://arxiv.org/pdf/2008.01053.pdf)
>  Sustainability is the key concept in the management of products that reached their end-of-life. We propose that end-of-life products have -- besides their value as recyclable assets -- additional value for producer and consumer. We argue this is especially true for the machining industry, where we illustrate an automatic characterization of worn cutting tools to foster value co-creation between tool manufacturer and tool user (customer) in the future. In the work at hand, we present a deep-learning-based computer vision system for the automatic classification of worn tools regarding flank wear and chipping. The resulting Matthews Correlation Coefficient of 0.878 and 0.644 confirms the feasibility of our system based on the VGG-16 network and Gradient Boosting. Based on these first results we derive a research agenda which addresses the need for a more holistic tool characterization by semantic segmentation and assesses the perceived business impact and usability by different user groups.      
### 69.Segmenting overlapped objects in images. A study to support the diagnosis of sickle cell disease  [ :arrow_down: ](https://arxiv.org/pdf/2008.00997.pdf)
>  Overlapped objects are found on multiple kinds of images, they are a source of problem due its partial information. Multiple types of algorithm are used to address this problem from simple and naive methods to more complex ones. In this work we propose a new method for the segmentation of overlapped object. Finally we compare the results of this algorithm with the state-of-art in two experiments: one with a new dataset, developed specially for this work, and red blood smears from sickle-cell disease patients.      
### 70.Age of Information-Reliability Trade-offs in Energy Harvesting Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.00987.pdf)
>  Age of Information (AoI) is a recently defined quantity, which measures the freshness of information in a communication scheme. In this paper, we analyze a network that consists of a sensor node, an energy source and a receiver. The energy source is broadcasting energy and the sensor is charging its battery using energy-harvesting technologies. Whenever the battery gets fully charged, the sensor measures some quantity (called its status) from an environment, and (or) transmits its status to the receiver. The full analysis of AoI of this network, in the setting when each status is sent once, is given previously. However, that approach does not present a reliability guarantee better than the success probability of one transmission. In this paper, we present a closed form expression for the AoI of a deterministic and a randomized scheme that guarantee a desired probability of successful transmission for each status, alongside with a zero-error scheme. Furthermore, we define a novel notion called AoI-reliability trade-off and present the AoI-reliability trade-offs of our schemes. Additionally, we show that numerical results match our theoretical findings.      
### 71.Predicted Composite Signed-Distance Fields for Real-Time Motion Planning in Dynamic Environments  [ :arrow_down: ](https://arxiv.org/pdf/2008.00969.pdf)
>  We present a novel framework for motion planning in dynamic environments that accounts for the predicted trajectories of moving objects in the scene. We explore the use of composite signed-distance fields in motion planning and detail how they can be used to generate signed-distance fields (SDFs) in real-time to incorporate predicted obstacle motions. We benchmark our approach of using composite SDFs against performing exact SDF calculations on the workspace occupancy grid. Our proposed technique generates predictions substantially faster and typically exhibits an 81--97% reduction in time for subsequent predictions. We integrate our framework with GPMP2 to demonstrate a full implementation of our approach in real-time, enabling a 7-DoF Panda arm to smoothly avoid a moving robot.      
### 72.SSGMT: A Secure Smart Grid Monitoring Technique  [ :arrow_down: ](https://arxiv.org/pdf/2008.00958.pdf)
>  Critical infrastructure systems like power grid require an improved critical in-formation infrastructure (CII) that can not only help in monitoring of the crit-ical entities but also take part in failure analysis and self-healing. Efficient designing of a CII is challenging as each kind of communication technology has its own advantages and disadvantages. Wired networks are highly scala-ble and secure, but they are neither cost effective nor dynamic in nature. Wireless communication technologies on the other hand are easy to deploy, low cost etc. but they are vulnerable to cyber-attacks. In order to optimize cost, power consumption, dynamic nature, accuracy and scalability a hybrid communication network is designed in this paper where a portion of the communication network is built using wireless sensor networks (WSN) and the rest is a wired network of fiber optic channels. To offer seamless opera-tion of the hybrid communication network and provide security a Secure Smart Grid Monitoring Technique (SSGMT) is also proposed. The perfor-mance of the proposed hybrid CII for the generation and transmission sys-tem of power grid coupled with the SSGMT during different cyber-attacks is tested using NS2 simulator. The simulation results show that the SSGMT for a joint power communication network of IEEE 118-Bus system performs better than the prevailing wireless CIIs like Lo-ADI and Modified AODV.      
### 73.Improving Generative Adversarial Networks with Local Coordinate Coding  [ :arrow_down: ](https://arxiv.org/pdf/2008.00942.pdf)
>  Generative adversarial networks (GANs) have shown remarkable success in generating realistic data from some predefined prior distribution (e.g., Gaussian noises). However, such prior distribution is often independent of real data and thus may lose semantic information (e.g., geometric structure or content in images) of data. In practice, the semantic information might be represented by some latent distribution learned from data. However, such latent distribution may incur difficulties in data sampling for GANs. In this paper, rather than sampling from the predefined prior distribution, we propose an LCCGAN model with local coordinate coding (LCC) to improve the performance of generating data. First, we propose an LCC sampling method in LCCGAN to sample meaningful points from the latent manifold. With the LCC sampling method, we can exploit the local information on the latent manifold and thus produce new data with promising quality. Second, we propose an improved version, namely LCCGAN++, by introducing a higher-order term in the generator approximation. This term is able to achieve better approximation and thus further improve the performance. More critically, we derive the generalization bound for both LCCGAN and LCCGAN++ and prove that a low-dimensional input is sufficient to achieve good generalization performance. Extensive experiments on four benchmark datasets demonstrate the superiority of the proposed method over existing GANs.      
### 74.Color Texture Image Retrieval Based on Copula Multivariate Modeling in the Shearlet Domain  [ :arrow_down: ](https://arxiv.org/pdf/2008.00910.pdf)
>  In this paper, a color texture image retrieval framework is proposed based on Shearlet domain modeling using Copula multivariate model. In the proposed framework, Gaussian Copula is used to model the dependencies between different sub-bands of the Non Subsample Shearlet Transform (NSST) and non-Gaussian models are used for marginal modeling of the coefficients. Six different schemes are proposed for modeling NSST coefficients based on the four types of neighboring defined; moreover, Kullback Leibler Divergence(KLD) close form is calculated in different situations for the two Gaussian Copula and non Gaussian functions in order to investigate the similarities in the proposed retrieval framework. The Jeffery divergence (JD) criterion, which is a symmetrical version of KLD, is used for investigating similarities in the proposed framework. We have implemented our experiments on four texture image retrieval benchmark datasets, the results of which show the superiority of the proposed framework over the existing state-of-the-art methods. In addition, the retrieval time of the proposed framework is also analyzed in the two steps of feature extraction and similarity matching, which also shows that the proposed framework enjoys an appropriate retrieval time.      
### 75.Tracing carbon dioxide emissions in the European electricity markets  [ :arrow_down: ](https://arxiv.org/pdf/2008.00893.pdf)
>  Consumption-based carbon emission measures aim to account for emissions associated with power transmission from distant regions, as opposed to measures which only consider local power generation. Outlining key differences between two different methodological variants of this approach, we report results on consumption-based emission intensities of power generation for European countries from 2016 to 2019. We find that in particular for well connected smaller countries, the consideration of imports has a significant impact on the attributed emissions. For these countries, implicit methodological choices in the input-output model are reflected in both hourly and average yearly emission measures.      
### 76.Defining Traffic States using Spatio-temporal Traffic Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2008.00827.pdf)
>  Intersections are one of the main sources of congestion and hence, it is important to understand traffic behavior at intersections. Particularly, in developing countries with high vehicle density, mixed traffic type, and lane-less driving behavior, it is difficult to distinguish between congested and normal traffic behavior. In this work, we propose a way to understand the traffic state of smaller spatial regions at intersections using traffic graphs. The way these traffic graphs evolve over time reveals different traffic states - a) a congestion is forming (clumping), the congestion is dispersing (unclumping), or c) the traffic is flowing normally (neutral). We train a spatio-temporal deep network to identify these changes. Also, we introduce a large dataset called EyeonTraffic (EoT) containing 3 hours of aerial videos collected at 3 busy intersections in Ahmedabad, India. Our experiments on the EoT dataset show that the traffic graphs can help in correctly identifying congestion-prone behavior in different spatial regions of an intersection.      
### 77.A Generalized SIS Epidemic Model on Temporal Networks with Asymptomatic Carriers and Comments on Decay Ratio  [ :arrow_down: ](https://arxiv.org/pdf/2008.00826.pdf)
>  We study the class of SIS epidemics on temporal networks and propose a new activity-driven and adaptive epidemic model that captures the impact of asymptomatic and infectious individuals in the network. In the proposed model, referred to as the A-SIYS epidemic, each node can be in three possible states: susceptible, infected without symptoms or asymptomatic and infected with symptoms or symptomatic. Both asymptomatic and symptomatic individuals are infectious. We show that the proposed A-SIYS epidemic captures several well-established epidemic models as special cases and obtain sufficient conditions under which the disease gets eradicated by resorting to mean-field approximations. <br>In addition, we highlight a potential inaccuracy in the derivation of the upper bound on the decay ratio in the activity-driven adaptive SIS (A-SIS) model in (Ogura et. al., 2019) and present a more general version of their result. We numerically illustrate the evolution of the fraction of infected nodes in the A-SIS epidemic model and show that the bound in (Ogura et. al., 2019) often fails to capture the behavior of the epidemic in contrast with our results.      
### 78.Rethinking Image Deraining via Rain Streaks and Vapors  [ :arrow_down: ](https://arxiv.org/pdf/2008.00823.pdf)
>  Single image deraining regards an input image as a fusion of a background image, a transmission map, rain streaks, and atmosphere light. While advanced models are proposed for image restoration (i.e., background image generation), they regard rain streaks with the same properties as background rather than transmission medium. As vapors (i.e., rain streaks accumulation or fog-like rain) are conveyed in the transmission map to model the veiling effect, the fusion of rain streaks and vapors do not naturally reflect the rain image formation. In this work, we reformulate rain streaks as transmission medium together with vapors to model rain imaging. We propose an encoder-decoder CNN named as SNet to learn the transmission map of rain streaks. As rain streaks appear with various shapes and directions, we use ShuffleNet units within SNet to capture their anisotropic representations. As vapors are brought by rain streaks, we propose a VNet containing spatial pyramid pooling (SSP) to predict the transmission map of vapors in multi-scales based on that of rain streaks. Meanwhile, we use an encoder CNN named ANet to estimate atmosphere light. The SNet, VNet, and ANet are jointly trained to predict transmission maps and atmosphere light for rain image restoration. Extensive experiments on the benchmark datasets demonstrate the effectiveness of the proposed visual model to predict rain streaks and vapors. The proposed deraining method performs favorably against state-of-the-art deraining approaches.      
### 79.Generating Visually Aligned Sound from Videos  [ :arrow_down: ](https://arxiv.org/pdf/2008.00820.pdf)
>  We focus on the task of generating sound from natural videos, and the sound should be both temporally and content-wise aligned with visual signals. This task is extremely challenging because some sounds generated \emph{outside} a camera can not be inferred from video content. The model may be forced to learn an incorrect mapping between visual content and these irrelevant sounds. To address this challenge, we propose a framework named REGNET. In this framework, we first extract appearance and motion features from video frames to better distinguish the object that emits sound from complex background information. We then introduce an innovative audio forwarding regularizer that directly considers the real sound as input and outputs bottlenecked sound features. Using both visual and bottlenecked sound features for sound prediction during training provides stronger supervision for the sound prediction. The audio forwarding regularizer can control the irrelevant sound component and thus prevent the model from learning an incorrect mapping between video frames and sound emitted by the object that is out of the screen. During testing, the audio forwarding regularizer is removed to ensure that REGNET can produce purely aligned sound only from visual features. Extensive evaluations based on Amazon Mechanical Turk demonstrate that our method significantly improves both temporal and content-wise alignment. Remarkably, our generated sound can fool the human with a 68.12% success rate. Code and pre-trained models are publicly available at <a class="link-external link-https" href="https://github.com/PeihaoChen/regnet" rel="external noopener nofollow">this https URL</a>      
### 80.Kinematics of motion tracking using computer vision  [ :arrow_down: ](https://arxiv.org/pdf/2008.00813.pdf)
>  This paper describes the kinematics of the motion tracking of a rigid body using video recording. The novelty of the paper is on the adaptation of the methods and nomenclature used in Computer Vision to those used in Multibody System Dynamics. That way, the equations presented here can be used, for example, for inverse-dynamics multibody simulations driven by the motion tracking of selected bodies. This paper also adapts the well-known Zhang calibration method to the presented nomenclature.      
### 81.A Low-Complexity Algorithmic Framework for Large-Scale IRS-Assisted Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.00769.pdf)
>  Intelligent reflecting surfaces (IRSs) are revolutionary enablers for next-generation wireless communication networks, with the ability to customize the radio propagation environment. To fully exploit the potential of IRS-assisted wireless systems, reflective elements have to be jointly optimized with conventional communication techniques. However, the resulting optimization problems pose significant algorithmic challenges, mainly due to the large-scale non-convex constraints induced by the passive hardware implementations. In this paper, we propose a low-complexity algorithmic framework incorporating alternating optimization and gradient-based methods for large-scale IRS-assisted wireless systems. The proposed algorithm provably converges to a stationary point of the optimization problem. Extensive simulation results demonstrate that the proposed framework provides significant speedups compared with existing algorithms, while achieving a comparable or better performance.      
### 82.Tensorizing GAN with High-Order Pooling for Alzheimer's Disease Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2008.00748.pdf)
>  It is of great significance to apply deep learning for the early diagnosis of Alzheimer's Disease (AD). In this work, a novel tensorizing GAN with high-order pooling is proposed to assess Mild Cognitive Impairment (MCI) and AD. By tensorizing a three-player cooperative game based framework, the proposed model can benefit from the structural information of the brain. By incorporating the high-order pooling scheme into the classifier, the proposed model can make full use of the second-order statistics of the holistic Magnetic Resonance Imaging (MRI) images. To the best of our knowledge, the proposed Tensor-train, High-pooling and Semi-supervised learning based GAN (THS-GAN) is the first work to deal with classification on MRI images for AD diagnosis. Extensive experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset are reported to demonstrate that the proposed THS-GAN achieves superior performance compared with existing methods, and to show that both tensor-train and high-order pooling can enhance classification performance. The visualization of generated samples also shows that the proposed model can generate plausible samples for semi-supervised learning purpose.      
### 83.Heterogeneous Swarms for Maritime Dynamic Target Search and Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2008.00696.pdf)
>  Current strategies employed for maritime target search and tracking are primarily based on the use of agents following a predetermined path to perform a systematic sweep of a search area. Recently, dynamic Particle Swarm Optimization (PSO) algorithms have been used together with swarming multi-robot systems (MRS), giving search and tracking solutions the added properties of robustness, scalability, and flexibility. Swarming MRS also give the end-user the opportunity to incrementally upgrade the robotic system, inevitably leading to the use of heterogeneous swarming MRS. However, such systems have not been well studied and incorporating upgraded agents into a swarm may result in degraded mission performances. In this paper, we propose a PSO-based strategy using a topological k-nearest neighbor graph with tunable exploration and exploitation dynamics with an adaptive repulsion parameter. This strategy is implemented within a simulated swarm of 50 agents with varying proportions of fast agents tracking a target represented by a fictitious binary function. Through these simulations, we are able to demonstrate an increase in the swarm's collective response level and target tracking performance by substituting in a proportion of fast buoys.      
### 84.Deep Photo Cropper and Enhancer  [ :arrow_down: ](https://arxiv.org/pdf/2008.00634.pdf)
>  This paper introduces a new type of image enhancement problem. Compared to traditional image enhancement methods, which mostly deal with pixel-wise modifications of a given photo, our proposed task is to crop an image which is embedded within a photo and enhance the quality of the cropped image. We split our proposed approach into two deep networks: deep photo cropper and deep image enhancer. In the photo cropper network, we employ a spatial transformer to extract the embedded image. In the photo enhancer, we employ super-resolution to increase the number of pixels in the embedded image and reduce the effect of stretching and distortion of pixels. We use cosine distance loss between image features and ground truth for the cropper and the mean square loss for the enhancer. Furthermore, we propose a new dataset to train and test the proposed method. Finally, we analyze the proposed method with respect to qualitative and quantitative evaluations.      
### 85.Anchor-Assisted Intelligent Reflecting Surface Channel Estimation for Multiuser Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.00622.pdf)
>  Due to the passive nature of Intelligent Reflecting Surface (IRS), channel estimation is a fundamental challenge in IRS-aided wireless networks. Particularly, as the number of IRS reflecting elements and/or that of IRS-served users increase, the channel training overhead becomes excessively high. To tackle this challenge, we propose in this paper a new anchor-assisted two-phase channel estimation scheme, where two anchor nodes, namely A1 and A2, are deployed near the IRS for helping the base station (BS) to acquire the cascaded BS-IRS-user channels. Specifically, in the first phase, the partial channel state information (CSI), i.e., the element-wise channel gain square, of the BS-IRS link is obtained by estimating the BS-IRS-A1/A2 channels and the A1-IRS-A2 channel, separately. Then, in the second phase, by leveraging such partial knowledge of the BS-IRS channel that is common to all users, the individual cascaded BS-IRS-user channels are efficiently estimated. Simulation results demonstrate that the proposed anchor-assisted channel estimation scheme is able to achieve comparable mean-squared error (MSE) performance as compared to the conventional scheme, but with significantly reduced channel training time.      
### 86.audioLIME: Listenable Explanations Using Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00582.pdf)
>  Deep neural networks (DNNs) are successfully applied in a wide variety of music information retrieval (MIR) tasks but their predictions are usually not interpretable. We propose audioLIME, a method based on Local Interpretable Model-agnostic Explanations (LIME) extended by a musical definition of locality. The perturbations used in LIME are created by switching on/off components extracted by source separation which makes our explanations listenable. We validate audioLIME on two different music tagging systems and show that it produces sensible explanations in situations where a competing method cannot.      
### 87.IoT System for Real-Time Near-Crash Detection for Automated Vehicle Testing  [ :arrow_down: ](https://arxiv.org/pdf/2008.00549.pdf)
>  Our world is moving towards the goal of fully autonomous driving at a fast pace. While the latest automated vehicles (AVs) can handle most real-world scenarios they encounter, a major bottleneck for turning fully autonomous driving into reality is the lack of sufficient corner case data for training and testing AVs. Near-crash data, as a widely used surrogate data for traffic safety research, can also serve the purpose of AV testing if properly collected. To this end, this paper proposes an Internet-of-Things (IoT) system for real-time near-crash data collection. The system has several cool features. First, it is a low-cost and standalone system that is backward-compatible with any existing vehicles. People can fix the system to their dashboards for near-crash data collection and collision warning without the approval or help of vehicle manufacturers. Second, we propose a new near-crash detection method that models the target's size changes and relative motions with the bounding boxes generated by deep-learning-based object detection and tracking. This near-crash detection method is fast, accurate, and reliable; particularly, it is insensitive to camera parameters, thereby having an excellent transferability to different dashboard cameras. We have conducted comprehensive experiments with 100 videos locally processed at Jetson, as well as real-world tests on cars and buses. Besides collecting corner cases, it can also serve as a white-box platform for testing innovative algorithms and evaluating other AV products. The system contributes to the real-world testing of AVs and has great potential to be brought into large-scale deployment.      
### 88.On the Security of Networked Control Systems in Smart Vehicle and its Adaptive Cruise Control  [ :arrow_down: ](https://arxiv.org/pdf/2008.00414.pdf)
>  With the benefits of Internet of Vehicles (IoV) paradigm, come along unprecedented security challenges. Among many applications of inter-connected systems, vehicular networks and smart cars are examples that are already rolled out. Smart vehicles not only have networks connecting their internal components e.g. via Controller Area Network (CAN) bus, but also are connected to the outside world through road side units and other vehicles. In some cases, the internal and external network packets pass through the same hardware and are merely isolated by software defined rules. Any misconfiguration opens a window for the hackers to intrude into vehicles' internal components e.g. central lock system, Engine Control Unit (ECU), Anti-lock Braking System (ABS) or Adaptive Cruise Control (ACC) system. Compromise of any of these can lead to disastrous outcomes. In this paper, we study the security of smart vehicles' adaptive cruise control systems in the presence of covert attacks. We define two covert/stealth attacks in the context of cruise control and propose a novel intrusion detection and compensation method to disclose and respond to such attacks. More precisely, we focus on the covert cyber attacks that compromise the integrity of cruise controller and employ a neural network identifier in the IDS engine to estimate the system output dynamically and compare it against the ACC output. If any anomaly is detected, an embedded substitute controller kicks in and takes over the control. We conducted extensive experiments in MATLAB to evaluate the effectiveness of the proposed scheme in a simulated environment.      
### 89.Point Cloud Completion by Learning Shape Priors  [ :arrow_down: ](https://arxiv.org/pdf/2008.00394.pdf)
>  In view of the difficulty in reconstructing object details in point cloud completion, we propose a shape prior learning method for object completion. The shape priors include geometric information in both complete and the partial point clouds. We design a feature alignment strategy to learn the shape prior from complete points, and a coarse to fine strategy to incorporate partial prior in the fine stage. To learn the complete objects prior, we first train a point cloud auto-encoder to extract the latent embeddings from complete points. Then we learn a mapping to transfer the point features from partial points to that of the complete points by optimizing feature alignment losses. The feature alignment losses consist of a L2 distance and an adversarial loss obtained by Maximum Mean Discrepancy Generative Adversarial Network (MMD-GAN). The L2 distance optimizes the partial features towards the complete ones in the feature space, and MMD-GAN decreases the statistical distance of two point features in a Reproducing Kernel Hilbert Space. We achieve state-of-the-art performances on the point cloud completion task. Our code is available at <a class="link-external link-https" href="https://github.com/xiaogangw/point-cloud-completion-shape-prior" rel="external noopener nofollow">this https URL</a>.      
### 90.Animating Through Warping: an Efficient Method for High-Quality Facial Expression Animation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00362.pdf)
>  Advances in deep neural networks have considerably improved the art of animating a still image without operating in 3D domain. Whereas, prior arts can only animate small images (typically no larger than 512x512) due to memory limitations, difficulty of training and lack of high-resolution (HD) training datasets, which significantly reduce their potential for applications in movie production and interactive systems. Motivated by the idea that HD images can be generated by adding high-frequency residuals to low-resolution results produced by a neural network, we propose a novel framework known as Animating Through Warping (ATW) to enable efficient animation of HD images. <br>Specifically, the proposed framework consists of two modules, a novel two-stage neural-network generator and a novel post-processing module known as Animating Through Warping (ATW). It only requires the generator to be trained on small images and can do inference on an image of any size. During inference, an HD input image is decomposed into a low-resolution component(128x128) and its corresponding high-frequency residuals. The generator predicts the low-resolution result as well as the motion field that warps the input face to the desired status (e.g., expressions categories or action units). Finally, the ResWarp module warps the residuals based on the motion field and adding the warped residuals to generates the final HD results from the naively up-sampled low-resolution results. Experiments show the effectiveness and efficiency of our method in generating high-resolution animations. Our proposed framework successfully animates a 4K facial image, which has never been achieved by prior neural models. In addition, our method generally guarantee the temporal coherency of the generated animations. Source codes will be made publicly available.      
### 91.V2I Connectivity-Based Dynamic Queue-Jump Lane for Emergency Vehicles: A Deep Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.00335.pdf)
>  Emergency vehicle (EMV) service is a key function of cities and is exceedingly challenging due to urban traffic congestion. A main reason behind EMV service delay is the lack of communication and cooperation between vehicles blocking EMVs. In this paper, we study the improvement of EMV service under V2I connectivity. We consider the establishment of dynamic queue jump lanes (DQJLs) based on real-time coordination of connected vehicles. We develop a novel Markov decision process formulation for the DQJL problem, which explicitly accounts for the uncertainty of drivers' reaction to approaching EMVs. We propose a deep neural network-based reinforcement learning algorithm that efficiently computes the optimal coordination instructions. We also validate our approach on a micro-simulation testbed using Simulation of Urban Mobility (SUMO). Validation results show that with our proposed methodology, the centralized control system saves approximately 15\% EMV passing time than the benchmark system.      
### 92.Analytical Modeling and Design of Gallium Oxide Schottky Barrier Diodes Beyond Unipolar Figure of Merit Using High-k Dielectric Superjunction Structures  [ :arrow_down: ](https://arxiv.org/pdf/2008.00280.pdf)
>  This work presents the design of beta-Ga2O3 schottky barrier diode using high-k dielectric superjunction to significantly enhance the breakdown voltage vs on-resistance trade-off beyond its already high unipolar figure of merit. The device parameters are optimized using both TCAD simulations and analytical modeling using conformal mapping technique. The dielectric superjunction structure is found to be highly sensitive to the device dimensions and the dielectric constant of the insulator. The aspect ratio, which is the ratio of the length to the width of the drift region, is found to be the most important parameter in designing the structure and the proposed approach only works for aspect ratio much greater than one. The width of the dielectric layer and the dielectric constant also plays a crucial role in improving the device properties and are optimized to achieve maximum figure of merit. Using the optimized structure with an aspect ratio of 10 and a dielectric constant of 300, the structure is predicted to surpass the b-Ga2O3 unipolar figure of merit by four times indicating the promise of such structures for exceptional FOM vertical power electronics.      
### 93.Distributed Nonconvex Optimization: Oracle-free Iterations and Globally Optimal Solution  [ :arrow_down: ](https://arxiv.org/pdf/2008.00252.pdf)
>  Distributed optimization is concerned with using local computation and communication to realize a global aim of optimizing the sum of local objective functions. It has gained wide attention for a variety of applications in networked systems. This paper addresses a class of constrained distributed nonconvex optimization problems involving univariate objective functions, aiming to achieve global optimization with a simple iteration rule not requiring local oracle queries (i.e., evaluations of gradients or function values). We propose a novel algorithm named CPCA, exploiting the notion of combining Chebyshev polynomial approximation, average consensus and polynomial optimization. The proposed algorithm is i) able to yield $\epsilon$ globally optimal solutions for any arbitrarily small given tolerance $\epsilon$, ii) efficient in terms of both oracle complexities and inter-agent communication costs, and iii) distributed terminable when the specified precision requirement is met. The key insight is to use polynomial approximations to substitute for general objectives, and turn to solve an easier approximate version of the original problem. Due to the nice analytic properties owned by polynomials, this approximation not only facilitates efficient global optimization, but also allows the proposed algorithm's consensus-based iteration structure free from local oracle queries. We provide a comprehensive analysis of the accuracy and complexities of the proposed algorithm.      
### 94.Meta-DRN: Meta-Learning for 1-Shot Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00247.pdf)
>  Modern deep learning models have revolutionized the field of computer vision. But, a significant drawback of most of these models is that they require a large number of labelled examples to generalize properly. Recent developments in few-shot learning aim to alleviate this requirement. In this paper, we propose a novel lightweight CNN architecture for 1-shot image segmentation. The proposed model is created by taking inspiration from well-performing architectures for semantic segmentation and adapting it to the 1-shot domain. We train our model using 4 meta-learning algorithms that have worked well for image classification and compare the results. For the chosen dataset, our proposed model has a 70% lower parameter count than the benchmark, while having better or comparable mean IoU scores using all 4 of the meta-learning algorithms.      
### 95.An Explainable Machine Learning Model for Early Detection of Parkinson's Disease using LIME on DaTscan Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2008.00238.pdf)
>  Parkinson's disease (PD) is a degenerative and progressive neurological condition. Early diagnosis can improve treatment for patients and is performed through dopaminergic imaging techniques like the SPECT DaTscan. In this study, we propose a machine learning model that accurately classifies any given DaTscan as having Parkinson's disease or not, in addition to providing a plausible reason for the prediction. This is kind of reasoning is done through the use of visual indicators generated using Local Interpretable Model-Agnostic Explainer (LIME) methods. DaTscans were drawn from the Parkinson's Progression Markers Initiative database and trained on a CNN (VGG16) using transfer learning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a specificity of 90.9%. Keeping model interpretability of paramount importance, especially in the healthcare field, this study utilises LIME explanations to distinguish PD from non-PD, using visual superpixels on the DaTscans. It could be concluded that the proposed system, in union with its measured interpretability and accuracy may effectively aid medical workers in the early diagnosis of Parkinson's Disease.      
### 96.Efficient Adversarial Attacks for Visual Object Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2008.00217.pdf)
>  Visual object tracking is an important task that requires the tracker to find the objects quickly and accurately. The existing state-ofthe-art object trackers, i.e., Siamese based trackers, use DNNs to attain high accuracy. However, the robustness of visual tracking models is seldom explored. In this paper, we analyze the weakness of object trackers based on the Siamese network and then extend adversarial examples to visual object tracking. We present an end-to-end network FAN (Fast Attack Network) that uses a novel drift loss combined with the embedded feature loss to attack the Siamese network based trackers. Under a single GPU, FAN is efficient in the training speed and has a strong attack performance. The FAN can generate an adversarial example at 10ms, achieve effective targeted attack (at least 40% drop rate on OTB) and untargeted attack (at least 70% drop rate on OTB).      
### 97.State-of-The-Art Fuzzy Active Contour Models for Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2008.00175.pdf)
>  Image segmentation is the initial step for every image analysis task. A large variety of segmentation algorithm has been proposed in the literature during several decades with some mixed success. Among them, the fuzzy energy based active contour models get attention to the researchers during last decade which results in development of various methods. A good segmentation algorithm should perform well in a large number of images containing noise, blur, low contrast, region in-homogeneity, etc. However, the performances of the most of the existing fuzzy energy based active contour models have been evaluated typically on the limited number of images. In this article, our aim is to review the existing fuzzy active contour models from the theoretical point of view and also evaluate them experimentally on a large set of images under the various conditions. The analysis under a large variety of images provides objective insight into the strengths and weaknesses of various fuzzy active contour models. Finally, we discuss several issues and future research direction on this particular topic.      
### 98.Land Cover Classification from Remote Sensing Images Based on Multi-Scale Fully Convolutional Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.00168.pdf)
>  In this paper, a Multi-Scale Fully Convolutional Network (MSFCN) with multi-scale convolutional kernel is proposed to exploit discriminative representations from two-dimensional (2D) satellite images.      
### 99.Cyber-Resilient Transactive Energy System Design over Insecure Communication Links  [ :arrow_down: ](https://arxiv.org/pdf/2008.00152.pdf)
>  In this paper, the privacy and security issues associated with transactive energy systems over insecure communications are addressed. In particular, it is ensured that, during market-based interactions: (1) each agent's bidding information remains private; and (2) any extraneous data injection attack can be easily detected. A unified cryptography-based approach that can simultaneously achieve both objectives is developed, where privacy preservation is realized by the Paillier encryption scheme, and attack detection is achieved by the Paillier digital signature scheme. Simulation results verify the effectiveness of the proposed cyber-resilient design for transactive energy systems.      
### 100.Intelligent Management of Mobile Systems through Computational Self-Awareness  [ :arrow_down: ](https://arxiv.org/pdf/2008.00095.pdf)
>  Runtime resource management for many-core systems is increasingly complex. The complexity can be due to diverse workload characteristics with conflicting demands, or limited shared resources such as memory bandwidth and power. Resource management strategies for many-core systems must distribute shared resource(s) appropriately across workloads, while coordinating the high-level system goals at runtime in a scalable and robust manner. <br>To address the complexity of dynamic resource management in many-core systems, state-of-the-art techniques that use heuristics have been proposed. These methods lack the formalism in providing robustness against unexpected runtime behavior. One of the common solutions for this problem is to deploy classical control approaches with bounds and formal guarantees. Traditional control theoretic methods lack the ability to adapt to (1) changing goals at runtime (i.e., self-adaptivity), and (2) changing dynamics of the modeled system (i.e., self-optimization). <br>In this chapter, we explore adaptive resource management techniques that provide self-optimization and self-adaptivity by employing principles of computational self-awareness, specifically reflection. By supporting these self-awareness properties, the system can reason about the actions it takes by considering the significance of competing objectives, user requirements, and operating conditions while executing unpredictable workloads.      
### 101.Survey of Spectrum Regulation for Intelligent Transportation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.00084.pdf)
>  As 5G communication technology develops, vehicular communications that require high reliability, low latency, and massive connectivity are drawing increasing interest from those in academia and industry. Due to these developing technologies, vehicular communication is not limited to vehicle components in the forms of Vehicle-to-Vehicle (V2V) or Vehicle-to-Infrastructure (V2I) networks, but has also been extended to connect with others, such as pedestrians and cellular users. Dedicated Short-Range Communications (DSRC) is the conventional vehicular communication standard for Intelligent Transportation Systems (ITS). More recently, the 3rd Generation Partnership Project introduced Cellular-Vehicle-to-Everything (C-V2X), a competitor to DSRC. Meanwhile, the Federal Communications Commission (FCC)issued a Notice of Proposed Rulemaking (NPRM) to consider deploying Unlicensed National Information Infrastructure (U-NII)devices in the ITS band with two interference mitigation approaches: Detect-and-Vacate (DAV)and Re-channelization (Re-CH). With multiple standard options and interference mitigation approaches, numerous regulatory taxonomies can be identified and notification of relevant technical challenges issued. However, these challenges are much broader than the current and future regulatory taxonomies pursued by the different countries involved. Because their plans differ, the technical and regulatory challenges vary. This paper presents a literature survey about the technical challenges, the current and future ITS band usage plans, and the major research testbeds for the U.S., Europe, China, Korea, and Japan. This survey shows that the most likely deployment taxonomies are (1) DSRC, C-V2X, and Wi-Fi with Re-CH; (2) DSRC and C-V2X with interoperation, and (3) C-V2X only. The most difficult technical challenge is the interoperability between the Wi-Fi-like DSRC and 4G LTE-like C-V2X.      
### 102.Dynamic Object Tracking and Masking for Visual SLAM  [ :arrow_down: ](https://arxiv.org/pdf/2008.00072.pdf)
>  In dynamic environments, performance of visual SLAM techniques can be impaired by visual features taken from moving objects. One solution is to identify those objects so that their visual features can be removed for localization and mapping. This paper presents a simple and fast pipeline that uses deep neural networks, extended Kalman filters and visual SLAM to improve both localization and mapping in dynamic environments (around 14 fps on a GTX 1080). Results on the dynamic sequences from the TUM dataset using RTAB-Map as visual SLAM suggest that the approach achieves similar localization performance compared to other state-of-the-art methods, while also providing the position of the tracked dynamic objects, a 3D map free of those dynamic objects, better loop closure detection with the whole pipeline able to run on a robot moving at moderate speed.      
### 103.Infusing Reachability-Based Safety into Planning and Control for Multi-agent Interactions  [ :arrow_down: ](https://arxiv.org/pdf/2008.00067.pdf)
>  Within a robot autonomy stack, the planner and controller are typically designed separately, and serve different purposes. As such, there is often a diffusion of responsibilities when it comes to ensuring safety for the robot. We propose that a planner and controller should share the same interpretation of safety but apply this knowledge in a different yet complementary way. To achieve this, we use Hamilton-Jacobi (HJ) reachability theory at the planning level to provide the robot planner with the foresight to avoid entering regions with possible inevitable collision. However, this alone does not guarantee safety. In conjunction with this HJ reachability-infused planner, we propose a minimally-interventional multi-agent safety-preserving controller also derived via HJ-reachability theory. The safety controller maintains safety for the robot without unduly impacting planner performance. We demonstrate the benefits of our proposed approach in a multi-agent highway scenario where a robot car is rewarded to navigate through traffic as fast as possible, and we show that our approach provides strong safety assurances yet achieves the highest performance compared to other safety controllers.      
### 104.Eminence Grise Coalitions: On the Shaping of Public Opinion  [ :arrow_down: ](https://arxiv.org/pdf/1409.7091.pdf)
>  We consider a network of evolving opinions. It includes multiple individuals with first-order opinion dynamics defined in continuous time and evolving based on a general exogenously defined time-varying underlying graph. In such a network, for an arbitrary fixed initial time, a subset of individuals forms an eminence grise coalition, abbreviated as EGC, if the individuals in that subset are capable of leading the entire network to agreeing on any desired opinion, through a cooperative choice of their own initial opinions. In this endeavor, the coalition members are assumed to have access to full profile of the underlying graph of the network as well as the initial opinions of all other individuals. While the complete coalition of individuals always qualifies as an EGC, we establish the existence of a minimum size EGC for an arbitrary time-varying network; also, we develop a non-trivial set of upper and lower bounds on that size. As a result, we show that, even when the underlying graph does not guarantee convergence to a global or multiple consensus, a generally restricted coalition of agents can steer public opinion towards a desired global consensus without affecting any of the predefined graph interactions, provided they can cooperatively adjust their own initial opinions. Geometric insights into the structure of EGC's are given. The results are also extended to the discrete time case where the relation with Decomposition-Separation Theorem is also made explicit.      
### 105.Consensus Algorithms and the Decomposition-Separation Theorem  [ :arrow_down: ](https://arxiv.org/pdf/1303.6674.pdf)
>  Convergence properties of time inhomogeneous Markov chain based discrete and continuous time linear consensus algorithms are analyzed. Provided that a so-called infinite jet flow property is satisfied by the underlying chains, necessary conditions for both consensus and multiple consensus are established. A recenet extension by Sonin of the classical Kolmogorov-Doeblin decomposition-separation for homogeneous Markov chains to the inhomogeneous case is then employed to show that the obtained necessary conditions are also sufficient when the chain is of Class P*, as defined by Touri and Nedic. It is also shown that Sonin's theorem leads to a rediscovery and generalization of most of the existing related consensus results in the literature.      
### 106.Theorems about Ergodicity and Class-Ergodicity of Chains with Applications in Known Consensus Models  [ :arrow_down: ](https://arxiv.org/pdf/1204.6624.pdf)
>  In a multi-agent system, unconditional (multiple) consensus is the property of reaching to (multiple) consensus irrespective of the instant and values at which states are initialized. For linear algorithms, occurrence of unconditional (multiple) consensus turns out to be equivalent to (class-) ergodicity of the transition chain (A_n). For a wide class of chains, chains with so-called balanced asymmetry property, necessary and sufficient conditions for ergodicity and class-ergodicity are derived. The results are employed to analyze the limiting behavior of agents' states in the JLM model, the Krause model, and the Cucker-Smale model. In particular, unconditional single or multiple consensus occurs in all three models. Moreover, a necessary and sufficient condition for unconditional consensus in the JLM model and a sufficient condition for consensus in the Cucker-Smale model are obtained.      
### 107.Linear Consensus Algorithms Based on Balanced Asymmetric Chains  [ :arrow_down: ](https://arxiv.org/pdf/1204.6093.pdf)
>  Multi agent consensus algorithms with update steps based on so-called balanced asymmetric chains, are analyzed. For such algorithms it is shown that (i) the set of accumulation points of states is finite, (ii) the asymptotic unconditional occurrence of single consensus or multiple consensuses is directly related to the property of absolute infinite flow for the underlying update chain. The results are applied to well known consensus models.      
