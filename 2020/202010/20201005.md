# ArXiv eess --Mon, 5 Oct 2020
### 1.Convergence Certificate for Stochastic Derivative-Free Trust-Region Methods based on Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2010.01120.pdf)
>  In many machine learning applications, one wants to learn the unknown objective and constraint functions of an optimization problem from available data and then apply some technique to attain a local optimizer of the learned model. This work considers Gaussian processes as global surrogate models and utilizes them in conjunction with derivative-free trust-region methods. It is well known that derivative-free trust-region methods converge globally---provided the surrogate model is probabilistically fully linear. We prove that \glspl{gp} are indeed probabilistically fully linear, thus resulting in fast (compared to linear or quadratic local surrogate models) and global convergence. We draw upon the optimization of a chemical reactor to demonstrate the efficiency of \gls{gp}-based trust-region methods.      
### 2.Polyphonic Piano Transcription Using Autoregressive Multi-State Note Model  [ :arrow_down: ](https://arxiv.org/pdf/2010.01104.pdf)
>  Recent advances in polyphonic piano transcription have been made primarily by a deliberate design of neural network architectures that detect different note states such as onset or sustain and model the temporal evolution of the states. The majority of them, however, use separate neural networks for each note state, thereby optimizing multiple loss functions, and also they handle the temporal evolution of note states by abstract connections between the state-wise neural networks or using a post-processing module. In this paper, we propose a unified neural network architecture where multiple note states are predicted as a softmax output with a single loss function and the temporal order is learned by an auto-regressive connection within the single neural network. This compact model allows to increase note states without architectural complexity. Using the MAESTRO dataset, we examine various combinations of multiple note states including on, onset, sustain, re-onset, offset, and off. We also show that the autoregressive module effectively learns inter-state dependency of notes. Finally, we show that our proposed model achieves performance comparable to state-of-the-arts with fewer parameters.      
### 3.DC power grids with constant-power loads -- Part I: A full characterization of power flow feasibility, long-term voltage stability and their correspondence  [ :arrow_down: ](https://arxiv.org/pdf/2010.01076.pdf)
>  In this two-part paper we study the feasibility of the power flow equations of DC power grids with constant power loads. In Part I of this paper we present a rigorous introduction into the problem of power flow feasibility of such power grids, and the problem of selecting a desirable operating point which satisfies the power flow equations. Our main contributions are as follows. We introduce and identify all long-term voltage semi-stable operating points, and show that there exists a one-to-one correspondence between such operating points and the power demands for which the power flow equations are feasible. The unique long-term voltage stable operating point associated to a feasible power demand can be found by solving an initial value problem. In addition, we characterize all feasible power demands as the intersection of closed half-spaces, and give a novel proof for the convexity of the set of feasible power demands. Moreover, we recover a known necessary LMI condition for the feasibility of a vector of power demands and prove that it is also sufficient. We present a similar necessary and sufficient condition for feasibility under small perturbation. <br>Part II of this paper further explores the implications to these results. In particular, we prove that the feasible power demands and high-voltage operating points are in one-to-one correspondence as well, and that the high-voltage operating points and long-term voltage stable operating points coincide. In addition, we show how existing sufficient conditions for the feasibility of the AC power flow equations with constant-power loads can be improved in the DC case.      
### 4.Efficient Image Super-Resolution Using Pixel Attention  [ :arrow_down: ](https://arxiv.org/pdf/2010.01073.pdf)
>  This work aims at designing a lightweight convolutional neural network for image super resolution (SR). With simplicity bare in mind, we construct a pretty concise and effective network with a newly proposed pixel attention scheme. Pixel attention (PA) is similar as channel attention and spatial attention in formulation. The difference is that PA produces 3D attention maps instead of a 1D attention vector or a 2D map. This attention scheme introduces fewer additional parameters but generates better SR results. On the basis of PA, we propose two building blocks for the main branch and the reconstruction branch, respectively. The first one - SC-PA block has the same structure as the Self-Calibrated convolution but with our PA layer. This block is much more efficient than conventional residual/dense blocks, for its twobranch architecture and attention scheme. While the second one - UPA block combines the nearest-neighbor upsampling, convolution and PA layers. It improves the final reconstruction quality with little parameter cost. Our final model- PAN could achieve similar performance as the lightweight networks - SRResNet and CARN, but with only 272K parameters (17.92% of SRResNet and 17.09% of CARN). The effectiveness of each proposed component is also validated by ablation study. The code is available at <a class="link-external link-https" href="https://github.com/zhaohengyuan1/PAN" rel="external noopener nofollow">this https URL</a>.      
### 5.Improving the Fidelity of Mixed-Monotone Reachable Set Approximations via State Transformations  [ :arrow_down: ](https://arxiv.org/pdf/2010.01065.pdf)
>  Mixed-monotone systems are separable via a decomposition function into increasing and decreasing components, and this decomposition function allows for embedding the system dynamics in a higher-order monotone embedding system. Embedding the system dynamics in this way facilitates the efficient over-approximation of reachable sets with hyperrectangles, however, unlike the monotonicity property, which can be applied to compute, e.g., the tightest hyperrectangle containing a reachable set, the application of the mixed-monotonicity property generally results in conservative reachable set approximations. In this work, explore conservatism in the method and we consider, in particular, embedding systems that are monotone with respect to an alternative partial order. This alternate embedding system is constructed with a decomposition function for a related system, formed via a linear transformation of the initial state-space. We show how these alternate embedding systems allow for computing reachable sets with improved fidelity, i.e., reduced conservatism.      
### 6.A 5G-NR Satellite Extension for the QuaDRiGa Channel Model  [ :arrow_down: ](https://arxiv.org/pdf/2010.01002.pdf)
>  Low Earth orbit (LEO) satellite networks will become an integral part of the global telecommunication infrastructure. Modeling the radio-links of these networks and their interaction with existing terrestrial systems is crucial for the design, planning and scaling of these networks. The 3rd generation partnership project (3GPP) addressed this by providing guideline for such a radio-channel model. However, the proposed model lacks a satellite orbit model and has some inconsistencies in the provided parameters. This is addressed in this paper. We provide a non-geostationary-satellite model that can be integrated into geometry-based stochastic channel models (GSCMs) such as QuaDRiGa. We then use this model to obtain the GSCM parameters from a simplified environment model and compare the results to the 3GPP parameter-set. This solves the inconsistencies, but our simplified approach does not consider many propagation effects. Future work must therefore rely on measurements or accurate Ray-tracing models to obtain the parameters.      
### 7.Quantitative assessment of linear noise-reduction filters for spectroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2010.00987.pdf)
>  Linear noise-reduction filters used in spectroscopy must strike a balance between reducing noise and preserving lineshapes, the two conflicting requirements of interest.      
### 8.Computation of invariant sets via immersion for discrete-time nonlinear systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.00974.pdf)
>  In this paper, we propose a method for computing invariant sets of discrete-time nonlinear systems with or without additive disturbances by lifting the nonlinear dynamics into a higher dimensional linear model. In particular, we focus on the maximal invariant set contained in some given constraint set. Some special types of nonlinear systems can be immersed into higher dimensional linear systems with state transformations, which allows us to establish linear representations of nonlinear systems. For such systems, we can characterize invariant sets of the original nonlinear system using its higher dimensional linear representation. For general nonlinear systems, in which equivalent linear models cannot be achieved exactly, we use high-dimensional linear approximations to compute the maximal invariant set. Given the bound on the mismatch between the linear approximation and the original system, we provide an invariant inner approximation of the maximal invariant set by tightening the constraint set.      
### 9.6G Cellular Networks and Connected Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2010.00972.pdf)
>  With 5G mobile communication systems been commercially rolled out, research discussions on next generation mobile systems, i.e., 6G, have started. On the other hand, vehicular technologies are also evolving rapidly, from connected vehicles as coined by V2X (vehicle to everything) to autonomous vehicles to the combination of the two, i.e., the networks of connected autonomous vehicles (CAV). How fast the evolution of these two areas will go head-in-head is of great importance, which is the focus of this paper. Based on a brief overview on the technological evolution of V2X to CAV and 6G key technologies, this paper explores two complementary research directions, namely, 6G for CAVs versus CAVs for 6G. The former investigates how various 6G key enablers, such as THz, cell free communication and artificial intelligence (AI), can be utilized to provide CAV mission-critical services. The latter discusses how CAVs can facilitate effective deployment and operation of 6G systems. This paper attempts to investigate the interactions between the two technologies to spark more research efforts in these areas.      
### 10.Deep Learning Based Computer-Aided Systems for Breast Cancer Imaging : A Critical Review  [ :arrow_down: ](https://arxiv.org/pdf/2010.00961.pdf)
>  This paper provides a critical review of the literature on deep learning applications in breast tumor diagnosis using ultrasound and mammography images. It also summarizes recent advances in computer-aided diagnosis (CAD) systems, which make use of new deep learning methods to automatically recognize images and improve the accuracy of diagnosis made by radiologists. This review is based upon published literature in the past decade (January 2010 January 2020). The main findings in the classification process reveal that new DL-CAD methods are useful and effective screening tools for breast cancer, thus reducing the need for manual feature extraction. The breast tumor research community can utilize this survey as a basis for their current and future studies.      
### 11.Detection of COVID-19 from Chest Computed Tomography (CT) images using Deep learning: Comparing COGNEX VisionPro Deep Learning 1.0 Software with Open Source Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.00958.pdf)
>  For testing patients infected with COVID-19, along with RT-PCR testing, chest radiology images are being used. For the detection of COVID-19 from radiology images, many organizations are proposing the use of Deep Learning. University of Waterloo and DarwinAI, have designed their own Deep Learning model COVIDNet-CT to detect COVID-19 from infected chest CT images. Additionally, they have introduced a CT image dataset COVIDx-CT, from CT images collected by the China National Center for Bioinformation. COVIDx-CT contains 104,009 CT image slices across 1,489 patient cases. After obtaining remarkable results on the detection of COVID-19 from chest X-ray images by using the COGNEX VisionPro Deep Learning Software 1.0 this time we test the performance of the software on the detection of COVID-19 from CT images. COGNEX Deep Learning Software: VisionPro Deep Learning, is a Deep Learning software that is used across various domains ranging from factory automation to life sciences. In this study, we train the classification model on 82,818 chest CT training and validation images from the COVIDx-CT dataset in 3 classes - normal, pneumonia, and COVID-19 and then test the results of the classification on the 21,191 test images are compared with the results of COVIDNet-CT and various other state of the art Deep Learning models from the open-source community. Also, we test how reducing the number of images in the training set effects the results of the software. Overall, VisionPro Deep Learning gives the best results with F-scores over 99%, even as the number of images in the training set is reduced significantly. This software is by no means a stand-alone solution in the detection of COVID-19 but can aid radiologists and clinicians in achieving faster and understandable diagnosis using the full potential of Deep Learning, without the prerequisite of having to code in any programming language.      
### 12."5G Densification Increases Human Exposure to Radio-Frequency Pollution": True or False?  [ :arrow_down: ](https://arxiv.org/pdf/2010.00933.pdf)
>  A very popular theory circulating among non-scientific communities claims that the massive deployment of 5G base stations over the territory, a.k.a. 5G densification, always triggers an uncontrolled and exponential increase of human exposure to Radio Frequency "Pollution" (RFP). To face such concern in a way that can be understood by the layman, in this work we develop a very simple model to compute the RFP, based on a set of worst-case and conservative assumptions. We then provide closed-form expressions to evaluate the RFP variation in a pair of candidate 5G deployments, subject to different densification levels. Results, obtained over a wide set of representative 5G scenarios, dispel the myth: 5G densification triggers an RFP decrease when the radiated power from the 5G base stations is adjusted to ensure a minimum sensitivity at the cell edge. Eventually, we analyze the conditions under which the RFP may increase when the network is densified (e.g., when the radiated power does not scale with the cell size), proving that the amount of RFP is always controlled. Finally, the results obtained by simulation confirm the outcomes of the RFP model.      
### 13.Multi-Resolution 3D Convolutional Neural Networks for Automatic Coronary Centerline Extraction in Cardiac CT Angiography Scans  [ :arrow_down: ](https://arxiv.org/pdf/2010.00925.pdf)
>  We propose a deep learning-based automatic coronary artery tree centerline tracker (AuCoTrack) extending the vessel tracker by Wolterink (<a class="link-https" data-arxiv-id="1810.03143" href="https://arxiv.org/abs/1810.03143">arXiv:1810.03143</a>). A dual pathway Convolutional Neural Network (CNN) operating on multi-scale 3D inputs predicts the direction of the coronary arteries as well as the presence of a bifurcation. A similar multi-scale dual pathway 3D CNN is trained to identify coronary artery endpoints for terminating the tracking process. Two or more continuation directions are derived based on the bifurcation detection. The iterative tracker detects the entire left and right coronary artery trees based on only two ostium landmarks derived from a model-based segmentation of the heart. <br>The 3D CNNs were trained on a proprietary dataset consisting of 43 CCTA scans. An average sensitivity of 87.1% and clinically relevant overlap of 89.1% was obtained relative to a refined manual segmentation. In addition, the MICCAI 2008 Coronary Artery Tracking Challenge (CAT08) training and test datasets were used to benchmark the algorithm and to assess its generalization. An average overlap of 93.6% and a clinically relevant overlap of 96.4% were obtained. The proposed method achieved better overlap scores than the current state-of-the-art automatic centerline extraction techniques on the CAT08 dataset with a vessel detection rate of 95%.      
### 14.Tubular Shape Aware Data Generation for Semantic Segmentation in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.00907.pdf)
>  Chest X-ray is one of the most widespread examinations of the human body. In interventional radiology, its use is frequently associated with the need to visualize various tube-like objects, such as puncture needles, guiding sheaths, wires, and catheters. Detection and precise localization of these tube-like objects in the X-ray images is, therefore, of utmost value, catalyzing the development of accurate target-specific segmentation algorithms. Similar to the other medical imaging tasks, the manual pixel-wise annotation of the tubes is a resource-consuming process. In this work, we aim to alleviate the lack of the annotated images by using artificial data. Specifically, we present an approach for synthetic data generation of the tube-shaped objects, with a generative adversarial network being regularized with a prior-shape constraint. Our method eliminates the need for paired image--mask data and requires only a weakly-labeled dataset (10--20 images) to reach the accuracy of the fully-supervised models. We report the applicability of the approach for the task of segmenting tubes and catheters in the X-ray images, whereas the results should also hold for the other imaging modalities.      
### 15.Weight Encode Reconstruction Network for Computed Tomography in a Semi-Case-Wise and Learning-Based Way  [ :arrow_down: ](https://arxiv.org/pdf/2010.00893.pdf)
>  Classic algebraic reconstruction technology (ART) for computed tomography requires pre-determined weights of the voxels for projecting pixel values. However, such weight cannot be accurately obtained due to the limitation of the physical understanding and computation resources. In this study, we propose a semi-case-wise learning-based method named Weight Encode Reconstruction Network (WERNet) to tackle the issues mentioned above. The model is trained in a self-supervised manner without the label of a voxel set. It contains two branches, including the voxel weight encoder and the voxel attention part. Using gradient normalization, we are able to co-train the encoder and voxel set numerically stably. With WERNet, the reconstructed result was obtained with a cosine similarity greater than 0.999 with the ground truth. Moreover, the model shows the extraordinary capability of denoising comparing to the classic ART method. In the generalization test of the model, the encoder is transferable from a voxel set with complex structure to the unseen cases without the deduction of the accuracy.      
### 16.Impact of Short Blocklength Coding on Stability of an AGV Control System in Industry 4.0  [ :arrow_down: ](https://arxiv.org/pdf/2010.00884.pdf)
>  With the advent of 5G and beyond, using wireless communication for closed-loop control and automation processes is one of the main aspects of the envisioned Industry 4.0. In this regard, a major challenge is to ensure a robust and stable control system over an unreliable wireless channel. One of the main use-cases in this context is Automated Guided Vehicle (AGV) control in a future factory. Specifically, we consider a system where an AGV controller is placed in an edge cloud in the factory network infrastructure and the control commands are sent over a time-correlated Rayleigh fading channel. In an industrial control, short packets are exchanged between the controller and the actuator. Therefore, in this case, Shannon's assumption for an infinite block length is not applicable. The objective is to analyse the stability performance of an AGV control system in a Finite Block-Length (FBL) regime. We evaluate the coding rate required to maintain a stable edge cloud based AGV system. The results illustrate that adapting the control parameters can lower the stringent requirements on the coding rate. It reveals that a constant stability performance can be achieved even at higher coding rate by increasing the AGV's velocity. Moreover, this paper also determines the maximum number of AGVs that can be served seamlessly over the available communication resources while maintaining a stable control system.      
### 17.Super-Nyquist Co-Prime Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2010.00858.pdf)
>  The theory of co-prime arrays has been studied in the past. Nyquist rate estimation of second order statistics using the combined difference set was demonstrated with low latency. This paper proposes a novel method to reconstruct the second order statistics at a rate that is twice the Nyquist rate using the same sub-Nyquist co-prime samplers. We analyse the difference set, and derive the closed-form expressions for the weight function and the bias of the correlogram estimate. The main lobe width of the bias window is approximately half of the width obtained using the prototype co-prime sampler. Since the proposed scheme employs the same rate prototype co-prime samplers; the number of samples acquired in one co-prime period and hardware cost are unaffected. Super-Nyquist estimation with multiple co-prime periods is also described. Furthermore, n-tuple or multi-level co-prime structure is presented from a super-Nyquist perspective. Here, estimation at a rate q times higher than Nyquist is possible, where q is the number of sub-samplers.      
### 18.Morphological segmentation of hyperspectral images  [ :arrow_down: ](https://arxiv.org/pdf/2010.00853.pdf)
>  The present paper develops a general methodology for the morphological segmentation of hyperspectral images, i.e., with an important number of channels. This approach, based on watershed, is composed of a spectral classification to obtain the markers and a vectorial gradient which gives the spatial information. Several alternative gradients are adapted to the different hyperspectral functions. Data reduction is performed either by Factor Analysis or by model fitting. Image segmentation is done on different spaces: factor space, parameters space, etc. On all these spaces the spatial/spectral segmentation approach is applied, leading to relevant results on the image.      
### 19.Multidimensional Index Modulation for 5G and Beyond Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.00850.pdf)
>  This study examines the flexible utilization of existing IM techniques in a comprehensive manner to satisfy the challenging and diverse requirements of 5G and beyond services. After spatial modulation (SM), which transmits information bits through antenna indices, application of IM to orthogonal frequency division multiplexing (OFDM) subcarriers has opened the door for the extension of IM into different dimensions, such as radio frequency (RF) mirrors, time slots, codes, and dispersion matrices. Recent studies have introduced the concept of multidimensional IM by various combinations of one-dimensional IM techniques to provide higher spectral efficiency (SE) and better bit error rate (BER) performance at the expense of higher transmitter (Tx) and receiver (Rx) complexity. Despite the ongoing research on the design of new IM techniques and their implementation challenges, proper use of the available IM techniques to address different requirements of 5G and beyond networks is an open research area in the literature. For this reason, we first provide the dimensional-based categorization of available IM domains and review the existing IM types regarding this categorization. Then, we develop a framework that investigates the efficient utilization of these techniques and establishes a link between the IM schemes and 5G services, namely enhanced mobile broadband (eMBB), massive machine-type communications (mMTC), and ultra-reliable low-latency communication (URLLC). Additionally, this work defines key performance indicators (KPIs) to quantify the advantages and disadvantages of IM techniques in time, frequency, space, and code dimensions. Finally, future recommendations are given regarding the design of flexible IM-based communication systems for 5G and beyond wireless networks.      
### 20.Empirical Low-Altitude UAV Spatial Channel Modeling for Cellular Networks Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2010.00841.pdf)
>  Cellular-connected unmanned aerial vehicles (UAVs) have recently attracted a surge of interests in both academia and industry. Understanding the air-to-ground (A2G) propagation channels is essential to enable reliable and/or high-throughput communications for UAVs and protect the ground user equipments (UEs). In this contribution, a recently conducted measurement campaign for the A2G channels is introduced. A uniform circular array (UCA) with 16 antenna elements was employed to collect the downlink signals of two different Long Term Evolution (LTE) networks, at the heights of 0-40m in three different, namely rural, urban and industrial scenarios. The channel impulse responses (CIRs) have been extracted from the received data, and the spatial/angular parameters of the multipath components in individual channels were estimated according to a high-resolution-parameter estimation (HRPE) principle. Based on the HRPE results, clusters of multipath components were further identified. Finally, comprehensive spatial channel characteristics were investigated in the composite and cluster levels at different heights in the three scenarios.      
### 21.Supervised Heart Rate Tracking using Wrist-Type Photoplethysmographic (PPG) Signals during Physical Exercise without Simultaneous Acceleration Signals  [ :arrow_down: ](https://arxiv.org/pdf/2010.00769.pdf)
>  PPG based heart rate (HR) monitoring has recently attracted much attention with the advent of wearable devices such as smart watches and smart bands. However, due to severe motion artifacts (MA) caused by wristband stumbles, PPG based HR monitoring is a challenging problem in scenarios where the subject performs intensive physical exercises. This work proposes a novel approach to the problem based on supervised learning by Neural Network (NN). By simulations on the benchmark datasets [1], we achieve acceptable estimation accuracy and improved run time in comparison with the literature. A major contribution of this work is that it alleviates the need to use simultaneous acceleration signals. The simulation results show that although the proposed method does not process the simultaneous acceleration signals, it still achieves the acceptable Mean Absolute Error (MAE) of 1.39 Beats Per Minute (BPM) on the benchmark data set.      
### 22.A Modified Schmidl-Cox OFDM Timing Detector  [ :arrow_down: ](https://arxiv.org/pdf/2010.00762.pdf)
>  We describe a simple modification of the Schmidl-Cox detector for establishing timing in OFDM transmissions that stabilizes performance in transitions from no-signal to signal, or vice-versa. Moreover, the proposed modification scales the detector's metric between 0 and 1 for all scenarios, simplifying threshold setting, and improves timing detector SNR.      
### 23.Specifying User Preferences using Weighted Signal Temporal Logic  [ :arrow_down: ](https://arxiv.org/pdf/2010.00752.pdf)
>  We extend Signal Temporal Logic (STL) to enable the specification of importance and priorities. The extension, called Weighted STL (wSTL), has the same qualitative (Boolean) semantics as STL, but additionally defines weights associated with Boolean and temporal operators that modulate its quantitative semantics (robustness). We show that the robustness of wSTL can be defined as weighted generalizations of all known compatible robustness functionals (i.e., robustness scores that are recursively defined over formulae) that can take into account the weights in wSTL formulae. We utilize this weighted robustness to distinguish signals with respect to a desired wSTL formula that has sub-formulae with different importance or priorities and time preferences, and demonstrate its usefulness in problems with conflicting tasks where satisfaction of all tasks cannot be achieved. We also employ wSTL robustness in an optimization framework to synthesize controllers that maximize satisfaction of a specification with user specified preferences.      
### 24.Training Strategies to Handle Missing Modalities for Audio-Visual Expression Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.00734.pdf)
>  Automatic audio-visual expression recognition can play an important role in communication services such as tele-health, VOIP calls and human-machine interaction. Accuracy of audio-visual expression recognition could benefit from the interplay between the two modalities. However, most audio-visual expression recognition systems, trained in ideal conditions, fail to generalize in real world scenarios where either the audio or visual modality could be missing due to a number of reasons such as limited bandwidth, interactors' orientation, caller initiated muting. This paper studies the performance of a state-of-the art transformer when one of the modalities is missing. We conduct ablation studies to evaluate the model in the absence of either modality. Further, we propose a strategy to randomly ablate visual inputs during training at the clip or frame level to mimic real world scenarios. Results conducted on in-the-wild data, indicate significant generalization in proposed models trained on missing cues, with gains up to 17% for frame level ablations, showing that these training strategies cope better with the loss of input modalities.      
### 25.Parameter Estimation via Fokker-Planck Type Residual: Application to Linear Stationary Random Vibration  [ :arrow_down: ](https://arxiv.org/pdf/2010.00727.pdf)
>  In this study, we propose a new method that is useful for estimating unknown parameter values of stochastic differential equation (SDE) models, based on probability density function (PDF) data measured from random dynamical systems. As our method does not require explicit description of PDF, it can be applied to the SDE models even when their PDFs are hardly derived in explicit forms due to multiplicative-noise terms, nonlinear terms, and so on. Therefore, our method is expected to provide a versatile tool to dynamically parameterize measured PDF data. In our proposed method, it is assumed that a measured PDF is obtained from a random dynamical system whose structure is described by a known SDE model with unknown parameter values. With the help of ItÃ´ calculus, the Fokker-Planck equation (FPE) is derived from the SDE model. The measured PDF and a candidate of parameter values are substituted into the FPE to calculate a FPE residual. Our method is applied to two random vibration systems. Their FPE residuals tend to zero as the parameter values tend to exact values, showing that our proposed FPE residual can be utilized for unknown parameter estimation of SDE models.      
### 26.Performance Analysis and Optimization of NOMA with HARQ for Short Packet Communications in Massive IoT  [ :arrow_down: ](https://arxiv.org/pdf/2010.00708.pdf)
>  In this paper, we consider the massive non-orthogonal multiple access (NOMA) with hybrid automatic repeat request (HARQ) for short packet communications. To reduce the latency, each user can perform one re-transmission provided that the previous packet was not decoded successfully. The system performance is evaluated for both coordinated and uncoordinated transmissions. We first develop a Markov model (MM) to analyze the system dynamics and characterize the packet error rate (PER) and throughput of each user in the coordinated scenario. The power levels are then optimized for two scenarios, including the power constrained and reliability constrained scenarios. A simple yet efficient dynamic cell planning is also designed for the uncoordinated scenario. Numerical results show that both coordinated and uncoordinated NOMA-HARQ with a limited number of retransmissions can achieve the desired level of reliability with the guaranteed latency using a proper power control strategy. Results also show that NOMA-HARQ achieves a higher throughput compared to the orthogonal multiple access scheme with HARQ under the same average received power constraint at the base station.      
### 27.PHASED: Phase-Aware Submodularity-Based Energy Disaggregation  [ :arrow_down: ](https://arxiv.org/pdf/2010.00696.pdf)
>  Energy disaggregation is the task of discerning the energy consumption of individual appliances from aggregated measurements, which holds promise for understanding and reducing energy usage. In this paper, we propose PHASED, an optimization approach for energy disaggregation that has two key features: PHASED (i) exploits the structure of power distribution systems to make use of readily available measurements that are neglected by existing methods, and (ii) poses the problem as a minimization of a difference of submodular functions. We leverage this form by applying a discrete optimization variant of the majorization-minimization algorithm to iteratively minimize a sequence of global upper bounds of the cost function to obtain high-quality approximate solutions. PHASED improves the disaggregation accuracy of state-of-the-art models by up to 61% and achieves better prediction on heavy load appliances.      
### 28.Helicality: An Isomap-based Measure of Octave Equivalence in Audio Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.00673.pdf)
>  Octave equivalence serves as domain-knowledge in MIR systems, including chromagram, spiral convolutional networks, and harmonic CQT. Prior work has applied the Isomap manifold learning algorithm to unlabeled audio data to embed frequency sub-bands in 3-D space where the Euclidean distances are inversely proportional to the strength of their Pearson correlations. However, discovering octave equivalence via Isomap requires visual inspection and is not scalable. To address this problem, we define "helicality" as the goodness of fit of the 3-D Isomap embedding to a Shepherd-Risset helix. Our method is unsupervised and uses a custom Frank-Wolfe algorithm to minimize a least-squares objective inside a convex hull. Numerical experiments indicate that isolated musical notes have a higher helicality than speech, followed by drum hits.      
### 29.Jam-Guard: Low-Cost, Hand-held Device for First Responders to Detect and Localize Jammers  [ :arrow_down: ](https://arxiv.org/pdf/2010.00655.pdf)
>  Intentional and unintentional interferences collectively referred to as Radio Frequency Interference (RFI) result in severe security threat to the public safety, first responder emergency rescue and military missions. Such RFI if not detected and localized can disrupt the wireless communication which forms the backbone of first responder and military operations. The prime objective of this work was to design and prototype a RFI detection and localization device, Jam-Guard that significantly outperforms traditional approaches in real-life deployment yet be computationally feasible to be developed as a low SWaC (size, weight, and cost) device. The proposed device employs a unique combination of robust parallel detection algorithms based on Kurtosis and FRactional Fourier Transform (FRFT) with Golden Section Search algorithm to rapidly detect RFI that affects critical communication signals. The localization scheme is designed to leverage the FRFT output from the detection phase to ease the computational load. We give a detailed account of the device prototyping and evaluation. To demonstrate the efficacy of the proposed detection approach as opposed to conventional energy detection (employed in several commercial interference detectors), we compare the two schemes on test and target platforms. The proposed scheme depicted significant improvement (~40 dB) in detection probability both in preliminary implementation and target prototype experiments.      
### 30.Compensating PDE actuator and sensor dynamics using Sylvester equation  [ :arrow_down: ](https://arxiv.org/pdf/2010.00615.pdf)
>  We consider the problem of stabilizing PDE-ODE cascade systems in which the input is applied to the PDE system whose output drives the ODE system. We also consider the dual problem of constructing an observer for ODE-PDE cascade systems in which the output of the ODE system drives the PDE system, whose output is measured. The PDE in these problems is stable and the ODE is unstable. While the ODE system models the plant in both the problems, the PDE system models the actuator in the stabilization problem and the sensor in the dual problem. In the literature, these problems have been solved for specific PDE models using the backstepping approach. In contrast, in the present work we consider these problems in an abstract framework by letting the PDE system be any regular linear system. Using a state transformation obtained by solving a Sylvester equation with unbounded operators, we first diagonalize the state operator corresponding to the cascade systems. We then solve the stabilization problem and the dual estimation problem, provided they are solvable, by solving certain finite-dimensional counterparts. We also derive necessary and sufficient conditions for verifying the solvability of these problems. We show that the controller which solves the stabilization problem is robust to certain unbounded perturbations. We illustrate our theory by designing a stabilizing controller for a PDE-ODE cascade in which the PDE is a 1D diffusion equation and an observer for a ODE-PDE cascade in which the PDE is a 1D wave equation.      
### 31.REQIBA: Regression and Deep Q-Learning for Intelligent UAV Cellular User to Base Station Association  [ :arrow_down: ](https://arxiv.org/pdf/2010.01126.pdf)
>  Unmanned Aerial Vehicles (UAVs) are emerging as important users of next-generation cellular networks. By operating in the sky, these UAV users experience very different radio conditions than terrestrial users, due to factors such as strong Line-of-Sight (LoS) channels (and interference) and Base Station (BS) antenna misalignment. The consequence of this is that the UAVs experience significant degradation to their received quality of service, particularly when they are moving and are subject to frequent handovers. The solution is to allow the UAV to be aware of its surrounding environment, and intelligently connect into the cellular network using this awareness. In this paper we present REgression and deep Q-learning for Intelligent UAV cellular user to Base station Association (REQIBA) to allow a UAV which is flying over an urban area to intelligently connect to underlying BSs, using information about the received signal powers, the BS locations, and the surrounding building topology. We demonstrate how REQIBA can as much as double the total UAV throughput, when compared to heuristic association schemes similar to those commonly used by terrestrial users. We also evaluate how environmental factors such as UAV height, building density, and throughput loss due to handovers impact the performance of our solution.      
### 32.Secrecy Rate Maximization in Multi-IRS Millimeter Wave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.01113.pdf)
>  In this paper, the problem of physical layer security enhancement in a millimeter-wave (mmWave) network equipped with multiple Intelligent Reflecting Surfaces (IRSs) is investigated. In this network, the IRSs assist in signal transmission from the Base Station (BS) to desired users and at the same time in securing signals from an unauthorized eavesdropper. Our objective is to maximize the secrecy rate by jointly optimizing the active and passive beamformers at the base station and IRSs, respectively. The optimization problem is non-convex and hence, we solve it by decomposing it into two disjoint active and passive beamforming design sub-problems and then iteratively solving them by alternating and Semi-Definite Relaxation (SDR) techniques. Simulation results show the advantage of using multiple IRSs in secrecy rate enhancement of the mmWave networks. In additio12n, we show how the secrecy rate improves with the number of IRSs in the network and also with the number of reflecting elements at the IRS.      
### 33.POMDPs in Continuous Time and Discrete Spaces  [ :arrow_down: ](https://arxiv.org/pdf/2010.01014.pdf)
>  Many processes, such as discrete event systems in engineering or population dynamics in biology, evolve in discrete space and continuous time. We consider the problem of optimal decision making in such discrete state and action space systems under partial observability. This places our work at the intersection of optimal filtering and optimal control. At the current state of research, a mathematical description for simultaneous decision making and filtering in continuous time with finite countable state and action spaces is still missing. In this paper, we give a mathematical description of a continuous-time POMDP. By leveraging optimal filtering theory we derive a HJB type equation that characterizes the optimal solution. Using techniques from deep learning we approximately solve the resulting partial integro-differential equation. We present (i) an approach solving the decision problem offline by learning an approximation of the value function and (ii) an online algorithm which provides a solution in belief space using deep reinforcement learning. We show the applicability on a set of toy examples which pave the way for future methods providing solutions for high dimensional problems.      
### 34.Optimization of DMD-based independent amplitude and phase modulation: a spatial resolution and quantization  [ :arrow_down: ](https://arxiv.org/pdf/2010.00955.pdf)
>  This paper presents the results of a comprehensive study on the optimization of the optical system for independent amplitude and phase wavefront manipulation, which is based on a digital micromirror device implementation. The parameters of generated binary fringe patterns to reach the optimal quality of target complex-valued wavefront have been found for several examples, and a general algorithm for DMD pattern optimization is described. It was shown that a trade-off between spatial resolution and quantization of the target amplitude and phase distribution should be achieved. The increase of carrier frequency results in higher spatial resolution of the modulated complex wave but decreases its quantization. The dependence of the best DMD-pattern generation parameters on the type of target complex wavefront is discussed in terms of spatial resolution and quantization degree.      
### 35.A Deep-Unfolded Reference-Based RPCA Network For Video Foreground-Background Separation  [ :arrow_down: ](https://arxiv.org/pdf/2010.00929.pdf)
>  Deep unfolded neural networks are designed by unrolling the iterations of optimization algorithms. They can be shown to achieve faster convergence and higher accuracy than their optimization counterparts. This paper proposes a new deep-unfolding-based network design for the problem of Robust Principal Component Analysis (RPCA) with application to video foreground-background separation. Unlike existing designs, our approach focuses on modeling the temporal correlation between the sparse representations of consecutive video frames. To this end, we perform the unfolding of an iterative algorithm for solving reweighted $\ell_1$-$\ell_1$ minimization; this unfolding leads to a different proximal operator (a.k.a. different activation function) adaptively learned per neuron. Experimentation using the moving MNIST dataset shows that the proposed network outperforms a recently proposed state-of-the-art RPCA network in the task of video foreground-background separation.      
### 36.Stochastic Analysis of Satellite Broadband by Mega-Constellations with Inclined LEOs  [ :arrow_down: ](https://arxiv.org/pdf/2010.00871.pdf)
>  As emerging massive constellations are intended to provide seamless connectivity for remote areas using hundreds of small low Earth orbit (LEO) satellites, new methodologies have great importance to study the performance of these networks. In this paper, we derive both downlink and uplink analytical expressions for coverage probability and data rate of an inclined LEO constellation under general fading, regardless of exact satellites' positions. Our solution involves two phases as we, first, abstract the network into a uniformly distributed network. Secondly, we obtain a new parameter, effective number of satellites, for every user's latitude which compensates for the performance mismatch between the actual and uniform constellations. In addition to exact derivation of the network performance metrics, this study provides insight into selecting the constellation parameters, e.g., the total number of satellites, altitude, and inclination angle.      
### 37.Weight and Gradient Centralization in Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.00866.pdf)
>  Batch normalization is currently the most widely used variant of internal normalization for deep neural networks. Additional work has shown that the normalization of weights and additional conditioning as well as the normalization of gradients further improve the generalization. In this work, we combine several of these methods and thereby increase the generalization of the networks. The advantage of the newer methods compared to the batch normalization is not only increased generalization, but also that these methods only have to be applied during training and, therefore, do not influence the running time during use. Link to CUDA code <a class="link-external link-https" href="https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/" rel="external noopener nofollow">this https URL</a>      
### 38.Cascaded Channel Estimation for IRS-assisted Mmwave Multi-antenna with Quantized Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2010.00865.pdf)
>  In this letter, we optimize the channel estimator of the cascaded channel in an intelligent reflecting surface (IRS)-assisted millimeter wave (mmWave) multi-antenna system. In this system, the receiver is equipped with a hybrid architecture adopting quantized beamforming. Different from traditional multiple-input multiple-output (MIMO) systems, the design of channel estimation is challenging since the IRS is usually a passive array with limited signal processing capability. We derive the optimized channel estimator in a closed form by reformulating the problem of cascaded channel estimation in this system, leveraging the typical mean-squared error (MSE) criterion. Considering the presence of possible channel sparsity in mmWave channels, we generalize the proposed method by exploiting the channel sparsity for further performance enhancement and computational complexity reduction. Simulation results verify that the proposed estimator significantly outperforms the existing ones.      
### 39.Nonsmoothness in Machine Learning: specific structure, proximal identification, and applications  [ :arrow_down: ](https://arxiv.org/pdf/2010.00848.pdf)
>  Nonsmoothness is often a curse for optimization; but it is sometimes a blessing, in particular for applications in machine learning. In this paper, we present the specific structure of nonsmooth optimization problems appearing in machine learning and illustrate how to leverage this structure in practice, for compression, acceleration, or dimension reduction. We pay a special attention to the presentation to make it concise and easily accessible, with both simple examples and general results.      
### 40.Maximal benefits and possible detrimental effects of binary decision aids  [ :arrow_down: ](https://arxiv.org/pdf/2010.00828.pdf)
>  Binary decision aids, such as alerts, are a simple and widely used form of automation. The formal analysis of a user's task performance with an aid sees the process as the combination of information from two detectors who both receive input about an event and evaluate it. The user's decisions are based on the output of the aid and on the information, the user obtains independently. We present a simple method for computing the maximal benefits a user can derive from a binary aid as a function of the user's and the aid's sensitivities. Combining the user and the aid often adds little to the performance the better detector could achieve alone. Also, if users assign non-optimal weights to the aid, performance may drop dramatically. Thus, the introduction of a valid aid can actually lower detection performance, compared to a more sensitive user working alone. Similarly, adding a user to a system with high sensitivity may lower its performance. System designers need to consider the potential adverse effects of introducing users or aids into systems.      
### 41.Deep Composer Classification Using Symbolic Representation  [ :arrow_down: ](https://arxiv.org/pdf/2010.00823.pdf)
>  In this study, we train deep neural networks to classify composer on a symbolic domain. The model takes a two-channel two-dimensional input, i.e., onset and note activations of time-pitch representation, which is converted from MIDI recordings and performs a single-label classification. On the experiments conducted on MAESTRO dataset, we report an F1 value of 0.8333 for the classification of 13~classical composers.      
### 42.Ranging success probability of PPP distributed automotive radar in presence of generalized fading  [ :arrow_down: ](https://arxiv.org/pdf/2010.00803.pdf)
>  In automotive radar applications, multiple radars are used in all vehicles for improving the imaging quality. However this causes radar-to-radar interference from neighbouring vehicles, thus reducing the imaging quality. One metric to measure the imaging quality is ranging success probability. The ranging success probability is the probability that a multiple radar system successfully detects an object at a given range, under certain operating conditions. In state-of-the-art literature, closed form expressions for ranging success probability have been derived assuming no fading in desired signal component. Similarly in literature, though distribution of fading in interferers is assumed to be arbitrary, closed form expression is derived only for no-fading assumption in interferers. As fading is always present in a wireless channel, we have derived ranging success probability assuming desired channel experiences the popular Rayleigh fading. And we have assumed generalized $\kappa$-$\mu$ shadowed fading for interfering channels that generalizes many popular fading models such as Rayleigh, Rician, Nakagami-$m$, $\kappa$-$\mu$ etc. The interferers are assumed to be located on points drawn from a Poisson point process distribution. We have also studied how the relationship between shadowing component and number of clusters can affect the impact of LOS component on ranging success probability.      
### 43.Greedy Covariance Control for Stochastic Nonlinear Systems using Gaussian Process Prediction Models and the Unscented Transform  [ :arrow_down: ](https://arxiv.org/pdf/2010.00778.pdf)
>  In this work, the problem of steering the first two moments of the uncertain state of an unknown discrete-time nonlinear stochastic system to a given terminal distribution in finite time is considered. Toward that goal, first, a non-parametric prediction model is learned from a set of available training data points using Gaussian process regression: a powerful machine learning tool for learning distributions over arbitrary nonlinear functions. Second, a tractable nonlinear covariance steering algorithm that utilizes the Gaussian process prediction model to compute a feedback policy that will drive the probability density function of the state of the system close to the goal density is formulated. In particular, a greedy covariance steering control policy is implemented that linearizes the Gaussian process prediction model around the latest mean and covariance predictions at each time step and solves the linear covariance steering control problem, which can be formulated as a tractable, finite-dimensional convex program. Then, only the first control law of the solution to the linear problem is applied. At each step, the information on the state statistics is updated by computing approximations of the predicted state mean and covariance of the resulting closed-loop nonlinear system step using the unscented transform and the learned Gaussian process prediction model. Numerical simulations illustrating the main ideas of this paper are also presented.      
### 44.Deep Learning for Earth Image Segmentation based on Imperfect Polyline Labels with Annotation Errors  [ :arrow_down: ](https://arxiv.org/pdf/2010.00757.pdf)
>  In recent years, deep learning techniques (e.g., U-Net, DeepLab) have achieved tremendous success in image segmentation. The performance of these models heavily relies on high-quality ground truth segment labels. Unfortunately, in many real-world problems, ground truth segment labels often have geometric annotation errors due to manual annotation mistakes, GPS errors, or visually interpreting background imagery at a coarse resolution. Such location errors will significantly impact the training performance of existing deep learning algorithms. Existing research on label errors either models ground truth errors in label semantics (assuming label locations to be correct) or models label location errors with simple square patch shifting. These methods cannot fully incorporate the geometric properties of label location errors. To fill the gap, this paper proposes a generic learning framework based on the EM algorithm to update deep learning model parameters and infer hidden true label locations simultaneously. Evaluations on a real-world hydrological dataset in the streamline refinement application show that the proposed framework outperforms baseline methods in classification accuracy (reducing the number of false positives by 67% and reducing the number of false negatives by 55%).      
### 45.Exploiting Multi-Path for Safeguarding mmWave Communications Against Randomly Located Eavesdroppers  [ :arrow_down: ](https://arxiv.org/pdf/2010.00733.pdf)
>  Communication in the millimeter-wave (mmWave) band has recently been proposed to enable giga-bit-per-second data rates for next generation wireless systems. Physical layer security techniques have emerged as a simple and yet effective way to safeguard these systems against eavesdropping attacks. These techniques make use of the large antenna arrays available in mmWave systems to provide an array gain at the target receiver and degrade the signal quality at the eavesdropper. Despite their effectiveness, majority of these techniques are based on line-of-sight communication links between the transmitter and the receiver, and may fail in the presence of blockages or non-line-of-sight links. This paper builds upon previous work and extends physical layer security to the non-line-of-sight communication case and randomly located eavesdroppers. Specifically, the large dimensional antenna arrays in mmWave systems and the intrinsic characteristics of wireless channel are exploited to induce noiselike signals that jam eavesdroppers with sensitive receivers. Numerical results show that the proposed techniques provide higher secrecy rate when compared to conventional array and physical layer techniques based on line-of-sight links.      
### 46.Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2010.00672.pdf)
>  As an emerging field in Machine Learning, Explainable AI (XAI) has been offering remarkable performance in interpreting the decisions made by Convolutional Neural Networks (CNNs). To achieve visual explanations for CNNs, methods based on class activation mapping and randomized input sampling have gained great popularity. However, the attribution methods based on these techniques provide lower resolution and blurry explanation maps that limit their explanation power. To circumvent this issue, visualization based on various layers is sought. In this work, we collect visualization maps from multiple layers of the model based on an attribution-based input sampling technique and aggregate them to reach a fine-grained and complete explanation. We also propose a layer selection strategy that applies to the whole family of CNN-based models, based on which our extraction framework is applied to visualize the last layers of each convolutional block of the model. Moreover, we perform an empirical analysis of the efficacy of derived lower-level information to enhance the represented attributions. Comprehensive experiments conducted on shallow and deep models trained on natural and industrial datasets, using both ground-truth and model-truth based evaluation metrics validate our proposed algorithm by meeting or outperforming the state-of-the-art methods in terms of explanation ability and visual quality, demonstrating that our method shows stability regardless of the size of objects or instances to be explained.      
### 47.Machine Learning in Generation, Detection, and Mitigation of Cyberattacks in Smart Grid: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2010.00661.pdf)
>  Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber and physical equipment to run at an optimal operating point. Cyberattacks are the principal threats confronting the usage and advancement of the state-of-the-art systems. The advancement of SG has added a wide range of technologies, equipment, and tools to make the system more reliable, efficient, and cost-effective. Despite attaining these goals, the threat space for the adversarial attacks has also been expanded because of the extensive implementation of the cyber networks. Due to the promising computational and reasoning capability, machine learning (ML) is being used to exploit and defend the cyberattacks in SG by the attackers and system operators, respectively. In this paper, we perform a comprehensive summary of cyberattacks generation, detection, and mitigation schemes by reviewing state-of-the-art research in the SG domain. Additionally, we have summarized the current research in a structured way using tabular format. We also present the shortcomings of the existing works and possible future research direction based on our investigation.      
### 48.StreamSoNG: A Soft Streaming Classification Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.00635.pdf)
>  Examining most streaming clustering algorithms leads to the understanding that they are actually incremental classification models. They model existing and newly discovered structures via summary information that we call footprints. Incoming data is normally assigned crisp labels (into one of the structures) and that structure's footprints are incrementally updated. There is no reason that these assignments need to be crisp. In this paper, we propose a new streaming classification algorithm that uses Neural Gas prototypes as footprints and produces a possibilistic label vector (typicalities) for each incoming vector. These typicalities are generated by a modified possibilistic k-nearest neighbor algorithm. The approach is tested on synthetic and real image datasets with excellent results.      
