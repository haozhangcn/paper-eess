# ArXiv eess --Fri, 24 Jul 2020
### 1.PIPAL: a Large-Scale Image Quality Assessment Dataset for Perceptual Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2007.12142.pdf)
>  Image quality assessment (IQA) is the key factor for the fast development of image restoration (IR) algorithms. The most recent IR methods based on Generative Adversarial Networks (GANs) have achieved significant improvement in visual performance, but also presented great challenges for quantitative evaluation. Notably, we observe an increasing inconsistency between perceptual quality and the evaluation results. Then we raise two questions: (1) Can existing IQA methods objectively evaluate recent IR algorithms? (2) When focus on beating current benchmarks, are we getting better IR algorithms? To answer these questions and promote the development of IQA methods, we contribute a large-scale IQA dataset, called Perceptual Image Processing Algorithms (PIPAL) dataset. Especially, this dataset includes the results of GAN-based methods, which are missing in previous datasets. We collect more than 1.13 million human judgments to assign subjective scores for PIPAL images using the more reliable "Elo system". Based on PIPAL, we present new benchmarks for both IQA and super-resolution methods. Our results indicate that existing IQA methods cannot fairly evaluate GAN-based IR algorithms. While using appropriate evaluation methods is important, IQA methods should also be updated along with the development of IR algorithms. At last, we improve the performance of IQA networks on GAN-based distortions by introducing anti-aliasing pooling. Experiments show the effectiveness of the proposed method.      
### 2.Integration of an Energy Management Tool and Digital Twin for Coordination and Control of Multi-vector Smart Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2007.12129.pdf)
>  As Internet of Things (IoT) technologies enable greater communication between energy assets in smart cities, the operational coordination of various energy networks in a city or district becomes more viable. Suitable tools are needed that can harness advanced control and machine learning techniques to achieve environmental, economic and resilience objectives. In this paper, an energy management tool is presented that can offer optimal control, scheduling, forecasting and coordination services to energy assets across a district, enabling optimal decisions under user-defined objectives. The tool presented here can coordinate different sub-systems in a district to avoid the violation of high-level system constraints and is designed in a generic fashion to enable transferable use across different energy sectors. The work demonstrates the potential for a single open-source optimisation framework to be applied across multiple energy vectors, providing local government the opportunity to manage different assets in a coordinated fashion. This is shown through case studies that integrate low-carbon communal heating for social housing with electric vehicle charge-point management to achieve high-level system constraints and local government objectives in the borough of Greenwich, London. The paper illustrates the theoretical methodology, the software architecture and the digital twin-based testing environment underpinning the proposed approach.      
### 3.Version Control of Speaker Recognition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2007.12069.pdf)
>  This paper discusses one of the most challenging practical engineering problems in speaker recognition systems - the version control of models and user profiles. A typical speaker recognition system consists of two stages: the enrollment stage, where a profile is generated from user-provided enrollment audio; and the runtime stage, where the voice identity of the runtime audio is compared against the stored profiles. As technology advances, the speaker recognition system needs to be updated for better performance. However, if the stored user profiles are not updated accordingly, version mismatch will result in meaningless recognition results. In this paper, we describe different version control strategies for different types of speaker recognition systems, according to how they are deployed in the production environment.      
### 4.A Computation-Efficient CNN System for High-Quality Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2007.12066.pdf)
>  In this paper, a Convolutional Neural Network (CNN) system is proposed for brain tumor segmentation. The system consists of three parts, a pre-processing block to reduce the data volume, an application-specific CNN(ASCNN) to segment tumor areas precisely, and a refinement block to detect/remove false positive pixels. The CNN, designed specifically for the task, has 7 convolution layers, 16 channels per layer, requiring only 11716 parameters. The convolutions combined with max-pooling in the first half of the CNN are performed to localize tumor areas. Two convolution modes, namely depthwise convolution and standard convolution, are performed in parallel in the first 2 layers to extract elementary features efficiently. For a fine classification of pixel-wise precision in the second half of the CNN, the feature maps are modulated by adding the weighted local features generated in the first half of the CNN. The performance of the proposed system has been evaluated by an online platform with dataset BRATS2018. Requiring a very low computation volume, the proposed system delivers a high segmentation quality indicated by its average Dice scores of 0.75, 0.88 and 0.76 for enhancing tumor, whole tumor and tumor core, respectively, and the median Dice scores of 0.85, 0.92, and 0.86. The consistency in system performance has also been measured, demonstrating that the system is able to reproduce almost the same output to the same input after retraining. The simple structure of the proposed system facilitates its implementation in computation restricted environment, and a wide range of applications can thus be expected.      
### 5.mmRAPID: Machine Learning assisted Noncoherent Compressive Millimeter-Wave Beam Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2007.12060.pdf)
>  Millimeter-wave communication has the potential to deliver orders of magnitude increases in mobile data rates. A key design challenge is to enable rapid beam alignment with phased arrays. Traditional millimeter-wave systems require a high beam alignment overhead, typically an exhaustive beam sweep, to find the beam direction with the highest beamforming gain. Compressive sensing is a promising framework to accelerate beam alignment. However, model mismatch from practical array hardware impairments poses a challenge to its implementation. In this work, we introduce a neural network assisted compressive beam alignment method that uses noncoherent received signal strength measured by a small number of pseudorandom sounding beams to infer the optimal beam steering direction. We experimentally showcase our proposed approach with a 60GHz 36-element phased array in a suburban line-of-sight environment. The results show that our approach achieves post alignment beamforming gain within 1dB margin compared to an exhaustive search with 90.2 percent overhead reduction. Compared to purely model-based noncoherent compressive beam alignment, our method has 75 percent overhead reduction.      
### 6.Federated Learning in the Sky: Aerial-Ground Air Quality Sensing Framework with UAV Swarms  [ :arrow_down: ](https://arxiv.org/pdf/2007.12004.pdf)
>  Due to air quality significantly affects human health, it is becoming increasingly important to accurately and timely predict the Air Quality Index (AQI). To this end, this paper proposes a new federated learning-based aerial-ground air quality sensing framework for fine-grained 3D air quality monitoring and forecasting. Specifically, in the air, this framework leverages a light-weight Dense-MobileNet model to achieve energy-efficient end-to-end learning from haze features of haze images taken by Unmanned Aerial Vehicles (UAVs) for predicting AQI scale distribution. Furthermore, the Federated Learning Framework not only allows various organizations or institutions to collaboratively learn a well-trained global model to monitor AQI without compromising privacy, but also expands the scope of UAV swarms monitoring. For ground sensing systems, we propose a Graph Convolutional neural network-based Long Short-Term Memory (GC-LSTM) model to achieve accurate, real-time and future AQI inference. The GC-LSTM model utilizes the topological structure of the ground monitoring station to capture the spatio-temporal correlation of historical observation data, which helps the aerial-ground sensing system to achieve accurate AQI inference. Through extensive case studies on a real-world dataset, numerical results show that the proposed framework can achieve accurate and energy-efficient AQI sensing without compromising the privacy of raw data.      
### 7.CVR-Net: A deep convolutional neural network for coronavirus recognition from chest radiography images  [ :arrow_down: ](https://arxiv.org/pdf/2007.11993.pdf)
>  The novel Coronavirus Disease 2019 (COVID-19) is a global pandemic disease spreading rapidly around the world. A robust and automatic early recognition of COVID-19, via auxiliary computer-aided diagnostic tools, is essential for disease cure and control. The chest radiography images, such as Computed Tomography (CT) and X-ray, and deep Convolutional Neural Networks (CNNs), can be a significant and useful material for designing such tools. However, designing such an automated tool is challenging as a massive number of manually annotated datasets are not publicly available yet, which is the core requirement of supervised learning systems. In this article, we propose a robust CNN-based network, called CVR-Net (Coronavirus Recognition Network), for the automatic recognition of the coronavirus from CT or X-ray images. The proposed end-to-end CVR-Net is a multi-scale-multi-encoder ensemble model, where we have aggregated the outputs from two different encoders and their different scales to obtain the final prediction probability. We train and test the proposed CVR-Net on three different datasets, where the images have collected from different open-source repositories. We compare our proposed CVR-Net with state-of-the-art methods, which are trained and tested on the same datasets. We split three datasets into five different tasks, where each task has a different number of classes, to evaluate the multi-tasking CVR-Net. Our model achieves an overall F1-score &amp; accuracy of 0.997 &amp; 0.998; 0.963 &amp; 0.964; 0.816 &amp; 0.820; 0.961 &amp; 0.961; and 0.780 &amp; 0.780, respectively, for task-1 to task-5. As the CVR-Net provides promising results on the small datasets, it can be an auspicious computer-aided diagnostic tool for the diagnosis of coronavirus to assist the clinical practitioners and radiologists. Our source codes and model are publicly available at <a class="link-external link-https" href="https://github.com/kamruleee51/CVR-Net" rel="external noopener nofollow">this https URL</a>.      
### 8.So you think you can DAS? A viewpoint on delay-and-sum beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2007.11960.pdf)
>  Delay-and-sum (DAS) is the most widespread digital beamformer in high-frame-rate ultrasound imaging. Its implementation is simple and compatible with real-time applications. In this viewpoint article, we describe the fundamentals of DAS beamforming. The underlying theory and numerical approach are detailed so that users can be aware of its functioning and limitations. In particular, we discuss the importance of the f-number and speed of sound on image quality, and propose one solution to set their values from a physical viewpoint. We suggest determining the f-number from the directivity of the transducer elements and the speed of sound from the phase dispersion of the delayed signals. Simplified Matlab codes are provided for the sake of clarity and openness. The effect of the f-number and speed of sound on the lateral resolution and contrast-to-noise ratio was investigated in vitro and in vivo. If not properly preset, these two factors had a substantial negative impact on standard metrics of image quality (namely CNR and FWHM). When beamforming with DAS in vitro or in vivo, it is recommended to optimize these parameters in order to use it wisely and prevent image degradation.      
### 9.Using modern motion estimation algorithms in existing video codecs  [ :arrow_down: ](https://arxiv.org/pdf/2007.11948.pdf)
>  Motion estimation is a key component of any modern video codec. Our understanding of motion and the estimation of motion from video has come a very long way since 2000. More than 135 different algorithms have been recently reviewed by Scharstein et al <a class="link-external link-http" href="http://vision.middlebury.edu/flow/" rel="external noopener nofollow">this http URL</a>. These new algorithms differ markedly from Block Matching which has been the mainstay of video compression for some time. This paper presents comparisons of H.264 and MP4 compression using different motion estimation methods. In so doing we present as well methods for adapting pre-computed motion fields for use within a codec. We do not observe significant gains to be had with the methods chosen w.r.t. Rate Distortion tradeoffs but the results reflect a significantly more complex interrelationship between motion and compression than would be expected. There remains much more to be done to improve the coverage of this comparison to the emerging standards but these initial results show that there is value in these explorations.      
### 10.Dynamic residential load scheduling based on an adaptive consumption level pricing scheme  [ :arrow_down: ](https://arxiv.org/pdf/2007.11932.pdf)
>  Demand response (DR) for smart grids, which intends to balance the required power demand with the available supply resources, has been gaining widespread attention. The growing demand for electricity has presented new opportunities for residential load scheduling systems to improve energy consumption by shifting or curtailing the demand required with respect to price change or emergency cases. In this paper, a dynamic residential load scheduling system (DRLS) is proposed for optimal scheduling of household appliances on the basis of an adaptive consumption level (CL) pricing scheme (ACLPS). The proposed load scheduling system encourages customers to manage their energy consumption within the allowable consumption allowance (CA) of the proposed DR pricing scheme to achieve lower energy bills. Simulation results show that employing the proposed DRLS system benefits the customers by reducing their energy bill and the utility companies by decreasing the peak load of the aggregated load demand. For a given case study, the proposed residential load scheduling system based on ACLPS allows customers to reduce their energy bills by up to 53% and to decrease the peak load by up to 35%.      
### 11.Sub-Nyquist Co-Prime Sensing with Compressed Inter-Element Spacing -- Low Latency Approach  [ :arrow_down: ](https://arxiv.org/pdf/2007.11918.pdf)
>  Co-prime arrays with compressed inter-element spacing (CACIS) is one of the generalizations of the co-prime array. The inter-element spacing can be varied in this case. The prototype co-prime arrays and nested arrays are a special case of the CACIS scheme. The problems that were not addressed previously are considered in this paper. The fundamentals of the difference set for the CACIS configuration are developed for low latency. In addition, the closed-form expressions for the weight function (number of samples that contribute to estimate the autocorrelation) and bias window of the correlogram estimate, which were previously unknown, are derived. Ideally, the bias window should be an impulse. Several examples are provided along with simulations to verify the claims made. All possible sample pairs are used for estimation, which provides for low latency. As an application, temporal spectrum is considered for simulations.      
### 12.Simulation of Blockchain based Power Trading with Solar Power Prediction in Prosumer Consortium Model  [ :arrow_down: ](https://arxiv.org/pdf/2007.11885.pdf)
>  Prosumer consortium in a local group can be one of the solutions for energy costs, increasing performance and supplying university with improved electrification with distributed power generations. This research study demonstrates the simulation of blockchain based power trading with the supplement of solar power prediction with MLFF neural network training in two prosumer nodes. It can be the forefront to implement a market model with distributed generations based decentralized blockchain system in a university grid system which can balance the electricity demand and supply within the institute market, secure and rapid transaction, moreover, the local market system can be reinforced by forecasting solar generation. The performance of the MLFF training to predict the Because of it, prosumer bodies can do decision making before trading as for their benefit.      
### 13.Deep Spatial-angular Regularization for Compressive Light Field Reconstruction over Coded Apertures  [ :arrow_down: ](https://arxiv.org/pdf/2007.11882.pdf)
>  Coded aperture is a promising approach for capturing the 4-D light field (LF), in which the 4-D data are compressively modulated into 2-D coded measurements that are further decoded by reconstruction algorithms. The bottleneck lies in the reconstruction algorithms, resulting in rather limited reconstruction quality. To tackle this challenge, we propose a novel learning-based framework for the reconstruction of high-quality LFs from acquisitions via learned coded apertures. The proposed method incorporates the measurement observation into the deep learning framework elegantly to avoid relying entirely on data-driven priors for LF reconstruction. Specifically, we first formulate the compressive LF reconstruction as an inverse problem with an implicit regularization term. Then, we construct the regularization term with an efficient deep spatial-angular convolutional sub-network to comprehensively explore the signal distribution free from the limited representation ability and inefficiency of deterministic mathematical modeling. Experimental results show that the reconstructed LFs not only achieve much higher PSNR/SSIM but also preserve the LF parallax structure better, compared with state-of-the-art methods on both real and synthetic LF benchmarks. In addition, experiments show that our method is efficient and robust to noise, which is an essential advantage for a real camera system. The code is publicly available at \url{<a class="link-external link-https" href="https://github.com/angmt2008/LFCA" rel="external noopener nofollow">this https URL</a>}      
### 14.Regularization of Building Boundaries in Satellite Images using Adversarial and Regularized Losses  [ :arrow_down: ](https://arxiv.org/pdf/2007.11840.pdf)
>  In this paper we present a method for building boundary refinement and regularization in satellite images using a fully convolutional neural network trained with a combination of adversarial and regularized losses. Compared to a pure Mask R-CNN model, the overall algorithm can achieve equivalent performance in terms of accuracy and completeness. However, unlike Mask R-CNN that produces irregular footprints, our framework generates regularized and visually pleasing building boundaries which are beneficial in many applications.      
### 15.A Non-Intrusive Load Monitoring Approach for Very Short Term Power Predictions in Commercial Buildings  [ :arrow_down: ](https://arxiv.org/pdf/2007.11819.pdf)
>  This paper presents a new algorithm to extract device profiles fully unsupervised from three phases reactive and active aggregate power measurements. The extracted device profiles are applied for the disaggregation of the aggregate power measurements using particle swarm optimization. Finally, this paper provides a new approach for short term power predictions using the disaggregation data. For this purpose, a state changes forecast for every device is carried out by an artificial neural network and converted into a power prediction afterwards by reconstructing the power regarding the state changes and the device profiles. The forecast horizon is 15 minutes. To demonstrate the developed approaches, three phase reactive and active aggregate power measurements of a multi-tenant commercial building are used. The granularity of data is 1 s. In this work, 52 device profiles are extracted from the aggregate power data. The disaggregation shows a very accurate reconstruction of the measured power with a percentage energy error of approximately 1 %. The developed indirect power prediction method applied to the measured power data outperforms two persistence forecasts and an artificial neural network, which is designed for 24h-day-ahead power predictions working in the power domain.      
### 16.Adaptive Control of Time-Varying Parameter Systems with Asymptotic Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2007.11801.pdf)
>  A continuous adaptive control design is developed for nonlinear dynamical systems with linearly parameterizable uncertainty involving time-varying uncertain parameters. The key feature of this design is a robust integral of the sign of the error (RISE)-like term in the adaptation law which compensates for potentially destabilizing terms in the closed-loop error system arising from the time-varying nature of uncertain parameters. A Lyapunov-based stability analysis ensures asymptotic tracking, and boundedness of the closed-loop signals.      
### 17.Sound Field Translation and Mixed Source Model for Virtual Applications with Perceptual Validation  [ :arrow_down: ](https://arxiv.org/pdf/2007.11795.pdf)
>  Non-interactive and linear experiences like cinema film offer high quality surround sound audio to enhance immersion, however the listener's experience is usually fixed to a single acoustic perspective. With the rise of virtual reality, there is a demand for recording and recreating real-world experiences in a way that allows for the user to interact and move within the reproduction. Conventional sound field translation techniques take a recording and expand it into an equivalent environment of virtual sources. However, the finite sampling of a commercial higher order microphone produces an acoustic sweet-spot in the virtual reproduction. As a result, the technique remains to restrict the listener's navigable region. In this paper, we propose a method for listener translation in an acoustic reproduction that incorporates a mixture of near-field and far-field sources in a sparsely expanded virtual environment. We perceptually validate the method through a Multiple Stimulus with Hidden Reference and Anchor (MUSHRA) experiment. Compared to the planewave benchmark, the proposed method offers both improved source localizability and robustness to spectral distortions at translated positions. A cross-examination with numerical simulations demonstrated that the sparse expansion relaxes the inherent sweet-spot constraint, leading to the improved localizability for sparse environments. Additionally, the proposed method is seen to better reproduce the intensity and binaural room impulse response spectra of near-field environments, further supporting the strong perceptual results.      
### 18.Deep Learning Based Segmentation of Various Brain Lesions for Radiosurgery  [ :arrow_down: ](https://arxiv.org/pdf/2007.11784.pdf)
>  Semantic segmentation of medical images with deep learning models is rapidly developed. In this study, we benchmarked state-of-the-art deep learning segmentation algorithms on our clinical stereotactic radiosurgery dataset, demonstrating the strengths and weaknesses of these algorithms in a fairly practical scenario. In particular, we compared the model performances with respect to their sampling method, model architecture, and the choice of loss functions, identifying the suitable settings for their applications and shedding light on the possible improvements.      
### 19.Grid-Coupled Dynamic Response of Battery-Driven Voltage Source Converters  [ :arrow_down: ](https://arxiv.org/pdf/2007.11776.pdf)
>  With the increasing interest in converter-fed islanded microgrids, particularly for resilience, it is becoming more critical to understand the dynamical behavior of these systems. This paper takes a holistic view of grid-forming converters and considers control approaches for both modeling and regulating the DC-link voltage when the DC-source is a battery energy storage system. We are specifically interested in understanding the performance of these controllers, subject to large load changes, for decreasing values of the DC-side capacitance. We consider a fourth, second, and zero-order model of the battery; and establish that the zero-order model captures the dynamics of interest for the timescales considered for disturbances examined. Additionally, we adapt a grid search for optimizing the controller parameters of the DC/DC controller and show how the inclusion of AC side measurements into the DC/DC controller can improve its dynamic performance. This improvement in performance offers the opportunity to reduce the DC-side capacitance given an admissible DC voltage transient deviation, thereby, potentially allowing for more reliable capacitor technology to be deployed.      
### 20.Guided Deep Decoder: Unsupervised Image Pair Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2007.11766.pdf)
>  The fusion of input and guidance images that have a tradeoff in their information (e.g., hyperspectral and RGB image fusion or pansharpening) can be interpreted as one general problem. However, previous studies applied a task-specific handcrafted prior and did not address the problems with a unified approach. To address this limitation, in this study, we propose a guided deep decoder network as a general prior. The proposed network is composed of an encoder-decoder network that exploits multi-scale features of a guidance image and a deep decoder network that generates an output image. The two networks are connected by feature refinement units to embed the multi-scale features of the guidance image into the deep decoder network. The proposed network allows the network parameters to be optimized in an unsupervised way without training data. Our results show that the proposed network can achieve state-of-the-art performance in various image fusion problems.      
### 21.Leading Cruise Control in Mixed Traffic Flow  [ :arrow_down: ](https://arxiv.org/pdf/2007.11753.pdf)
>  Vehicle-to-vehicle (V2V) communications have a great potential to improve traffic system performance. Most existing work of connected and autonomous vehicles (CAVs) focused on adaptation to downstream traffic conditions, neglecting the impact of CAVs' behaviors on upstream traffic flow. In this paper, we introduce a notion of Leading Cruise Control (LCC) that retains the basic car-following operation and explicitly considers the influence of the CAV's actions on the vehicles behind. We first present a detailed modeling process for LCC. Then, rigorous controllability analysis verifies the feasibility of exploiting the CAV as a leader to actively lead the motion of its following vehicles. Besides, the head-to-tail transfer function is derived for LCC under adequate employment of V2V connectivity. Numerical studies confirm the potential of LCC to strengthen the capability of CAVs in suppressing traffic instabilities and smoothing traffic flow.      
### 22.Sequential Routing Framework: Fully Capsule Network-based Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2007.11747.pdf)
>  Capsule networks (CapsNets) have recently gotten attention as alternatives for convolutional neural networks (CNNs) with their greater hierarchical representation capabilities. In this paper, we introduce the sequential routing framework (SRF) which we believe is the first method to adapt a CapsNet-only structure to sequence-to-sequence recognition. In SRF, input sequences are capsulized then sliced by the window size. Each sliced window is classified to a label at the corresponding time through iterative routing mechanisms. Afterwards, training losses are computed using connectionist temporal classification (CTC). During routing, two kinds of information, learnable weights and iteration outputs are shared across the slices. By sharing the information, the required parameter numbers can be controlled by the given window size regardless of the length of sequences. Moreover, the method can minimize decoding speed degradation caused by the routing iterations since it can operate in a non-iterative manner at inference time without dropping accuracy. We empirically proved the validity of our method by performing phoneme sequence recognition tasks on the TIMIT corpus. The proposed method attains an 82.6% phoneme recognition rate. It is 0.8% more accurate than that of CNN-based CTC networks and on par with that of recurrent neural network transducers (RNN-Ts). Even more, the method requires less than half the parameters compared to the two architectures.      
### 23.A weakly supervised registration-based framework for prostate segmentation via the combination of statistical shape model and CNN  [ :arrow_down: ](https://arxiv.org/pdf/2007.11726.pdf)
>  Precise determination of target is an essential procedure in prostate interventions, such as the prostate biopsy, lesion detection and targeted therapy. However, the prostate delineation may be tough in some cases due to tissue ambiguity or lack of partial anatomical boundary. To address this problem, we proposed a weakly supervised registration-based framework for the precise prostate segmentation, by combining convolutional neural network (CNN) with statistical shape model (SSM). To obtain the prostate region, an inception-based neural network (SSM-Net) was firstly exploited to predict the model transform, shape control parameters and a fine-tuning vector, for the generation of prostate boundary. According to the inferred boundary, a normalized distance map was calculated. Then, a residual U-net (ResU-Net) was employed to predict a probability label map from the input images. Finally, the average of the distance map and the probability map was regarded as the prostate segmentation. After that, two public dataset PROMISE12 and NCI- ISBI 2013 were utilized for the model computation and for the network training and testing. The validation results demonstrate that the segmentation framework using a SSM with 9500 nodes achieved the best performance, with a dice of 0.904 and an average surface distance of 1.88 mm. In addition, we verified the impact of model elasticity augmentation and fine-tuning item on the network segmentation capability. As a result, both factors have improved the delineation accuracy, with dice increased by 10% and 7% respectively. In conclusion, via the combination of two weakly supervised neural networks, our segmentation method might be an effective and robust approach for prostate segmentation.      
### 24.Safety-Critical Model Predictive Control with Discrete-Time Control Barrier Function  [ :arrow_down: ](https://arxiv.org/pdf/2007.11718.pdf)
>  The optimal performance of robotic systems is usually achieved near the limit of state and input bounds. Model predictive control (MPC) is a prevalent strategy to handle these operational constraints, however, safety still remains an open challenge for MPC as it needs to guarantee that the system stays within an invariant set. In order to obtain safe optimal performance in the context of set invariance, we present a safety-critical model predictive control strategy utilizing discrete-time control barrier functions (CBFs), which guarantees system safety and accomplishes optimal performance via model predictive control. We analyze the stability and the feasibility properties of our control design. We verify the properties of our method on a 2D double integrator model for obstacle avoidance. We also validate the algorithm numerically using a competitive car racing example, where the ego car is able to overtake other racing cars.      
### 25.Model-Agnostic Algorithm for Real-Time Attack Identification in Power Grid using Koopman Modes  [ :arrow_down: ](https://arxiv.org/pdf/2007.11717.pdf)
>  Malicious activities on measurements from sensors like Phasor Measurement Units (PMUs) can mislead the control center operator into taking wrong control actions resulting in disruption of operation, financial losses, and equipment damage. In particular, false data attacks initiated during power systems transients caused due to abrupt changes in load and generation can fool the conventional model-based detection methods relying on thresholds comparison to trigger an anomaly. In this paper, we propose a Koopman mode decomposition (KMD) based algorithm to detect and identify false data attacks in real-time. The Koopman modes (KMs) are capable of capturing the nonlinear modes of oscillation in the transient dynamics of the power networks and reveal the spatial embedding of both natural and anomalous modes of oscillations in the sensor measurements. The Koopman-based spatio-temporal nonlinear modal analysis is used to filter out the false data injected by an attacker. The performance of the algorithm is illustrated on the IEEE 68-bus test system using synthetic attack scenarios generated on GridSTAGE, a recently developed multivariate spatio-temporal data generation framework for simulation of adversarial scenarios in cyber-physical power systems.      
### 26.Epileptic Seizure Prediction: A Semi-Dilated Convolutional Neural Network Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2007.11716.pdf)
>  Accurate prediction of epileptic seizures has remained elusive, despite the many advances in machine learning and time-series classification. In this work, we develop a convolutional network module that exploits Electroencephalogram (EEG) scalograms to distinguish between the pre-seizure and normal brain activities. Since these scalograms have rectangular image shapes with many more temporal bins than spectral bins, the presented module uses "semi-dilated convolutions" to create a proportional non-square receptive field. The proposed semi-dilated convolutions support exponential expansion of the receptive field over the long dimension (image width, i.e. time) while maintaining high resolution over the short dimension (image height, i.e., frequency). The proposed architecture comprises a set of co-operative semi-dilated convolutional blocks, each block has a stack of parallel semi-dilated convolutional modules with different dilation rates. Results show that our proposed solution outperforms the state-of-the-art methods, achieving seizure prediction sensitivity scores of 88.45% and 89.52% for the American Epilepsy Society and Melbourne University EEG datasets, respectively.      
### 27.Distributed Power Apportioning with Early Dispatch for Ancillary Services in Renewable Grids  [ :arrow_down: ](https://arxiv.org/pdf/2007.11715.pdf)
>  This article develops a distributed framework for coordinating distributed energy resources (DERs) in a power network to provide secondary frequency response (SFR) as an ancillary service to the bulk power system. A distributed finite-time protocol-based solution is adopted that allows each DER in the network to determine power reference commands. The distributed protocol respects information exchange constraints posed by a communication network layer while being robust to delays in the communications channels. The proposed framework enables coordinated response and control of the aggregated DERs by apportioning the share of generation that each DER needs to provide towards meeting any specified global SFR command while allowing for adjustments due to variability in generation and demand in order to prioritize renewable energy sources in the network. A novel early dispatch mechanism with brown start is synthesized to achieve initial DER response to changing SFR commands that is faster than state-of-the-art distributed approaches. The proposed power apportioning protocol is validated using an end-to-end power hardware-in-the-loop configuration at a distribution system scale with 40+ physical hardware DERs, underlying 7-MW power system model, a 250-DER communication topology with physical and simulated distributed controller nodes, varied communication protocols, and an underlying real-world power system model. Experimental results demonstrate the efficacy of the proposed method toward distributed coordination of hundreds of DERs for providing fast response at SFR timescales.      
### 28.Analysis and Optimization for IRS-Aided Multi-pair Communications Relying on Statistical CSI  [ :arrow_down: ](https://arxiv.org/pdf/2007.11704.pdf)
>  In this paper, we investigate an intelligent reflecting surface (IRS) assisted multi-pair communication system, in which multiple pairs of users exchange information via an IRS. We derive an approximate expression for the achievable rate when only statistical channel state information (CSI) is available. Then, a genetic algorithm (GA) is proposed to solve the rate maximization problem. In particular, both the scenarios of continuous phase shift (CPS) and discrete phase shift (DPS) are considered. Simulation results verify the correctness of our derived results and show that the proposed GA method has almost the same performance as the globally optimal solution obtained by the exhaustive search method. In addition, three bits for discretization are capable of achieving a large portion of the achievable rate for the CPS case.      
### 29.Multi-modality imaging with structure-promoting regularisers  [ :arrow_down: ](https://arxiv.org/pdf/2007.11689.pdf)
>  Imaging with multiple modalities or multiple channels is becoming increasingly important for our modern society. A key tool for understanding and early diagnosis of cancer and dementia is PET-MR, a combined positron emission tomography and magnetic resonance imaging scanner which can simultaneously acquire functional and anatomical data. Similarly in remote sensing, while hyperspectral sensors may allow to characterise and distinguish materials, digital cameras offer high spatial resolution to delineate objects. In both of these examples, the imaging modalities can be considered individually or jointly. In this chapter we discuss mathematical approaches which allow to combine information from several imaging modalities so that multi-modality imaging can be more than just the sum of its components.      
### 30.Darwin's Neural Network: AI-based Strategies for Rapid and Scalable Cell and Coronavirus Screening  [ :arrow_down: ](https://arxiv.org/pdf/2007.11653.pdf)
>  Recent advances in the interdisciplinary scientific field of machine perception, computer vision, and biomedical engineering underpin a collection of machine learning algorithms with a remarkable ability to decipher the contents of microscope and nanoscope images. Machine learning algorithms are transforming the interpretation and analysis of microscope and nanoscope imaging data through use in conjunction with biological imaging modalities. These advances are enabling researchers to carry out real-time experiments that were previously thought to be computationally impossible. Here we adapt the theory of survival of the fittest in the field of computer vision and machine perception to introduce a new framework of multi-class instance segmentation deep learning, Darwin's Neural Network (DNN), to carry out morphometric analysis and classification of COVID19 and MERS-CoV collected in vivo and of multiple mammalian cell types in vitro.      
### 31.Mean Square Optimal Control by Interconnection for Linear Stochastic Hamiltonian Systems  [ :arrow_down: ](https://arxiv.org/pdf/2007.11649.pdf)
>  This paper is concerned with linear stochastic Hamiltonian (LSH) systems subject to random external forces. Their dynamics are modelled by linear stochastic differential equations, parameterised by stiffness, mass, damping and coupling matrices. A class of physical couplings is discussed for such systems using inerters, springs and dampers. We consider a problem of minimising a steady-state quadratic cost functional over the coupling parameters for the interconnection of two LSH systems, one of which plays the role of an analog controller. For this mean square optimal control-by-interconnection setting, we outline first-order necessary conditions of optimality which employ variational methods developed previously for constrained linear quadratic Gaussian control problems.      
### 32.Is Multichannel Access Useful in Timely Information Update?  [ :arrow_down: ](https://arxiv.org/pdf/2007.12136.pdf)
>  This paper investigates information freshness of multichannel access in information update systems. Age of information (AoI) is a fundamentally important metric to characterize information freshness, defined as the time elapsed since the generation of the last successfully received update. When multiple devices share the same wireless channel to send updates to a common receiver, an interesting question is whether dividing the whole channel into several subchannels will lead to better AoI performance. Given the same frequency band, dividing it into different numbers of subchannels lead to different transmission times and packet error rates (PER) of short update packets, thus affecting information freshness. We focus on a multichannel access system where different devices take turns to transmit with a cyclic schedule repeated over time. We first derive the average AoI by estimating the PERs of short packets. Then we examine bounded AoI, for which the instantaneous AoI is required to be below a threshold a large percentage of the time. Simulation results indicate that multichannel access can provide low average AoI and uniform bounded AoI simultaneously across different received powers. Overall, our investigations provide insights into practical designs of multichannel access systems with AoI requirements.      
### 33.Sound2Sight: Generating Visual Dynamics from Sound and Context  [ :arrow_down: ](https://arxiv.org/pdf/2007.12130.pdf)
>  Learning associations across modalities is critical for robust multimodal reasoning, especially when a modality may be missing during inference. In this paper, we study this problem in the context of audio-conditioned visual synthesis -- a task that is important, for example, in occlusion reasoning. Specifically, our goal is to generate future video frames and their motion dynamics conditioned on audio and a few past frames. To tackle this problem, we present Sound2Sight, a deep variational framework, that is trained to learn a per frame stochastic prior conditioned on a joint embedding of audio and past frames. This embedding is learned via a multi-head attention-based audio-visual transformer encoder. The learned prior is then sampled to further condition a video forecasting module to generate future frames. The stochastic prior allows the model to sample multiple plausible futures that are consistent with the provided audio and the past context. Moreover, to improve the quality and coherence of the generated frames, we propose a multimodal discriminator that differentiates between a synthesized and a real audio-visual clip. We empirically evaluate our approach, vis-รก-vis closely-related prior methods, on two new datasets viz. (i) Multimodal Stochastic Moving MNIST with a Surprise Obstacle, (ii) Youtube Paintings; as well as on the existing Audio-Set Drums dataset. Our extensive experiments demonstrate that Sound2Sight significantly outperforms the state of the art in the generated video quality, while also producing diverse video content.      
### 34.Augmentation adversarial training for unsupervised speaker recognition  [ :arrow_down: ](https://arxiv.org/pdf/2007.12085.pdf)
>  The goal of this work is to train robust speaker recognition models without speaker labels. Recent works on unsupervised speaker representations are based on contrastive learning in which they encourage within-utterance embeddings to be similar and across-utterance embeddings to be dissimilar. However, since the within-utterance segments share the same acoustic characteristics, it is difficult to separate the speaker information from the channel information. To this end, we propose augmentation adversarial training strategy that trains the network to be discriminative for the speaker information, while invariant to the augmentation applied. Since the augmentation simulates the acoustic characteristics, training the network to be invariant to augmentation also encourages the network to be invariant to the channel information in general. Extensive experiments on the VoxCeleb and VOiCES datasets show significant improvements over previous works using self-supervision, and the performance of our self-supervised models far exceed that of humans.      
### 35.TSIT: A Simple and Versatile Framework for Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2007.12072.pdf)
>  We introduce a simple and versatile framework for image-to-image translation. We unearth the importance of normalization layers, and provide a carefully designed two-stream generative model with newly proposed feature transformations in a coarse-to-fine fashion. This allows multi-scale semantic structure information and style representation to be effectively captured and fused by the network, permitting our method to scale to various tasks in both unsupervised and supervised settings. No additional constraints (e.g., cycle consistency) are needed, contributing to a very clean and simple method. Multi-modal image synthesis with arbitrary style control is made possible. A systematic study compares the proposed method with several state-of-the-art task-specific baselines, verifying its effectiveness in both perceptual quality and quantitative evaluations.      
### 36.AM-DCGAN: Analog Memristive Hardware Accelerator for Deep Convolutional Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.12063.pdf)
>  Generative Adversarial Network (GAN) is a well known computationally complex algorithm requiring signficiant computational resources in software implementations including large amount of data to be trained. This makes its implementation in edge devices with conventional microprocessor hardware a slow and difficult task. In this paper, we propose to accelerate the computationally intensive GAN using memristive neural networks in analog domain. We present a fully analog hardware design of Deep Convolutional GAN (DCGAN) based on CMOS-memristive convolutional and deconvolutional networks simulated using 180nm CMOS technology.      
### 37.Improving distribution and flexible quantization for DCT coefficients  [ :arrow_down: ](https://arxiv.org/pdf/2007.12055.pdf)
>  While it is a common knowledge that AC coefficients of Fourier-related transforms, like DCT-II of JPEG image compression, are from Laplace distribution, there was tested more general EPD (exponential power distribution) $\rho\sim \exp(-|x|^{\kappa})$ family, leading to maximum likelihood estimated (MLE) $\kappa\approx 0.5$ instead of Laplace distribution $\kappa=1$ - such replacement gives $\approx 0.1$ bits/value mean savings. Additional general observation here is that standard uniform division into odd number of quantization regions gets significantly lower mean distortion than for even. <br>Especially for such continuous distributions, there is also discussed quantization approach through optimized continuous \emph{quantization density function} $q$, which inverse CDF (cumulative distribution function) $Q$ on regular lattice $\{Q^{-1}((i-1/2)/N):i=1\ldots N\}$ gives quantization nodes - allowing for flexible inexpensive choice of optimized (non-uniform) quantization - of varying size $N$, with rate-distortion control. Optimizing $q$ for distortion alone leads to significant improvement, however, at cost of increased entropy due to more uniform distribution. Optimizing both turns out leading to nearly uniform quantization here, with automatized tail handling.      
### 38.Robust Control Synthesis and Verification for Wire-Borne Underactuated Brachiating Robots Using Sum-of-Squares Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2007.12047.pdf)
>  Control of wire-borne underactuated brachiating robots requires a robust feedback control design that can deal with dynamic uncertainties, actuator constraints and unmeasurable states. In this paper, we develop a robust feedback control for brachiating on flexible cables, building on previous work on optimal trajectory generation and time-varying LQR controller design. We propose a novel simplified model for approximation of the flexible cable dynamics, which enables inclusion of parametric model uncertainties in the system. We then use semidefinite programming (SDP) and sum-of-squares (SOS) optimization to synthesize a time-varying feedback control with formal robustness guarantees to account for model uncertainties and unmeasurable states in the system. Through simulation, hardware experiments and comparison with a time-varying LQR controller, it is shown that the proposed robust controller results in relatively large robust backward reachable sets and is able to reliably track a pre-generated optimal trajectory and achieve the desired brachiating motion in the presence of parametric model uncertainties, actuator limits, and unobservable states.      
### 39.AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification  [ :arrow_down: ](https://arxiv.org/pdf/2007.12034.pdf)
>  Convolutional operations have two limitations: (1) do not explicitly model where to focus as the same filter is applied to all the positions, and (2) are unsuitable for modeling long-range dependencies as they only operate on a small neighborhood. While both limitations can be alleviated by attention operations, many design choices remain to be determined to use attention, especially when applying attention to videos. Towards a principled way of applying attention to videos, we address the task of spatiotemporal attention cell search. We propose a novel search space for spatiotemporal attention cells, which allows the search algorithm to flexibly explore various design choices in the cell. The discovered attention cells can be seamlessly inserted into existing backbone networks, e.g., I3D or S3D, and improve video classification accuracy by more than 2% on both Kinetics-600 and MiT datasets. The discovered attention cells outperform non-local blocks on both datasets, and demonstrate strong generalization across different modalities, backbones, and datasets. Inserting our attention cells into I3D-R50 yields state-of-the-art performance on both datasets.      
### 40.Blackout Resilient Optical Core Network  [ :arrow_down: ](https://arxiv.org/pdf/2007.11930.pdf)
>  A disaster may not necessarily demolish the telecommunications infrastructure, but instead it might affect the national grid and cause blackouts, consequently disrupting the network operation unless there is an alternative power source(s). In this paper, power outages are considered, and the telecommunication network performance is evaluated during a blackout. Two approaches are presented to minimize the impact of power outage and maximize the survival time of the blackout node. A mixed integer linear programming (MILP) model is developed to evaluate the network performance under a single node blackout scenario. The model is used to evaluate the network under the two proposed scenarios. The results show that the proposed approach succeeds in extending the network life time while minimizing the required amount of backup energy.      
### 41.Multi-Compartment Variational Online Learning for Spiking Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.11894.pdf)
>  Spiking Neural Networks (SNNs) offer a novel computational paradigm that captures some of efficiency of biological brains for inference and learning via recursive processing and binary neural activations. Most existing training algorithms for SNNs assume spiking neuron models in which a neuron outputs individual spikes as a function of the dynamics of an internal state variable known as membrane potential. This paper explores a more general model in which each spiking neuron contains multiple compartments, each tracking the dynamics of a distinct membrane potential, while sharing the same synaptic weights across compartments. It is demonstrated that learning rules based on probabilistic generalized linear neural models can leverage the presence of multiple compartments through modern variational inference based on importance weighting or generalized expectation-maximization. The key idea is to use the neural compartments to sample multiple independent spiking signals from hidden neurons so as to obtain better statistical estimates of the likelihood training criterion. The derived online learning algorithms follow three-factor rules with global learning signals. Experimental results on a structured output memorization task and classification task with a standard neuromorphic data set demonstrate significant improvements in terms of accuracy and calibration with an increasing number of compartments.      
### 42.Real-time CNN-based Segmentation Architecture for Ball Detection in a Single View Setup  [ :arrow_down: ](https://arxiv.org/pdf/2007.11876.pdf)
>  This paper considers the task of detecting the ball from a single viewpoint in the challenging but common case where the ball interacts frequently with players while being poorly contrasted with respect to the background. We propose a novel approach by formulating the problem as a segmentation task solved by an efficient CNN architecture. To take advantage of the ball dynamics, the network is fed with a pair of consecutive images. Our inference model can run in real time without the delay induced by a temporal analysis. We also show that test-time data augmentation allows for a significant increase the detection accuracy. As an additional contribution, we publicly release the dataset on which this work is based.      
### 43.An Experimental mmWave Channel Model for UAV-to-UAV Communications  [ :arrow_down: ](https://arxiv.org/pdf/2007.11869.pdf)
>  Unmanned Aerial Vehicle (UAV) networks can provide a resilient communication infrastructure to enhance terrestrial networks in case of traffic spikes or disaster scenarios. However, to be able to do so, they need to be based on high-bandwidth wireless technologies for both radio access and backhaul. With this respect, the millimeter wave (mmWave) spectrum represents an enticing solution, since it provides large chunks of untapped spectrum that can enable ultra-high data-rates for aerial platforms. Aerial mmWave channels, however, experience characteristics that are significantly different from terrestrial deployments in the same frequency bands. As of today, mmWave aerial channels have not been extensively studied and modeled. Specifically, the combination of UAV micro-mobility (because of imprecisions in the control loop, and external factors including wind) and the highly directional mmWave transmissions require ad hoc models to accurately capture the performance of UAV deployments. To fill this gap, we propose an empirical propagation loss model for UAV-to-UAV communications at 60 GHz, based on an extensive aerial measurement campaign conducted with the Facebook Terragraph channel sounders. We compare it with 3GPP channel models and make the measurement dataset publicly available.      
### 44.End-to-end Learning of Compressible Features  [ :arrow_down: ](https://arxiv.org/pdf/2007.11797.pdf)
>  Pre-trained convolutional neural networks (CNNs) are powerful off-the-shelf feature generators and have been shown to perform very well on a variety of tasks. Unfortunately, the generated features are high dimensional and expensive to store: potentially hundreds of thousands of floats per example when processing videos. Traditional entropy based lossless compression methods are of little help as they do not yield desired level of compression, while general purpose lossy compression methods based on energy compaction (e.g. PCA followed by quantization and entropy coding) are sub-optimal, as they are not tuned to task specific objective. We propose a learned method that jointly optimizes for compressibility along with the task objective for learning the features. The plug-in nature of our method makes it straight-forward to integrate with any target objective and trade-off against compressibility. We present results on multiple benchmarks and demonstrate that our method produces features that are an order of magnitude more compressible, while having a regularization effect that leads to a consistent improvement in accuracy.      
### 45.Illumination invariant hyperspectral image unmixing based on a digital surface model  [ :arrow_down: ](https://arxiv.org/pdf/2007.11770.pdf)
>  Although many spectral unmixing models have been developed to address spectral variability caused by variable incident illuminations, the mechanism of the spectral variability is still unclear. This paper proposes an unmixing model, named illumination invariant spectral unmixing (IISU). IISU makes the first attempt to use the radiance hyperspectral data and a LiDAR-derived digital surface model (DSM) in order to physically explain variable illuminations and shadows in the unmixing framework. Incident angles, sky factors, visibility from the sun derived from the LiDAR-derived DSM support the explicit explanation of endmember variability in the unmixing process from radiance perspective. The proposed model was efficiently solved by a straightforward optimization procedure. The unmixing results showed that the other state-of-the-art unmixing models did not work well especially in the shaded pixels. On the other hand, the proposed model estimated more accurate abundances and shadow compensated reflectance than the existing models.      
### 46.History Repeats Itself: Human Motion Prediction via Motion Attention  [ :arrow_down: ](https://arxiv.org/pdf/2007.11755.pdf)
>  Human motion prediction aims to forecast future human poses given a past motion. Whether based on recurrent or feed-forward neural networks, existing methods fail to model the observation that human motion tends to repeat itself, even for complex sports actions and cooking activities. Here, we introduce an attention-based feed-forward network that explicitly leverages this observation. In particular, instead of modeling frame-wise attention via pose similarity, we propose to extract motion attention to capture the similarity between the current motion context and the historical motion sub-sequences. Aggregating the relevant past motions and processing the result with a graph convolutional network allows us to effectively exploit motion patterns from the long-term history to predict the future poses. Our experiments on Human3.6M, AMASS and 3DPW evidence the benefits of our approach for both periodical and non-periodical actions. Thanks to our attention model, it yields state-of-the-art results on all three datasets. Our code is available at <a class="link-external link-https" href="https://github.com/wei-mao-2019/HisRepItself" rel="external noopener nofollow">this https URL</a>.      
### 47.Threat of Adversarial Attacks on Face Recognition: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2007.11709.pdf)
>  Face recognition (FR) systems have demonstrated outstanding verification performance, suggesting suitability for real-world applications, ranging from photo tagging in social media to automated border control (ABC). In an advanced FR system with deep learning-based architecture, however, promoting the recognition efficiency alone is not sufficient and the system should also withstand potential kinds of attacks designed to target its proficiency. Recent studies show that (deep) FR systems exhibit an intriguing vulnerability to imperceptible or perceptible but natural-looking adversarial input images that drive the model to incorrect output predictions. In this article, we present a comprehensive survey on adversarial attacks against FR systems and elaborate on the competence of new countermeasures against them. Further, we propose a taxonomy of existing attack and defense strategies according to different criteria. Finally, we compare the presented approaches according to techniques' characteristics.      
### 48.Attention based Multiple Instance Learning for Classification of Blood Cell Disorders  [ :arrow_down: ](https://arxiv.org/pdf/2007.11641.pdf)
>  Red blood cells are highly deformable and present in various shapes. In blood cell disorders, only a subset of all cells is morphologically altered and relevant for the diagnosis. However, manually labeling of all cells is laborious, complicated and introduces inter-expert variability. We propose an attention based multiple instance learning method to classify blood samples of patients suffering from blood cell disorders. Cells are detected using an R-CNN architecture. With the features extracted for each cell, a multiple instance learning method classifies patient samples into one out of four blood cell disorders. The attention mechanism provides a measure of the contribution of each cell to the overall classification and significantly improves the network's classification accuracy as well as its interpretability for the medical expert.      
### 49.Subjective and Objective Quality Assessment of High Frame Rate Videos  [ :arrow_down: ](https://arxiv.org/pdf/2007.11634.pdf)
>  High frame rate (HFR) videos are becoming increasingly common with the tremendous popularity of live, high-action streaming content such as sports. Although HFR contents are generally of very high quality, high bandwidth requirements make them challenging to deliver efficiently, while simultaneously maintaining their quality. To optimize trade-offs between bandwidth requirements and video quality, in terms of frame rate adaptation, it is imperative to understand the intricate relationship between frame rate and perceptual video quality. Towards advancing progression in this direction we designed a new subjective resource, called the LIVE-YouTube-HFR (LIVE-YT-HFR) dataset, which is comprised of 480 videos having 6 different frame rates, obtained from 16 diverse contents. In order to understand the combined effects of compression and frame rate adjustment, we also processed videos at 5 compression levels at each frame rate. To obtain subjective labels on the videos, we conducted a human study yielding 19,000 human quality ratings obtained from a pool of 85 human subjects. We also conducted a holistic evaluation of existing state-of-the-art Full and No-Reference video quality algorithms, and statistically benchmarked their performance on the new database. The LIVE-YT-HFR database has been made available online for public use and evaluation purposes, with hopes that it will help advance research in this exciting video technology direction. It may be obtained at \url{<a class="link-external link-https" href="https://live.ece.utexas.edu/research/LIVE_YT_HFR/LIVE_YT_HFR/index.html" rel="external noopener nofollow">this https URL</a>}      
