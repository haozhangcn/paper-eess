# ArXiv eess --Tue, 26 Oct 2021
### 1.Automatic Impact-sounding Acoustic Inspection of Concrete Structure  [ :arrow_down: ](https://arxiv.org/pdf/2110.13125.pdf)
>  Impact sounding signal has been shown to contain information about structural integrity flaws and subsurface objects from previous research. As non-destructive testing (NDT) method, one of the biggest challenges in impact sounding based inspection is the subsurface targets detection and reconstruction. This paper presents the importance and practicability of using solenoids to trigger impact sounding signal and using acoustic data to reconstruct subsurface objects to address this issue. First, by taking advantage of Visual Simultaneous Localization and Mapping (V-SLAM), we could obtain the 3D position of the robot during the inspection. Second, our NDE method is based on Frequency Density (FD) analysis for the Fast Fourier Transform (FFT) of the impact sounding signal. At last, by combining the 3D position data and acoustic data, this paper creates a 3D map to highlight the possible subsurface objects. The experimental results demonstrate the feasibility of the method.      
### 2.Dual Skip Connections Minimize the False Positive Rate of Lung Nodule Detection in CT images  [ :arrow_down: ](https://arxiv.org/pdf/2110.13036.pdf)
>  Pulmonary cancer is one of the most commonly diagnosed and fatal cancers and is often diagnosed by incidental findings on computed tomography. Automated pulmonary nodule detection is an essential part of computer-aided diagnosis, which is still facing great challenges and difficulties to quickly and accurately locate the exact nodules' positions. This paper proposes a dual skip connection upsampling strategy based on Dual Path network in a U-Net structure generating multiscale feature maps, which aims to minimize the ratio of false positives and maximize the sensitivity for lesion detection of nodules. The results show that our new upsampling strategy improves the performance by having 85.3% sensitivity at 4 FROC per image compared to 84.2% for the regular upsampling strategy or 81.2% for VGG16-based Faster-R-CNN.      
### 3.A Novel Reconstruction Algorithm based on Fractional Fourier Transform for Unlimited Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2110.13003.pdf)
>  The recovery of bandlimited signals with high dynamic range is a hot issue in sampling research. The unlimited sampling theory expands the recordable range of traditional analog-to-digital converters (ADCs) arbitrarily, and the signal is folded back into a low dynamic range measurement, avoiding the saturation problem. We study the unlimited sampling problem of high dynamic nonbandlimited signals in the Fourier domain (FD) based on the fractional Fourier transform (FRFT). First, the modular nonlinear folding is performed in the fractional Fourier domain (FRFD) for modular arithmetic. Then, the fractional spectrum is estimated for any folding time by means of annihilation filtering. Finally, a novel unlimited sampling algorithm in the FRFD is obtained. The results show that the non-bandlimited signal can be reconstructed in the FD based on the FRFT, and it is not affected by the ADC threshold.      
### 4.Reconfigurable and Real-Time Nyquist OTDM Demultiplexing in Silicon Photonics  [ :arrow_down: ](https://arxiv.org/pdf/2110.13002.pdf)
>  We demonstrate for the first time, to the best of our knowledge, reconfigurable and real-time orthogonal time-domain demultiplexing of coherent multilevel Nyquist signals in silicon photonics. No external pulse source is needed and frequencytime coherence is used to sample the incoming Nyquist OTDM signal with orthogonal sinc-shaped Nyquist pulse sequences using Mach-Zehnder modulators. All the parameters such as bandwidth and channel selection are completely tunable in the electrical domain. The feasibility of this scheme is demonstrated through a demultiplexing experiment over the entire C-band (1530 nm - 1550 nm), employing 24 Gbaud Nyquist QAM signals due to experimental constraints on the transmitter side. However, the silicon Mach-Zehnder modulator with a 3-dB bandwidth of only 16 GHz can demultiplex Nyquist pulses of 90 GHz optical bandwidth suggesting a possibility to reach symbol rates up to 90 GBd in an integrated Nyquist transceiver.      
### 5.Real-Time Wave Mitigation for Water-Air OWC Systems Via Beam Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2110.13001.pdf)
>  In a water-air optical wireless communication (OWC) channel, dynamic ocean waves may significantly deflect the light beam from its original direction, thus deteriorating the communication performance. In this letter, a beam tracking system to mitigate wave-induced communication degradation is experimentally demonstrated. By employing the beam tracking on the PAM6 system, a maximum of 486% improvement (from 140 Mb/s to 820 Mb/s) in throughput is realized at a 1.2-m air distance for an average wave slope changing rate of 0.34 rad/s. For PAM4 signals, the packet loss rate reduces significantly from 75% to 11%, and a maximum throughput of 1.25 Gb/s is achieved.      
### 6.Extreme Beam-forming with Metagrating-assisted Planar Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2110.13000.pdf)
>  We present a highly efficient metagrating-assisted antenna (MGA) architecture with a simple integrated feed. Power from a localized line source is distributed throughout the arbitrarily large antenna aperture with the help of a passive and lossless electromagnetic metagrating (MG). With appropriately designed meta-wire loading, the omnidirectional source field can be efficiently transformed into directive radiation. To aid the design process, a 2-dimensional volume-surface integral equation framework which accurately predicts the radiation pattern of the MGA is developed. Through constrained optimization, the directivity of the MGA in the desired direction is maximized. In this way, extreme-angle beam steering is demonstrated.      
### 7.Deep learning-based design of broadband GHz complex and random metasurfaces  [ :arrow_down: ](https://arxiv.org/pdf/2110.12999.pdf)
>  We are interested to explore the limit in using deep learning (DL) to study the electromagnetic response for complex and random metasurfaces, without any specific applications in mind. For simplicity, we focus on a simple pure reflection problem of a broadband electromagnetic (EM) plane wave incident normally on such complex metasurfaces in the frequency regime of 2 to 12 GHz. In doing so, we create a deep learning (DL) based framework called metasurface design deep convolutional neural network (MSDCNN) for both the forward and inverse design of three different classes of complex metasurfaces: (a) Arbitrary connecting polygons, (b) Basic pattern combination, and (c) Fully random binary patterns. The performance of each metasurface is evaluated and cross-benchmarked. Dependent on the type of complex metasurfaces, sample size, and DL algorithms used, MSDCNN is able to provide good agreements and can be a faster design tool for complex metasurfaces as compared to the traditional full-wave electromagnetic simulation methods. However, no single universal deep convolutional neural network (DCNN) model can work well for all metasurface classes based on detailed statistical analysis (such as mean, variance, kurtosis, mean squared error). Our findings report important information on the advantages and limitation of current DL models in designing these ultimately complex metasurfaces.      
### 8.A wavelet-based dynamic mode decomposition for modeling mechanical systems from partial observations  [ :arrow_down: ](https://arxiv.org/pdf/2110.12990.pdf)
>  Dynamic mode decomposition (DMD) has emerged as a popular data-driven modeling approach to identifying spatio-temporal coherent structures in dynamical systems, owing to its strong relation with the Koopman operator. For dynamical systems with external forcing, the identified model should not only be suitable for a specific forcing function but should generally approximate the input-output behavior of the underlying dynamics. A novel methodology for modeling those classes of dynamical systems is proposed in the present work, using wavelets in conjunction with the input-output dynamic mode decomposition (ioDMD). Our non-intrusive approach constructs numerical models directly from trajectories of the full model's inputs and outputs, without requiring the full-model operators. These trajectories are generated by running a simulation of the full model or observing the original dynamical systems' response to inputs in an experimental framework. Hence, the present methodology is applicable for dynamical systems whose internal state vector measurements are not available. Instead, data from only a few output locations are only accessible, as often the case in practice. The present methodology's applicability is explained by modeling the input-output response of a finite element beam model. The WDMD provides a linear state-space representation of the dynamical system using the response measurements and the corresponding input forcing functions. The developed state-space model is then used to simulate the beam's response towards different types of forcing functions. The method is further validated on an experimental data set using modal analysis on a simple free-free beam, demonstrating the efficacy of the proposed methodology as an appropriate candidate for modeling practical dynamical systems despite having no access to internal state measurements and treating the full model as a black-box.      
### 9.Generative Residual Attention Network for Disease Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.12984.pdf)
>  Accurate identification and localization of abnormalities from radiology images serve as a critical role in computer-aided diagnosis (CAD) systems. Building a highly generalizable system usually requires a large amount of data with high-quality annotations, including disease-specific global and localization information. However, in medical images, only a limited number of high-quality images and annotations are available due to annotation expenses. In this paper, we explore this problem by presenting a novel approach for disease generation in X-rays using a conditional generative adversarial learning. Specifically, given a chest X-ray image from a source domain, we generate a corresponding radiology image in a target domain while preserving the identity of the patient. We then use the generated X-ray image in the target domain to augment our training to improve the detection performance. We also present a unified framework that simultaneously performs disease generation and localization.We evaluate the proposed approach on the X-ray image dataset provided by the Radiological Society of North America (RSNA), surpassing the state-of-the-art baseline detection algorithms.      
### 10.Neural ODE and DAE Modules for Power System Dynamic Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2110.12981.pdf)
>  The time-domain simulation is the fundamental tool for power system transient stability analysis. Accurate and reliable simulations rely on accurate dynamic component modeling. In practical power systems, dynamic component modeling has long faced the challenges of model determination and model calibration, especially with the rapid development of renewable generation and power electronics. In this paper, based on the general framework of neural ordinary differential equations (ODEs), a modified neural ODE module and a neural differential-algebraic equations (DAEs) module for power system dynamic component modeling are proposed. The modules adopt an autoencoder to raise the dimension of state variables, model the dynamics of components with artificial neural networks (ANNs), and keep the numerical integration structure. In the neural DAE module, an additional ANN is used to calculate injection currents. The neural models can be easily integrated into time-domain simulations. With datasets consisting of sampled curves of input variables and output variables, the proposed modules can be used to fulfill the tasks of parameter inference, physics-data-integrated modeling, black-box modeling, etc., and can be easily integrated into power system dynamic simulations. Some simple numerical tests are carried out in the IEEE-39 system and prove the validity and potentiality of the proposed modules.      
### 11.Interactive Segmentation via Deep Learning and B-Spline Explicit Active Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2110.12939.pdf)
>  Automatic medical image segmentation via convolutional neural networks (CNNs) has shown promising results. However, they may not always be robust enough for clinical use. Sub-optimal segmentation would require clinician's to manually delineate the target object, causing frustration. To address this problem, a novel interactive CNN-based segmentation framework is proposed in this work. The aim is to represent the CNN segmentation contour as B-splines by utilising B-spline explicit active surfaces (BEAS). The interactive element of the framework allows the user to precisely edit the contour in real-time, and by utilising BEAS it ensures the final contour is smooth and anatomically plausible. This framework was applied to the task of 2D segmentation of the levator hiatus from 2D ultrasound (US) images, and compared to the current clinical tools used in pelvic floor disorder clinic (4DView, GE Healthcare; Zipf, Austria). Experimental results show that: 1) the proposed framework is more robust than current state-of-the-art CNNs; 2) the perceived workload calculated via the NASA-TLX index was reduced more than half for the proposed approach in comparison to current clinical tools; and 3) the proposed tool requires at least 13 seconds less user time than the clinical tools, which was significant (p=0.001).      
### 12.Revealing unforeseen diagnostic image features with deep learning by detecting cardiovascular diseases from apical four-chamber ultrasounds  [ :arrow_down: ](https://arxiv.org/pdf/2110.12915.pdf)
>  Background. With the rise of highly portable, wireless, and low-cost ultrasound devices and automatic ultrasound acquisition techniques, an automated interpretation method requiring only a limited set of views as input could make preliminary cardiovascular disease diagnoses more accessible. In this study, we developed a deep learning (DL) method for automated detection of impaired left ventricular (LV) function and aortic valve (AV) regurgitation from apical four-chamber (A4C) ultrasound cineloops and investigated which anatomical structures or temporal frames provided the most relevant information for the DL model to enable disease classification. <br>Methods and Results. A4C ultrasounds were extracted from 3,554 echocardiograms of patients with either impaired LV function (n=928), AV regurgitation (n=738), or no significant abnormalities (n=1,888). Two convolutional neural networks (CNNs) were trained separately to classify the respective disease cases against normal cases. The overall classification accuracy of the impaired LV function detection model was 86%, and that of the AV regurgitation detection model was 83%. Feature importance analyses demonstrated that the LV myocardium and mitral valve were important for detecting impaired LV function, while the tip of the mitral valve anterior leaflet, during opening, was considered important for detecting AV regurgitation. <br>Conclusion. The proposed method demonstrated the feasibility of a 3D CNN approach in detection of impaired LV function and AV regurgitation using A4C ultrasound cineloops. The current research shows that DL methods can exploit large training data to detect diseases in a different way than conventionally agreed upon methods, and potentially reveal unforeseen diagnostic image features.      
### 13.Anatomical and Diagnostic Bayesian Segmentation in Prostate MRI $-$Should Different Clinical Objectives Mandate Different Loss Functions?  [ :arrow_down: ](https://arxiv.org/pdf/2110.12889.pdf)
>  We hypothesize that probabilistic voxel-level classification of anatomy and malignancy in prostate MRI, although typically posed as near-identical segmentation tasks via U-Nets, require different loss functions for optimal performance due to inherent differences in their clinical objectives. We investigate distribution, region and boundary-based loss functions for both tasks across 200 patient exams from the publicly-available ProstateX dataset. For evaluation, we conduct a thorough comparative analysis of model predictions and calibration, measured with respect to multi-class volume segmentation of the prostate anatomy (whole-gland, transitional zone, peripheral zone), as well as, patient-level diagnosis and lesion-level detection of clinically significant prostate cancer. Notably, we find that distribution-based loss functions (in particular, focal loss) are well-suited for diagnostic or panoptic segmentation tasks such as lesion detection, primarily due to their implicit property of inducing better calibration. Meanwhile, (with the exception of focal loss) both distribution and region/boundary-based loss functions perform equally well for anatomical or semantic segmentation tasks, such as quantification of organ shape, size and boundaries.      
### 14.Multi-vehicle experiment platform: A Digital Twin Realization Method  [ :arrow_down: ](https://arxiv.org/pdf/2110.12859.pdf)
>  With the development of V2X technology, multiple vehicles cooperative control has been widely studied. However, filed testing is rarely conducted due to financial and safety considerations. To solve this problem, this study proposes a digital twin method to carry out multi-vehicle experiments, which uses combination of physical and virtual vehicles to perform coordination tasks. To confirm effectiveness of this method, a prototype system is developed, which consists of sand table testbed, its twin system and cloud. Several aspects are quantified to describe system performance, including time delay and localization accuracy. Finally, a vehicle level experiment in platoon scenario is carried out and experiment results confirm effectiveness of this method.      
### 15.Experimental implementation of an emission-aware prosumer with online flexibility quantification and provision  [ :arrow_down: ](https://arxiv.org/pdf/2110.12831.pdf)
>  Emission-aware and flexible building operation can play a crucial role in the energy transition. On the one hand, building operation accounts for a significant portion of global energy-related emissions. On the other hand, they may provide the future low-carbon energy system with flexibility to achieve secure, stable, and efficient operation. This paper reports an experimental implementation of an emission-aware flexible prosumer considering all behind-the-meter assets of an actual occupied building by incorporating a model predictive control strategy into an existing building energy management system. The resultant can minimize the equivalent carbon emission due to electricity imports and provide flexibility to the energy system. The experimental results indicate an emission reduction of 12.5% compared to a benchmark that maximizes PV self-consumption. In addition, flexibility provision is demonstrated with an emulated distribution system operator. The results suggest that flexibility can be provided without the risk of rebound effects due to the flexibility envelope self-reported in advance.      
### 16.Automatic segmentation of novel coronavirus pneumonia lesions in CT images utilizing deep-supervised ensemble learning network  [ :arrow_down: ](https://arxiv.org/pdf/2110.12827.pdf)
>  Background: The 2019 novel coronavirus disease (COVID-19) has been spread widely in the world, causing a huge threat to people's living environment. Objective: Under computed tomography (CT) imaging, the structure features of COVID-19 lesions are complicated and varied greatly in different cases. To accurately locate COVID-19 lesions and assist doctors to make the best diagnosis and treatment plan, a deep-supervised ensemble learning network is presented for COVID-19 lesion segmentation in CT images. Methods: Considering the fact that a large number of COVID-19 CT images and the corresponding lesion annotations are difficult to obtained, a transfer learning strategy is employed to make up for the shortcoming and alleviate the overfitting problem. Based on the reality that traditional single deep learning framework is difficult to extract COVID-19 lesion features effectively, which may cause some lesions to be undetected. To overcome the problem, a deep-supervised ensemble learning network is presented to combine with local and global features for COVID-19 lesion segmentation. Results: The performance of the proposed method was validated in experiments with a publicly available dataset. Compared with manual annotations, the proposed method acquired a high intersection over union (IoU) of 0.7279. Conclusion: A deep-supervised ensemble learning network was presented for coronavirus pneumonia lesion segmentation in CT images. The effectiveness of the proposed method was verified by visual inspection and quantitative evaluation. Experimental results shown that the proposed mehtod has a perfect performance in COVID-19 lesion segmentation.      
### 17.Raw Bayer Pattern Image Synthesis with Conditional GAN  [ :arrow_down: ](https://arxiv.org/pdf/2110.12823.pdf)
>  In this paper, we propose a method to generate Bayer pattern images by Generative adversarial network (GANs). It is shown theoretically that using the transformed data in GANs training is able to improve the generator learning of the original data distribution, owing to the invariant of Jensen Shannon(JS) divergence between two distributions under invertible and differentiable transformation. The Bayer pattern images can be generated by configuring the transformation as demosaicing, by converting the existing standard color datasets to Bayer domain, the proposed method is promising in the applications such as to find the optimal ISP configuration for computer vision tasks, in the in sensor or near sensor computing, even in photography. Experiments show that the images generated by our proposed method outperform the original Pix2PixHD model in FID score, PSNR, and SSIM, and the training process is more stable. For the situation similar to in sensor or near sensor computing for object detection, by using our proposed method, the model performance can be improved without the modification to the image sensor.      
### 18.On Synchronization of Wireless Acoustic Sensor Networks in the Presence of Time-varying Sampling Rate Offsets and Speaker Changes  [ :arrow_down: ](https://arxiv.org/pdf/2110.12820.pdf)
>  A wireless acoustic sensor network records audio signals with sampling time and sampling rate offsets between the audio streams, if the analog-digital converters (ADCs) of the network devices are not synchronized. Here, we introduce a new sampling rate offset model to simulate time-varying sampling frequencies caused, for example, by temperature changes of ADC crystal oscillators, and propose an estimation algorithm to handle this dynamic aspect in combination with changing acoustic source positions. Furthermore, we show how deep neural network based estimates of the distances between microphones and human speakers can be used to determine the sampling time offsets. This enables a synchronization of the audio streams to reflect the physical time differences of flight.      
### 19.Continuous Reset Element  [ :arrow_down: ](https://arxiv.org/pdf/2110.12801.pdf)
>  This paper addresses the main goal of using reset control in precision motion control systems, breaking of the well-known "Waterbed effect". A new architecture for reset elements will be introduced which has a continuous output signal as opposed to conventional reset elements. A steady-state precision study is presented, showing the steady-state precision is preserved while the peak of sensitivity is reduced. The architecture is then used for a "Constant in Gain Lead in Phase" (CgLp) element and a numerical analysis on transient response shows a significant improvement in transient response. It is shown that by following the presented guideline for tuning, settling time can be reduced and at the same time a no-overshoot step response can be achieved. A practical example is presented to verify the results and also to show that the proposed element can achieve a complex-order behaviour.      
### 20.Data-Driven Demand-Side Flexibility Quantification: Prediction and Approximation of Flexibility Envelopes  [ :arrow_down: ](https://arxiv.org/pdf/2110.12796.pdf)
>  Real-time quantification of residential building energy flexibility is needed to enable a cost-efficient operation of active distribution grids. A promising means is to use the so-called flexibility envelope concept to represent the time-dependent and inter-temporally coupled flexibility potential. However, existing optimization-based quantification entails high computational burdens limiting flexibility utilization in real-time applications, and a more computationally efficient quantification approach is desired. Additionally, the communication of a flexibility envelope to system operators in its original form is data-intensive. In order to address the computational burdens, this paper first trains several machine learning models based on historical quantification results for online use. Subsequently, probability distribution functions are proposed to approximate the flexibility envelopes with significantly fewer parameters, which can be communicated to system operators instead of the original flexibility envelope. The results show that the most promising prediction and approximation approaches allow for a minimum reduction of the computational burden by a factor of 9 and of the communication load by a factor of 6.6, respectively.      
### 21.Parallel Feedforward Compensation for Output Synchronization: Fully Distributed Control and Indefinite Laplacian  [ :arrow_down: ](https://arxiv.org/pdf/2110.12787.pdf)
>  This work is associated with the use of parallel feedforward compensators (PFCs) for the problem of output synchronization over heterogeneous agents and the benefits this approach can provide. Specifically, it addresses the addition of stable PFCs on agents that interact with each other using diffusive couplings. The value in the application of such PFC is twofold. Firstly, it has been an issue that output synchronization among passivity-short systems requires global information for the design of controllers in the cases when initial conditions need to be taken into account, such as average consensus and distributed optimization. We show that a stable PFC can be designed to passivate a passivity-short system while its output asymptotically vanishes as its input tends to zero. As a result, output synchronization is achieved among these systems by fully distributed controls without altering the original consensus results. Secondly, it is generally required in the literature that the graph Laplacian be positive semidefinite, i.e., $L \geq 0$ for undirected graphs or $L + L^T \geq 0$ for balanced directed graphs, to achieve output synchronization over signed weighted graphs. We show that the PFC serves as output feedback to the communication graph to enhance the robustness against negative weight edges. As a result, output synchronization is achieved over a signed weighted and balanced graph, even if the corresponding Laplacian is not positive semidefinite.      
### 22.Dictionary Learning Using Rank-One Atomic Decomposition (ROAD)  [ :arrow_down: ](https://arxiv.org/pdf/2110.12786.pdf)
>  Dictionary learning aims at seeking a dictionary under which the training data can be sparsely represented. Methods in the literature typically formulate the dictionary learning problem as an optimization w.r.t. two variables, i.e., dictionary and sparse coefficients, and solve it by alternating between two stages: sparse coding and dictionary update. The key contribution of this work is a Rank-One Atomic Decomposition (ROAD) formulation where dictionary learning is cast as an optimization w.r.t. a single variable which is a set of rank one matrices. The resulting algorithm is hence single-stage. Compared with two-stage algorithms, ROAD minimizes the sparsity of the coefficients whilst keeping the data consistency constraint throughout the whole learning process. An alternating direction method of multipliers (ADMM) is derived to solve the optimization problem and the lower bound of the penalty parameter is computed to guarantees a global convergence despite non-convexity of the optimization formulation. From practical point of view, ROAD reduces the number of tuning parameters required in other benchmark algorithms. Numerical tests demonstrate that ROAD outperforms other benchmark algorithms for both synthetic data and real data, especially when the number of training samples is small.      
### 23.Data-driven Control of Dynamic Event-triggered Systems with Delays  [ :arrow_down: ](https://arxiv.org/pdf/2110.12768.pdf)
>  This paper studies data-driven control of unknown sampled-data systems with communication delays under an event-triggering transmission mechanism. Data-based representations for stochastic linear systems with a known or an unknown system input matrix are first developed, along with a novel class of dynamic triggering schemes for sampled-data systems with time delays. A model-based stability condition for the resulting event-triggered time-delay system is established using a looped-functional approach. Combining this model-based condition with the data-driven representations, data-based stability conditions are derived. Building on the data-based conditions, methods for co-designing the controller gain and the event-triggering matrix are subsequently provided for both cases with or without using the input matrix. Finally, a numerical example is presented to corroborate the role of additional prior knowledge of the input matrix in reducing the conservatism of stability conditions, as well as the merits of our approaches relative to existing results.      
### 24.Data-Driven Resilient Predictive Control under Denial-of-Service  [ :arrow_down: ](https://arxiv.org/pdf/2110.12766.pdf)
>  The study of resilient control of linear time-invariant (LTI) systems against denial-of-service (DoS) attacks is gaining popularity in emerging cyber-physical applications. In previous works, explicit system models are required to design a predictor-based resilient controller. These models can be either given a priori or obtained through a prior system identification step. Recent research efforts have focused on data-driven control based on pre-collected input-output trajectories (i.e., without explicit system models). In this paper, we take an initial step toward data-driven stabilization of stochastic LTI systems under DoS attacks, and develop a resilient model predictive control (MPC) scheme driven purely by data-dependent conditions. The proposed data-driven control method achieves the same level of resilience as the model-based control method. For example, local input-to-state stability (ISS) is achieved under mild assumptions on the noise and the DoS attacks. To recover global ISS, two modifications are further suggested at the price of reduced resilience against DoS attacks or increased computational complexity. Finally, a numerical example is given to validate the effectiveness of the proposed control method.      
### 25.Patch vs. Global Image-Based Unsupervised Anomaly Detection in MR Brain Scans of Early Parkinsonian Patients  [ :arrow_down: ](https://arxiv.org/pdf/2110.12707.pdf)
>  Although neural networks have proven very successful in a number of medical image analysis applications, their use remains difficult when targeting subtle tasks such as the identification of barely visible brain lesions, especially given the lack of annotated datasets. Good candidate approaches are patch-based unsupervised pipelines which have both the advantage to increase the number of input data and to capture local and fine anomaly patterns distributed in the image, while potential inconveniences are the loss of global structural information. We illustrate this trade-off on Parkinson's disease (PD) anomaly detection comparing the performance of two anomaly detection models based on a spatial auto-encoder (AE) and an adaptation of a patch-fed siamese auto-encoder (SAE). On average, the SAE model performs better, showing that patches may indeed be advantageous.      
### 26.A Nearly Optimal Chattering Reduction Method of Sliding Mode Control With an Application to a Two-wheeled Mobile Robot  [ :arrow_down: ](https://arxiv.org/pdf/2110.12706.pdf)
>  The problem we focus on in this paper is to find a nearly optimal sliding mode controller of continuous-time nonlinear multiple-input multiple-output (MIMO) systems that can both reduce chattering and minimize the cost function, which is a measure of the performance index of dynamics systems. First, the deficiency of chattering in traditional SMC and the quasi-SMC method are analyzed in this paper. In quasi-SMC, the signum function of the traditional SMC is replaced with a continuous saturation function. Then, a chattering reduction algorithm based on integral reinforcement learning (IRL) is proposed. Under an initial sliding mode controller, the proposed method can learn the nearly optimal saturation function using policy iteration. To satisfy the requirement of the learned saturation function, we treat the problem of training the saturation function as the constraint of an optimization problem. The online neural network implementation of the proposed algorithm is presented based on symmetric radius basis functions and a regularized batch least-squares (BLS) algorithm to train the control law in this paper. Finally, two examples are simulated to verify the effectiveness of the proposed method. The second example is an application to a real-world dynamics model -- a two-wheeled variable structure robot.      
### 27.Hybrid learning of Non-Cartesian k-space trajectory and MR image reconstruction networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.12691.pdf)
>  Compressed sensing (CS) in Magnetic resonance Imaging (MRI) essentially involves the optimization of 1) the sampling pattern in k-space under MR hardware constraints and 2) image reconstruction from the undersampled k-space data. Recently, deep learning methods have allowed the community to address both problems simultaneously, especially in the non-Cartesian acquisition setting. This paper aims to contribute to this field by tackling some major concerns in existing approaches.Regarding the learning of the sampling pattern, we perform ablation studies using parameter-free reconstructions like the density compensated (DCp) adjoint operator of the nonuniform fast Fourier transform (NUFFT) to ensure that the learned k-space trajectories actually sample the center of k-space densely. Additionally we optimize these trajectories by embedding a projected gradient descent algorithm over the hardware MR constraints. Later, we introduce a novel hybrid learning approach that operates across multiple resolutions to jointly optimize the reconstruction network and the k-space trajectory and present improved image reconstruction quality at 20-fold acceleration factor on T1 and T2-weighted images on the fastMRI dataset with SSIM scores of nearly 0.92-0.95 in our retrospective studies.      
### 28.Transient Synchronization Stability Analysis of Wind Farms with MMC-HVDC Integration Under Offshore AC Grid Fault  [ :arrow_down: ](https://arxiv.org/pdf/2110.12685.pdf)
>  The MMC-HVDC connected offshore wind farms (OWFs) could suffer short circuit fault (SCF), whereas their transient stability is not well analysed. In this paper, the mechanism of the loss of synchronization (LOS) of this system is analysed considering the whole system state from the fault-on to the post-fault, and the discussion on fault type and fault clearance is addressed as well. A stability index is proposed to quantify the transient synchronization stability (TSS) of the system, which is capable to not only estimate whether the wind turbine generators (WTGs) be able to get resynchronized with the offshore MMC after the fault is cleared, but also to evaluate the performance of stability improving methods as well. Finally, a scenario of six cases is tested on the PSCAD/EMTDC simulation platform, where the performances of four existing stability improving methods are thoroughly compared via both numerical simulation and the proposed stability index.      
### 29.Controllable and Interpretable Singing Voice Decomposition via Assem-VC  [ :arrow_down: ](https://arxiv.org/pdf/2110.12676.pdf)
>  We propose a singing decomposition system that encodes time-aligned linguistic content, pitch, and source speaker identity via Assem-VC. With decomposed speaker-independent information and the target speaker's embedding, we could synthesize the singing voice of the target speaker. In conclusion, we made a perfectly synced duet with the user's singing voice and the target singer's converted singing voice.      
### 30.Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian Noise  [ :arrow_down: ](https://arxiv.org/pdf/2110.12662.pdf)
>  Controllers for autonomous systems that operate in safety-critical settings must account for stochastic disturbances. Such disturbances are often modelled as process noise, and common assumptions are that the underlying distributions are known and/or Gaussian. In practice, however, these assumptions may be unrealistic and can lead to poor approximations of the true noise distribution. We present a novel planning method that does not rely on any explicit representation of the noise distributions. In particular, we address the problem of computing a controller that provides probabilistic guarantees on safely reaching a target. First, we abstract the continuous system into a discrete-state model that captures noise by probabilistic transitions between states. As a key contribution, we adapt tools from the scenario approach to compute probably approximately correct (PAC) bounds on these transition probabilities, based on a finite number of samples of the noise. We capture these bounds in the transition probability intervals of a so-called interval Markov decision process (iMDP). This iMDP is robust against uncertainty in the transition probabilities, and the tightness of the probability intervals can be controlled through the number of samples. We use state-of-the-art verification techniques to provide guarantees on the iMDP, and compute a controller for which these guarantees carry over to the autonomous system. Realistic benchmarks show the practical applicability of our method, even when the iMDP has millions of states or transitions.      
### 31.Online Strategy Synthesis for Safe and Optimized Control of Steerable Needles  [ :arrow_down: ](https://arxiv.org/pdf/2110.12590.pdf)
>  Autonomous systems are often applied in uncertain environments, which require prospective action planning and retrospective data evaluation for future planning to ensure safe operation. Formal approaches may support these systems with safety guarantees, but are usually expensive and do not scale well with growing system complexity. In this paper, we introduce online strategy synthesis based on classical strategy synthesis to derive formal safety guarantees while reacting and adapting to environment changes. To guarantee safety online, we split the environment into region types which determine the acceptance of action plans and trigger local correcting actions. Using model checking on a frequently updated model, we can then derive locally safe action plans (prospectively), and match the current model against new observations via reachability checks (retrospectively). As use case, we successfully apply online strategy synthesis to medical needle steering, i.e., navigating a (flexible and beveled) needle through tissue towards a target without damaging its surroundings.      
### 32.Improving Online Railway Deadlock Detection using a Partial Order Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2110.12578.pdf)
>  Although railway dispatching on large national networks is gradually becoming more computerized, there are still major obstacles to retrofitting (semi-)autonomous control systems. In addition to requiring extensive and detailed digitalization of infrastructure models and information systems, exact optimization for railway dispatching is computationally hard. Heuristic algorithms and manual overrides are likely to be required for semi-autonomous railway operations for the foreseeable future. <br>In this context, being able to detect problems such as deadlocks can be a valuable part of a runtime verification system. If bound-for-deadlock situations are correctly recognized as early as possible, human operators will have more time to better plan for recovery operations. Deadlock detection may also be useful for verification in a feedback loop with a heuristic or semi-autonomous dispatching algorithm if the dispatching algorithm cannot itself guarantee a deadlock-free plan. <br>We describe a SAT-based planning algorithm for online detection of bound-for-deadlock situations. The algorithm exploits parallel updates of train positions and a partial order reduction technique to significantly reduce the number of state transitions (and correspondingly, the sizes of the formulas) in the SAT instances needed to prove whether a deadlock situation is bound to happen in the future. Implementation source code and benchmark instances are supplied, and a direct comparison against another recent study demonstrates significant performance gains.      
### 33.Rate Splitting with Wireless Edge Caching: A System-Level-based Co-design  [ :arrow_down: ](https://arxiv.org/pdf/2110.12491.pdf)
>  Rate splitting (RS) and wireless edge caching are essential means for meeting the quality of service requirements of future wireless networks. In this work, we focus on the cross-layer co-design of wireless edge caching schemes with sophisticated physical layer techniques, which facilitate non-orthogonal multiple access and interference mitigation. A flexible caching-aided RS (CRS) technique is proposed that operates in various modes that specify the cache placement at the receivers. We consider two caching policies: the intelligent coded caching (CC), as well as the well-known most popular content (MPC) policy. Both caching policies are integrated within the design parameters of RS in order to serve multiple cache-enabled receivers. The proposed technique is investigated from a system level perspective by taking into account spatial randomness. We consider a single cell network consisting of center and edge receivers and provide a comprehensive analytical framework for the evaluation of the proposed technique in terms of achieved rates. Specifically, we derive the rate achieved at each receiver under minimum rate constraints while incorporating the cache placement characteristics. Numerical results are presented which highlight the flexibility of the proposed technique and show how caching can be exploited in order to further boost the performance of RS.      
### 34.Requirement analysis for an artificial intelligence model for the diagnosis of the COVID-19 from chest X-ray data  [ :arrow_down: ](https://arxiv.org/pdf/2110.12464.pdf)
>  There are multiple papers published about different AI models for the COVID-19 diagnosis with promising results. Unfortunately according to the reviews many of the papers do not reach the level of sophistication needed for a clinically usable model. In this paper I go through multiple review papers, guidelines, and other relevant material in order to generate more comprehensive requirements for the future papers proposing a AI based diagnosis of the COVID-19 from chest X-ray data (CXR). Main findings are that a clinically usable AI needs to have an extremely good documentation, comprehensive statistical analysis of the possible biases and performance, and an explainability module.      
### 35.A CMOS SoC for Wireless Ultrasonic Power/Data Transfer and SHM Measurements on Structures  [ :arrow_down: ](https://arxiv.org/pdf/2110.12428.pdf)
>  This paper describes a highly-integrated CMOS system-on-chip (SoC) for active structural health monitoring (SHM). The chip integrates ultrasonic power and bidirectional half-duplex data transfer, a power management unit (PMU), and an ultrasound transceiver to enable wireless ultrasonically-coupled sensor SHM networks on structures. The PMU includes an active bias-flip rectifier with off-delay compensation, high-efficiency dual-path DC-DC converter with inductor time-sharing, and five switched-capacitor DC-DC converters to generate multi-level spectrally band-limited pulses for guided-wave SHM. The chip was fabricated in a standard 180 nm process and has a die area of $2\times 2$ mm$^{2}$. Test results show power conversion efficiency (PCE) $&gt;85\%$ for the active rectifier, $&gt;70$\% for the inductive DC-DC converter, and $&gt;60$\% for the switched-capacitor DC-DC converters. Output pulses have a peak-to-sidelobe ratio (PSL) $&gt;30$~dB and worst-case out-of-band emissions $&lt;-30$~dB, respectively. The SoC was integrated with a low-power microcontroller and passive components to realize miniaturized (15~mm $\times$ 30~mm) wireless SHM nodes. A set of nodes was deployed on an SHM test-bed (carbon fiber reinforced polymer sheet) representing an airframe panel. Tests on this wireless network confirm both long-range ultrasound power/data transfer and the ability to detect structural damage.      
### 36.Task-Based Graph Signal Compression  [ :arrow_down: ](https://arxiv.org/pdf/2110.12387.pdf)
>  Graph signals arise in various applications, ranging from sensor networks to social media data. The high-dimensional nature of these signals implies that they often need to be compressed in order to be stored and transmitted. The common framework for graph signal compression is based on sampling, resulting in a set of continuous-amplitude samples, which in turn have to be quantized into a finite bit representation. In this work we study the joint design of graph signal sampling along with quantization, for graph signal compression. We focus on bandlimited graph signals, and show that the compression problem can be represented as a task-based quantization setup, in which the task is to recover the spectrum of the signal. Based on this equivalence, we propose a joint design of the sampling and recovery mechanisms for a fixed quantization mapping, and present an iterative algorithm for dividing the available bit budget among the discretized samples. Furthermore, we show how the proposed approach can be realized using graph filters combining elements corresponding the neighbouring nodes of the graph, thus facilitating distributed implementation at reduced complexity. Our numerical evaluations on both synthetic and real world data shows that the joint sampling and quantization method yields a compact finite bit representation of high-dimensional graph signals, which allows reconstruction of the original signal with accuracy within a small gap of that achievable with infinite resolution quantizers.      
### 37.Uncertainty-Aware Lung Nodule Segmentation with Multiple Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2110.12372.pdf)
>  Since radiologists have different training and clinical experience, they may provide various segmentation maps for a lung nodule. As a result, for a specific lung nodule, some regions have a higher chance of causing segmentation uncertainty, which brings difficulty for lung nodule segmentation with multiple annotations. To address this problem, this paper proposes an Uncertainty-Aware Segmentation Network (UAS-Net) based on multi-branch U-Net, which can learn the valuable visual features from the regions that may cause segmentation uncertainty and contribute to a better segmentation result. Meanwhile, this network can provide a Multi-Confidence Mask (MCM) simultaneously, pointing out regions with different segmentation uncertainty levels. We introduce a Feature-Aware Concatenation structure for different learning targets and let each branch have a specific learning preference. Moreover, a joint adversarial learning process is also adopted to help learn discriminative features of complex structures. Experimental results show that our method can predict the reasonable regions with higher uncertainty and improve lung nodule segmentation performance in LIDC-IDRI.      
### 38.Robust Sliding Mode Control of a Magnetic Levitation System: Continuous-Time and Discrete-Time Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2110.12363.pdf)
>  This paper presents three types of sliding mode controllers for a magnetic levitation system. First, a proportional-integral sliding mode controller (PI-SMC) is designed using a new switching surface and a proportional plus power rate reaching law. The PI-SMC is more robust than a feedback linearization controller in the presence of mismatched uncertainties and outperforms the SMC schemes reported recently in the literature in terms of the convergence rate and settling time. Next, to reduce the chattering phenomenon in the PI-SMC, a state feedback-based discrete-time SMC algorithm is developed. However, the disturbance rejection ability is compromised to some extent. Furthermore, to improve the robustness without compromising the chattering reduction benefits of the discrete-time SMC, mismatched uncertainties like sensor noise and track input disturbance are incorporated in a robust discrete-time SMC design using multirate output feedback (MROF). With this technique, it is possible to realize the effect of a full-state feedback controller without incurring the complexity of a dynamic controller or an additional discrete-time observer. Also, the MROF-based discrete-time SMC strategy can stabilize the magnetic levitation system with excellent dynamic and steady-state performance with superior robustness in the presence of mismatched uncertainties. The stability of the closed-loop system under the proposed controllers is proved by using the Lyapunov stability theory. The simulation results and analytical comparisons demonstrate the effectiveness and robustness of the proposed control schemes.      
### 39.Convolutional Autoencoder-Based Phase Shift Feedback Compression for Intelligent Reflecting Surface-Assisted Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12348.pdf)
>  In recent years, intelligent reflecting surface (IRS) has emerged as a promising technology for 6G due to its potential/ability to significantly enhance energy- and spectrum-efficiency. To this end, it is crucial to adjust the phases of reflecting elements of the IRS, and most of the research works focus on how to optimize/quantize the phase for different optimization objectives. In particular, the quantized phase shift (QPS) is assumed to be available at the IRS, which, however, does not always hold and should be fed back to the IRS in practice. Unfortunately, the feedback channel is generally bandwidth-limited, which cannot support a huge amount of feedback overhead of the QPS particularly for a large number of reflecting elements and/or the quantization level of each reflecting element. In order to break this bottleneck, in this letter, we propose a convolutional autoencoder-based scheme, in which the QPS is compressed on the receiver side and reconstructed on the IRS side. In order to solve the problems of mismatched distribution and vanishing gradient, we remove the batch normalization (BN) layers and introduce a denosing module. By doing so, it is possible to achieve a high compression ratio with a reliable reconstruction accuracy in the bandwidth-limited feedback channel, and it is also possible to accommodate existing works assuming available QPS at the IRS. Simulation results confirm the high reconstruction accuracy of the feedback/compressed QPS through a feedback channel, and show that the proposed scheme can significantly outperform the existing compression algorithms.      
### 40.Quantitative Analysis of Demand Response Using Thermostatically Controlled Loads  [ :arrow_down: ](https://arxiv.org/pdf/2110.12345.pdf)
>  The flexible power consumption feature of thermostatically controlled loads (TCLs) such as heating, ventilation, and air-conditioning (HVAC) systems makes them attractive targets for demand response (DR). TCLs possess a brief period where their power utilization can be altered without any significant impact on customer comfort level. This indicates TCLs are hidden potentials for providing ancillary services. This paper proposes a novel metric of demand response support time (DRST) for HVAC enabled demand response and a novel algorithm for the quantification of such HVAC-DR. The consumers' comfort will not be compromised with the proposed DRST-based HVAC-DR. Case studies demonstrate its benefits in terms of cost saving in microgrid day-ahead scheduling and reduction of forced load shedding during a grid-microgrid tie-line outage event. This illustrates the reserve potential benefits and the increase of microgrid reliability when DRST-based HVAC-DR is considered.      
### 41.High-Sensitivity Electric Potential Sensors for Non-Contact Monitoring of Physiological Signals  [ :arrow_down: ](https://arxiv.org/pdf/2110.12313.pdf)
>  The paper describes highly-sensitive passive electric potential sensors (EPS) for non-contact detection of multiple biophysical signals, including electrocardiogram (ECG), respiration cycle (RC), and electroencephalogram (EEG). The proposed EPS uses an optimized transimpedance amplifier (TIA), a single guarded sensing electrode, and an adaptive cancellation loop (ACL) to maximize sensitivity (DC transimpedance $=150$~G$\Omega$) in the presence of power line interference (PLI) and motion artifacts. Tests were performed on healthy adult volunteers in noisy and unshielded indoor environments. Useful sensing ranges for ECG, RC, and EEG measurements, as validated against reference contact sensors, were observed to be approximately 50~cm, 100~cm, and 5~cm, respectively. ECG and RC signals were also successfully measured through wooden tables for subjects in sleep-like postures. The EPS were integrated with a wireless microcontroller to realize wireless sensor nodes capable of streaming acquired data to a remote base station in real-time.      
### 42.Data-driven estimation of system norms via impulse response  [ :arrow_down: ](https://arxiv.org/pdf/2110.12310.pdf)
>  This paper proposes a method for estimating the norms of a system in a pure data-driven fashion based on their identified Impulse Response (IR) coefficients. The calculation of norms is briefly reviewed and the main expressions for the IR-based estimations are presented. As a case study, the $\mathcal{H}_{1}$, $\mathcal{H}_2$, and $\mathcal{H}_{\infty}$ norms of the sensitivity transfer function of five different discrete-time closed-loop systems are estimated for a Signal-to-Noise-Ratio (SNR) of 10 dB, achieving low percent error values if compared to the real value. To verify the influence of the noise amplitude, norms are estimated considering a wide range of SNR values, for a specific system, presenting low Mean Percent Error (MPE) if compared to the real norms. The proposed technique is also compared to an existing state-space-based method in terms of $\mathcal{H}_{\infty}$, through Monte Carlo, showing a reduction of approximately 48 % in the MPE for a wide range of SNR values.      
### 43.A Study of Acoustic Features in Arabic Speaker Identification under Noisy Environmental Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2110.12304.pdf)
>  One of the major parts of the voice recognition field is the choice of acoustic features which have to be robust against the variability of the speech signal, mismatched conditions, and noisy environments. Thus, different speech feature extraction techniques have been developed. In this paper, we investigate the robustness of several front-end techniques in Arabic speaker identification. We evaluate five different features in babble, factory and subway conditions at the various signal to noise ratios (SNR). The obtained results showed that two of the auditory feature i.e. gammatone frequency cepstral coefficient (GFCC) and power normalization cepstral coefficients (PNCC), unlike their combination performs substantially better than a conventional speaker features i.e. Mel-frequency cepstral coefficients (MFCC).      
### 44.pystorms: A simulation sandbox for the development and evaluation of stormwater control algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2110.12289.pdf)
>  Recent accessibility of affordable sensing technologies, microcontrollers, and wireless communication technology has made it possible for stormwater systems to be retrofitted with an assortment of sensors and actuators. These smart stormwater systems have enabled the real-time sensing of their surrounding environmental dynamics, and subsequently, provide the basis for autonomous and adaptive operational control strategies. Additionally, these systems allow for inexpensive and minimally-invasive stormwater control interventions (e.g. hydraulic valve operated by cellularly-connected actuator) in lieu of new construction. However promising this area of smart stormwater control, there still remain barriers -- for experts and novices alike -- to access a set of shared tools and methods for investigating, developing, and contributing to it. In an effort to make smart stormwater control research more methodical, efficient, and accessible, we present pystorms, a Python-based simulation sandbox that facilitates the quantitative evaluation and comparison of control strategies. The pystorms simulation sandbox comes with (i) a collection of real world-inspired stormwater control scenarios on which any number of control strategies can be applied and tested via (ii) an accompanying Python programming interface coupled with a stormwater simulator. For the first time, pystorms enables rigorous and efficient evaluation of smart stormwater control methodologies across a diverse set of watersheds with only a few lines of code. We present the details of pystorms here and demonstrate its usage by applying and evaluating two stormwater control strategies.      
### 45.Perineural Invasion Detection in Multiple Organ Cancer Based on Deep Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2110.12283.pdf)
>  Perineural invasion (PNI) by malignant tumor cells has been reported as an independent indicator of poor prognosis in various cancers. Assessment of PNI in small nerves on glass slides is a labor-intensive task. In this study, we propose an algorithm to detect the perineural invasions in colon, prostate, and pancreas cancers based on a convolutional neural network (CNN).      
### 46."One-Shot" Reduction of Additive Artifacts in Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.12274.pdf)
>  Medical images may contain various types of artifacts with different patterns and mixtures, which depend on many factors such as scan setting, machine condition, patients' characteristics, surrounding environment, etc. However, existing deep-learning-based artifact reduction methods are restricted by their training set with specific predetermined artifact types and patterns. As such, they have limited clinical adoption. In this paper, we introduce One-Shot medical image Artifact Reduction (OSAR), which exploits the power of deep learning but without using pre-trained general networks. Specifically, we train a light-weight image-specific artifact reduction network using data synthesized from the input image at test-time. Without requiring any prior large training data set, OSAR can work with almost any medical images that contain varying additive artifacts which are not in any existing data sets. In addition, Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are used as vehicles and show that the proposed method can reduce artifacts better than state-of-the-art both qualitatively and quantitatively using shorter test time.      
### 47.Benchmarking of Lightweight Deep Learning Architectures for Skin Cancer Classification using ISIC 2017 Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2110.12270.pdf)
>  Skin cancer is one of the deadly types of cancer and is common in the world. Recently, there has been a huge jump in the rate of people getting skin cancer. For this reason, the number of studies on skin cancer classification with deep learning are increasing day by day. For the growth of work in this area, the International Skin Imaging Collaboration (ISIC) organization was established and they created an open dataset archive. In this study, images were taken from ISIC 2017 Challenge. The skin cancer images taken were preprocessed and data augmented. Later, these images were trained with transfer learning and fine-tuning approach and deep learning models were created in this way. 3 different mobile deep learning models and 3 different batch size values were determined for each, and a total of 9 models were created. Among these models, the NASNetMobile model with 16 batch size got the best result. The accuracy value of this model is 82.00%, the precision value is 81.77% and the F1 score value is 0.8038. Our method is to benchmark mobile deep learning models which have few parameters and compare the results of the models.      
### 48.Joint Beamforming and Interference Cancellation in MmWave Wideband Full-Duplex Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12266.pdf)
>  Full-duplex (FD) systems have the capability to transmit and receive at the same time in the same frequency band. FD systems can reduce congestion and latency and improve coverage and spectral efficiency. As a relay, they can increase range and decrease outages. Full-duplex (FD) wireless systems have been emerging as a practical solution to provide high bandwidth, low latency, and big data processing in millimeter wave and Terahertz systems to support cellular networks, autonomous driving, platooning, advanced driving assistance and other systems. However, FD systems suffer from loopback self-interference that can swamp the analog-to-digital converters (ADCs) resulting in very low spectral efficiency. In this context, we consider a cellular system wherein uplink and downlink users independently communicate with FD base station. The proposed contributions are (1) three hybrid beamforming algorithms to cancel self-interference and increase the received power, and (2) evaluation of outage probability, spectral efficiency, and energy efficiency of the proposed algorithms. We consider full-digital beamforming and upper bound as benchmarks. Finally, we show the resiliency of Algorithm 2 against self-interference in comparison with Algorithms 1 and 3, as well as conventional approaches such as beam steering, angle search and singular value decomposition.      
### 49.Fixed-Time Convergent Distributed Observer Design of Linear Systems: A Kernel-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.12263.pdf)
>  This note investigates the distributed observer for a continuous-time linear time-invariant system with distributed sensor nodes and each can access a portion of the system output. The communication network between the agents is prescribed by a directed graph in which each node involves a finite-time convergent state observer. The local observer estimates and broadcasts the observable states among neighbours so that the full state vector can be recovered at each node and the estimation error reaches zero after a fixed time in the absence of perturbation. This represents a new distributed estimation framework that enables reduced information exchange compared to a Luenberger-like approach, and the ubiquitous communication delay can be compensated. Moreover, the robustness of the algorithm in the presence of bounded measurement and process noise is characterised. Numerical simulations and comparisons show the effectiveness of the observer and its advantages over the renewed existing methods.      
### 50.A Comprehensive Electric Vehicle Model for Vehicle-to-Grid Strategy Development  [ :arrow_down: ](https://arxiv.org/pdf/2110.12225.pdf)
>  An electric vehicle model is developed to characterize the behavior of the Smart e.d. (2013) while driving, charging and providing vehicle-to-grid services. The battery model is an electro-thermal model with a dual polarization equivalent circuit electrical model coupled with a lumped thermal model with active liquid cooling. The aging trend of the EV's 50 Ah large format pouch cell with NMC chemistry is evaluated via accelerated aging tests in the laboratory. The EV model is completed with the measurement of the on-board charger efficiency and the charging control behavior via IEC 61851-1. Performance of the model is validated using laboratory pack tests, charging and driving field data. The RMSE of the cell voltage was between 18.49 mV and 67.17 mV per cell for the validation profiles. Cells stored at 100 % SOC and 40 $^{\circ}C$ reached end-of-life (80 % of initial capacity) after 431 days to 589 days. The end-of-life for a cell cycled with 80 % DOD around an SOC of 50 % is reached after 3634 equivalent full cycles which equates to a driving distance of over 420000 km. The full parameter set of the model is provided to serve as a resource for vehicle-to-grid strategy development.      
### 51.Dual Shape Guided Segmentation Network for Organs-at-Risk in Head and Neck CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.12192.pdf)
>  The accurate segmentation of organs-at-risk (OARs) in head and neck CT images is a critical step for radiation therapy of head and neck cancer patients. However, manual delineation for numerous OARs is time-consuming and laborious, even for expert oncologists. Moreover, manual delineation results are susceptible to high intra- and inter-variability. To this end, we propose a novel dual shape guided network (DSGnet) to automatically delineate nine important OARs in head and neck CT images. To deal with the large shape variation and unclear boundary of OARs in CT images, we represent the organ shape using an organ-specific unilateral inverse-distance map (UIDM) and guide the segmentation task from two different perspectives: direct shape guidance by following the segmentation prediction and across shape guidance by sharing the segmentation feature. In the direct shape guidance, the segmentation prediction is not only supervised by the true label mask, but also by the true UIDM, which is implemented through a simple yet effective encoder-decoder mapping from the label space to the distance space. In the across shape guidance, UIDM is used to facilitate the segmentation by optimizing the shared feature maps. For the experiments, we build a large head and neck CT dataset with a total of 699 images from different volunteers, and conduct comprehensive experiments and comparisons with other state-of-the-art methods to justify the effectiveness and efficiency of our proposed method. The overall Dice Similarity Coefficient (DSC) value of 0.842 across the nine important OARs demonstrates great potential applications in improving the delineation quality and reducing the time cost.      
### 52.TELET: A Monotonic Algorithm to Design Large Dimensional Equiangular Tight Frames for Applications in Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.12182.pdf)
>  An Equiangular tight frame (ETF) - also known as the Welch-bound-equality sequences - consists of a sequence of unit norm vectors whose absolute inner product is identical and minimal. Due to this unique property, these frames are preferred in different applications such as in constructing sensing matrices for compressed sensing systems, robust transmission, and quantum computing. Construction of ETFs involves solving a challenging non-convex minimax optimization problem, and only a few methods were successful in constructing them, albeit only for smaller dimensions. In this paper, we propose an iterative algorithm named TEchnique to devise Large dimensional Equiangular Tight-frames (TELET-frames) based on the majorization minimization (MM) procedure - in which we design and minimize a tight upper bound for the ETF cost function at every iteration. Since TELET is designed using the MM approach, it inherits useful properties of MM such as monotonicity and guaranteed convergence to a stationary point. Subsequently, we use the derived frames to construct optimized sensing matrix for compressed sensing systems. In the numerical simulations, we show that the proposed algorithm can generate complex and real frames (in the order of hundreds) with very low mutual coherence value when compared to the state-of-the-art algorithm, with a slight increase in computational cost. Experiments using synthetic data and real images reveal that the optimized sensing matrix obtained through the frames constructed by TELET performs better, in terms of image reconstruction accuracy, than the sensing matrix constructed using state-of-the-art methods.      
### 53.Newtonian Mechanics Based Transient Stability PART III: Superimposed Machine  [ :arrow_down: ](https://arxiv.org/pdf/2110.12180.pdf)
>  This paper analyzes the mechanisms of the superimposed machine and also its inherit problems in TSA. Based on the global monitoring of the original system trajectory, the transient energy is mistakenly defined as the superimposition of the transient energy of all machines in the system. This "energy superimposition" directly causes the superimposed machine to become a pseudo machine without any equation of motion, and in this way the superimposed machine completely violates all the machine paradigms. The violations bring the two inherit defects in TSA: (i) the stability of the superimposed machine is unable to be characterized precisely, and (ii) the variance of the original system trajectory is unstable to be depicted clearly. The two defects are also reflected in the definitions of the superimposed-machine based transient stability concepts. In particular, the swing and the critical stability of the system are unable to be defined strictly, and the potential energy surface cannot be modeled precisely. Simulation results show that the problems of the pseudo superimposed-machine in TSA.      
### 54.Vertebrae segmentation, identification and localization using a graph optimization and a synergistic cycle  [ :arrow_down: ](https://arxiv.org/pdf/2110.12177.pdf)
>  This paper considers the segmentation, identification and localization of vertebrae in CT images. Although these three tasks are related, they face specific problems that add up when they are addressed together. For example neighboring vertebrae with similar shapes perturb the identification and vertebrae with complex or even pathological morphologies impact the segmentation. Consequently, the three tasks tend to be approached independently, e.g. labelling (localization and identification) or segmenting only, or, when treated globally, a sequential strategy is used. Sequential methods however are prone to accumulate errors as they are not able to recover from mistakes of the previous module. In this work, we propose to combine all three tasks and leverage their interdependence: locations ease the segmentation, the segmentations in turn improve the locations and they all contribute and benefit from the identification task. To this purpose we propose a virtuous cycle to enforce coherence between the three tasks. Within such a cycle, the tasks interoperate and are iterated until a global consistency criterion is satisfied. Our experiments validate this strategy with anatomically coherent results that outperform the state of the art on the VerSe20 challenge benchmark. Our code and model are openly available for research purposes at <a class="link-external link-https" href="https://gitlab.inria.fr/spine/vertebrae_segmentation" rel="external noopener nofollow">this https URL</a>.      
### 55.New Methods for MLE of Toeplitz Structured Covariance Matrices with Applications to RADAR Problems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12176.pdf)
>  This work considers Maximum Likelihood Estimation (MLE) of a Toeplitz structured covariance matrix. In this regard, an equivalent reformulation of the MLE problem is introduced and two iterative algorithms are proposed for the optimization of the equivalent problem. Both the strategies are based on the Majorization Minimization (MM) framework and hence enjoy nice properties such as monotonicity and ensured convergence to a stationary point of the equivalent MLE problem. The proposed algorithms are also extended to deal with MLE of other related covariance structures, namely, the banded Toeplitz, Toeplitz-block-Toeplitz, low rank Toeplitz structure plus a scalar matrix (accounting for white noise), and finally Toeplitz matrices satisfying a condition number constraint. Through numerical simulations, it is shown that new methods provide satisfactory performance levels in terms of both mean square estimation error and signal-to-interference-plus-noise ratio.      
### 56.Adversarial Deep Feature Extraction Network for User Independent Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.12163.pdf)
>  User dependence remains one of the most difficult general problems in Human Activity Recognition (HAR), in particular when using wearable sensors. This is due to the huge variability of the way different people execute even the simplest actions. In addition, detailed sensor fixtures and placement will be different for different people or even at different times for the same users. In theory, the problem can be solved by a large enough data set. However, recording data sets that capture the entire diversity of complex activity sets is seldom practicable. Instead, models are needed that focus on features that are invariant across users. To this end, we present an adversarial subject-independent feature extraction method with the maximum mean discrepancy (MMD) regularization for human activity recognition. The proposed model is capable of learning a subject-independent embedding feature representation from multiple subjects datasets and generalizing it to unseen target subjects. The proposed network is based on the adversarial encoder-decoder structure with the MMD realign the data distribution over multiple subjects. Experimental results show that the proposed method not only outperforms state-of-the-art methods over the four real-world datasets but also improves the subject generalization effectively. We evaluate the method on well-known public data sets showing that it significantly improves user-independent performance and reduces variance in results.      
### 57.Family of Integrated Multi-Input Multi-Output DC-DC Power Converters  [ :arrow_down: ](https://arxiv.org/pdf/2110.12139.pdf)
>  This paper explores a family of integrated multiport converters using three-switch which can provide single-input dual-output (SIDO) or dual-input single-output (DISO) with bidirectional power flow between any two ports. The concept can be extended to the n-switch converters to achieve more inputs and/or outputs. The proposed converters can be applied to interfacing sources, loads and storage elements having different voltage levels in applications such as dc nanogrids, electric vehicle, multiport power supplies, distributed generation systems. Various topological configurations of the integrated multiport n-switch converter are investigated. The operating principles and PWM control strategy of these converters are analyzed in detail. A universalized hardware prototype is built, experimental results are provided for verification.      
### 58.Advanced Load Shedding for Integrated Power and Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12134.pdf)
>  This paper introduces an advanced load shedding algorithm to improve the operability performance of a medium voltage direct current (MVDC) integrated shipboard power and energy system. Outcomes are compared to a baseline algorithm while considering power generation contingency scenarios. The case study is conducted with a real-time, embedded algorithm implementation using a control hardware-in-the-loop (CHIL) setup.      
### 59.Distributed Dynamic State Estimation for Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2110.12133.pdf)
>  Conventionally, the dynamic state estimation of variables in power networks is performed based on the forecasting-aided model of bus voltages. This approach is effective in the stiff grids at the transmission level, where the bus voltages are less sensitive to variations of the load. However, in microgrids, bus voltages can fluctuate significantly under load changes, the forecasting-aided model may not sufficiently accurate. To resolve this problem, this paper proposes a dynamic state estimation scheme for microgrids using the state-space model derived from differential equations of power networks. In the proposed scheme, the branch currents are the state variables, whereas the bus voltages become the inputs which can vary freely with loads. As a result, the entire microgrids system can be partitioned into local areas, where neighbor areas share the common inputs. The proposed estimation scheme then can be implemented in a distributed manner. A novel Kalman-based filtering method is derived to estimate both states and inputs simultaneously. Only information of common inputs is exchanged between neighboring estimators. Simulation results of the 13-bus Potsdam microgrid (New York State) are provided to prove the feasibility and performances of the proposed scheme.      
### 60.Three-Layer Joint Distributionally Robust Chance-Constrained Framework for Optimal Day-Ahead Scheduling of E-mobility Ecosystem  [ :arrow_down: ](https://arxiv.org/pdf/2110.12123.pdf)
>  A high number of electric vehicles (EVs) in the transportation sector necessitates an advanced scheduling framework for e-mobility ecosystem operation as a whole in order to overcome range anxiety and create a viable business model for charging stations (CSs). The framework must account for the stochastic nature of all stakeholders' operations, including EV drivers, CSs, and retailers and their mutual interactions. In this paper, a three-layer joint distributionally robust chance-constrained (DRCC) model is proposed to plan grid-to-vehicle (G2V) and vehicle-to-grid (V2G) operation in day-ahead for e-mobility ecosystems. The proposed stochastic model does not rely on a specific probability distribution for stochastic parameters. To solve the problem, an iterative process is proposed using joint DRCC formulation. To achieve computational traceability, the exact reformulation is implemented for double-sided and single-sided chance constraints (CCs). Furthermore, the impact of temporal correlation of uncertain PV generation on CSs operation is considered. A simulation study is carried out for an ecosystem of three retailers, nine CSs, and 600 EVs based on real data from San Francisco, the USA. The simulation results show the necessity and applicability of such a scheduling method for the e-mobility ecosystem in an uncertain environment, e.g., by reducing the number of unique EVs that failed to reach their destination from 272 to 61.      
### 61.Joint Task Offloading and Resource Allocation for IoT Edge Computing with Sequential Task Dependency  [ :arrow_down: ](https://arxiv.org/pdf/2110.12115.pdf)
>  Incorporating mobile edge computing (MEC) in the Internet of Things (IoT) enables resource-limited IoT devices to offload their computation tasks to a nearby edge server. In this paper, we investigate an IoT system assisted by the MEC technique with its computation task subjected to sequential task dependency, which is critical for video stream processing and other intelligent applications. To minimize energy consumption per IoT device while limiting task processing delay, task offloading strategy, communication resource, and computation resource are optimized jointly under both slow and fast fading channels. In slow fading channels, an optimization problem is formulated, which is mixed-integer and non-convex. To solve this challenging problem, we decompose it as a one-dimensional search of task offloading decision problem and a non-convex optimization problem with task offloading decision given. Through mathematical manipulations, the non-convex problem is transformed to be a convex one, which is shown to be solvable only with the simple Golden search method. In fast fading channels, optimal online policy depending on instant channel state is derived. In addition, it is proved that the derived policy will converge to the offline policy when channel coherence time is low, which can help to save extra computation complexity. Numerical results verify the correctness of our analysis and the effectiveness of our proposed strategies over existing methods.      
### 62.Dense Dual-Attention Network for Light Field Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2110.12114.pdf)
>  Light field (LF) images can be used to improve the performance of image super-resolution (SR) because both angular and spatial information is available. It is challenging to incorporate distinctive information from different views for LF image SR. Moreover, the long-term information from the previous layers can be weakened as the depth of network increases. In this paper, we propose a dense dual-attention network for LF image SR. Specifically, we design a view attention module to adaptively capture discriminative features across different views and a channel attention module to selectively focus on informative information across all channels. These two modules are fed to two branches and stacked separately in a chain structure for adaptive fusion of hierarchical features and distillation of valid information. Meanwhile, a dense connection is used to fully exploit multi-level information. Extensive experiments demonstrate that our dense dual-attention mechanism can capture informative information across views and channels to improve SR performance. Comparative results show the advantage of our method over state-of-the-art methods on public datasets.      
### 63.Integrated Task and Motion Planning for Safe Legged Navigation in Partially Observable Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.12097.pdf)
>  This study proposes a hierarchically integrated framework for safe task and motion planning (TAMP) of bipedal locomotion in a partially observable environment with dynamic obstacles and uneven terrain. The high-level task planner employs linear temporal logic (LTL) for a reactive game synthesis between the robot and its environment and provides a formal guarantee on navigation safety and task completion. To address environmental partial observability, a belief abstraction is employed at the high-level navigation planner to estimate the dynamic obstacles' location when they are out of the robot's local field of view. Accordingly, a synthesized action planner sends a set of locomotion actions including walking step, step height, and heading angle change, to the middle-level motion planner, while incorporating safe locomotion specifications extracted from safety theorems based on a reduced-order model (ROM) of the locomotion process. The motion planner employs the ROM to design safety criteria and a sampling algorithm to generate non-periodic motion plans that accurately track high-level actions. To address external perturbations, this study also investigates safe sequential composition of the keyframe locomotion state and achieves robust transitions against external perturbations through reachability analysis. A set of ROM-based hyperparameters are finally interpolated to design whole-body locomotion gaits generated by trajectory optimization and validate the viable deployment of the ROM-based TAMP to the full-body trajectory generation for a 20-degrees-of-freedom Cassie bipedal robot designed by Agility Robotics. The proposed framework is validated by a set of scenarios in uneven, partially observable environments with dynamical obstacles.      
### 64.Adversarial Multi-Player Bandits for Cognitive Radar Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.12094.pdf)
>  We model a radar network as an adversarial bandit problem, where the environment pre-selects reward sequences for each of several actions available to the network. This excludes environments which vary rewards in response to the learner's actions. Adversarial environments include those with third party emitters which enter and exit the environment according to some criteria which does not depend on the radar network. The network consists of several independent radar nodes, which attempt to attain the highest possible SINR in each of many time steps. We show that in such an environment, simple sub-band selection algorithms are unable to consistently attain high SINR. However, through the use of adversarial multi-player bandit algorithms, a radar network can continue to track targets without a loss in tracking precision.      
### 65.Multiplication-Avoiding Variant of Power Iteration with Applications  [ :arrow_down: ](https://arxiv.org/pdf/2110.12065.pdf)
>  Power iteration is a fundamental algorithm in data analysis. It extracts the eigenvector corresponding to the largest eigenvalue of a given matrix. Applications include ranking algorithms, recommendation systems, principal component analysis (PCA), among many others. In this paper, We introduce multiplication-avoiding power iteration (MAPI), which replaces the standard $\ell_2$-inner products that appear at the regular power iteration (RPI) with multiplication-free vector products which are Mercer-type kernel operations related with the $\ell_1$ norm. Precisely, for an $n\times n$ matrix, MAPI requires $n$ multiplications, while RPI needs $n^2$ multiplications per iteration. Therefore, MAPI provides a significant reduction of the number of multiplication operations, which are known to be costly in terms of energy consumption. We provide applications of MAPI to PCA-based image reconstruction as well as to graph-based ranking algorithms. When compared to RPI, MAPI not only typically converges much faster, but also provides superior performance.      
### 66.Supervised Learning-Enabled Ideal Observer Approximation for Joint Detection and Estimation Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2110.12042.pdf)
>  The ideal observer (IO) sets an upper performance limit among all observers and has been advocated for assessing and optimizing imaging systems. For general joint detection and estimation (detection-estimation) tasks, estimation ROC (EROC) analysis has been established for evaluating the performance of observers. However, in general, it is difficult to accurately approximate the IO that maximizes the area under the EROC curve. In this study, a hybrid method that employs machine learning is proposed to accomplish this. Specifically, a hybrid approach is developed that combines a multi-task convolutional neural network and a Markov-Chain Monte Carlo (MCMC) method in order to approximate the IO for detection-estimation tasks. In addition, a purely supervised learning-based sub-ideal observer is proposed. Computer-simulation studies are conducted to validate the proposed method, which include signal-known-statistically/background-known-exactly and signal-known-statistically/background-known-statistically tasks. The EROC curves produced by the proposed method are compared to those produced by the MCMC approach or analytical computation when feasible. The proposed method provides a new approach for approximating the IO and may advance the application of EROC analysis for optimizing imaging systems.      
### 67.Online Demodulation and Trigger for Flux-ramp Modulated SQUID Signals  [ :arrow_down: ](https://arxiv.org/pdf/2110.12017.pdf)
>  Due to the periodic characteristics of SQUIDs, a suitable linearization technique is required for SQUID-based readout. Flux-ramp modulation is a common linearization technique and is typically applied for the readout of a microwave-SQUID-multiplexer as well as since recently also for dc-SQUIDs. Flux-ramp modulation requires another stage in the signal processing chain to demodulate the SQUID output signal before further processing. For cryogenic microcalorimenters, these events are given by fast exponentially rising and slowly exponentially decaying pulses which shall be detected by a trigger engine and recorded by a storage logic. Since the data rate can be decreased significantly by demodulation and event detection, it is desirable to do both steps on the deployed fast FPGA logic during measurement before passing the data to a general-purpose processor. <br>In this contribution, we show the implementation of efficient multi-channel flux-ramp demodulation computed at run-time on a SoC-FPGA. Furthermore, a concept and implementation for an online trigger and buffer mechanism with its theoretical trigger loss rates depending on buffer size is presented. Both FPGA modules can be operated with up to 500 MHz clock frequency and can efficiently process 32 channels. Correct functionality and data reduction capability of the modules are demonstrated in measurements utilizing magnetic microcalorimeter irradiated with an Iron-55 source for event generation and read out by a microwave SQUID multiplexer.      
### 68.Disturbance Bounds for Signal Temporal Logic Task Satisfaction: A Dynamics Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2110.12014.pdf)
>  This letter offers a novel approach to Test and Evaluation of pre-existing controllers from a control barrier function and dynamics perspective. More aptly, prior Test and Evaluation techniques tend to require apriori knowledge of a space of allowable disturbances. Our work, however, determines a two-norm disturbance-bound rejectable by a system's controller without requiring specific knowledge of these disturbances beforehand. The authors posit that determination of such a disturbance bound offers a better understanding of the robustness with which a given controller achieves a specified task - as motivated through a simple, linear-system example. Additionally, we show that our resulting disturbance bound is accurate through simulation of 1000 randomized trials in which a Segway-controller pair satisfies its specification despite randomized perturbations within our identified bound.      
### 69.Semi-Supervised Semantic Segmentation of Vessel Images using Leaking Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2110.11998.pdf)
>  Semantic segmentation based on deep learning methods can attain appealing accuracy provided large amounts of annotated samples. However, it remains a challenging task when only limited labelled data are available, which is especially common in medical imaging. In this paper, we propose to use Leaking GAN, a GAN-based semi-supervised architecture for retina vessel semantic segmentation. Our key idea is to pollute the discriminator by leaking information from the generator. This leads to more moderate generations that benefit the training of GAN. As a result, the unlabelled examples can be better utilized to boost the learning of the discriminator, which eventually leads to stronger classification performance. In addition, to overcome the variations in medical images, the mean-teacher mechanism is utilized as an auxiliary regularization of the discriminator. Further, we modify the focal loss to fit it as the consistency objective for mean-teacher regularizer. Extensive experiments demonstrate that the Leaking GAN framework achieves competitive performance compared to the state-of-the-art methods when evaluated on benchmark datasets including DRIVE, STARE and CHASE\_DB1, using as few as 8 labelled images in the semi-supervised setting. It also outperforms existing algorithms on cross-domain segmentation tasks.      
### 70.PhotoWCT$^2$: Compact Autoencoder for Photorealistic Style Transfer Resulting from Blockwise Training and Skip Connections of High-Frequency Residuals  [ :arrow_down: ](https://arxiv.org/pdf/2110.11995.pdf)
>  Photorealistic style transfer is an image editing task with the goal to modify an image to match the style of another image while ensuring the result looks like a real photograph. A limitation of existing models is that they have many parameters, which in turn prevents their use for larger image resolutions and leads to slower run-times. We introduce two mechanisms that enable our design of a more compact model that we call PhotoWCT$^2$, which preserves state-of-art stylization strength and photorealism. First, we introduce blockwise training to perform coarse-to-fine feature transformations that enable state-of-art stylization strength in a single autoencoder in place of the inefficient cascade of four autoencoders used in PhotoWCT. Second, we introduce skip connections of high-frequency residuals in order to preserve image quality when applying the sequential coarse-to-fine feature transformations. Our PhotoWCT$^2$ model requires fewer parameters (e.g., 30.3\% fewer) while supporting higher resolution images (e.g., 4K) and achieving faster stylization than existing models.      
### 71.A Reinforcement Learning Approach to Parameter Selection for Distributed Optimization in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.11991.pdf)
>  With the increasing penetration of distributed energy resources, distributed optimization algorithms have attracted significant attention for power systems applications due to their potential for superior scalability, privacy, and robustness to a single point-of-failure. The Alternating Direction Method of Multipliers (ADMM) is a popular distributed optimization algorithm; however, its convergence performance is highly dependent on the selection of penalty parameters, which are usually chosen heuristically. In this work, we use reinforcement learning (RL) to develop an adaptive penalty parameter selection policy for the AC optimal power flow (ACOPF) problem solved via ADMM with the goal of minimizing the number of iterations until convergence. We train our RL policy using deep Q-learning, and show that this policy can result in significantly accelerated convergence (up to a 59% reduction in the number of iterations compared to existing, curvature-informed penalty parameter selection methods). Furthermore, we show that our RL policy demonstrates promise for generalizability, performing well under unseen loading schemes as well as under unseen losses of lines and generators (up to a 50% reduction in iterations). This work thus provides a proof-of-concept for using RL for parameter selection in ADMM for power systems applications.      
### 72.Multichannel Speech Enhancement without Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2110.13130.pdf)
>  Deep neural networks are often coupled with traditional spatial filters, such as MVDR beamformers for effectively exploiting spatial information. Even though single-stage end-to-end supervised models can obtain impressive enhancement, combining them with a beamformer and a DNN-based post-filter in a multistage processing provides additional improvements. In this work, we propose a two-stage strategy for multi-channel speech enhancement that does not need a beamformer for additional performance. First, we propose a novel attentive dense convolutional network (ADCN) for predicting real and imaginary parts of complex spectrogram. ADCN obtains state-of-the-art results among single-stage models. Next, we use ADCN in the proposed strategy with a recently proposed triple-path attentive recurrent network (TPARN) for predicting waveform samples. The proposed strategy uses two insights; first, using different approaches in two stages; and second, using a stronger model in the first stage. We illustrate the efficacy of our strategy by evaluating multiple models in a two-stage approach with and without beamformer.      
### 73.Rotation Equivariant Deforestation Segmentation and Driver Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.13097.pdf)
>  Deforestation has become a significant contributing factor to climate change and, due to this, both classifying the drivers and predicting segmentation maps of deforestation has attracted significant interest. In this work, we develop a rotation equivariant convolutional neural network model to predict the drivers and generate segmentation maps of deforestation events from Landsat 8 satellite images. This outperforms previous methods in classifying the drivers and predicting the segmentation map of deforestation, offering a 9% improvement in classification accuracy and a 7% improvement in segmentation map accuracy. In addition, this method predicts stable segmentation maps under rotation of the input image, which ensures that predicted regions of deforestation are not dependent upon the rotational orientation of the satellite.      
### 74.Unsupervised Source Separation By Steering Pretrained Music Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.13071.pdf)
>  We showcase an unsupervised method that repurposes deep models trained for music generation and music tagging for audio source separation, without any retraining. An audio generation model is conditioned on an input mixture, producing a latent encoding of the audio used to generate audio. This generated audio is fed to a pretrained music tagger that creates source labels. The cross-entropy loss between the tag distribution for the generated audio and a predefined distribution for an isolated source is used to guide gradient ascent in the (unchanging) latent space of the generative model. This system does not update the weights of the generative model or the tagger, and only relies on moving through the generative model's latent space to produce separated sources. We use OpenAI's Jukebox as the pretrained generative model, and we couple it with four kinds of pretrained music taggers (two architectures and two tagging datasets). Experimental results on two source separation datasets, show this approach can produce separation estimates for a wider variety of sources than any tested supervised or unsupervised system. This work points to the vast and heretofore untapped potential of large pretrained music models for audio-to-audio tasks like source separation.      
### 75.ML-Based Analysis to Identify Speech Features Relevant in Predicting Alzheimer's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2110.13023.pdf)
>  Alzheimer's disease (AD) is a neurodegenerative disease that affects nearly 50 million individuals across the globe and is one of the leading causes of deaths globally. It is projected that by 2050, the number of people affected by the disease would more than double. Consequently, the growing advancements in technology beg the question, can technology be used to predict Alzheimer's for a better and early diagnosis? In this paper, we focus on this very problem. Specifically, we have trained both ML models and neural networks to predict and classify participants based on their speech patterns. We computed a number of linguistic variables using DementiaBank's Pitt Corpus, a database consisting of transcripts of interviews with subjects suffering from multiple neurodegenerative diseases. We then trained both binary classifiers, as well as multiclass classifiers to distinguish AD from normal aging and other neurodegenerative diseases. We also worked on establishing the link between specific speech factors that can help determine the onset of AD. Confusion matrices and feature importance graphs have been plotted model-wise to compare the performances of our models. In both multiclass and binary classification, neural networks were found to outperform the other models with a testing accuracy of 76.44% and 92.05% respectively. For the feature importance, it was concluded that '%_PRESP' (present participle), '%_3S' (3rd person present tense markers) were two of the most important speech features for our classifiers in predicting AD.      
### 76.Blockchain application in simulated environment for Cyber-Physical Systems Security  [ :arrow_down: ](https://arxiv.org/pdf/2110.12974.pdf)
>  Critical Infrastructures (CIs) such as power grid, water and gas distribution are controlled by Industrial Control Systems (ICS). Sensors and actuators of a physical plant are managed by the ICS. Data and commands transmitted over the network from the Programmable Logic Controllers (PLCs) are saved and parsed within the Historian. Generally, this architecture guarantees to check for any process anomalies that may occur due to component failures and cyber attacks. The other use of this data allows activities such as forensic analysis. To secure the network is also crucial to protect the communication between devices. A cyber attack on the log devices could jeopardize any forensic analysis be it for maintenance, or discovering an attack trail. In this paper is proposed a strategy to secure plant operational data recorded in the Historian and data exchange in the network. An integrity checking mechanism, in combination with blockchain, is used to ensure data integrity. Data redundancy is achieved by applying an efficient replication mechanism and enables data recovery after an attack.      
### 77.Anomaly-Based Intrusion Detection System for Cyber-Physical System Security  [ :arrow_down: ](https://arxiv.org/pdf/2110.12963.pdf)
>  Over the past decade, industrial control systems have experienced a massive integration with information technologies. Industrial networks have undergone numerous technical transformations to protect operational and production processes, leading today to a new industrial revolution. Information Technology tools are not able to guarantee confidentiality, integrity and availability in the industrial domain, therefore it is of paramount importance to understand the interaction of the physical components with the networks. For this reason, usually, the industrial control systems are an example of Cyber-Physical Systems (CPS). This paper aims to provide a tool for the detection of cyber attacks in cyber-physical systems. This method is based on Machine Learning to increase the security of the system. Through the analysis of the values assumed by Machine Learning it is possible to evaluate the classification performance of the three models. The model obtained using the training set, allows to classify a sample of anomalous behavior and a sample that is related to normal behavior. The attack identification is implemented in water tank system, and the identification approach using Machine Learning aims to avoid dangerous states, such as the overflow of a tank. The results are promising, demonstrating its effectiveness.      
### 78.Optimal Transmit Beamforming for Secrecy Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2110.12945.pdf)
>  This paper studies a secrecy integrated sensing and communication (ISAC) system, in which a multi-antenna base station (BS) aims to send confidential messages to a single-antenna communication user (CU), and at the same time sense several targets that may be suspicious eavesdroppers. To ensure the sensing quality while preventing the eavesdropping, we consider that the BS sends dedicated sensing signals (in addition to confidential information signals) that play a dual role of artificial noise (AN) for confusing the eavesdropping targets. Under this setup, we jointly optimize the transmit information and sensing beamforming at the BS, to minimize the matching error between the transmit beampattern and a desired beampattern for sensing, subject to the minimum secrecy rate requirement at the CU and the transmit power constraint at the BS. Although the formulated problem is non-convex, we propose an algorithm to obtain the globally optimal solution by using the semidefinite relaxation (SDR) together with a one-dimensional (1D) search. Next, to avoid the high complexity induced by the 1D search, we also present two sub-optimal solutions based on zero-forcing and separate beamforming designs, respectively. Numerical results show that the proposed designs properly adjust the information and sensing beams to balance the tradeoffs among communicating with CU, sensing targets, and confusing eavesdroppers, thus achieving desirable transmit beampattern for sensing while ensuring the CU's secrecy rate.      
### 79.Learning to run a power network with trust  [ :arrow_down: ](https://arxiv.org/pdf/2110.12908.pdf)
>  Artificial agents are promising for realtime power system operations, particularly, to compute remedial actions for congestion management. Currently, these agents are limited to only autonomously run by themselves. However, autonomous agents will not be deployed any time soon. Operators will still be in charge of taking action in the future. Aiming at designing an assistant for operators, we here consider humans in the loop and propose an original formulation for this problem. We first advance an agent with the ability to send to the operator alarms ahead of time when the proposed actions are of low confidence. We further model the operator's available attention as a budget that decreases when alarms are sent. We present the design and results of our competition "Learning to run a power network with trust" in which we benchmark the ability of submitted agents to send relevant alarms while operating the network to their best.      
### 80.Cortical representations of Auditory Perception using Graph Independent Component on EEG  [ :arrow_down: ](https://arxiv.org/pdf/2110.12904.pdf)
>  Recent studies indicate that the neurons involved in a cognitive task aren't locally limited but span out to multiple human brain regions. We obtain network components and their locations for the task of listening to music. The recorded EEG data is modeled as a graph, and it is assumed that the overall activity is a contribution of several independent subnetworks. To identify these intrinsic cognitive subnetworks corresponding to music perception, we propose to decompose the whole brain graph-network into multiple subnetworks. We perform this decomposition to a group of brain networks by performing Graph-Independent Component Analysis. Graph-ICA is a variant of ICA that decomposes the measured graph into independent source graphs. Having obtained independent subnetworks, we calculate the electrode positions by computing the local maxima of these subnetwork matrices. We observe that the computed electrodes' location corresponds to the temporal lobes and the Broca's area, which are indeed involved in the task of auditory processing and perception. The computed electrodes also span the brain's frontal lobe, which is involved in attention and generating a stimulus-evoked response. The weight of the subnetwork that corresponds to the aforementioned brain regions increases with the increase in the music recording's tempo. The results suggest that whole-brain networks can be decomposed into independent subnetworks and analyze cognitive responses to music stimulus.      
### 81.Efficient Coding Approach Towards Non-Linear Spectro-Temporal Receptive Fields  [ :arrow_down: ](https://arxiv.org/pdf/2110.12903.pdf)
>  Linear Non-Linear(LN) models are widely used to characterize the receptive fields of early-stage auditory processing. We apply the principle of efficient coding to the LN model of Spectro-Temporal Receptive Fields(STRFs) of the neurons in primary auditory cortex. The Efficient Coding Principle has been previously used to understand early visual receptive fields and linear STRFs in auditory processing. Efficient coding is realized by jointly optimizing the mutual information between stimuli and neural responses subjected to the metabolic cost of firing spikes. We compare the predictions of the efficient coding principle with the physiological observations, which match qualitatively under realistic conditions of noise in stimuli and the spike generation process.      
### 82.Automated Scoring System of HER2 in Pathological Images under the Microscope  [ :arrow_down: ](https://arxiv.org/pdf/2110.12900.pdf)
>  Breast cancer is the most common cancer among women worldwide. The human epidermal growth factor receptor 2(HER2) with immunohistochemical(IHC) is widely used for pathological evaluation to provide the appropriate therapy for patients with breast cancer. However, the deficiency of pathologists is extremely significant in the current society, and visual diagnosis of the HER2 overexpression is subjective and susceptible to inter-observer variation. Recently, with the rapid development of artificial intelligence(AI) in disease diagnosis, several automated HER2 scoring methods using traditional computer vision or machine learning methods indicate the improvement of the HER2 diagnostic accuracy, but the unreasonable interpretation in pathology, as well as the expensive and ethical issues for annotation, make these methods still have a long way to deploy in hospitals to ease pathologists' burden in real. In this paper, we propose a HER2 automated scoring system that strictly follows the HER2 scoring guidelines simulating the real workflow of HER2 scores diagnosis by pathologists. Unlike the previous work, our method takes the positive control of HER2 into account to make sure the assay performance for each slide, eliminating work for repeated comparison and checking for the current field of view(FOV) and positive control FOV, especially for the borderline cases. Besides, for each selected FOV under the microscope, our system provides real-time HER2 scores analysis and visualizations of the membrane staining intensity and completeness corresponding with the cell classification. Our rigorous workflow along with the flexible interactive adjustion in demand substantially assists pathologists to finish the HER2 diagnosis faster and improves the robustness and accuracy. The proposed system will be embedded in our Thorough Eye platform for deployment in hospitals.      
### 83.Photonics-assisted microwave pulse detection and frequency measurement based on pulse replication and frequency-to-time mapping  [ :arrow_down: ](https://arxiv.org/pdf/2110.12857.pdf)
>  A photonics-assisted microwave pulse detection and frequency measurement scheme is proposed. The unknown microwave pulse is converted to the optical domain and then injected into a fiber loop for pulse replication, which makes it easier to identify the microwave pulse with large pulse repetition interval (PRI), whereas stimulated Brillouin scattering-based frequency-to-time mapping (FTTM) is utilized to measure the carrier frequency of the microwave pulse. A sweep optical carrier is generated and modulated by the unknown microwave pulse and a continuous-wave single-frequency reference, generating two different frequency sweep optical signals, which are combined and used as the probe wave to detect a fixed Brillouin gain spectrum. When the optical signal is detected in a photodetector, FTTM is realized and the frequency of the microwave pulse can be determined. An experiment is performed. For a fiber loop containing a 210-m fiber, pulse replication and FTTM of the pulses with a PRI of 20 {\mu}s and pulse width of 1.20, 1.00, 0.85, and 0.65 {\mu}s are realized. Under a certain sweep frequency chirp rate of 0.978 THz/s, the measurement errors are below {\pm}12 and {\pm}5 MHz by using one pair of pulses and multiple pairs of pulses, respectively. The influence of the sweep frequency chirp rate and pulse width on the measurement error has also been studied. To a certain extent, the faster the frequency sweep, the greater the frequency measurement error. For a specific sweep frequency chirp rate, the measurement error is almost unaffected by the pulse width to be measured.      
### 84.Actions Speak Louder than Listening: Evaluating Music Style Transfer based on Editing Experience  [ :arrow_down: ](https://arxiv.org/pdf/2110.12855.pdf)
>  The subjective evaluation of music generation techniques has been mostly done with questionnaire-based listening tests while ignoring the perspectives from music composition, arrangement, and soundtrack editing. In this paper, we propose an editing test to evaluate users' editing experience of music generation models in a systematic way. To do this, we design a new music style transfer model combining the non-chronological inference architecture, autoregressive models and the Transformer, which serves as an improvement from the baseline model on the same style transfer task. Then, we compare the performance of the two models with a conventional listening test and the proposed editing test, in which the quality of generated samples is assessed by the amount of effort (e.g., the number of required keyboard and mouse actions) spent by users to polish a music clip. Results on two target styles indicate that the improvement over the baseline model can be reflected by the editing test quantitatively. Also, the editing test provides profound insights which are not accessible from usual listening tests. The major contribution of this paper is the systematic presentation of the editing test and the corresponding insights, while the proposed music style transfer model based on state-of-the-art neural networks represents another contribution.      
### 85.Effect of surface treatment on vibration energy transfer of ultrasonic sonotrode  [ :arrow_down: ](https://arxiv.org/pdf/2110.12842.pdf)
>  In this paper, two kinds of ultrasonic radiation rod with surface treatment (ion nitriding and vacuum carburizing) are selected to carry out finite element analysis on ultrasonic vibration system and casting system, and explore the influence of surface treatment on vibration energy transmission of radiation rod. The cavitation field of radiation rod with different surface treatment in water was obtained through the cavitation erosion area of aluminum foil in water by using the aluminum foil cavitation experiment, so as to verify the simulation results of sound pressure field in aluminum melt. The results show that the surface treatment weakens the vibration response of the radiating rod, reduces the longitudinal amplitude of the radiating rod, and reduces the amplitude of sound pressure transmitted into the aluminum melt.      
### 86.Silicon photonic-electronic neural network for fibre nonlinearity compensation  [ :arrow_down: ](https://arxiv.org/pdf/2110.12833.pdf)
>  In optical communication systems, fibre nonlinearity is the major obstacle in increasing the transmission capacity. Typically, digital signal processing techniques and hardware are used to deal with optical communication signals, but increasing speed and computational complexity create challenges for such approaches. Highly parallel, ultrafast neural networks using photonic devices have the potential to ease the requirements placed on the digital signal processing circuits by processing the optical signals in the analogue domain. Here we report a silicon photonice-lectronic neural network for solving fibre nonlinearity compensation of submarine optical fibre transmission systems. Our approach uses a photonic neural network based on wavelength-division multiplexing built on a CMOS-compatible silicon photonic platform. We show that the platform can be used to compensate optical fibre nonlinearities and improve the signal quality (Q)-factor in a 10,080 km submarine fibre communication system. The Q-factor improvement is comparable to that of a software-based neural network implemented on a 32-bit graphic processing unit-assisted workstation. Our reconfigurable photonic-electronic integrated neural network promises to address pressing challenges in high-speed intelligent signal processing.      
### 87.High-Speed Trains Access Connectivity Through RIS-Assisted FSO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2110.12804.pdf)
>  Free-space optic (FSO) is a promising solution to provide broadband Internet access for high-speed trains (HSTs). Besides, reconfigurable intelligent surfaces (RIS) are considered as hardware technology to improve performance of optical wireless communication systems. In this paper, we propose a RIS-assisted FSO system to provide access connectivity for HTSs, as an upgrade for the existing direct and relay-assisted FSO access setups. Our motivation is mainly based on well-proven results indicating that a RIS-assisted optical wireless system, with a large enough number of RIS elements, outperforms a relay-assisted one thanks to its programmable structure. We firstly compute the statistical expressions of the considered RIS-assisted FSO channels under weak and moderate-to-strong fading conditions. Then, the network's average signal-to-noise ratio and outage probability are formulated based on the assumed fading conditions, and for two fixed- and dynamic-oriented RIS coverage scenarios. Our results reveal that the proposed access network offers up to around 44% higher data rates and 240% wider coverage area for each FSO base station (FSO-BS) compared to those of the relay-assisted one. The increase of coverage area, on average, reduces 67% the number of required FSO-BSs for a given distance, which results in fewer handover processes compared to the alternative setups. Finally, the results are verified through Monte-Carlo simulations.      
### 88.RIS-aided Massive MIMO: Achieving Large Multiplexing Gains with non-Large Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2110.12800.pdf)
>  This paper considers an antenna structure where a (non-large) array of radiating elements is placed at short distance in front of a reconfigurable intelligent surface (RIS). We propose a channel estimation procedure using different configurations of the RIS elements and derive a closed-form expression for an achievable downlink spectral efficiency by using the popular hardening lower-bound. Next, we formulate an optimization problem, with respect to the phase shifts of the RIS, aimed at minimizing the channels cross-correlations while preserving the channels individual norms. The numerical analysis shows that the proposed structure is capable of overcoming the performance of a conventional massive MIMO system without the RIS.      
### 89.Scalable Channel Estimation and Reflection Optimization for Reconfigurable Intelligent Surface-Enhanced OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12799.pdf)
>  This paper proposes a scalable channel estimation and reflection optimization framework for reconfigurable intelligent surface (RIS)-enhanced orthogonal frequency division multiplexing (OFDM) systems. Specifically, the proposed scheme firstly generates a training set of RIS reflection coefficient vectors offline. For each RIS reflection coefficient vector in the training set, the proposed scheme estimates only the end-to-end composite channel and then performs the transmit power allocation. As a result, the RIS reflection optimization is simplified by searching for the optimal reflection coefficient vector maximizing the achievable rate from the pre-designed training set. The proposed scheme is capable of flexibly adjusting the training overhead according to the given channel coherence time, which is in sharp contrast to the conventional counterparts. Moreover, we discuss the computational complexity of the proposed scheme and analyze the theoretical scaling law of the achievable rate versus the number of training slots. Finally, simulation results demonstrate that the proposed scheme is superior to existing approaches in terms of decreasing training overhead, reducing complexity as well as improving rate performance in the presence of channel estimation errors.      
### 90.Random Matrix based Physical Layer Secret Key Generation in Static Channels  [ :arrow_down: ](https://arxiv.org/pdf/2110.12785.pdf)
>  Physical layer secret key generation exploits the reciprocal channel randomness for key generation and has proven to be an effective addition security layer in wireless communications. However, static or scarcely random channels require artificially induced dynamics to improve the secrecy performance, e.g., using intelligent reflecting surface (IRS). One key challenge is that the induced random phase from IRS is also reflected in the direction to eavesdroppers (Eve). This leakage enables Eve nodes to estimate the legitimate channels and secret key via a globally known pilot sequence. To mitigate the secret key leakage issue, we propose to exploit random matrix theory to inform the design of a new physical layer secret key generation (PL-SKG) algorithm. We prove that, when sending appropriate random Gaussian matrices, the singular values of Alice's and Bob's received signals follow a similar probability distribution. Leveraging these common singular values, we propose a random Gaussian matrix based PL-SKG (RGM PL-SKG), which avoids the usages of the globally known pilot and thereby prevents the aforementioned leakage issue. Our results show the following: (i) high noise resistance which leads to superior secret key rate (SKR) improvement (up to 300%) in low SNR regime, and (ii) general improved SKR performance against multiple colluded Eves. We believe our combination of random matrix theory and PL-SKG shows a new paradigm to secure the wireless communication channels.      
### 91.A Deep Reinforcement Learning Approach for Audio-based Navigation and Audio Source Localization in Multi-speaker Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.12778.pdf)
>  In this work we apply deep reinforcement learning to the problems of navigating a three-dimensional environment and inferring the locations of human speaker audio sources within, in the case where the only available information is the raw sound from the environment, as a simulated human listener placed in the environment would hear it. For this purpose we create two virtual environments using the Unity game engine, one presenting an audio-based navigation problem and one presenting an audio source localization problem. We also create an autonomous agent based on PPO online reinforcement learning algorithm and attempt to train it to solve these environments. Our experiments show that our agent achieves adequate performance and generalization ability in both environments, measured by quantitative metrics, even when a limited amount of training data are available or the environment parameters shift in ways not encountered during training. We also show that a degree of agent knowledge transfer is possible between the environments.      
### 92.Lexicographic Optimisation of Conditional Value at Risk and Expected Value for Risk-Averse Planning in MDPs  [ :arrow_down: ](https://arxiv.org/pdf/2110.12746.pdf)
>  Planning in Markov decision processes (MDPs) typically optimises the expected cost. However, optimising the expectation does not consider the risk that for any given run of the MDP, the total cost received may be unacceptably high. An alternative approach is to find a policy which optimises a risk-averse objective such as conditional value at risk (CVaR). In this work, we begin by showing that there can be multiple policies which obtain the optimal CVaR. We formulate the lexicographic optimisation problem of minimising the expected cost subject to the constraint that the CVaR of the total cost is optimal. We present an algorithm for this problem and evaluate our approach on three domains, including a road navigation domain based on real traffic data. Our experimental results demonstrate that our lexicographic approach attains improved expected cost while maintaining the optimal CVaR.      
### 93.DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2110.12612.pdf)
>  This paper describes the Microsoft end-to-end neural text to speech (TTS) system: DelightfulTTS for Blizzard Challenge 2021. The goal of this challenge is to synthesize natural and high-quality speech from text, and we approach this goal in two perspectives: The first is to directly model and generate waveform in 48 kHz sampling rate, which brings higher perception quality than previous systems with 16 kHz or 24 kHz sampling rate; The second is to model the variation information in speech through a systematic design, which improves the prosody and naturalness. Specifically, for 48 kHz modeling, we predict 16 kHz mel-spectrogram in acoustic model, and propose a vocoder called HiFiNet to directly generate 48 kHz waveform from predicted 16 kHz mel-spectrogram, which can better trade off training efficiency, modelling stability and voice quality. We model variation information systematically from both explicit (speaker ID, language ID, pitch and duration) and implicit (utterance-level and phoneme-level prosody) perspectives: 1) For speaker and language ID, we use lookup embedding in training and inference; 2) For pitch and duration, we extract the values from paired text-speech data in training and use two predictors to predict the values in inference; 3) For utterance-level and phoneme-level prosody, we use two reference encoders to extract the values in training, and use two separate predictors to predict the values in inference. Additionally, we introduce an improved Conformer block to better model the local and global dependency in acoustic model. For task SH1, DelightfulTTS achieves 4.17 mean score in MOS test and 4.35 in SMOS test, which indicates the effectiveness of our proposed system      
### 94.Antenna Array Enabled Space/Air/Ground Communications and Networking for 6G  [ :arrow_down: ](https://arxiv.org/pdf/2110.12610.pdf)
>  Antenna arrays have a long history of more than 100 years and have evolved closely with the development of electronic and information technologies, playing an indispensable role in wireless communications and radar. With the rapid development of electronic and information technologies, the demand for all-time, all-domain, and full-space network services has exploded, and new communication requirements have been put forward on various space/air/ground platforms. To meet the ever increasing requirements of the future sixth generation (6G) wireless communications, such as high capacity, wide coverage, low latency, and strong robustness, it is promising to employ different types of antenna arrays with various beamforming technologies in space/air/ground communication networks, bringing in advantages such as considerable antenna gains, multiplexing gains, and diversity gains. However, enabling antenna array for space/air/ground communication networks poses specific, distinctive and tricky challenges, which has aroused extensive research attention. This paper aims to overview the field of antenna array enabled space/air/ground communications and networking. The technical potentials and challenges of antenna array enabled space/air/ground communications and networking are presented first. Subsequently, the antenna array structures and designs are discussed. We then discuss various emerging technologies facilitated by antenna arrays to meet the new communication requirements of space/air/ground communication systems. Enabled by these emerging technologies, the distinct characteristics, challenges, and solutions for space communications, airborne communications, and ground communications are reviewed. Finally, we present promising directions for future research in antenna array enabled space/air/ground communications and networking.      
### 95.Lhotse: a speech data representation library for the modern deep learning ecosystem  [ :arrow_down: ](https://arxiv.org/pdf/2110.12561.pdf)
>  Speech data is notoriously difficult to work with due to a variety of codecs, lengths of recordings, and meta-data formats. We present Lhotse, a speech data representation library that draws upon lessons learned from Kaldi speech recognition toolkit and brings its concepts into the modern deep learning ecosystem. Lhotse provides a common JSON description format with corresponding Python classes and data preparation recipes for over 30 popular speech corpora. Various datasets can be easily combined together and re-purposed for different tasks. The library handles multi-channel recordings, long recordings, local and cloud storage, lazy and on-the-fly operations amongst other features. We introduce Cut and CutSet concepts, which simplify common data wrangling tasks for audio and help incorporate acoustic context of speech utterances. Finally, we show how Lhotse leverages PyTorch data API abstractions and adopts them to handle speech data for deep learning.      
### 96.Mathematical Modeling for Holistic Convex Optimization of Hybrid Trains  [ :arrow_down: ](https://arxiv.org/pdf/2110.12540.pdf)
>  We look into modeling fuel cell hybrid trains for the purpose of optimizing their operation using convex optimization. Models and constraints necessary to form a physically feasible yet convex problem are reviewed. This effort is described as holistic due to the broad consideration of train speed, energy management system, and battery thermals. The minimized objective is hydrogen fuel consumption for a given target journey time. A novel battery thermal model is proposed to aid with battery thermal management and thus preserve battery lifetime. All models are derived in the space-domain which along constraint relaxations guarantee a convex optimization problem. First-principle knowledge and real-world data justify the suitableness of the proposed models for the intended optimization problem.      
### 97.Discrete acoustic space for an efficient sampling in neural text-to-speech  [ :arrow_down: ](https://arxiv.org/pdf/2110.12539.pdf)
>  We present an SVQ-VAE architecture using a split vector quantizer for NTTS, as an enhancement to the well-known VAE and VQ-VAE architectures. Compared to these previous architectures, our proposed model retains the benefits of using an utterance-level bottleneck, while reducing the associated loss of representation power. We train the model on recordings in the highly expressive task-oriented dialogues domain and show that SVQ-VAE achieves a statistically significant improvement in naturalness over the VAE and VQ-VAE models. Furthermore, we demonstrate that the SVQ-VAE acoustic space is predictable from text, reducing the gap between the standard constant vector synthesis and vocoded recordings by 32%.      
### 98.Fronthaul Compression for Uplink Massive MIMO using Matrix Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2110.12532.pdf)
>  Massive MIMO opens up attractive possibilities for next generation wireless systems with its large number of antennas offering spatial diversity and multiplexing gain. However, the fronthaul link that connects a massive MIMO Remote Radio Head (RRH) and carries IQ samples to the Baseband Unit (BBU) of the base station can throttle the network capacity/speed if appropriate data compression techniques are not applied. In this paper, we propose an iterative technique for fronthaul load reduction in the uplink for massive MIMO systems that utilizes the convolution structure of the received signals. We use an alternating minimisation algorithm for blind deconvolution of the received data matrix that provides compression ratios of 30-50. In addition, the technique presented here can be used for blind decoding of OFDM signals in massive MIMO systems.      
### 99.Learning convex regularizers satisfying the variational source condition for inverse problems  [ :arrow_down: ](https://arxiv.org/pdf/2110.12520.pdf)
>  Variational regularization has remained one of the most successful approaches for reconstruction in imaging inverse problems for several decades. With the emergence and astonishing success of deep learning in recent years, a considerable amount of research has gone into data-driven modeling of the regularizer in the variational setting. Our work extends a recently proposed method, referred to as adversarial convex regularization (ACR), that seeks to learn data-driven convex regularizers via adversarial training in an attempt to combine the power of data with the classical convex regularization theory. Specifically, we leverage the variational source condition (SC) during training to enforce that the ground-truth images minimize the variational loss corresponding to the learned convex regularizer. This is achieved by adding an appropriate penalty term to the ACR training objective. The resulting regularizer (abbreviated as ACR-SC) performs on par with the ACR, but unlike ACR, comes with a quantitative convergence rate estimate.      
### 100.Deep Neural Networks on EEG Signals to Predict Auditory Attention Score Using Gramian Angular Difference Field  [ :arrow_down: ](https://arxiv.org/pdf/2110.12503.pdf)
>  Auditory attention is a selective type of hearing in which people focus their attention intentionally on a specific source of a sound or spoken words whilst ignoring or inhibiting other auditory stimuli. In some sense, the auditory attention score of an individual shows the focus the person can have in auditory tasks. The recent advancements in deep learning and in the non-invasive technologies recording neural activity beg the question, can deep learning along with technologies such as electroencephalography (EEG) be used to predict the auditory attention score of an individual? In this paper, we focus on this very problem of estimating a person's auditory attention level based on their brain's electrical activity captured using 14-channeled EEG signals. More specifically, we deal with attention estimation as a regression problem. The work has been performed on the publicly available Phyaat dataset. The concept of Gramian Angular Difference Field (GADF) has been used to convert time-series EEG data into an image having 14 channels, enabling us to train various deep learning models such as 2D CNN, 3D CNN, and convolutional autoencoders. Their performances have been compared amongst themselves as well as with the work done previously. Amongst the different models we tried, 2D CNN gave the best performance. It outperformed the existing methods by a decent margin of 0.22 mean absolute error (MAE).      
### 101.Robustness via Uncertainty-aware Cycle Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2110.12467.pdf)
>  Unpaired image-to-image translation refers to learning inter-image-domain mapping without corresponding image pairs. Existing methods learn deterministic mappings without explicitly modelling the robustness to outliers or predictive uncertainty, leading to performance degradation when encountering unseen perturbations at test time. To address this, we propose a novel probabilistic method based on Uncertainty-aware Generalized Adaptive Cycle Consistency (UGAC), which models the per-pixel residual by generalized Gaussian distribution, capable of modelling heavy-tailed distributions. We compare our model with a wide variety of state-of-the-art methods on various challenging tasks including unpaired image translation of natural images, using standard datasets, spanning autonomous driving, maps, facades, and also in medical imaging domain consisting of MRI. Experimental results demonstrate that our method exhibits stronger robustness towards unseen perturbations in test data. Code is released here: <a class="link-external link-https" href="https://github.com/ExplainableML/UncertaintyAwareCycleConsistency" rel="external noopener nofollow">this https URL</a>.      
### 102.Model Predictive Control with Gaussian Processes for Flexible Multi-Modal Physical Human Robot Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2110.12433.pdf)
>  Physical human-robot interaction can improve human ergonomics, task efficiency, and the flexibility of automation, but often requires application-specific methods to detect human state and determine robot response. At the same time, many potential human-robot interaction tasks involve discrete modes, such as phases of a task or multiple possible goals, where each mode has a distinct objective and human behavior. In this paper, we propose a novel method for multi-modal physical human-robot interaction that builds a Gaussian process model for human force in each mode of a collaborative task. These models are then used for Bayesian inference of the mode, and to determine robot reactions through model predictive control. This approach enables optimization of robot trajectory based on the belief of human intent, while considering robot impedance and human joint configuration, according to ergonomic- and/or task-related objectives. The proposed method reduces programming time and complexity, requiring only a low number of demonstrations (here, three per mode) and a mode-specific objective function to commission a flexible online human-robot collaboration task. We validate the method with experiments on an admittance-controlled industrial robot, performing a collaborative assembly task with two modes where assistance is provided in full six degrees of freedom. It is shown that the developed algorithm robustly re-plans to changes in intent or robot initial position, achieving online control at 15 Hz.      
### 103.Quantum Computer Music: Foundations and Initial Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2110.12408.pdf)
>  Quantum computing is a nascent technology, which is advancing rapidly. There is a long history of research into using computers for music. Nowadays computers are absolutely essential for the music economy. Thus, it is very likely that quantum computers will impact the music industry in time to come. This chapter lays the foundations of the new field of 'Quantum Computer Music'. It begins with an introduction to algorithmic computer music and methods to program computers to generate music, such as Markov chains and random walks. Then, it presents quantum computing versions of those methods. The discussions are supported by detailed explanations of quantum computing concepts and walk-through examples. A bespoke generative music algorithm is presented, the Basak-Miranda algorithm, which leverages a property of quantum mechanics known as constructive and destructive interference to operate a musical Markov chain. An Appendix introducing the fundamentals of quantum computing deemed necessary to understand the chapter and a link to access Jupyter Notebooks with examples are also provided.      
### 104.SenseMag: Enabling Low-Cost Traffic Monitoring using Non-invasive Magnetic Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.12377.pdf)
>  The operation and management of intelligent transportation systems (ITS), such as traffic monitoring, relies on real-time data aggregation of vehicular traffic information, including vehicular types (e.g., cars, trucks, and buses), in the critical roads and highways. While traditional approaches based on vehicular-embedded GPS sensors or camera networks would either invade drivers' privacy or require high deployment cost, this paper introduces a low-cost method, namely SenseMag, to recognize the vehicular type using a pair of non-invasive magnetic sensors deployed on the straight road section. SenseMag filters out noises and segments received magnetic signals by the exact time points that the vehicle arrives or departs from every sensor node. Further, SenseMag adopts a hierarchical recognition model to first estimate the speed/velocity, then identify the length of vehicle using the predicted speed, sampling cycles, and the distance between the sensor nodes. With the vehicle length identified and the temporal/spectral features extracted from the magnetic signals, SenseMag classify the types of vehicles accordingly. Some semi-automated learning techniques have been adopted for the design of filters, features, and the choice of hyper-parameters. Extensive experiment based on real-word field deployment (on the highways in Shenzhen, China) shows that SenseMag significantly outperforms the existing methods in both classification accuracy and the granularity of vehicle types (i.e., 7 types by SenseMag versus 4 types by the existing work in comparisons). To be specific, our field experiment results validate that SenseMag is with at least $90\%$ vehicle type classification accuracy and less than 5\% vehicle length classification error.      
### 105.Quality Map Fusion for Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.12338.pdf)
>  Generative adversarial models that capture salient low-level features which convey visual information in correlation with the human visual system (HVS) still suffer from perceptible image degradations. The inability to convey such highly informative features can be attributed to mode collapse, convergence failure and vanishing gradients. In this paper, we improve image quality adversarially by introducing a novel quality map fusion technique that harnesses image features similar to the HVS and the perceptual properties of a deep convolutional neural network (DCNN). We extend the widely adopted l2 Wasserstein distance metric to other preferable quality norms derived from Banach spaces that capture richer image properties like structure, luminance, contrast and the naturalness of images. We also show that incorporating a perceptual attention mechanism (PAM) that extracts global feature embeddings from the network bottleneck with aggregated perceptual maps derived from standard image quality metrics translate to a better image quality. We also demonstrate impressive performance over other methods.      
### 106.Fully Distributed Actor-Critic Architecture for Multitask Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.12306.pdf)
>  We propose a fully distributed actor-critic architecture, named Diff-DAC, with application to multitask reinforcement learning (MRL). During the learning process, agents communicate their value and policy parameters to their neighbours, diffusing the information across a network of agents with no need for a central station. Each agent can only access data from its local task, but aims to learn a common policy that performs well for the whole set of tasks. The architecture is scalable, since the computational and communication cost per agent depends on the number of neighbours rather than the overall number of agents. We derive Diff-DAC from duality theory and provide novel insights into the actor-critic framework, showing that it is actually an instance of the dual ascent method. We prove almost sure convergence of Diff-DAC to a common policy under general assumptions that hold even for deep-neural network approximations. For more restrictive assumptions, we also prove that this common policy is a stationary point of an approximation of the original problem. Numerical results on multitask extensions of common continuous control benchmarks demonstrate that Diff-DAC stabilises learning and has a regularising effect that induces higher performance and better generalisation properties than previous architectures.      
### 107.Self-Validation: Early Stopping for Single-Instance Deep Generative Priors  [ :arrow_down: ](https://arxiv.org/pdf/2110.12271.pdf)
>  Recent works have shown the surprising effectiveness of deep generative models in solving numerous image reconstruction (IR) tasks, even without training data. We call these models, such as deep image prior and deep decoder, collectively as single-instance deep generative priors (SIDGPs). The successes, however, often hinge on appropriate early stopping (ES), which by far has largely been handled in an ad-hoc manner. In this paper, we propose the first principled method for ES when applying SIDGPs to IR, taking advantage of the typical bell trend of the reconstruction quality. In particular, our method is based on collaborative training and self-validation: the primal reconstruction process is monitored by a deep autoencoder, which is trained online with the historic reconstructed images and used to validate the reconstruction quality constantly. Experimentally, on several IR problems and different SIDGPs, our self-validation method is able to reliably detect near-peak performance and signal good ES points. Our code is available at <a class="link-external link-https" href="https://sun-umn.github.io/Self-Validation/" rel="external noopener nofollow">this https URL</a>.      
### 108.espiownage: Tracking Transients in Steelpan Drum Strikes Using Surveillance Technology  [ :arrow_down: ](https://arxiv.org/pdf/2110.12261.pdf)
>  We present an improvement in the ability to meaningfully track features in high speed videos of Caribbean steelpan drums illuminated by Electronic Speckle Pattern Interferometry (ESPI). This is achieved through the use of up-to-date computer vision libraries for object detection and image segmentation as well as a significant effort toward cleaning the dataset previously used to train systems for this application. Besides improvements on previous metric scores by 10% or more, noteworthy in this project are the introduction of a segmentation-regression map for the entire drum surface yielding interference fringe counts comparable to those obtained via object detection, as well as the accelerated workflow for coordinating the data-cleaning-and-model-training feedback loop for rapid iteration allowing this project to be conducted on a timescale of only 18 days.      
### 109.Knowledge Transfer based Radio and Computation Resource Allocation for 5G RAN Slicing  [ :arrow_down: ](https://arxiv.org/pdf/2110.12245.pdf)
>  To implement network slicing in 5G, resource allocation is a key function to allocate limited network resources such as radio and computation resources to multiple slices. However, the joint resource allocation also leads to a higher complexity in the network management. In this work, we propose a knowledge transfer based resource allocation (KTRA) method to jointly allocate radio and computation resources for 5G RAN slicing. Compared with existing works, the main difference is that the proposed KTRA method has a knowledge transfer capability. It is designed to use the prior knowledge of similar tasks to improve performance of the target task, e.g., faster convergence speed or higher average reward. The proposed KTRA is compared with Qlearning based resource allocation (QLRA), and KTRA method presents a 18.4% lower URLLC delay and a 30.1% higher eMBB throughput as well as a faster convergence speed.      
### 110.Generalized Polarization Transform: A Novel Coded Transmission Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2110.12224.pdf)
>  With the standardization and deployment of 5G, the focus has now shifted toward developing beyond-5G (B5G) solutions. A new wave of applications and services will demand ultra-high data rates and reliability. To this end, future wireless systems are expected to pave the way for entirely new fundamental air interface technologies to attain a breakthrough in spectrum efficiency (SE). This article discusses a new paradigm, named generalized polarization transform (GPT), to achieve an integrated design of coding, modulation, multi-antenna, multiple access, etc., in a real sense. The GPT enabled air interface develops far-reaching insights that the joint optimization of critical air interface ingredients can achieve remarkable gains on SE compared with the state-of-the-art module-stacking design. We present a comprehensive overview of the application of GPT in various coded transmission systems approaching Shannon limits under short to moderate blocklengths and highlight several promising trends for future research.      
### 111.PROMPT: Parallel Iterative Algorithm for $\ell_{p}$ norm linear regression via Majorization Minimization with an application to semi-supervised graph learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.12190.pdf)
>  In this paper, we consider the problem of $\ell_{p}$ norm linear regression, which has several applications such as in sparse recovery, data clustering, and semi-supervised learning. The problem, even though convex, does not enjoy a closed-form solution. The state-of-the-art algorithms are iterative but suffer from convergence issues, i.e., they either diverge for p&gt;3 or the convergence to the optimal solution is sensitive to the initialization of the algorithm. Also, these algorithms are not generalizable to every possible value of $p$. In this paper, we propose an iterative algorithm : Parallel IteRative AlgOrithM for $\ell_{P}$ norm regression via MajorizaTion Minimization (PROMPT) based on the principle of Majorization Minimization and prove that the proposed algorithm is monotonic and converges to the optimal solution of the problem for any value of $p$. The proposed algorithm can also parallelly update each element of the regression variable, which helps to handle large scale data efficiently, a common scenario in this era of data explosion. Subsequently, we show that the proposed algorithm can also be applied for the graph based semi-supervised learning problem. We show through numerical simulations that the proposed algorithm converges to the optimal solution for any random initialization and also performs better than the state-of-the-art algorithms in terms of speed of convergence. We also evaluate the performance of the proposed algorithm using simulated and real data for the graph based semi-supervised learning problem.      
### 112.Spatio-Temporal Graph Complementary Scattering Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.12150.pdf)
>  Spatio-temporal graph signal analysis has a significant impact on a wide range of applications, including hand/body pose action recognition. To achieve effective analysis, spatio-temporal graph convolutional networks (ST-GCN) leverage the powerful learning ability to achieve great empirical successes; however, those methods need a huge amount of high-quality training data and lack theoretical interpretation. To address this issue, the spatio-temporal graph scattering transform (ST-GST) was proposed to put forth a theoretically interpretable framework; however, the empirical performance of this approach is constrainted by the fully mathematical design. To benefit from both sides, this work proposes a novel complementary mechanism to organically combine the spatio-temporal graph scattering transform and neural networks, resulting in the proposed spatio-temporal graph complementary scattering networks (ST-GCSN). The essence is to leverage the mathematically designed graph wavelets with pruning techniques to cover major information and use trainable networks to capture complementary information. The empirical experiments on hand pose action recognition show that the proposed ST-GCSN outperforms both ST-GCN and ST-GST.      
### 113.Optimizing Alignment of Speech and Language Latent Spaces for End-to-End Speech Recognition and Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2110.12138.pdf)
>  The advances in attention-based encoder-decoder (AED) networks have brought great progress to end-to-end (E2E) automatic speech recognition (ASR). One way to further improve the performance of AED-based E2E ASR is to introduce an extra text encoder for leveraging extensive text data and thus capture more context-aware linguistic information. However, this approach brings a mismatch problem between the speech encoder and the text encoder due to the different units used for modeling. In this paper, we propose an embedding aligner and modality switch training to better align the speech and text latent spaces. The embedding aligner is a shared linear projection between text encoder and speech encoder trained by masked language modeling (MLM) loss and connectionist temporal classification (CTC), respectively. The modality switch training randomly swaps speech and text embeddings based on the forced alignment result to learn a joint representation space. Experimental results show that our proposed approach achieves a relative 14% to 19% word error rate (WER) reduction on Librispeech ASR task. We further verify its effectiveness on spoken language understanding (SLU), i.e., an absolute 2.5% to 2.8% F1 score improvement on SNIPS slot filling task.      
### 114.A Study of Multimodal Person Verification Using Audio-Visual-Thermal Data  [ :arrow_down: ](https://arxiv.org/pdf/2110.12136.pdf)
>  In this paper, we study an approach to multimodal person verification using audio, visual, and thermal modalities. The combination of audio and visual modalities has already been shown to be effective for robust person verification. From this perspective, we investigate the impact of further increasing the number of modalities by supplementing thermal images. In particular, we implemented unimodal, bimodal, and trimodal verification systems using the state-of-the-art deep learning architectures and compared their performance under clean and noisy conditions. We also compared two popular fusion approaches based on simple score averaging and soft attention mechanism. The experiment conducted on the SpeakingFaces dataset demonstrates the superiority of the trimodal verification system over both unimodal and bimodal systems. To enable the reproducibility of the experiment and facilitate research into multimodal person verification, we make our code, pretrained models and preprocessed dataset freely available in our GitHub repository.      
### 115.On Geometric Connections of Embedded and Quotient Geometries in Riemannian Fixed-rank Matrix Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2110.12121.pdf)
>  In this paper, we propose a general procedure for establishing the landscape connections of a Riemannian optimization problem under the embedded and quotient geometries. By applying the general procedure to the fixed-rank positive semidefinite (PSD) and general matrix optimization, we establish an exact Riemannian gradient connection under two geometries at every point on the manifold and sandwich inequalities between the spectra of Riemannian Hessians at Riemannian first-order stationary points (FOSPs). These results immediately imply an equivalence on the sets of Riemannian FOSPs, Riemannian second-order stationary points (SOSPs) and strict saddles of fixed-rank matrix optimization under the embedded and the quotient geometries. To the best of our knowledge, this is the first geometric landscape connection between the embedded and the quotient geometries for fixed-rank matrix optimization and it provides a concrete example on how these two geometries are connected in Riemannian optimization. In addition, the effects of the Riemannian metric and quotient structure on the landscape connection are discussed. We also observe an algorithmic connection for fixed-rank matrix optimization under two geometries with some specific Riemannian metrics. A number of novel ideas and technical ingredients including a unified treatment for different Riemannian metrics and new horizontal space representations under quotient geometries are developed to obtain our results. The results in this paper deepen our understanding of geometric connections of Riemannian optimization under different Riemannian geometries and provide a few new theoretical insights to unanswered questions in the literature.      
### 116.Single-shot fast 3D imaging through scattering media using structured illumination  [ :arrow_down: ](https://arxiv.org/pdf/2110.12103.pdf)
>  Conventional approaches for 3D imaging in or through scattering media are usually limited to 2D reconstruction of objects at some discontinuous locations, although the time-consuming iteration, guide-star, or complex system are implemented. How to quickly visualize dynamic 3D objects behind scattering media is still an open issue. Here, by using structured light illumination, we propose a single-shot technique that can quickly acquire continuous 3D surfaces of objects hidden behind the diffuser. The proposed method can realize the 3D imaging of single, multiple, and dynamic targets from the speckled structured light patterns under broad or narrow band light illumination, in which only once calibration of the imaging setup is needed before conducting the imaging. Our approach paves the way to quickly visualize dynamic objects behind scattering media in 3D and multispectral.      
### 117.Strategically revealing intentions in General Lotto games  [ :arrow_down: ](https://arxiv.org/pdf/2110.12099.pdf)
>  In this paper, we highlight scenarios in General Lotto games where there exist incentives to reveal one's intentions to an opponent. The General Lotto game is a popular model of competitive resource allocation. We study a multi-step extension where one player has the option to publicly pre-commit resources to battlefields before play begins. In response, the opponent decides which of these battlefields to secure by matching the pre-commitment with its own resources, and which of them to withdraw from entirely. They then engage in a General Lotto game over the remaining set of battlefields. We show that the weaker-resource player never has an incentive to pre-commit, while a stronger player can have incentives to pre-commit. However, this is not necessarily true in settings where the battlefield valuations are asymmetric across players. This setting is known to admit a richer set of outcomes, where multiple payoff-distinct equilibria can arise in simultaneous play. We show that pre-committing in this environment can guarantee a payoff that exceeds the second-highest equilibrium payoff from simultaneous play. Our work highlights the strategic role that revealing information plays can have in a variety of adversarial contexts.      
### 118.Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid Precoding  [ :arrow_down: ](https://arxiv.org/pdf/2110.12059.pdf)
>  In this paper, we propose an end-to-end deep learning-based joint transceiver design algorithm for millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems, which consists of deep neural network (DNN)-aided pilot training, channel feedback, and hybrid analog-digital (HAD) precoding. Specifically, we develop a DNN architecture that maps the received pilots into feedback bits at the receiver, and then further maps the feedback bits into the hybrid precoder at the transmitter. To reduce the signaling overhead and channel state information (CSI) mismatch caused by the transmission delay, a two-timescale DNN composed of a long-term DNN and a short-term DNN is developed. The analog precoders are designed by the long-term DNN based on the CSI statistics and updated once in a frame consisting of a number of time slots. In contrast, the digital precoders are optimized by the short-term DNN at each time slot based on the estimated low-dimensional equivalent CSI matrices. A two-timescale training method is also developed for the proposed DNN with a binary layer. We then analyze the generalization ability and signaling overhead for the proposed DNN based algorithm. Simulation results show that our proposed technique significantly outperforms conventional schemes in terms of bit-error rate performance with reduced signaling overhead and shorter pilot sequences.      
### 119.Development of Semantic Web-based Imaging Database for Biological Morphome  [ :arrow_down: ](https://arxiv.org/pdf/2110.12058.pdf)
>  We introduce the RIKEN Microstructural Imaging Metadatabase, a semantic web-based imaging database in which image metadata are described using the Resource Description Framework (RDF) and detailed biological properties observed in the images can be represented as Linked Open Data. The metadata are used to develop a large-scale imaging viewer that provides a straightforward graphical user interface to visualise a large microstructural tiling image at the gigabyte level. We applied the database to accumulate comprehensive microstructural imaging data produced by automated scanning electron microscopy. As a result, we have successfully managed vast numbers of images and their metadata, including the interpretation of morphological phenotypes occurring in sub-cellular components and biosamples captured in the images. We also discuss advanced utilisation of morphological imaging data that can be promoted by this database.      
### 120.Generative Adversarial Networks for Non-Raytraced Global Illumination on Older GPU Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2110.12039.pdf)
>  We give an overview of the different rendering methods and we demonstrate that the use of a Generative Adversarial Networks (GAN) for Global Illumination (GI) gives a superior quality rendered image to that of a rasterisations image. We utilise the Pix2Pix architecture and specify the hyper-parameters and methodology used to mimic ray-traced images from a set of input features. We also demonstrate that the GANs quality is comparable to the quality of the ray-traced images, but is able to produce the image, at a fraction of the time.      
### 121.Ultimate capacity limit of a multi-span link with phase-insensitive amplification  [ :arrow_down: ](https://arxiv.org/pdf/2110.11958.pdf)
>  The Shannon capacity of a point-to-point link with an optimised configuration of optical amplifiers is compared with general detection strategies permitted by quantum mechanics. Results suggest that the primary application area of receivers based on such strategies may be unamplified short-distance links or free-space optical communication      
### 122.Variational Probabilistic Multi-Hypothesis Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2110.11954.pdf)
>  This paper proposes a novel multi-target tracking (MTT) algorithm for scenarios with arbitrary numbers of measurements per target. We propose the variational probabilistic multi-hypothesis tracking (VPMHT) algorithm based on the variational Bayesian expectation-maximisation (VBEM) algorithm to resolve the MTT problem in the classic PMHT algorithm. With the introduction of variational inference, the proposed VPMHT handles track-loss much better than the conventional probabilistic multi-hypothesis tracking (PMHT) while preserving a similar or even better tracking accuracy. Extensive numerical simulations are conducted to demonstrate the effectiveness of the proposed algorithm.      
### 123.Fast computation of mutual information in the frequency domain with applications to global multimodal image alignment  [ :arrow_down: ](https://arxiv.org/pdf/2106.14699.pdf)
>  Multimodal image alignment is the process of finding spatial correspondences between images formed by different imaging techniques or under different conditions, to facilitate heterogeneous data fusion and correlative analysis. The information-theoretic concept of mutual information (MI) is widely used as a similarity measure to guide multimodal alignment processes, where most works have focused on local maximization of MI that typically works well only for small displacements; this points to a need for global maximization of MI, which has previously been computationally infeasible due to the high run-time complexity of existing algorithms. We propose an efficient algorithm for computing MI for all discrete displacements (formalized as the cross-mutual information function (CMIF)), which is based on cross-correlation computed in the frequency domain. We show that the algorithm is equivalent to a direct method while asymptotically superior in terms of run-time. Furthermore, we propose a method for multimodal image alignment for transformation models with few degrees of freedom (e.g. rigid) based on the proposed CMIF-algorithm. We evaluate the efficacy of the proposed method on three distinct benchmark datasets, of aerial images, cytological images, and histological images, and we observe excellent success-rates (in recovering known rigid transformations), overall outperforming alternative methods, including local optimization of MI as well as several recent deep learning-based approaches. We also evaluate the run-times of a GPU implementation of the proposed algorithm and observe speed-ups from 100 to more than 10,000 times for realistic image sizes compared to a GPU implementation of a direct method. Code is shared as open-source at \url{<a class="link-external link-http" href="http://github.com/MIDA-group/globalign" rel="external noopener nofollow">this http URL</a>}.      
