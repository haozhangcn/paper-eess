# ArXiv eess --Thu, 28 Oct 2021
### 1.End-to-end LSTM based estimation of volcano event epicenter localization  [ :arrow_down: ](https://arxiv.org/pdf/2110.14594.pdf)
>  In this paper, an end-to-end based LSTM scheme is proposed to address the problem of volcano event localization without any a priori model relating phase picking with localization estimation. It is worth emphasizing that automatic phase picking in volcano signals is highly inaccurate because of the short distances between the event epicenters and the seismograph stations. LSTM was chosen due to its capability to capture the dynamics of time varying signals, and to remove or add information within the memory cell state and model long-term dependencies. A brief insight into LSTM is also discussed here. The results presented in this paper show that the LSTM based architecture provided a success rate, i.e., an error smaller than 1.0Km, equal to 48.5%, which in turn is dramatically superior to the one delivered by automatic phase picking. Moreover, the proposed end-to-end LSTM based method gave a success rate 18% higher than CNN.      
### 2.TA-Net: Topology-Aware Network for Gland Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14593.pdf)
>  Gland segmentation is a critical step to quantitatively assess the morphology of glands in histopathology image analysis. However, it is challenging to separate densely clustered glands accurately. Existing deep learning-based approaches attempted to use contour-based techniques to alleviate this issue but only achieved limited success. To address this challenge, we propose a novel topology-aware network (TA-Net) to accurately separate densely clustered and severely deformed glands. The proposed TA-Net has a multitask learning architecture and enhances the generalization of gland segmentation by learning shared representation from two tasks: instance segmentation and gland topology estimation. The proposed topology loss computes gland topology using gland skeletons and markers. It drives the network to generate segmentation results that comply with the true gland topology. We validate the proposed approach on the GlaS and CRAG datasets using three quantitative metrics, F1-score, object-level Dice coefficient, and object-level Hausdorff distance. Extensive experiments demonstrate that TA-Net achieves state-of-the-art performance on the two datasets. TA-Net outperforms other approaches in the presence of densely clustered glands.      
### 3.BeamScatter: Scalable, Deployable Long-Range backscatter communication with Beam-Steering  [ :arrow_down: ](https://arxiv.org/pdf/2110.14585.pdf)
>  WiFi backscatter tags can enable direct connectivity of IoT devices with commodity WiFi hardware at low power. However, most state-of-the-art backscatter tag implementations in this area have a limited transmitter to tag range and are not suitable to be deployed in a WiFi mesh network nor take full advantage of today's WiFi networks. In this paper, we present BeamScatter, which can realize a backscatter tag-based onMIMO techniques that can work at a very long separation of 28m from an access point and enables their deployment in WiFi mesh networks. BeamScatter presents a novel technique to perform beam-steering on the MIMO tag at a very low power consumption of 88uW and achieve a peak throughput of 1Mbps. Next BeamScatter creates a novel modeling framework to decide the optimal phase setting on the tag to steer the backscattered signal towards a specific direction of interest.      
### 4.Differential Deep Detection in Massive MIMO With One-Bit ADC  [ :arrow_down: ](https://arxiv.org/pdf/2110.14534.pdf)
>  This article presents a differential detection scheme for the uplink of a massive MIMO system that employs one-bit quantizers on each receive antenna. We focus on the detection of differential amplitude and phase shift keying symbols and we use the Bussgang theorem to express the quantized received signal in terms of quantized signals received during previous channel uses. Subsequently, we derive the maximum likelihood detector for the differentially encoded amplitude and phase information symbols. We note that while the one-bit detector can decode the differentially encoded phase information symbols, it fails to decode the differentially encoded amplitude information. To decode the amplitude information, we present a one-bit variable quantization level (VQL) system and train a deep neural network to perform two-symbol differential amplitude detection. Through Monte-Carlo simulations, we empirically validate the performance of the proposed amplitude and phase detectors. The presented numerical results show that the spectral efficiency attained in one-bit differential systems is better than the spectral efficiency attained in one-bit coherent systems      
### 5.Conditional Invertible Neural Networks for Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2110.14520.pdf)
>  Over the last years, deep learning methods have become an increasingly popular choice to solve tasks from the field of inverse problems. Many of these new data-driven methods have produced impressive results, although most only give point estimates for the reconstruction. However, especially in the analysis of ill-posed inverse problems, the study of uncertainties is essential. In our work, we apply generative flow-based models based on invertible neural networks to two challenging medical imaging tasks, i.e. low-dose computed tomography and accelerated medical resonance imaging. We test different architectures of invertible neural networks and provide extensive ablation studies. In most applications, a standard Gaussian is used as the base distribution for a flow-based model. Our results show that the choice of a radial distribution can improve the quality of reconstructions.      
### 6.PL-Net: Progressive Learning Network for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14484.pdf)
>  In recent years, segmentation methods based on deep convolutional neural networks (CNNs) have made state-of-the-art achievements for many medical analysis tasks. However, most of these approaches improve performance by optimizing the structure or adding new functional modules of the U-Net, which ignoring the complementation and fusion of the coarse-grained and fine-grained semantic information. To solve the above problems, we propose a medical image segmentation framework called progressive learning network (PL-Net), which includes internal progressive learning (IPL) and external progressive learning (EPL). PL-Net has the following advantages: (1) IPL divides feature extraction into two "steps", which can mix different size receptive fields and capture semantic information from coarse to fine granularity without introducing additional parameters; (2) EPL divides the training process into two "stages" to optimize parameters, and realizes the fusion of coarse-grained information in the previous stage and fine-grained information in the latter stage. We evaluate our method in different medical image analysis tasks, and the results show that the segmentation performance of PL-Net is better than the state-of-the-art methods of U-Net and its variants.      
### 7.An Arbitrary Scale Super-Resolution Approach for 3-Dimensional Magnetic Resonance Image using Implicit Neural Representation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14476.pdf)
>  High Resolution (HR) medical images provide rich anatomical structure details to facilitate early and accurate diagnosis. In MRI, restricted by hardware capacity, scan time, and patient cooperation ability, isotropic 3D HR image acquisition typically requests long scan time and, results in small spatial coverage and low SNR. Recent studies showed that, with deep convolutional neural networks, isotropic HR MR images could be recovered from low-resolution (LR) input via single image super-resolution (SISR) algorithms. However, most existing SISR methods tend to approach a scale-specific projection between LR and HR images, thus these methods can only deal with a fixed up-sampling rate. For achieving different up-sampling rates, multiple SR networks have to be built up respectively, which is very time-consuming and resource-intensive. In this paper, we propose ArSSR, an Arbitrary Scale Super-Resolution approach for recovering 3D HR MR images. In the ArSSR model, the reconstruction of HR images with different up-scaling rates is defined as learning a continuous implicit voxel function from the observed LR images. Then the SR task is converted to represent the implicit voxel function via deep neural networks from a set of paired HR-LR training examples. The ArSSR model consists of an encoder network and a decoder network. Specifically, the convolutional encoder network is to extract feature maps from the LR input images and the fully-connected decoder network is to approximate the implicit voxel function. Due to the continuity of the learned function, a single ArSSR model can achieve arbitrary up-sampling rate reconstruction of HR images from any input LR image after training. Experimental results on three datasets show that the ArSSR model can achieve state-of-the-art SR performance for 3D HR MR image reconstruction while using a single trained model to achieve arbitrary up-sampling scales.      
### 8.Bayesian-based Symbol Detector for Orthogonal Time Frequency Space Modulation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.14345.pdf)
>  Recently, the orthogonal time frequency space (OTFS) modulation is proposed for 6G wireless system to deal with high Doppler spread. The high Doppler spread happens when the transmitted signal is reflected towards the receiver by fast moving objects (e.g. high speed cars), which causes inter-carrier interference (ICI). Recent state-of-the-art OTFS detectors fail to achieve an acceptable bit-error-rate (BER) performance as the number of mobile reflectors increases which in turn, results in high inter-carrier-interference (ICI). In this paper, we propose a novel detector for OTFS systems, referred to as the Bayesian based parallel interference and decision statistics combining (B-PIC-DSC) OTFS detector that can achieve a high BER performance, under high ICI environments. The B-PIC-DSC OTFS detector employs the PIC and DSC schemes to iteratively cancel the interference, and the Bayesian concept to take the probability measure into the consideration when refining the transmitted symbols. Our simulation results show that in contrast to the state-of-the-art OTFS detectors, the proposed detector is able to achieve a BER of less than $10^{-5}$, when SNR is over $14$ dB, under high ICI environments.      
### 9.Over-the-Air Aggregation for Federated Learning: Waveform Superposition and Prototype Validation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14285.pdf)
>  In this paper, we develop an orthogonal-frequency-division-multiplexing (OFDM)-based over-the-air (OTA) aggregation solution for wireless federated learning (FL). In particular, the local gradients in massive IoT devices are modulated by an analog waveform and are then transmitted using the same wireless resources. To this end, achieving perfect waveform superposition is the key challenge, which is difficult due to the existence of frame timing offset (TO) and carrier frequency offset (CFO). In order to address these issues, we propose a two-stage waveform pre-equalization technique with a customized multiple access protocol that can estimate and then mitigate the TO and CFO for the OTA aggregation. Based on the proposed solution, we develop a hardware transceiver and application software to train a real-world FL task, which learns a deep neural network to predict the received signal strength with global positioning system information. Experiments verify that the proposed OTA aggregation solution can achieve comparable performance to offline learning procedures with high prediction accuracy.      
### 10.SiWa: See into Walls via Deep UWB Radar  [ :arrow_down: ](https://arxiv.org/pdf/2110.14279.pdf)
>  Being able to see into walls is crucial for diagnostics of building health; it enables inspections of wall structure without undermining the structural integrity. However, existing sensing devices do not seem to offer a full capability in mapping the in-wall structure while identifying their status (e.g., seepage and corrosion). In this paper, we design and implement SiWa as a low-cost and portable system for wall inspections. Built upon a customized IR-UWB radar, SiWa scans a wall as a user swipes its probe along the wall surface; it then analyzes the reflected signals to synthesize an image and also to identify the material status. Although conventional schemes exist to handle these problems individually, they require troublesome calibrations that largely prevent them from practical adoptions. To this end, we equip SiWa with a deep learning pipeline to parse the rich sensory data. With an ingenious construction and innovative training, the deep learning modules perform structural imaging and the subsequent analysis on material status, without the need for parameter tuning and calibrations. We build SiWa as a prototype and evaluate its performance via extensive experiments and field studies; results confirm that SiWa accurately maps in-wall structures, identifies their materials, and detects possible failures, suggesting a promising solution for diagnosing building health with lower effort and cost.      
### 11.Hybrid consensus for multi-agent systems with time-driven jumps  [ :arrow_down: ](https://arxiv.org/pdf/2110.14277.pdf)
>  In this paper, the behavior of scalar multi-agent systems over networks subject to time-driven jumps. Assuming that all agents communicate through distinct communication digraphs at jump and flow times, the asymptotic multi-consensus behavior of the hybrid network is explicitly characterized. The hybrid multi-consensus is shown to be associated with a suitable partition that is almost equitable for both the jump and flow communication digraphs. In doing so, no assumption on the underlying digraphs is introduced. Finally, the coupling rules making the multi-consensus subspace attractive are established. Several simulation examples illustrate the theoretical results.      
### 12.Kalman-Like Filter under Binary Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2110.14264.pdf)
>  This paper is concerned with the linear/nonlinear Kalman-like filtering problem under binary sensors. Since innovation represents new information in the sensor measurement and serves to correct the prediction for the Kalman-like filter (KLF), a novel uncertain measurement model is proposed such that the innovation generated from binary sensor can be captured. When considering linear dynamic systems, a conservative estimation error covariance with adjustable parameters is constructed by matrix inequality, and then an optimal filter gain is derived by minimizing its trace. Meanwhile, the optimal selection criterion of an adjustable parameter is developed by minimizing the upper bound of the conservative estimation error covariance. When considering nonlinear dynamic systems, a conservative estimation error covariance with adjustable parameters is also constructed via unscented transform and matrix inequalities. Then, following the idea of designing KLF in linear dynamic systems, the nonlinear filter gain and the optimal adjustable parameter are designed. Finally, $O_2$ content estimation and nonlinear numerical system are employed to show the effectiveness and advantages of the proposed methods.      
### 13.Beamforming Feedback-based Model-driven Angle of Departure Estimation Toward Firmware-Agnostic WiFi Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.14211.pdf)
>  This paper proves that the angle of departure (AoD) estimation using the multiple signal classification (MUSIC) with only WiFi control frames for beamforming feedback (BFF), defined in IEEE 802.11ac/ax, is possible. Although channel state information (CSI) enables model-driven AoD estimation, most BFF-based sensing techniques are data-driven because they only contain the right singular vectors of CSI and subcarrier-averaged stream gain. Specifically, we find that right singular vectors with a subcarrier-averaged stream gain of zero have the same role as the noise subspace vectors in the CSI-based MUSIC algorithm. Numerical evaluations confirm that the proposed BFF-based MUSIC successfully estimates the AoDs and gains for all propagation paths. Meanwhile, this result implies a potential privacy risk; a malicious sniffer can carry out AoD estimation only with unencrypted BFF frames.      
### 14.Distributionally Robust Day-ahead Scheduling for Power-traffic Network Considering Multiple Uncertainties under a Potential Game Framework  [ :arrow_down: ](https://arxiv.org/pdf/2110.14209.pdf)
>  Widespread utilization of electric vehicles (EVs) incurs more uncertainties and impacts on the scheduling of the power-transportation coupled network. This paper investigates optimal power scheduling for a power-transportation coupled network in the day-ahead energy market considering multiple uncertainties related to photovoltaic (PV) generation and the traffic demand of vehicles. Specifically, the EV drivers choose the lowest-cost routes in response to electricity prices and the power operators maximize their operating profits. Furthermore, we show the interactions between the power system and EV users from a potential game-theoretic perspective, and the scheduling problem of the equilibrium of power-transportation coupled network can be interpreted by a two-stage distributionally robust optimization (DRO) model. In addition, uncertainties of PV generation and traffic demand are established as scenario-based ambiguity sets combined with the historical distribution information, respectively. A combination of the duality theory and the Benders decomposition is developed to solve the DRO model. Simulation results demonstrate the effectiveness and applicability of the proposed approach.      
### 15.Arbitrarily Fast Switched Distributed Stabilization of Partially Unknown Interconnected Multiagent Systems: A Proactive Cyber Defense Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2110.14199.pdf)
>  A design framework recently has been developed to stabilize interconnected multiagent systems in a distributed manner, and systematically capture the architectural aspect of cyber-physical systems. Such a control theoretic framework, however, results in a stabilization protocol which is passive with respect to the cyber attacks and conservative regarding the guaranteed level of resiliency. We treat the control layer topology and stabilization gains as the degrees of freedom, and develop a mixed control and cybersecurity design framework to address the above concerns. From a control perspective, despite the agent layer modeling uncertainties and perturbations, we propose a new step-by-step procedure to design a set of control sublayers for an arbitrarily fast switching of the control layer topology. From a proactive cyber defense perspective, we propose a satisfiability modulo theory formulation to obtain a set of control sublayer structures with security considerations, and offer a frequent and fast mutation of these sublayers such that the control layer topology will remain unpredictable for the adversaries. We prove the robust input-to-state stability of the two-layer interconnected multiagent system, and validate the proposed ideas in simulation.      
### 16.QU-net++: Image Quality Detection Framework for Segmentation of 3D Medical Image Stacks  [ :arrow_down: ](https://arxiv.org/pdf/2110.14181.pdf)
>  Automated segmentation of pathological regions of interest has been shown to aid prognosis and follow up treatment. However, accurate pathological segmentations require high quality of annotated data that can be both cost and time intensive to generate. In this work, we propose an automated two-step method that evaluates the quality of medical images from 3D image stacks using a U-net++ model, such that images that can aid further training of the U-net++ model can be detected based on the disagreement in segmentations produced from the final two layers. Images thus detected can then be used to further fine tune the U-net++ model for semantic segmentation. The proposed QU-net++ model isolates around 10\% of images per 3D stack and can scale across imaging modalities to segment cysts in OCT images and ground glass opacity in Lung CT images with Dice cores in the range 0.56-0.72. Thus, the proposed method can be applied for multi-modal binary segmentation of pathology.      
### 17.Control of a Floating Wind Turbine on a Novel Actuated Platform  [ :arrow_down: ](https://arxiv.org/pdf/2110.14169.pdf)
>  Designing a floating offshore wind turbine (FOWT) controller requires solving engineering challenges not found for fixed-bottom turbines. This paper applies several methods from the growing body of FOWT control literature to the 10-MW Ultraflexible Smart FLoating Offshore Wind Turbine (USFLOWT) baseline generator-speed controller. USFLOWT aims to reduce capital expenses using the lightweight SpiderFLOAT platform, a novel smart floating substructure with built-in distributed actuators for direct platform tilt and heave control. In this work, the USFLOWT baseline controller is improved through detuning and parallel compensation with both blade pitch and generator torque. The SpiderFLOAT platform additionally allows motion compensation through distributed platform actuators. Two proposed SpiderFLOAT actuator types are considered for active platform control: a low-bandwidth actuator that uses variable floater ballast to bring a heeling platform to a steady-state upright position, and a high-bandwidth actuator that dynamically changes the substructure geometry to actively reject transient platform motion. Each control approach is tested for USFLOWT using the open-source aero-hydro-servo-elastic wind turbine simulation tool OpenFAST. Performance results for each approach are compared across a range of above-rated wind speeds, and promising combined approaches are further evaluated to recommend future multi-parameter optimization pathways.      
### 18.Physically Explainable CNN for SAR Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.14144.pdf)
>  Integrating the special electromagnetic characteristics of Synthetic Aperture Radar (SAR) in deep neural networks is essential in order to enhance the explainability and physics awareness of deep learning. In this paper, we firstly propose a novel physics guided and injected neural network for SAR image classification, which is mainly guided by explainable physics models and can be learned with very limited labeled data. The proposed framework comprises three parts: (1) generating physics guided signals using existing explainable models, (2) learning physics-aware features with physics guided network, and (3) injecting the physics-aware features adaptively to the conventional classification deep learning model for prediction. The prior knowledge, physical scattering characteristic of SAR in this paper, is injected into the deep neural network in the form of physics-aware features which is more conducive to understanding the semantic labels of SAR image patches. A hybrid Image-Physics SAR dataset format is proposed, and both Sentinel-1 and Gaofen-3 SAR data are taken for evaluation. The experimental results show that our proposed method substantially improve the classification performance compared with the counterpart data-driven CNN. Moreover, the guidance of explainable physics signals leads to explainability of physics-aware features and the physics consistency of features are also preserved in the predictions. We deem the proposed method would promote the development of physically explainable deep learning in SAR image interpretation field.      
### 19.Separating Long-Form Speech with Group-Wise Permutation Invariant Training  [ :arrow_down: ](https://arxiv.org/pdf/2110.14142.pdf)
>  Multi-talker conversational speech processing has drawn many interests for various applications such as meeting transcription. Speech separation is often required to handle overlapped speech that is commonly observed in conversation. Although the existing utterancelevel permutation invariant training-based continuous speech separation approach has proven to be effective in various conditions, it lacks the ability to leverage the long-span relationship of utterances and is computationally inefficient due to the highly overlapped sliding windows. To overcome these drawbacks, we propose a novel training scheme named Group-PIT, which allows direct training of the speech separation models on the long-form speech with a low computational cost for label assignment. Two different speech separation approaches with Group-PIT are explored, including direct long-span speech separation and short-span speech separation with long-span tracking. The experiments on the simulated meeting-style data demonstrate the effectiveness of our proposed approaches, especially in dealing with a very long speech input.      
### 20.Closing the Gap Between Time-Domain Multi-Channel Speech Enhancement on Real and Simulation Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2110.14139.pdf)
>  The deep learning based time-domain models, e.g. Conv-TasNet, have shown great potential in both single-channel and multi-channel speech enhancement. However, many experiments on the time-domain speech enhancement model are done in simulated conditions, and it is not well studied whether the good performance can generalize to real-world scenarios. In this paper, we aim to provide an insightful investigation of applying multi-channel Conv-TasNet based speech enhancement to both simulation and real data. Our preliminary experiments show a large performance gap between the two conditions in terms of the ASR performance. Several approaches are applied to close this gap, including the integration of multi-channel Conv-TasNet into the beamforming model with various strategies, and the joint training of speech enhancement and speech recognition models. Our experiments on the CHiME-4 corpus show that our proposed approaches can greatly reduce the speech recognition performance discrepancy between simulation and real data, while preserving the strong speech enhancement capability in the frontend.      
### 21.Improving Cell-Free Massive MIMO Detection Performance via Expectation Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14128.pdf)
>  Cell-free (CF) massive multiple-input multiple-output (M-MIMO) technology plays a prominent role in the beyond fifth-generation (5G) networks. However, designing a high performance CF M-MIMO detector is a challenging task due to the presence of pilot contamination which appears when the number of pilot sequences is smaller than the number of users. This work proposes a CF M-MIMO detector referred to as CF expectation propagation (CF-EP) that incorporates the pilot contamination when calculating the posterior belief. The simulation results show that the proposed detector achieves significant improvements in terms of the bit-error rate and sum spectral efficiency performances as compared to the ones of the state-of-the-art CF detectors.      
### 22.Newtonian Mechanics Based Transient Stability PART V: Inner-group Machine  [ :arrow_down: ](https://arxiv.org/pdf/2110.14123.pdf)
>  This paper analyzes the mechanisms of the inner-group machine. It is first clarified that the inner-group machine is created from the difference between the equivalent system and the original system. The inner-group machine stability is analyzed based on the machine paradigms. In particular, strict correlation between the inner-group machine trajectory and the inner-group machine transient energy conversion is established through the I-CR system modeling. Then, the transient characteristics of the inner-group machine are analyzed. It is clarified that the inner-group motions might be inseparable or separable, and the inner-group machine DLP will occur later than the EDLP and IDLP. Simulation results show that the severity of the original system cannot be simply evaluated through its equivalent system once any inner-group motion becomes fierce.      
### 23.A C-Band Fully Polarimetric Automotive Synthetic Aperture Radar  [ :arrow_down: ](https://arxiv.org/pdf/2110.14114.pdf)
>  Due to the rapid increase in 76 GHz automotive spectrum use in recent years, wireless interference is becoming a legitimate area of concern. However, the recent rise in interest of automated vehicles (AVs) has also spurred new growth and adoption of low frequency vehicle-to-everything (V2X) communications in and around the 5.8 GHz unlicensed bands, opening the possibility for communications spectrum reuse in the form of joint radar-communications (JRC). In this work, we present a low frequency 5.9 GHz side-looking polarimetric synthetic aperture radar (SAR) for automotive use, utilizing a ranging waveform in a common low frequency V2X communications band. A synthetic aperture technique is employed to address the angular resolution concerns commonly associated with radars at lower frequencies. Three side-looking fully polarimetric SAR images in various urban scenes are presented and discussed to highlight the unique opportunities for landmark inference afforded through measurement of co- and cross-polarized scattering.      
### 24.Model Reduction of Swing Equations with Physics Informed PDE  [ :arrow_down: ](https://arxiv.org/pdf/2110.14066.pdf)
>  This manuscript is the first step towards building a robust and efficient model reduction methodology to capture transient dynamics in a transmission level electric power system. Such dynamics is normally modeled on seconds-to-tens-of-seconds time scales by the so-called swing equations, which are ordinary differential equations defined on a spatially discrete model of the power grid. We suggest, following Seymlyen (1974) and Thorpe, Seyler and Phadke (1999), to map the swing equations onto a linear, inhomogeneous Partial Differential Equation (PDE) of parabolic type in two space and one time dimensions with time-independent coefficients and properly defined boundary conditions. The continuous two-dimensional spatial domain is defined by a geographical map of the area served by the power grid, and associated with the PDE coefficients derived from smoothed graph-Laplacian of susceptances, machine inertia and damping. Inhomogeneous source terms represent spatially distributed injection/consumption of power. We illustrate our method on PanTaGruEl (Pan-European Transmission Grid and ELectricity generation model). We show that, when properly coarse-grained, i.e. with the PDE coefficients and source terms extracted from a spatial convolution procedure of the respective discrete coefficients in the swing equations, the resulting PDE reproduces faithfully and efficiently the original swing dynamics. We finally discuss future extensions of this work, where the presented PDE-based reduced modeling will initialize a physics-informed machine learning approach for real-time modeling, $n-1$ feasibility assessment and transient stability analysis of power systems.      
### 25.How will electric vehicles affect traffic congestion and energy consumption: an integrated modelling approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.14064.pdf)
>  This paper explores the impact of electric vehicles (EVs) on traffic congestion and energy consumption by proposing an integrated bi-level framework comprising of: a) a dynamic micro-scale traffic simulation suitable for modelling current and hypothetical traffic and charging demand scenarios and b) a queue model for capturing the impact of fast charging station use, informed by traffic flows, travel distances, availability of charging infrastructure and estimated vehicle battery state of charge. To the best of our knowledge, this paper represents the first integrated analysis of potential traffic congestion and energy infrastructure impacts linked to EV uptake, based on real traffic flows and the placement and design of existing fast-charging infrastructure. Results showcase that the integrated queue-energy-transport modelling framework can predict correctly the limitations of the EV infrastructure as well as the traffic congestion evolution. The modelling approach identifies concrete pain points to be addressed in both traffic and energy management and planning. The code for this project can be found at : <a class="link-external link-https" href="https://github.com/Future-Mobility-Lab/EV-charging-impact" rel="external noopener nofollow">this https URL</a>      
### 26.A Cost-Effective, Scalable, and Portable IoT Data Infrastructure for Indoor Environment Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.14042.pdf)
>  The vast number of facility management systems, home automation systems, and the ever-increasing number of Internet of Things (IoT) devices are in constant need of environmental monitoring. Indoor environment data can be utilized to improve indoor facilities and better occupants' working and living experience, however, such data are scarce because many existing facility monitoring technologies are expensive and proprietary for certain building systems, such as building automation systems, energy management systems, and maintenance systems. In this work, the authors designed and prototyped a cost-effective, distributed, scalable, and portable indoor environmental data collection system, Building Data Lite (BDL). BDL is based on Raspberry Pi computers and multiple changeable arrays of sensors, such as sensors of temperature, humidity, light, motion, sound, vibration, and multiple types of gases. The system includes a distributed sensing network and a centralized server. The server provides a web-based graphical user interface that enables users to access the collected data over the Internet. To evaluate the BDL system's functionality, cost-effectiveness, scalability, and portability, the research team conducted a case study in an affordable housing community where the system prototype is deployed to 12 households. The case study results indicate that the system is functioning as designed, costs about \$3500 to sense 48 building zones (about \$73 per zone) and provides 12 types of indoor environment data, is easy to scale up, and is fully portable.      
### 27.r-local sensing: Improved algorithm and applications  [ :arrow_down: ](https://arxiv.org/pdf/2110.14034.pdf)
>  The unlabeled sensing problem is to solve a noisy linear system of equations under unknown permutation of the measurements. We study a particular case of the problem where the permutations are restricted to be r-local, i.e. the permutation matrix is block diagonal with r x r blocks. Assuming a Gaussian measurement matrix, we argue that the r-local permutation model is more challenging compared to a recent sparse permutation model. We propose a proximal alternating minimization algorithm for the general unlabeled sensing problem that provably converges to a first order stationary point. Applied to the r-local model, we show that the resulting algorithm is efficient. We validate the algorithm on synthetic and real datasets. We also formulate the 1-d unassigned distance geometry problem as an unlabeled sensing problem with a structured measurement matrix.      
### 28.Noninvasive ultrasound for Lithium-ion batteries state estimation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14033.pdf)
>  Lithium-ion battery degradation estimation using fast and noninvasive techniques is a crucial issue in the circular economy framework of this technology. Currently, most of the approaches used to establish the battery-state (i.e., State of Charge (SoC), State of Health (SoH)) require time-consuming processes. In the present preliminary study, an ultrasound array was used to assess the influence of the SoC and SoH on the variations in the time of flight (TOF) and the speed of sound (SOS) of the ultrasound wave inside the batteries. Nine aged 18650 Lithium-ion batteries were imaged at 100% and 0% SoC using a Vantage-256 system (Verasonics, Inc.) equipped with a 64-element ultrasound array and a center frequency of 5 MHz (Imasonic SAS). It was found that second-life batteries have a complex ultrasound response due to the presence of many degradation pathways and, thus, making it harder to analyze the ultrasound measurements. Although further analysis must be done to elucidate a clear correlation between changes in the ultrasound wave properties and the battery state estimation, this approach seems very promising for future nondestructive evaluation of second-life batteries.      
### 29.Deep Integrated Pipeline of Segmentation Leading to Classification for Automated Detection of Breast Cancer from Breast Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.14013.pdf)
>  Breast cancer has become a symbol of tremendous concern in the modern world, as it is one of the major causes of cancer mortality worldwide. In this concern, many people are frequently screening for breast cancer in order to be identified early and avert mortality from the disease by receiving treatment. Breast Ultrasonography Images are frequently utilized by doctors to diagnose breast cancer at an early stage. However, the complex artifacts and heavily noised Breast Ultrasonography Images make detecting Breast Cancer a tough challenge. Furthermore, the ever-increasing number of patients being screened for Breast Cancer necessitates the use of automated Computer Aided Technology for high accuracy diagnosis at a cheap cost and in a short period of time. The current progress of Artificial Intelligence (AI) in the fields of Medical Image Analysis and Health Care is a boon to humanity. In this study, we have proposed a compact integrated automated pipelining framework which integrates ultrasonography image preprocessing with Simple Linear Iterative Clustering (SLIC) to tackle the complex artifact of Breast Ultrasonography Images complementing semantic segmentation with Modified U-Net leading to Breast Tumor classification with robust feature extraction using a transfer learning approach with pretrained VGG 16 model and densely connected neural network architecture. The proposed automated pipeline can be effectively implemented to assist medical practitioners in making more accurate and timely diagnoses of breast cancer.      
### 30.Paving the Way for Consensus: Convergence of Block Gossip Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2110.14609.pdf)
>  Gossip protocols are popular methods for average consensus problems in distributed computing. We prove new convergence guarantees for a variety of such protocols, including path, clique, and synchronous pairwise gossip. These arise by exploiting the connection between these protocols and the block randomized Kaczmarz method for solving linear systems. Moreover, we extend existing convergence results for block randomized Kaczmarz to allow for a more general choice of blocks, rank-deficient systems, and provide a tighter convergence rate guarantee. We furthermore apply this analysis to inconsistent consensus models and obtain similar guarantees. An extensive empirical analysis of these methods is provided for a variety of synthetic networks.      
### 31.Spatio-Temporal Federated Learning for Massive Wireless Edge Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.14578.pdf)
>  This paper presents a novel approach to conduct highly efficient federated learning (FL) over a massive wireless edge network, where an edge server and numerous mobile devices (clients) jointly learn a global model without transporting the huge amount of data collected by the mobile devices to the edge server. The proposed FL approach is referred to as spatio-temporal FL (STFL), which jointly exploits the spatial and temporal correlations between the learning updates from different mobile devices scheduled to join STFL in various training epochs. The STFL model not only represents the realistic intermittent learning behavior from the edge server to the mobile devices due to data delivery outage, but also features a mechanism of compensating loss learning updates in order to mitigate the impacts of intermittent learning. An analytical framework of STFL is proposed and employed to study the learning capability of STFL via its convergence performance. In particular, we have assessed the impact of data delivery outage, intermittent learning mitigation, and statistical heterogeneity of datasets on the convergence performance of STFL. The results provide crucial insights into the design and analysis of STFL based wireless networks.      
### 32.Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons  [ :arrow_down: ](https://arxiv.org/pdf/2110.14549.pdf)
>  The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.      
### 33.Power Minimization of Downlink Spectrum Slicing for eMBB and URLLC Users  [ :arrow_down: ](https://arxiv.org/pdf/2110.14544.pdf)
>  5G technology allows the presence of heterogeneous services in the same physical network. On the radio access network (RAN), the spectrum slicing of the shared radio resources is a critical task to guarantee the performance of each service. In this paper, we analyze a downlink communication in which a base station (BS) should serve two types of traffic, enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC), respectively. Due to the nature of low-latency traffic, the BS knows the channel state information (CSI) of the eMBB users only. In this setting, we study the power minimization problem employing orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) schemes. We analyze the impact of resource sharing, showing that the knowledge of eMBB CSI can be used also in resource allocation for URLLC users. Based on this analysis, we propose two algorithms: a feasible and a block coordinated descent approach (BCD). We show that the BCD is optimal for the URLLC power allocation. The numerical results show that NOMA leads to a lower power consumption compared to OMA, except when the URLLC user is very close to the BS. For the last case, the optimal approach depends on the channel condition of the eMBB user. In any case, even when the OMA paradigm attains the best performance, the gap with NOMA is negligible, proving the NOMA capacity in exploiting the shared resources to reduce the power consumption in every condition.      
### 34.Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations  [ :arrow_down: ](https://arxiv.org/pdf/2110.14513.pdf)
>  We present a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. Most of the previous works have focused on using information bottleneck to disentangle analysis features for controllable synthesis, which usually results in poor reconstruction quality. We address this issue by proposing a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch, and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSY does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. Taking advantage of fully self-supervised training, NANSY can be easily extended to a multilingual setting by simply training it with a multilingual dataset. The experiments show that NANSY can achieve significant improvement in performance in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification.      
### 35.Validation Methods for Energy Time Series Scenarios from Deep Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.14451.pdf)
>  The design and operation of modern energy systems are heavily influenced by time-dependent and uncertain parameters, e.g., renewable electricity generation, load-demand, and electricity prices. These are typically represented by a set of discrete realizations known as scenarios. A popular scenario generation approach uses deep generative models (DGM) that allow scenario generation without prior assumptions about the data distribution. However, the validation of generated scenarios is difficult, and a comprehensive discussion about appropriate validation methods is currently lacking. To start this discussion, we provide a critical assessment of the currently used validation methods in the energy scenario generation literature. In particular, we assess validation methods based on probability density, auto-correlation, and power spectral density. Furthermore, we propose using the multifractal detrended fluctuation analysis (MFDFA) as an additional validation method for non-trivial features like peaks, bursts, and plateaus. As representative examples, we train generative adversarial networks (GANs), Wasserstein GANs (WGANs), and variational autoencoders (VAEs) on two renewable power generation time series (photovoltaic and wind from Germany in 2013 to 2015) and an intra-day electricity price time series form the European Energy Exchange in 2017 to 2019. We apply the four validation methods to both the historical and the generated data and discuss the interpretation of validation results as well as common mistakes, pitfalls, and limitations of the validation methods. Our assessment shows that no single method sufficiently characterizes a scenario but ideally validation should include multiple methods and be interpreted carefully in the context of scenarios over short time periods.      
### 36.Exploring single-song autoencoding schemes for audio-based music structure analysis  [ :arrow_down: ](https://arxiv.org/pdf/2110.14437.pdf)
>  The ability of deep neural networks to learn complex data relations and representations is established nowadays, but it generally relies on large sets of training data. This work explores a "piece-specific" autoencoding scheme, in which a low-dimensional autoencoder is trained to learn a latent/compressed representation specific to a given song, which can then be used to infer the song structure. Such a model does not rely on supervision nor annotations, which are well-known to be tedious to collect and often ambiguous in Music Structure Analysis. We report that the proposed unsupervised auto-encoding scheme achieves the level of performance of supervised state-of-the-art methods with 3 seconds tolerance when using a Log Mel spectrogram representation on the RWC-Pop dataset.      
### 37.Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of audio signals  [ :arrow_down: ](https://arxiv.org/pdf/2110.14434.pdf)
>  Nonnegative Tucker Decomposition (NTD), a tensor decomposition model, has received increased interest in the recent years because of its ability to blindly extract meaningful patterns in tensor data. Nevertheless, existing algorithms to compute NTD are mostly designed for the Euclidean loss. On the other hand, NTD has recently proven to be a powerful tool in Music Information Retrieval. This work proposes a Multiplicative Updates algorithm to compute NTD with the beta-divergence loss, often considered a better loss for audio processing. We notably show how to implement efficiently the multiplicative rules using tensor algebra, a naive approach being intractable. Finally, we show on a Music Structure Analysis task that unsupervised NTD fitted with beta-divergence loss outperforms earlier results obtained with the Euclidean loss.      
### 38.Generalizing AUC Optimization to Multiclass Classification for Audio Segmentation With Limited Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2110.14425.pdf)
>  Area under the ROC curve (AUC) optimisation techniques developed for neural networks have recently demonstrated their capabilities in different audio and speech related tasks. However, due to its intrinsic nature, AUC optimisation has focused only on binary tasks so far. In this paper, we introduce an extension to the AUC optimisation framework so that it can be easily applied to an arbitrary number of classes, aiming to overcome the issues derived from training data limitations in deep learning solutions. Building upon the multiclass definitions of the AUC metric found in the literature, we define two new training objectives using a one-versus-one and a one-versus-rest approach. In order to demonstrate its potential, we apply them in an audio segmentation task with limited training data that aims to differentiate 3 classes: foreground music, background music and no music. Experimental results show that our proposal can improve the performance of audio segmentation systems significantly compared to traditional training criteria such as cross entropy.      
### 39.Zero-shot Voice Conversion via Self-supervised Prosody Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.14422.pdf)
>  Voice Conversion (VC) for unseen speakers, also known as zero-shot VC, is an attractive topic due to its usefulness in real use-case scenarios. Recent work in this area made progress with disentanglement methods that separate utterance content and speaker characteristics. Although crucial, extracting disentangled prosody characteristics for unseen speakers remains an open issue. In this paper, we propose a novel self-supervised approach to effectively learn the prosody characteristics. Then, we use the learned prosodic representations to train our VC model for zero-shot conversion. Our evaluation demonstrates that we can efficiently extract disentangled prosody representation. Moreover, we show improved performance compared to the state-of-the-art zero-shot VC models.      
### 40.Localized Super Resolution for Foreground Images using U-Net and MR-CNN  [ :arrow_down: ](https://arxiv.org/pdf/2110.14413.pdf)
>  Images play a vital role in understanding data through visual representation. It gives a clear representation of the object in context. But if this image is not clear it might not be of much use. Thus, the topic of Image Super Resolution arose and many researchers have been working towards applying Computer Vision and Deep Learning Techniques to increase the quality of images. One of the applications of Super Resolution is to increase the quality of Portrait Images. Portrait Images are images which mainly focus on capturing the essence of the main object in the frame, where the object in context is highlighted whereas the background is occluded. When performing Super Resolution the model tries to increase the overall resolution of the image. But in portrait images the foreground resolution is more important than that of the background. In this paper, the performance of a Convolutional Neural Network (CNN) architecture known as U-Net for Super Resolution combined with Mask Region Based CNN (MR-CNN) for foreground super resolution is analysed. This analysis is carried out based on Localized Super Resolution i.e. We pass the LR Images to a pre-trained Image Segmentation model (MR-CNN) and perform super resolution inference on the foreground or Segmented Images and compute the Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) metrics for comparisons.      
### 41.Traffic Forecasting on Traffic Moving Snippets  [ :arrow_down: ](https://arxiv.org/pdf/2110.14383.pdf)
>  Advances in traffic forecasting technology can greatly impact urban mobility. In the traffic4cast competition, the task of short-term traffic prediction is tackled in unprecedented detail, with traffic volume and speed information available at 5 minute intervals and high spatial resolution. To improve generalization to unknown cities, as required in the 2021 extended challenge, we propose to predict small quadratic city sections, rather than processing a full-city-raster at once. At test time, breaking down the test data into spatially-cropped overlapping snippets improves stability and robustness of the final predictions, since multiple patches covering one cell can be processed independently. With the performance on the traffic4cast test data and further experiments on a validation set it is shown that patch-wise prediction indeed improves accuracy. Further advantages can be gained with a Unet++ architecture and with an increasing number of patches per sample processed at test time. We conclude that our snippet-based method, combined with other successful network architectures proposed in the competition, can leverage performance, in particular on unseen cities. All source code is available at <a class="link-external link-https" href="https://github.com/NinaWie/NeurIPS2021-traffic4cast" rel="external noopener nofollow">this https URL</a>.      
### 42.Binarized ResNet: Enabling Automatic Modulation Classification at the resource-constrained Edge  [ :arrow_down: ](https://arxiv.org/pdf/2110.14357.pdf)
>  In this paper, we propose a ResNet based neural architecture to solve the problem of Automatic Modulation Classification. We showed that our architecture outperforms the state-of-the-art (SOTA) architectures. We further propose to binarize the network to deploy it in the Edge network where the devices are resource-constrained i.e. have limited memory and computing power. Instead of simple binarization, rotated binarization is applied to the network which helps to close the significant performance gap between the real and the binarized network. Because of the immense representation capability or the real network, its rotated binarized version achieves $85.33\%$ accuracy compared to $95.76\%$ accuracy of the proposed real network with $2.33$ and $16$ times lesser computing power than two of the SOTA architectures, MCNet and RMLResNet respectively, and approximately $16$ times less memory than both. The performance can be improved further to $87.74\%$ by taking an ensemble of four such rotated binarized networks.      
### 43.Application of Time Separation Technique to Enhance C-arm CT Dynamic Liver Perfusion Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2110.14318.pdf)
>  Perfusion imaging is an interesting new modality for evaluation and assessment of the liver cancer treatment. C-Arm CT provides a possibility to perform perfusion imaging scans intra-operatively for even faster evaluation. The slow speed of the C-Arm CT rotation and the presence of the noise, however, have an impact on the reconstruction and therefore model based approaches have to be applied. In this work we apply the Time separation technique (TST), to denoise data, speed up reconstruction and improve resulting perfusion images. We show on animal experiment data that Dynamic C-Arm CT Liver Perfusion Imaging together with the processing of the data based on the TST provides comparable results to standard CT liver perfusion imaging.      
### 44.RF-Based Human Activity Recognition Using Signal Adapted Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2110.14307.pdf)
>  Human Activity Recognition (HAR) plays a critical role in a wide range of real-world applications, and it is traditionally achieved via wearable sensing. Recently, to avoid the burden and discomfort caused by wearable devices, device-free approaches exploiting RF signals arise as a promising alternative for HAR. Most of the latest device-free approaches require training a large deep neural network model in either time or frequency domain, entailing extensive storage to contain the model and intensive computations to infer activities. Consequently, even with some major advances on device-free HAR, current device-free approaches are still far from practical in real-world scenarios where the computation and storage resources possessed by, for example, edge devices, are limited. Therefore, we introduce HAR-SAnet which is a novel RF-based HAR framework. It adopts an original signal adapted convolutional neural network architecture: instead of feeding the handcraft features of RF signals into a classifier, HAR-SAnet fuses them adaptively from both time and frequency domains to design an end-to-end neural network model. We apply point-wise grouped convolution and depth-wise separable convolutions to confine the model scale and to speed up the inference execution time. The experiment results show that the recognition accuracy of HAR-SAnet outperforms state-of-the-art algorithms and systems.      
### 45.Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.14296.pdf)
>  Learning how complex dynamical systems evolve over time is a key challenge in system identification. For safety critical systems, it is often crucial that the learned model is guaranteed to converge to some equilibrium point. To this end, neural ODEs regularized with neural Lyapunov functions are a promising approach when states are fully observed. For practical applications however, partial observations are the norm. As we will demonstrate, initialization of unobserved augmented states can become a key problem for neural ODEs. To alleviate this issue, we propose to augment the system's state with its history. Inspired by state augmentation in discrete-time systems, we thus obtain neural delay differential equations. Based on classical time delay stability analysis, we then show how to ensure stability of the learned models, and theoretically analyze our approach. Our experiments demonstrate its applicability to stable system identification of partially observed systems and learning a stabilizing feedback policy in delayed feedback control.      
### 46.A Subgame Perfect Equilibrium Reinforcement Learning Approach to Time-inconsistent Problems  [ :arrow_down: ](https://arxiv.org/pdf/2110.14295.pdf)
>  In this paper, we establish a subgame perfect equilibrium reinforcement learning (SPERL) framework for time-inconsistent (TIC) problems. In the context of RL, TIC problems are known to face two main challenges: the non-existence of natural recursive relationships between value functions at different time points and the violation of Bellman's principle of optimality that raises questions on the applicability of standard policy iteration algorithms for unprovable policy improvement theorems. We adapt an extended dynamic programming theory and propose a new class of algorithms, called backward policy iteration (BPI), that solves SPERL and addresses both challenges. To demonstrate the practical usage of BPI as a training framework, we adapt standard RL simulation methods and derive two BPI-based training algorithms. We examine our derived training frameworks on a mean-variance portfolio selection problem and evaluate some performance metrics including convergence and model identifiability.      
### 47.Deep Learning For Prominence Detection In Children's Read Speech  [ :arrow_down: ](https://arxiv.org/pdf/2110.14273.pdf)
>  The detection of perceived prominence in speech has attracted approaches ranging from the design of linguistic knowledge-based acoustic features to the automatic feature learning from suprasegmental attributes such as pitch and intensity contours. We present here, in contrast, a system that operates directly on segmented speech waveforms to learn features relevant to prominent word detection for children's oral fluency assessment. The chosen CRNN (convolutional recurrent neural network) framework, incorporating both word-level features and sequence information, is found to benefit from the perceptually motivated SincNet filters as the first convolutional layer. We further explore the benefits of the linguistic association between the prosodic events of phrase boundary and prominence with different multi-task architectures. Matching the previously reported performance on the same dataset of a random forest ensemble predictor trained on carefully chosen hand-crafted acoustic features, we evaluate further the possibly complementary information from hand-crafted acoustic and pre-trained lexical features.      
### 48.Massive MIMO NOMA with Wavelet Pulse Shaping to Minimize Undesired Channel Interference  [ :arrow_down: ](https://arxiv.org/pdf/2110.14185.pdf)
>  In this article, wavelet OFDM based non-orthogonal-multiple-access (NOMA) combined with massive MIMO system for 6G networks is proposed. For mMIMO transmissions, the proposed system could enhance the performance by utilizing wavelets to compensate for channel impairments on the transmitted signal. Performance measures include spectral efficiency, symbol error rate (SER), and peak to average ratio (PAPR). Simulation results prove that the proposed system outperforms the conventional OFDM based NOMA systems.      
### 49.On the Dynamics of the Tavis-Cummings Model  [ :arrow_down: ](https://arxiv.org/pdf/2110.14174.pdf)
>  The purpose of this paper is to present a comprehensive study of the Tavis-Cummings model from a system-theoretic perspective. A typical form of the Tavis-Cummings model is composed of an ensemble of non-interacting two-level systems that are all coupled to a common cavity resonator. A Tavis-Cummings system exhibits superradiance phenomenon, for example an ensemble of $N$ two-level atoms act collectively as a giant atom which decays $N$ times as fast as an individual atom. An associated quantum linear passive system is proposed, whose canonical form reveals typical features of the Tavis-Cummings model, including $\sqrt{N}$- scaling, dark states, bright states, single-excitation superradiant and subradiant states. The passivity of this linear system is related to the vacuum Rabi mode splitting phenomenon in a Tavis-Cummings system. On the basis of the linear model, an analytic form is presented for the steady-state output single-photon state of the Tavis-Cummings model driven by a single-photon state. Master equations are used to study the excitation properties of the Tavis-Cummings model in the multi-excitation scenario. Finally, in terms of the transition matrix for a linear time-varying system, a computational framework is proposed for calculating the state of the Tavis-Cummings model, which is applicable to the multi-excitation case.      
### 50.Identifying the key components in ResNet-50 for diabetic retinopathy grading from fundus images: a systematic investigation  [ :arrow_down: ](https://arxiv.org/pdf/2110.14160.pdf)
>  Although deep learning based diabetic retinopathy (DR) classification methods typically benefit from well-designed architectures of convolutional neural networks, the training setting also has a non-negligible impact on the prediction performance. The training setting includes various interdependent components, such as objective function, data sampling strategy and data augmentation approach. To identify the key components in a standard deep learning framework (ResNet-50) for DR grading, we systematically analyze the impact of several major components. Extensive experiments are conducted on a publicly-available dataset EyePACS. We demonstrate that (1) the ResNet-50 framework for DR grading is sensitive to input resolution, objective function, and composition of data augmentation, (2) using mean square error as the loss function can effectively improve the performance with respect to a task-specific evaluation metric, namely the quadratically-weighted Kappa, (3) utilizing eye pairs boosts the performance of DR grading and (4) using data resampling to address the problem of imbalanced data distribution in EyePACS hurts the performance. Based on these observations and an optimal combination of the investigated components, our framework, without any specialized network design, achieves the state-of-the-art result (0.8631 for Kappa) on the EyePACS test set (a total of 42670 fundus images) with only image-level labels. Our codes and pre-trained model are available at <a class="link-external link-https" href="https://github.com/YijinHuang/pytorch-classification" rel="external noopener nofollow">this https URL</a>      
### 51.A Linear Bayesian Learning Receiver Scheme for Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.14138.pdf)
>  Much stringent reliability and processing latency requirements in ultra-reliable-low-latency-communication (URLLC) traffic make the design of linear massive multiple-input-multiple-output (M-MIMO) receivers becomes very challenging. Recently, Bayesian concept has been used to increase the detection reliability in minimum-mean-square-error (MMSE) linear receivers. However, the latency processing time is a major concern due to the exponential complexity of matrix inversion operations in MMSE schemes. This paper proposes an iterative M-MIMO receiver that is developed by using a Bayesian concept and a parallel interference cancellation (PIC) scheme, referred to as a linear Bayesian learning (LBL) receiver. PIC has a linear complexity as it uses a combination of maximum ratio combining (MRC) and decision statistic combining (DSC) schemes to avoid matrix inversion operations. Simulation results show that the bit-error-rate (BER) and latency processing performances of the proposed receiver outperform the ones of MMSE and best Bayesian-based receivers by minimum $2$ dB and $19$ times for various M-MIMO system configurations.      
### 52.Temporal Knowledge Distillation for On-device Audio Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.14131.pdf)
>  Improving the performance of on-device audio classification models remains a challenge given the computational limits of the mobile environment. Many studies leverage knowledge distillation to boost predictive performance by transferring the knowledge from large models to on-device models. However, most lack the essence of the temporal information which is crucial to audio classification tasks, or similar architecture is often required. In this paper, we propose a new knowledge distillation method designed to incorporate the temporal knowledge embedded in attention weights of large models to on-device models. Our distillation method is applicable to various types of architectures, including the non-attention-based architectures such as CNNs or RNNs, without any architectural change during inference. Through extensive experiments on both an audio event detection dataset and a noisy keyword spotting dataset, we show that our proposed method improves the predictive performance across diverse on-device architectures.      
### 53.Data-driven decomposition of brain dynamics with principal component analysis in different types of head impacts  [ :arrow_down: ](https://arxiv.org/pdf/2110.14116.pdf)
>  Strain and strain rate are effective traumatic brain injury predictors. Kinematics-based models estimating these metrics suffer from significant different distributions of both kinematics and the injury metrics across head impact types. To address this, previous studies focus on the kinematics but not the injury metrics. We have previously shown the kinematic features vary largely across head impact types, resulting in different patterns of brain deformation. This study analyzes the spatial distribution of brain deformation and applies principal component analysis (PCA) to extract the representative patterns of injury metrics (maximum principal strain (MPS), MPS rate (MPSR) and MPSXMPSR) in four impact types (simulation, football, mixed martial arts and car crashes). We apply PCA to decompose the patterns of the injury metrics for all impacts in each impact type, and investigate the distributions among brain regions using the first principal component (PC1). Furthermore, we developed a deep learning head model (DLHM) to predict PC1 and then inverse-transform to predict for all brain elements. PC1 explained &gt;80% variance on the datasets. Based on PC1 coefficients, the corpus callosum and midbrain exhibit high variance on all datasets. We found MPSXMPSR the most sensitive metric on which the top 5% of severe impacts further deviates from the mean and there is a higher variance among the severe impacts. Finally, the DLHM reached mean absolute errors of &lt;0.018 for MPS, &lt;3.7 (1/s) for MPSR and &lt;1.1 (1/s) for MPSXMPSR, much smaller than the injury thresholds. The brain injury metric in a dataset can be decomposed into mean components and PC1 with high explained variance. The brain dynamics decomposition enables better interpretation of the patterns in brain injury metrics and the sensitivity of brain injury metrics across impact types. The decomposition also reduces the dimensionality of DLHM.      
### 54.A Bayesian Receiver with Improved Complexity-Reliability Trade-off in Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.14112.pdf)
>  The stringent requirements on reliability and processing delay in the fifth-generation ($5$G) cellular networks introduce considerable challenges in the design of massive multiple-input-multiple-output (M-MIMO) receivers. The two main components of an M-MIMO receiver are a detector and a decoder. To improve the trade-off between reliability and complexity, a Bayesian concept has been considered as a promising approach that enhances classical detectors, e.g. minimum-mean-square-error detector. This work proposes an iterative M-MIMO detector based on a Bayesian framework, a parallel interference cancellation scheme, and a decision statistics combining concept. We then develop a high performance M-MIMO receiver, integrating the proposed detector with a low complexity sequential decoding for polar codes. Simulation results of the proposed detector show a significant performance gain compared to other low complexity detectors. Furthermore, the proposed M-MIMO receiver with sequential decoding ensures one order magnitude lower complexity compared to a receiver with stack successive cancellation decoding for polar codes from the 5G New Radio standard.      
### 55.Bounding the Distance to Unsafe Sets with Convex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2110.14047.pdf)
>  This work proposes an algorithm to bound the minimum distance between points on trajectories of a dynamical system and points on an unsafe set. Prior work on certifying safety of trajectories includes barrier and density methods, which do not provide a margin of proximity to the unsafe set in terms of distance. The distance estimation problem is relaxed to a Monge-Kantorovich type optimal transport problem based on existing occupation-measure methods of peak estimation. Specialized programs may be developed for polyhedral norm distances (e.g. L1 and Linfinity) and for scenarios where a shape is traveling along trajectories (e.g. rigid body motion). The distance estimation problem will be correlatively sparse when the distance objective is separable.      
### 56.Intelligent Meta-Imagers: From Compressed to Learned Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.14022.pdf)
>  Computational meta-imagers synergize metamaterial hardware with advanced signal processing approaches such as compressed sensing. Recent advances in artificial intelligence (AI) are gradually reshaping the landscape of meta-imaging. Most recent works use AI for data analysis, but some also use it to program the physical meta-hardware. The role of "intelligence" in the measurement process and its implications for critical metrics like latency are often not immediately clear. Here, we comprehensively review the evolution of computational meta-imaging from the earliest frequency-diverse compressive systems to modern programmable intelligent meta-imagers. We introduce a clear taxonomy in terms of the flow of task-relevant information that has direct links to information theory: compressive meta-imagers indiscriminately acquire all scene information in a task-agnostic measurement process that aims at a near-isometric embedding; intelligent meta-imagers highlight task-relevant information in a task-aware measurement process that is purposefully non-isometric. We provide explicit design tutorials for the integration of programmable meta-atoms as trainable physical weights into an intelligent end-to-end sensing pipeline. This merging of the physical world of metamaterial engineering and the digital world of AI enables the remarkable latency gains of intelligent meta-imagers. We further outline emerging opportunities for cognitive meta-imagers with reverberation-enhanced resolution and we point out how the meta-imaging community can reap recent advances in the vibrant field of metamaterial wave processors to reach the holy grail of low-energy ultra-fast all-analog intelligent meta-sensors.      
