# ArXiv eess --Tue, 5 Oct 2021
### 1.Quickest Change Detection with Non-stationary and Composite Post-change Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2110.01581.pdf)
>  The problem of quickest detection of a change in the distribution of a sequence of independent observations is considered. The pre-change distribution is assumed to be known and stationary, while the post-change distributions are assumed to evolve in a pre-determined non-stationary manner with some possible parametric uncertainty. In particular, it is assumed that the cumulative KL divergence between the post-change and the pre-change distributions grows super-linearly with time after the change-point. For the case where the post-change distributions are known, a universal asymptotic lower bound on the delay is derived, as the false alarm rate goes to zero. Furthermore, a window-limited CuSum test is developed, and shown to achieve the lower bound asymptotically. For the case where the post-change distributions have parametric uncertainty, a window-limited generalized likelihood-ratio test is developed and is shown to achieve the universal lower bound asymptotically. Extensions to the case with dependent observations are discussed. The analysis is validated through numerical results on synthetic data. The use of the window-limited generalized likelihood-ratio test in monitoring pandemics is also demonstrated.      
### 2.Assessing glaucoma in retinal fundus photographs using Deep Feature Consistent Variational Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2110.01534.pdf)
>  One of the leading causes of blindness is glaucoma, which is challenging to detect since it remains asymptomatic until the symptoms are severe. Thus, diagnosis is usually possible until the markers are easy to identify, i.e., the damage has already occurred. Early identification of glaucoma is generally made based on functional, structural, and clinical assessments. However, due to the nature of the disease, researchers still debate which markers qualify as a consistent glaucoma metric. Deep learning methods have partially solved this dilemma by bypassing the marker identification stage and analyzing high-level information directly to classify the data. Although favorable, these methods make expert analysis difficult as they provide no insight into the model discrimination process. In this paper, we overcome this using deep generative networks, a deep learning model that learns complicated, high-dimensional probability distributions. We train a Deep Feature consistent Variational Autoencoder (DFC-VAE) to reconstruct optic disc images. We show that a small-sized latent space obtained from the DFC-VAE can learn the high-dimensional glaucoma data distribution and provide discriminatory evidence between normal and glaucoma eyes. Latent representations of size as low as 128 from our model got a 0.885 area under the receiver operating characteristic curve when trained with Support Vector Classifier.      
### 3.Analysis of the Implication of Current Limits in Grid Forming Wind Farm  [ :arrow_down: ](https://arxiv.org/pdf/2110.01526.pdf)
>  There is an ongoing trend of reduction in short circuit power at the grid connection point due to decommissioning of synchronous generation plants causing system strength issues in wind power plants. Whereas wind power plant rating and export cable length are increasing, further weakening the system strength and accompanied by stability challenges. Under such a scenario, a grid forming control demonstrated to operate in a weaker system has value creation potential for application in wind turbine generators. In addition, the grid forming control can also enable a wind power plant to operate in islanded mode, provide inertially and phase jump active power support. However, the application of grid forming control has challenges because grid forming control applied to a power converter (GFC) has a voltage source behavior and does not stiffly control the grid side active power and thus requires a separate current limiting mechanism. However, there could be potential challenges in maintaining the synchronism of GFC when the current limit is triggered, particularly during the grid voltage phase jump event. Modeling and capturing such a phenomenon is a challenge in a wind farm with many wind turbines. To that end, this paper investigates the modeling adequacy of the aggregated GFC-WF to a single GF-WTG of total WF rating in capturing GFC-WF dynamics. The challenges related to loss of synchronization stability when one or more wind turbine generators enter current limited operation during a grid phase jump events are also evaluated in this paper.      
### 4.Exploiting Pre-Trained ASR Models for Alzheimer's Disease Recognition Through Spontaneous Speech  [ :arrow_down: ](https://arxiv.org/pdf/2110.01493.pdf)
>  Alzheimer's disease (AD) is a progressive neurodegenerative disease and recently attracts extensive attention worldwide. Speech technology is considered a promising solution for the early diagnosis of AD and has been enthusiastically studied. Most recent works concentrate on the use of advanced BERT-like classifiers for AD detection. Input to these classifiers are speech transcripts produced by automatic speech recognition (ASR) models. The major challenge is that the quality of transcription could degrade significantly under complex acoustic conditions in the real world. The detection performance, in consequence, is largely limited. This paper tackles the problem via tailoring and adapting pre-trained neural-network based ASR model for the downstream AD recognition task. Only bottom layers of the ASR model are retained. A simple fully-connected neural network is added on top of the tailored ASR model for classification. The heavy BERT classifier is discarded. The resulting model is light-weight and can be fine-tuned in an end-to-end manner for AD recognition. Our proposed approach takes only raw speech as input, and no extra transcription process is required. The linguistic information of speech is implicitly encoded in the tailored ASR model and contributes to boosting the performance. Experiments show that our proposed approach outperforms the best manual transcript-based RoBERTa by an absolute margin of 4.6% in terms of accuracy. Our best-performing models achieve the accuracy of 83.2% and 78.0% in the long-audio and short-audio competition tracks of the 2021 NCMMSC Alzheimer's Disease Recognition Challenge, respectively.      
### 5.Data-driven Identification of Nonlinear Power System Dynamics Using Output-only Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2110.01469.pdf)
>  In this paper, we propose a novel approach for the data-driven characterization of power system dynamics. The developed method of Extended Subspace Identification (ESI) is suitable for systems with output measurements when all the dynamics states are not observable. It is particularly applicable for power systems dynamic identification using Phasor Measurement Units (PMUs) measurements. As in the case of power systems, it is often expensive or impossible to measure all the internal dynamic states of system components such as generators, controllers and loads. PMU measurements capture voltages, currents, power injection and frequencies, which can be considered as the outputs of system dynamics. The ESI method is suitable for system identification, capturing nonlinear modes, computing participation factor of output measurements in system modes and identifying system parameters such as system inertia. The proposed method is suitable for measurements with a noise similar to realistic system measurements. The developed method addresses some of the known deficiencies of existing data-driven dynamic system characterization methods. The approach is validated for multiple network models and dynamic event scenarios with synthetic PMU measurements.      
### 6.Drone Charging Stations Deployment in Rural Areas for Better Wireless Coverage: Challenges and Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2110.01459.pdf)
>  While the fifth-generation cellular (5G) is meant to deliver Gigabit peak data speeds, low latency, and connect to billions of devices, and 6G is already on the way, half of the world population living in rural areas are still facing challenges connecting to the internet. Compared with urban areas, users in rural areas are greatly impacted by low income, high cost of backhaul connectivity, limited resources, extreme weather, and natural geographical limitations. Hereby, how to connect the rural areas and what are the difficulties of providing connectivity draw great attention. This article first provides a brief discussion about existing technologies and strategies for enhancing the network coverage in rural areas, their advantages, limitations, and cost. Next, we mainly focus on the UAV-assisted network in resource-limited regions. Considering the limitation of the on-board battery of UAVs and the electricity supply scarcity in some rural regions, we investigate the possibility and performance enhancement of the deployment of renewable energy (RE) charging stations. We outline three practical scenarios, and use simulation results to demonstrate that RE charging stations can be a possible solution to address the limited on-board battery of UAVs in rural areas, specially when they can harvest and store enough energy. Finally, future works and challenges are discussed.      
### 7.WaveBeat: End-to-end beat and downbeat tracking in the time domain  [ :arrow_down: ](https://arxiv.org/pdf/2110.01436.pdf)
>  Deep learning approaches for beat and downbeat tracking have brought advancements. However, these approaches continue to rely on hand-crafted, subsampled spectral features as input, restricting the information available to the model. In this work, we propose WaveBeat, an end-to-end approach for joint beat and downbeat tracking operating directly on waveforms. This method forgoes engineered spectral features, and instead, produces beat and downbeat predictions directly from the waveform, the first of its kind for this task. Our model utilizes temporal convolutional networks (TCNs) operating on waveforms that achieve a very large receptive field ($\geq$ 30 s) at audio sample rates in a memory efficient manner by employing rapidly growing dilation factors with fewer layers. With a straightforward data augmentation strategy, our method outperforms previous state-of-the-art methods on some datasets, while producing comparable results on others, demonstrating the potential for time domain approaches.      
### 8.Economics of Semantic Communication System in Wireless Powered Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2110.01423.pdf)
>  The semantic communication system enables wireless devices to communicate effectively with the semantic meaning of the data. Wireless powered Internet of Things (IoT) that adopts the semantic communication system relies on harvested energy to transmit semantic information. However, the issue of energy constraint in the semantic communication system is not well studied. In this paper, we propose a semantic-based energy valuation and take an economic approach to solve the energy allocation problem as an incentive mechanism design. In our model, IoT devices (bidders) place their bids for the energy and power transmitter (auctioneer) decides the winner and payment by using deep learning based optimal auction. Results show that the revenue of wireless power transmitter is maximized while satisfying Individual Rationality (IR) and Incentive Compatibility (IC).      
### 9.Individualized sound pressure equalization in hearing devices exploiting an electro-acoustic model  [ :arrow_down: ](https://arxiv.org/pdf/2110.01422.pdf)
>  To improve sound quality in hearing devices, the hearing device output should be appropriately equalized. To achieve optimal individualized equalization typically requires knowledge of all transfer functions between the source, the hearing device, and the individual eardrum. However, in practice the measurement of all of these transfer functions is not feasible. This study investigates sound pressure equalization using different transfer function estimates. Specifically, an electro-acoustic model is used to predict the sound pressure at the individual eardrum, and average estimates are used to predict the remaining transfer functions. Experimental results show that using these assumptions a practically feasible and close-to-optimal individualized sound pressure equalization can be achieved.      
### 10.Model Based Control of Soft Robots: A Survey of the State of the Art and Open Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2110.01358.pdf)
>  Continuum soft robots are mechanical systems entirely made of continuously deformable elements. This design solution aims to bring robots closer to invertebrate animals and soft appendices of vertebrate animals (e.g., an elephant's trunk, a monkey's tail). This work aims to introduce the control theorist perspective to this novel development in robotics. We aim to remove the barriers to entry into this field by presenting existing results and future challenges using a unified language and within a coherent framework. Indeed, the main difficulty in entering this field is the wide variability of terminology and scientific backgrounds, making it quite hard to acquire a comprehensive view on the topic. Another limiting factor is that it is not obvious where to draw a clear line between the limitations imposed by the technology not being mature yet and the challenges intrinsic to this class of robots. In this work, we argue that the intrinsic effects are the continuum or multi-body dynamics, the presence of a non-negligible elastic potential field, and the variability in sensing and actuation strategies.      
### 11.Multi-dimensional Lorenz-Based Chaotic Waveforms for Wireless Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2110.01357.pdf)
>  In this paper, we investigate multi-dimensional chaotic signals with respect to wireless power transfer (WPT). Specifically, we analyze a multi-dimensional Lorenz-based chaotic signal under a WPT framework. By taking into account the nonlinearities of the energy harvesting process, closed-form analytical expressions for the average harvested energy are derived. Moreover, the practical limitations of the high power amplifier (HPA) at the transmitter are also taken into consideration. We interestingly observe that for these types of signals, high peak-to-average-power-ratio (PAPR) is not the only criterion for obtaining enhanced WPT. We demonstrate that while the HPA imperfections do not significantly affect the signal PAPR, it notably degrades the energy transfer performance. As the proposed framework is general, we also demonstrate its application with respect to a Henon signal based WPT. Finally we compare Lorenz and Henon signals with the conventional multisine waveforms in terms of WPT performance.      
### 12.Blindness (Diabetic Retinopathy) Severity Scale Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.01333.pdf)
>  Diabetic retinopathy (DR) is a severe complication of diabetes that can cause permanent blindness. Timely diagnosis and treatment of DR are critical to avoid total loss of vision. Manual diagnosis is time consuming and error-prone. In this paper, we propose a novel deep learning based method for automatic screening of retinal fundus images to detect and classify DR based on the severity. The method uses a dual-path configuration of deep neural networks to achieve the objective. In the first step, a modified UNet++ based retinal vessel segmentation is used to create a fundus image that emphasises elements like haemorrhages, cotton wool spots, and exudates that are vital to identify the DR stages. Subsequently, two convolutional neural networks (CNN) classifiers take the original image and the newly created fundus image respectively as inputs and identify the severity of DR on a scale of 0 to 4. These two scores are then passed through a shallow neural network classifier (ANN) to predict the final DR stage. The public datasets STARE, DRIVE, CHASE DB1, and APTOS are used for training and evaluation. Our method achieves an accuracy of 94.80% and Quadratic Weighted Kappa (QWK) score of 0.9254, and outperform many state-of-the-art methods.      
### 13.Synthetic Velocity Mapping Cardiac MRI Coupled with Automated Left Ventricle Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.01304.pdf)
>  Temporal patterns of cardiac motion provide important information for cardiac disease diagnosis. This pattern could be obtained by three-directional CINE multi-slice left ventricular myocardial velocity mapping (3Dir MVM), which is a cardiac MR technique providing magnitude and phase information of the myocardial motion simultaneously. However, long acquisition time limits the usage of this technique by causing breathing artifacts, while shortening the time causes low temporal resolution and may provide an inaccurate assessment of cardiac motion. In this study, we proposed a frame synthesis algorithm to increase the temporal resolution of 3Dir MVM data. Our algorithm is featured by 1) three attention-based encoders which accept magnitude images, phase images, and myocardium segmentation masks respectively as inputs; 2) three decoders that output the interpolated frames and corresponding myocardium segmentation results; and 3) loss functions highlighting myocardium pixels. Our algorithm can not only increase the temporal resolution 3Dir MVMs, but can also generates the myocardium segmentation results at the same time.      
### 14.Light-weight Deformable Registration using Adversarial Learning with Distilling Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2110.01293.pdf)
>  Deformable registration is a crucial step in many medical procedures such as image-guided surgery and radiation therapy. Most recent learning-based methods focus on improving the accuracy by optimizing the non-linear spatial correspondence between the input images. Therefore, these methods are computationally expensive and require modern graphic cards for real-time deployment. In this paper, we introduce a new Light-weight Deformable Registration network that significantly reduces the computational cost while achieving competitive accuracy. In particular, we propose a new adversarial learning with distilling knowledge algorithm that successfully leverages meaningful information from the effective but expensive teacher network to the student network. We design the student network such as it is light-weight and well suitable for deployment on a typical CPU. The extensively experimental results on different public datasets show that our proposed method achieves state-of-the-art accuracy while significantly faster than recent methods. We further show that the use of our adversarial learning algorithm is essential for a time-efficiency deformable registration method. Finally, our source code and trained models are available at: <a class="link-external link-https" href="https://github.com/aioz-ai/LDR_ALDK" rel="external noopener nofollow">this https URL</a>.      
### 15.Passivity-based Local Criteria for Stability of Power Systems with Converter-Interfaced Generation  [ :arrow_down: ](https://arxiv.org/pdf/2110.01216.pdf)
>  With the increasing penetration of converter-interfaced distributed generation systems, it would be advantageous to specify local compliance criteria for these devices to ensure the small-signal stability of the interconnected system. Passivity of the device admittance, which is an example of a local criterion, has been used previously to avoid resonances between these devices and the lightly damped oscillatory modes of the network. Typical active and reactive power control strategies like droop control and virtual synchronous generator control inherently violate the passivity constraints on admittance at low frequencies, although this does not necessarily mean that the interconnected system will be unstable. Therefore, passivity of the admittance is unsuitable as a stability criterion for devices that are represented by their wide-band models. To overcome this problem, this paper proposes the use of criteria based on admittance at higher frequencies and an alternative transfer function at lower frequencies. The alternative representation uses active and reactive power and the derivatives of the polar components of voltage as interface variables. To allow for the separate analysis at low and high frequencies, the device dynamics should exhibit a slow-fast separation; this is proposed as an additional constraint. Adherence to the proposed criteria is not onerous and is easily verifiable through frequency response analysis.      
### 16.Evaluation on Energy Efficiency of UE in UL Cell-Free Massive MIMO System With Power Control Methods  [ :arrow_down: ](https://arxiv.org/pdf/2110.01211.pdf)
>  Cell-free massive multiple-input multiple-output (CF mMIMO) systems are expected to provide faster and more robust connections to user equipments (UEs) by cooperation of a massive number of distributed access points, and to be one of the key technologies for beyond 5G (B5G). In B5G, energy efficiency (EE) is one of the most important key indicators because various kinds of devices connect to the network and communicate with each other. While previously proposed transmit power control methods in CF mMIMO systems have aimed to maximize spectral efficiency or total EE, we evaluate in this paper a different approach for maximizing the minimum EE among all UEs. We show that this algorithm can provide the optimum solution in polynomial time, and demonstrate with simulations the improved minimum EE compared to conventional methods.      
### 17.A Game Theoretic Approach for Demand Response Allocation among Strategic Prosumers in Regulated Distribution Utilities  [ :arrow_down: ](https://arxiv.org/pdf/2110.01205.pdf)
>  This paper studies an optimal allocation of demand response (DR) provisions among strategic photovoltaic (PV) prosumers, through third-party DR providers which operate within the territory of the regulated distribution utility. A game theoretic model, consisting of a sequential game coupled with a simultaneous game, is proposed to capture the competition and interaction among PV prosumers, the third-party DR providers, and the utility company. An iterative approach is proposed to solve for the Nash equilibrium of the game. With this game theoretic model, the DR provision quantities for strategic PV prosumers are optimally determined, considering the profit maximizations of the PV prosumers, the DR providers, and the utility company. Case studies on an IEEE test system verifies the proposed model and the solution approach.      
### 18.From Control to Mathematics-Part II: Observability-Based Design for Iterative Methods in Solving Linear Equations  [ :arrow_down: ](https://arxiv.org/pdf/2110.01203.pdf)
>  The control approaches generally resort to the tools from the mathematics, but whether and how the mathematics can benefit from the control approaches is unclear. This paper aims to bring the "control design" idea into the mathematics by providing an observer-based iterative method that focuses on solving linear algebraic equations (LAEs). An inherent relationship is revealed between the problem-solving of LAEs and the design of observer-based control systems, with which the iterative method for solving LAEs is exploited based on the design of the basic state observers. It is shown that all (least squares) solutions for any (un)solvable LAEs can be determined exponentially fast or monotonically with different selections of initial conditions. By integrating the design idea of the deadbeat control, the solving of LAEs can be achieved within only finite iterations. In particular, our proposed iterative method can be leveraged to develop a new observer-based design algorithm to realize the perfect tracking objective of conventional two-dimensional iterative learning control (ILC) systems, where the gap between classical ILC design and popular feedback-based control design is narrowed.      
### 19.AASIST: Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.01200.pdf)
>  Artefacts that differentiate spoofed from bona-fide utterances can reside in spectral or temporal domains. Their reliable detection usually depends upon computationally demanding ensemble systems where each subsystem is tuned to some specific artefacts. We seek to develop an efficient, single system that can detect a broad range of different spoofing attacks without score-level ensembles. We propose a novel heterogeneous stacking graph attention layer which models artefacts spanning heterogeneous temporal and spectral domains with a heterogeneous attention mechanism and a stack node. With a new max graph operation that involves a competitive mechanism and an extended readout scheme, our approach, named AASIST, outperforms the current state-of-the-art by 20% relative. Even a lightweight variant, AASIST-L, with only 85K parameters, outperforms all competing systems.      
### 20.The Second DiCOVA Challenge: Dataset and performance analysis for COVID-19 diagnosis using acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2110.01177.pdf)
>  The Second DiCOVA Challenge aims at accelerating the research in diagnosing COVID-19 using acoustics (DiCOVA), a topic at the intersection of acoustics signal processing, machine learning, and healthcare. This challenge is an open call to researchers to analyze a dataset of audio recordings, collected from individuals with and without COVID-19, for a two-class classification. The development set audio recordings correspond to breathing, cough, and speech sound samples collected from 965 (172 COVID) individuals. The challenge features four tracks, one associated with each sound category and a fourth fusion track allowing experimentation with combination of the individual sound categories. In this paper, we introduce the challenge and provide a detailed description of the task and a baseline system.      
### 21.Deep Kernel Representation for Image Reconstruction in PET  [ :arrow_down: ](https://arxiv.org/pdf/2110.01174.pdf)
>  Image reconstruction for positron emission tomography (PET) is challenging because of the ill-conditioned tomographic problem and low counting statistics. Kernel methods address this challenge by using kernel representation to incorporate image prior information in the forward model of iterative PET image reconstruction. Existing kernel methods construct the kernels commonly using an empirical process, which may lead to suboptimal performance. In this paper, we describe the equivalence between the kernel representation and a trainable neural network model. A deep kernel method is proposed by exploiting deep neural networks to enable an automated learning of an optimized kernel model. The proposed method is directly applicable to single subjects. The training process utilizes available image prior data to seek the best way to form a set of robust kernels optimally rather than empirically. The results from computer simulations and a real patient dataset demonstrate that the proposed deep kernel method can outperform existing kernel method and neural network method for dynamic PET image reconstruction.      
### 22.Decoupling Speaker-Independent Emotions for Voice Conversion Via Source-Filter Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.01164.pdf)
>  Emotional voice conversion (VC) aims to convert a neutral voice to an emotional (e.g. happy) one while retaining the linguistic information and speaker identity. We note that the decoupling of emotional features from other speech information (such as speaker, content, etc.) is the key to achieving remarkable performance. Some recent attempts about speech representation decoupling on the neutral speech can not work well on the emotional speech, due to the more complex acoustic properties involved in the latter. To address this problem, here we propose a novel Source-Filter-based Emotional VC model (SFEVC) to achieve proper filtering of speaker-independent emotion features from both the timbre and pitch features. Our SFEVC model consists of multi-channel encoders, emotion separate encoders, and one decoder. Note that all encoder modules adopt a designed information bottlenecks auto-encoder. Additionally, to further improve the conversion quality for various emotions, a novel two-stage training strategy based on the 2D Valence-Arousal (VA) space was proposed. Experimental results show that the proposed SFEVC along with a two-stage training strategy outperforms all baselines and achieves the state-of-the-art performance in speaker-independent emotional VC with nonparallel data.      
### 23.Decentralized Safe Reinforcement Learning for Voltage Control  [ :arrow_down: ](https://arxiv.org/pdf/2110.01126.pdf)
>  Inverter-based distributed energy resources provide the possibility for fast time-scale voltage control by quickly adjusting their reactive power. The power-electronic interfaces allow these resources to realize almost arbitrary control law, but designing these decentralized controllers is nontrivial. Reinforcement learning (RL) approaches are becoming increasingly popular to search for policy parameterized by neural networks. It is difficult, however, to enforce that the learned controllers are safe, in the sense that they may introduce instabilities into the system. <br>This paper proposes a safe learning approach for voltage control. We prove that the system is guaranteed to be exponentially stable if each controller satisfies certain Lipschitz constraints. The set of Lipschitz bound is optimized to enlarge the search space for neural network controllers. We explicitly engineer the structure of neural network controllers such that they satisfy the Lipschitz constraints by design. A decentralized RL framework is constructed to train local neural network controller at each bus in a model-free setting.      
### 24.Cloud-Cluster Architecture for Detection in Intermittently Connected Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.01119.pdf)
>  We consider a centralized detection problem where sensors experience noisy measurements and intermittent connectivity to a centralized fusion center. The sensors may collaborate locally within predefined sensor clusters and fuse their noisy sensor data to reach a common local estimate of the detected event in each cluster. The connectivity of each sensor cluster is intermittent and depends on the available communication opportunities of the sensors to the fusion center. Upon receiving the estimates from all the connected sensor clusters the fusion center fuses the received estimates to make a final determination regarding the occurrence of the event across the deployment area. We refer to this hybrid communication scheme as a cloud-cluster architecture. We propose a method for optimizing the decision rule for each cluster and analyzing the expected detection performance resulting from our hybrid scheme. Our method is tractable and addresses the high computational complexity caused by heterogeneous sensors' and clusters' detection quality, heterogeneity in their communication opportunities, and non-convexity of the loss function. Our analysis shows that clustering the sensors provides resilience to noise in the case of low sensor communication probability with the cloud. For larger clusters, a steep improvement in detection performance is possible even for a low communication probability by using our cloud-cluster architecture.      
### 25.Quadrotor Control on $SU(2)\times R^3$ with SLAM Integration  [ :arrow_down: ](https://arxiv.org/pdf/2110.01099.pdf)
>  We present a trajectory tracking controller for a quadrotor unmanned aerial vehicle (UAV) configured on $SU(2)\times R^3$, and relate this result to a family of geometric tracking controllers on $SO(3)\times R^3$. The theoretical results are complemented by simulation examples, and the controller is subsequently implemented in practice and integrated with a simultaneous localization and mapping (SLAM) system through an extended Kalman filter (EKF). This facilitates the operation of the UAV without external motion capture systems, and we demonstrate that the proposed control system can be used for inventorying tasks in a supermarket environment without external positioning systems.      
### 26.Characterizing Power Support from Distribution Networks via Flexibility Area Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.01086.pdf)
>  This paper proposes a framework for characterizing and managing active distribution networks (ADNs) via flexibility area segmentation. Specifically, flexible active and reactive power support at the interface with transmission networks is analyzed. The framework is fundamentally different from existing studies that either characterize ADN flexibility considering the full availability of flexible units or determine a risk-averse share of the flexibility area using robust optimization models. Such methods cannot provide sufficient information to distribution system operators (DSOs) on the structure of the flexibility area and reliability of its components. The proposed segmentation approach relies on combinatorial optimization models and classifies the ADN flexibility area's segments by the number of flexible units activated and probabilities associated with units activation. The resulting classification enables DSOs to analyze and manage the provision of ADNs flexibility services. The applicability and scalability of the proposed framework is illustrated based on the 33-bus and 124-bus radial distribution network case studies.      
### 27.Multi-task Voice-Activated Framework using Self-supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.01077.pdf)
>  Self-supervised learning methods such as wav2vec 2.0 have shown promising results in learning speech representations from unlabelled and untranscribed speech data that are useful for speech recognition. Since these representations are learned without any task-specific supervision, they can also be useful for other voice-activated tasks like speaker verification, keyword spotting, emotion classification etc. In our work, we propose a general purpose framework for adapting a pre-trained wav2vec 2.0 model for different voice-activated tasks. We develop downstream network architectures that operate on the contextualized speech representations of wav2vec 2.0 to adapt the representations for solving a given task. Finally, we extend our framework to perform multi-task learning by jointly optimizing the network parameters on multiple voice activated tasks using a shared transformer backbone. Both of our single and multi-task frameworks achieve state-of-the-art results in speaker verification and keyword spotting benchmarks. Our best performing models achieve 1.98% and 3.15% EER on VoxCeleb1 test set when trained on VoxCeleb2 and VoxCeleb1 respectively, and 98.23% accuracy on Google Speech Commands v1.0 keyword spotting dataset.      
### 28.Efficient Modeling of Morphing Wing Flight Using Neural Networks and Cubature Rules  [ :arrow_down: ](https://arxiv.org/pdf/2110.01057.pdf)
>  Fluidic locomotion of flapping Micro Aerial Vehicles (MAVs) can be very complex, particularly when the rules from insect flight dynamics (fast flapping dynamics and light wings) are not applicable. In these situations, widely used averaging techniques can fail quickly. The primary motivation is to find efficient models for complex forms of aerial locomotion where wings constitute a large part of body mass (i.e., dominant inertial effects) and deform in multiple directions (i.e., morphing wing). <br>In these systems, high degrees of freedom yields complex inertial, Coriolis, and gravity terms. We use Algorithmic Differentiation (AD) and Bayesian filters computed with cubature rules conjointly to quickly estimate complex fluid-structure interactions. In general, Bayesian filters involve finding complex numerical integration (e.g., find posterior integrals). Using cubature rules to compute Gaussian-weighted integrals and AD, we show that the complex multi-degrees-of-freedom dynamics of morphing MAVs can be computed very efficiently and accurately. Therefore, our work facilitates closed-loop feedback control of these morphing MAVs.      
### 29.EAR-U-Net: EfficientNet and attention-based residual U-Net for automatic liver segmentation in CT  [ :arrow_down: ](https://arxiv.org/pdf/2110.01014.pdf)
>  Purpose: This paper proposes a new network framework called EAR-U-Net, which leverages EfficientNetB4, attention gate, and residual learning techniques to achieve automatic and accurate liver segmentation. Methods: The proposed method is based on the U-Net framework. First, we use EfficientNetB4 as the encoder to extract more feature information during the encoding stage. Then, an attention gate is introduced in the skip connection to eliminate irrelevant regions and highlight features of a specific segmentation task. Finally, to alleviate the problem of gradient vanishment, we replace the traditional convolution of the decoder with a residual block to improve the segmentation accuracy. Results: We verified the proposed method on the LiTS17 and SLiver07 datasets and compared it with classical networks such as FCN, U-Net, Attention U-Net, and Attention Res-U-Net. In the Sliver07 evaluation, the proposed method achieved the best segmentation performance on all five standard metrics. Meanwhile, in the LiTS17 assessment, the best performance is obtained except for a slight inferior on RVD. Moreover, we also participated in the MICCIA-LiTS17 challenge, and the Dice per case score was 0.952. Conclusion: The proposed method's qualitative and quantitative results demonstrated its applicability in liver segmentation and proved its good prospect in computer-assisted liver segmentation.      
### 30.Massive-MIMO MF Beamforming with or without Grouped STBC for Ultra-Reliable Single-Shot Transmission Using Aged CSIT  [ :arrow_down: ](https://arxiv.org/pdf/2110.00996.pdf)
>  The technology of using massive transmit-antennas to enable ultra-reliable single-shot transmission (URSST) is challenged by the transmitter-side channel knowledge (i.e., CSIT) imperfection. When the imperfectness mainly comes from the channel time-variation, the outage probability of the matched filter (MF) transmitter beamforming is investigated based on the first-order Markov model of the aged CSIT. With a fixed transmit-power, the transmitter-side uncertainty of the instantaneous signal-to-noise ratio (iSNR) is mathematically characterized. In order to guarantee the outage probability for every single shot, a transmit-power adaptation approach is proposed to satisfy a pessimistic iSNR requirement, which is predicted using the Chernoff lower bound of the beamforming gain. Our numerical results demonstrate a remarkable transmit-power efficiency when comparing with power control approaches using other lower bounds. In addition, a combinatorial approach of the MF beamforming and grouped space-time block code (G-STBC) is proposed to further mitigate the detrimental impact of the CSIT uncertainty. It is shown, through both theoretical analysis and computer simulations, that the combinatorial approach can further improve the transmit-power efficiency with a good tradeoff between the outage probability and the latency.      
### 31.Adaptive Unfolding Total Variation Network for Low-Light Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2110.00984.pdf)
>  Real-world low-light images suffer from two main degradations, namely, inevitable noise and poor visibility. Since the noise exhibits different levels, its estimation has been implemented in recent works when enhancing low-light images from raw Bayer space. When it comes to sRGB color space, the noise estimation becomes more complicated due to the effect of the image processing pipeline. Nevertheless, most existing enhancing algorithms in sRGB space only focus on the low visibility problem or suppress the noise under a hypothetical noise level, leading them impractical due to the lack of robustness. To address this issue,we propose an adaptive unfolding total variation network (UTVNet), which approximates the noise level from the real sRGB low-light image by learning the balancing parameter in the model-based denoising method with total variation regularization. Meanwhile, we learn the noise level map by unrolling the corresponding minimization process for providing the inferences of smoothness and fidelity constraints. Guided by the noise level map, our UTVNet can recover finer details and is more capable to suppress noise in real captured low-light scenes. Extensive experiments on real-world low-light images clearly demonstrate the superior performance of UTVNet over state-of-the-art methods.      
### 32.Adaptive Real-Time Grid Operation via Online Feedback Optimization with Sensitivity Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2110.00954.pdf)
>  In this paper we propose an approach based on an Online Feedback Optimization (OFO) controller with grid input-output sensitivity estimation for real-time grid operation, e.g., at subsecond time scales. The OFO controller uses grid measurements as feedback to update the value of the controllable elements in the grid, and track the solution of a time-varying AC Optimal Power Flow (AC-OPF). Instead of relying on a full grid model, e.g., grid admittance matrix, OFO only requires the steady-state sensitivity relating a change in the controllable inputs, e.g., power injections set-points, to a change in the measured outputs, e.g., voltage magnitudes. Since an inaccurate sensitivity may lead to a model-mismatch and jeopardize the performance, we propose a recursive least-squares estimation that enables OFO to learn the sensitivity from measurements during real-time operation, turning OFO into a model-free approach. We analytically certify the convergence of the proposed OFO with sensitivity estimation, and validate its performance on a simulation using the IEEE 123-bus test feeder, and comparing it against a state-of-the-art OFO with constant sensitivity.      
### 33.Interactive Segmentation for COVID-19 Infection Quantification on Longitudinal CT scans  [ :arrow_down: ](https://arxiv.org/pdf/2110.00948.pdf)
>  Consistent segmentation of COVID-19 patient's CT scans across multiple time points is essential to assess disease progression and response to therapy accurately. Existing automatic and interactive segmentation models for medical images only use data from a single time point (static). However, valuable segmentation information from previous time points is often not used to aid the segmentation of a patient's follow-up scans. Also, fully automatic segmentation techniques frequently produce results that would need further editing for clinical use. In this work, we propose a new single network model for interactive segmentation that fully utilizes all available past information to refine the segmentation of follow-up scans. In the first segmentation round, our model takes 3D volumes of medical images from two-time points (target and reference) as concatenated slices with the additional reference time point segmentation as a guide to segment the target scan. In subsequent segmentation refinement rounds, user feedback in the form of scribbles that correct the segmentation and the target's previous segmentation results are additionally fed into the model. This ensures that the segmentation information from previous refinement rounds is retained. Experimental results on our in-house multiclass longitudinal COVID-19 dataset show that the proposed model outperforms its static version and can assist in localizing COVID-19 infections in patient's follow-up scans.      
### 34.Artificial Intelligence For Breast Cancer Detection: Trends &amp; Directions  [ :arrow_down: ](https://arxiv.org/pdf/2110.00942.pdf)
>  In the last decade, researchers working in the domain of computer vision and Artificial Intelligence (AI) have beefed up their efforts to come up with the automated framework that not only detects but also identifies stage of breast cancer. The reason for this surge in research activities in this direction are mainly due to advent of robust AI algorithms (deep learning), availability of hardware that can train those robust and complex AI algorithms and accessibility of large enough dataset required for training AI algorithms. Different imaging modalities that have been exploited by researchers to automate the task of breast cancer detection are mammograms, ultrasound, magnetic resonance imaging, histopathological images or any combination of them. This article analyzes these imaging modalities and presents their strengths, limitations and enlists resources from where their datasets can be accessed for research purpose. This article then summarizes AI and computer vision based state-of-the-art methods proposed in the last decade, to detect breast cancer using various imaging modalities. Generally, in this article we have focused on to review frameworks that have reported results using mammograms as it is most widely used breast imaging modality that serves as first test that medical practitioners usually prescribe for the detection of breast cancer. Second reason of focusing on mammogram imaging modalities is the availability of its labeled datasets. Datasets availability is one of the most important aspect for the development of AI based frameworks as such algorithms are data hungry and generally quality of dataset affects performance of AI based algorithms. In a nutshell, this research article will act as a primary resource for the research community working in the field of automated breast imaging analysis.      
### 35.Exploration of AI-Oriented Power System Transient Stability Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2110.00931.pdf)
>  Artificial Intelligence (AI) has made significant progress in the past 5 years and is playing a more and more important role in power system analysis and control. It is foreseeable that the future power system transient stability simulations will be deeply integrated with AI. However, the existing power system dynamic simulation tools are not AI-friendly enough. In this paper, a general design of an AI-oriented power system transient stability simulator is proposed. It is a parallel simulator with a flexible application programming interface so that the simulator has rapid simulation speed, neural network supportability, and network topology accessibility. A prototype of this design is implemented and made public based on our previously realized simulator. Tests of this AI-oriented simulator are carried out under multiple scenarios, which proves that the design and implementation of the simulator are reasonable, AI-friendly, and highly efficient.      
### 36.Application of Artificial Neural Networks for Catalysis  [ :arrow_down: ](https://arxiv.org/pdf/2110.00924.pdf)
>  Catalyst, as an important material, plays a crucial role in the development of chemical industry. By improving the performance of the catalyst, the economic benefit can be greatly improved. Artificial neural network (ANN), as one of the most popular machine learning algorithms, relies on its good ability of nonlinear transformation, parallel processing, self-learning, self-adaptation and good associative memory, has been widely applied to various areas. Through the optimization of catalyst by ANN, the consumption of time and resources can be greatly reduced and greater economic benefits can be obtained. In this review, we show how this powerful technique helps people address the highly complicated problems and accelerate the progress of the catalysis community.      
### 37.Attention module improves both performance and interpretability of 4D fMRI decoding neural network  [ :arrow_down: ](https://arxiv.org/pdf/2110.00920.pdf)
>  Decoding brain cognitive states from neuroimaging signals is an important topic in neuroscience. In recent years, deep neural networks (DNNs) have been recruited for multiple brain state decoding and achieved good performance. However, the open question of how to interpret the DNN black box remains unanswered. Capitalizing on advances in machine learning, we integrated attention modules into brain decoders to facilitate an in-depth interpretation of DNN channels. A 4D convolution operation was also included to extract temporo-spatial interaction within the fMRI signal. The experiments showed that the proposed model obtains a very high accuracy (97.4%) and outperforms previous researches on the 7 different task benchmarks from the Human Connectome Project (HCP) dataset. The visualization analysis further illustrated the hierarchical emergence of task-specific masks with depth. Finally, the model was retrained to regress individual traits within the HCP and to classify viewing images from the BOLD5000 dataset, respectively. Transfer learning also achieves good performance. A further visualization analysis shows that, after transfer learning, low-level attention masks remained similar to the source domain, whereas high-level attention masks changed adaptively. In conclusion, the proposed 4D model with attention module performed well and facilitated interpretation of DNNs, which is helpful for subsequent research.      
### 38.Disarranged Zone Learning (DZL): An unsupervised and dynamic automatic stenosis recognition methodology based on coronary angiography  [ :arrow_down: ](https://arxiv.org/pdf/2110.00896.pdf)
>  We proposed a novel unsupervised methodology named Disarranged Zone Learning (DZL) to automatically recognize stenosis in coronary angiography. The methodology firstly disarranges the frames in a video, secondly it generates an effective zone and lastly trains an encoder-decoder GRU model to learn the capability to recover disarranged frames. The breakthrough of our study is to discover and validate the Sequence Intensity (Recover Difficulty) is a measure of Coronary Artery Stenosis Status. Hence, the prediction accuracy of DZL is used as an approximator of coronary stenosis indicator. DZL is an unsupervised methodology and no label engineering effort is needed, the sub GRU model in DZL works as a self-supervised approach. So DZL could theoretically utilize infinitely huge amounts of coronary angiographies to learn and improve performance without laborious data labeling. There is no data preprocessing precondition to run DZL as it dynamically utilizes the whole video, hence it is easy to be implemented and generalized to overcome the data heterogeneity of coronary angiography. The overall average precision score achieves 0.93, AUC achieves 0.8 for this pure methodology. The highest segmented average precision score is 0.98 and the highest segmented AUC is 0.87 for coronary occlusion indicator. Finally, we developed a software demo to implement DZL methodology.      
### 39.A Robust Alternative for Graph Convolutional Neural Networks via Graph Neighborhood Filters  [ :arrow_down: ](https://arxiv.org/pdf/2110.00844.pdf)
>  Graph convolutional neural networks (GCNNs) are popular deep learning architectures that, upon replacing regular convolutions with graph filters (GFs), generalize CNNs to irregular domains. However, classical GFs are prone to numerical errors since they consist of high-order polynomials. This problem is aggravated when several filters are applied in cascade, limiting the practical depth of GCNNs. To tackle this issue, we present the neighborhood graph filters (NGFs), a family of GFs that replaces the powers of the graph shift operator with $k$-hop neighborhood adjacency matrices. NGFs help to alleviate the numerical issues of traditional GFs, allow for the design of deeper GCNNs, and enhance the robustness to errors in the topology of the graph. To illustrate the advantage over traditional GFs in practical applications, we use NGFs in the design of deep neighborhood GCNNs to solve graph signal denoising and node classification problems over both synthetic and real-world data.      
### 40.Welsch Based Multiview Disparity Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2110.00803.pdf)
>  In this work, we explore disparity estimation from a high number of views. We experimentally identify occlusions as a key challenge for disparity estimation for applications with high numbers of views. In particular, occlusions can actually result in a degradation in accuracy as more views are added to a dataset. We propose the use of a Welsch loss function for the data term in a global variational framework for disparity estimation. We also propose a disciplined warping strategy and a progressive inclusion of views strategy that can reduce the need for coarse to fine strategies that discard high spatial frequency components from the early iterations. Experimental results demonstrate that the proposed approach produces superior and/or more robust estimates than other conventional variational approaches.      
### 41.Significance of Data Augmentation for Improving Cleft Lip and Palate Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.00797.pdf)
>  The automatic recognition of pathological speech, particularly from children with any articulatory impairment, is a challenging task due to various reasons. The lack of available domain specific data is one such obstacle that hinders its usage for different speech-based applications targeting pathological speakers. In line with the challenge, in this work, we investigate a few data augmentation techniques to simulate training data for improving the children speech recognition considering the case of cleft lip and palate (CLP) speech. The augmentation techniques explored in this study, include vocal tract length perturbation (VTLP), reverberation, speaking rate, pitch modification, and speech feature modification using cycle consistent adversarial networks (CycleGAN). Our study finds that the data augmentation methods significantly improve the CLP speech recognition performance, which is more evident when we used feature modification using CycleGAN, VTLP and reverberation based methods. More specifically, the results from this study show that our systems produce an improved phone error rate compared to the systems without data augmentation.      
### 42.Dynamic-Programming-Based Failure-Tolerant Control for Satellite with Thrusters in 6-DOF Motion  [ :arrow_down: ](https://arxiv.org/pdf/2110.00783.pdf)
>  In this paper, a dynamic-programming approach to the coupled translational and rotational control of thruster-driven spacecraft is studied. To reduce the complexity of the problem, dynamic-programming-based optimal policies are calculated using decoupled position and attitude dynamics with generalized forces and torques as controls. A quadratic-programming-based control allocation is then used to map the controls to actuator commands. To control the spacecraft in the event of thruster failure, both the dynamic programming policies and control allocation are reconfigured to cope with the losses in controls. The control allocation parameters are adjusted dynamically to ensure the satellite always approaches the target from the side with two operative thrusters to achieve a stable control. The effectiveness of the proposed dynamic programming control is compared with a Lyapunov-stable control method, which shows that the proposed method is more fuel-efficient in tracking the same path.      
### 43.End-to-End Complex-Valued Multidilated Convolutional Neural Network for Joint Acoustic Echo Cancellation and Noise Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2110.00745.pdf)
>  Echo and noise suppression is an integral part of a full-duplex communication system. Many recent acoustic echo cancellation (AEC) systems rely on a separate adaptive filtering module for linear echo suppression and a neural module for residual echo suppression. However, not only do adaptive filtering modules require convergence and remain susceptible to changes in acoustic environments, but this two-stage framework also often introduces unnecessary delays to the AEC system when neural modules are already capable of both linear and nonlinear echo suppression. In this paper, we exploit the offset-compensating ability of complex time-frequency masks and propose an end-to-end complex-valued neural network architecture. The building block of the proposed model is a pseudocomplex extension based on the densely-connected multidilated DenseNet (D3Net) building block, resulting in a very small network of only 354K parameters. The architecture utilized the multi-resolution nature of the D3Net building blocks to eliminate the need for pooling, allowing the network to extract features using large receptive fields without any loss of output resolution. We also propose a dual-mask technique for joint echo and noise suppression with simultaneous speech enhancement. Evaluation on both synthetic and real test sets demonstrated promising results across multiple energy-based metrics and perceptual proxies.      
### 44.Learning Region of Attraction for Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.00731.pdf)
>  Estimating the region of attraction (ROA) of general nonlinear autonomous systems remains a challenging problem and requires a case-by-case analysis. Leveraging the universal approximation property of neural networks, in this paper, we propose a counterexample-guided method to estimate the ROA of general nonlinear dynamical systems provided that they can be approximated by piecewise linear neural networks and that the approximation error can be bounded. Specifically, our method searches for robust Lyapunov functions using counterexamples, i.e., the states at which the Lyapunov conditions fail. We generate the counterexamples using Mixed-Integer Quadratic Programming. Our method is guaranteed to find a robust Lyapunov function in the parameterized function class, if exists, after collecting a finite number of counterexamples. We illustrate our method through numerical examples.      
### 45.Implementation of MPPT Technique of Solar Module with Supervised Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.00728.pdf)
>  In this paper, we proposed a method using supervised ML in solar PV system for MPPT analysis. For this purpose, an overall schematic diagram of a PV system is designed and simulated to create a dataset in MATLAB/ Simulink. Thus, by analyzing the output characteristics of a solar cell, an improved MPPT algorithm on the basis of neural network (NN) method is put forward to track the maximum power point (MPP) of solar cell modules. To perform the task, Bayesian Regularization method was chosen as the training algorithm as it works best even for smaller data supporting the wide range of the train data set. The theoretical results show that the improved NN MPPT algorithm has higher efficiency compared with the Perturb and Observe method in the same environment, and the PV system can keep working at MPP without oscillation and probability of any kind of misjudgment. So it can not only reduce misjudgment, but also avoid power loss around the MPP. Moreover, we implemented the algorithm in a hardware set-up and verified the theoretical result comparing it with the empirical data.      
### 46.Joint Estimation of System Inertia and Load Relief  [ :arrow_down: ](https://arxiv.org/pdf/2110.00699.pdf)
>  Modern power systems with high share of renewable generation are at the risk of rapid changes in frequency and inertia resulting from contingencies. The importance of an accurate assessment of system and load relief, as well as frequency changes in the critical timescales is more pronounced in these power systems. This knowledge serves as an insight which will guide the solutions required for enhanced security and resilience. A novel procedure for simultaneously assessing system inertia and load relief using a closed-form system frequency response (SFR) model to fit measured disturbance data is presented. Results of applying the proposed approach on generator contingencies in the South West Interconnected System (SWIS) in Western Australia demonstrate the validity of the method and indicate that it can overcome some of the limitations observed in conventional inertia estimation methods based on the linearised swing equation, such as the sliding window and polynomial fit methods.      
### 47.Multi-view SA-LA Net: A framework for simultaneous segmentation of RV on multi-view cardiac MR Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.00682.pdf)
>  We proposed a multi-view SA-LA model for simultaneous segmentation of RV on the short-axis (SA) and long-axis (LA) cardiac MR images. The multi-view SA-LA model is a multi-encoder, multi-decoder U-Net architecture based on the U-Net model. One encoder-decoder pair segments the RV on SA images and the other pair on LA images. Multi-view SA-LA model assembles an extremely rich set of synergistic features, at the root of the encoder branch, by combining feature maps learned from matched SA and LA cardiac MR images. Segmentation performance is further enhanced by: (1) incorporating spatial context of LV as a prior and (2) performing deep supervision in the last three layers of the decoder branch. Multi-view SA-LA model was extensively evaluated on the MICCAI 2021 Multi- Disease, Multi-View, and Multi- Centre RV Segmentation Challenge dataset (M&amp;Ms-2021). M&amp;Ms-2021 dataset consists of multi-phase, multi-view cardiac MR images of 360 subjects acquired at four clinical centers with three different vendors. On the challenge cohort (160 subjects), the proposed multi-view SA-LA model achieved a Dice Score of 91% and Hausdorff distance of 11.2 mm on short-axis images and a Dice Score of 89.6% and Hausdorff distance of 8.1 mm on long-axis images. Moreover, multi-view SA-LA model exhibited strong generalization to unseen RV related pathologies including Dilated Right Ventricle (DSC: SA 91.41%, LA 89.63%) and Tricuspidal Regurgitation (DSC: SA 91.40%, LA 90.40%) with low variance (std_DSC: SA &lt;5%, LA&lt;6%).      
### 48.Speech Technology for Everyone: Automatic Speech Recognition for Non-Native English with Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.00678.pdf)
>  To address the performance gap of English ASR models on L2 English speakers, we evaluate fine-tuning of pretrained wav2vec 2.0 models (Baevski et al., 2020; Xu et al., 2021) on L2-ARCTIC, a non-native English speech corpus (Zhao et al., 2018) under different training settings. We compare \textbf{(a)} models trained with a combination of diverse accents to ones trained with only specific accents and \textbf{(b)} results from different single-accent models. Our experiments demonstrate the promise of developing ASR models for non-native English speakers, even with small amounts of L2 training data and even without a language model. Our models also excel in the zero-shot setting where we train on multiple L2 datasets and test on a blind L2 test set.      
### 49.Data-Driven Detection and Identification of IoT-Enabled Load-Altering Attacks in Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2110.00667.pdf)
>  Advances in edge computing are powering the development and deployment of Internet of Things (IoT) systems in an effort to provide advanced services and resource efficiency. However, large-scale IoT-based load-altering attacks (LAAs) can have a serious impact on power grid operations such as destabilizing the grid's control loops. Timely detection and identification of any compromised nodes is important to minimize the adverse effects of these attacks on power grid operations. In this work, we present two data-driven algorithms to detect and identify compromised nodes and the attack parameters of the LAAs. The first, based on the Sparse Identification of Nonlinear Dynamics (SINDy) approach, adopts a sparse regression framework to identify attack parameters that best describes the observed dynamics. The second method, based on physics-informed neural networks (PINN), adopts deep neural networks to infer the attack parameters from the measurements. Both methods are presented utilizing edge computing for deployment over decentralized architectures. Extensive simulations performed on IEEE bus systems show that the proposed algorithms outperform existing approaches, such as those based on unscented Kalman filter, especially in systems that exhibit fast dynamics and are effective in detecting and identifying locations of attack in a timely manner.      
### 50.Online Distribution System State Estimation via Stochastic Gradient Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2110.00665.pdf)
>  Distribution network operation is becoming more challenging because of the growing integration of intermittent and volatile distributed energy resources (DERs). This motivates the development of new distribution system state estimation (DSSE) paradigms that can operate at fast timescale based on real-time data stream of asynchronous measurements enabled by modern information and communications technology. To solve the real-time DSSE with asynchronous measurements effectively and accurately, this paper formulates a weighted least squares DSSE problem and proposes an online stochastic gradient algorithm to solve it. The performance of the proposed scheme is analytically guaranteed and is numerically corroborated with realistic data on IEEE-123 bus feeder.      
### 51.MAP-CSI: Single-site Map-Assisted Localization Using Massive MIMO CSI  [ :arrow_down: ](https://arxiv.org/pdf/2110.00654.pdf)
>  This paper presents a new map-assisted localization approach utilizing Chanel State Information (CSI) in Massive Multiple-Input Multiple-Output (MIMO) systems. Map-assisted localization is an environment-aware approach in which the communication system has information regarding the surrounding environment. By combining radio frequency ray tracing parameters of the multipath components (MPC) with the environment map, it is possible to accomplish localization. Unfortunately, in real-world scenarios, ray tracing parameters are typically not explicitly available. Thus, additional complexity is added at a base station to obtain this information. On the other hand, CSI is a common communication parameter, usually estimated for any communication channel. In this work, we leverage the already available CSI data to propose a novel map-assisted CSI localization approach, referred to as MAP-CSI. We show that Angle-of-Departure (AoD) and Time-of-Arrival (ToA) can be extracted from CSI and then be used in combination with the environment map to localize the user. We perform simulations on a public MIMO dataset and show that our method works for both line-of-sight (LOS) and non-line-of-sight (NLOS) scenarios. We compare our method to the state-of-the-art (SoA) method that uses the ray tracing data. Using MAP-CSI, we accomplish an average localization error of 1.8 m in LOS and 2.8 m in mixed (combination of LOS and NLOS samples) scenarios. On the other hand, SoA ray tracing has an average error of 1.0 m and 2.2 m, respectively, but requires explicit AoD and ToA information to perform the localization task.      
### 52.The Proportional Integral Notch and Coleman Blade Effective Wind Speed Estimators and Their Similarities  [ :arrow_down: ](https://arxiv.org/pdf/2110.00639.pdf)
>  The estimation of the rotor effective wind speed is used in modern wind turbines to provide advanced power and load control capabilities. However, with the ever increasing rotor sizes, the wind field over the rotor surface shows a higher degree of spatial variation. A single effective wind speed estimation therefore limits the attainable levels of load mitigation, and the estimation of the Blade Effective Wind Speed (BEWS) might present opportunities for improved load control. This letter introduces two novel BEWS estimator approaches: A Proportional Integral Notch (PIN) estimator based on individual blade load measurements, and a Coleman estimator targeting the estimation in the non-rotating frame. Given the seeming disparities between these two estimators, the objective of this letter is to analyze the similarities between the approaches. It is shown that the PIN estimator, which is equivalent to the diagonal form of the Coleman estimator, is a simple but effective method to estimate the BEWS. The Coleman estimator, which takes the coupling effects between individual blades into account, shows a more well behaved transient response than the PIN estimator.      
### 53.Terminal Adaptive Guidance for Autonomous Hypersonic Strike Weapons via Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.00634.pdf)
>  An adaptive guidance system suitable for the terminal phase trajectory of a hypersonic strike weapon is optimized using reinforcement meta learning. The guidance system maps observations directly to commanded bank angle, angle of attack, and sideslip angle rates. Importantly, the observations are directly measurable from radar seeker outputs with minimal processing. The optimization framework implements a shaping reward that minimizes the line of sight rotation rate, with a terminal reward given if the agent satisfies path constraints and meets terminal accuracy and speed criteria. We show that the guidance system can adapt to off-nominal flight conditions including perturbation of aerodynamic coefficient parameters, actuator failure scenarios, sensor scale factor errors, and actuator lag, while satisfying heating rate, dynamic pressure, and load path constraints, as well as a minimum impact speed constraint. We demonstrate precision strike capability against a maneuvering ground target and the ability to divert to a new target, the latter being important to maximize strike effectiveness for a group of hypersonic strike weapons. Moreover, we demonstrate a threat evasion strategy against interceptors with limited midcourse correction capability, where the hypersonic strike weapon implements multiple diverts to alternate targets, with the last divert to the actual target. Finally, we include preliminary results for an integrated guidance and control system in a six degrees-of-freedom environment.      
### 54.Subsystem decomposition and state estimation of nonlinear processes with implicit time-scale multiplicity  [ :arrow_down: ](https://arxiv.org/pdf/2110.00618.pdf)
>  In this work, we propose a subsystem decomposition approach and a distributed estimation scheme for a class of implicit two-time-scale nonlinear systems. Taking the advantage of the two-time-scale separation, these processes are decomposed into smaller subsystems such as fast subsystem and slow subsystem. In the proposed method, an approach, composite solution, combines the approximate solutions obtained from both fast and slow subsystems. Based on the fast and slow subsystems, a distributed state estimation scheme is proposed to handle the implicit time-scale multiplicity. In the proposed design, an extended Kalman filter (EKF) is designed for the fast subsystem and a moving horizon estimator (MHE) is designed for the slow subsystem. There is a communication between the estimators: the slow subsystem is only required to send information to the fast subsystem one-directionally. The fast subsystem estimator does not send out any information. The estimators use different sampling of the state measurements, i.e., fast sampling of the fast state variables is considered in the fast EKF and slow sampling of the slow state variables is considered in the slow MHE. Extensive simulations based on a chemical process are performed to illustrate the effectiveness and applicability of the proposed subsystem decomposition and composite state estimation architecture.      
### 55.Wideband Signal Localization with Spectral Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.00583.pdf)
>  Signal localization is a spectrum sensing problem that jointly detects the presence of a signal and estimates a center frequency and bandwidth. This is a step beyond most spectrum sensing work which estimates "present" or "not present" detections for either a single channel or fixed sized channels. We define the signal localization task, present the metrics of precision and recall, and establish baselines for traditional energy detection on this task. We introduce a new dataset that is useful for training neural networks to perform this task and show a training framework to train signal detectors to achieve the task and present precision and recall curves over SNR. This neural network based approach shows an 8 dB improvement in recall over the traditional energy detection approach with minor improvements in precision.      
### 56.Sensitivity Study of Fiducial-Aided Navigation of Unmanned Aerial Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2110.01596.pdf)
>  The possible applications and benefits of autonomous Unmanned Aerial Vehicle (UAV) use in urban areas are gaining considerable attention. Before these possibilities can be realized, it is essential that UAVs be able to navigate reliably and precisely in urban environments. The most common means of determining the location of a UAV is to utilize position measurements from Global Navigation Satellite Systems (GNSS). In urban environments, however, GNSS measurements are significantly degraded due to occlusions and multipath. This research analyzes the use of camera Line-of-Sight (LOS) measurements to self-describing fiducials as a replacement for conventional GNSS measurements. An extended Kalman filter (EKF) is developed and validated for the purpose of combining continuous measurements from an Inertial Measurement Unit (IMU) with the discrete LOS measurements to accurately estimate the states of a UAV. The sensitivity of the estimation error covariance to various system parameters is assessed, including IMU grade, fiducial placement, vehicle altitude, and image processing frequency.      
### 57.Factorized Neural Transducer for Efficient Language Model Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2110.01500.pdf)
>  In recent years, end-to-end (E2E) based automatic speech recognition (ASR) systems have achieved great success due to their simplicity and promising performance. Neural Transducer based models are increasingly popular in streaming E2E based ASR systems and have been reported to outperform the traditional hybrid system in some scenarios. However, the joint optimization of acoustic model, lexicon and language model in neural Transducer also brings about challenges to utilize pure text for language model adaptation. This drawback might prevent their potential applications in practice. In order to address this issue, in this paper, we propose a novel model, factorized neural Transducer, by factorizing the blank and vocabulary prediction, and adopting a standalone language model for the vocabulary prediction. It is expected that this factorization can transfer the improvement of the standalone language model to the Transducer for speech recognition, which allows various language model adaptation techniques to be applied. The experiment results show that, in spite of minor performance degradation in the general test set introduced by the factorization, the proposed factorized neural Transducer presents 15% to 20% WER improvements when the out-of-domain text data is available for language model adaptation.      
### 58.Risk-Aware Learning for Scalable Voltage Optimization in Distribution Grids  [ :arrow_down: ](https://arxiv.org/pdf/2110.01490.pdf)
>  Real-time coordination of distributed energy resources (DERs) is crucial for regulating the voltage profile in distribution grids. By capitalizing on a scalable neural network (NN) architecture, machine learning tools can attain decentralized DER decisions by minimizing the average loss of prediction. This paper aims to improve these learning-enabled approaches by accounting for the potential risks associated with reactive power prediction and voltage deviation. Specifically, we advocate to measure such risks using the conditional value-at-risk (CVaR) loss based on the worst-case samples only, which could lead to the learning efficiency issue. To tackle this issue, we propose to accelerate the training process under the CVaR loss objective by selecting the mini-batches that are more likely to contain the worst-case samples of interest. Numerical tests using real-world data on the IEEE 123-bus test case have demonstrated the computation and safety improvements of the proposed risk-aware learning algorithm for decentralized DER decision making in distribution systems.      
### 59.Planning 5G Networks for Rural Fixed Wireless Access  [ :arrow_down: ](https://arxiv.org/pdf/2110.01456.pdf)
>  We study the planning of a rural 5G multi-user massive MIMO fixed wireless access system to offer fixed broadband service to homes. Specifically, we aim to determine the user limit, i.e., the maximum number of homes that can simultaneously receive target minimum bit rates (MBRs) on the downlink (DL) and on the uplink (UL) given a set of network resources and a cell radius. To compute that limit, we must understand how resources should be shared between the DL and UL and how user and stream selection, precoding and combining, and power distribution should be performed. We use block diagonalization and propose a static grouping strategy that organizes homes into fixed groups (of possibly different sizes) in the DL and UL; then we develop a simple approach to compute the user limit that we validate numerically. We study the impact of group size and show that smaller groups yield larger user limits in a 3.5~GHz band. We show how the user limit at different cell radii is impacted by the system bandwidth, the number of antennas at the BS and homes, the BS power, and the DL and UL MBRs. Lastly, we offer insights into how the network could be operated.      
### 60.Extended dynamic mode decomposition with dictionary learning using neural ordinary differential equations  [ :arrow_down: ](https://arxiv.org/pdf/2110.01450.pdf)
>  Nonlinear phenomena can be analyzed via linear techniques using operator-theoretic approaches. Data-driven method called the extended dynamic mode decomposition (EDMD) and its variants, which approximate the Koopman operator associated with the nonlinear phenomena, have been rapidly developing by incorporating machine learning methods. Neural ordinary differential equations (NODEs), which are a neural network equipped with a continuum of layers, and have high parameter and memory efficiencies, have been proposed. In this paper, we propose an algorithm to perform EDMD using NODEs. NODEs are used to find a parameter-efficient dictionary which provides a good finite-dimensional approximation of the Koopman operator. We show the superiority of the parameter efficiency of the proposed method through numerical experiments.      
### 61.Building a Noisy Audio Dataset to Evaluate Machine Learning Approaches for Automatic Speech Recognition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.01425.pdf)
>  Automatic speech recognition systems are part of people's daily lives, embedded in personal assistants and mobile phones, helping as a facilitator for human-machine interaction while allowing access to information in a practically intuitive way. Such systems are usually implemented using machine learning techniques, especially with deep neural networks. Even with its high performance in the task of transcribing text from speech, few works address the issue of its recognition in noisy environments and, usually, the datasets used do not contain noisy audio examples, while only mitigating this issue using data augmentation techniques. This work aims to present the process of building a dataset of noisy audios, in a specific case of degenerated audios due to interference, commonly present in radio transmissions. Additionally, we present initial results of a classifier that uses such data for evaluation, indicating the benefits of using this dataset in the recognizer's training process. Such recognizer achieves an average result of 0.4116 in terms of character error rate in the noisy set (SNR = 30).      
### 62.Neural Network Verification in Control  [ :arrow_down: ](https://arxiv.org/pdf/2110.01388.pdf)
>  Learning-based methods could provide solutions to many of the long-standing challenges in control. However, the neural networks (NNs) commonly used in modern learning approaches present substantial challenges for analyzing the resulting control systems' safety properties. Fortunately, a new body of literature could provide tractable methods for analysis and verification of these high dimensional, highly nonlinear representations. This tutorial first introduces and unifies recent techniques (many of which originated in the computer vision and machine learning communities) for verifying robustness properties of NNs. The techniques are then extended to provide formal guarantees of neural feedback loops (e.g., closed-loop system with NN control policy). The provided tools are shown to enable closed-loop reachability analysis and robust deep reinforcement learning.      
### 63.Audio-Visual Evaluation of Oratory Skills  [ :arrow_down: ](https://arxiv.org/pdf/2110.01367.pdf)
>  What makes a talk successful? Is it the content or the presentation? We try to estimate the contribution of the speaker's oratory skills to the talk's success, while ignoring the content of the talk. By oratory skills we refer to facial expressions, motions and gestures, as well as the vocal features. We use TED Talks as our dataset, and measure the success of each talk by its view count. Using this dataset we train a neural network to assess the oratory skills in a talk through three factors: body pose, facial expressions, and acoustic features. <br>Most previous work on automatic evaluation of oratory skills uses hand-crafted expert annotations for both the quality of the talk and for the identification of predefined actions. Unlike prior art, we measure the quality to be equivalent to the view count of the talk as counted by TED, and allow the network to automatically learn the actions, expressions, and sounds that are relevant to the success of a talk. We find that oratory skills alone contribute substantially to the chances of a talk being successful.      
### 64.Towards Time-Optimal Tunnel-Following for Quadrotors  [ :arrow_down: ](https://arxiv.org/pdf/2110.01351.pdf)
>  Minimum-time navigation within constrained and dynamic environments is of special relevance in robotics. Seeking time-optimality, while guaranteeing the integrity of time-varying spatial bounds, is an appealing trade-off for agile vehicles, such as quadrotors. State of the art approaches, either assume bounds to be static and generate time-optimal trajectories offline, or compromise time-optimality for constraint satisfaction. Leveraging nonlinear model predictive control and a path parametric reformulation of the quadrotor model, we present a real-time control that approximates time-optimal behavior and remains within dynamic corridors. The efficacy of the approach is evaluated according to simulated results, showing itself capable of performing extremely aggressive maneuvers as well as stop-and-go and backward motions.      
### 65.Automated Aerial Animal Detection When Spatial Resolution Conditions Are Varied  [ :arrow_down: ](https://arxiv.org/pdf/2110.01329.pdf)
>  Knowing where livestock are located enables optimized management and mustering. However, Australian farms are large meaning that many of Australia's livestock are unmonitored which impacts farm profit, animal welfare and the environment. Effective animal localisation and counting by analysing satellite imagery overcomes this management hurdle however, high resolution satellite imagery is expensive. Thus, to minimise cost the lowest spatial resolution data that enables accurate livestock detection should be selected. In our work, we determine the association between object detector performance and spatial degradation for cattle, sheep and dogs. Accurate ground truth was established using high resolution drone images which were then downsampled to various ground sample distances (GSDs). Both circular and cassegrain aperture optics were simulated to generate point spread functions (PSFs) corresponding to various optical qualities. By simulating the PSF, rather than approximating it as a Gaussian, the images were accurately degraded to match the spatial resolution and blurring structure of satellite imagery. <br>Two existing datasets were combined and used to train and test a YoloV5 object detection network. Detector performance was found to drop steeply around a GSD of 0.5m/px and was associated with PSF matrix structure within this GSD region. Detector mAP performance fell by 52 percent when a cassegrain, rather than circular, aperture was used at a 0.5m/px GSD. Overall blurring magnitude also had a small impact when matched to GSD, as did the internal network resolution. Our results here inform the selection of remote sensing data requirements for animal detection tasks, allowing farmers and ecologists to use more accessible medium resolution imagery with confidence.      
### 66.A Survey on Channel Estimation and Practical Passive Beamforming Design for Intelligent Reflecting Surface Aided Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2110.01292.pdf)
>  Intelligent reflecting surface (IRS) has emerged as a key enabling technology to realize smart and reconfigurable radio environment for wireless communications, by digitally controlling the signal reflection via a large number of passive reflecting elements in real time. Different from conventional wireless communication techniques that only adapt to but have no or limited control over dynamic wireless channels, IRS provides a new and cost-effective means to combat the wireless channel impair-ments in a proactive manner. However, despite its great potential, IRS faces new and unique challenges in its efficient integration into wireless communication systems, especially its channel estimation and passive beamforming design under various practical hardware constraints. In this paper, we provide a comprehensive survey on the up-to-date research in IRS-aided wireless communications, with an emphasis on the promising solutions to tackle practical design issues. Furthermore, we discuss new and emerging IRS architectures and applications as well as their practical design problems to motivate future research.      
### 67.Optimal Placement of Roadside Infrastructure Sensors towards Safer Autonomous Vehicle Deployments  [ :arrow_down: ](https://arxiv.org/pdf/2110.01251.pdf)
>  Vehicles with driving automation are increasingly being developed for deployment across the world. However, the onboard sensing and perception capabilities of such automated or autonomous vehicles (AV) may not be sufficient to ensure safety under all scenarios and contexts. Infrastructure-augmented environment perception using roadside infrastructure sensors can be considered as an effective solution, at least for selected regions of interest such as urban road intersections or curved roads that present occlusions to the AV. However, they incur significant costs for procurement, installation and maintenance. Therefore these sensors must be placed strategically and optimally to yield maximum benefits in terms of the overall safety of road users. In this paper, we propose a novel methodology towards obtaining an optimal placement of V2X (Vehicle-to-everything) infrastructure sensors, which is particularly attractive to urban AV deployments, with various considerations including costs, coverage and redundancy. We combine the latest advances made in raycasting and linear optimization literature to deliver a tool for urban city planners, traffic analysis and AV deployment operators. Through experimental evaluation in representative environments, we prove the benefits and practicality of our approach.      
### 68.Audio Captioning Using Sound Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.01210.pdf)
>  This technical report proposes an audio captioning system for DCASE 2021 Task 6 audio captioning challenge. Our proposed model is based on an encoder-decoder architecture with bi-directional Gated Recurrent Units (BiGRU) using pretrained audio features and sound event detection. A pretrained neural network (PANN) is used to extract audio features and Word2Vec is selected with the aim of extracting word embeddings from the audio captions. To create semantically meaningful captions, we extract sound events from the audio clips and feed the encoder-decoder architecture with sound events in addition to PANNs features. Our experiments on the Clotho dataset show that our proposed method significantly achieves better results than the challenge baseline model across all evaluation metrics.      
### 69.Enhance Images as You Like with Unpaired Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.01161.pdf)
>  Low-light image enhancement exhibits an ill-posed nature, as a given image may have many enhanced versions, yet recent studies focus on building a deterministic mapping from input to an enhanced version. In contrast, we propose a lightweight one-path conditional generative adversarial network (cGAN) to learn a one-to-many relation from low-light to normal-light image space, given only sets of low- and normal-light training images without any correspondence. By formulating this ill-posed problem as a modulation code learning task, our network learns to generate a collection of enhanced images from a given input conditioned on various reference images. Therefore our inference model easily adapts to various user preferences, provided with a few favorable photos from each user. Our model achieves competitive visual and quantitative results on par with fully supervised methods on both noisy and clean datasets, while being 6 to 10 times lighter than state-of-the-art generative adversarial networks (GANs) approaches.      
### 70.On the Interplay Between Sparsity, Naturalness, Intelligibility, and Prosody in Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.01147.pdf)
>  Are end-to-end text-to-speech (TTS) models over-parametrized? To what extent can these models be pruned, and what happens to their synthesis capabilities? This work serves as a starting point to explore pruning both spectrogram prediction networks and vocoders. We thoroughly investigate the tradeoffs between sparstiy and its subsequent effects on synthetic speech. Additionally, we explored several aspects of TTS pruning: amount of finetuning data versus sparsity, TTS-Augmentation to utilize unspoken text, and combining knowledge distillation and pruning. Our findings suggest that not only are end-to-end TTS models highly prunable, but also, perhaps surprisingly, pruned TTS models can produce synthetic speech with equal or higher naturalness and intelligibility, with similar prosody. All of our experiments are conducted on publicly available models, and findings in this work are backed by large-scale subjective tests and objective measures. Code and 200 pruned models are made available to facilitate future research on efficiency in TTS.      
### 71.Safe Control with Neural Network Dynamic Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.01110.pdf)
>  Safety is critical in autonomous robotic systems. A safe control law ensures forward invariance of a safe set (a subset in the state space). It has been extensively studied regarding how to derive a safe control law with a control-affine analytical dynamic model. However, in complex environments and tasks, it is challenging and time-consuming to obtain a principled analytical model of the system. In these situations, data-driven learning is extensively used and the learned models are encoded in neural networks. How to formally derive a safe control law with Neural Network Dynamic Models (NNDM) remains unclear due to the lack of computationally tractable methods to deal with these black-box functions. In fact, even finding the control that minimizes an objective for NNDM without any safety constraint is still challenging. In this work, we propose MIND-SIS (Mixed Integer for Neural network Dynamic model with Safety Index Synthesis), the first method to derive safe control laws for NNDM. The method includes two parts: 1) SIS: an algorithm for the offline synthesis of the safety index (also called as barrier function), which uses evolutionary methods and 2) MIND: an algorithm for online computation of the optimal and safe control signal, which solves a constrained optimization using a computationally efficient encoding of neural networks. It has been theoretically proved that MIND-SIS guarantees forward invariance and finite convergence. And it has been numerically validated that MIND-SIS achieves safe and optimal control of NNDM. From our experiments, the optimality gap is less than $10^{-8}$, and the safety constraint violation is $0$.      
### 72.Parallel Actors and Learners: A Framework for Generating Scalable RL Implementations  [ :arrow_down: ](https://arxiv.org/pdf/2110.01101.pdf)
>  Reinforcement Learning (RL) has achieved significant success in application domains such as robotics, games, health care and others. However, training RL agents is very time consuming. Current implementations exhibit poor performance due to challenges such as irregular memory accesses and synchronization overheads. <br>In this work, we propose a framework for generating scalable reinforcement learning implementations on multicore systems. Replay Buffer is a key component of RL algorithms which facilitates storage of samples obtained from environmental interactions and their sampling for the learning process. We define a new data structure for prioritized replay buffer based on $K$-ary sum tree that supports asynchronous parallel insertions, sampling, and priority updates. To address the challenge of irregular memory accesses, we propose a novel data layout to store the nodes of the sum tree that reduces the number of cache misses. Additionally, we propose \textit{lazy writing} mechanism to reduce synchronization overheads of the replay buffer. Our framework employs parallel actors to concurrently collect data via environmental interactions, and parallel learners to perform stochastic gradient descent using the collected data. Our framework supports a wide range of reinforcement learning algorithms including DQN, DDPG, TD3, SAC, etc. We demonstrate the effectiveness of our framework in accelerating RL algorithms by performing experiments on CPU + GPU platform using OpenAI benchmarks. Our results show that the performance of our approach scales linearly with the number of cores. Compared with the baseline approaches, we reduce the convergence time by 3.1x$\sim$10.8x. By plugging our replay buffer implementation into existing open source reinforcement learning frameworks, we achieve 1.1x$\sim$2.1x speedup for sequential executions.      
### 73.A Unified 3D Beam Training and Tracking Procedure for Terahertz Communication  [ :arrow_down: ](https://arxiv.org/pdf/2110.01066.pdf)
>  Terahertz (THz) communication is considered as an attractive way to overcome the bandwidth bottleneck and satisfy the ever-increasing capacity demand in the future. Due to the high directivity and propagation loss of THz waves, a massive MIMO system using beamforming is envisioned as a promising technology in THz communication to realize high-gain and directional transmission. However, pilots, which are the fundamentals for many beamforming schemes, are challenging to be accurately detected in the THz band owing to the severe propagation loss. In this paper, a unified 3D beam training and tracking procedure is proposed to effectively realize the beamforming in THz communications, by considering the line-of-sight (LoS) propagation. In particular, a novel quadruple-uniform planar array (QUPA) architecture is analyzed to enlarge the signal coverage, increase the beam gain, and reduce the beam squint loss. Then, a new 3D grid-based (GB) beam training is developed with low complexity, including the design of the 3D codebook and training protocol. Finally, a simple yet effective grid-based hybrid (GBH) beam tracking is investigated to support THz beamforming in an efficient manner. The communication framework based on this procedure can dynamically trigger beam training/tracking depending on the real-time quality of service. Numerical results are presented to demonstrate the superiority of our proposed beam training and tracking over the benchmark methods.      
### 74.A QLP Decomposition via Randomization  [ :arrow_down: ](https://arxiv.org/pdf/2110.01011.pdf)
>  This paper is concerned with full matrix decomposition of matrices, primarily low-rank matrices. It develops a QLP-like decomposition algorithm such that when operating on a matrix A, gives A = QLP^T , where Q and P are orthonormal, and L is lower-triangular. The proposed algorithm, termed Rand-QLP, utilizes randomization and the unpivoted QR decomposition. This in turn enables Rand-QLP to leverage modern computational architectures, thus addressing a serious bottleneck associated with classical and most recent matrix decomposition algorithms. We derive several error bounds for Rand- QLP: bounds for the first k approximate singular values as well as the trailing block of the middle factor, which show that Rand-QLP is rank-revealing; and bounds for the distance between approximate subspaces and the exact ones for all four fundamental subspaces of a given matrix. We assess the speed and approximation quality of Rand-QLP on synthetic and real matrices with different dimensions and characteristics, and compare our results with those of multiple existing algorithms.      
### 75.Enriching Ontology with Temporal Commonsense for Low-Resource Audio Tagging  [ :arrow_down: ](https://arxiv.org/pdf/2110.01009.pdf)
>  Audio tagging aims at predicting sound events occurred in a recording. Traditional models require enormous laborious annotations, otherwise performance degeneration will be the norm. Therefore, we investigate robust audio tagging models in low-resource scenarios with the enhancement of knowledge graphs. Besides existing ontological knowledge, we further propose a semi-automatic approach that can construct temporal knowledge graphs on diverse domain-specific label sets. Moreover, we leverage a variant of relation-aware graph neural network, D-GCN, to combine the strength of the two knowledge types. Experiments on AudioSet and SONYC urban sound tagging datasets suggest the effectiveness of the introduced temporal knowledge, and the advantage of the combined KGs with D-GCN over single knowledge source.      
### 76.Multimodal Fusion Based Attentive Networks for Sequential Music Recommendation  [ :arrow_down: ](https://arxiv.org/pdf/2110.01001.pdf)
>  Music has the power to evoke intense emotional experiences and regulate the mood of an individual. With the advent of online streaming services, research in music recommendation services has seen tremendous progress. Modern methods leveraging the listening histories of users for session-based song recommendations have overlooked the significance of features extracted from lyrics and acoustic content. We address the task of song prediction through multiple modalities, including tags, lyrics, and acoustic content. In this paper, we propose a novel deep learning approach by refining Attentive Neural Networks using representations derived via a Transformer model for lyrics and Variational Autoencoder for acoustic features. Our model achieves significant improvement in performance over existing state-of-the-art models using lyrical and acoustic features alone. Furthermore, we conduct a study to investigate the impact of users' psychological health on our model's performance.      
### 77.Graph Representation Learning for Spatial Image Steganalysis  [ :arrow_down: ](https://arxiv.org/pdf/2110.00957.pdf)
>  In this paper, we introduce a graph representation learning architecture for spatial image steganalysis, which is motivated by the assumption that steganographic modifications unavoidably distort the statistical characteristics of the hidden graph features derived from cover images. In the detailed architecture, we translate each image to a graph, where nodes represent the patches of the image and edges indicate the local associations between the patches. Each node is associated with a feature vector determined from the corresponding patch by a shallow convolutional neural network (CNN) structure. By feeding the graph to an attention network, the discriminative features can be learned for efficient steganalysis. Experiments indicate that the reported architecture achieves a competitive performance compared to the benchmark CNN model, which has shown the potential of graph learning for steganalysis.      
### 78.PL-EESR: Perceptual Loss Based END-TO-END Robust Speaker Representation Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2110.00940.pdf)
>  Speech enhancement aims to improve the perceptual quality of the speech signal by suppression of the background noise. However, excessive suppression may lead to speech distortion and speaker information loss, which degrades the performance of speaker embedding extraction. To alleviate this problem, we propose an end-to-end deep learning framework, dubbed PL-EESR, for robust speaker representation extraction. This framework is optimized based on the feedback of the speaker identification task and the high-level perceptual deviation between the raw speech signal and its noisy version. We conducted speaker verification tasks in both noisy and clean environment respectively to evaluate our system. Compared to the baseline, our method shows better performance in both clean and noisy environments, which means our method can not only enhance the speaker relative information but also avoid adding distortions.      
### 79.Observer-based Control Barrier Functions for Safety Critical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.00923.pdf)
>  This paper considers the safety-critical control design problem with output measurements. An observer-based safety control framework that integrates the estimation error quantified observer and the control barrier function (CBF) approach is proposed. The function approximation technique is employed to approximate the uncertainties introduced by the state estimation error, and an adaptive CBF approach is proposed to design the safe controller which is obtained by solving a convex quadratic program (QP). Theoretical results for CBFs with a relative degree 1 and a higher relative degree are given individually. The effectiveness of the proposed control approach is demonstrated by two numerical examples.      
### 80.Does deep learning model calibration improve performance in class-imbalanced medical image classification?  [ :arrow_down: ](https://arxiv.org/pdf/2110.00918.pdf)
>  In medical image classification tasks, it is common to find that the number of normal samples far exceeds the number of abnormal samples. In such class-imbalanced situations, reliable training of deep neural networks continues to be a major challenge. Under these circumstances, the predicted class confidence may be biased toward the majority class. Calibration has been suggested to alleviate some of these effects. However, there is insufficient analysis explaining when and whether calibrating a model would be beneficial in improving performance. In this study, we perform a systematic analysis of the effect of model calibration on its performance on two medical image modalities, namely, chest X-rays (CXRs) and fundus images, using various deep learning classifier backbones. For this, we study the following variations: (i) the degree of imbalances in the dataset used for training; (ii) calibration methods; and, (iii) two classification thresholds, namely, default decision threshold of 0.5, and optimal threshold from precision-recall (PR) curves. Our results indicate that at the default operating threshold of 0.5, the performance achieved through calibration is significantly superior (p &lt; 0.05) to an uncalibrated model. However, at the PR-guided threshold, these gains were not significantly different (p &gt; 0.05). This finding holds for both image modalities and at varying degrees of imbalance.      
### 81.Control Barrier Function Meets Interval Analysis: Safety-Critical Control with Measurement and Actuation Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2110.00915.pdf)
>  This paper presents a framework for designing provably safe feedback controllers for sampled-data control affine systems with measurement and actuation uncertainties. Based on the interval Taylor model of nonlinear functions, a sampled-data control barrier function (CBF) condition is proposed which ensures the forward invariance of a safe set for sampled-data systems. Reachable set overapproximation and Lasserre's hierarchy of polynomial optimization are used for finding the margin term in the sampled-data CBF condition. Sufficient conditions for a safe controller in the presence of measurement and actuation uncertainties are proposed, for CBFs with relative degree 1 and higher relative degree individually. The effectiveness of the proposed method is illustrated by two numerical examples and an experimental example that implements the proposed controller on the Crazyflie quadcopter in real-time.      
### 82.AI based Algorithms of Path Planning, Navigation and Control for Mobile Ground Robots and UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2110.00910.pdf)
>  As the demands of autonomous mobile robots are increasing in recent years, the requirement of the path planning/navigation algorithm should not be content with the ability to reach the target without any collisions, but also should try to achieve possible optimal or suboptimal path from the initial position to the target according to the robot's constrains in practice. This report investigates path planning and control strategies for mobile robots with machine learning techniques, including ground mobile robots and flying UAVs. <br>In this report, the hybrid reactive collision-free navigation problem under an unknown static environment is investigated firstly. By combining both the reactive navigation and Q-learning method, we intend to keep the good characteristics of reactive navigation algorithm and Q-learning and overcome the shortcomings of only relying on one of them. The proposed method is then extended into 3D environments. The performance of the mentioned strategies are verified by extensive computer simulations, and good results are obtained. Furthermore, the more challenging dynamic environment situation is taken into our consideration. We tackled this problem by developing a new path planning method that utilizes the integrated environment representation and reinforcement learning. Our novel approach enables to find the optimal path to the target efficiently and avoid collisions in a cluttered environment with steady and moving obstacles. The performance of these methods is compared with other different aspects.      
### 83.Vision-aided Dynamic Quadrupedal Locomotion on Discrete Terrain using Motion Libraries  [ :arrow_down: ](https://arxiv.org/pdf/2110.00891.pdf)
>  In this paper, we present a framework rooted in control and planning that enables quadrupedal robots to traverse challenging terrains with discrete footholds using visual feedback. Navigating discrete terrain is challenging for quadrupeds because the motion of the robot can be aperiodic, highly dynamic, and blind for the hind legs of the robot. Additionally, the robot needs to reason over both the feasible footholds as well as robot velocity by speeding up and slowing down at different parts of the terrain. We build an offline library of periodic gaits which span two trotting steps on the robot, and switch between different motion primitives to achieve aperiodic motions of different step lengths on an A1 robot. The motion library is used to provide targets to a geometric model predictive controller which controls stance. To incorporate visual feedback, we use terrain mapping tools to build a local height map of the terrain around the robot using RGB and depth cameras, and extract feasible foothold locations around both the front and hind legs of the robot. Our experiments show a Unitree A1 robot navigating multiple unknown, challenging and discrete terrains in the real world.      
### 84.Appropriate transient thermal analysis of an absorber plate in flat-plate solar collectors from beginning to end operational conditions  [ :arrow_down: ](https://arxiv.org/pdf/2110.00837.pdf)
>  This work establishes a closed-form analysis for two-dimensional transient heat transfer in an absorber plate based on the thermal wave model when the collector starts to work. The method of separation of variables is employed to determine the exact thermal response during the starting of a solar collector. The thermal field is represented by 2-D thermal contours and 3-D surface plots to provide an accurate prediction compared to the 1-D analysis using the time-lag theory. An influence of Fourier number on the heat flow in the absorber plate is studied for different thermal relaxation times. The present analysis highlights that the magnitude of plate temperature depends significantly on the physical geometry. Differences in two models of heat propagation, viz. classical and thermal wave, in the absorber plate have an alteration in predicted collector performances. The present study also develops another design situation for heat transfer in the absorber plate when the collector shutdowns to the ambient state from its steady condition. Laplace Transform Method (LTM) in combination with the product solution method uses to determine the temperature with the initial condition represented as a steady case. Due to the lagging nature of thermal behavior, a significant difference between the classical and thermal wave models for the propagation of heat was observed, and also this study determines the exact time to be taken to reach the dead state for the complete shutdown of the collector.      
### 85.Communication Models for Reconfigurable Intelligent Surfaces: From Surface Electromagnetics to Wireless Networks Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2110.00833.pdf)
>  A reconfigurable intelligent surface (RIS) is a planar structure that is engineered to dynamically control the electromagnetic waves. In wireless communications, RISs have recently emerged as a promising technology for realizing programmable and reconfigurable wireless propagation environments through nearly passive signal transformations. With the aid of RISs, a wireless environment becomes part of the network design parameters that are subject to optimization. <br>In this tutorial paper, we focus our attention on communication models for RISs. First, we review the communication models that are most often employed in wireless communications and networks for analyzing and optimizing RISs, and elaborate on their advantages and limitations. Then, we concentrate on models for RISs that are based on inhomogeneous sheets of surface impedance, and offer a step-by-step tutorial on formulating electromagnetically-consistent analytical models for optimizing the surface impedance. The differences between local and global designs are discussed and analytically formulated in terms of surface power efficiency and reradiated power flux through the Poynting vector. Finally, with the aid of numerical results, we discuss how approximate global designs can be realized by using locally passive RISs with zero electrical resistance (i.e., inhomogeneous reactance boundaries with no local power amplification), even for large angles of reflection and at high power efficiency.      
### 86.Processing Phoneme Specific Segments for Cleft Lip and Palate Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2110.00794.pdf)
>  The cleft lip and palate (CLP) speech intelligibility is distorted due to the deformation in their articulatory system. For addressing the same, a few previous works perform phoneme specific modification in CLP speech. In CLP speech, both the articulation error and the nasalization distorts the intelligibility of a word. Consequently, modification of a specific phoneme may not always yield in enhanced entire word-level intelligibility. For such cases, it is important to identify and isolate the phoneme specific error based on the knowledge of acoustic events. Accordingly, the phoneme specific error modification algorithms can be exploited for transforming the specified errors and enhance the word-level intelligibility. Motivated by that, in this work, we combine some of salient phoneme specific enhancement approaches and demonstrate their effectiveness in improving the word-level intelligibility of CLP speech. The enhanced speech samples are evaluated using subjective and objective evaluation metrics.      
### 87.A Theoretical Overview of Neural Contraction Metrics for Learning-based Control with Guaranteed Stability  [ :arrow_down: ](https://arxiv.org/pdf/2110.00693.pdf)
>  This paper presents a theoretical overview of a Neural Contraction Metric (NCM): a neural network model of an optimal contraction metric and corresponding differential Lyapunov function, the existence of which is a necessary and sufficient condition for incremental exponential stability of non-autonomous nonlinear system trajectories. Its innovation lies in providing formal robustness guarantees for learning-based control frameworks, utilizing contraction theory as an analytical tool to study the nonlinear stability of learned systems via convex optimization. In particular, we rigorously show in this paper that, by regarding modeling errors of the learning schemes as external disturbances, the NCM control is capable of obtaining an explicit bound on the distance between a time-varying target trajectory and perturbed solution trajectories, which exponentially decreases with time even under the presence of deterministic and stochastic perturbation. These useful features permit simultaneous synthesis of a contraction metric and associated control law by a neural network, thereby enabling real-time computable and probably robust learning-based control for general control-affine nonlinear systems.      
### 88.Contraction Theory for Nonlinear Stability Analysis and Learning-based Control: A Tutorial Overview  [ :arrow_down: ](https://arxiv.org/pdf/2110.00675.pdf)
>  Contraction theory is an analytical tool to study differential dynamics of a non-autonomous (i.e., time-varying) nonlinear system under a contraction metric defined with a uniformly positive definite matrix, the existence of which results in a necessary and sufficient characterization of incremental exponential stability of multiple solution trajectories with respect to each other. By using a squared differential length as a Lyapunov-like function, its nonlinear stability analysis boils down to finding a suitable contraction metric that satisfies a stability condition expressed as a linear matrix inequality, indicating that many parallels can be drawn between well-known linear systems theory and contraction theory for nonlinear systems. Furthermore, contraction theory takes advantage of a superior robustness property of exponential stability used in conjunction with the comparison lemma. This yields much-needed safety and stability guarantees for neural network-based control and estimation schemes, without resorting to a more involved method of using uniform asymptotic stability for input-to-state stability. Such distinctive features permit systematic construction of a contraction metric via convex optimization, thereby obtaining an explicit exponential bound on the distance between a time-varying target trajectory and solution trajectories perturbed externally due to disturbances and learning errors. The objective of this paper is therefore to present a tutorial overview of contraction theory and its advantages in nonlinear stability analysis of deterministic and stochastic systems, with an emphasis on deriving formal robustness and stability guarantees for various learning-based and data-driven automatic control methods. In particular, we provide a detailed review of techniques for finding contraction metrics and associated control and estimation laws using deep neural networks.      
### 89.Online Obstructive Sleep Apnea Detection Based on Hybrid Machine Learning And Classifier Combination For Home-based Applications  [ :arrow_down: ](https://arxiv.org/pdf/2110.00660.pdf)
>  Automatic detection of obstructive sleep apnea (OSA) is in great demand. OSA is one of the most prevalent diseases of the current century and established comorbidity to Covid-19. OSA is characterized by complete or relative breathing pauses during sleep. According to medical observations, if OSA remained unrecognized and un-treated, it may lead to physical and mental complications. The gold standard of scoring OSA severity is the time-consuming and expensive method of polysomnography (PSG). The idea of online home-based surveillance of OSA is welcome. It serves as an effective way for spurred detection and reference of patients to sleep clinics. In addition, it can perform automatic control of the therapeutic/assistive devices. In this paper, several configurations for online OSA detection are proposed. The best configuration uses both ECG and SpO2 signals for feature extraction and MI analysis for feature reduction. Various methods of supervised machine learning are exploited for classification. Finally, to reach the best result, the most successful classifiers in sensitivity and specificity are combined in groups of three members with four different combination methods. The proposed method has advantages like limited use of biological signals, automatic detection, online working scheme, and uniform and acceptable performance (over 85%) in all the employed databases. These advantages have not been integrated in previous published methods.      
### 90.Multi-lane Cruising Using Hierarchical Planning and Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.00650.pdf)
>  Competent multi-lane cruising requires using lane changes and within-lane maneuvers to achieve good speed and maintain safety. This paper proposes a design for autonomous multi-lane cruising by combining a hierarchical reinforcement learning framework with a novel state-action space abstraction. While the proposed solution follows the classical hierarchy of behavior decision, motion planning and control, it introduces a key intermediate abstraction within the motion planner to discretize the state-action space according to high level behavioral decisions. We argue that this design allows principled modular extension of motion planning, in contrast to using either monolithic behavior cloning or a large set of hand-written rules. Moreover, we demonstrate that our state-action space abstraction allows transferring of the trained models without retraining from a simulated environment with virtually no dynamics to one with significantly more realistic dynamics. Together, these results suggest that our proposed hierarchical architecture is a promising way to allow reinforcement learning to be applied to complex multi-lane cruising in the real world.      
### 91.Motion Planning for Autonomous Vehicles in the Presence of Uncertainty Using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.00640.pdf)
>  Motion planning under uncertainty is one of the main challenges in developing autonomous driving vehicles. In this work, we focus on the uncertainty in sensing and perception, resulted from a limited field of view, occlusions, and sensing range. This problem is often tackled by considering hypothetical hidden objects in occluded areas or beyond the sensing range to guarantee passive safety. However, this may result in conservative planning and expensive computation, particularly when numerous hypothetical objects need to be considered. We propose a reinforcement learning (RL) based solution to manage uncertainty by optimizing for the worst case outcome. This approach is in contrast to traditional RL, where the agents try to maximize the average expected reward. The proposed approach is built on top of the Distributional RL with its policy optimization maximizing the stochastic outcomes' lower bound. This modification can be applied to a range of RL algorithms. As a proof-of-concept, the approach is applied to two different RL algorithms, Soft Actor-Critic and DQN. The approach is evaluated against two challenging scenarios of pedestrians crossing with occlusion and curved roads with a limited field of view. The algorithm is trained and evaluated using the SUMO traffic simulator. The proposed approach yields much better motion planning behavior compared to conventional RL algorithms and behaves comparably to humans driving style.      
### 92.Reconstructing group wavelet transform from feature maps with a reproducing kernel iteration  [ :arrow_down: ](https://arxiv.org/pdf/2110.00600.pdf)
>  In this paper we consider the problem of reconstructing an image that is downsampled in the space of its $SE(2)$ wavelet transform, which is motivated by classical models of simple cells receptive fields and feature preference maps in primary visual cortex. We prove that, whenever the problem is solvable, the reconstruction can be obtained by an elementary project and replace iterative scheme based on the reproducing kernel arising from the group structure, and show numerical results on real images.      
### 93.Emergency Vehicles Audio Detection and Localization in Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2109.14797.pdf)
>  Emergency vehicles in service have right-of-way over all other vehicles. Hence, all other vehicles are supposed to take proper actions to yield emergency vehicles with active sirens. As this task requires the cooperation between ears and eyes for human drivers, it also needs audio detection as a supplement to vision-based algorithms for fully autonomous driving vehicles. In urban driving scenarios, we need to know both the existence of emergency vehicles and their relative positions to us to decide the proper actions. We present a novel system from collecting the real-world siren data to the deployment of models using only two cost-efficient microphones. We are able to achieve promising performance for each task separately, especially within the crucial 10m to 50m distance range to react (the size of our ego vehicle is around 5m in length and 2m in width). The recall rate to determine the existence of sirens is 99.16% , the median and mean angle absolute error is 9.64 and 19.18 respectively, and the median and mean distance absolute error of 9.30m and 10.58m respectively within that range. We also benchmark various machine learning approaches that can determine the siren existence and sound source localization which includes direction and distance simultaneously within 50ms of latency.      
