# ArXiv eess --Fri, 29 Oct 2021
### 1.Photon Limited Non-Blind Deblurring Using Algorithm Unrolling  [ :arrow_down: ](https://arxiv.org/pdf/2110.15314.pdf)
>  Image deblurring in photon-limited conditions is ubiquitous in a variety of low-light applications such as photography, microscopy and astronomy. However, the presence of photon shot noise due to low-illumination and/or short exposure makes the deblurring task substantially more challenging than the conventional deblurring problems. In this paper we present an algorithm unrolling approach for the photon-limited deblurring problem by unrolling a Plug-and-Play algorithm for a fixed number of iterations. By introducing a three-operator splitting formation of the Plug-and-Play framework, we obtain a series of differentiable steps which allows the fixed iteration unrolled network to be trained end-to-end. The proposed algorithm demonstrates significantly better image recovery compared to existing state-of-the-art deblurring approaches. We also present a new photon-limited deblurring dataset for evaluating the performance of algorithms.      
### 2.Cooperative Deep $Q$-learning Framework for Environments Providing Image Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2110.15305.pdf)
>  In this paper, we address two key challenges in deep reinforcement learning setting, sample inefficiency and slow learning, with a dual NN-driven learning approach. In the proposed approach, we use two deep NNs with independent initialization to robustly approximate the action-value function in the presence of image inputs. In particular, we develop a temporal difference (TD) error-driven learning approach, where we introduce a set of linear transformations of the TD error to directly update the parameters of each layer in the deep NN. We demonstrate theoretically that the cost minimized by the error-driven learning (EDL) regime is an approximation of the empirical cost and the approximation error reduces as learning progresses, irrespective of the size of the network. Using simulation analysis, we show that the proposed methods enables faster learning and convergence and requires reduced buffer size (thereby increasing the sample efficiency).      
### 3.Quaternion Offset Linear Canonical Transform in One dimensional Setting  [ :arrow_down: ](https://arxiv.org/pdf/2110.15280.pdf)
>  In this paper, we introduce quaternion offset linear canonical transform of integrable and square integrable functions. Moreover, we show that the proposed transform satisfies all the respective properties like inversion formula, linearity, Moyals formula , product theorem and the convolution theorem      
### 4.SVM and ANN based Classification of EMG signals by using PCA and LDA  [ :arrow_down: ](https://arxiv.org/pdf/2110.15279.pdf)
>  In recent decades, biomedical signals have been used for communication in Human-Computer Interfaces (HCI) for medical applications; an instance of these signals are the myoelectric signals (MES), which are generated in the muscles of the human body as unidimensional patterns. Because of this, the methods and algorithms developed for pattern recognition in signals can be applied for their analyses once these signals have been sampled and turned into electromyographic (EMG) signals. Additionally, in recent years, many researchers have dedicated their efforts to studying prosthetic control utilizing EMG signal classification, that is, by logging a set of MES in a proper range of frequencies to classify the corresponding EMG signals. The feature classification can be carried out on the time domain or by using other domains such as the frequency domain (also known as the spectral domain), time scale, and time-frequency, amongst others. One of the main methods used for pattern recognition in myoelectric signals is the Support Vector Machines (SVM) technique whose primary function is to identify an n-dimensional hyperplane to separate a set of input feature points into different classes. This technique has the potential to recognize complex patterns and on several occasions, it has proven its worth when compared to other classifiers such as Artificial Neural Network (ANN), Linear Discriminant Analysis (LDA), and Principal Component Analysis(PCA). The key concepts underlying the SVM are (a) the hyperplane separator; (b) the kernel function; (c) the optimal separation hyperplane; and (d) a soft margin (hyperplane tolerance).      
### 5.Self-supervised EEG Representation Learning for Automatic Sleep Staging  [ :arrow_down: ](https://arxiv.org/pdf/2110.15278.pdf)
>  Objective: In this paper, we aim to learn robust vector representations from massive unlabeled Electroencephalogram (EEG) signals, such that the learned representations (1) are expressive enough to replace the raw signals in the sleep staging task; and (2) provide better predictive performance than supervised models in scenarios of fewer labels and noisy samples. <br>Materials and Methods: We propose a self-supervised model, named Contrast with the World Representation (ContraWR), for EEG signal representation learning, which uses global statistics from the dataset to distinguish signals associated with different sleep stages. The ContraWR model is evaluated on three real-world EEG datasets that include both at-home and in-lab recording settings. <br>Results: ContraWR outperforms recent self-supervised learning methods, MoCo, SimCLR, BYOL, SimSiam on the sleep staging task across three datasets. ContraWR also beats supervised learning when fewer training labels are available (e.g., 4% accuracy improvement when less than 2% data is labeled). Moreover, the model provides informative representations in 2D projection. <br>Discussion: The proposed model can be generalized to other unsupervised physiological signal learning tasks. Future directions include exploring task-specific data augmentations and combining self-supervised with supervised methods, building upon the initial success of self-supervised learning in this paper. <br>Conclusions: We show that ContraWR is robust to noise and can provide high-quality EEG representations for downstream prediction tasks. In low-label scenarios (e.g., only 2% data has labels), ContraWR shows much better predictive power (e.g., 4% improvement on sleep staging accuracy) than supervised baselines.      
### 6.A Novel Sleep Stage Classification Using CNN Generated by an Efficient Neural Architecture Search with a New Data Processing Trick  [ :arrow_down: ](https://arxiv.org/pdf/2110.15277.pdf)
>  With the development of automatic sleep stage classification (ASSC) techniques, many classical methods such as k-means, decision tree, and SVM have been used in automatic sleep stage classification. However, few methods explore deep learning on ASSC. Meanwhile, most deep learning methods require extensive expertise and suffer from a mass of handcrafted steps which are time-consuming especially when dealing with multi-classification tasks. In this paper, we propose an efficient five-sleep-stage classification method using convolutional neural networks (CNNs) with a novel data processing trick and we design neural architecture search (NAS) technique based on genetic algorithm (GA), NAS-G, to search for the best CNN architecture. Firstly, we attach each kernel with an adaptive coefficient to enhance the signal processing of the inputs. This can enhance the propagation of informative features and suppress the propagation of useless features in the early stage of the network. Then, we make full use of GA's heuristic search and the advantage of no need for the gradient to search for the best architecture of CNN. This can achieve a CNN with better performance than a handcrafted one in a large search space at the minimum cost. We verify the convergence of our data processing trick and compare the performance of traditional CNNs before and after using our trick. Meanwhile, we compare the performance between the CNN generated through NAS-G and the traditional CNNs with our trick. The experiments demonstrate that the convergence of CNNs with data processing trick is faster than without data processing trick and the CNN with data processing trick generated by NAS-G outperforms the handcrafted counterparts that use the data processing trick too.      
### 7.Joint Model and Data Driven Receiver Design for Data-Dependent Superimposed Training Scheme with Imperfect Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2110.15262.pdf)
>  Data-dependent superimposed training (DDST) scheme has shown the potential to achieve high bandwidth efficiency, while encounters symbol misidentification caused by hardware imperfection. To tackle these challenges, a joint model and data driven receiver scheme is proposed in this paper. Specifically, based on the conventional linear receiver model, the least squares (LS) estimation and zero forcing (ZF) equalization are first employed to extract the initial features for channel estimation and data detection. Then, shallow neural networks, named CE-Net and SD-Net, are developed to refine the channel estimation and data detection, where the imperfect hardware is modeled as a nonlinear function and data is utilized to train these neural networks to approximate it. Simulation results show that compared with the conventional minimum mean square error (MMSE) equalization scheme, the proposed one effectively suppresses the symbol misidentification and achieves similar or better bit error rate (BER) performance without the second-order statistics about the channel and noise.      
### 8.Incremental Adaptive Dynamic Programming for Approximate Optimal Tracking Control: a Decoupled and Model-Free Approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.15237.pdf)
>  This paper proposes a new formulation for the optimal tracking control problem (OTCP) of Euler-Lagrange systems. This formulation extends the incremental adaptive dynamic programming (IADP) technique, a reinforcement learning based method for solving the robust optimal regulation control problem (RORCP), to learn the approximate solution to the OTCP. Departing from available solutions to the OTCP, our developed tracking control scheme settles the curse of complexity problem in value function approximation from a decoupled way, circumvents the learning inefficiency regarding varying desired trajectories by avoiding introducing a reference trajectory dynamics into the learning process, and requires neither an accurate nor identified dynamics through the time delay estimation technique. Specifically, we first convert the intractable OTCP of a high-dimensional uncertain system into multiple manageable sub-RORCPs of low-dimensional incremental error subsystems. Then, the resulting sub-RORCPs are approximately solved by IADP implemented as a parallel critic learning structure. The proposed tracking control scheme is developed with rigorous theoretical analysis of system stability and weight convergence, and validated numerically on a 6-DoF quadrotor and experimentally on a 3-DoF robot manipulator.      
### 9.Consensus-Based Decentralized Energy Trading for Distributed Energy Resources  [ :arrow_down: ](https://arxiv.org/pdf/2110.15178.pdf)
>  In smart grids, distributed energy resources (DERs) have penetrated residential zones to provide a new form of electricity supply, mainly from renewable energy. Residential households and commercial buildings with DERs have become prosumers in the local grids, since they can sell surplus power to others. Researches have been initiated to integrate and utilize DERs through better control and communication strategies. With the advances in the Internet of Things (IoT) technology, unprecedented coordination among DERs can be achieved to facilitate energy trading and transactive energy management. However, preventing leakage of users' information during the optimization process keeps challenging researchers, which drives them to develop privacy-preserving energy management systems. In this paper, we develop a fully decentralized transactive energy management using the consensus-based algorithm. To be specific, we design a virtual pool for prosumers to trade energy and exchange information with IoT technologies' support. The consensus-based algorithm enables prosumers to obtain the optimal energy schedule independently in a coordinated manner without revealing any personal data. We use real-world data to perform simulations and validate our developed algorithm. The results show that our consensus-based decentralized transactive energy management strategy is feasible and can significantly reduce the overall system cost.      
### 10.Deep Learning Analysis of Cardiac MRI in Legacy Datasets: Multi-Ethnic Study of Atherosclerosis  [ :arrow_down: ](https://arxiv.org/pdf/2110.15144.pdf)
>  The shape and motion of the heart provide essential clues to understanding the mechanisms of cardiovascular disease. With the advent of large-scale cardiac imaging data, statistical atlases become a powerful tool to provide automated and precise quantification of the status of patient-specific heart geometry with respect to reference populations. The Multi-Ethnic Study of Atherosclerosis (MESA), begun in 2000, was the first large cohort study to incorporate cardiovascular MRI in over 5000 participants, and there is now a wealth of follow-up data over 20 years. Building a machine learning based automated analysis is necessary to extract the additional imaging information necessary for expanding original manual analyses. However, machine learning tools trained on MRI datasets with different pulse sequences fail on such legacy datasets. Here, we describe an automated atlas construction pipeline using deep learning methods applied to the legacy cardiac MRI data in MESA. For detection of anatomical cardiac landmark points, a modified VGGNet convolutional neural network architecture was used in conjunction with a transfer learning sequence between two-chamber, four-chamber, and short-axis MRI views. A U-Net architecture was used for detection of the endocardial and epicardial boundaries in short axis images. Both network architectures resulted in good segmentation and landmark detection accuracies compared with inter-observer variations. Statistical relationships with common risk factors were similar between atlases derived from automated vs manual annotations. The automated atlas can be employed in future studies to examine the relationships between cardiac morphology and future events.      
### 11.Accelerating Parameter Extraction of Power MOSFET Models Using Automatic Differentiation  [ :arrow_down: ](https://arxiv.org/pdf/2110.15048.pdf)
>  The extraction of the model parameters is as important as the development of compact model itself because simulation accuracy is fully determined by the accuracy of the parameters used. This study proposes an efficient model-parameter extraction method for compact models of power MOSFETs. The proposed method employs automatic differentiation (AD), which is extensively used for training artificial neural networks. In the proposed AD-based parameter extraction, gradient of all the model parameters is analytically calculated by forming a graph that facilitates the backward propagation of errors. Based on the calculated gradient, computationally intensive numerical differentiation is eliminated and the model parameters are efficiently optimized. Experiments are conducted to fit current and capacitance characteristics of commercially available silicon carbide MOSFET using power MOSFET models having 13 model parameters. Results demonstrated that the proposed method could successfully derive the model parameters 3.50x faster than a conventional numerical-differentiation method while achieving the equal accuracy.      
### 12.TorchAudio: Building Blocks for Audio and Speech Processing  [ :arrow_down: ](https://arxiv.org/pdf/2110.15018.pdf)
>  This document describes version 0.10 of torchaudio: building blocks for machine learning applications in the audio and speech processing domain. The objective of torchaudio is to accelerate the development and deployment of machine learning applications for researchers and engineers by providing off-the-shelf building blocks. The building blocks are designed to be GPU-compatible, automatically differentiable, and production-ready. torchaudio can be easily installed from Python Package Index repository and the source code is publicly available under a BSD-2-Clause License (as of September 2021) at <a class="link-external link-https" href="https://github.com/pytorch/audio" rel="external noopener nofollow">this https URL</a>. In this document, we provide an overview of the design principles, functionalities, and benchmarks of torchaudio. We also benchmark our implementation of several audio and speech operations and models. We verify through the benchmarks that our implementations of various operations and models are valid and perform similarly to other publicly available implementations.      
### 13.Residual Motion Compensation in Automotive MIMO SAR Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2110.14995.pdf)
>  This paper deals with the analysis, estimation, and compensation of trajectory errors in automotive-based Synthetic Aperture Radar (SAR) systems. First of all, we define the geometry of the acquisition and the model of the received signal. We then proceed by analytically evaluating the effect of an error in the vehicle's trajectory. Based on the derived model, we introduce a motion compensation (MoCo) procedure capable of estimating and compensating constant velocity motion errors leading to a well-focused and well-localized SAR image. The procedure is validated using real data gathered by a 77 GHz automotive SAR with MIMO capabilities.      
### 14.Multi-Beam Automotive SAR Imaging in Urban Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2110.14988.pdf)
>  Automotive synthetic aperture radar (SAR) systems are rapidly emerging as a candidate technological solution to enable a high-resolution environment mapping for autonomous driving. Compared to lidars and cameras, automotive-legacy radars can work in any weather condition and without an external source of illumination, but are limited in either range or angular resolution. SARs offer a relevant increase in angular resolution, provided that the ego-motion of the radar platform is known along the synthetic aperture. In this paper, we present the results of an experimental campaign aimed at assessing the potential of a multi-beam SAR imaging in an urban scenario, composed of various targets (buildings, cars, pedestrian, etc.), employing a 77 GHz multiple-input multiple-output (MIMO) radar platform based on a mass-market available automotive-grade technology. The results highlight a centimeter-level accuracy of the SAR images in realistic driving conditions, showing the possibility to use a multi-angle focusing approach to detect and discriminate between different targets based on their angular scattering response.      
### 15.Diagnosis of COVID-19 Using Machine Learning and Deep Learning: A review  [ :arrow_down: ](https://arxiv.org/pdf/2110.14910.pdf)
>  Background: This paper provides a systematic review of the application of Artificial Intelligence (AI) in the form of Machine Learning (ML) and Deep Learning (DL) techniques in fighting against the effects of novel coronavirus disease (COVID-19). Objective &amp; Methods: The objective is to perform a scoping review on AI for COVID-19 using preferred reporting items of systematic reviews and meta-analysis (PRISMA) guidelines. A literature search was performed for relevant studies published from 1 January 2020 till 27 March 2021. Out of 4050 research papers available in reputed publishers, a full-text review of 440 articles was done based on the keywords of AI, COVID-19, ML, forecasting, DL, X-ray, and Computed Tomography (CT). Finally, 52 articles were included in the result synthesis of this paper. As part of the review, different ML regression methods were reviewed first in predicting the number of confirmed and death cases. Secondly, a comprehensive survey was carried out on the use of ML in classifying COVID-19 patients. Thirdly, different datasets on medical imaging were compared in terms of the number of images, number of positive samples and number of classes in the datasets. The different stages of the diagnosis, including preprocessing, segmentation and feature extraction were also reviewed. Fourthly, the performance results of different research papers were compared to evaluate the effectiveness of DL methods on different datasets. Results: Results show that residual neural network (ResNet-18) and densely connected convolutional network (DenseNet 169) exhibit excellent classification accuracy for X-ray images, while DenseNet-201 has the maximum accuracy in classifying CT scan images. This indicates that ML and DL are useful tools in assisting researchers and medical professionals in predicting, screening and detecting COVID-19.      
### 16.Degraded Reference Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2110.14899.pdf)
>  In practical media distribution systems, visual content usually undergoes multiple stages of quality degradation along the delivery chain, but the pristine source content is rarely available at most quality monitoring points along the chain to serve as a reference for quality assessment. As a result, full-reference (FR) and reduced-reference (RR) image quality assessment (IQA) methods are generally infeasible. Although no-reference (NR) methods are readily applicable, their performance is often not reliable. On the other hand, intermediate references of degraded quality are often available, e.g., at the input of video transcoders, but how to make the best use of them in proper ways has not been deeply investigated. Here we make one of the first attempts to establish a new paradigm named degraded-reference IQA (DR IQA). Specifically, we lay out the architectures of DR IQA and introduce a 6-bit code to denote the choices of configurations. We construct the first large-scale databases dedicated to DR IQA and will make them publicly available. We make novel observations on distortion behavior in multi-stage distortion pipelines by comprehensively analyzing five multiple distortion combinations. Based on these observations, we develop novel DR IQA models and make extensive comparisons with a series of baseline models derived from top-performing FR and NR models. The results suggest that DR IQA may offer significant performance improvement in multiple distortion environments, thereby establishing DR IQA as a valid IQA paradigm that is worth further exploration.      
### 17.Enhancing RF Sensing with Deep Learning: A Layered Approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.14849.pdf)
>  In recent years, radio frequency (RF) sensing has gained increasing popularity due to its pervasiveness, low cost, non-intrusiveness, and privacy preservation. However, realizing the promises of RF sensing is highly nontrivial, given typical challenges such as multipath and interference. One potential solution leverages deep learning to build direct mappings from the RF domain to target domains, hence avoiding complex RF physical modeling. While earlier solutions exploit only simple feature extraction and classification modules, an emerging trend adds functional layers on top of elementary modules for more powerful generalizability and flexible applicability. To better understand this potential, this article takes a layered approach to summarize RF sensing enabled by deep learning. Essentially, we present a four-layer framework: physical, backbone, generalization, and application. While this layered framework provides readers a systematic methodology for designing deep interpreted RF sensing, it also facilitates making improvement proposals and hints at future research opportunities.      
### 18.V2iFi: in-Vehicle Vital Sign Monitoring via Compact RF Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.14848.pdf)
>  Given the significant amount of time people spend in vehicles, health issues under driving condition have become a major concern. Such issues may vary from fatigue, asthma, stroke, to even heart attack, yet they can be adequately indicated by vital signs and abnormal activities. Therefore, in-vehicle vital sign monitoring can help us predict and hence prevent these issues. Whereas existing sensor-based (including camera) methods could be used to detect these indicators, privacy concern and system complexity both call for a convenient yet effective and robust alternative. This paper aims to develop V2iFi, an intelligent system performing monitoring tasks using a COTS impulse radio mounted on the windshield. V2iFi is capable of reliably detecting driver's vital signs under driving condition and with the presence of passengers, thus allowing for potentially inferring corresponding health issues. Compared with prior work based on Wi-Fi CSI, V2iFi is able to distinguish reflected signals from multiple users, and hence provide finer-grained measurements under more realistic settings. We evaluate V2iFi both in lab environments and during real-life road tests; the results demonstrate that respiratory rate, heart rate, and heart rate variability can all be estimated accurately. Based on these estimation results, we further discuss how machine learning models can be applied on top of V2iFi so as to improve both physiological and psychological wellbeing in driving environments.      
### 19.Continuous Speech Separation with Recurrent Selective Attention Network  [ :arrow_down: ](https://arxiv.org/pdf/2110.14838.pdf)
>  While permutation invariant training (PIT) based continuous speech separation (CSS) significantly improves the conversation transcription accuracy, it often suffers from speech leakages and failures in separation at "hot spot" regions because it has a fixed number of output channels. In this paper, we propose to apply recurrent selective attention network (RSAN) to CSS, which generates a variable number of output channels based on active speaker counting. In addition, we propose a novel block-wise dependency extension of RSAN by introducing dependencies between adjacent processing blocks in the CSS framework. It enables the network to utilize the separation results from the previous blocks to facilitate the current block processing. Experimental results on the LibriCSS dataset show that the RSAN-based CSS (RSAN-CSS) network consistently improves the speech recognition accuracy over PIT-based models. The proposed block-wise dependency modeling further boosts the performance of RSAN-CSS.      
### 20.SCALP -- Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata  [ :arrow_down: ](https://arxiv.org/pdf/2110.14787.pdf)
>  Computer-aided diagnosis plays a salient role in more accessible and accurate cardiopulmonary diseases classification and localization on chest radiography. Millions of people get affected and die due to these diseases without an accurate and timely diagnosis. Recently proposed contrastive learning heavily relies on data augmentation, especially positive data augmentation. However, generating clinically-accurate data augmentations for medical images is extremely difficult because the common data augmentation methods in computer vision, such as sharp, blur, and crop operations, can severely alter the clinical settings of medical images. In this paper, we proposed a novel and simple data augmentation method based on patient metadata and supervised knowledge to create clinically accurate positive and negative augmentations for chest X-rays. We introduce an end-to-end framework, SCALP, which extends the self-supervised contrastive approach to a supervised setting. Specifically, SCALP pulls together chest X-rays from the same patient (positive keys) and pushes apart chest X-rays from different patients (negative keys). In addition, it uses ResNet-50 along with the triplet-attention mechanism to identify cardiopulmonary diseases, and Grad-CAM++ to highlight the abnormal regions. Our extensive experiments demonstrate that SCALP outperforms existing baselines with significant margins in both classification and localization tasks. Specifically, the average classification AUCs improve from 82.8% (SOTA using DenseNet-121) to 83.9% (SCALP using ResNet-50), while the localization results improve on average by 3.7% over different IoU thresholds.      
### 21.Analyzing Photovoltaic's Impact on Conservation Voltage Reduction in Distribution Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.14777.pdf)
>  Conservation voltage reduction (CVR) has been widely implemented in distribution networks and helped utilities effectively reduce energy and peak load. However, the increasing penetration level of solar photovoltaic (PV) has affected voltage profiles and the performance of CVR. It remains an outstanding question how CVR and solar PV interact with each other. Understanding this interaction is important for utilities in implementing CVR and assessing its performance. This paper studies the impact of solar PV on CVR in a real distribution system in the Midwest U.S. using comprehensive simulations. We have considered various PV allocations and penetration levels, as well as different inverter control modes according to IEEE Std 1547-2018. Three metrics are used to quantify the impact of solar PV on CVR: voltages at the substation, voltage distribution across the network, and energy consumption reduction due to CVR. The results show that the allocations of solar PV have the most significant effect on the CVR performance, where a dispersed allocation of solar PV will help flatten voltage profile and achieve deeper voltage reductions at the substation, less energy consumption and line losses.      
### 22.A Semi-Blind Method for Localization of Underwater Acoustic Sources  [ :arrow_down: ](https://arxiv.org/pdf/2110.14767.pdf)
>  Underwater acoustic localization has traditionally been challenging due to the presence of unknown environmental structure and dynamic conditions. The problem is richer still when such structure includes occlusion, which causes the loss of line-of-sight (LOS) between the acoustic source and the receivers, on which many of the existing localization algorithms rely. We develop a semi-blind passive localization method capable of accurately estimating the source's position even in the possible absence of LOS between the source and all receivers. Based on typically-available prior knowledge of the water surface and bottom, we derive a closed-form expression for the optimal estimator under a multi-ray propagation model, which is suitable for shallow-water environments and high-frequency signals. By exploiting a computationally efficient form of this estimator, our methodology makes comparatively high-resolution localization feasible. We also derive the Cramér-Rao bound for this model, which can be used to guide the placement of collections of receivers so as to optimize localization accuracy. The method improves a balance of accuracy and robustness to environmental model mismatch, relative to existing localization methods that are useful in similar settings. The method is validated with simulations and water tank experiments.      
### 23.Lung Cancer Lesion Detection in Histopathology Images Using Graph-Based Sparse PCA Network  [ :arrow_down: ](https://arxiv.org/pdf/2110.14728.pdf)
>  Early detection of lung cancer is critical for improvement of patient survival. To address the clinical need for efficacious treatments, genetically engineered mouse models (GEMM) have become integral in identifying and evaluating the molecular underpinnings of this complex disease that may be exploited as therapeutic targets. Assessment of GEMM tumor burden on histopathological sections performed by manual inspection is both time consuming and prone to subjective bias. Therefore, an interplay of needs and challenges exists for computer-aided diagnostic tools, for accurate and efficient analysis of these histopathology images. In this paper, we propose a simple machine learning approach called the graph-based sparse principal component analysis (GS-PCA) network, for automated detection of cancerous lesions on histological lung slides stained by hematoxylin and eosin (H&amp;E). Our method comprises four steps: 1) cascaded graph-based sparse PCA, 2) PCA binary hashing, 3) block-wise histograms, and 4) support vector machine (SVM) classification. In our proposed architecture, graph-based sparse PCA is employed to learn the filter banks of the multiple stages of a convolutional network. This is followed by PCA hashing and block histograms for indexing and pooling. The meaningful features extracted from this GS-PCA are then fed to an SVM classifier. We evaluate the performance of the proposed algorithm on H&amp;E slides obtained from an inducible K-rasG12D lung cancer mouse model using precision/recall rates, F-score, Tanimoto coefficient, and area under the curve (AUC) of the receiver operator characteristic (ROC) and show that our algorithm is efficient and provides improved detection accuracy compared to existing algorithms.      
### 24.Fast Video-based Face Recognition in Collaborative Learning Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.14720.pdf)
>  Face recognition is a classical problem in Computer Vision that has experienced significant progress. Yet, in digital videos, face recognition is complicated by occlusion, pose and lighting variations, and persons entering/leaving the scene. The thesis's goal is to develop a fast method for face recognition in digital videos that is applicable to large datasets. The thesis introduces several methods to address the problems associated with video face recognition. First, to address issues associated with pose and lighting variations, a collection of face prototypes is associated with each student. Second, to speed up the process, sampling, K-means Clustering, and a combination of both are used to reduce the number of face prototypes per student. Third, the videos are processed at different frame rates. Fourth, the thesis proposes the use of active sets to address occlusion and to eliminate face recognition application on video frames with slow face motions. Fifth, the thesis develops a group face detector that recognizes students within a collaborative learning group, while rejecting out-of-group face detections. Sixth, the thesis introduces a face DeID for protecting the students' identities. Seventh, the thesis uses data augmentation to increase the training set's size. The different methods are combined using multi-objective optimization to guarantee that the full method remains fast without sacrificing accuracy. To test the approach, the thesis develops the AOLME dataset of 138 student faces (81 boys and 57 girls) of ages 10 to 14, who are predominantly Latina/o students. Compared to the baseline method, the final optimized method resulted in fast recognition times with significant improvements in face recognition accuracy. Using face prototype sampling only, the proposed method achieved an accuracy of 71.8% compared to 62.3% for the baseline system, while running 11.6 times faster.      
### 25.Sharp-GAN: Sharpness Loss Regularized GAN for Histopathology Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.14709.pdf)
>  Existing deep learning-based approaches for histopathology image analysis require large annotated training sets to achieve good performance; but annotating histopathology images is slow and resource-intensive. Conditional generative adversarial networks have been applied to generate synthetic histopathology images to alleviate this issue, but current approaches fail to generate clear contours for overlapped and touching nuclei. In this study, We propose a sharpness loss regularized generative adversarial network to synthesize realistic histopathology images. The proposed network uses normalized nucleus distance map rather than the binary mask to encode nuclei contour information. The proposed sharpness loss enhances the contrast of nuclei contour pixels. The proposed method is evaluated using four image quality metrics and segmentation results on two public datasets. Both quantitative and qualitative results demonstrate that the proposed approach can generate realistic histopathology images with clear nuclei contours.      
### 26.Alternating Learning Approach for Variational Networks and Undersampling Pattern in Parallel MRI Applications  [ :arrow_down: ](https://arxiv.org/pdf/2110.14703.pdf)
>  Purpose: To propose an alternating learning approach to learn the sampling pattern (SP) and the parameters of variational networks (VN) in accelerated parallel magnetic resonance imaging (MRI). Methods: The approach alternates between improving the SP, using bias-accelerated subset selection, and improving parameters of the VN, using ADAM with monotonicity verification. The algorithm learns an effective pair: an SP that captures fewer k-space samples generating undersampling artifacts that are removed by the VN reconstruction. The proposed approach was tested for stability and convergence, considering different initial SPs. The quality of the VNs and SPs was compared against other approaches, including joint learning methods and VN learning with fixed variable density Poisson-disc SPs, using two different datasets and different acceleration factors (AF). Results: The root mean squared error (RMSE) improvements ranged from 14.9% to 51.2% considering AF from 2 to 20 in the tested brain and knee joint datasets when compared to the other approaches. The proposed approach has shown stable convergence, obtaining similar SPs with the same RMSE under different initial conditions. Conclusion: The proposed approach was stable and learned effective SPs with the corresponding VN parameters that produce images with better quality than other approaches, improving accelerated parallel MRI applications.      
### 27.DDK: A Deep Koopman Approach for Dynamics Modeling and Trajectory Tracking of Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2110.14700.pdf)
>  Autonomous driving has attracted lots of attention in recent years. An accurate vehicle dynamics is important for autonomous driving techniques, e.g. trajectory prediction, motion planning, and control of trajectory tracking. Although previous works have made some results, the strong nonlinearity, precision, and interpretability of dynamics for autonomous vehicles are open problems worth being studied. In this paper, the approach based on the Koopman operator named deep direct Koopman (DDK) is proposed to identify the model of the autonomous vehicle and the identified model is a linear time-invariant (LTI) version, which is convenient for motion planning and controller design. In the approach, the Koopman eigenvalues and system matrix are considered as trainable tensors with the original states of the autonomous vehicle being concatenated to a part of the Koopman eigenfunctions so that a physically interpretable subsystem can be extracted from the identified latent dynamics. Subsequently, the process of the identification model is trained under the proposed method based on the dataset which consists of about 60km of data collected with a real electric SUV while the effectiveness of the identified model is validated. Meanwhile, a high-fidelity vehicle dynamics is identified in CarSim with DDK, and then, a linear model predictive control (MPC) called DDK-MPC integrating DDK is designed to validate the performance for the control of trajectory tracking. Simulation results illustrate that the model of the nonlinear vehicle dynamics can be identified effectively via the proposed method and that excellent tracking performance can be obtained with the identified model under DDK-MPC.      
### 28.Improving Super-Resolution Performance using Meta-Attention Layers  [ :arrow_down: ](https://arxiv.org/pdf/2110.14638.pdf)
>  Convolutional Neural Networks (CNNs) have achieved impressive results across many super-resolution (SR) and image restoration tasks. While many such networks can upscale low-resolution (LR) images using just the raw pixel-level information, the ill-posed nature of SR can make it difficult to accurately super-resolve an image which has undergone multiple different degradations. Additional information (metadata) describing the degradation process (such as the blur kernel applied, compression level, etc.) can guide networks to super-resolve LR images with higher fidelity to the original source. Previous attempts at informing SR networks with degradation parameters have indeed been able to improve performance in a number of scenarios. However, due to the fully-convolutional nature of many SR networks, most of these metadata fusion methods either require a complete architectural change, or necessitate the addition of significant extra complexity. Thus, these approaches are difficult to introduce into arbitrary SR networks without considerable design alterations. In this paper, we introduce meta-attention, a simple mechanism which allows any SR CNN to exploit the information available in relevant degradation parameters. The mechanism functions by translating the metadata into a channel attention vector, which in turn selectively modulates the network's feature maps. Incorporating meta-attention into SR networks is straightforward, as it requires no specific type of architecture to function correctly. Extensive testing has shown that meta-attention can consistently improve the pixel-level accuracy of state-of-the-art (SOTA) networks when provided with relevant degradation metadata. For PSNR, the gain on blurred/downsampled (X4) images is of 0.2969 dB (on average) and 0.3320 dB for SOTA general and face SR models, respectively.      
### 29.MEGAN: Memory Enhanced Graph Attention Network for Space-Time Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2110.15327.pdf)
>  Space-time video super-resolution (STVSR) aims to construct a high space-time resolution video sequence from the corresponding low-frame-rate, low-resolution video sequence. Inspired by the recent success to consider spatial-temporal information for space-time super-resolution, our main goal in this work is to take full considerations of spatial and temporal correlations within the video sequences of fast dynamic events. To this end, we propose a novel one-stage memory enhanced graph attention network (MEGAN) for space-time video super-resolution. Specifically, we build a novel long-range memory graph aggregation (LMGA) module to dynamically capture correlations along the channel dimensions of the feature maps and adaptively aggregate channel features to enhance the feature representations. We introduce a non-local residual block, which enables each channel-wise feature to attend global spatial hierarchical features. In addition, we adopt a progressive fusion module to further enhance the representation ability by extensively exploiting spatial-temporal correlations from multiple frames. Experiment results demonstrate that our method achieves better results compared with the state-of-the-art methods quantitatively and visually.      
### 30.VRM-Phase I VKW system description of long-short video customizable keyword wakeup challenge  [ :arrow_down: ](https://arxiv.org/pdf/2110.15316.pdf)
>  Keyword wakeup technology has always been a research hotspot in speech processing, but many related works were done on different datasets. We organized a Chinese long-short video keyword wakeup challenge (Video Keyword Wakeup Challenge, VKW) for testing the ability of each participating team to build a keyword wakeup system under the public dataset. All submitted systems not only need to support the setting of multiple different keywords, but also need to support the wakeup of any costumed keyword.This paper mainly describes the basic situation of the VKW challenge and the experimental results of some participating teams.      
### 31.Learning to Control using Image Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2110.15290.pdf)
>  Learning to control complex systems using non-traditional feedback, e.g., in the form of snapshot images, is an important task encountered in diverse domains such as robotics, neuroscience, and biology (cellular systems). In this paper, we present a two neural-network (NN)-based feedback control framework to design control policies for systems that generate feedback in the form of images. In particular, we develop a deep $Q$-network (DQN)-driven learning control strategy to synthesize a sequence of control inputs from snapshot images that encode the information pertaining to the current state and control action of the system. Further, to train the networks we employ a direct error-driven learning (EDL) approach that utilizes a set of linear transformations of the NN training error to update the NN weights in each layer. We verify the efficacy of the proposed control strategy using numerical examples.      
### 32.Multi-Pair Two-Way Massive MIMO DF Relaying Over Rician Fading Channels Under Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2110.15242.pdf)
>  We investigate a multi-pair two-way decode-andforward relaying aided massive multiple-input multiple-output antenna system under Rician fading channels, in which multiple pairs of users exchange information through a relay station having multiple antennas. Imperfect channel state information is considered in the context of maximum-ratio processing. Closedform expressions are derived for approximating the sum spectral efficiency (SE) of the system. Moreover, we obtain the powerscaling laws at the users and the relay station to satisfy a certain SE requirement in three typical scenarios. Finally, simulations validate the accuracy of the derived results.      
### 33.Subpixel object segmentation using wavelets and multi resolution analysis  [ :arrow_down: ](https://arxiv.org/pdf/2110.15233.pdf)
>  We propose a novel deep learning framework for fast prediction of boundaries of two-dimensional simply connected domains using wavelets and Multi Resolution Analysis (MRA). The boundaries are modelled as (piecewise) smooth closed curves using wavelets and the so-called Pyramid Algorithm. Our network architecture is a hybrid analog of the U-Net, where the down-sampling path is a two-dimensional encoder with learnable filters, and the upsampling path is a one-dimensional decoder, which builds curves up from low to high resolution levels. Any wavelet basis induced by a MRA can be used. This flexibility allows for incorporation of priors on the smoothness of curves. The effectiveness of the proposed method is demonstrated by delineating boundaries of simply connected domains (organs) in medical images using Debauches wavelets and comparing performance with a U-Net baseline. Our model demonstrates up to 5x faster inference speed compared to the U-Net, while maintaining similar performance in terms of Dice score and Hausdorff distance.      
### 34.Word-level confidence estimation for RNN transducers  [ :arrow_down: ](https://arxiv.org/pdf/2110.15222.pdf)
>  Confidence estimate is an often requested feature in applications such as medical transcription where errors can impact patient care and the confidence estimate could be used to alert medical professionals to verify potential errors in recognition. <br>In this paper, we present a lightweight neural confidence model tailored for Automatic Speech Recognition (ASR) system with Recurrent Neural Network Transducers (RNN-T). Compared to other existing approaches, our model utilizes: (a) the time information associated with recognized words, which reduces the computational complexity, and (b) a simple and elegant trick for mapping between sub-word and word sequences. The mapping addresses the non-unique tokenization and token deletion problems while amplifying differences between confusable words. Through extensive empirical evaluations on two different long-form test sets, we demonstrate that the model achieves a performance of 0.4 Normalized Cross Entropy (NCE) and 0.05 Expected Calibration Error (ECE). It is robust across different ASR configurations, including target types (graphemes vs. morphemes), traffic conditions (streaming vs. non-streaming), and encoder types. We further discuss the importance of evaluation metrics to reflect practical applications and highlight the need for further work in improving Area Under the Curve (AUC) for Negative Precision Rate (NPV) and True Negative Rate (TNR).      
### 35.Black-Box Assessment of Optical Spectrum Services  [ :arrow_down: ](https://arxiv.org/pdf/2110.15207.pdf)
>  A spectral sweep process is introduced to discover performance issues in optical spectrum services. We detect filtering penalty, spectral ripple/tilt and channel crosstalk in field measurements, potentially leading to increased service robustness in low-margin networks.      
### 36.Energy Efficient Resource Allocation in Federated Fog Computing Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.15204.pdf)
>  There is a continuous growth in demand for time sensitive applications which has shifted the cloud paradigm from a centralized computing architecture towards distributed heterogeneous computing platforms where resources located at the edge of the network are used to provide cloud-like services. This paradigm is widely known as fog computing. Virtual machines (VMs) have been widely utilized in both paradigms to enhance the network scalability, improve resource utilization, and energy efficiency. Moreover, Passive Optical Networks (PONs) are a technology suited to handling the enormous volumes of data generated in the access network due to their energy efficiency and large bandwidth. In this paper, we utilize a PON to provide the connectivity between multiple distributed fog units to achieve federated (i.e. cooperative) computing units in the access network to serve intensive demands. We propose a mixed integer linear program (MILP) to optimize the VM placement in the federated fog computing units with the objective of minimizing the total power consumption while considering inter-VM traffic. The results show a significant power saving as a result of the proposed optimization model by up to 52%, in the VM-allocation compared to a baseline approach that allocates the VM requests while neglecting the power consumption and inter-VMs traffic in the optimization framework.      
### 37.Coexistence and Spectrum Sharing Above 100 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2110.15187.pdf)
>  [...] This paper explores how spectrum policy and spectrum technologies can evolve to enable sharing among different stakeholders in the above 100 GHz spectrum, without introducing harmful interference or disrupting either security applications or fundamental science exploration. This portion of the spectrum presents new opportunities to design spectrum sharing schemes, based on novel antenna designs, directional ultra-high-rate communications, and active/passive user coordination. The paper provides a tutorial on current regulations above 100 GHz, and highlights how sharing is central to allowing each stakeholder to make the most out of this spectrum. It then defines - through detailed simulations based on standard International Telecommunications Union (ITU) channel and antenna models - scenarios in which active users may introduce harmful interference to passive sensing. Based on this evaluation, it reviews a number of promising techniques that can enable active/passive sharing above 100 GHz. The critical review and tutorial on policy and technologies of this paper have the potential to kickstart future research and regulations that promote safe coexistence between active and passive users above 100 GHz, further benefiting the development of digital technologies and scientific exploration.      
### 38.Feature Learning for Neural-Network-Based Positioning with Channel State Information  [ :arrow_down: ](https://arxiv.org/pdf/2110.15160.pdf)
>  Recent channel state information (CSI)-based positioning pipelines rely on deep neural networks (DNNs) in order to learn a mapping from estimated CSI to position. Since real-world communication transceivers suffer from hardware impairments, CSI-based positioning systems typically rely on features that are designed by hand. In this paper, we propose a CSI-based positioning pipeline that directly takes raw CSI measurements and learns features using a structured DNN in order to generate probability maps describing the likelihood of the transmitter being at pre-defined grid points. To further improve the positioning accuracy of moving user equipments, we propose to fuse a time-series of learned CSI features or a time-series of probability maps. To demonstrate the efficacy of our methods, we perform experiments with real-world indoor line-of-sight (LoS) and non-LoS channel measurements. We show that CSI feature learning and time-series fusion can reduce the mean distance error by up to 2.5$\boldsymbol\times$ compared to the state-of-the-art.      
### 39.An Adaptable Approach to Learn Realistic Legged Locomotion without Examples  [ :arrow_down: ](https://arxiv.org/pdf/2110.14998.pdf)
>  Learning controllers that reproduce legged locomotion in nature have been a long-time goal in robotics and computer graphics. While yielding promising results, recent approaches are not yet flexible enough to be applicable to legged systems of different morphologies. This is partly because they often rely on precise motion capture references or elaborate learning environments that ensure the naturality of the emergent locomotion gaits but prevent generalization. This work proposes a generic approach for ensuring realism in locomotion by guiding the learning process with the spring-loaded inverted pendulum model as a reference. Leveraging on the exploration capacities of Reinforcement Learning (RL), we learn a control policy that fills in the information gap between the template model and full-body dynamics required to maintain stable and periodic locomotion. The proposed approach can be applied to robots of different sizes and morphologies and adapted to any RL technique and control architecture. We present experimental results showing that even in a model-free setup and with a simple reactive control architecture, the learned policies can generate realistic and energy-efficient locomotion gaits for a bipedal and a quadrupedal robot. And most importantly, this is achieved without using motion capture, strong constraints in the dynamics or kinematics of the robot, nor prescribing limb coordination. We provide supplemental videos for qualitative analysis of the naturality of the learned gaits.      
### 40.Model-based electron density profile estimation and control, applied to ITER  [ :arrow_down: ](https://arxiv.org/pdf/2110.14975.pdf)
>  In contemporary magnetic confinement devices, the density distribution is sensed with interferometers and actuated with feedback controlled gas injection and open-loop pellet injection. This is at variance with the density control for ITER and DEMO, that will depend mainly on pellet injection as an actuator in feed-back control. This paper presents recent developments in state estimation and control of the electron density profile for ITER using relevant sensors and actuators. As a first step, Thomson scattering is included in an existing dynamic state observer. Second, model predictive control is developed as a strategy to regulate the density profile while avoiding limits associated with the total density (Greenwald limit) or gradients in the density distribution (e.g. neo-classical impurity transport). Simulations show that high quality density profile estimation can be achieved with Thomson Scattering and that the controller is capable of regulating the distribution as desired.      
### 41.End-to-End Speech Emotion Recognition: Challenges of Real-Life Emergency Call Centers Data Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2110.14957.pdf)
>  Recognizing a speaker's emotion from their speech can be a key element in emergency call centers. End-to-end deep learning systems for speech emotion recognition now achieve equivalent or even better results than conventional machine learning approaches. In this paper, in order to validate the performance of our neural network architecture for emotion recognition from speech, we first trained and tested it on the widely used corpus accessible by the community, IEMOCAP. We then used the same architecture as the real life corpus, CEMO, composed of 440 dialogs (2h16m) from 485 speakers. The most frequent emotions expressed by callers in these real life emergency dialogues are fear, anger and positive emotions such as relief. In the IEMOCAP general topic conversations, the most frequent emotions are sadness, anger and happiness. Using the same end-to-end deep learning architecture, an Unweighted Accuracy Recall (UA) of 63% is obtained on IEMOCAP and a UA of 45.6% on CEMO, each with 4 classes. Using only 2 classes (Anger, Neutral), the results for CEMO are 76.9% UA compared to 81.1% UA for IEMOCAP. We expect that these encouraging results with CEMO can be improved by combining the audio channel with the linguistic channel. Real-life emotions are clearly more complex than acted ones, mainly due to the large diversity of emotional expressions of speakers. Index Terms-emotion detection, end-to-end deep learning architecture, call center, real-life database, complex emotions.      
### 42.A Novel Sample-efficient Deep Reinforcement Learning with Episodic Policy Transfer for PID-Based Control in Cardiac Catheterization Robots  [ :arrow_down: ](https://arxiv.org/pdf/2110.14941.pdf)
>  Robotic catheterization is typically used for percutaneous coronary intervention procedures nowadays and it involves steering flexible endovascular tools to open up occlusion in the coronaries. In this study, a sample-efficient deep reinforcement learning with episodic policy transfer is, for the first time, used for motion control during robotic catheterization with fully adaptive PID tuning strategy. The reinforcement model aids the agent to continuously learn from its interactions in its environment and adaptively tune PID control gains for axial navigation of endovascular tool. The model was validated for axial motion control of a robotic system designed for intravascular catheterization. Simulation and experimental trials were done to validate the application of the model, and results obtained shows it could self-tune PID gains appropriately for motion control of a robotic catheter system. Performance comparison with conventional methods in average of 10 trials shows the agent tunes the gain better with error of 0.003 mm. Thus, the proposed model would offer more stable set-point motion control robotic catheterization.      
### 43.A recursive robust filtering approach for 3D registration  [ :arrow_down: ](https://arxiv.org/pdf/2110.14932.pdf)
>  This work presents a new recursive robust filtering approach for feature-based 3D registration. Unlike the common state-of-the-art alignment algorithms, the proposed method has four advantages that have not yet occurred altogether in any previous solution. For instance, it is able to deal with inherent noise contaminating sensory data; it is robust to uncertainties caused by noisy feature localisation; it also combines the advantages of both (Formula presented.) and (Formula presented.) norms for a higher performance and a more prospective prevention of local minima. The result is an accurate and stable rigid body transformation. The latter enables a thorough control over the convergence regarding the alignment as well as a correct assessment of the quality of registration. The mathematical rationale behind the proposed approach is explained, and the results are validated on physical and synthetic data.      
### 44.Distributed Joint Multi-cell Optimization of IRS Parameters with Linear Precoders  [ :arrow_down: ](https://arxiv.org/pdf/2110.14906.pdf)
>  We present distributed methods for jointly optimizing Intelligent Reflecting Surface (IRS) phase-shifts and beamformers in a cellular network. The proposed schemes require knowledge of only the intra-cell training sequences and corresponding received signals without explicit channel estimation. Instead, an SINR objective is estimated via sample means and maximized directly. This automatically includes and mitigates both intra- and inter-cell interference provided that the uplink training is synchronized across cells. Different schemes are considered that limit the set of known training sequences from interferers. With MIMO links an iterative synchronous bi-directional training scheme jointly optimizes the IRS parameters with the beamformers and combiners. Simulation results show that the proposed distributed methods show a modest performance degradation compared to centralized channel estimation schemes, which estimate and exchange all cross-channels between cells, and perform significantly better than channel estimation schemes which ignore the inter-cell interference.      
### 45.Pilot Optimization and Channel Estimation for Two-way Relaying Network Aided by IRS with Finite Discrete Phase Shifters  [ :arrow_down: ](https://arxiv.org/pdf/2110.14879.pdf)
>  In this paper, we investigate the problem of pilot optimization and channel estimation of two-way relaying network (TWRN) aided by an intelligent reflecting surface (IRS) with finite discrete phase shifters. In a TWRN, there exists a challenging problem that the two cascading channels from source-to-IRS-to-Relay and destination-to-IRS-to-relay interfere with each other. Via designing the initial phase shifts of IRS and pilot pattern, the two cascading channels are separated by using simple arithmetic operations like addition and subtraction. Then, the least-squares estimator is adopted to estimate the two cascading channels and two direct channels from source to relay and destination to relay. The corresponding mean square errors (MSE) of channel estimators are derived. By minimizing MSE, the optimal phase shift matrix of IRS is proved. Then, two special matrices Hadamard and discrete Fourier transform (DFT) matrix is shown to be two optimal training matrices for IRS. Furthermore, the IRS with discrete finite phase shifters is taken into account. Using theoretical derivation and numerical simulations, we find that 3-4 bits phase shifters are sufficient for IRS to achieve a negligible MSE performance loss. More importantly, the Hadamard matrix requires only one-bit phase shifters to achieve the optimal MSE performance while the DFT matrix requires at least three or four bits to achieve the same performance. Thus, the Hadamard matrix is a perfect choice for channel estimation using low-resolution phase-shifting IRS.      
### 46.MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.14795.pdf)
>  We introduce MedMNIST v2, a large-scale MNIST-like dataset collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D. All images are pre-processed into a small size of 28x28 (2D) or 28x28x28 (3D) with the corresponding classification labels so that no background knowledge is required for users. Covering primary data modalities in biomedical images, MedMNIST v2 is designed to perform classification on lightweight 2D and 3D images with various dataset scales (from 100 to 100,000) and diverse tasks (binary/multi-class, ordinal regression, and multi-label). The resulting dataset, consisting of 708,069 2D images and 10,214 3D images in total, could support numerous research / educational purposes in biomedical image analysis, computer vision, and machine learning. We benchmark several baseline methods on MedMNIST v2, including 2D / 3D neural networks and open-source / commercial AutoML tools. The data and code are publicly available at <a class="link-external link-https" href="https://medmnist.com/" rel="external noopener nofollow">this https URL</a>.      
### 47.Millimeter Wave Wireless-Assisted Robotic Navigation with Link State Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.14789.pdf)
>  The millimeter wave (mmWave) bands have attracted considerable attention for high precision localization applications due to the ability to capture high angular and temporal resolution measurements. This paper explores mmWave-based positioning for a target localization problem where a fixed target broadcasts mmWave signals and a mobile robotic agent attempts to listen to the signals to locate and navigate to the target. A three strage procedure is proposed: First, the mobile agent uses tensor decomposition methods to detect the wireless paths and their angles. Second, a machine-learning trained classifier is then used to predict the link state, meaning if the strongest path is line-of-sight (LOS) or non-LOS (NLOS). For the NLOS case, the link state predictor also determines if the strongest path arrived via one or more reflections. Third, based on the link state, the agent either follows the estimated angles or explores the environment. The method is demonstrated on a large dataset of indoor environments supplemented with ray tracing to simulate the wireless propagation. The path estimation and link state classification are also integrated into a state-ofthe-art neural simultaneous localization and mapping (SLAM) module to augment camera and LIDAR-based navigation. It is shown that the link state classifier can successfully generalize to completely new environments outside the training set. In addition, the neural-SLAM module with the wireless path estimation and link state classifier provides rapid navigation to the target, close to a baseline that knows the target location.      
### 48.Distributed Asynchronous Games With Causal Memory are Undecidable  [ :arrow_down: ](https://arxiv.org/pdf/2110.14768.pdf)
>  We show the undecidability of the controller synthesis problem when both the plant and the controllers are asynchronous automata and the controllers have causal memory      
### 49.Using PPP Information to Implement a Global Real-Time Virtual Network DGNSS Approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.14763.pdf)
>  Global Navigation Satellite Systems (GNSS) provide positioning services for connected and autonomous vehicles. Differential GNSS (DGNSS) has been demonstrated to provide reliable, high quality range correction information enabling real-time navigation with sub-meter or centimeter accuracy. However, DGNSS requires a local reference station near each user, which for a continental or global scale implementation would require a dense network of reference stations whose construction and maintenance would be prohibitively expensive. Precise Point Positioning (PPP) affords more flexibility as a public service for GNSS receivers, but its State Space Representation (SSR) format is not currently supported by most receivers. This article proposes a novel Virtual Network DGNSS (VN-DGNSS) design that capitalizes on the PPP infrastructure to provide global coverage for real-time navigation without building physical reference stations. Correction information is computed using data from public GNSS SSR data services and transmitted to users by Radio Technical Commission for Maritime Services (RTCM) Observation Space Representation (OSR) messages which are accepted by most receivers. The real-time stationary and moving platform testing performance, using u-blox M8P and ZED-F9P receivers, surpasses the Society of Automotive Engineering (SAE) specification (68% of horizontal error $\leqslant$ 1.5 m and vertical error $\leqslant$ 3 m) and shows significantly better horizontal performance than GNSS Open Service (OS). The moving tests also show better horizontal performance than the ZEDF9P receiver with Satellite Based Augmentation Systems (SBAS) enabled and achieve the lane-level accuracy which requires 95% of horizontal errors less than 1 meter.      
### 50.An Autonomous Probing System for Collecting Measurements at Depth from Small Surface Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2110.14738.pdf)
>  This paper presents the portable autonomous probing system (APS), a low-cost robotic design for collecting water quality measurements at targeted depths from an autonomous surface vehicle (ASV). This system fills an important but often overlooked niche in marine sampling by enabling mobile sensor observations throughout the near-surface water column without the need for advanced underwater equipment. We present a probe delivery mechanism built with commercially available components and describe the corresponding open-source simulator and winch controller. Finally, we demonstrate the system in a field deployment and discuss design trade-offs and areas for future improvement. Project details are available on <a class="link-external link-https" href="https://johannah.github.io/publication/sample-at-depth" rel="external noopener nofollow">this https URL</a> our website      
### 51.Feedback-Induced Flutter Oscillations in a Flexible Tail-Like Appendage for Underwater Propulsion  [ :arrow_down: ](https://arxiv.org/pdf/2110.14733.pdf)
>  Oscillating propulsors can provide both propulsive and maneuvering forces to an underwater vehicle. Because the working area is the same, it is possible to provide maneuvering forces that are similar in magnitude to that of the propulsive forces. An oscillating propulsor in the form of a flexible beam is investigated; the flexible beam is appended to an underwater vehicle by a pin joint and actuated by a motor. It is shown that the flexible propulsor can be driven into post-flutter limit cycle oscillations using feedback of the state of the propulsor. The limit cycle oscillations result in traveling waves, which in turn generate propulsive forces. The elastic strain of the propulsor is used to provide feedback; it is shown that changing the location of strain measurement can result in a rich set of stability transitions, each stability transition is associated with a specific mode of flutter-based propulsion with unique thrust and efficiency characteristics.      
