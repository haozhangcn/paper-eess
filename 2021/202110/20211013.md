# ArXiv eess --Wed, 13 Oct 2021
### 1.Method to Build Equivalent Models of Microgrids for RMS Dynamic Simulation of Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.06160.pdf)
>  The high penetration of distributed renewable energy resources in power systems has changed their dynamic behavior, not only at the distribution level but also at the transmission levels. For analyses performed in this new reality of interconnected systems, a suitable equivalent model is required to represent the active dynamics of distribution systems. In this context, this paper proposes the application of a gray-box method to obtain an appropriate equivalent model for active distribution networks. From data measured at the point of common coupling, a trajectory sensitivity analysis is carried out to select the most important parameters of this equivalent model, which are then estimated by an evolutionary algorithm. The results show that the application of the sensitivity analysis can improve the quality of the parameter estimation process (since it focuses only on relevant parameters), enabling an efficient tuning of an equivalent ADN model.      
### 2.CSI Sensing and Feedback: A Semi-Supervised Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2110.06142.pdf)
>  Deep learning-based (DL-based) channel state information (CSI) feedback for a Massive multiple-input multiple-output (MIMO) system has proved to be a creative and efficient application. However, the existing systems ignored the wireless channel environment variation sensing, e.g., indoor and outdoor scenarios. Moreover, systems training requires excess pre-labeled CSI data, which is often unavailable. In this letter, to address these issues, we first exploit the rationality of introducing semi-supervised learning on CSI feedback, then one semi-supervised CSI sensing and feedback Network ($S^2$CsiNet) with three classifiers comparisons is proposed. Experiment shows that $S^2$CsiNet primarily improves the feasibility of the DL-based CSI feedback system by \textbf{\textit{indoor}} and \textbf{\textit{outdoor}} environment sensing and at most 96.2\% labeled dataset decreasing and secondarily boost the system performance by data distillation and latent information mining.      
### 3.EEG functional connectivity and deep learning for automatic diagnosis of brain disorders: Alzheimer's disease and schizophrenia  [ :arrow_down: ](https://arxiv.org/pdf/2110.06140.pdf)
>  Mental disorders are among the leading causes of disability worldwide. The first step in treating these conditions is to obtain an accurate diagnosis, but the absence of established clinical tests makes this task challenging. Machine learning algorithms can provide a possible solution to this problem, as we describe in this work. We present a method for the automatic diagnosis of mental disorders based on the matrix of connections obtained from EEG time series and deep learning. We show that our approach can classify patients with Alzheimer's disease and schizophrenia with a high level of accuracy. The comparison with the traditional cases, that use raw EEG time series, shows that our method provides the highest precision. Therefore, the application of deep neural networks on data from brain connections is a very promising method to the diagnosis of neurological disorders.      
### 4.Classification of anomalous gait using Machine Learning techniques and embedded sensors  [ :arrow_down: ](https://arxiv.org/pdf/2110.06139.pdf)
>  Human gait can be a predictive factor for detecting pathologies that affect human locomotion according to studies. In addition, it is known that a high investment is demanded in order to raise a traditional clinical infrastructure able to provide human gait examinations, making them unaffordable for economically vulnerable patients. In face of this scenario, this work proposes an accessible and modern solution composed of a wearable device, to acquire 3D-accelerometer and 3D-gyroscope measurements, and machine learning techniques to classify between distinct categories of induced gait disorders. In order to develop the proposed research, it was created a dataset with the target label being 4 distinct and balanced categories of anomalous gait. The machine learning techniques that achieved the best performances (in terms of accuracy) in this dataset were through the application of Principal Component Analysis algorithm following of a Support Vector Machines classifier (94 \%). Further, an architecture based on a Feedforward Neural Network yielded even better results (96 \%). Finally, it is also presented computational performance comparison between the models implemented.      
### 5.An Activity Recognition Framework for Continuous Monitoring of Non-Steady-State Locomotion of Individuals with Parkinson's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2110.06137.pdf)
>  Fundamental knowledge in activity recognition of individuals with motor disorders such as Parkinson's disease (PD) has been primarily limited to detection of steady-state/static tasks (sitting, standing, walking). To date, identification of non-steady-state locomotion on uneven terrains (stairs, ramps) has not received much attention. Furthermore, previous research has mainly relied on data from a large number of body locations which could adversely affect user convenience and system performance. Here, individuals with mild stages of PD and healthy subjects performed non-steady-state circuit trials comprising stairs, ramp, and changes of direction. An offline analysis using a linear discriminant analysis (LDA) classifier and a Long-Short Term Memory (LSTM) neural network was performed for task recognition. The performance of accelerographic and gyroscopic information from varied lower/upper-body segments were tested across a set of user-independent and user-dependent training paradigms. Comparing the F1 score of a given signal across classifiers showed improved performance using LSTM compared to LDA. Using LSTM, even a subset of information (e.g., feet data) in subject-independent training appeared to provide F1 score &gt; 0.8. However, employing LDA was shown to be at the expense of being limited to using a subject-dependent training and/or biomechanical data from multiple body locations. The findings could inform a number of applications in the field of healthcare monitoring and developing advanced lower-limb assistive devices by providing insights into classification schemes capable of handling non-steady-state and unstructured locomotion in individuals with mild Parkinson's disease.      
### 6.Fetal Gender Identification using Machine and Deep Learning Algorithms on Phonocardiogram Signals  [ :arrow_down: ](https://arxiv.org/pdf/2110.06131.pdf)
>  Phonocardiogram (PCG) signal analysis is a critical, widely-studied technology to noninvasively analyze the heart's mechanical activity. Through evaluating heart sounds, this technology has been chiefly leveraged as a preliminary solution to automatically diagnose Cardiovascular diseases among adults; however, prenatal tasks such as fetal gender identification have been relatively less studied using fetal Phonocardiography (FPCG). In this work, we apply common PCG signal processing techniques on the gender-tagged Shiraz University Fetal Heart Sounds Database and study the applicability of previously proposed features in classifying fetal gender using both Machine Learning and Deep Learning models. Even though PCG data acquisition's cost-effectiveness and feasibility make it a convenient method of Fetal Heart Rate (FHR) monitoring, the contaminated nature of PCG signals with the noise of various types makes it a challenging modality. To address this problem, we experimented with both static and adaptive noise reduction techniques such as Low-pass filtering, Denoising Autoencoders, and Source Separators. We apply a wide range of previously proposed classifiers to our dataset and propose a novel ensemble method of Fetal Gender Identification (FGI). Our method substantially outperformed the baseline and reached up to 91% accuracy in classifying fetal gender of unseen subjects.      
### 7.Spatial mixup: Directional loudness modification as data augmentation for sound event localization and detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.06126.pdf)
>  Data augmentation methods have shown great importance in diverse supervised learning problems where labeled data is scarce or costly to obtain. For sound event localization and detection (SELD) tasks several augmentation methods have been proposed, with most borrowing ideas from other domains such as images, speech, or monophonic audio. However, only a few exploit the spatial properties of a full 3D audio scene. We propose Spatial Mixup, as an application of parametric spatial audio effects for data augmentation, which modifies the directional properties of a multi-channel spatial audio signal encoded in the ambisonics domain. Similarly to beamforming, these modifications enhance or suppress signals arriving from certain directions, although the effect is less pronounced. Therefore enabling deep learning models to achieve invariance to small spatial perturbations. The method is evaluated with experiments in the DCASE 2021 Task 3 dataset, where spatial mixup increases performance over a non-augmented baseline, and compares to other well known augmentation methods. Furthermore, combining spatial mixup with other methods greatly improves performance.      
### 8.MEDUSA: Multi-scale Encoder-Decoder Self-Attention Deep Neural Network Architecture for Medical Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2110.06063.pdf)
>  Medical image analysis continues to hold interesting challenges given the subtle characteristics of certain diseases and the significant overlap in appearance between diseases. In this work, we explore the concept of self-attention for tackling such subtleties in and between diseases. To this end, we introduce MEDUSA, a multi-scale encoder-decoder self-attention mechanism tailored for medical image analysis. While self-attention deep convolutional neural network architectures in existing literature center around the notion of multiple isolated lightweight attention mechanisms with limited individual capacities being incorporated at different points in the network architecture, MEDUSA takes a significant departure from this notion by possessing a single, unified self-attention mechanism with significantly higher capacity with multiple attention heads feeding into different scales in the network architecture. To the best of the authors' knowledge, this is the first "single body, multi-scale heads" realization of self-attention and enables explicit global context amongst selective attention at different levels of representational abstractions while still enabling differing local attention context at individual levels of abstractions. With MEDUSA, we obtain state-of-the-art performance on multiple challenging medical image analysis benchmarks including COVIDx, RSNA RICORD, and RSNA Pneumonia Challenge when compared to previous work. Our MEDUSA model is publicly available.      
### 9.Auction-Based vs Continuous Clearing in Local Flexibility Markets with Block Bids  [ :arrow_down: ](https://arxiv.org/pdf/2110.06028.pdf)
>  Flexibility markets can be introduced as a tool for the distribution system operator (DSO) to avoid high costs and public opposition against new network investments. Continuous flexibility markets have the advantage of allowing more liquidity, which can be critical in the earlier stages of such markets, and can be operated closer to real-time, thereby enabling a better use of the latest forecasts; but, by design, they also result to a lower social welfare compared to auction-based markets. This paper has two main contributions. First, it introduces a continuous local flexibility market which includes both network constraints and asymmetric block bids. Second, it proposes an algorithm that can accurately determine the upper and lower bound of the social welfare loss compared with an auction-based clearing model.      
### 10.Word Order Does Not Matter For Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05994.pdf)
>  In this paper, we study training of automatic speech recognition system in a weakly supervised setting where the order of words in transcript labels of the audio training data is not known. We train a word-level acoustic model which aggregates the distribution of all output frames using LogSumExp operation and uses a cross-entropy loss to match with the ground-truth words distribution. Using the pseudo-labels generated from this model on the training set, we then train a letter-based acoustic model using Connectionist Temporal Classification loss. Our system achieves 2.4%/5.3% on test-clean/test-other subsets of LibriSpeech, which is competitive with the supervised baseline's performance.      
### 11.Phase Noise Resilient Three-Level Continuous-Phase Modulation for DFT-Spread OFDM  [ :arrow_down: ](https://arxiv.org/pdf/2110.05990.pdf)
>  A novel OFDM-based waveform with low peak-to-average power ratio (PAPR) and high robustness against phase noise (PN) is presented. It follows the discrete Fourier transform spread orthogonal frequency division multiplexing (DFT-s-OFDM) signal model. 3MSK, is inspired by continuous-phase frequency shift keying (FSK), but it uses three frequencies in the baseband model -- specifically, 0 and $\pm f_{symbol}/4$, where $f_{symbol}$ is the symbol rate -- which effectively constrains the phase transitions between consecutive symbols to 0 and $\pm \pi/2$ rad. Motivated by the phase controlled model of modulation, different degrees of phase continuity can be achieved, while supporting receiver processing with low complexity. The signal characteristics are improved by generating an initial time-domain nearly constant envelope signal at higher than the symbol rate. This helps to reach smooth phase transitions between 3MSK symbols. Also the possibility of using excess bandwidth is investigated by transmitting additional non-zero subcarriers outside active subcarriers of the basic DFT-s-OFDM model, which provides the capability to greatly reduce the PAPR. Due to the fact that the information is encoded in the phase transitions, a receiver model that tracks the phase variations without needing reference signals is developed. To this end, it is shown that this new modulation is well-suited for non-coherent receivers, even under strong phase noise (PN) conditions, thus allowing to reduce the overhead of reference signals. Evaluations of this physical-layer modulation and waveform scheme are performed in terms of transmitter metrics such as PAPR, OOB emissions and achievable output power after the power amplifier (PA). Finally, coded radio link evaluations are also shown and provided, demonstrating that 3MSK has a similar BER performance as that of traditional QPSK.      
### 12.Early Melanoma Diagnosis with Sequential Dermoscopic Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.05976.pdf)
>  Dermatologists often diagnose or rule out early melanoma by evaluating the follow-up dermoscopic images of skin lesions. However, existing algorithms for early melanoma diagnosis are developed using single time-point images of lesions. Ignoring the temporal, morphological changes of lesions can lead to misdiagnosis in borderline cases. In this study, we propose a framework for automated early melanoma diagnosis using sequential dermoscopic images. To this end, we construct our method in three steps. First, we align sequential dermoscopic images of skin lesions using estimated Euclidean transformations, extract the lesion growth region by computing image differences among the consecutive images, and then propose a spatio-temporal network to capture the dermoscopic changes from aligned lesion images and the corresponding difference images. Finally, we develop an early diagnosis module to compute probability scores of malignancy for lesion images over time. We collected 179 serial dermoscopic imaging data from 122 patients to verify our method. Extensive experiments show that the proposed model outperforms other commonly used sequence models. We also compared the diagnostic results of our model with those of seven experienced dermatologists and five registrars. Our model achieved higher diagnostic accuracy than clinicians (63.69% vs. 54.33%, respectively) and provided an earlier diagnosis of melanoma (60.7% vs. 32.7% of melanoma correctly diagnosed on the first follow-up images). These results demonstrate that our model can be used to identify melanocytic lesions that are at high-risk of malignant transformation earlier in the disease process and thereby redefine what is possible in the early detection of melanoma.      
### 13.Improving Character Error Rate Is Not Equal to Having Clean Speech: Speech Enhancement for ASR Systems with Black-box Acoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.05968.pdf)
>  A deep neural network (DNN)-based speech enhancement (SE) aiming to maximize the performance of an automatic speech recognition (ASR) system is proposed in this paper. In order to optimize the DNN-based SE model in terms of the character error rate (CER), which is one of the metric to evaluate the ASR system and generally non-differentiable, our method uses two DNNs: one for speech processing and one for mimicking the output CERs derived through an acoustic model (AM). Then both of DNNs are alternately optimized in the training phase. Even if the AM is a black-box, e.g., like one provided by a third-party, the proposed method enables the DNN-based SE model to be optimized in terms of the CER since the DNN mimicking the AM is differentiable. Consequently, it becomes feasible to build CER-centric SE model that has no negative effect, e.g., additional calculation cost and changing network architecture, on the inference phase since our method is merely a training scheme for the existing DNN-based methods. Experimental results show that our method improved CER by 7.3% relative derived through a black-box AM although certain noise levels are kept.      
### 14.Denoising Diffusion Gamma Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.05948.pdf)
>  Generative diffusion processes are an emerging and effective tool for image and speech generation. In the existing methods, the underlying noise distribution of the diffusion process is Gaussian noise. However, fitting distributions with more degrees of freedom could improve the performance of such generative models. In this work, we investigate other types of noise distribution for the diffusion process. Specifically, we introduce the Denoising Diffusion Gamma Model (DDGM) and show that noise from Gamma distribution provides improved results for image and speech generation. Our approach preserves the ability to efficiently sample state in the training diffusion process while using Gamma noise.      
### 15.Ambient Backscatter Communications in Mobile Networks: Crowd-Detectable Zero-Energy-Devices  [ :arrow_down: ](https://arxiv.org/pdf/2110.05927.pdf)
>  In this paper, we introduce the new concept of Crowd-Detectable Zero-Energy-Devices. Such devices harvest solar or ambient light energy to power themselves, backscatter ambient waves to communicate, and are detected simultaneously by a smartphone connected to the network, and the network itself, as long as the device is close to the considered smartphone. Such device is a promising sustainable solution for the future of the Internet of Things. We describe an example of use case: asset tracking with zero added energy, zero new signals and zero new infrastructure in the network, thanks to the anonymous and transparent participation of smartphones connected to the wireless network. We then present our first prototypes of such devices that backscatter TV, 4G and 5G signals, and show our first experiments in challenging conditions and environments.      
### 16.Joint Minimum DL-UL Rate Maximization for Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2110.05915.pdf)
>  In cell-free massive multiple-input multiple-output (MIMO) systems, the beamforming strategies at the base stations (BSs) and user equipments (UEs) can be computed building on bi-directional training. However, the precoding/decoding optimization in the downlink (DL) and in the uplink (UL) generally requires two separate bi-directional training phases, which can be wasteful in the case of short scheduling blocks. This paper proposes a framework to reduce the bi-directional training overhead by considering a common beamforming training strategy for both DL and UL when the UEs to be served in the two directions are the same. In doing so, we consider the problem of maximizing the (weighted) minimum DL-UL rate among all the UEs. Numerical results show that, in scenarios with short scheduling blocks, the proposed framework outperforms the case where the DL and UL beamforming strategies are computed individually via two separate bi-directional training phases thanks to the reduced training overhead. Even more substantial gains are observed with respect to the case with a single bi-directional training phase, where the DL (resp. UL) beamforming strategies are reused in the UL (resp. DL).      
### 17.Label-Aware Ranked Loss for robust People Counting using Automotive in-cabin Radar  [ :arrow_down: ](https://arxiv.org/pdf/2110.05876.pdf)
>  In this paper, we introduce the Label-Aware Ranked loss, a novel metric loss function. Compared to the state-of-the-art Deep Metric Learning losses, this function takes advantage of the ranked ordering of the labels in regression problems. To this end, we first show that the loss minimises when datapoints of different labels are ranked and laid at uniform angles between each other in the embedding space. Then, to measure its performance, we apply the proposed loss on a regression task of people counting with a short-range radar in a challenging scenario, namely a vehicle cabin. The introduced approach improves the accuracy as well as the neighboring labels accuracy up to 83.0% and 99.9%: An increase of 6.7%and 2.1% on state-of-the-art methods, respectively.      
### 18.Explicit CSI Feedback Compression via Learned Approximate Message Passing  [ :arrow_down: ](https://arxiv.org/pdf/2110.05837.pdf)
>  Explicit channel state information at the transmitter side is helpful to improve downlink precoding performance for multi-user MIMO systems. In order to reduce feedback signalling overhead, compression of Channel State Information (CSI) is essential. In this work different low complexity compressed sensing algorithms are compared in the context of an explicit CSI feedback scheme for 5G new radio. A neural network approach, based on learned approximate message passing for the computation of row-sparse solutions to matrix-valued compressed sensing problems is introduced. Due to extensive weight sharing, it shares the low memory footprint and fast evaluation of the forward pass with few iterations of a first order iterative algorithm. Furthermore it can be trained on purely synthetic data prior to deployment. Its performance in the explicit CSI feedback application is evaluated, and its key benefits in terms of computational complexity savings are discussed.      
### 19.Swish-Driven GoogleNet for Intelligent Analog Beam Selection in Terahertz Beamspace MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2110.05830.pdf)
>  In this paper, we propose an intelligent analog beam selection strategy in a terahertz (THz) band beamspace multiple-input multiple-output (MIMO) system. First inspired by transfer learning, we fine-tune the pre-trained off-the-shelf GoogleNet classifier, to learn analog beam selection as a multi-class mapping problem. Simulation results show 83% accuracy for the analog beam selection, which subsequently results in 12% spectral efficiency (SE) gain, upon the existing counterparts. Towards a more accurate classifier, we replace the conventional rectified linear unit (ReLU) activation function of the GoogleNet with the recently proposed Swish and retrain the fine-tuned GoogleNet to learn analog beam selection. It is numerically indicated that the fine-tuned Swish-driven GoogleNet achieves 86% accuracy, as well as 18% improvement in achievable SE, upon the similar schemes. Eventually, a strong ensembled classifier is developed to learn analog beam selection by sequentially training multiple fine-tuned Swish-driven GoogleNet classifiers. According to the simulations, the strong ensembled model is 90% accurate and yields 27% gain in achievable SE, in comparison with prior methods.      
### 20.SDWNet: A Straight Dilated Network with Wavelet Transformation for Image Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2110.05803.pdf)
>  Image deblurring is a classical computer vision problem that aims to recover a sharp image from a blurred image. To solve this problem, existing methods apply the Encode-Decode architecture to design the complex networks to make a good performance. However, most of these methods use repeated up-sampling and down-sampling structures to expand the receptive field, which results in texture information loss during the sampling process and some of them design the multiple stages that lead to difficulties with convergence. Therefore, our model uses dilated convolution to enable the obtainment of the large receptive field with high spatial resolution. Through making full use of the different receptive fields, our method can achieve better performance. On this basis, we reduce the number of up-sampling and down-sampling and design a simple network structure. Besides, we propose a novel module using the wavelet transform, which effectively helps the network to recover clear high-frequency texture details. Qualitative and quantitative evaluations of real and synthetic datasets show that our deblurring method is comparable to existing algorithms in terms of performance with much lower training requirements. The source code and pre-trained models are available at <a class="link-external link-https" href="https://github.com/FlyEgle/SDWNet" rel="external noopener nofollow">this https URL</a>.      
### 21.BERTraffic: A Robust BERT-Based Approach for Speaker Change Detection and Role Identification of Air-Traffic Communications  [ :arrow_down: ](https://arxiv.org/pdf/2110.05781.pdf)
>  Automatic Speech Recognition (ASR) is gaining special interest in Air Traffic Control (ATC). ASR allows transcribing the communications between air traffic controllers (ATCOs) and pilots. These transcriptions are used to extract ATC command types and named entities such as aircraft callsigns. One common problem is when the Speech Activity Detection (SAD) or diarization system fails and then two or more single speaker segments are in the same recording, jeopardizing the overall system's performance. We developed a system that combines the segmentation of a SAD module with a BERT-based model that performs Speaker Change Detection (SCD) and Speaker Role Identification (SRI) based on ASR transcripts (i.e., diarization + SRI). This research demonstrates on a real-life ATC test set that performing diarization directly on textual data surpass acoustic level diarization. The proposed model reaches up to ~0.90/~0.95 F1-score on ATCO/pilot for SRI on several test sets. The text-based diarization system brings a 27% relative improvement on Diarization Error Rate (DER) compared to standard acoustic-based diarization. These results were on ASR transcripts of a challenging ATC test set with an estimated ~13% word error rate, validating the approach's robustness even on noisy ASR transcripts.      
### 22.Role of Externally Provided Randomness in Stochastic Teams and Zero-sum Team Games  [ :arrow_down: ](https://arxiv.org/pdf/2110.05758.pdf)
>  Stochastic team decision problem is extensively studied in literature and the existence of optimal solution is obtained in recent literature. The value of information in statistical problem and decision theory is classical problem. Much of earlier does not qualitatively describe role of externally provided private and common randomness in stochastic team problem and team vs team zero sum game. <br>In this paper, we study the role of extrenally provided private or common randomness in stochastic team decision. We make observation that the randomness independent of environment does not benefit either team but randomness dependent on environment benefit teams and decreases the expected cost function. We also studied LQG team game with special information structure on private or common randomness. We extend these study to problem team vs team zero sum game. We show that if a game admits saddle point solution, then private or common randomness independent of environment does not benefit either team. We also analyze the scenario when a team with having more information than other team which is dependent on environment and game has saddle point solution, then team with more information benefits. This is also illustrated numerically for LQG team vs team zero sum game. Finally, we show for discrete team vs team zero sum game that private randomness independent of environment benefits team when there is no saddle point condition. Role of common randomness is discussed for discrete game.      
### 23.VarArray: Array-Geometry-Agnostic Continuous Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2110.05745.pdf)
>  Continuous speech separation using a microphone array was shown to be promising in dealing with the speech overlap problem in natural conversation transcription. This paper proposes VarArray, an array-geometry-agnostic speech separation neural network model. The proposed model is applicable to any number of microphones without retraining while leveraging the nonlinear correlation between the input channels. The proposed method adapts different elements that were proposed before separately, including transform-average-concatenate, conformer speech separation, and inter-channel phase differences, and combines them in an efficient and cohesive way. Large-scale evaluation was performed with two real meeting transcription tasks by using a fully developed transcription system requiring no prior knowledge such as reference segmentations, which allowed us to measure the impact that the continuous speech separation system could have in realistic settings. The proposed model outperformed a previous approach to array-geometry-agnostic modeling for all of the geometry configurations considered, achieving asclite-based speaker-agnostic word error rates of 17.5% and 20.4% for the AMI development and evaluation sets, respectively, in the end-to-end setting using no ground-truth segmentations.      
### 24.Global games with Poisson observations: Bio-inspired distributed coordination of multi-agent systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.05735.pdf)
>  Global games are a class of incomplete information games where the payoffs exhibit strategic complementarity leading to an incentive for the agents to coordinate their actions. Such games have been used to model scenarios in many socioeconomic phenomena, where the private signals available to the agents are typically assumed to be Gaussian. We study an instance of a global game where the agents observe Poisson random variables, which are inspired by applications in microbiology where information signals are disseminated via discrete molecular signals rather than continuous. Although this observation model violates the essential technical assumptions present in the Gaussian case, we present preliminary results on the existence of Bayesian Nash equilibria in pure threshold policies in two variants of the underlying random state-of-the-world: an arbitrarily distributed discrete binary state and a continuous state with uniform distribution.      
### 25.Joint 3-D Positioning and Power Allocation for UAV Relay Aided by Geographic Information  [ :arrow_down: ](https://arxiv.org/pdf/2110.05715.pdf)
>  In this paper, we study to employ geographic information to address the blockage problem of air-to-ground links between UAV and terrestrial nodes. In particular, a UAV relay is deployed to establish communication links from a ground base station to multiple ground users. To improve communication capacity, we first model the blockage effect caused by buildings according to the three-dimensional (3-D) geographic information. Then, an optimization problem is formulated to maximize the minimum capacity among users by jointly optimizing the 3-D position and power allocation of the UAV relay, under the constraints of link capacity, maximum transmit power, and blockage. To solve this complex non-convex problem, a two-loop optimization framework is developed based on Lagrangian relaxation. The outer-loop aims to obtain proper Lagrangian multipliers to ensure the solution of the Lagrangian problem converge to the tightest upper bound on the original problem. The inner-loop solves the Lagrangian problem by applying the block coordinate descent (BCD) and successive convex approximation (SCA) techniques, where UAV 3-D positioning and power allocation are alternately optimized in each iteration. Simulation results confirm that the proposed solution significantly outperforms two benchmark schemes and achieves a performance close to the upper bound on the UAV relay system.      
### 26.The Mirrornet : Learning Audio Synthesizer Controls Inspired by Sensorimotor Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2110.05695.pdf)
>  Experiments to understand the sensorimotor neural interactions in the human cortical speech system support the existence of a bidirectional flow of interactions between the auditory and motor regions. Their key function is to enable the brain to 'learn' how to control the vocal tract for speech production. This idea is the impetus for the recently proposed "MirrorNet", a constrained autoencoder architecture. In this paper, the MirrorNet is applied to learn, in an unsupervised manner, the controls of a specific audio synthesizer (DIVA) to produce melodies only from their auditory spectrograms. The results demonstrate how the MirrorNet discovers the synthesizer parameters to generate the melodies that closely resemble the original and those of unseen melodies, and even determine the best set parameters to approximate renditions of complex piano melodies generated by a different synthesizer. This generalizability of the MirrorNet illustrates its potential to discover from sensory data the controls of arbitrary motor-plants such as autonomous vehicles.      
### 27.Development of A Load Control Algorithm to Enhance Energy Sustainability for the International Space Station  [ :arrow_down: ](https://arxiv.org/pdf/2110.05678.pdf)
>  This paper presents a load control algorithm for control of energy sources and loads to enhance energy sustainability and reliability of the International Space Station (ISS), which is a large spacecraft in orbit around Earth. In this paper, the ISS electric power system was simulated in MATLAB/Simulink to be able to evaluate the performance of the developed algorithm in a simulated environment. This study also aims to emphasize the importance of load control algorithms on energy sustainability for critical systems, like ISS, having limited energy sources.      
### 28.Data-Driven Strictly Positive Real System Identification with prior System Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2110.05672.pdf)
>  Strictly Positive Real (SPR) transfer functions arise in many areas of engineering like passivity theory in circuit analysis and adaptive control to name a few. In many physical systems, it is possible to conclude that the system is Positive Real (PR) or SPR but system identification algorithms might produce estimates which are not SPR. In this paper, an algorithm to approximate frequency response data with SPR transfer functions using Generalized Orthonormal Basis Functions (GOBFs) is presented. Prior knowledge of the system helps us to get approximate pole locations, which can then be used to construct GOBFs. Next, a convex optimization problem will be formulated to obtain an estimate of the SPR transfer function.      
### 29.Adaptive Feedforward Reference Design for Active Vibration Rejection in Multi-Actuator Hard Disk Drives  [ :arrow_down: ](https://arxiv.org/pdf/2110.05669.pdf)
>  In December 2017, Seagate unveiled the Multi Actuator Technology to double the data performance of the future generation hard disk drives (HDD). This technology will equip drives with two dual stage actuators (DSA) each comprising of a voice coil motor (VCM) actuator and a piezoelectric micro actuator (MA) operating on the same pivot point. Each DSA is responsible for controlling half of the drive's arms. As both the DSAs operate independently on the same pivot timber, the control forces and torques generated by one can affect the operation of the other and thereby worsening the performance drastically. In this paper, a robust adaptive feedforward controller is designed as an add-on controller to an existing stabilizing feedback controller to reject the disturbances transferred through the common pivot timber by shaping the references to the VCM actuator and the total output of the dual stage system.      
### 30.Accurate and Generalizable Quantitative Scoring of Liver Steatosis from Ultrasound Images via Scalable Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05664.pdf)
>  Background &amp; Aims: Hepatic steatosis is a major cause of chronic liver disease. 2D ultrasound is the most widely used non-invasive tool for screening and monitoring, but associated diagnoses are highly subjective. We developed a scalable deep learning (DL) algorithm for quantitative scoring of liver steatosis from 2D ultrasound images. <br>Approach &amp; Results: Using retrospectively collected multi-view ultrasound data from 3,310 patients, 19,513 studies, and 228,075 images, we trained a DL algorithm to diagnose steatosis stages (healthy, mild, moderate, or severe) from ultrasound diagnoses. Performance was validated on two multi-scanner unblinded and blinded (initially to DL developer) histology-proven cohorts (147 and 112 patients) with histopathology fatty cell percentage diagnoses, and a subset with FibroScan diagnoses. We also quantified reliability across scanners and viewpoints. Results were evaluated using Bland-Altman and receiver operating characteristic (ROC) analysis. The DL algorithm demonstrates repeatable measurements with a moderate number of images (3 for each viewpoint) and high agreement across 3 premium ultrasound scanners. High diagnostic performance was observed across all viewpoints: area under the curves of the ROC to classify &gt;=mild, &gt;=moderate, =severe steatosis grades were 0.85, 0.90, and 0.93, respectively. The DL algorithm outperformed or performed at least comparably to FibroScan with statistically significant improvements for all levels on the unblinded histology-proven cohort, and for =severe steatosis on the blinded histology-proven cohort. <br>Conclusions: The DL algorithm provides a reliable quantitative steatosis assessment across view and scanners on two multi-scanner cohorts. Diagnostic performance was high with comparable or better performance than FibroScan.      
### 31.Nearest Subspace Search in The Signed Cumulative Distribution Transform Space for 1D Signal Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.05606.pdf)
>  This paper presents a new method to classify 1D signals using the signed cumulative distribution transform (SCDT). The proposed method exploits certain linearization properties of the SCDT to render the problem easier to solve in the SCDT space. The method uses the nearest subspace search technique in the SCDT domain to provide a non-iterative, effective, and simple to implement classification algorithm. Experiments show that the proposed technique outperforms the state-of-the-art neural networks using a very low number of training samples and is also robust to out-of-distribution examples on simulated data. We also demonstrate the efficacy of the proposed technique in real-world applications by applying it to an ECG classification problem. The python code implementing the proposed classifier can be found in PyTransKit (<a class="link-external link-https" href="https://github.com/rohdelab/PyTransKit" rel="external noopener nofollow">this https URL</a>).      
### 32.DeepFilterNet: A Low Complexity Speech Enhancement Framework for Full-Band Audio based on Deep Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2110.05588.pdf)
>  Complex-valued processing has brought deep learning-based speech enhancement and signal extraction to a new level. Typically, the process is based on a time-frequency (TF) mask which is applied to a noisy spectrogram, while complex masks (CM) are usually preferred over real-valued masks due to their ability to modify the phase. Recent work proposed to use a complex filter instead of a point-wise multiplication with a mask. This allows to incorporate information from previous and future time steps exploiting local correlations within each frequency band. In this work, we propose DeepFilterNet, a two stage speech enhancement framework utilizing deep filtering. First, we enhance the spectral envelope using ERB-scaled gains modeling the human frequency perception. The second stage employs deep filtering to enhance the periodic components of speech. Additionally to taking advantage of perceptual properties of speech, we enforce network sparsity via separable convolutions and extensive grouping in linear and recurrent layers to design a low complexity architecture. We further show that our two stage deep filtering approach outperforms complex masks over a variety of frequency resolutions and latencies and demonstrate convincing performance compared to other state-of-the-art models.      
### 33.SRU++: Pioneering Fast Recurrence with Attention for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05571.pdf)
>  The Transformer architecture has been well adopted as a dominant architecture in most sequence transduction tasks including automatic speech recognition (ASR), since its attention mechanism excels in capturing long-range dependencies. While models built solely upon attention can be better parallelized than regular RNN, a novel network architecture, SRU++, was recently proposed. By combining the fast recurrence and attention mechanism, SRU++ exhibits strong capability in sequence modeling and achieves near-state-of-the-art results in various language modeling and machine translation tasks with improved compute efficiency. In this work, we present the advantages of applying SRU++ in ASR tasks by comparing with Conformer across multiple ASR benchmarks and study how the benefits can be generalized to long-form speech inputs. On the popular LibriSpeech benchmark, our SRU++ model achieves 2.0% / 4.7% WER on test-clean / test-other, showing competitive performances compared with the state-of-the-art Conformer encoder under the same set-up. Specifically, SRU++ can surpass Conformer on long-form speech input with a large margin, based on our analysis.      
### 34.Improving Frequency Stability of Low-Inertia Systems using Virtual Induction Machine  [ :arrow_down: ](https://arxiv.org/pdf/2110.05568.pdf)
>  This paper presents a novel strategy for synchronization of grid-connected Voltage Source Converters (VSCs) in power systems with low rotational inertia. The proposed model is based on emulating the physical properties of an induction machine and capitalizes on its inherent grid-friendly properties such as self-synchronization, oscillation damping and standalone capabilities. A detailed mathematical model of an induction machine is derived, which includes the possibility of obtaining the unknown grid frequency by processing the voltage and current measurements at the converter output. This eliminates the need for the phase-locked loop unit, traditionally employed in grid-following VSC control schemes, while simultaneously preserving the applied system-level and device-level control. Furthermore, the appropriate steps for obtaining an index-1 DAE representation of the induction-machine-based synchronization unit within the VSC control scheme are provided. The EMT simulations validate the mathematical principles of the proposed model, whereas a small-signal analysis provides guidelines for appropriate control tuning and reveals interesting properties pertaining to the nature of the underlying operation mode.      
### 35.Perturbation Theory-Aided Learned Digital Back-Propagation Scheme for Optical Fiber Nonlinearity Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2110.05563.pdf)
>  Derived from the regular perturbation treatment of the nonlinear Schrodinger equation, a machine learning-based scheme to mitigate the intra-channel optical fiber nonlinearity is proposed. Referred to as the perturbation theory-aided (PA) learned digital back-propagation (LDBP), the proposed scheme constructs a deep neural network (DNN) in a way similar to the split-step Fourier method: linear and nonlinear operations alternate. Inspired by the perturbation analysis, the intra-channel cross-phase modulation term is conveniently represented by matrix operations in the DNN. The introduction of this term in each nonlinear operation considerably improves the performance, as well as enables the flexibility of PA-LDBP by adjusting the numbers of spans per step. The proposed scheme is evaluated by numerical simulations of a single carrier optical fiber communication system operating at 32 Gbaud with 64-quadrature amplitude modulation and 20*80 km transmission distance. The results show that the proposed scheme achieves approximately 3.5 dB, 1.8 dB, 1.4 dB, and 0.5 dB performance gain in terms of Q2 factor over the linear compensation, when the numbers of spans per step are 1, 2, 4, and 10, respectively. Two methods are proposed to reduce the complexity of PALDBP, i.e., pruning the number of perturbation coefficients and chromatic dispersion compensation in the frequency domain for multi-span per step cases. Investigation of the performance and complexity suggests that PA-LDBP attains improved performance gains with reduced complexity when compared to LDBP in the cases of 4 and 10 spans per step.      
### 36.Smoothed Separable Nonnegative Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2110.05528.pdf)
>  Given a set of data points belonging to the convex hull of a set of vertices, a key problem in data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point for each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by ALLS, we propose smoothed VCA (SVCA) and smoothed SPA (SSPA) that generalize VCA and SPA by assuming the presence of several nearby data points to each vertex. We illustrate the effectiveness of SVCA and SSPA over VCA, SPA and ALLS on synthetic data sets, and on the unmixing of hyperspectral images.      
### 37.Synergistic Offline-Online Control Synthesis via Local Gaussian Process Regression  [ :arrow_down: ](https://arxiv.org/pdf/2110.05525.pdf)
>  Autonomous systems often have complex and possibly unknown dynamics due to, e.g., black-box components. This leads to unpredictable behaviors and makes control design with performance guarantees a major challenge. This paper presents a data-driven control synthesis framework for such systems subject to linear temporal logic on finite traces (LTLf) specifications. The framework combines a baseline (offline) controller with a novel online controller and refinement procedure that improves the baseline guarantees as new data is collected. The baseline controller is computed offline on an uncertain abstraction constructed using Gaussian process (GP) regression on a given dataset. The offline controller provides a lower bound on the probability of satisfying the LTLf specification, which may be far from optimal due to both discretization and regression errors. The synergy arises from the online controller using the offline abstraction along with the current state and new data to choose the next best action. The online controller may improve the baseline guarantees since it avoids the discretization error and reduces regression error as new data is collected. The new data are also used to refine the abstraction and offline controller using local GP regression, which significantly reduces the computation overhead. Evaluations show the efficacy of the proposed offline-online framework, especially when compared against the offline controller.      
### 38.Towards formalization and monitoring of microscopic traffic parameters using temporal logic  [ :arrow_down: ](https://arxiv.org/pdf/2110.06208.pdf)
>  Smart cities are revolutionizing the transportation infrastructure by the integration of technology. However, ensuring that various transportation system components are operating as expected and in a safe manner is a great challenge. In this work, we propose the use of formal methods as a means to specify and reason about the traffic network's complex properties. Formal methods provide a flexible tool to define the safe operation of the traffic network by capturing non-conforming behavior, exploring various possible states of the traffic scene, and detecting any inconsistencies within it. Hence, we develop specification-based monitoring for the analysis of traffic networks using the formal language, Signal Temporal Logic. We develop monitors that identify safety-related behavior such as conforming to speed limits and maintaining appropriate headway. The framework is tested using a calibrated micro-simulated highway scenario and offline specification-based monitoring is applied to individual vehicle trajectories to understand whether they violate or satisfy the defined safety specifications. Statistical analysis of the outputs show that our approach can differentiate violating from conforming vehicle trajectories based on the defined specifications. This work can be utilized by traffic management centers to study the traffic stream properties, identify possible hazards, and provide valuable feedback for automating the traffic monitoring systems.      
### 39.Blind Modulo Analog-to-Digital Conversion of Vector Processes  [ :arrow_down: ](https://arxiv.org/pdf/2110.06183.pdf)
>  In a growing number of applications, there is a need to digitize a (possibly high) number of correlated signals whose spectral characteristics are challenging for traditional analog-to-digital converters (ADCs). Examples, among others, include multiple-input multiple-output systems where the ADCs must acquire at once several signals at a very wide but sparsely and dynamically occupied bandwidth supporting diverse services. In such scenarios, the resolution requirements can be prohibitively high. As an alternative, the recently proposed modulo-ADC architecture can in principle require dramatically fewer bits in the conversion to obtain the target fidelity, but requires that spatiotemporal information be known and explicitly taken into account by the analog and digital processing in the converter, which is frequently impractical. Building on our recent work, we address this limitation and develop a blind version of the architecture that requires no such knowledge in the converter. In particular, it features an automatic modulo-level adjustment and a fully adaptive modulo-decoding mechanism, allowing it to asymptotically match the characteristics of the unknown input signal. Simulation results demonstrate the successful operation of the proposed algorithm.      
### 40.M2GAN: A Multi-Stage Self-Attention Network for Image Rain Removal on Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2110.06164.pdf)
>  Image deraining is a new challenging problem in applications of autonomous vehicles. In a bad weather condition of heavy rainfall, raindrops, mainly hitting the vehicle's windshield, can significantly reduce observation ability even though the windshield wipers might be able to remove part of it. Moreover, rain flows spreading over the windshield can yield the physical effect of refraction, which seriously impede the sightline or undermine the machine learning system equipped in the vehicle. In this paper, we propose a new multi-stage multi-task recurrent generative adversarial network (M2GAN) to deal with challenging problems of raindrops hitting the car's windshield. This method is also applicable for removing raindrops appearing on a glass window or lens. M2GAN is a multi-stage multi-task generative adversarial network that can utilize prior high-level information, such as semantic segmentation, to boost deraining performance. To demonstrate M2GAN, we introduce the first real-world dataset for rain removal on autonomous vehicles. The experimental results show that our proposed method is superior to other state-of-the-art approaches of deraining raindrops in respect of quantitative metrics and visual quality. M2GAN is considered the first method to deal with challenging problems of real-world rains under unconstrained environments such as autonomous vehicles.      
### 41.COVID-19 Diagnosis from Cough Acoustics using ConvNets and Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.06123.pdf)
>  With the periodic rise and fall of COVID-19 and countries being inflicted by its waves, an efficient, economic, and effortless diagnosis procedure for the virus has been the utmost need of the hour. COVID-19 positive individuals may even be asymptomatic making the diagnosis difficult, but amongst the infected subjects, the asymptomatic ones need not be entirely free of symptoms caused by the virus. They might not show any observable symptoms like the symptomatic subjects, but they may differ from uninfected ones in the way they cough. These differences in the coughing sounds are minute and indiscernible to the human ear, however, these can be captured using machine learning-based statistical models. In this paper, we present a deep learning approach to analyze the acoustic dataset provided in Track 1 of the DiCOVA 2021 Challenge containing cough sound recordings belonging to both COVID-19 positive and negative examples. To perform the classification on the sound recordings as belonging to a COVID-19 positive or negative examples, we propose a ConvNet model. Our model achieved an AUC score percentage of 72.23 on the blind test set provided by the same for an unbiased evaluation of the models. The ConvNet model incorporated with Data Augmentation further increased the AUC-ROC percentage from 72.23 to 87.07. It also outperformed the DiCOVA 2021 Challenge's baseline model by 23% thus, claiming the top position on the DiCOVA 2021 Challenge leaderboard. This paper proposes the use of Mel frequency cepstral coefficients as the feature input for the proposed model.      
### 42.Improving the Performance of Automated Audio Captioning via Integrating the Acoustic and Semantic Information  [ :arrow_down: ](https://arxiv.org/pdf/2110.06100.pdf)
>  Automated audio captioning (AAC) has developed rapidly in recent years, involving acoustic signal processing and natural language processing to generate human-readable sentences for audio clips. The current models are generally based on the neural encoder-decoder architecture, and their decoder mainly uses acoustic information that is extracted from the CNN-based encoder. However, they have ignored semantic information that could help the AAC model to generate meaningful descriptions. This paper proposes a novel approach for automated audio captioning based on incorporating semantic and acoustic information. Specifically, our audio captioning model consists of two sub-modules. (1) The pre-trained keyword encoder utilizes pre-trained ResNet38 to initialize its parameters, and then it is trained by extracted keywords as labels. (2) The multi-modal attention decoder adopts an LSTM-based decoder that contains semantic and acoustic attention modules. Experiments demonstrate that our proposed model achieves state-of-the-art performance on the Clotho dataset. Our code can be found at <a class="link-external link-https" href="https://github.com/WangHelin1997/DCASE2021_Task6_PKU" rel="external noopener nofollow">this https URL</a>      
### 43.Cubature Kalman Filter Based Training of Hybrid Differential Equation Recurrent Neural Network Physiological Dynamic Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.06089.pdf)
>  Modeling biological dynamical systems is challenging due to the interdependence of different system components, some of which are not fully understood. To fill existing gaps in our ability to mechanistically model physiological systems, we propose to combine neural networks with physics-based models. Specifically, we demonstrate how we can approximate missing ordinary differential equations (ODEs) coupled with known ODEs using Bayesian filtering techniques to train the model parameters and simultaneously estimate dynamic state variables. As a study case we leverage a well-understood model for blood circulation in the human retina and replace one of its core ODEs with a neural network approximation, representing the case where we have incomplete knowledge of the physiological state dynamics. Results demonstrate that state dynamics corresponding to the missing ODEs can be approximated well using a neural network trained using a recursive Bayesian filtering approach in a fashion coupled with the known state dynamic differential equations. This demonstrates that dynamics and impact of missing state variables can be captured through joint state estimation and model parameter estimation within a recursive Bayesian state estimation (RBSE) framework. Results also indicate that this RBSE approach to training the NN parameters yields better outcomes (measurement/state estimation accuracy) than training the neural network with backpropagation through time in the same setting.      
### 44.Model reduction by least squares moment matching for linear and nonlinear systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.06072.pdf)
>  The paper addresses the model reduction problem for linear and nonlinear systems using the notion of least squares moment matching. For linear systems, the main idea is to approximate a transfer function by ensuring that the interpolation conditions imposed by moment matching are satisfied in a least squares sense. The paper revisits this idea using tools from output regulation theory to provide a new time-domain characterization of least squares moment matching. It is shown that least squares moment matching can be characterized in terms of an optimization problem involving an invariance equation and in terms of the steady-state behavior of an error system. This characterization, in turn, is then used to define a nonlinear enhancement of the notion of least squares moment matching and to develop a model reduction theory for nonlinear systems based on the notion of least squares moment matching. Parameterized families of models achieving least squares moment matching are determined both for linear and nonlinear systems. The new parameterizations are shown to admit natural geometric and system-theoretic interpretations. The theory is illustrated by worked-out numerical examples.      
### 45.Generalized Memory Approximate Message Passing  [ :arrow_down: ](https://arxiv.org/pdf/2110.06069.pdf)
>  Generalized approximate message passing (GAMP) is a promising technique for unknown signal reconstruction of generalized linear models (GLM). However, it requires that the transformation matrix has independent and identically distributed (IID) entries. In this context, generalized vector AMP (GVAMP) is proposed for general unitarily-invariant transformation matrices but it has a high-complexity matrix inverse. To this end, we propose a universal generalized memory AMP (GMAMP) framework including the existing orthogonal AMP/VAMP, GVAMP, and MAMP as special instances. Due to the characteristics that local processors are all memory, GMAMP requires stricter orthogonality to guarantee the asymptotic IID Gaussianity and state evolution. To satisfy such orthogonality, local orthogonal memory estimators are established. The GMAMP framework provides a new principle toward building new advanced AMP-type algorithms. As an example, we construct a Bayes-optimal GMAMP (BO-GMAMP), which uses a low-complexity memory linear estimator to suppress the linear interference, and thus its complexity is comparable to GAMP. Furthermore, we prove that for unitarily-invariant transformation matrices, BO-GMAMP achieves the replica minimum (i.e., Bayes-optimal) MSE if it has a unique fixed point.      
### 46.The Terminating-Knockoff Filter: Fast High-Dimensional Variable Selection with False Discovery Rate Control  [ :arrow_down: ](https://arxiv.org/pdf/2110.06048.pdf)
>  We propose the Terminating-Knockoff (T-Knock) filter, a fast variable selection method for high-dimensional data. The T-Knock filter controls a user-defined target false discovery rate (FDR) while maximizing the number of selected true positives. This is achieved by fusing the solutions of multiple early terminated random experiments. The experiments are conducted on a combination of the original data and multiple sets of randomly generated knockoff variables. A finite sample proof based on martingale theory for the FDR control property is provided. Numerical simulations show that the FDR is controlled at the target level while allowing for a high power. We prove under mild conditions that the knockoffs can be sampled from any univariate distribution. The computational complexity of the proposed method is derived and it is demonstrated via numerical simulations that the sequential computation time is multiple orders of magnitude lower than that of the strongest benchmark methods in sparse high-dimensional settings. The T-Knock filter outperforms state-of-the-art methods for FDR control on a simulated genome-wide association study (GWAS), while its computation time is more than two orders of magnitude lower than that of the strongest benchmark methods.      
### 47.Robust Glare Detection: Review, Analysis, and Dataset Release  [ :arrow_down: ](https://arxiv.org/pdf/2110.06006.pdf)
>  Sun Glare widely exists in the images captured by unmanned ground and aerial vehicles performing in outdoor environments. The existence of such artifacts in images will result in wrong feature extraction and failure of autonomous systems. Humans will try to adapt their view once they observe a glare (especially when driving), and this behavior is an essential requirement for the next generation of autonomous vehicles. The source of glare is not limited to the sun, and glare can be seen in the images captured during the nighttime and in indoor environments, which is due to the presence of different light sources; reflective surfaces also influence the generation of such artifacts. The glare's visual characteristics are different on images captured by various cameras and depend on several factors such as the camera's shutter speed and exposure level. Hence, it is challenging to introduce a general - robust and accurate - algorithm for glare detection that can perform well in various captured images. This research aims to introduce the first dataset for glare detection, which includes images captured by different cameras. Besides, the effect of multiple image representations and their combination in glare detection is examined using the proposed deep network architecture. The released dataset is available at <a class="link-external link-https" href="https://github.com/maesfahani/glaredetection" rel="external noopener nofollow">this https URL</a>      
### 48.Optimisation of Region of Attraction Estimates for the Exponential Stabilisation of the Intrinsic Geometrically Exact Beam Model  [ :arrow_down: ](https://arxiv.org/pdf/2110.06002.pdf)
>  A systematic approach to maximise estimates on the region of attraction in the exponential stabilisation of geometrically exact (nonlinear) beam models via boundary feedback is presented. Starting from recently established stability results based on Lyapunov arguments, the main contribution of the presented work is to maximise the analytically found bounds on the initial datum, for which local exponential stability is guaranteed, via search of (optimal) polynomial Lyapunov functionals using an iterative semi-definite programming approach.      
### 49.Network-Aware Flexibility Requests for Distribution-Level Flexibility Markets  [ :arrow_down: ](https://arxiv.org/pdf/2110.05983.pdf)
>  Local flexibility markets will become a central tool for distribution system operators (DSOs), who need to ensure a safe grid operation against increased costs and public opposition for new network investments. Despite extended recent literature on local flexibility markets, little attention has been paid on how to determine the flexibility request that the DSOs shall submit to such markets. Considering the constraints that the network introduces (e.g. line and voltage limits), so far it has been unclear how the DSO shall determine how much flexibility it requires and at which network locations. Addressing an open question for several DSOs, this paper introduces a method to design network-aware flexibility requests from a DSO perspective. We consider uncertainty, which could be the result of fluctuating renewable production or demand, and we compare our approach against a stochastic market clearing mechanism, which serves as a benchmark, deriving analytical conditions for their performance. We demonstrate our methods on a real German distribution grid.      
### 50.Frame-level multi-channel speaker verification with large-scale ad-hoc microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2110.05975.pdf)
>  Automatic speaker verification (ASV) with ad-hoc microphone arrays has received attention. Unlike traditional microphone arrays, the number of microphones and their spatial arrangement in an ad-hoc microphone array is unknown, which makes conventional multi-channel ASV techniques ineffective in ad-hoc microphone array settings. Recently, an utterance-level ASV with ad-hoc microphone arrays has been proposed, which first extracts utterance-level speaker embeddings from each channel of an ad-hoc microphone array, and then fuses the embeddings for the final verification. However, this method cannot make full use of the cross-channel information. In this paper, we present a novel multi-channel ASV model at the frame-level. Specifically, we add spatio-temporal processing blocks (STB) before the pooling layer, which models the contextual relationship within and between channels and across time, respectively. The channel-attended outputs from STB are sent to the pooling layer to obtain an utterance-level speaker representation. Experimental results demonstrate the effectiveness of the proposed method.      
### 51.Multi-channel Narrow-Band Deep Speech Separation with Full-band Permutation Invariant Training  [ :arrow_down: ](https://arxiv.org/pdf/2110.05966.pdf)
>  This paper addresses the problem of multi-channel multi-speech separation based on deep learning techniques. In the short time Fourier transform domain, we propose an end-to-end narrow-band network that directly takes as input the multi-channel mixture signals of one frequency, and outputs the separated signals of this frequency. In narrow-band, the spatial information (or inter-channel difference) can well discriminate between speakers at different positions. This information is intensively used in many narrow-band speech separation methods, such as beamforming and clustering of spatial vectors. The proposed network is trained to learn a rule to automatically exploit this information and perform speech separation. Such a rule should be valid for any frequency, thence the network is shared by all frequencies. In addition, a full-band permutation invariant training criterion is proposed to solve the frequency permutation problem encountered by most narrow-band methods. Experiments show that, by focusing on deeply learning the narrow-band information, the proposed method outperforms the oracle beamforming method and the state-of-the-art deep learning based method.      
### 52.C3PU: Cross-Coupling Capacitor Processing Unit Using Analog-Mixed Signal In-Memory Computing for AI Inference  [ :arrow_down: ](https://arxiv.org/pdf/2110.05947.pdf)
>  This paper presents a novel cross-coupling capacitor processing unit (C3PU) that supports analog-mixed signal in memory computing to perform multiply-and-accumulate (MAC) operations. The C3PU consists of a capacitive unit, a CMOS transistor, and a voltage-to-time converter (VTC). The capacitive unit serves as a computational element that holds the multiplier operand and performs multiplication once the multiplicand is applied at the terminal. The multiplicand is the input voltage that is converted to a pulse width signal using a low power VTC. The transistor transfers this multiplication where a voltage level is generated. A demonstrator of 5x4 C3PU array that is capable of implementing 4 MAC units is presented. The design has been verified using Monte Carlo simulation in 65 nm technology. The 5x4 C3PU consumed energy of 66.4 fJ/MAC at 0.3 V voltage supply with an error of 5.7%. The proposed unit achieves lower energy and occupies a smaller area by 3.4x and 3.6x, respectively, with similar error value when compared to a digital-based 8x4-bit fixed point MAC unit. The C3PU has been utilized through an iris fower classification utilizing an artificial neural network which achieved a 90% classification accuracy compared to ideal accuracy of 96.67% using MATLAB.      
### 53.Rank-based loss for learning hierarchical representations  [ :arrow_down: ](https://arxiv.org/pdf/2110.05941.pdf)
>  Hierarchical taxonomies are common in many contexts, and they are a very natural structure humans use to organise information. In machine learning, the family of methods that use the 'extra' information is called hierarchical classification. However, applied to audio classification, this remains relatively unexplored. Here we focus on how to integrate the hierarchical information of a problem to learn embeddings representative of the hierarchical relationships. Previously, triplet loss has been proposed to address this problem, however it presents some issues like requiring the careful construction of the triplets, and being limited in the extent of hierarchical information it uses at each iteration. In this work we propose a rank based loss function that uses hierarchical information and translates this into a rank ordering of target distances between the examples. We show that rank based loss is suitable to learn hierarchical representations of the data. By testing on unseen fine level classes we show that this method is also capable of learning hierarchically correct representations of the new classes. Rank based loss has two promising aspects, it is generalisable to hierarchies with any number of levels, and is capable of dealing with data with incomplete hierarchical labels.      
### 54.Intelligent Players in a Fictitious Play Framework  [ :arrow_down: ](https://arxiv.org/pdf/2110.05939.pdf)
>  Fictitious play is a popular learning algorithm in which players that utilize the history of actions played by the players and the knowledge of their own payoff matrix can converge to the Nash equilibrium under certain conditions on the game. We consider the presence of an intelligent player that has access to the entire payoff matrix for the game. We show that by not conforming to fictitious play, such a player can achieve a better payoff than the one at the Nash Equilibrium. This result can be viewed both as a fragility of the fictitious play algorithm to a strategic intelligent player and an indication that players should not throw away additional information they may have, as suggested by classical fictitious play.      
### 55.Energy-cost aware off-grid base stations with IoT devices for developing a green heterogeneous network  [ :arrow_down: ](https://arxiv.org/pdf/2110.05906.pdf)
>  Heterogeneous network (HetNet) is a specified cellular platform to tackle the rapidly growing anticipated data traffic. From communications perspective, data loads can be mapped to energy loads that are generally placed on the operator networks. Meanwhile, renewable energy aided networks offer to curtail fossil fuel consumption, so to reduce environmental pollution. This paper proposes a renewable energy based power supply architecture for off-grid HetNet using a novel energy sharing model. Solar photovoltaic (PV) along with sufficient energy storage devices are used for each macro, micro, pico, or femto base station (BS). Additionally, biomass generator (BG) is used for macro and micro BSs. The collocated macro and micro BSs are connected through end-to-end resistive lines. A novel weighted proportional-fair resource-scheduling algorithm with sleep mechanisms is proposed for non-real time (NRT) applications by trading-off the power consumption and communication delays. Furthermore, the proposed algorithm with extended discontinuous reception (eDRX) and power saving mode (PSM) for narrowband internet of things (IoT) applications extends battery lifetime for IoT devices. HOMER optimization software is used to perform optimal system architecture, economic, and carbon footprint analyses while Monte-Carlo simulation tool is used for evaluating the throughput and energy efficiency performances. The proposed algorithms are valid for the practical data of the rural areas. We demonstrate the proposed power supply architecture is energy-efficient, cost-effective, reliable, and eco-friendly.      
### 56.Video Is Graph: Structured Graph Module for Video Action Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05904.pdf)
>  In the field of action recognition, video clips are always treated as ordered frames for subsequent processing. To achieve spatio-temporal perception, existing approaches propose to embed adjacent temporal interaction in the convolutional layer. The global semantic information can therefore be obtained by stacking multiple local layers hierarchically. However, such global temporal accumulation can only reflect the high-level semantics in deep layers, neglecting the potential low-level holistic clues in shallow layers. In this paper, we first propose to transform a video sequence into a graph to obtain direct long-term dependencies among temporal frames. To preserve sequential information during transformation, we devise a structured graph module (SGM), achieving fine-grained temporal interactions throughout the entire network. In particular, SGM divides the neighbors of each node into several temporal regions so as to extract global structural information with diverse sequential flows. Extensive experiments are performed on standard benchmark datasets, i.e., Something-Something V1 &amp; V2, Diving48, Kinetics-400, UCF101, and HMDB51. The reported performance and analysis demonstrate that SGM can achieve outstanding precision with less computational complexity.      
### 57.Sanctuary lost: a cyber-physical warfare in space  [ :arrow_down: ](https://arxiv.org/pdf/2110.05878.pdf)
>  Over the last decades, space has grown from a purely scientific struggle, fueled by the desire to demonstrate superiority of one regime over the other, to an anchor point of the economies of essentially all developed countries. Many businesses depend crucially on satellite communication or data acquisition, not only for defense purposes, but increasingly also for day-to-day applications. However, although so far space faring nations refrained from extending their earth-bound conflicts into space, this critical infrastructure is not as invulnerable as common knowledge suggests. In this paper, we analyze the threats space vehicles are exposed to and what must change to mitigate them. In particular, we shall focus on cyber threats, which may well be mounted by small countries and terrorist organizations, whose incentives do not necessarily include sustainability of the space domain and who may not be susceptible to the threat of mutual retaliation on the ground. We survey incidents, highlight threats and raise awareness from general preparedness for accidental faults, which is already widely spread within the space community, to preparedness and tolerance of both accidental and malicious faults (such as targeted attacks by cyber terrorists and nation-state hackers).      
### 58.Modelling and analysis of offshore energy hubs  [ :arrow_down: ](https://arxiv.org/pdf/2110.05868.pdf)
>  Clean, multi-carrier Offshore Energy Hubs (OEHs) may become pivotal for efficient offshore wind power generation and distribution. In addition, OEHs may provide decarbonised energy supply for maritime transport, oil and gas recovery, and offshore farming while also enabling conversion and temporary storage of liquefied decarbonised energy carriers for export. Here, we investigate the role of OEHs in the transition of the Norwegian continental shelf energy system towards zero-emission energy supply. We develop a mixed-integer linear programming model for investment planning and operational optimisation to achieve decarbonisation at minimum costs. We consider clean technologies, including offshore wind, offshore solar, OEHs and subsea cables. We conduct sensitivity analysis on CO$_2$ tax, CO$_2$ budget and the capacity of power from shore. The results show that (a) a hard carbon cap is necessary for stimulating a zero-emission offshore energy system; (b) offshore wind integration and power from shore can more than halve current emissions, but OEHs with storage are necessary for zero-emission production and (c) at certain CO$_2$ tax levels, the system with OEHs can potentially reduce CO$_2$ emissions by 50% and energy losses by 10%, compared to a system with only offshore renewables, gas turbines and power from shore.      
### 59.MetricGAN-U: Unsupervised speech enhancement/ dereverberation based only on noisy/ reverberated speech  [ :arrow_down: ](https://arxiv.org/pdf/2110.05866.pdf)
>  Most of the deep learning-based speech enhancement models are learned in a supervised manner, which implies that pairs of noisy and clean speech are required during training. Consequently, several noisy speeches recorded in daily life cannot be used to train the model. Although certain unsupervised learning frameworks have also been proposed to solve the pair constraint, they still require clean speech or noise for training. Therefore, in this paper, we propose MetricGAN-U, which stands for MetricGAN-unsupervised, to further release the constraint from conventional unsupervised learning. In MetricGAN-U, only noisy speech is required to train the model by optimizing non-intrusive speech quality metrics. The experimental results verified that MetricGAN-U outperforms baselines in both objective and subjective metrics.      
### 60.A bridge between features and evidence for binary attribute-driven perfect privacy  [ :arrow_down: ](https://arxiv.org/pdf/2110.05840.pdf)
>  Attribute-driven privacy aims to conceal a single user's attribute, contrary to anonymisation that tries to hide the full identity of the user in some data. When the attribute to protect from malicious inferences is binary, perfect privacy requires the log-likelihood-ratio to be zero resulting in no strength-of-evidence. This work presents an approach based on normalizing flow that maps a feature vector into a latent space where the strength-of-evidence, related to the binary attribute, and an independent residual are disentangled. It can be seen as a non-linear discriminant analysis where the mapping is invertible allowing generation by mapping the latent variable back to the original space. This framework allows to manipulate the log-likelihood-ratio of the data and thus to set it to zero for privacy. We show the applicability of the approach on an attribute-driven privacy task where the sex information is removed from speaker embeddings. Results on VoxCeleb2 dataset show the efficiency of the method that outperforms in terms of privacy and utility our previous experiments based on adversarial disentanglement.      
### 61.Covariance-Based Joint Device Activity and Delay Detection in Asynchronous mMTC  [ :arrow_down: ](https://arxiv.org/pdf/2110.05815.pdf)
>  In this letter, we study the joint device activity and delay detection problem in asynchronous massive machine-type communications (mMTC), where all active devices asynchronously transmit their preassigned preamble sequences to the base station (BS) for device identification and delay detection. We first formulate this joint detection problem as a maximum likelihood estimation problem, which depends on the received signal only through its sample covariance, and then propose efficient coordinate descent type of algorithms to solve the formulated problem. Our proposed covariance-based approach is sharply different from the existing compressed sensing (CS) approach for the same problem. Numerical results show that our proposed covariance-based approach significantly outperforms the CS approach in terms of the detection performance since our proposed approach can make better use of the BS antennas than the CS approach.      
### 62.Adapting TTS models For New Speakers using Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05798.pdf)
>  Training neural text-to-speech (TTS) models for a new speaker typically requires several hours of high quality speech data. Prior works on voice cloning attempt to address this challenge by adapting pre-trained multi-speaker TTS models for a new voice, using a few minutes of speech data of the new speaker. However, publicly available large multi-speaker datasets are often noisy, thereby resulting in TTS models that are not suitable for use in products. We address this challenge by proposing transfer-learning guidelines for adapting high quality single-speaker TTS models for a new speaker, using only a few minutes of speech data. We conduct an extensive study using different amounts of data for a new speaker and evaluate the synthesized speech in terms of naturalness and voice/style similarity to the target speaker. We find that fine-tuning a single-speaker TTS model on just 30 minutes of data, can yield comparable performance to a model trained from scratch on more than 27 hours of data for both male and female target speakers.      
### 63.Zero-bias Deep Neural Network for Quickest RF Signal Surveillance  [ :arrow_down: ](https://arxiv.org/pdf/2110.05797.pdf)
>  The Internet of Things (IoT) is reshaping modern society by allowing a decent number of RF devices to connect and share information through RF channels. However, such an open nature also brings obstacles to surveillance. For alleviation, a surveillance oracle, or a cognitive communication entity needs to identify and confirm the appearance of known or unknown signal sources in real-time. In this paper, we provide a deep learning framework for RF signal surveillance. Specifically, we jointly integrate the Deep Neural Networks (DNNs) and Quickest Detection (QD) to form a sequential signal surveillance scheme. We first analyze the latent space characteristic of neural network classification models, and then we leverage the response characteristics of DNN classifiers and propose a novel method to transform existing DNN classifiers into performance-assured binary abnormality detectors. In this way, we seamlessly integrate the DNNs with the parametric quickest detection. Finally, we propose an enhanced Elastic Weight Consolidation (EWC) algorithm with better numerical stability for DNNs in signal surveillance systems to evolve incrementally, we demonstrate that the zero-bias DNN is superior to regular DNN models considering incremental learning and decision fairness. We evaluated the proposed framework using real signal datasets and we believe this framework is helpful in developing a trustworthy IoT ecosystem.      
### 64.Uplink Performance of Cell-Free Massive MIMO Over Spatially Correlated Rician Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2110.05796.pdf)
>  We consider a practical cell-free massive multiple-input-multiple-output (MIMO) system with multi-antenna access points (APs) and spatially correlated Rician fading channels. The significant phase-shift of the line-of-sight component induced by the user equipment movement is modeled randomly. Furthermore, we investigate the uplink spectral efficiency (SE) with maximum ratio (MR)/local minimum mean squared error (L-MMSE) combining and optimal large-scale fading decoding based on the phase-aware MMSE, phase-aware element-wise MMSE and linear MMSE (LMMSE) estimators. Then new closed-form SE expressions with MR combining are derived. Numerical results validate our derived expressions and show that the SE benefits from the spatial correlation. It is important to observe that the performance gap between L-MMSE and MR combining increases with the number of antennas per AP and the SE of the LMMSE estimator is lower than that of other estimators due to the lack of phase-shifts knowledge.      
### 65.Large-scale Self-Supervised Speech Representation Learning for Automatic Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2110.05777.pdf)
>  The speech representations learned from large-scale unlabeled data have shown better generalizability than those from supervised learning and thus attract a lot of interest to be applied for various downstream tasks. In this paper, we explore the limits of speech representations learned by different self-supervised objectives and datasets for automatic speaker verification (ASV), especially with a well-recognized SOTA ASV model, ECAPA-TDNN [1], as a downstream model. The representations from all hidden layers of the pre-trained model are firstly averaged with learnable weights and then fed into the ECAPA-TDNN as input features. The experimental results on Voxceleb dataset show that the weighted average representation is significantly superior to FBank, a conventional handcrafted feature for ASV. Our best single system achieves 0.564%, 0.561%, and 1.230% equal error rate (EER) on the three official trials of VoxCeleb1, separately. Accordingly, the ensemble system with three pre-trained models can further improve the EER to 0.431%, 0.507% and 1.081%. Among the three evaluation trials, our best system outperforms the winner system [2] of the VoxCeleb Speaker Recognition Challenge 2021 (VoxSRC2021) on the VoxCeleb1-E trial.      
### 66.Music Sentiment Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2110.05765.pdf)
>  Music sentiment transfer is a completely novel task. Sentiment transfer is a natural evolution of the heavily-studied style transfer task, as sentiment transfer is rooted in applying the sentiment of a source to be the new sentiment for a target piece of media; yet compared to style transfer, sentiment transfer has been only scantily studied on images. Music sentiment transfer attempts to apply the high level objective of sentiment transfer to the domain of music. We propose CycleGAN to bridge disparate domains. In order to use the network, we choose to use symbolic, MIDI, data as the music format. Through the use of a cycle consistency loss, we are able to create one-to-one mappings that preserve the content and realism of the source data. Results and literature suggest that the task of music sentiment transfer is more difficult than image sentiment transfer because of the temporal characteristics of music and lack of existing datasets.      
### 67.UniSpeech-SAT: Universal Speech Representation Learning with Speaker Aware Pre-Training  [ :arrow_down: ](https://arxiv.org/pdf/2110.05752.pdf)
>  Self-supervised learning (SSL) is a long-standing goal for speech processing, since it utilizes large-scale unlabeled data and avoids extensive human labeling. Recent years witness great successes in applying self-supervised learning in speech recognition, while limited exploration was attempted in applying SSL for modeling speaker characteristics. In this paper, we aim to improve the existing SSL framework for speaker representation learning. Two methods are introduced for enhancing the unsupervised speaker information extraction. First, we apply the multi-task learning to the current SSL framework, where we integrate the utterance-wise contrastive loss with the SSL objective function. Second, for better speaker discrimination, we propose an utterance mixing strategy for data augmentation, where additional overlapped utterances are created unsupervisely and incorporate during training. We integrate the proposed methods into the HuBERT framework. Experiment results on SUPERB benchmark show that the proposed system achieves state-of-the-art performance in universal representation learning, especially for speaker identification oriented tasks. An ablation study is performed verifying the efficacy of each proposed method. Finally, we scale up training dataset to 94 thousand hours public audio data and achieve further performance improvement in all SUPERB tasks.      
### 68.Foster Strengths and Circumvent Weaknesses: a Speech Enhancement Framework with Two-branch Collaborative Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05713.pdf)
>  Recent single-channel speech enhancement methods usually convert waveform to the time-frequency domain and use magnitude/complex spectrum as the optimizing target. However, both magnitude-spectrum-based methods and complex-spectrum-based methods have their respective pros and cons. In this paper, we propose a unified two-branch framework to foster strengths and circumvent weaknesses of different paradigms. The proposed framework could take full advantage of the apparent spectral regularity in magnitude spectrogram and break the bottleneck that magnitude-based methods have suffered. Within each branch, we use collaborative expert block and its variants as substitutes for regular convolution layers. Experiments on TIMIT benchmark demonstrate that our method is superior to existing state-of-the-art ones.      
### 69.Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2110.05706.pdf)
>  This paper unifies the multi-focus images fusion (MFIF) and blind super resolution (SR) problems as the multi-focus image super resolution fusion (MFISRF) task, and proposes a novel unified dataset-free unsupervised framework named deep fusion prior (DFP) to address such MFISRF task. DFP consists of SKIPnet network, DoubleReblur focus measurement tactic, decision embedding module and loss functions. In particular, DFP can obtain MFISRF only from two low-resolution inputs without any extent dataset; SKIPnet implementing unsupervised learning via deep image prior is an end-to-end generated network acting as the engine of DFP; DoubleReblur is used to determine the primary decision map without learning but based on estimated PSF and Gaussian kernels convolution; decision embedding module optimizes the decision map via learning; and DFP losses composed of content loss, joint gradient loss and gradient limit loss can obtain high-quality MFISRF results robustly. Experiments have proved that our proposed DFP approaches and even outperforms those state-of-art MFIF and SR method combinations. Additionally, DFP is a general framework, thus its networks and focus measurement tactics can be continuously updated to further improve the MFISRF performance. DFP codes are open source and will be available soon at <a class="link-external link-http" href="http://github.com/GuYuanjie/DeepFusionPrior" rel="external noopener nofollow">this http URL</a>.      
### 70.Review of Kernel Learning for Intra-Hour Solar Forecasting with Infrared Sky Images and Cloud Dynamic Feature Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2110.05622.pdf)
>  The uncertainty of the energy generated by photovoltaic systems incurs an additional cost for a guaranteed, reliable supply of energy (i.e., energy storage). This investigation aims to decrease the additional cost by introducing probabilistic multi-task intra-hour solar forecasting (feasible in real time applications) to increase the penetration of photovoltaic systems in power grids. The direction of moving clouds is estimated in consecutive sequences of sky images by extracting features of cloud dynamics with the objective of forecasting the global solar irradiance that reaches photovoltaic systems. The sky images are acquired using a low-cost infrared sky imager mounted on a solar tracker. The solar forecasting algorithm is based on kernel learning methods, and uses the clear sky index as predictor and features extracted from clouds as feature vectors. The proposed solar forecasting algorithm achieved 16.45\% forecasting skill 8 minutes ahead with a resolution of 15 seconds. In contrast, previous work reached 15.4\% forecasting skill with the resolution of 1 minute. Therefore, this solar forecasting algorithm increases the performances with respect to the state-of-the-art, providing grid operators with the capability of managing the inherent uncertainties of power grids with a high penetration of photovoltaic systems.      
### 71.Signal Processing on Cell Complexes  [ :arrow_down: ](https://arxiv.org/pdf/2110.05614.pdf)
>  The processing of signals supported on non-Euclidean domains has attracted large interest in the last years. Thus far, such non-Euclidean domains have been abstracted primarily as graphs with signals supported on the nodes, though recently the processing of signals on more general structures such as simplicial complexes has also been considered. In this paper, we give an introduction to signal processing on (abstract) regular cell complexes, which provide a unifying framework encompassing graphs, simplicial complexes, cubical complexes and various meshes as special cases. We discuss how appropriate Hodge Laplacians for these cell complexes can be derived. These Hodge Laplacians enable the construction of convolutional filters, which can be employed in linear filtering and non-linear filtering via neural networks defined on cell complexes.      
### 72.Partial Variable Training for Efficient On-Device Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05607.pdf)
>  This paper aims to address the major challenges of Federated Learning (FL) on edge devices: limited memory and expensive communication. We propose a novel method, called Partial Variable Training (PVT), that only trains a small subset of variables on edge devices to reduce memory usage and communication cost. With PVT, we show that network accuracy can be maintained by utilizing more local training steps and devices, which is favorable for FL involving a large population of devices. According to our experiments on two state-of-the-art neural networks for speech recognition and two different datasets, PVT can reduce memory usage by up to 1.9$\times$ and communication cost by up to 593$\times$ while attaining comparable accuracy when compared with full network training.      
### 73.A caster-wheel-aware MPC-based motion planner for mobile robotics  [ :arrow_down: ](https://arxiv.org/pdf/2110.05604.pdf)
>  Differential drive mobile robots often use one or more caster wheels for balance. Caster wheels are appreciated for their ability to turn in any direction almost on the spot, allowing the robot to do the same and thereby greatly simplifying the motion planning and control. However, in aligning the caster wheels to the intended direction of motion they produce a so-called bore torque. As a result, additional motor torque is required to move the robot, which may in some cases exceed the motor capacity or compromise the motion planner's accuracy. Instead of taking a decoupled approach, where the navigation and disturbance rejection algorithms are separated, we propose to embed the caster wheel awareness into the motion planner. To do so, we present a caster-wheel-aware term that is compatible with MPC-based control methods, leveraging the existence of caster wheels in the motion planning stage. As a proof of concept, this term is combined with a a model-predictive trajectory tracking controller. Since this method requires knowledge of the caster wheel angle and rolling speed, an observer that estimates these states is also presented. The efficacy of the approach is shown in experiments on an intralogistics robot and compared against a decoupled bore-torque reduction approach and a caster-wheel agnostic controller. Moreover, the experiments show that the presented caster wheel estimator performs sufficiently well and therefore avoids the need for additional sensors.      
### 74.Evaluation of Latent Space Disentanglement in the Presence of Interdependent Attributes  [ :arrow_down: ](https://arxiv.org/pdf/2110.05587.pdf)
>  Controllable music generation with deep generative models has become increasingly reliant on disentanglement learning techniques. However, current disentanglement metrics, such as mutual information gap (MIG), are often inadequate and misleading when used for evaluating latent representations in the presence of interdependent semantic attributes often encountered in real-world music datasets. In this work, we propose a dependency-aware information metric as a drop-in replacement for MIG that accounts for the inherent relationship between semantic attributes.      
### 75.vocadito: A dataset of solo vocals with $f_0$, note, and lyric annotations  [ :arrow_down: ](https://arxiv.org/pdf/2110.05580.pdf)
>  To compliment the existing set of datasets, we present a small dataset entitled vocadito, consisting of 40 short excerpts of monophonic singing, sung in 7 different languages by singers with varying of levels of training, and recorded on a variety of devices. We provide several types of annotations, including $f_0$, lyrics, and two different note annotations. All annotations were created by musicians. We provide an analysis of the differences between the two note annotations, and see that the agreement level is low, which has implications for evaluating vocal note estimation algorithms. We also analyze the relation between the $f_0$ and note annotations, and show that quantizing $f_0$ values in frequency does not provide a reasonable note estimate, reinforcing the difficulty of the note estimation task for singing voice. Finally, we provide baseline results from recent algorithms on vocadito for note and $f_0$ transcription. Vocadito is made freely available for public use.      
### 76.UrbanNet: Leveraging Urban Maps for Long Range 3D Object Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.05561.pdf)
>  Relying on monocular image data for precise 3D object detection remains an open problem, whose solution has broad implications for cost-sensitive applications such as traffic monitoring. We present UrbanNet, a modular architecture for long range monocular 3D object detection with static cameras. Our proposed system combines commonly available urban maps along with a mature 2D object detector and an efficient 3D object descriptor to accomplish accurate detection at long range even when objects are rotated along any of their three axes. We evaluate UrbanNet on a novel challenging synthetic dataset and highlight the advantages of its design for traffic detection in roads with changing slope, where the flat ground approximation does not hold. Data and code are available at <a class="link-external link-https" href="https://github.com/TRAILab/UrbanNet" rel="external noopener nofollow">this https URL</a>      
### 77.Addressing crash-imminent situations caused by human driven vehicle errors in a mixed traffic stream: a model-based reinforcement learning approach for CAV  [ :arrow_down: ](https://arxiv.org/pdf/2110.05556.pdf)
>  It is anticipated that the era of fully autonomous vehicle operations will be preceded by a lengthy "Transition Period" where the traffic stream will be mixed, that is, consisting of connected autonomous vehicles (CAVs), human-driven vehicles (HDVs) and connected human-driven vehicles (CHDVs). In recognition of the fact that public acceptance of CAVs will hinge on safety performance of automated driving systems, and that there will likely be safety challenges in the early part of the transition period, significant research efforts have been expended in the development of safety-conscious automated driving systems. Yet still, there appears to be a lacuna in the literature regarding the handling of the crash-imminent situations that are caused by errant human driven vehicles (HDVs) in the vicinity of the CAV during operations on the roadway. In this paper, we develop a simple model-based Reinforcement Learning (RL) based system that can be deployed in the CAV to generate trajectories that anticipate and avoid potential collisions caused by drivers of the HDVs. The model involves an end-to-end data-driven approach that contains a motion prediction model based on deep learning, and a fast trajectory planning algorithm based on model predictive control (MPC). The proposed system requires no prior knowledge or assumption about the physical environment including the vehicle dynamics, and therefore represents a general approach that can be deployed on any type of vehicle (e.g., truck, buse, motorcycle, etc.). The framework is trained and tested in the CARLA simulator with multiple collision imminent scenarios, and the results indicate the proposed model can avoid the collision at high successful rate (&gt;85%) even in highly compact and dangerous situations.      
### 78.Quantifying the Risk of Wildfire Ignition by Power Lines under Extreme Weather Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2110.05551.pdf)
>  This paper presents a surrogate model to quantify the risk of wildfire ignition by individual power lines under extreme weather conditions. Wind speed and wind gust can lead to conductor clashing, which is a cause of igniting disastrous wildfires. The 3D non-linear vibration equations of power lines are employed to generate a dataset that considers physical, structural, and meteorological parameters, including the span of the power line, conductor diameter, wind speed, wind gust, phase clearance, and wind direction. A set of machine learning models is assembled based on these features to generate a score representing the risk of conductor clashing for each power line within a network, quantifying the risk of wildfire ignition. The rendered score represents the chance of the conductor clashing in place of simulating a Runge-Kutta method. A discussion on the impact of various meteorological parameters on power lines under the energization risk is presented. Besides, it is shown how the presented risk measure can be utilized to weigh in the fire safety and service continuity trade-off.      
### 79.UnfairGAN: An Enhanced Generative Adversarial Network for Raindrop Removal from A Single Image  [ :arrow_down: ](https://arxiv.org/pdf/2110.05523.pdf)
>  Image deraining is a new challenging problem in real-world applications, such as autonomous vehicles. In a bad weather condition of heavy rainfall, raindrops, mainly hitting glasses or windshields, can significantly reduce observation ability. Moreover, raindrops spreading over the glass can yield refraction's physical effect, which seriously impedes the sightline or undermine machine learning systems. In this paper, we propose an enhanced generative adversarial network to deal with the challenging problems of raindrops. UnfairGAN is an enhanced generative adversarial network that can utilize prior high-level information, such as edges and rain estimation, to boost deraining performance. To demonstrate UnfairGAN, we introduce a large dataset for training deep learning models of rain removal. The experimental results show that our proposed method is superior to other state-of-the-art approaches of deraining raindrops regarding quantitative metrics and visual quality.      
### 80.Image Compression and Classification Using Qubits and Quantum Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05476.pdf)
>  Recent work suggests that quantum machine learning techniques can be used for classical image classification by encoding the images in quantum states and using a quantum neural network for inference. However, such work has been restricted to very small input images, at most 4 x 4, that are unrealistic and cannot even be accurately labeled by humans. The primary difficulties in using larger input images is that hitherto-proposed encoding schemes necessitate more qubits than are physically realizable. We propose a framework to classify larger, realistic images using quantum systems. Our approach relies on a novel encoding mechanism that embeds images in quantum states while necessitating fewer qubits than prior work. Our framework is able to classify images that are larger than previously possible, up to 16 x 16 for the MNIST dataset on a personal laptop, and obtains accuracy comparable to classical neural networks with the same number of learnable parameters. We also propose a technique for further reducing the number of qubits needed to represent images that may result in an easier physical implementation at the expense of final performance. Our work enables quantum machine learning and classification on classical datasets of dimensions that were previously intractable by physically realizable quantum computers or classical simulation      
