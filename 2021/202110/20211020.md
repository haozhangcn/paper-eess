# ArXiv eess --Wed, 20 Oct 2021
### 1.Model Predictive Control for Automotive Climate Control Systems via Value Function Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2110.10142.pdf)
>  Among the auxiliary loads in light-duty vehicles, the air conditioning system is the single largest energy consumer. For electrified vehicles, the impact of heating and cooling loads becomes even more significant, as they compete with the powertrain for battery energy use and can significantly reduce the range or performance. While considerable work has been made in the field of optimal energy management for electrified vehicles and optimization of vehicle velocity for eco-driving, few contributions have addressed the application of energy-optimal control for heating and cooling loads. <br>This paper proposes an energy management strategy for the thermal management system of an electrified powertrain, based on Model Predictive Control. Starting from a nonlinear model of the vapor compression refrigeration system that captures the dynamics of the refrigerant in the heat exchangers and the power consumption of the system, a constrained multi-objective optimal control problem is formulated to reduce energy consumption while tracking a desired thermal set point. An efficient implementation of MPC is proposed for real-time applications by introducing a terminal cost obtained from the approximation of the global optimal solution.      
### 2.Chunked Autoregressive GAN for Conditional Waveform Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.10139.pdf)
>  Conditional waveform synthesis models learn a distribution of audio waveforms given conditioning such as text, mel-spectrograms, or MIDI. These systems employ deep generative models that model the waveform via either sequential (autoregressive) or parallel (non-autoregressive) sampling. Generative adversarial networks (GANs) have become a common choice for non-autoregressive waveform synthesis. However, state-of-the-art GAN-based models produce artifacts when performing mel-spectrogram inversion. In this paper, we demonstrate that these artifacts correspond with an inability for the generator to learn accurate pitch and periodicity. We show that simple pitch and periodicity conditioning is insufficient for reducing this error relative to using autoregression. We discuss the inductive bias that autoregression provides for learning the relationship between instantaneous frequency and phase, and show that this inductive bias holds even when autoregressively sampling large chunks of the waveform during each forward pass. Relative to prior state-of- the-art GAN-based models, our proposed model, Chunked Autoregressive GAN (CARGAN) reduces pitch error by 40-60%, reduces training time by 58%, maintains a fast generation speed suitable for real-time or interactive applications, and maintains or improves subjective quality.      
### 3.Electricity Tariff Design via Lens of Energy Justice  [ :arrow_down: ](https://arxiv.org/pdf/2110.10122.pdf)
>  Distributed Energy Resources (DERs) can significantly affect the net social benefit in power systems, raising concerns pertaining to distributive justice, equity, and fairness. Electricity tariff and DERs share a symbiotic relationship whereby the design of the former directly impacts the economic efficiency and equity in the system. Current tariff design approaches suffer from opaque efficiency-equity trade-offs and are also agnostic of the externalities that affect both economic efficiency and equity. Therefore, this paper develops a justice-cognizant tariff design framework that improves the economic efficiency of tariff without sacrificing its distributional equity, and encompasses economic welfare, social costs of environmental and public health impacts, and socio-economic and demographic characteristics of electricity consumers. The proposed framework is based on a Single Leader Single Follower (SLSF) game incorporating a multi-objective optimization problem, and is evaluated on four different tariff structures. The SLSF game is reformulated as a Multi-Objective Problem with Equilibrium Constraints (MOPEC) and is solved by integrating the objective sum method for multi-objective optimization and Scholtes's relaxation technique for equilibrium constraints. We compare the economic efficiency and equity of the proposed framework using the 11-zone New York ISO and 7-bus Manhattan power networks. The results demonstrate that spatially- and temporally-granular tariffs ensure equity and economic efficiency at a lower energy burden to consumers.      
### 4.Low Complexity Single Source DOA Estimation Based on Reduced Dimension SVR  [ :arrow_down: ](https://arxiv.org/pdf/2110.10118.pdf)
>  Conventional direction of arrival (DOA) estimation algorithms suffer from performance degradation due to antenna pattern distortion and substantial computational complexity in real-time execution. The support vector regression (SVR) approach is a possible solution to overcome those limitations. In this work, we propose a sequential DOA estimation technique that combines the reduced dimension SVR (for the azimuthal plane) with a closed form approach (for the elevation plane). Thus, the training and testing are only required for the azimuthal angles which makes it very attractive from the implementation complexity point of view. Our analysis demonstrates that the proposed algorithm offers significant complexity gain over the popular MUSIC algorithm while exhibiting similar root-mean-square error performance.      
### 5.In-Orbit Lunar Satellite Image Super Resolution for Selective Data Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2110.10109.pdf)
>  Rapid technological advancements have tremendously increased the data acquisition capabilities of remote sensing satellites. However, the data utilization efficiency in satellite missions is very low. This growing data also escalates the cost required for data downlink transmission and post-processing. Selective data transmission based on in-orbit inferences will address these issues to a great extent. Therefore, to decrease the cost of the satellite mission, we propose a novel system design for selective data transmission, based on in-orbit inferences. As the resolution of images plays a critical role in making precise inferences, we also include in-orbit super-resolution (SR) in the system design. We introduce a new image reconstruction technique and a unique loss function to enable the execution of the SR model on low-power devices suitable for satellite environments. We present a residual dense non-local attention network (RDNLA) that provides enhanced super-resolution outputs to improve the SR performance. SR experiments on Kaguya digital ortho maps (DOMs) demonstrate that the proposed SR algorithm outperforms the residual dense network (RDN) in terms of PSNR and block-sensitive PSNR by a margin of +0.1 dB and +0.19 dB, respectively. The proposed SR system consumes 48% less memory and 67% less peak instantaneous power than the standard SR model, RDN, making it more suitable for execution on a low-powered device platform.      
### 6.Subframework-Based Rigidity Control in Multirobot Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.10106.pdf)
>  This paper presents an alternative approach for analyzing distance-based rigidity in networks of mobile agents, based on a subframework scheme. The advantage of this point of view lies in expressing framework rigidity, which is inherently global, as a localized property. Also, we show that a framework's normalized rigidity eigenvalue degrades as its graph diameter increases. Thus, the rigidity eigenvalues associated to the subframeworks arise naturally as localized rigidity metrics. A decentralized subframework-based controller for maintaining rigidity using only range measurements is developed, which is also aimed to minimize the network's communication load. Finally, we show that the information exchange required by the controller is completed in a finite number of iterations, showing the convenience of the proposed scheme.      
### 7.Data-Driven Predictive Control for Connected and Autonomous Vehicles in Mixed Traffic  [ :arrow_down: ](https://arxiv.org/pdf/2110.10097.pdf)
>  Cooperative control of Connected and Autonomous Vehicles (CAVs) promises great benefits for mixed traffic. Most existing research focuses on model-based control strategies, assuming that car-following dynamics of human-driven vehicles (HDVs) are explicitly known. In this paper, instead of relying on a parametric car-following model, we introduce a data-driven predictive control strategy to achieve safe and optimal control for CAVs in mixed traffic. We first present a linearized dynamical model for mixed traffic systems, and investigate its controllability and observability. Based on these control-theoretic properties, we then propose a novel DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control) strategy for CAVs based on measurable driving data to smooth mixed traffic . Our method is implemented in a receding horizon manner, in which input/output constraints are incorporated to achieve collision-free guarantees. Nonlinear traffic simulations show that DeeP-LCC can save up to 24.96% fuel consumption during a braking scenario of Extra-Urban Driving Cycle while ensuring safety.      
### 8.Stochastic Primal-Dual Deep Unrolling Networks for Imaging Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2110.10093.pdf)
>  In this work we present a new type of efficient deep-unrolling networks for solving imaging inverse problems. Classical deep-unrolling methods require full forward operator and its adjoint across each layer, and hence can be computationally more expensive than other end-to-end methods such as FBP-ConvNet, especially in 3D image reconstruction tasks. We propose a stochastic (ordered-subsets) extension of the Learned Primal-Dual (LPD) which is the state-of-the-art unrolling network. In our unrolling network, we only use a subset of the forward and adjoint operator, to achieve computational efficiency. We consider 3 ways of training the proposed network to cope with different scenarios of the availability of the training data, including (1) supervised training on paired data, (2) unsupervised adversarial training which enable us to train the network without paired ground-truth data, (3) equivariant self-supervised training approach, which utilizes equivariant structure which is prevalent in many imaging applications, and only requires measurement data. Our numerical results demonstrate the effectiveness of our approach in X-ray CT imaging task, showing that our networks achieve similar reconstruction accuracies as the full-batch LPD, while require only a fraction of the computation.      
### 9.Energy Management System for Resilience-Oriented Operation of Ship Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.10053.pdf)
>  This paper proposes an original energy management methodology for enhancing the resilience of ship power systems considering multiple types of energy storage systems, including battery energy storage systems (BESS) and supercapacitor energy storage systems (SCESS). The primary function of the proposed EMS is to maximize the load operability while taking ramp-rate characteristics of energy storage systems (ESS) and generators into account innovatively. Balancing state-of-charge (SoC) of BESS and prioritizing the SoC level of SCESS are two additional objectives of the proposed EMS to manage energy storage systems. The receding horizon optimization (RHO) technique is proposed to reduce the computational burden, making the proposed method feasible for real-time applications. An all-electric MVDC ship power system is used to evaluate the performance of the proposed methodology. Simulation studies and results demonstrate the effectiveness of the proposed method in managing the ESS to ensure the system resilience under generation power shortage. In addition, the proposed RHO technique significantly reduces the computation burden seen in the FHO technique while maintaining an acceptable resilience performance.      
### 10.Optimal Grid-Forming Control of Battery Energy Storage Systems Providing Multiple Services: Modelling and Experimental Validation  [ :arrow_down: ](https://arxiv.org/pdf/2110.10052.pdf)
>  This paper proposes and experimentally validates a joint control and scheduling framework for a grid-forming converter-interfaced BESS providing multiple services to the electrical grid. The framework is designed to dispatch the operation of a distribution feeder hosting heterogeneous prosumers according to a dispatch plan and provide frequency containment reserve and voltage control as additional services. The framework consists of three phases. In the day-ahead scheduling phase, a robust optimization problem is solved to compute the optimal dispatch plan and frequency droop coefficient, accounting for the uncertainty of the aggregated prosumption. In the intra-day phase, a model predictive control algorithm is used to compute the power set-point for the BESS to achieve the tracking of the dispatch plan. Finally, in a real-time stage, the power setpoint originated by the dispatch tracking is converted into a feasible frequency set-point for the grid forming converter by means of a convex optimisation problem accounting for the capability curve of the power converter. The proposed framework is experimentally validated by using a grid-scale 720 kVA/560 kWh BESS connected to a 20 kV distribution feeder of the EPFL hosting stochastic prosumption and PV generation.      
### 11.Formal Power Series Approach to Nonlinear Systems with Additive Static Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2110.10034.pdf)
>  The goal of this paper is to compute the generating series of a closed-loop system when the plant is described in terms of a Chen-Fliess series and an additive static output feedback is applied. The first step is to consider the so called Wiener-Fliess connection consisting of a Chen-Fliess series followed by a memoryless function. Of particular importance will be the contractive nature of this map, which is needed to show that the closed-loop system has a Chen-Fliess series representation. To explicitly compute the generating series, two Hopf algebras are needed, the existing output feedback Hopf algebra used to describe dynamic output feedback, and the Hopf algebra of the shuffle group. These two combinatorial structures are combined to compute what will be called the Wiener-Fliess feedback product. It will be shown that this product has a natural interpretation as a transformation group acting on the plant and preserves the relative degree of the plant. The convergence of the Wiener-Fliess composition product and the additive static feedback product are completely characterized.      
### 12.Private Language Model Adaptation for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.10026.pdf)
>  Speech model adaptation is crucial to handle the discrepancy between server-side proxy training data and actual data received on users' local devices. With the use of federated learning (FL), we introduce an efficient approach on continuously adapting neural network language models (NNLMs) on private devices with applications on automatic speech recognition (ASR). To address the potential speech transcription errors in the on-device training corpus, we perform empirical studies on comparing various strategies of leveraging token-level confidence scores to improve the NNLM quality in the FL settings. Experiments show that compared with no model adaptation, the proposed method achieves relative 2.6% and 10.8% word error rate (WER) reductions on two speech evaluation datasets, respectively. We also provide analysis in evaluating privacy guarantees of our presented procedure.      
### 13.Data-driven and Automatic Surface Texture Analysis Using Persistent Homology  [ :arrow_down: ](https://arxiv.org/pdf/2110.10005.pdf)
>  Surface roughness plays an important role in analyzing engineering surfaces. It quantifies the surface topography and can be used to determine whether the resulting surface finish is acceptable or not. Nevertheless, while several existing tools and standards are available for computing surface roughness, these methods rely heavily on user input thus slowing down the analysis and increasing manufacturing costs. Therefore, fast and automatic determination of the roughness level is essential to avoid costs resulting from surfaces with unacceptable finish, and user-intensive analysis. In this study, we propose a Topological Data Analysis (TDA) based approach to classify the roughness level of synthetic surfaces using both their areal images and profiles. We utilize persistent homology from TDA to generate persistence diagrams that encapsulate information on the shape of the surface. We then obtain feature matrices for each surface or profile using Carlsson coordinates, persistence images, and template functions. We compare our results to two widely used methods in the literature: Fast Fourier Transform (FFT) and Gaussian filtering. The results show that our approach yields mean accuracies as high as 97%. We also show that, in contrast to existing surface analysis tools, our TDA-based approach is fully automatable and provides adaptive feature extraction.      
### 14.Hybrid-Layers Neural Network Architectures for Modeling the Self-Interference in Full-Duplex Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.09997.pdf)
>  Full-duplex (FD) systems have been introduced to provide high data rates for beyond fifth-generation wireless networks through simultaneous transmission of information over the same frequency resources. However, the operation of FD systems is practically limited by the self-interference (SI), and efficient SI cancelers are sought to make the FD systems realizable. Typically, polynomial-based cancelers are employed to mitigate the SI; nevertheless, they suffer from high complexity. This article proposes two novel hybrid-layers neural network (NN) architectures to cancel the SI with low complexity. The first architecture is referred to as hybrid-convolutional recurrent NN (HCRNN), whereas the second is termed as hybrid-convolutional recurrent dense NN (HCRDNN). In contrast to the state-of-the-art NNs that employ dense or recurrent layers for SI modeling, the proposed NNs exploit, in a novel manner, a combination of different hidden layers (e.g., convolutional, recurrent, and/or dense) in order to model the SI with lower computational complexity than the polynomial and the state-of-the-art NN-based cancelers. The key idea behind using hybrid layers is to build an NN model, which makes use of the characteristics of the different layers employed in its architecture. More specifically, in the HCRNN, a convolutional layer is employed to extract the input data features using a reduced network scale. Moreover, a recurrent layer is then applied to assist in learning the temporal behavior of the input signal from the localized feature map of the convolutional layer. In the HCRDNN, an additional dense layer is exploited to add another degree of freedom for adapting the NN settings in order to achieve the best compromise between the cancellation performance and computational complexity. Complexity analysis and numerical simulations are provided to prove the superiority of the proposed architectures.      
### 15.Switched Control Applied to a Totem-Pole Bridgeless Rectifier for Power Factor Correction  [ :arrow_down: ](https://arxiv.org/pdf/2110.09996.pdf)
>  The wide range of operation of bridgeless rectifiers requires a control technique that guarantee robustness. Linear Power Factor Correction (PFC) control techniques, although effective, cannot guarantee such robustness. Nonlinear techniques such as one cycle control are more robust, but other options should be explored. In this work, an affine model is obtained for a Totem-Pole Bridgeless Rectifier (TPBR). An extension to an existing switched control design technique is presented in order to achieve PFC in a robust fashion for the TPBR. Simulations with nonideal components and distorted grid voltage show a precise, fast and robust performance of the switched controller. The effective reference following of the proposed method allows the user to define a current reference waveform that prioritize THD or power factor, depending on the application and norm requirements.      
### 16.ERQA: Edge-Restoration Quality Assessment for Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2110.09992.pdf)
>  Despite the growing popularity of video super-resolution (VSR), there is still no good way to assess the quality of the restored details in upscaled frames. Some SR methods may produce the wrong digit or an entirely different face. Whether a method's results are trustworthy depends on how well it restores truthful details. Image super-resolution can use natural distributions to produce a high-resolution image that is only somewhat similar to the real one. VSR enables exploration of additional information in neighboring frames to restore details from the original scene. The ERQA metric, which we propose in this paper, aims to estimate a model's ability to restore real details using VSR. On the assumption that edges are significant for detail and character recognition, we chose edge fidelity as the foundation for this metric. Experimental validation of our work is based on the MSU Video Super-Resolution Benchmark, which includes the most difficult patterns for detail restoration and verifies the fidelity of details from the original frame. Code for the proposed metric is publicly available at <a class="link-external link-https" href="https://github.com/msu-video-group/ERQA" rel="external noopener nofollow">this https URL</a>.      
### 17.ECG-ATK-GAN: Robustness against Adversarial Attacks on ECG using Conditional Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.09983.pdf)
>  Recently deep learning has reached human-level performance in classifying arrhythmia from Electrocardiogram (ECG). However, deep neural networks (DNN) are vulnerable to adversarial attacks, which can misclassify ECG signals by decreasing the model's precision. Adversarial attacks are crafted perturbations injected in data that manifest the conventional DNN models to misclassify the correct class. Thus, safety concerns arise as it becomes challenging to establish the system's reliability, given that clinical applications require high levels of trust. To mitigate this problem and make DNN models more robust in clinical and real-life settings, we introduce a novel Conditional Generative Adversarial Network (GAN), robust against adversarial attacked ECG signals and retaining high accuracy. Furthermore, we compared it with other state-of-art models to detect cardiac abnormalities from indistinguishable adversarial attacked ECGs. The experiment confirms, our model is more robust against adversarial attacks compared to other architectures.      
### 18.Can Dynamic TDD Enabled Half-Duplex Cell-Free Massive MIMO Outperform Full-Duplex Cellular Massive MIMO?  [ :arrow_down: ](https://arxiv.org/pdf/2110.09968.pdf)
>  We consider a dynamic time division duplex (DTDD) enabled cell-free massive multiple-input multiple-output (CF-mMIMO) system, where each half-duplex (HD) access point (AP) is scheduled to operate in the uplink (UL) or downlink (DL) mode based on the data demands of the user equipments (UEs). The goal is to maximize the sum UL-DL spectral efficiency (SE). We theoretically establish the sub-modularity of the sum SE, which allows us to develop a new, low complexity, greedy algorithm for the combinatorial AP scheduling problem, with guaranteed optimality properties. We also consider pilot sequence reuse among the UEs to limit the channel estimation overhead. In CF systems, all the APs estimate the channel from every UE, making pilot allocation problem different from the cellular case. We develop a novel algorithm that iteratively minimizes the maximum pilot contamination across the UEs. We compare our solutions, both theoretically and via simulations, against a full duplex (FD) multi-cell mMIMO system. Our results show that, due to the joint processing of the signals at the central processing unit, CF-mMIMO with dynamic HD AP-scheduling significantly outperforms cellular FD-mMIMO in terms of the sum SE and 90% likely SE. Thus, DTDD enabled HD CF-mMIMO is a promising alternative to cellular FD-mMIMO, without the cost of hardware for self-interference suppression.      
### 19.SleepPriorCL: Contrastive Representation Learning with Prior Knowledge-based Positive Mining and Adaptive Temperature for Sleep Staging  [ :arrow_down: ](https://arxiv.org/pdf/2110.09966.pdf)
>  The objective of this paper is to learn semantic representations for sleep stage classification from raw physiological time series. Although supervised methods have gained remarkable performance, they are limited in clinical situations due to the requirement of fully labeled data. Self-supervised learning (SSL) based on contrasting semantically similar (positive) and dissimilar (negative) pairs of samples have achieved promising success. However, existing SSL methods suffer the problem that many semantically similar positives are still uncovered and even treated as negatives. In this paper, we propose a novel SSL approach named SleepPriorCL to alleviate the above problem. Advances of our approach over existing SSL methods are two-fold: 1) by incorporating prior domain knowledge into the training regime of SSL, more semantically similar positives are discovered without accessing ground-truth labels; 2) via investigating the influence of the temperature in contrastive loss, an adaptive temperature mechanism for each sample according to prior domain knowledge is further proposed, leading to better performance. Extensive experiments demonstrate that our method achieves state-of-the-art performance and consistently outperforms baselines.      
### 20.The Cocktail Fork Problem: Three-Stem Audio Separation for Real-World Soundtracks  [ :arrow_down: ](https://arxiv.org/pdf/2110.09958.pdf)
>  The cocktail party problem aims at isolating any source of interest within a complex acoustic scene, and has long inspired audio source separation research. Recent efforts have mainly focused on separating speech from noise, speech from speech, musical instruments from each other, or sound events from each other. However, separating an audio mixture (e.g., movie soundtrack) into the three broad categories of speech, music, and sound effects (here understood to include ambient noise and natural sound events) has been left largely unexplored, despite a wide range of potential applications. This paper formalizes this task as the cocktail fork problem, and presents the Divide and Remaster (DnR) dataset to foster research on this topic. DnR is built from three well-established audio datasets (LibriVox, FMA, FSD50k), taking care to reproduce conditions similar to professionally produced content in terms of source overlap and relative loudness, and made available at CD quality. We benchmark standard source separation algorithms on DnR, and further introduce a new mixed-STFT-resolution model to better address the variety of acoustic characteristics of the three source types. Our best model produces SI-SDR improvements over the mixture of 11.3 dB for music, 11.8 dB for speech, and 10.9 dB for sound effects.      
### 21.Food Odor Recognition via Multi-step Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.09956.pdf)
>  Predicting food labels and freshness from its odor remains a decades-old task that requires a complicated algorithm combined with high sensitivity sensors. In this paper, we initiate a multi-step classifier, which firstly clusters food into four categories, then classifies the food label concerning the predicted category, and finally identifies the freshness. We use BME688 gas sensors packed with BME AI studio for data collection and feature extraction. The normalized dataset was preprocessed with PCA and LDA. We evaluated the effectiveness of algorithms such as tree methods, MLP, and CNN through assessment indexes at each stage. We also carried out an ablation experiment to show the necessity and feasibility of the multi-step classifier. The results demonstrated the robustness and adaptability of the multi-step classifier.      
### 22.Positional-Spectral-Temporal Attention in 3D Convolutional Neural Networks for EEG Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.09955.pdf)
>  Recognizing the feelings of human beings plays a critical role in our daily communication. Neuroscience has demonstrated that different emotion states present different degrees of activation in different brain regions, EEG frequency bands and temporal stamps. In this paper, we propose a novel structure to explore the informative EEG features for emotion recognition. The proposed module, denoted by PST-Attention, consists of Positional, Spectral and Temporal Attention modules to explore more discriminative EEG features. Specifically, the Positional Attention module is to capture the activate regions stimulated by different emotions in the spatial dimension. The Spectral and Temporal Attention modules assign the weights of different frequency bands and temporal slices respectively. Our method is adaptive as well as efficient which can be fit into 3D Convolutional Neural Networks (3D-CNN) as a plug-in module. We conduct experiments on two real-world datasets. 3D-CNN combined with our module achieves promising results and demonstrate that the PST-Attention is able to capture stable patterns for emotion recognition from EEG.      
### 23.Minimal Compression of a Radio-Frequency Pulse  [ :arrow_down: ](https://arxiv.org/pdf/2110.09953.pdf)
>  Quadrature amplitude modulation (QAM) and a complementary representation of a causal waveform have been used to develop a sidelobe-free pulse-compression technique. Envelopes of radio-frequency (RF) pulses under study include both unimodal (Laplacian, Gaussian, rectangular) and bimodal (Hermite-Gaussian) shapes. Although the achievable compression gain is small (~2), the generation and phase-invariant correlation processing of such created compressible pulses can be accomplished with the use of low-complexity systems.      
### 24.Towards Polarization-Insensitive Coherent Coded Phase OTDR  [ :arrow_down: ](https://arxiv.org/pdf/2110.09949.pdf)
>  We explore the alternatives for interrogating a fiber sensor from the polarization point of view, and demonstrate a better accuracy with dual polarization probing for coherent phi-OTDR compared with single polarization probing.      
### 25.Analysis of False Data Injection Impact on AI based Solar Photovoltaic Power Generation Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2110.09948.pdf)
>  The use of solar photovoltaics (PV) energy provides additional resources to the electric power grid. The downside of this integration is that the solar power supply is unreliable and highly dependent on the weather condition. The predictability and stability of forecasting are critical for the full utilization of solar power. This study reviews and evaluates various machine learning-based models for solar PV power generation forecasting using a public dataset. Furthermore, The root mean squared error (RMSE), mean squared error (MSE), and mean average error (MAE) metrics are used to evaluate the results. Linear Regression, Gaussian Process Regression, K-Nearest Neighbor, Decision Trees, Gradient Boosting Regression Trees, Multi-layer Perceptron, and Support Vector Regression algorithms are assessed. Their responses against false data injection attacks are also investigated. The Multi-layer Perceptron Regression method shows robust prediction on both regular and noise injected datasets over other methods.      
### 26.Multipath-based Localization and Tracking considering Off-Body Channel Effects  [ :arrow_down: ](https://arxiv.org/pdf/2110.09932.pdf)
>  This paper deals with multipath-based positioning and tracking in off-body channels. An analysis of the effects introduced by the human body and the implications on positioning and tracking is presented based on channel measurements obtained in an indoor scenario. It shows the influence of the radio signal bandwidth on the human body induced field of view (FOV) and the number of multipath components (MPCs) detected and estimated by a deterministic maximum likelihood (ML) algorithm. A multipath-based positioning and tracking algorithm is proposed that associates these estimated MPC parameters with floor plan features and exploits a human body-dependent FOV function. The proposed algorithm is able to provide accurate position estimates even for an off-body radio channel in a multipath-prone environment with the signal bandwidth found to be a limiting factor.      
### 27.Speech Representation Learning Through Self-supervised Pretraining And Multi-task Finetuning  [ :arrow_down: ](https://arxiv.org/pdf/2110.09930.pdf)
>  Speech representation learning plays a vital role in speech processing. Among them, self-supervised learning (SSL) has become an important research direction. It has been shown that an SSL pretraining model can achieve excellent performance in various downstream tasks of speech processing. On the other hand, supervised multi-task learning (MTL) is another representation learning paradigm, which has been proven effective in computer vision (CV) and natural language processing (NLP). However, there is no systematic research on the general representation learning model trained by supervised MTL in speech processing. In this paper, we show that MTL finetuning can further improve SSL pretraining. We analyze the generalizability of supervised MTL finetuning to examine if the speech representation learned by MTL finetuning can generalize to unseen new tasks.      
### 28.CycleFlow: Purify Information Factors by Cycle Loss  [ :arrow_down: ](https://arxiv.org/pdf/2110.09928.pdf)
>  SpeechFlow is a powerful factorization model based on information bottleneck (IB), and its effectiveness has been reported by several studies. A potential problem of SpeechFlow, however, is that if the IB channels are not well designed, the resultant factors cannot be well disentangled. In this study, we propose a CycleFlow model that combines random factor substitution and cycle loss to solve this problem. Experiments on voice conversion tasks demonstrate that this simple technique can effectively reduce mutual information among individual factors, and produce clearly better conversion than the IB-based SpeechFlow. CycleFlow can also be used as a powerful tool for speech editing. We demonstrate this usage by an emotion perception experiment.      
### 29.Conditional De-Identification of 3D Magnetic Resonance Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.09927.pdf)
>  Privacy protection of medical image data is challenging. Even if metadata is removed, brain scans are vulnerable to attacks that match renderings of the face to facial image databases. Solutions have been developed to de-identify diagnostic scans by obfuscating or removing parts of the face. However, these solutions either fail to reliably hide the patient's identity or are so aggressive that they impair further analyses. We propose a new class of de-identification techniques that, instead of removing facial features, remodels them. Our solution relies on a conditional multi-scale GAN architecture. It takes a patient's MRI scan as input and generates a 3D volume conditioned on the patient's brain, which is preserved exactly, but where the face has been de-identified through remodeling. We demonstrate that our approach preserves privacy far better than existing techniques, without compromising downstream medical analyses. Analyses were run on the OASIS-3 and ADNI corpora.      
### 30.Speech Enhancement Based on Cyclegan with Noise-informed Training  [ :arrow_down: ](https://arxiv.org/pdf/2110.09924.pdf)
>  Speech enhancement (SE) approaches can be classified into supervised and unsupervised categories. For unsupervised SE, a well-known cycle-consistent generative adversarial network (CycleGAN) model, which comprises two generators and two discriminators, has been shown to provide a powerful nonlinear mapping ability and thus achieve a promising noise-suppression capability. However, a low-efficiency training process along with insufficient knowledge between noisy and clean speech may limit the enhancement performance of the CycleGAN SE at runtime. In this study, we propose a novel noise-informed-training CycleGAN approach that incorporates additional inputs into the generators and discriminators to assist the CycleGAN in learning a more accurate transformation of speech signals between the noise and clean domains. The additional input feature serves as an indicator that provides more information during the CycleGAN training stage. Experiment results confirm that the proposed approach can improve the CycleGAN SE model while achieving a better sound quality and fewer signal distortions.      
### 31.Speech Enhancement-assisted Stargan Voice Conversion in Noisy Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.09923.pdf)
>  Numerous voice conversion (VC) techniques have been proposed for the conversion of voices among different speakers. Although the decent quality of converted speech can be observed when VC is applied in a clean environment, the quality will drop sharply when the system is running under noisy conditions. In order to address this issue, we propose a novel enhancement-based StarGAN (E-StarGAN) VC system, which leverages a speech enhancement (SE) technique for signal pre-processing. SE systems are generally used to reduce noise components in noisy speech and to generate enhanced speech for downstream application tasks. Therefore, we investigated the effectiveness of E-StarGAN, which combines VC and SE, and demonstrated the robustness of the proposed approach in various noisy environments. The results of VC experiments conducted on a Mandarin dataset show that when combined with SE, the proposed E-StarGAN VC model is robust to unseen noises. In addition, the subjective listening test results show that the proposed E-StarGAN model can improve the sound quality of speech signals converted from noise-corrupted source utterances.      
### 32.Dynamics and control of clustered tensegrity systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.09898.pdf)
>  This paper presents the formulations of nonlinear and linearized statics, dynamics, and control for any clustered tensegrity system (CTS). Based on the Lagrangian method and FEM assumptions, the nonlinear clustered tensegrity dynamics with and without constraints are first derived. It is shown that the traditional tensegrity system (TTS), whose node to node strings are individual ones, yield to be a special case of the CTS. Then, equilibrium equations of the CTS in three standard forms (in terms of nodal coordinate, force density, and force vector) and the compatibility equation are given. Moreover, the linearized dynamics and modal analysis of the CTS with and without constraints are also derived. We also present a nonlinear shape control law for the control of any CTS. The control turns out to be a linear algebra problem in terms of the control variable, which is the force densities in the strings. The statics, dynamics, and control examples are carefully selected to demonstrate the developed principles. The presented approaches can boost the comprehensive studies of the statics, dynamics, and control for any CTS, as well as promoting the integration of structure and control design.      
### 33.Multi-Modal Pre-Training for Automated Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.09890.pdf)
>  Traditionally, research in automated speech recognition has focused on local-first encoding of audio representations to predict the spoken phonemes in an utterance. Unfortunately, approaches relying on such hyper-local information tend to be vulnerable to both local-level corruption (such as audio-frame drops, or loud noises) and global-level noise (such as environmental noise, or background noise) that has not been seen during training. In this work, we introduce a novel approach which leverages a self-supervised learning technique based on masked language modeling to compute a global, multi-modal encoding of the environment in which the utterance occurs. We then use a new deep-fusion framework to integrate this global context into a traditional ASR method, and demonstrate that the resulting method can outperform baseline methods by up to 7% on Librispeech; gains on internal datasets range from 6% (on larger models) to 45% (on smaller models).      
### 34.Bilateral-ViT for Robust Fovea Localization  [ :arrow_down: ](https://arxiv.org/pdf/2110.09860.pdf)
>  The fovea is an important anatomical landmark of the retina. Detecting the location of the fovea is essential for the analysis of many retinal diseases. However, robust fovea localization remains a challenging problem, as the fovea region often appears fuzzy, and retina diseases may further obscure its appearance. This paper proposes a novel vision transformer (ViT) approach that integrates information both inside and outside the fovea region to achieve robust fovea localization. Our proposed network named Bilateral-Vision-Transformer (Bilateral-ViT) consists of two network branches: a transformer-based main network branch for integrating global context across the entire fundus image and a vessel branch for explicitly incorporating the structure of blood vessels. The encoded features from both network branches are subsequently merged with a customized multi-scale feature fusion (MFF) module. Our comprehensive experiments demonstrate that the proposed approach is significantly more robust for diseased images and establishes the new state of the arts on both Messidor and PALM datasets.      
### 35.A Novel Recurrent Adaptive Backstepping Optimal Control Strategy for a Single Inverted Pendulum System  [ :arrow_down: ](https://arxiv.org/pdf/2110.09846.pdf)
>  In this paper, a novel recurrent adaptive backstepping optimal control strategy for a single inverted pendulum system is studied. By this method, an inverted pendulum is stabilized using projection recurrent neural network-based adaptive backstepping control (PRNN-ABC). The inverted pendulum is a popular nonlinear system that is used in both industry and academic and is applied various control approaches since it has many applications. Here, first of all, the backstepping control laws are investigated based on the nonlinear dynamic model of the system. Second, by considering control constrains and performance index, the constrained optimization problem is formulated. Later, the optimization problem will be converted to a constrained quadratic problem (QP). To study the recurrent neural network (RNN) according to the Karush- Kuhn-Tucker (KKT) optimization conditions and the variational inequality, the dynamic model of the RNN will be derived. At last, the stability analysis of the system is studied using Lyapunov function.      
### 36.Cutting Voxel Projector a New Approach to Construct 3D Cone Beam CT Operator  [ :arrow_down: ](https://arxiv.org/pdf/2110.09841.pdf)
>  In this paper, we introduce a new class of projectors for 3D cone beam tomographic reconstruction. We find analytical formulas for the relationship between the voxel volume projected onto a given detector pixel and its contribution to the extinction value detected on that pixel. Using this approach, we construct a near-exact projector and backprojector that can be used especially for algebraic reconstruction techniques. We have implemented this cutting voxel projector and a less accurate, speed-optimized version of it together with two established projectors, a ray tracing projector based on Siddon's algorithm and a TT footprint projector. We show that the cutting voxel projector achieves, especially for large cone beam angles, noticeably higher accuracy than the TT projector. Moreover, our implementation of the relaxed version of the cutting voxel projector is significantly faster than current footprint projector implementations. We further show that Siddon's algorithm with comparable accuracy would be much slower than the cutting voxel projector. All algorithms are implemented within an open source framework for algebraic reconstruction in OpenCL 1.2 and C++ and are optimized for GPU computation. They are published as open-source software under the GNU GPL 3 license, see <a class="link-external link-https" href="https://github.com/kulvait/KCT_cbct" rel="external noopener nofollow">this https URL</a>.      
### 37.Distributed order estimation of ARX model under cooperative excitation condition  [ :arrow_down: ](https://arxiv.org/pdf/2110.09826.pdf)
>  In this paper, we consider the distributed estimation problem of a linear stochastic system described by an autoregressive model with exogenous inputs (ARX) when both the system orders and parameters are unknown. We design distributed algorithms to estimate the unknown orders and parameters by combining the proposed local information criterion (LIC) with the distributed least squares method. The simultaneous estimation for both the system orders and parameters brings challenges for the theoretical analysis. Some analysis techniques, such as double array martingale limit theory, stochastic Lyapunov functions, and martingale convergence theorems are employed. For the case where the upper bounds of the true orders are available, we introduce a cooperative excitation condition, under which the strong consistency of the estimation for the orders and parameters is established. Moreover, for the case where the upper bounds of true orders are unknown, similar distributed algorithm is proposed to estimate both the orders and parameters, and the corresponding convergence analysis for the proposed algorithm is provided. We remark that our results are obtained without relying on the independency or stationarity assumptions of regression vectors, and the cooperative excitation conditions can show that all sensors can cooperate to fulfill the estimation task even though any individual sensor can not.      
### 38.Optimal Scheduling of Flexible Power-to-X Technologies in the Day-ahead Electricity Market  [ :arrow_down: ](https://arxiv.org/pdf/2110.09800.pdf)
>  The ambitious CO2 emission targets of the Paris agreements are achievable only with renewable energy, CO2-free power generation, new policies, and planning. The main motivation of this paper is that future green fuels from power-to-X assets should be produced from power with the lowest possible emissions while still keeping the cost of electricity low. To this end we propose a power-to-X scheduling framework that is capable of co-optimizing CO2 emission intensity and electricity prices in the day-ahead electricity market scheduling. Three realistic models for local production units are developed for flexible dispatch and the impact on electricity market scheduling is examined. Furthermore, the possible benefits of using CO2 emission intensity and electricity prices trade-off in scheduling are discussed. We find that there is a non-linear trade-off between CO2 emission intensity and cost, favoring a weighted optimization between the two objectives.      
### 39.Event-Triggered Tracking Control of Networked and Quantized Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.09786.pdf)
>  This paper studies the tracking control problem of networked and quantized control systems under both multiple networks and event-triggered mechanisms. Multiple networks are to connect the plant and reference system with decentralized controllers to guarantee their information transmission, whereas event-triggered mechanisms are to reduce the information transmission via multiple networks. In this paper, all networks are independent and asynchronous and have local event-triggered mechanisms, which are based on local measurements and determine whether the local measurements need to be transmitted. We first implement an emulation-based approach to develop a novel hybrid model for tracking control of networked and quantized control systems. Next, sufficient conditions are derived and decentralized event-triggered mechanisms are designed to ensure the tracking performance. Finally, a numerical example is given to illustrate the obtained results.      
### 40.User Based Design and Evaluation Pipelineo for Indoor Airships  [ :arrow_down: ](https://arxiv.org/pdf/2110.09748.pdf)
>  Designing a controllable airship for non-expert users or preemptively evaluating the performance of desired airships has always been a very challenging problem. This paper explores the blimp design parameter space from the aspect of the user by considering various distributions of thrust, combinations of propulsive mechanisms, and balloon shapes. We provide open-source modular hardware and reconfigurable software design tools that allow inexperienced users to design a custom airship in a short time. Based on these design parameters, this paper develops a more engineering-focused evaluation system that can characterize the performance of different indoor blimps. An analytical comparison and some case studies that consider various points in the design parameter space have been conducted to prove the feasibility and validity of our design and evaluation system.      
### 41.Spectral Variability Augmented Sparse Unmixing of Hyperspectral Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.09744.pdf)
>  Spectral unmixing (SU) expresses the mixed pixels existed in hyperspectral images as the product of endmember and abundance, which has been widely used in hyperspectral imagery analysis. However, the influence of light, acquisition conditions and the inherent properties of materials, results in that the identified endmembers can vary spectrally within a given image (construed as spectral variability). To address this issue, recent methods usually use a priori obtained spectral library to represent multiple characteristic spectra of the same object, but few of them extracted the spectral variability explicitly. In this paper, a spectral variability augmented sparse unmixing model (SVASU) is proposed, in which the spectral variability is extracted for the first time. The variable spectra are divided into two parts of intrinsic spectrum and spectral variability for spectral reconstruction, and modeled synchronously in the SU model adding the regular terms restricting the sparsity of abundance and the generalization of the variability coefficient. It is noted that the spectral variability library and the intrinsic spectral library are all constructed from the In-situ observed image. Experimental results over both synthetic and real-world data sets demonstrate that the augmented decomposition by spectral variability significantly improves the unmixing performance than the decomposition only by spectral library, as well as compared to state-of-the-art algorithms.      
### 42.Cross-Vendor CT Image Data Harmonization Using CVH-CT  [ :arrow_down: ](https://arxiv.org/pdf/2110.09693.pdf)
>  While remarkable advances have been made in Computed Tomography (CT), most of the existing efforts focus on imaging enhancement while reducing radiation dose. How to harmonize CT image data captured using different scanners is vital in cross-center large-scale radiomics studies but remains the boundary to explore. Furthermore, the lack of paired training image problem makes it computationally challenging to adopt existing deep learning models. %developed for CT image standardization. %this problem more challenging. We propose a novel deep learning approach called CVH-CT for harmonizing CT images captured using scanners from different vendors. The generator of CVH-CT uses a self-attention mechanism to learn the scanner-related information. We also propose a VGG feature-based domain loss to effectively extract texture properties from unpaired image data to learn the scanner-based texture distributions. The experimental results show that CVH-CT is clearly better than the baselines because of the use of the proposed domain loss, and CVH-CT can effectively reduce the scanner-related variability in terms of radiomic features.      
### 43.Data Driven Prediction of Battery Cycle Life Before Capacity Degradation  [ :arrow_down: ](https://arxiv.org/pdf/2110.09687.pdf)
>  Ubiquitous use of lithium-ion batteries across multiple industries presents an opportunity to explore cost saving initiatives as the price to performance ratio continually decreases in a competitive environment. Manufacturers using lithium-ion batteries ranging in applications from mobile phones to electric vehicles need to know how long batteries will last for a given service life. To understand this, expensive testing is required. <br>This paper utilizes the data and methods implemented by Kristen A. Severson, et al, to explore the methodologies that the research team used and presents another method to compare predicted results vs. actual test data for battery capacity fade. The fundamental effort is to find out if machine learning techniques may be trained to use early life cycle data in order to accurately predict battery capacity over the battery life cycle. Results show comparison of methods between Gaussian Process Regression (GPR) and Elastic Net Regression (ENR) and highlight key data features used from the extensive dataset found in the work of Severson, et al.      
### 44.Coordinated Beamforming in Quantized Massive MIMO Systems with Per-Antenna Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2110.09671.pdf)
>  In this work, we present a solution for coordinated beamforming for large-scale downlink (DL) communication systems with low-resolution data converters when employing a per-antenna power constraint that limits the maximum antenna power to alleviate hardware cost. To this end, we formulate and solve the antenna power minimax problem for the coarsely quantized DL system with target signal-to-interference-plus-noise ratio requirements. We show that the associated Lagrangian dual with uncertain noise covariance matrices achieves zero duality gap and that the dual solution can be used to obtain the primal DL solution. Using strong duality, we propose an iterative algorithm to determine the optimal dual solution, which is used to compute the optimal DL beamformer. We further update the noise covariance matrices using the optimal DL solution with an associated subgradient and perform projection onto the feasible domain. Through simulation, we evaluate the proposed method in maximum antenna power consumption and peak-to-average power ratio which are directly related to hardware efficiency.      
### 45.Osteoporosis Prescreening using Panoramic Radiographs through a Deep Convolutional Neural Network with Attention Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2110.09662.pdf)
>  Objectives. The aim of this study was to investigate whether a deep convolutional neural network (CNN) with an attention module can detect osteoporosis on panoramic radiographs. <br>Study Design. A dataset of 70 panoramic radiographs (PRs) from 70 different subjects of age between 49 to 60 was used, including 49 subjects with osteoporosis and 21 normal subjects. We utilized the leave-one-out cross-validation approach to generate 70 training and test splits. Specifically, for each split, one image was used for testing and the remaining 69 images were used for training. A deep convolutional neural network (CNN) using the Siamese architecture was implemented through a fine-tuning process to classify an PR image using patches extracted from eight representative trabecula bone areas (Figure 1). In order to automatically learn the importance of different PR patches, an attention module was integrated into the deep CNN. Three metrics, including osteoporosis accuracy (OPA), non-osteoporosis accuracy (NOPA) and overall accuracy (OA), were utilized for performance evaluation. <br>Results. The proposed baseline CNN approach achieved the OPA, NOPA and OA scores of 0.667, 0.878 and 0.814, respectively. With the help of the attention module, the OPA, NOPA and OA scores were further improved to 0.714, 0.939 and 0.871, respectively. <br>Conclusions. The proposed method obtained promising results using deep CNN with an attention module, which might be applied to osteoporosis prescreening.      
### 46.System Norm Regularization Methods for Koopman Operator Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2110.09658.pdf)
>  Approximating the Koopman operator from data is numerically challenging when many lifting functions are considered. Even low-dimensional systems can yield unstable or ill-conditioned results in a high-dimensional lifted space. In this paper, Extended DMD and DMD with control, two popular methods for approximating the Koopman operator, are reformulated as convex optimization problems with linear matrix inequality constraints. Both hard asymptotic stability constraints and system norm regularizers are considered as methods to improve the numerical conditioning of the approximate Koopman operator. In particular, the $\mathcal{H}_\infty$ norm is used as a regularizer to penalize the input-output gain of the linear system defined by the Koopman operator. Weighting functions are then applied to penalize the system gain at particular frequencies.      
### 47.Personalized Speech Enhancement: New Models and Comprehensive Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2110.09625.pdf)
>  Personalized speech enhancement (PSE) models utilize additional cues, such as speaker embeddings like d-vectors, to remove background noise and interfering speech in real-time and thus improve the speech quality of online video conferencing systems for various acoustic scenarios. In this work, we propose two neural networks for PSE that achieve superior performance to the previously proposed VoiceFilter. In addition, we create test sets that capture a variety of scenarios that users can encounter during video conferencing. Furthermore, we propose a new metric to measure the target speaker over-suppression (TSOS) problem, which was not sufficiently investigated before despite its critical importance in deployment. Besides, we propose multi-task training with a speech recognition back-end. Our results show that the proposed models can yield better speech recognition accuracy, speech intelligibility, and perceptual quality than the baseline models, and the multi-task training can alleviate the TSOS issue in addition to improving the speech recognition accuracy.      
### 48.Model Order Estimation for A Sum of Complex Exponentials  [ :arrow_down: ](https://arxiv.org/pdf/2110.09616.pdf)
>  In this paper, we present a new method for estimating the number of terms in a sum of exponentially damped sinusoids embedded in noise. In particular, we propose to combine the shift-invariance property of the Hankel matrix associated with the signal with a constraint over its singular values to penalize small order estimations. With this new methodology, the algebraic and statistical structures of the Hankel matrix are considered. The new order estimation technique shows significant improvements over subspace-based methods. In particular, when a good separation between the noise and the signal subspaces is not possible, the new methodology outperforms known techniques. We evaluate the performance of our method using numerical experiments and comparing its performance with previous results found in the literature.      
### 49.Geometry-Based Output Robust Tracking Control of a Quadrotor  [ :arrow_down: ](https://arxiv.org/pdf/2110.09591.pdf)
>  The paper solves the problem of tracking control of a quadrotor with unmeasurable pitch and roll angles based on the geometric approach with the use of the enhanced extended observer and the internal model. The proposed approach makes it possible to ensure the movement of a quadrotor in a horizontal plane along a trajectory given in the form of a sinusoidal or second-order polynomial function with semiglobal asymptotic convergence of the tracking errors to zero.      
### 50.Robust Control of a Surface Vessel with Adaptive Rejection of Disturbances with Unknown Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2110.09587.pdf)
>  This paper solves the problem of station-keeping control of a surface vessel under conditions of sinusoidal disturbances with unknown parameters. The proposed control algorithm is based on the geometric approach with the use of the adaptive internal model and the extended observer. The paper analytically proves the boundedness of the trajectories of the system and their semiglobal convergence to an arbitrarily small set. The performance of the algorithm is illustrated by computer simulation.      
### 51.Set-based State Estimation with Probabilistic Consistency Guarantee under Epistemic Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2110.09584.pdf)
>  Consistent state estimation is challenging, especially under the epistemic uncertainties arising from learned (nonlinear) dynamic and observation models. In this work, we develop a set-based estimation algorithm, that produces zonotopic state estimates that respect the epistemic uncertainties in the learned models, in addition to the aleatoric uncertainties. Our algorithm guarantees probabilistic consistency, in the sense that the true state is always bounded by the zonotopes, with a high probability. We formally relate our set-based approach with the corresponding probabilistic approach (GP-EKF) in the case of learned (nonlinear) models. In particular, when linearization errors and aleatoric uncertainties are omitted, and epistemic uncertainties are simplified, our set-based approach reduces to its probabilistic counterpart. Our method's improved consistency is empirically demonstrated in both a simulated pendulum domain and a real-world robot-assisted dressing domain, where the robot estimates the configuration of the human arm utilizing the force measurements at its end effector.      
### 52.Wideband and Entropy-Aware Deep Soft Bit Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2110.09541.pdf)
>  Deep learning has been recently applied to physical layer processing in digital communication systems in order to improve end-to-end performance. In this work, we introduce a novel deep learning solution for soft bit quantization across wideband channels. Our method is trained end-to-end with quantization- and entropy-aware augmentations to the loss function and is used at inference in conjunction with source coding to achieve near-optimal compression gains over wideband channels. To efficiently train our method, we prove and verify that a fixed feature space quantization scheme is sufficient for efficient learning. When tested on channel distributions never seen during training, the proposed method achieves a compression gain of up to $10 \%$ in the high SNR regime versus previous state-of-the-art methods. To encourage reproducible research, our implementation is publicly available at <a class="link-external link-https" href="https://github.com/utcsilab/wideband-llr-deep" rel="external noopener nofollow">this https URL</a>.      
### 53.Spatial-temporal water area monitoring of Miyun Reservoir using remote sensing imagery from 1984 to 2020  [ :arrow_down: ](https://arxiv.org/pdf/2110.09515.pdf)
>  Miyun Reservoir has produced huge benefits in flood control, agricultural irrigation, power generation, aquaculture, tourism, and urban water supply. Accurately water mapping is of great significance to the ecological environment monitoring of the Miyun Reservoir and the management of the South-to-North Water Diversion Project. On the 60th anniversary of the completion of the Miyun Reservoir, we took the Miyun Reservoir as the study area and collected all the Landsat-5 and Landsat-8 remote sensing images from 1984 to 2020 for water mapping. Based on the spectral, topographical and temporal-spatial characteristics of water, we proposed an automated method for long-term researvoir mapping, which can solve the problems caused by cloud, shadow, ice and snow pixels. Moreover, it can also deal with 'the same objects with different spectra' and spectral mixed problems. The overall accuracy is as high as 98.2% for the case with no cloud or snow/ice cover. The landscape division index is introduced to analyze the morphological changes of Miyun Reservoir. Based on the mapping results, we analyzed the changes of Miyun Reservoir from 1984 to 2020 and the driving factors of them.      
### 54.Continual self-training with bootstrapped remixing for speech enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2110.10103.pdf)
>  We propose RemixIT, a simple and novel self-supervised training method for speech enhancement. The proposed method is based on a continuously self-training scheme that overcomes limitations from previous studies including assumptions for the in-domain noise distribution and having access to clean target signals. Specifically, a separation teacher model is pre-trained on an out-of-domain dataset and is used to infer estimated target signals for a batch of in-domain mixtures. Next, we bootstrap the mixing process by generating artificial mixtures using permuted estimated clean and noise signals. Finally, the student model is trained using the permuted estimated sources as targets while we periodically update teacher's weights using the latest student model. Our experiments show that RemixIT outperforms several previous state-of-the-art self-supervised methods under multiple speech enhancement tasks. Additionally, RemixIT provides a seamless alternative for semi-supervised and unsupervised domain adaptation for speech enhancement tasks, while being general enough to be applied to any separation task and paired with any separation model.      
### 55.Riemannian classification of EEG signals with missing values  [ :arrow_down: ](https://arxiv.org/pdf/2110.10011.pdf)
>  This paper proposes two strategies to handle missing data for the classification of electroencephalograms using covariance matrices. The first approach estimates the covariance from imputed data with the $k$-nearest neighbors algorithm; the second relies on the observed data by leveraging the observed-data likelihood within an expectation-maximization algorithm. Both approaches are combined with the minimum distance to Riemannian mean classifier and applied to a classification task of event related-potentials, a widely known paradigm of brain-computer interface paradigms. As results show, the proposed strategies perform better than the classification based on observed data and allow to keep a high accuracy even when the missing data ratio increases.      
### 56.Temporal separation of whale vocalizations from background oceanic noise using a power calculation  [ :arrow_down: ](https://arxiv.org/pdf/2110.10010.pdf)
>  The process of analyzing audio signals in search of cetacean vocalizations is in many cases a very arduous task, requiring many complex computations, a plethora of digital processing techniques and the scrutinization of an audio signal with a fine comb to determine where the vocalizations are located. To ease this process, a computationally efficient and noise-resistant method for determining whether an audio segment contains a potential cetacean call is developed here with the help of a robust power calculation for stationary Gaussian noise signals and a recursive method for determining the mean and variance of a given sample frame. The resulting detector is tested on audio recordings containing Southern Right whale sounds and its performance compared to that of an existing contemporary energy detector. The detector exhibits good performance at moderate-to-high signal-to-noise ratio values. The detector succeeds in being easy to implement, computationally efficient to use and robust enough to accurately detect whale vocalizations in a noisy underwater environment.      
### 57.Random Feature Approximation for Online Nonlinear Graph Topology Identification  [ :arrow_down: ](https://arxiv.org/pdf/2110.09935.pdf)
>  Online topology estimation of graph-connected time series is challenging, especially since the causal dependencies in many real-world networks are nonlinear. In this paper, we propose a kernel-based algorithm for graph topology estimation. The algorithm uses a Fourier-based Random feature approximation to tackle the curse of dimensionality associated with the kernel representations. Exploiting the fact that the real-world networks often exhibit sparse topologies, we propose a group lasso based optimization framework, which is solve using an iterative composite objective mirror descent method, yielding an online algorithm with fixed computational complexity per iteration. The experiments conducted on real and synthetic data show that the proposed method outperforms its competitors.      
### 58.User-Centric Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.09869.pdf)
>  Data heterogeneity across participating devices poses one of the main challenges in federated learning as it has been shown to greatly hamper its convergence time and generalization capabilities. In this work, we address this limitation by enabling personalization using multiple user-centric aggregation rules at the parameter server. Our approach potentially produces a personalized model for each user at the cost of some extra downlink communication overhead. To strike a trade-off between personalization and communication efficiency, we propose a broadcast protocol that limits the number of personalized streams while retaining the essential advantages of our learning scheme. Through simulation results, our approach is shown to enjoy higher personalization capabilities, faster convergence, and better communication efficiency compared to other competing baseline solutions.      
### 59.Learning a self-supervised tone mapping operator via feature contrast masking loss  [ :arrow_down: ](https://arxiv.org/pdf/2110.09866.pdf)
>  High Dynamic Range (HDR) content is becoming ubiquitous due to the rapid development of capture technologies. Nevertheless, the dynamic range of common display devices is still limited, therefore tone mapping (TM) remains a key challenge for image visualization. Recent work has demonstrated that neural networks can achieve remarkable performance in this task when compared to traditional methods, however, the quality of the results of these learning-based methods is limited by the training data. Most existing works use as training set a curated selection of best-performing results from existing traditional tone mapping operators (often guided by a quality metric), therefore, the quality of newly generated results is fundamentally limited by the performance of such operators. This quality might be even further limited by the pool of HDR content that is used for training. In this work we propose a learning-based self-supervised tone mapping operator that is trained at test time specifically for each HDR image and does not need any data labeling. The key novelty of our approach is a carefully designed loss function built upon fundamental knowledge on contrast perception that allows for directly comparing the content in the HDR and tone mapped images. We achieve this goal by reformulating classic VGG feature maps into feature contrast maps that normalize local feature differences by their average magnitude in a local neighborhood, allowing our loss to account for contrast masking effects. We perform extensive ablation studies and exploration of parameters and demonstrate that our solution outperforms existing approaches with a single set of fixed parameters, as confirmed by both objective and subjective metrics.      
### 60.A SVD-Based Synchrophasor Estimator for P-class PMUs with Improved Immune from Interharmonic Tones  [ :arrow_down: ](https://arxiv.org/pdf/2110.09821.pdf)
>  The increasing use of renewable generation, power electronic devices, and nonlinear loads in power systems brings more severe interharmonic tones to the measurand, which can increase estimation errors of P-class PMUs, cause misoperation of protection relays, and even threaten the stability of the power systems. Therefore, the performance of the P-class synchrophasor estimator under interharmonic interference should be evaluated and new estimation schemes that can improve the operational robustness are needed for various protection and control applications. In this paper, a synchrophasor estimator design for P-class PMUs that introduces singular value decomposition to the least square algorithm based on the Taylor series is proposed. By constructing an optimization with proposed adjustable parameters, finite impulse response filters with high transition band attenuation are designed. Numerical and experimental tests verify the proposed dynamic synchrophasor estimator performance and show an effective improvement in rejecting interharmonic tones, especially when a short time window and light computational burden are required.      
### 61.Speech Pattern based Black-box Model Watermarking for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.09814.pdf)
>  As an effective method for intellectual property (IP) protection, model watermarking technology has been applied on a wide variety of deep neural networks (DNN), including speech classification models. However, how to design a black-box watermarking scheme for automatic speech recognition (ASR) models is still an unsolved problem, which is a significant demand for protecting remote ASR Application Programming Interface (API) deployed in cloud servers. Due to conditional independence assumption and label-detection-based evasion attack risk of ASR models, the black-box model watermarking scheme for speech classification models cannot apply to ASR models. In this paper, we propose the first black-box model watermarking framework for protecting the IP of ASR models. Specifically, we synthesize trigger audios by spreading the speech clips of model owners over the entire input audios and labeling the trigger audios with the stego texts, which hides the authorship information with linguistic steganography. Experiments on the state-of-the-art open-source ASR system DeepSpeech demonstrate the feasibility of the proposed watermarking scheme, which is robust against five kinds of attacks and has little impact on accuracy.      
### 62.Learning to Learn Graph Topologies  [ :arrow_down: ](https://arxiv.org/pdf/2110.09807.pdf)
>  Learning a graph topology to reveal the underlying relationship between data entities plays an important role in various machine learning and data analysis tasks. Under the assumption that structured data vary smoothly over a graph, the problem can be formulated as a regularised convex optimisation over a positive semidefinite cone and solved by iterative algorithms. Classic methods require an explicit convex function to reflect generic topological priors, e.g. the $\ell_1$ penalty for enforcing sparsity, which limits the flexibility and expressiveness in learning rich topological structures. We propose to learn a mapping from node data to the graph structure based on the idea of learning to optimise (L2O). Specifically, our model first unrolls an iterative primal-dual splitting algorithm into a neural network. The key structural proximal projection is replaced with a variational autoencoder that refines the estimated graph with enhanced topological properties. The model is trained in an end-to-end fashion with pairs of node data and graph samples. Experiments on both synthetic and real-world data demonstrate that our model is more efficient than classic iterative algorithms in learning a graph with specific topological properties.      
### 63.Geo-DefakeHop: High-Performance Geographic Fake Image Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.09795.pdf)
>  A robust fake satellite image detection method, called Geo-DefakeHop, is proposed in this work. Geo-DefakeHop is developed based on the parallel subspace learning (PSL) methodology. PSL maps the input image space into several feature subspaces using multiple filter banks. By exploring response differences of different channels between real and fake images for a filter bank, Geo-DefakeHop learns the most discriminant channels and uses their soft decision scores as features. Then, Geo-DefakeHop selects a few discriminant features from each filter bank and ensemble them to make a final binary decision. Geo-DefakeHop offers a light-weight high-performance solution to fake satellite images detection. Its model size is analyzed, which ranges from 0.8 to 62K parameters. Furthermore, it is shown by experimental results that it achieves an F1-score higher than 95\% under various common image manipulations such as resizing, compression and noise corruption.      
### 64.CIPS-3D: A 3D-Aware Generator of GANs Based on Conditionally-Independent Pixel Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.09788.pdf)
>  The style-based GAN (StyleGAN) architecture achieved state-of-the-art results for generating high-quality images, but it lacks explicit and precise control over camera poses. The recently proposed NeRF-based GANs made great progress towards 3D-aware generators, but they are unable to generate high-quality images yet. This paper presents CIPS-3D, a style-based, 3D-aware generator that is composed of a shallow NeRF network and a deep implicit neural representation (INR) network. The generator synthesizes each pixel value independently without any spatial convolution or upsampling operation. In addition, we diagnose the problem of mirror symmetry that implies a suboptimal solution and solve it by introducing an auxiliary discriminator. Trained on raw, single-view images, CIPS-3D sets new records for 3D-aware image synthesis with an impressive FID of 6.97 for images at the $256\times256$ resolution on FFHQ. We also demonstrate several interesting directions for CIPS-3D such as transfer learning and 3D-aware face stylization. The synthesis results are best viewed as videos, so we recommend the readers to check our github project at <a class="link-external link-https" href="https://github.com/PeterouZh/CIPS-3D" rel="external noopener nofollow">this https URL</a>      
### 65.SSAST: Self-Supervised Audio Spectrogram Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2110.09784.pdf)
>  Recently, neural networks based purely on self-attention, such as the Vision Transformer (ViT), have been shown to outperform deep learning models constructed with convolutional neural networks (CNNs) on various vision tasks, thus extending the success of Transformers, which were originally developed for language processing, to the vision domain. A recent study showed that a similar methodology can also be applied to the audio domain. Specifically, the Audio Spectrogram Transformer (AST) achieves state-of-the-art results on various audio classification benchmarks. However, pure Transformer models tend to require more training data compared to CNNs, and the success of the AST relies on supervised pretraining that requires a large amount of labeled data and a complex training pipeline, thus limiting the practical usage of AST. <br>This paper focuses on audio and speech classification, and aims to alleviate the data requirement issues with the AST by leveraging self-supervised learning using unlabeled data. Specifically, we propose to pretrain the AST model with joint discriminative and generative masked spectrogram patch modeling (MSPM) using unlabeled audio from AudioSet and Librispeech. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, emotion recognition, and speaker identification. The proposed self-supervised framework significantly boosts AST performance on all tasks, with an average improvement of 60.9%, leading to similar or even better results than a supervised pretrained AST. To the best of our knowledge, it is the first patch-based self-supervised learning framework in the audio and speech domain, and also the first self-supervised learning framework for AST.      
### 66.Improving Emotional Speech Synthesis by Using SUS-Constrained VAE and Text Encoder Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2110.09780.pdf)
>  Learning emotion embedding from reference audio is a straightforward approach for multi-emotion speech synthesis in encoder-decoder systems. But how to get better emotion embedding and how to inject it into TTS acoustic model more effectively are still under investigation. In this paper, we propose an innovative constraint to help VAE extract emotion embedding with better cluster cohesion. Besides, the obtained emotion embedding is used as query to aggregate latent representations of all encoder layers via attention. Moreover, the queries from encoder layers themselves are also helpful. Experiments prove the proposed methods can enhance the encoding of comprehensive syntactic and semantic information and produce more expressive emotional speech.      
### 67.Memory-Augmented Deep Unfolding Network for Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2110.09766.pdf)
>  Mapping a truncated optimization method into a deep neural network, deep unfolding network (DUN) has attracted growing attention in compressive sensing (CS) due to its good interpretability and high performance. Each stage in DUNs corresponds to one iteration in optimization. By understanding DUNs from the perspective of the human brain's memory processing, we find there exists two issues in existing DUNs. One is the information between every two adjacent stages, which can be regarded as short-term memory, is usually lost seriously. The other is no explicit mechanism to ensure that the previous stages affect the current stage, which means memory is easily forgotten. To solve these issues, in this paper, a novel DUN with persistent memory for CS is proposed, dubbed Memory-Augmented Deep Unfolding Network (MADUN). We design a memory-augmented proximal mapping module (MAPMM) by combining two types of memory augmentation mechanisms, namely High-throughput Short-term Memory (HSM) and Cross-stage Long-term Memory (CLM). HSM is exploited to allow DUNs to transmit multi-channel short-term memory, which greatly reduces information loss between adjacent stages. CLM is utilized to develop the dependency of deep information across cascading stages, which greatly enhances network representation capability. Extensive CS experiments on natural and MR images show that with the strong ability to maintain and balance information our MADUN outperforms existing state-of-the-art methods by a large margin. The source code is available at <a class="link-external link-https" href="https://github.com/jianzhangcs/MADUN/" rel="external noopener nofollow">this https URL</a>.      
### 68.A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.09759.pdf)
>  Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor the condition of the human heart. By using deep neural networks (DNNs), interpretation of ECG signals can be fully automated for the identification of potential abnormalities in a patient's heart in a fraction of a second. Studies have shown that given a sufficiently large amount of training data, DNN accuracy for ECG classification could reach human-expert cardiologist level. However, despite of the excellent performance in classification accuracy, DNNs are highly vulnerable to adversarial noises that are subtle changes in the input of a DNN and may lead to a wrong class-label prediction. It is challenging and essential to improve robustness of DNNs against adversarial noises, which are a threat to life-critical applications. In this work, we proposed a regularization method to improve DNN robustness from the perspective of noise-to-signal ratio (NSR) for the application of ECG signal classification. We evaluated our method on PhysioNet MIT-BIH dataset and CPSC2018 ECG dataset, and the results show that our method can substantially enhance DNN robustness against adversarial noises generated from adversarial attacks, with a minimal change in accuracy on clean data.      
### 69.Rep Works in Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2110.09720.pdf)
>  Multi-branch convolutional neural network architecture has raised lots of attention in speaker verification since the aggregation of multiple parallel branches can significantly improve performance. However, this design is not efficient enough during the inference time due to the increase of model parameters and extra operations. In this paper, we present a new multi-branch network architecture RepSPKNet that uses a re-parameterization technique. With this technique, our backbone model contains an efficient VGG-like inference state while its training state is a complicated multi-branch structure. We first introduce the specific structure of RepVGG into speaker verification and propose several variants of this structure. The performance is evaluated on VoxCeleb-based test sets. We demonstrate that both the branch diversity and the branch capacity play important roles in RepSPKNet designing. Our RepSPKNet achieves state-of-the-art performance with a 1.5982% EER and a 0.1374 minDCF on VoxCeleb1-H.      
### 70.PI(t)D(t) Control and Motion Profiling for Omnidirectional Mobile Robots  [ :arrow_down: ](https://arxiv.org/pdf/2110.09707.pdf)
>  Recently, a trend is emerging toward human-servicing autonomous mobile robots, with diverse applications including delivery of supplies in hospitals, hotels, or labs where personnel are scarce, or reacting to indoor emergencies. However, existing autonomous mobile robot (AMR) motion is slow and inefficient, a foundational barrier to proliferation of human-servicing applications. This research has developed a motion control architecture that demonstrates the potential of several algorithms for increasing speed and efficiency. These include a novel PI(t)D(t) controller that sets integral and derivative gains as functions of time, and motion-profiling applied for holonomic motion. Resulting performance indicates potential for faster, more efficient AMRs, that maintain high levels of accuracy and repeatability. The hope is that this research can serve as a proof of concept for faster motion-control, to remove a key barrier to further use of human-servicing mobile robots.      
### 71.Hybrid variable monitoring: An unsupervised process monitoring framework  [ :arrow_down: ](https://arxiv.org/pdf/2110.09704.pdf)
>  Traditional process monitoring methods, such as PCA, PLS, ICA, MD et al., are strongly dependent on continuous variables because most of them inevitably involve Euclidean or Mahalanobis distance. With industrial processes becoming more and more complex and integrated, binary variables also appear in monitoring variables besides continuous variables, which makes process monitoring more challenging. The aforementioned traditional approaches are incompetent to mine the information of binary variables, so that the useful information contained in them is usually discarded during the data preprocessing. To solve the problem, this paper focuses on the issue of hybrid variable monitoring (HVM) and proposes a novel unsupervised framework of process monitoring with hybrid variables. HVM is addressed in the probabilistic framework, which can effectively exploit the process information implicit in both continuous and binary variables at the same time. In HVM, the statistics and the monitoring strategy suitable for hybrid variables with only healthy state data are defined and the physical explanation behind the framework is elaborated. In addition, the estimation of parameters required in HVM is derived in detail and the detectable condition of the proposed method is analyzed. Finally, the superiority of HVM is fully demonstrated first on a numerical simulation and then on an actual case of a thermal power plant.      
### 72.Image Quality Assessment in the Modern Age  [ :arrow_down: ](https://arxiv.org/pdf/2110.09699.pdf)
>  This tutorial provides the audience with the basic theories, methodologies, and current progresses of image quality assessment (IQA). From an actionable perspective, we will first revisit several subjective quality assessment methodologies, with emphasis on how to properly select visual stimuli. We will then present in detail the design principles of objective quality assessment models, supplemented by an in-depth analysis of their advantages and disadvantages. Both hand-engineered and (deep) learning-based methods will be covered. Moreover, the limitations with the conventional model comparison methodology for objective quality models will be pointed out, and novel comparison methodologies such as those based on the theory of "analysis by synthesis" will be introduced. We will last discuss the real-world multimedia applications of IQA, and give a list of open challenging problems, in the hope of encouraging more and more talented researchers and engineers devoting to this exciting and rewarding research field.      
### 73.Neural Lexicon Reader: Reduce Pronunciation Errors in End-to-end TTS by Leveraging External Textual Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2110.09698.pdf)
>  End-to-end TTS suffers from high data requirements as it is difficult for both costly speech corpora to cover all necessary knowledge and neural models to learn the knowledge, hence additional knowledge needs to be injected manually. For example, to capture pronunciation knowledge on languages without regular orthography, a complicated grapheme-to-phoneme pipeline needs to be built based on a structured, large pronunciation lexicon, leading to extra, sometimes high, costs to extend neural TTS to such languages. In this paper, we propose a framework to learn to extract knowledge from unstructured external resources using Token2Knowledge attention modules. The framework is applied to build a novel end-to-end TTS model named Neural Lexicon Reader that extracts pronunciations from raw lexicon texts. Experiments support the potential of our framework that the model significantly reduces pronunciation errors in low-resource, end-to-end Chinese TTS, and the lexicon-reading capability can be transferred to other languages with a smaller amount of data.      
### 74.Convergence Rate of Accelerated Average Consensus with Local Node Memory: Optimization and Analytic Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2110.09678.pdf)
>  Previous researches have shown that adding local memory can accelerate the consensus. It is natural to ask questions like what is the fastest rate achievable by the $M$-tap memory acceleration, and what are the corresponding control parameters. This paper introduces a set of effective and previously unused techniques to analyze the convergence rate of accelerated consensus with $M$-tap memory of local nodes and to design the control protocols. These effective techniques, including the Kharitonov stability theorem, the Routh stability criterion and the robust stability margin, have led to the following new results: 1) the direct link between the convergence rate and the control parameters; 2) explicit formulas of the optimal convergence rate and the corresponding optimal control parameters for $M \leq 2$ on a given graph; 3) the optimal worst-case convergence rate and the corresponding optimal control parameters for the memory $M \geq 1$ on a set of uncertain graphs. We show that the acceleration with the memory $M = 1$ provides the optimal convergence rate in the sense of worst-case performance. Several numerical examples are given to demonstrate the validity and performance of the theoretical results.      
### 75.Accelerated Graph Learning from Smooth Signals  [ :arrow_down: ](https://arxiv.org/pdf/2110.09677.pdf)
>  We consider network topology identification subject to a signal smoothness prior on the nodal observations. A fast dual-based proximal gradient algorithm is developed to efficiently tackle a strongly convex, smoothness-regularized network inverse problem known to yield high-quality graph solutions. Unlike existing solvers, the novel iterations come with global convergence rate guarantees and do not require additional step-size tuning. Reproducible simulated tests demonstrate the effectiveness of the proposed method in accurately recovering random and real-world graphs, markedly faster than state-of-the-art alternatives and without incurring an extra computational burden.      
### 76.A survey on active noise control techniques -- Part II: Nonlinear systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.09672.pdf)
>  Part I of this paper reviewed the development of the linear active noise control (ANC) technique in the past decade. However, ANC systems might have to deal with some nonlinear components and the performance of linear ANC techniques may degrade in this scenario. To overcome this limitation, nonlinear ANC (NLANC) algorithms were developed. In Part II, we review the development of NLANC algorithms during the last decade. The contributions of heuristic ANC algorithms are outlined. Moreover, we emphasize recent advances of NLANC algorithms, such as spline ANC algorithms, kernel adaptive filters, and nonlinear distributed ANC algorithms. Then, we present recent applications of ANC technique including linear and nonlinear perspectives. Future research challenges regarding ANC techniques are also discussed.      
### 77.Neural Synthesis of Footsteps Sound Effects with Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.09605.pdf)
>  Footsteps are among the most ubiquitous sound effects in multimedia applications. There is substantial research into understanding the acoustic features and developing synthesis models for footstep sound effects. In this paper, we present a first attempt at adopting neural synthesis for this task. We implemented two GAN-based architectures and compared the results with real recordings as well as six traditional sound synthesis methods. Our architectures reached realism scores as high as recorded samples, showing encouraging results for the task at hand.      
### 78.Who calls the shots? Rethinking Few-Shot Learning for Audio  [ :arrow_down: ](https://arxiv.org/pdf/2110.09600.pdf)
>  Few-shot learning aims to train models that can recognize novel classes given just a handful of labeled examples, known as the support set. While the field has seen notable advances in recent years, they have often focused on multi-class image classification. Audio, in contrast, is often multi-label due to overlapping sounds, resulting in unique properties such as polyphony and signal-to-noise ratios (SNR). This leads to unanswered questions concerning the impact such audio properties may have on few-shot learning system design, performance, and human-computer interaction, as it is typically up to the user to collect and provide inference-time support set examples. We address these questions through a series of experiments designed to elucidate the answers to these questions. We introduce two novel datasets, FSD-MIX-CLIPS and FSD-MIX-SED, whose programmatic generation allows us to explore these questions systematically. Our experiments lead to audio-specific insights on few-shot learning, some of which are at odds with recent findings in the image domain: there is no best one-size-fits-all model, method, and support set selection criterion. Rather, it depends on the expected application scenario. Our code and data are available at <a class="link-external link-https" href="https://github.com/wangyu/rethink-audio-fsl" rel="external noopener nofollow">this https URL</a>.      
### 79.Adversarial Domain Adaptation with Paired Examples for Acoustic Scene Classification on Different Recording Devices  [ :arrow_down: ](https://arxiv.org/pdf/2110.09598.pdf)
>  In classification tasks, the classification accuracy diminishes when the data is gathered in different domains. To address this problem, in this paper, we investigate several adversarial models for domain adaptation (DA) and their effect on the acoustic scene classification task. The studied models include several types of generative adversarial networks (GAN), with different loss functions, and the so-called cycle GAN which consists of two interconnected GAN models. The experiments are performed on the DCASE20 challenge task 1A dataset, in which we can leverage the paired examples of data recorded using different devices, i.e., the source and target domain recordings. The results of performed experiments indicate that the best performing domain adaptation can be obtained using the cycle GAN, which achieves as much as 66% relative improvement in accuracy for the target domain device, while only 6\% relative decrease in accuracy on the source domain. In addition, by utilizing the paired data examples, we are able to improve the overall accuracy over the model trained using larger unpaired data set, while decreasing the computational cost of the model training.      
