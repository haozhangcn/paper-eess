# ArXiv eess --Tue, 12 Oct 2021
### 1.Spatial-temporal V-Net for automatic segmentation and quantification of right ventricles in gated myocardial perfusion SPECT images  [ :arrow_down: ](https://arxiv.org/pdf/2110.05443.pdf)
>  Background. Functional assessment of right ventricles (RV) using gated myocardial perfusion single-photon emission computed tomography (MPS) heavily relies on the precise extraction of right ventricular contours. In this paper, we present a new deep learning model integrating both the spatial and temporal features in SPECT images to perform the segmentation of RV epicardium and endocardium. Methods. By integrating the spatial features from each cardiac frame of gated MPS and the temporal features from the sequential cardiac frames of the gated MPS, we develop a Spatial-Temporal V-Net (S-T-V-Net) for automatic extraction of RV endocardial and epicardial contours. In the S-T-V-Net, a V-Net is employed to hierarchically extract spatial features, and convolutional long-term short-term memory (ConvLSTM) units are added to the skip-connection pathway to extract the temporal features. The input of the S-T-V-Net is an ECG-gated sequence of the SPECT images and the output is the probability map of the endocardial or epicardial masks. A Dice similarity coefficient (DSC) loss which penalizes the discrepancy between the model prediction and the ground truth is adopted to optimize the segmentation model. Results. Our segmentation model was trained and validated on a retrospective dataset with 34 subjects, and the cardiac cycle of each subject was divided into 8 gates. The proposed ST-V-Net achieved a DSC of 0.7924 and 0.8227 for the RV endocardium and epicardium, respectively. The mean absolute error, the mean squared error, and the Pearson correlation coefficient of the RV ejection fraction between the ground truth and the model prediction are 0.0907, 0.0130 and 0.8411. Conclusion. The results demonstrate that the proposed ST-V-Net is an effective model for RV segmentation. It has great promise for clinical use in RV functional assessment.      
### 2.On the invertibility of a voice privacy system using embedding alignement  [ :arrow_down: ](https://arxiv.org/pdf/2110.05431.pdf)
>  This paper explores various attack scenarios on a voice anonymization system using embeddings alignment techniques. We use Wasserstein-Procrustes (an algorithm initially designed for unsupervised translation) or Procrustes analysis to match two sets of x-vectors, before and after voice anonymization, to mimic this transformation as a rotation function. We compute the optimal rotation and compare the results of this approximation to the official Voice Privacy Challenge results. We show that a complex system like the baseline of the Voice Privacy Challenge can be approximated by a rotation, estimated using a limited set of x-vectors. This paper studies the space of solutions for voice anonymization within the specific scope of rotations. Rotations being reversible, the proposed method can recover up to 62% of the speaker identities from anonymized embeddings.      
### 3.Safe Model-Based Reinforcement Learning Using Robust Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2110.05415.pdf)
>  Reinforcement Learning (RL) is effective in many scenarios. However, it typically requires the exploration of a sufficiently large number of state-action pairs, some of which may be unsafe. Consequently, its application to safety-critical systems remains a challenge. Towards this end, an increasingly common approach to address safety involves the addition of a safety layer that projects the RL actions onto a safe set of actions. In turn, a challenge for such frameworks is how to effectively couple RL with the safety layer to improve the learning performance. In the context of leveraging control barrier functions for safe RL training, prior work focuses on a restricted class of barrier functions and utilizes an auxiliary neural net to account for the effects of the safety layer which inherently results in an approximation. In this paper, we frame safety as a differentiable robust-control-barrier-function layer in a model-based RL framework. As such, this approach both ensures safety and effectively guides exploration during training resulting in increased sample efficiency as demonstrated in the experiments.      
### 4.Artificial Intelligence in Electric Machine Drives: Advances and Trends  [ :arrow_down: ](https://arxiv.org/pdf/2110.05403.pdf)
>  This review paper systematically summarizes the existing literature on applying classical AI techniques and advanced deep learning algorithms to electric machine drives. It is anticipated that with the rapid progress in deep learning models and embedded hardware platforms, AI-based data-driven approaches will become increasingly popular for the automated high-performance control of electric machines. Additionally, this paper also provides some outlook towards promoting its widespread application in the industry, such as implementing advanced RL algorithms with good domain adaptation and transfer learning capabilities and deploying them onto low-cost SoC FPGA devices.      
### 5.Local Effects of Grid-Forming Converters Providing Frequency Regulation to Bulk Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2110.05392.pdf)
>  The progressive displacing of conventional generation in favour of renewable energy sources requires restoring an adequate capacity of regulating power to ensure reliable operation of power systems. Battery Energy Storage Systems (BESSs) are considered to be promising assets to restore suitable frequency regulation capacity levels. BESSs are typically connected to the grid with power-converters, able to operate in either grid-forming or grid-following modes. This paper quantitatively assesses the impact on the local distribution grid of BESSs providing frequency regulation to bulk power systems. Specific metrics are proposed to compare the performance of grid-forming and grid-following control. Experimental results are obtained taking advantage of a 720 kVA/500 kWh BESS connected to the 20 kV distribution grid of the EPFL campus. The quantitative evaluation based on suitably proposed metrics confirms the superior performance of the grid-forming strategy, compared to the grid-following one.      
### 6.Edge-wise funnel output synchronization of heterogeneous agents with relative degree one  [ :arrow_down: ](https://arxiv.org/pdf/2110.05330.pdf)
>  In a recent work by three of the authors, in order to enforce synchronization for scalar heterogeneous multi-agent systems with some useful characteristics, a node-wise funnel coupling law was proposed. The emergent dynamics, to which each of the agents synchronizes, was characterized and it was studied how networks can be synthesized which exhibit these emergent dynamics. The advantage of this synthesis is its suitability for plug-and-play operation. However, the aforementioned emergent dynamics under node-wise funnel coupling are determined by an algebraic equation which does not admit an explicit solution in general, and even its pointwise solution proves rather difficult. Furthermore, the contractivity assumption on the emergent dynamics, required to establish the synchronization, is hard to be checked without solving the algebraic equation. To resolve these drawbacks, in the present paper we present a new funnel coupling law that uses edge-wise output differences. Under this novel coupling the benign properties of node-wise funnel coupling are retained, but the emergent dynamics are given explicitly by the blended dynamics of the multi-agent system, which already proved an advantageous tool in the analysis and design of such networks. Additionally, our results are not restricted to scalar systems and treat the case that neighboring agents only communicate their output information, and not their complete state.      
### 7.The Effects of Vehicle-to-Infrastructure Communication Reliability on Performance of Signalized Intersection Traffic Control  [ :arrow_down: ](https://arxiv.org/pdf/2110.05285.pdf)
>  A vehicle-to-infrastructure communication can inform an intersection controller about the location and speed of connected vehicles. Recently, the design of adaptive intersection control algorithms that take advantage of this information evoked a lot of research, typically assuming a perfect communication. In this study, we explore possible effects of a temporal decrease in the reliability of the communication channel, on a throughput of a signalized intersection. We model road traffic and DSRC-VANET communication by integrating the well-established traffic and communication simulation tools (Vissim and OMNeT++). Comparisons of the perfect communication conditions with challenging, but realistic conditions involving communication distortions show that the adaptive intersection control may suffer from significantly increased average delays of vehicles. The level of delays is largely independent of whether the communication distortions affect all or only a single intersection approach. For some signal groups, the average vehicle delays are significantly increased, while for the others they are decreased, leading to the disbalance and unfairness. We show that the data received in the previous time intervals and simple assumptions about the vehicle movements can be used to estimate the lost data. The compensation of the communication distortions affecting a single intersection approach decreases the average vehicle delays. When the communication distortions impacting all the intersection approaches are compensated for, the vehicle delays are even set back to the levels comparable with the perfect communication conditions. Overall, the results demonstrate that the impact of the communication distortions should be considered in the design of the adaptive intersection control algorithms.      
### 8.Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05267.pdf)
>  Speech enhancement (SE) aims to suppress the additive noise from a noisy speech signal to improve the speech's perceptual quality and intelligibility. However, the over-suppression phenomenon in the enhanced speech might degrade the performance of downstream automatic speech recognition (ASR) task due to the missing latent information. To alleviate such problem, we propose an interactive feature fusion network (IFF-Net) for noise-robust speech recognition to learn complementary information from the enhanced feature and original noisy feature. Experimental results show that the proposed method achieves absolute word error rate (WER) reduction of 4.1% over the best baseline on RATS Channel-A corpus. Our further analysis indicates that the proposed IFF-Net can complement some missing information in the over-suppressed enhanced feature.      
### 9.A Comparative Study on Non-Autoregressive Modelings for Speech-to-Text Generation  [ :arrow_down: ](https://arxiv.org/pdf/2110.05249.pdf)
>  Non-autoregressive (NAR) models simultaneously generate multiple outputs in a sequence, which significantly reduces the inference speed at the cost of accuracy drop compared to autoregressive baselines. Showing great potential for real-time applications, an increasing number of NAR models have been explored in different fields to mitigate the performance gap against AR models. In this work, we conduct a comparative study of various NAR modeling methods for end-to-end automatic speech recognition (ASR). Experiments are performed in the state-of-the-art setting using ESPnet. The results on various tasks provide interesting findings for developing an understanding of NAR ASR, such as the accuracy-speed trade-off and robustness against long-form utterances. We also show that the techniques can be combined for further improvement and applied to NAR end-to-end speech translation. All the implementations are publicly available to encourage further research in NAR speech processing.      
### 10.Score-based diffusion models for accelerated MRI  [ :arrow_down: ](https://arxiv.org/pdf/2110.05243.pdf)
>  Score-based diffusion models provide a powerful way to model images using the gradient of the data distribution. Leveraging the learned score function as a prior, here we introduce a way to sample data from a conditional distribution given the measurements, such that the model can be readily used for solving inverse problems in imaging, especially for accelerated MRI. In short, we train a continuous time-dependent score function with denoising score matching. Then, at the inference stage, we iterate between numerical SDE solver and data consistency projection step to achieve reconstruction. Our model requires magnitude images only for training, and yet is able to reconstruct complex-valued data, and even extends to parallel imaging. The proposed method is agnostic to sub-sampling patterns, and can be used with any sampling schemes. Also, due to its generative nature, our approach can quantify uncertainty, which is not possible with standard regression settings. On top of all the advantages, our method also has very strong performance, even beating the models trained with full supervision. With extensive experiments, we verify the superiority of our method in terms of quality and practicality.      
### 11.Streaming Transformer Transducer Based Speech Recognition Using Non-Causal Convolution  [ :arrow_down: ](https://arxiv.org/pdf/2110.05241.pdf)
>  This paper improves the streaming transformer transducer for speech recognition by using non-causal convolution. Many works apply the causal convolution to improve streaming transformer ignoring the lookahead context. We propose to use non-causal convolution to process the center block and lookahead context separately. This method leverages the lookahead context in convolution and maintains similar training and decoding efficiency. Given the similar latency, using the non-causal convolution with lookahead context gives better accuracy than causal convolution, especially for open-domain dictation scenarios. Besides, this paper applies talking-head attention and a novel history context compression scheme to further improve the performance. The talking-head attention improves the multi-head self-attention by transferring information among different heads. The history context compression method introduces more extended history context compactly. On our in-house data, the proposed methods improve a small Emformer baseline with lookahead context by relative WERR 5.1\%, 14.5\%, 8.4\% on open-domain dictation, assistant general scenarios, and assistant calling scenarios, respectively.      
### 12.Efficient Cell-Specific Beamforming for Large Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2110.05214.pdf)
>  We propose an efficient method for designing broad beams with spatially flat array factor and efficient power utilization for cell-specific coverage in communication systems equipped with large antenna arrays. To ensure full power efficiency, the method is restricted to phase-only weight manipulations. Our framework is based on the discovered connection between dual-polarized beamforming and polyphase Golay sequences. Exploiting this connection, we propose several methods for array expansion from smaller to larger sizes, while preserving the radiation pattern. In addition, to fill the gaps in the feasible array sizes, we introduce the concept of $\epsilon$-complementarity that relaxes the requirement on zero side lobes of the sum aperiodic autocorrelation function of a sequence pair. Furthermore, we develop a modified Great Deluge algorithm (MGDA) that finds $\epsilon$-complementary pairs of arbitrary length, and hence enables broad beamforming for arbitrarily-sized uniform linear arrays. We also discuss the extension of this approach to two-dimensional uniform rectangular arrays. Our numerical results demonstrate the superiority of the proposed approach with respect to existing beam-broadening methods.      
### 13.Tracking of stabilizing, optimal control in fixed-time based on time-varying objective function  [ :arrow_down: ](https://arxiv.org/pdf/2110.05203.pdf)
>  The controller of an input-affine system is determined through minimizing a time-varying objective function, where stabilization is ensured via a Lyapunov function decay condition as constraint. This constraint is incorporated into the objective function via a barrier function. The time-varying minimum of the resulting relaxed cost function is determined by a tracking system. This system is constructed using derivatives up to second order of the relaxed cost function and improves the existing approaches in time-varying optimization. Under some mild assumptions, the tracking system yields a solution which is feasible for all times, and it converges to the optimal solution of the relaxed objective function in a user-defined fixed-time. The effectiveness of these results in comparison to exponential convergence is demonstrated in a case study.      
### 14.Service Scheduling for Random Requests with Fixed Waiting Costs  [ :arrow_down: ](https://arxiv.org/pdf/2110.05148.pdf)
>  We study service scheduling problems in a slotted system in which agents arrive with service requests according to a Bernoulli process and have to leave within two slots after arrival, service costs are quadratic in service rates, and there are also waiting costs. We consider fixed waiting costs. We frame the problems as average cost Markov decision processes. While the studied system is a linear system with quadratic costs, it has state dependent control. Moreover, it also possesses a non-standard cost function structure in the case of fixed waiting costs, rendering the optimization problem complex. Here, we characterize optimal policy. We also consider a system in which the agents make scheduling decisions for their respective service requests keeping their own cost in view. We again consider fixed waiting costs and frame this scheduling problem as a stochastic game. Here, we provide Nash equilibrium.      
### 15.AWEU-Net: An Attention-Aware Weight Excitation U-Net for Lung Nodule Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2110.05144.pdf)
>  Lung cancer is deadly cancer that causes millions of deaths every year around the world. Accurate lung nodule detection and segmentation in computed tomography (CT) images is the most important part of diagnosing lung cancer in the early stage. Most of the existing systems are semi-automated and need to manually select the lung and nodules regions to perform the segmentation task. To address these challenges, we proposed a fully automated end-to-end lung nodule detection and segmentation system based on a deep learning approach. In this paper, we used Optimized Faster R-CNN; a state-of-the-art detection model to detect the lung nodule regions in the CT scans. Furthermore, we proposed an attention-aware weight excitation U-Net, called AWEU-Net, for lung nodule segmentation and boundaries detection. To achieve more accurate nodule segmentation, in AWEU-Net, we proposed position attention-aware weight excitation (PAWE), and channel attention-aware weight excitation (CAWE) blocks to highlight the best aligned spatial and channel features in the input feature maps. The experimental results demonstrate that our proposed model yields a Dice score of 89.79% and 90.35%, and an intersection over union (IoU) of 82.34% and 83.21% on the publicly LUNA16 and LIDC-IDRI datasets, respectively.      
### 16.Non-Parametric Neuro-Adaptive Coordination of Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.05125.pdf)
>  We develop a learning-based algorithm for the distributed formation control of networked multi-agent systems governed by unknown, nonlinear dynamics. Most existing algorithms either assume certain parametric forms for the unknown dynamic terms or resort to unnecessarily large control inputs in order to provide theoretical guarantees. The proposed algorithm avoids these drawbacks by integrating neural network-based learning with adaptive control in a two-step procedure. In the first step of the algorithm, each agent learns a controller, represented as a neural network, using training data that correspond to a collection of formation tasks and agent parameters. These parameters and tasks are derived by varying the nominal agent parameters and the formation specifications of the task in hand, respectively. In the second step of the algorithm, each agent incorporates the trained neural network into an online and adaptive control policy in such a way that the behavior of the multi-agent closed-loop system satisfies a user-defined formation task. Both the learning phase and the adaptive control policy are distributed, in the sense that each agent computes its own actions using only local information from its neighboring agents. The proposed algorithm does not use any a priori information on the agents' unknown dynamic terms or any approximation schemes. We provide formal theoretical guarantees on the achievement of the formation task.      
### 17.State Estimation Using a Network of Distributed Observers With Unknown Inputs  [ :arrow_down: ](https://arxiv.org/pdf/2110.05078.pdf)
>  State estimation for a class of linear time-invariant systems with distributed output measurements (distributed sensors) and unknown inputs is addressed in this paper. The objective is to design a network of observers such that the state vector of the entire system can be estimated, while each observer (or node) has access to only local output measurements that may not be sufficient on its own to reconstruct the entire system's state. Existing results in the literature on distributed state estimation assume either that the system does not have inputs, or that all the system's inputs are globally known to all the observers. Accordingly, we address this gap by proposing a distributed observer capable of estimating the overall system's state in the presence of inputs, while each node only has limited local information on inputs and outputs. We provide a design method that guarantees convergence of the estimation errors under some mild joint detectability conditions. This design suits undirected communication graphs that may have switching topologies and also applies to strongly connected directed graphs. We also give existence conditions that harmonize with existing results on unknown input observers. Finally, simulation results verify the effectiveness of the proposed estimation scheme for various scenarios.      
### 18.Compressive Sensing Based Adaptive Defence Against Adversarial Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.05077.pdf)
>  Herein, security of deep neural network against adversarial attack is considered. Existing compressive sensing based defence schemes assume that adversarial perturbations are usually on high frequency components, whereas recently it has been shown that low frequency perturbations are more effective. This paper proposes a novel Compressive sensing based Adaptive Defence (CAD) algorithm which combats distortion in frequency domain instead of time domain. Unlike existing literature, the proposed CAD algorithm does not use information about the type of attack such as l0, l2, l-infinity etc. CAD algorithm uses exponential weight algorithm for exploration and exploitation to identify the type of attack, compressive sampling matching pursuit (CoSaMP) to recover the coefficients in spectral domain, and modified basis pursuit using a novel constraint for l0, l-infinity norm attack. Tight performance bounds for various recovery schemes meant for various attack types are also provided. Experimental results against five state-of-the-art white box attacks on MNIST and CIFAR-10 show that the proposed CAD algorithm achieves excellent classification accuracy and generates good quality reconstructed image with much lower computation      
### 19.Symmetry-Enhanced Attention Network for Acute Ischemic Infarct Segmentation with Non-Contrast CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.05039.pdf)
>  Quantitative estimation of the acute ischemic infarct is crucial to improve neurological outcomes of the patients with stroke symptoms. Since the density of lesions is subtle and can be confounded by normal physiologic changes, anatomical asymmetry provides useful information to differentiate the ischemic and healthy brain tissue. In this paper, we propose a symmetry enhanced attention network (SEAN) for acute ischemic infarct segmentation. Our proposed network automatically transforms an input CT image into the standard space where the brain tissue is bilaterally symmetric. The transformed image is further processed by a Ushape network integrated with the proposed symmetry enhanced attention for pixel-wise labelling. The symmetry enhanced attention can efficiently capture context information from the opposite side of the image by estimating long-range dependencies. Experimental results show that the proposed SEAN outperforms some symmetry-based state-of-the-art methods in terms of both dice coefficient and infarct localization.      
### 20.Multi-View Self-Attention Based Transformer for Speaker Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05036.pdf)
>  Initially developed for natural language processing (NLP), Transformer model is now widely used for speech processing tasks such as speaker recognition, due to its powerful sequence modeling capabilities. However, conventional self-attention mechanisms are originally designed for modeling textual sequence without considering the characteristics of speech and speaker modeling. Besides, different Transformer variants for speaker recognition have not been well studied. In this work, we propose a novel multi-view self-attention mechanism and present an empirical study of different Transformer variants with or without the proposed attention mechanism for speaker recognition. Specifically, to balance the capabilities of capturing global dependencies and modeling the locality, we propose a multi-view self-attention mechanism for speaker Transformer, in which different attention heads can attend to different ranges of the receptive field. Furthermore, we introduce and compare five Transformer variants with different network architectures, embedding locations, and pooling methods to learn speaker embeddings. Experimental results on the VoxCeleb1 and VoxCeleb2 datasets show that the proposed multi-view self-attention mechanism achieves improvement in the performance of speaker recognition, and the proposed speaker Transformer network attains excellent results compared with state-of-the-art models.      
### 21.When is gray-box modeling advantageous for virtual flow metering?  [ :arrow_down: ](https://arxiv.org/pdf/2110.05034.pdf)
>  Integration of physics and machine learning in virtual flow metering applications is known as gray-box modeling. The combination is believed to enhance multiphase flow rate predictions. However, the superiority of gray-box models is yet to be demonstrated in the literature. This article examines scenarios where a gray-box model is expected to outperform physics-based and data-driven models. The experiments are conducted with synthetic data where properties of the underlying data generating process are known and controlled. The results show that a gray-box model yields increased prediction accuracy over a physics-based model in the presence of process-model mismatch. They also show improvements over a data-driven model when the amount of available data is small. On the other hand, gray-box and data-driven models are similarly influenced by noisy measurements. Lastly, the results indicate that a gray-box approach may be advantageous in nonstationary process conditions. Unfortunately, choosing the best model prior to training is challenging, and overhead on model development is unavoidable.      
### 22.Internal Feedback in Biological Control: Constraints and Layered Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2110.05029.pdf)
>  Feedback is ubiquitous in both biological and engineered control systems. In biology, in addition to typical feedback between plant and controller, we observe feedback pathways within control systems, which we call internal feedback pathways (IFPs), that are often very complex. IFP is most familiar in neural systems, our primary motivation, but it appears everywhere from bacterial signal transduction to the human immune system. Standard modern and robust control theory potentially explains some previously cryptic IFP, but new theory expands this substantially. In this paper we describe the biology motivation for studying complex IFP and introduce the concepts necessary to explain it. The requisite theory will be explored in more detail in several companion papers.      
### 23.Understanding the Safety Requirements for Learning-based Power Systems Operations  [ :arrow_down: ](https://arxiv.org/pdf/2110.04983.pdf)
>  Recent advancements in machine learning and reinforcement learning have brought increased attention to their applicability in a range of decision-making tasks in the operations of power systems, such as short-term emergency control, Volt/VAr control, long-term residential demand response and battery energy management. Despite the promises of providing strong representation of complex system dynamics and fast, efficient learned operation strategies, the safety requirements of such learning paradigms are less discussed. This paper explores the design requirements on both data and model side of such learning algorithms by exploiting the impacts of adversarial attacks on safety critical system operations. Case studies performed on both voltage regulation and topology control tasks demonstrated the potential vulnerabilities of the standard reinforcement learning algorithms, and possible measures of machine learning robustness and security are discussed for power systems operation tasks.      
### 24.An Efficient Deep Learning Model for Automatic Modulation Recognition Based on Parameter Estimation and Transformation  [ :arrow_down: ](https://arxiv.org/pdf/2110.04980.pdf)
>  Automatic modulation recognition (AMR) is a promising technology for intelligent communication receivers to detect signal modulation schemes. Recently, the emerging deep learning (DL) research has facilitated high-performance DL-AMR approaches. However, most DL-AMR models only focus on recognition accuracy, leading to huge model sizes and high computational complexity, while some lightweight and low-complexity models struggle to meet the accuracy requirements. This letter proposes an efficient DL-AMR model based on phase parameter estimation and transformation, with convolutional neural network (CNN) and gated recurrent unit (GRU) as the feature extraction layers, which can achieve high recognition accuracy equivalent to the existing state-of-the-art models but reduces more than a third of the volume of their parameters. Meanwhile, our model is more competitive in training time and test time than the benchmark models with similar recognition accuracy. Moreover, we further propose to compress our model by pruning, which maintains the recognition accuracy higher than 90% while has less than 1/8 of the number of parameters comparing with state-of-the-art models.      
### 25.Koopman Operator Based Modeling and Control of Rigid Body Motion Represented by Dual Quaternions  [ :arrow_down: ](https://arxiv.org/pdf/2110.04967.pdf)
>  In this paper, we systematically derive a finite set of Koopman based observables to construct a lifted linear state space model that describes the rigid body dynamics based on the dual quaternion representation. In general, the Koopman operator is a linear infinite dimensional operator, which means that the derived linear state space model of the rigid body dynamics will be infinite-dimensional, which is not suitable for modeling and control design purposes. Recently, finite approximations of the operator computed by means of methods like the Extended Dynamic Mode Decomposition (EDMD) have shown promising results for different classes of problems. However, without using an appropriate set of observables in the EDMD approach, there can be no guarantees that the computed approximation of the nonlinear dynamics is sufficiently accurate. The major challenge in using the Koopman operator for constructing a linear state space model is the choice of observables. State-of-the-art methods in the field compute the approximations of the observables by using neural networks, standard radial basis functions (RBFs), polynomials or heuristic approximations of these functions. However, these observables might not providea sufficiently accurate approximation or representation of the dynamics. In contrast, we first show the pointwise convergence of the derived observable functions to zero, thereby allowing us to choose a finite set of these observables. Next, we use the derived observables in EDMD to compute the lifted linear state and input matrices for the rigid body dynamics. Finally, we show that an LQR type (linear) controller, which is designed based on the truncated linear state space model, can steer the rigid body to a desired state while its performance is commensurate with that of a nonlinear controller. The efficacy of our approach is demonstrated through numerical simulations.      
### 26.Advancing Momentum Pseudo-Labeling with Conformer and Initialization Strategy  [ :arrow_down: ](https://arxiv.org/pdf/2110.04948.pdf)
>  Pseudo-labeling (PL), a semi-supervised learning (SSL) method where a seed model performs self-training using pseudo-labels generated from untranscribed speech, has been shown to enhance the performance of end-to-end automatic speech recognition (ASR). Our prior work proposed momentum pseudo-labeling (MPL), which performs PL-based SSL via an interaction between online and offline models, inspired by the mean teacher framework. MPL achieves remarkable results on various semi-supervised settings, showing robustness to variations in the amount of data and domain mismatch severity. However, there is further room for improving the seed model used to initialize the MPL training, as it is in general critical for a PL-based method to start training from high-quality pseudo-labels. To this end, we propose to enhance MPL by (1) introducing the Conformer architecture to boost the overall recognition accuracy and (2) exploiting iterative pseudo-labeling with a language model to improve the seed model before applying MPL. The experimental results demonstrate that the proposed approaches effectively improve MPL performance, outperforming other PL-based methods. We also present in-depth investigations to make our improvements effective, e.g., with regard to batch normalization typically used in Conformer and LM quality.      
### 27.Application of Neural Network in Optimization of Chemical Process  [ :arrow_down: ](https://arxiv.org/pdf/2110.04942.pdf)
>  Artificial neural network (ANN) has been widely used due to its strong nonlinear mapping ability, fault tolerance and self-learning ability. This article summarizes the development history of artificial neural networks, introduces three common neural network types, BP neural network, RBF neural network and convolutional neural network, and focuses on the practical application in chemical process optimization, especially the results achieved in multi-objective control optimization and process parameter improvement.      
### 28.A Hybrid Scattering Transform for Signals with Isolated Singularities  [ :arrow_down: ](https://arxiv.org/pdf/2110.04910.pdf)
>  The scattering transform is a wavelet-based model of Convolutional Neural Networks originally introduced by S. Mallat. Mallat's analysis shows that this network has desirable stability and invariance guarantees and therefore helps explain the observation that the filters learned by early layers of a Convolutional Neural Network typically resemble wavelets. Our aim is to understand what sort of filters should be used in the later layers of the network. Towards this end, we propose a two-layer hybrid scattering transform. In our first layer, we convolve the input signal with a wavelet filter transform to promote sparsity, and, in the second layer, we convolve with a Gabor filter to leverage the sparsity created by the first layer. We show that these measurements characterize information about signals with isolated singularities. We also show that the Gabor measurements used in the second layer can be used to synthesize sparse signals such as those produced by the first layer.      
### 29.Personalizing ASR with limited data using targeted subset selection  [ :arrow_down: ](https://arxiv.org/pdf/2110.04908.pdf)
>  We study the task of personalizing ASR models to a target non-native speaker/accent while being constrained by a transcription budget on the duration of utterances selected from a large unlabelled corpus. We propose a subset selection approach using the recently proposed submodular mutual information functions, in which we identify a diverse set of utterances that match the target speaker/accent. This is specified through a few target utterances and achieved by modelling the relationship between the target subset and the selected subset using submodular mutual information functions. This method is applied at both the speaker and accent levels. We personalize the model by fine tuning it with utterances selected and transcribed from the unlabelled corpus. Our method is able to consistently identify utterances from the target speaker/accent using just speech features. We show that the targeted subset selection approach improves upon random sampling by as much as 2% to 5% (absolute) depending on the speaker and accent and is 2x to 4x more label-efficient compared to random sampling. We also compare with a skyline where we specifically pick from the target and generally outperforms the oracle in its selections.      
### 30.NormVAE: Normative Modeling on Neuroimaging Data using Variational Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2110.04903.pdf)
>  Normative modeling is an emerging method for understanding the heterogeneous biology underlying neuropsychiatric and neurodegenerative disorders at the level of the individual participant. Deep autoencoders have been implemented as normative models, where patient-level deviations are modelled as the squared difference between the actual and reconstructed input without any uncertainty estimates in the deviations. In this study, we assessed NormVAE, a novel normative modeling based variational autoencoder (VAE) which calculates subject-level normative abnormality maps (NAM) for quantifying uncertainty in the deviations. Our experiments on brain neuroimaging data of Alzheimer's Disease (AD) patients demonstrated that the NormVAE-generated patient-level abnormality maps exhibit increased sensitivity to disease staging compared to a baseline VAE, which generates deterministic subject-level deviations without any uncertainty estimates.      
### 31.Near-Field Wireless Power Transfer with Dynamic Metasurface Antennas  [ :arrow_down: ](https://arxiv.org/pdf/2110.04885.pdf)
>  Radio frequency wireless power transfer (WPT) enables charging low-power mobile devices without relying on wired infrastructure. Current existing WPT systems are typically designed assuming far-field propagation, where the radiated energy is steered in given angles, resulting in limited efficiency and possible radiation in undesired locations. When large arrays at high frequencies, such as DMA, are employed, WPT might take place in the radiating near-field (Fresnel) region where spherical wave propagation holds, rather than plane wave propagation as in the far-field. In this paper, we study WPT systems charging multiple devices in the Fresnel region, where the energy transmitter is equipped with an emerging DMA, exploring how the antenna configuration can exploit the spherical wavefront to generate focused energy beams. In particular, after presenting a mathematical model for DMA-based radiating near-field WPT systems, we characterize the weighted sum-harvested energy maximization problem of the considered system, and we propose an efficient solution to jointly design the DMA weights and digital precoding vector. Simulation results show that our design generates focused energy beams that are capable of improving energy transfer efficiency in the radiating near-field with minimal energy pollution.      
### 32.Injecting Text and Cross-lingual Supervision in Few-shot Learning from Self-Supervised Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.04863.pdf)
>  Self-supervised model pre-training has recently garnered significant interest, but relatively few efforts have explored using additional resources in fine-tuning these models. We demonstrate how universal phoneset acoustic models can leverage cross-lingual supervision to improve transfer of pretrained self-supervised representations to new languages. We also show how target-language text can be used to enable and improve fine-tuning with the lattice-free maximum mutual information (LF-MMI) objective. In three low-resource languages these techniques greatly improved few-shot learning performance.      
### 33.Deep Reinforcement Learning for Optimizing RIS-Assisted HD-FD Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.04859.pdf)
>  This letter investigates the reconfigurable intelligent surface (RIS)-assisted multiple-input single-output (MISO) wireless system, where both half-duplex (HD) and full-duplex (FD) operating modes are considered together, for the first time in the literature. The goal is to maximize the rate by optimizing the RIS phase shifts. A novel deep reinforcement learning (DRL) algorithm is proposed to solve the formulated non-convex optimization problem. The complexity analysis and Monte Carlo simulations illustrate that the proposed DRL algorithm significantly improves the rate compared to the non-optimized scenario in both HD and FD operating modes using a single parameter setting. Besides, it significantly reduces the computational complexity of the downlink HD MISO system and improves the achievable rate with a reduced number of steps per episode compared to the conventional DRL algorithm.      
### 34.Direct source and early reflections localization using deep deconvolution network under reverbrate environment  [ :arrow_down: ](https://arxiv.org/pdf/2110.04850.pdf)
>  This paper proposes a deconvolution-based network (DCNN) model for DOA estimation of direct source and early reflections under reverberate scenarios. Considering that the first-order reflections of the sound source also contain spatial directivity like the direct source, we treat both of them as the sources in the learning process. We use the covariance matrix of high order Ambisonics (HOA) signals in time domain as the input feature of the network, which is concise while contains precise spatial information under reverberate scenarios. Besides, we use the deconvolution-based network for the spatial pseudo-spectrum (SPS) reconstruction in the 2D polar space, based on which the spatial relationship between elevation and azimuth can be depicted. We have carried out a series of experiments based on simulated and measured data under different reverberate scenarios, which prove the robustness and accuracy of the proposed DCNN model.      
### 35.A Variational Bayes Moving Horizon Estimation Adaptive Filter with Guaranteed Stability  [ :arrow_down: ](https://arxiv.org/pdf/2110.04817.pdf)
>  This paper addresses state estimation of linear systems with special attention on unknown process and measurement noise covariances, aiming to enhance estimation accuracy while preserving the stability guarantee of the Kalman filter. To this end, the full information estimation problem over a finite interval is firstly addressed. Then, a novel adaptive variational Bayesian (VB) moving horizon estimation (MHE) method is proposed, exploiting VB inference, MHE and Monte Carlo integration with importance sampling for joint estimation of the unknown process and measurement noise covariances, along with the state trajectory over a moving window of fixed length. Further, it is proved that the proposed adaptive VB MHE filter ensures mean-square boundedness of the estimation error with any number of importance samples and VB iterations, as well as for any window length. Finally, simulation results on a target tracking example demonstrate the effectiveness of the VB MHE filter with enhanced estimation accuracy and convergence properties compared to the conventional non-adaptive Kalman filter and other existing adaptive filters.      
### 36.Stepwise-Refining Speech Separation Network via Fine-Grained Encoding in High-order Latent Domain  [ :arrow_down: ](https://arxiv.org/pdf/2110.04791.pdf)
>  The crux of single-channel speech separation is how to encode the mixture of signals into such a latent embedding space that the signals from different speakers can be precisely separated. Existing methods for speech separation either transform the speech signals into frequency domain to perform separation or seek to learn a separable embedding space by constructing a latent domain based on convolutional filters. While the latter type of methods learning an embedding space achieves substantial improvement for speech separation, we argue that the embedding space defined by only one latent domain does not suffice to provide a thoroughly separable encoding space for speech separation. In this paper, we propose the Stepwise-Refining Speech Separation Network (SRSSN), which follows a coarse-to-fine separation framework. It first learns a 1-order latent domain to define an encoding space and thereby performs a rough separation in the coarse phase. Then the proposed SRSSN learns a new latent domain along each basis function of the existing latent domain to obtain a high-order latent domain in the refining phase, which enables our model to perform a refining separation to achieve a more precise speech separation. We demonstrate the effectiveness of our SRSSN by conducting extensive experiments, including speech separation in a clean (noise-free) setting on WSJ0-2/3mix datasets as well as in noisy/reverberant settings on WHAM!/WHAMR! datasets. Furthermore, we also perform experiments of speech recognition on separated speech signals by our model to evaluate the performance of speech separation indirectly.      
### 37.Estimating the confidence of speech spoofing countermeasure  [ :arrow_down: ](https://arxiv.org/pdf/2110.04775.pdf)
>  Conventional speech spoofing countermeasures (CMs) are designed to make a binary decision on an input trial. However, a CM trained on a closed-set database is theoretically not guaranteed to perform well on unknown spoofing attacks. In some scenarios, an alternative strategy is to let the CM defer a decision when it is not confident. The question is then how to estimate a CM's confidence regarding an input trial. We investigated a few confidence estimators that can be easily plugged into a CM. On the ASVspoof2019 logical access database, the results demonstrate that an energy-based estimator and a neural-network-based one achieved acceptable performance in identifying unknown attacks in the test set. On a test set with additional unknown attacks and bona fide trials from other databases, the confidence estimators performed moderately well, and the CMs better discriminated bona fide and spoofed trials that had a high confidence score. Additional results also revealed the difficulty in enhancing a confidence estimator by adding unknown attacks to the training set.      
### 38.Rethinking Noise Synthesis and Modeling in Raw Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2110.04756.pdf)
>  The lack of large-scale real raw image denoising dataset gives rise to challenges on synthesizing realistic raw image noise for training denoising models. However, the real raw image noise is contributed by many noise sources and varies greatly among different sensors. Existing methods are unable to model all noise sources accurately, and building a noise model for each sensor is also laborious. In this paper, we introduce a new perspective to synthesize noise by directly sampling from the sensor's real noise. It inherently generates accurate raw image noise for different camera sensors. Two efficient and generic techniques: pattern-aligned patch sampling and high-bit reconstruction help accurate synthesis of spatial-correlated noise and high-bit noise respectively. We conduct systematic experiments on SIDD and ELD datasets. The results show that (1) our method outperforms existing methods and demonstrates wide generalization on different sensors and lighting conditions. (2) Recent conclusions derived from DNN-based noise modeling methods are actually based on inaccurate noise parameters. The DNN-based methods still cannot outperform physics-based statistical methods.      
### 39.Uncertainty in Data-Driven Kalman Filtering for Partially Known State-Space Models  [ :arrow_down: ](https://arxiv.org/pdf/2110.04738.pdf)
>  Providing a metric of uncertainty alongside a state estimate is often crucial when tracking a dynamical system. Classic state estimators, such as the Kalman filter (KF), provide a time-dependent uncertainty measure from knowledge of the underlying statistics, however, deep learning based tracking systems struggle to reliably characterize uncertainty. In this paper, we investigate the ability of KalmanNet, a recently proposed hybrid model-based deep state tracking algorithm, to estimate an uncertainty measure. By exploiting the interpretable nature of KalmanNet, we show that the error covariance matrix can be computed based on its internal features, as an uncertainty measure. We demonstrate that when the system dynamics are known, KalmanNet-which learns its mapping from data without access to the statistics-provides uncertainty similar to that provided by the KF; and while in the presence of evolution model-mismatch, KalmanNet pro-vides a more accurate error estimation.      
### 40.Prior Attention Network for Multi-Lesion Segmentation in Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2110.04735.pdf)
>  The accurate segmentation of multiple types of lesions from adjacent tissues in medical images is significant in clinical practice. Convolutional neural networks (CNNs) based on the coarse-to-fine strategy have been widely used in this field. However, multi-lesion segmentation remains to be challenging due to the uncertainty in size, contrast, and high interclass similarity of tissues. In addition, the commonly adopted cascaded strategy is rather demanding in terms of hardware, which limits the potential of clinical deployment. To address the problems above,we propose a novel Prior Attention Network (PANet) that follows the coarse-to-fine strategy to perform multi-lesion segmentation in medical images. The proposed network achieves the two steps of segmentation in a single network by inserting lesion-related spatial attention mechanism in the network. Further, we also propose the intermediate supervision strategy for generating lesion-related attention to acquire the regions of interest (ROIs), which accelerates the convergence and obviously improves the segmentation performance. We have investigated the proposed segmentation framework in two applications: 2D segmentation of multiple lung infections in lung CT slices and 3D segmentation of multiple lesions in brain MRIs. Experimental results show that in both 2D and 3D segmentation tasks our proposed network achieves better performance with less computational cost compared with cascaded networks. The proposed network can be regarded as a universal solution to multi-lesion segmentation in both 2D and 3D tasks. The source code is available at: <a class="link-external link-https" href="https://github.com/hsiangyuzhao/PANet" rel="external noopener nofollow">this https URL</a>.      
### 41.RTSNET: Deep Learning Aided Kalman Smoothing  [ :arrow_down: ](https://arxiv.org/pdf/2110.04717.pdf)
>  The smoothing task is the core of many signal processing applications. It deals with the recovery of a sequence of hidden state variables from a sequence of noisy observations in a one-shot manner. In this work, we propose RTSNet, a highly efficient model-based, and data-driven smoothing algorithm. RTSNet integrates dedicated trainable models into the flow of the classical Rauch-Tung-Striebel (RTS) smoother and is able to outperform it when operating under model mismatch and non-linearities while retaining its efficiency and interoperability. Our numerical study demonstrates that althoughRTSNet is based on more compact neural networks, which leads to faster training and inference times, it outperforms the state-of-the-art data-driven smoother in a non-linear use case.      
### 42.Stable and Transferable Wireless Resource Allocation Policies via Manifold Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.04706.pdf)
>  We consider the problem of resource allocation in large scale wireless networks. When contextualizing wireless network structures as graphs, we can model the limits of very large wireless systems as manifolds. To solve the problem in the machine learning framework, we propose the use of Manifold Neural Networks (MNNs) as a policy parametrization. In this work, we prove the stability of MNN resource allocation policies under the absolute perturbations to the Laplace-Beltrami operator of the manifold, representing system noise and dynamics present in wireless systems. These results establish the use of MNNs in achieving stable and transferable allocation policies for large scale wireless networks. We verify our results in numerical simulations that show superior performance relative to baseline methods.      
### 43.Stability of Neural Networks on Manifolds to Relative Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2110.04702.pdf)
>  Graph Neural Networks (GNNs) show impressive performance in many practical scenarios, which can be largely attributed to their stability properties. Empirically, GNNs can scale well on large size graphs, but this is contradicted by the fact that existing stability bounds grow with the number of nodes. Graphs with well-defined limits can be seen as samples from manifolds. Hence, in this paper, we analyze the stability properties of convolutional neural networks on manifolds to understand the stability of GNNs on large graphs. Specifically, we focus on stability to relative perturbations of the Laplace-Beltrami operator. To start, we construct frequency ratio threshold filters which separate the infinite-dimensional spectrum of the Laplace-Beltrami operator. We then prove that manifold neural networks composed of these filters are stable to relative operator perturbations. As a product of this analysis, we observe that manifold neural networks exhibit a trade-off between stability and discriminability. Finally, we illustrate our results empirically in a wireless resource allocation scenario where the transmitter-receiver pairs are assumed to be sampled from a manifold.      
### 44.Multi-Channel End-to-End Neural Diarization with Distributed Microphones  [ :arrow_down: ](https://arxiv.org/pdf/2110.04694.pdf)
>  Recent progress on end-to-end neural diarization (EEND) has enabled overlap-aware speaker diarization with a single neural network. This paper proposes to enhance EEND by using multi-channel signals from distributed microphones. We replace Transformer encoders in EEND with two types of encoders that process a multi-channel input: spatio-temporal and co-attention encoders. Both are independent of the number and geometry of microphones and suitable for distributed microphone settings. We also propose a model adaptation method using only single-channel recordings. With simulated and real-recorded datasets, we demonstrated that the proposed method outperformed conventional EEND when a multi-channel input was given while maintaining comparable performance with a single-channel input. We also showed that the proposed method performed well even when spatial information is inoperative given multi-channel inputs, such as in hybrid meetings in which the utterances of multiple remote participants are played back from the same loudspeaker.      
### 45.Poformer: A simple pooling transformer for speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2110.04692.pdf)
>  Most recent speaker verification systems are based on extracting speaker embeddings using a deep neural network. The pooling layer in the network aims to aggregate frame-level features extracted by the backbone. In this paper, we propose a new transformer based pooling structure called PoFormer to enhance the ability of the pooling layer to capture information along the whole time axis. Different from previous works that apply attention mechanism in a simple way or implement the multi-head mechanism in serial instead of in parallel, PoFormer follows the initial transformer structure with some minor modifications like a positional encoding generator, drop path and LayerScale to make the training procedure more stable and to prevent overfitting. Evaluated on various datasets, PoFormer outperforms the existing pooling system with at least a 13.00% improvement in EER and a 9.12% improvement in minDCF.      
### 46.Analysis of Ground Plane Size, Topography and Location on a Monopole Antenna's Performance Utilizing 3-D Printing  [ :arrow_down: ](https://arxiv.org/pdf/2110.04670.pdf)
>  The monopole antenna is widely used in communication applications and is typically mounted on various surfaces that act as ground planes; a prime example being the roof of a car. The shape of the ground plane can drastically change the patterns of the electromagnetic radiation of a monopole antenna as well as its RF performance. Extensive work has been done on the numerical modeling of arbitrarily shaped ground planes. However, due to their geometric complexity, there is very little work reported on the practical testing component of physical antennas with these obscure ground plane structures. This thesis illustrates how the additive manufacturing process presented can be used to physically realize arbitrarily shaped ground planes and provides a low-cost process to verify the numerical model. Ground Planes were modified while maintaining the same antenna length to evaluate the impact on antenna performance. The antenna was not optimized or changed to a standard antenna design. Varying radius spherical ground planes are modelled, as well as modified ground plane structures to evaluate the impact of the ground plane on a 1.3GHz monopole antenna's performance and in some cases to modify the antenna's performance in terms of gain, bandwidth, and radiation pattern. Designs such as the planar ground with horn was found to enhance monopole bandwidth by more than 5 times that of a standard planar ground but significantly deteriorate the antenna's radiation pattern. Moreover, complex geometry such as the fin sphere ground plane offered a 25% increase in gain relative to the standard sphere ground. Designs like the edge-mounted sphere can offer directive gain and radiation characteristics simply by altering the antennas' location mount location with respect to its ground plane. The techniques presented in this thesis offer new ways of producing 3D printed ground planes for RF applications.      
### 47.Exploring constraints on CycleGAN-based CBCT enhancement for adaptive radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2110.04659.pdf)
>  Research exploring CycleGAN-based synthetic image generation has recently accelerated in the medical community, as it is able to leverage unpaired datasets effectively. However, clinical acceptance of these synthetic images pose a significant challenge as they are subject to strict evaluation protocols. A commonly established drawback of the CycleGAN, the introduction of artifacts in generated images is unforgivable in the case of medical images. In an attempt to alleviate this drawback, we explore different constraints of the CycleGAN along with investigation of adaptive control of these constraints. The benefits of imposing additional constraints on the CycleGAN, in the form of structure retaining losses is also explored. A generalized frequency loss inspired by <a class="link-https" data-arxiv-id="2012.12821" href="https://arxiv.org/abs/2012.12821">arXiv:2012.12821</a> that preserves content in the frequency domain between source and target is investigated and compared with existing losses such as the MIND loss <a class="link-https" data-arxiv-id="1809.04536" href="https://arxiv.org/abs/1809.04536">arXiv:1809.04536</a>. CycleGAN implementations from the ganslate framework (<a class="link-external link-https" href="https://github.com/ganslate-team/ganslate" rel="external noopener nofollow">this https URL</a>) are used for experimentation in this thesis. Synthetic images generated from our methods are quantitatively and qualitatively investigated and outperform the baseline CycleGAN and other approaches. Furthermore, no observable artifacts or loss in image quality is found, which is critical for acceptance of these synthetic images. The synthetic medical images thus generated are also evaluated using domain-specific evaluation and using segmentation as a downstream task, in order to clearly highlight their applicability to clinical workflows.      
### 48.Complex Network-Based Approach for Feature Extraction and Classification of Musical Genres  [ :arrow_down: ](https://arxiv.org/pdf/2110.04654.pdf)
>  Musical genre's classification has been a relevant research topic. The association between music and genres is fundamental for the media industry, which manages musical recommendation systems, and for music streaming services, which may appear classified by genres. In this context, this work presents a feature extraction method for the automatic classification of musical genres, based on complex networks and their topological measurements. The proposed method initially converts the musics into sequences of musical notes and then maps the sequences as complex networks. Topological measurements are extracted to characterize the network topology, which composes a feature vector that applies to the classification of musical genres. The method was evaluated in the classification of 10 musical genres by adopting the GTZAN dataset and 8 musical genres by adopting the FMA dataset. The results were compared with methods in the literature. The proposed method outperformed all compared methods by presenting high accuracy and low standard deviation, showing its suitability for the musical genre's classification, which contributes to the media industry in the automatic classification with assertiveness and robustness. The proposed method is implemented in an open source in the Python language and freely available at <a class="link-external link-https" href="https://github.com/omatheuspimenta/examinner" rel="external noopener nofollow">this https URL</a>.      
### 49.DenseNet approach to segmentation and classification of dermatoscopic skin lesions images  [ :arrow_down: ](https://arxiv.org/pdf/2110.04632.pdf)
>  At present, cancer is one of the most important health issues in the world. Because early detection and appropriate treatment in cancer are very effective in the recovery and survival of patients, image processing as a diagnostic tool can help doctors to diagnose in the first recognition of cancer. One of the most important steps in diagnosing a skin lesion is to automatically detect the border of the skin image because the accuracy of the next steps depends on it. If these subtleties are identified, they can have a great impact on the diagnosis of the disease. Therefore, there is a good opportunity to develop more accurate algorithms to analyze such images. This paper proposes an improved method for segmentation and classification for skin lesions using two architectures, the U-Net for image segmentation and the DenseNet121 for image classification which have excellent accuracy. We tested the segmentation architecture of our model on the ISIC-2018 dataset and the classification on the HAM10000 dataset. Our results show that the combination of U-Net and DenseNet121 architectures provides acceptable results in dermatoscopic image analysis compared to previous research. Another classification examined in this study is cancerous and non-cancerous samples. In this classification, cancerous and non-cancerous samples were detected in DenseNet121 network with 79.49% and 93.11% accuracy respectively.      
### 50.Personalized Automatic Speech Recognition Trained on Small Disordered Speech Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2110.04612.pdf)
>  This study investigates the performance of personalized automatic speech recognition (ASR) for recognizing disordered speech using small amounts of per-speaker adaptation data. We trained personalized models for 195 individuals with different types and severities of speech impairment with training sets ranging in size from &lt;1 minute to 18-20 minutes of speech data. Word error rate (WER) thresholds were selected to determine Success Percentage (the percentage of personalized models reaching the target WER) in different application scenarios. For the home automation scenario, 79% of speakers reached the target WER with 18-20 minutes of speech; but even with only 3-4 minutes of speech, 63% of speakers reached the target WER. Further evaluation found similar improvement on test sets with conversational and out-of-domain, unprompted phrases. Our results demonstrate that with only a few minutes of recordings, individuals with disordered speech could benefit from personalized ASR.      
### 51.Learning MRI Artifact Removal With Unpaired Data  [ :arrow_down: ](https://arxiv.org/pdf/2110.04604.pdf)
>  Retrospective artifact correction (RAC) improves image quality post acquisition and enhances image usability. Recent machine learning driven techniques for RAC are predominantly based on supervised learning and therefore practical utility can be limited as data with paired artifact-free and artifact-corrupted images are typically insufficient or even non-existent. Here we show that unwanted image artifacts can be disentangled and removed from an image via an RAC neural network learned with unpaired data. This implies that our method does not require matching artifact-corrupted data to be either collected via acquisition or generated via simulation. Experimental results demonstrate that our method is remarkably effective in removing artifacts and retaining anatomical details in images with different contrasts.      
### 52.An evaluation of data augmentation methods for sound scene geotagging  [ :arrow_down: ](https://arxiv.org/pdf/2110.04585.pdf)
>  Sound scene geotagging is a new topic of research which has evolved from acoustic scene classification. It is motivated by the idea of audio surveillance. Not content with only describing a scene in a recording, a machine which can locate where the recording was captured would be of use to many. In this paper we explore a series of common audio data augmentation methods to evaluate which best improves the accuracy of audio geotagging classifiers. Our work improves on the state-of-the-art city geotagging method by 23% in terms of classification accuracy.      
### 53.Visually Exploring Multi-Purpose Audio Data  [ :arrow_down: ](https://arxiv.org/pdf/2110.04584.pdf)
>  We analyse multi-purpose audio using tools to visualise similarities within the data that may be observed via unsupervised methods. The success of machine learning classifiers is affected by the information contained within system inputs, so we investigate whether latent patterns within the data may explain performance limitations of such classifiers. We use the visual assessment of cluster tendency (VAT) technique on a well known data set to observe how the samples naturally cluster, and we make comparisons to the labels used for audio geotagging and acoustic scene classification. We demonstrate that VAT helps to explain and corroborate confusions observed in prior work to classify this audio, yielding greater insight into the performance - and limitations - of supervised classification systems. While this exploratory analysis is conducted on data for which we know the "ground truth" labels, this method of visualising the natural groupings as dictated by the data leads to important questions about unlabelled data that can help the evaluation and realistic expectations of future (including self-supervised) classification systems.      
### 54.Multimodal generation of upper-facial and head gestures with a Transformer Network using speech and text  [ :arrow_down: ](https://arxiv.org/pdf/2110.04527.pdf)
>  We propose a semantically-aware speech driven method to generate expressive and natural upper-facial and head motion for Embodied Conversational Agents (ECA). In this work, we tackle two key challenges: produce natural and continuous head motion and upper-facial gestures. We propose a model that generates gestures based on multimodal input features: the first modality is text, and the second one is speech prosody. Our model makes use of Transformers and Convolutions to map the multimodal features that correspond to an utterance to continuous eyebrows and head gestures. We conduct subjective and objective evaluations to validate our approach.      
### 55.Data Augmentation with Locally-time Reversed Speech for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.04511.pdf)
>  Psychoacoustic studies have shown that locally-time reversed (LTR) speech, i.e., signal samples time-reversed within a short segment, can be accurately recognised by human listeners. This study addresses the question of how well a state-of-the-art automatic speech recognition (ASR) system would perform on LTR speech. The underlying objective is to explore the feasibility of deploying LTR speech in the training of end-to-end (E2E) ASR models, as an attempt to data augmentation for improving the recognition performance. The investigation starts with experiments to understand the effect of LTR speech on general-purpose ASR. LTR speech with reversed segment duration of 5 ms - 50 ms is rendered and evaluated. For ASR training data augmentation with LTR speech, training sets are created by combining natural speech with different partitions of LTR speech. The efficacy of data augmentation is confirmed by ASR results on speech corpora in various languages and speaking styles. ASR on LTR speech with reversed segment duration of 15 ms - 30 ms is found to have lower error rate than with other segment duration. Data augmentation with these LTR speech achieves satisfactory and consistent improvement on ASR performance.      
### 56.Invertible Tone Mapping with Selectable Styles  [ :arrow_down: ](https://arxiv.org/pdf/2110.04491.pdf)
>  Although digital cameras can acquire high-dynamic range (HDR) images, the captured HDR information are mostly quantized to low-dynamic range (LDR) images for display compatibility and compact storage. In this paper, we propose an invertible tone mapping method that converts the multi-exposure HDR to a true LDR (8-bit per color channel) and reserves the capability to accurately restore the original HDR from this {\em invertible LDR}. Our invertible LDR can mimic the appearance of a user-selected tone mapping style. It can be shared over any existing social network platforms that may re-encode or format-convert the uploaded images, without much hurting the accuracy of the restored HDR counterpart. To achieve this, we regard the tone mapping and the restoration as coupled processes, and formulate them as an encoding-and-decoding problem through convolutional neural networks. Particularly, our model supports pluggable style modulators, each of which bakes a specific tone mapping style, and thus favors the application flexibility. Our method is evaluated with a rich variety of HDR images and multiple tone mapping operators, which shows the superiority over relevant state-of-the-art methods. Also, we conduct ablation study to justify our design and discuss the robustness and generality toward real applications.      
### 57.Wav2vec-S: Semi-Supervised Pre-Training for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.04484.pdf)
>  Self-supervised pre-training has dramatically improved the performance of automatic speech recognition (ASR). However, most existing self-supervised pre-training approaches are task-agnostic, i.e., could be applied to various downstream tasks. And there is a gap between the task-agnostic pre-training and the task-specific downstream fine-tuning, which may degrade the downstream performance. In this work, we propose a novel pre-training paradigm called wav2vec-S, where we use task-specific semi-supervised pre-training to bridge this gap. Specifically, the semi-supervised pre-training is conducted on the basis of self-supervised pre-training such as wav2vec 2.0. Experiments on ASR show that compared to wav2vec 2.0, wav2vec-S only requires marginal increment of pre-training time but could significantly improve ASR performance on in-domain, cross-domain and cross-lingual datasets. The average relative WER reductions are 26.3% and 6.3% for 1h and 10h fine-tuning, respectively.      
### 58.Towards Lifelong Learning of Multilingual Text-To-Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.04482.pdf)
>  This work presents a lifelong learning approach to train a multilingual Text-To-Speech (TTS) system, where each language was seen as an individual task and was learned sequentially and continually. It does not require pooled data from all languages altogether, and thus alleviates the storage and computation burden. One of the challenges of lifelong learning methods is "catastrophic forgetting": in TTS scenario it means that model performance quickly degrades on previous languages when adapted to a new language. We approach this problem via a data-replay-based lifelong learning method. We formulate the replay process as a supervised learning problem, and propose a simple yet effective dual-sampler framework to tackle the heavily language-imbalanced training samples. Through objective and subjective evaluations, we show that this supervised learning formulation outperforms other gradient-based and regularization-based lifelong learning methods, achieving 43% Mel-Cepstral Distortion reduction compared to a fine-tuning baseline.      
### 59.Optimization of A Mobile Optical SWIPT System With Asymmetric Spatially Separated Laser Resonator  [ :arrow_down: ](https://arxiv.org/pdf/2110.04463.pdf)
>  High-power and high-capacity simultaneous wireless information and power transfer (SWIPT) becomes more and more important with the development of Internet of Things technologies. Optical SWIPT, also known as simultaneous light information and power transfer (SLIPT), has unique advantages such as abundant spectrum resources and low propagation divergence, compared with RF technologies. However, optical SWIPT faces many challenges in beam steering and receiver positioning/tracking. Resonant beams generated by spatially separated laser resonators (SSLR) have many advantages, including high power, self-aligned mobility, and intrinsic safety. It has been proposed as the carrier of wireless charging and communication. Using resonant beams, mobile electronic devices can be remotely charged and supported with high-rate data transfer. In this paper, we propose a mobile optical SWIPT system based on asymmetric SSLR and present the system optimization procedure. We also determine the boundary of the achievable charging power and communication capacity, and discuss the trade-off between power transfer and information transfer. Numerical results show that the charging power of the optimized asymmetric system is much higher than that of the symmetric system in the previous work, and meanwhile, the channel capacity is kept almost unchanged.      
### 60.Vision Transformer based COVID-19 Detection using Chest X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2110.04458.pdf)
>  COVID-19 is a global pandemic, and detecting them is a momentous task for medical professionals today due to its rapid mutations. Current methods of examining chest X-rays and CT scan requires profound knowledge and are time consuming, which suggests that it shrinks the precious time of medical practitioners when people's lives are at stake. This study tries to assist this process by achieving state-of-the-art performance in classifying chest X-rays by fine-tuning Vision Transformer(ViT). The proposed approach uses pretrained models, fine-tuned for detecting the presence of COVID-19 disease on chest X-rays. This approach achieves an accuracy score of 97.61%, precision score of 95.34%, recall score of 93.84% and, f1-score of 94.58%. This result signifies the performance of transformer-based models on chest X-ray.      
### 61.Deep Joint Source-Channel Coding for Wireless Image Transmission with Adaptive Rate Control  [ :arrow_down: ](https://arxiv.org/pdf/2110.04456.pdf)
>  We present a novel adaptive deep joint source-channel coding (JSCC) scheme for wireless image transmission. The proposed scheme supports multiple rates using a single deep neural network (DNN) model and learns to dynamically control the rate based on the channel condition and image contents. Specifically, a policy network is introduced to exploit the tradeoff space between the rate and signal quality. To train the policy network, the Gumbel-Softmax trick is adopted to make the policy network differentiable and hence the whole JSCC scheme can be trained end-to-end. To the best of our knowledge, this is the first deep JSCC scheme that can automatically adjust its rate using a single network model. Experiments show that our scheme successfully learns a reasonable policy that decreases channel bandwidth utilization for high SNR scenarios or simple image contents. For an arbitrary target rate, our rate-adaptive scheme using a single model achieves similar performance compared to an optimized model specifically trained for that fixed target rate. To reproduce our results, we make the source code publicly available at <a class="link-external link-https" href="https://github.com/mingyuyng/Dynamic_JSCC" rel="external noopener nofollow">this https URL</a>.      
### 62.Sensoring and Application of Multimodal Data for the Detection of Freezing of Gait in Parkinson's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2110.04444.pdf)
>  The accurate and reliable detection or prediction of freezing of gaits (FOG) is important for fall prevention in Parkinson's Disease (PD) and studying the physiological transitions during the occurrence of FOG. Integrating both commercial and self-designed sensors, a protocal has been designed to acquire multimodal physical and physiological information during FOG, including gait acceleration (ACC), electroencephalogram (EEG), electromyogram (EMG), and skin conductance (SC). Two tasks were designed to trigger FOG, including gait initiation failure and FOG during walking. A total number of 12 PD patients completed the experiments and produced a total length of 3 hours and 42 minutes of valid data. The FOG episodes were labeled by two qualified physicians. Each unimodal data and combinations have been used to detect FOG. Results showed that multimodal data benefit the detection of FOG. Among unimodal data, EEG had better discriminative ability than ACC and EMG. However, the acquisition of EEG are more complicated. Multimodal motional and electrophysiological data can also be used to study the physiological transition process during the occurrence of FOG and provide personalised interventions.      
### 63.Multimodal Approach for Assessing Neuromotor Coordination in Schizophrenia Using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.04440.pdf)
>  This study investigates the speech articulatory coordination in schizophrenia subjects exhibiting strong positive symptoms (e.g. hallucinations and delusions), using two distinct channel-delay correlation methods. We show that the schizophrenic subjects with strong positive symptoms and who are markedly ill pose complex articulatory coordination pattern in facial and speech gestures than what is observed in healthy subjects. This distinction in speech coordination pattern is used to train a multimodal convolutional neural network (CNN) which uses video and audio data during speech to distinguish schizophrenic patients with strong positive symptoms from healthy subjects. We also show that the vocal tract variables (TVs) which correspond to place of articulation and glottal source outperform the Mel-frequency Cepstral Coefficients (MFCCs) when fused with Facial Action Units (FAUs) in the proposed multimodal network. For the clinical dataset we collected, our best performing multimodal network improves the mean F1 score for detecting schizophrenia by around 18% with respect to the full vocal tract coordination (FVTC) baseline method implemented with fusing FAUs and MFCCs.      
### 64.TitaNet: Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context  [ :arrow_down: ](https://arxiv.org/pdf/2110.04410.pdf)
>  In this paper, we propose TitaNet, a novel neural network architecture for extracting speaker representations. We employ 1D depth-wise separable convolutions with Squeeze-and-Excitation (SE) layers with global context followed by channel attention based statistics pooling layer to map variable-length utterances to a fixed-length embedding (t-vector). TitaNet is a scalable architecture and achieves state-of-the-art performance on speaker verification task with an equal error rate (EER) of 0.68% on the VoxCeleb1 trial file and also on speaker diarization tasks with diarization error rate (DER) of 1.73% on AMI-MixHeadset, 1.99% on AMI-Lapel and 1.11% on CH109. Furthermore, we investigate various sizes of TitaNet and present a light TitaNet-S model with only 6M parameters that achieve near state-of-the-art results in diarization tasks.      
### 65.Atomic Norm Based Localization and Orientation Estimation for Millimeter-Wave MIMO OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2110.04401.pdf)
>  Herein, an atomic norm based method for accurately estimating the location and orientation of a target from millimeter-wave multi-input-multi-output (MIMO) orthogonal frequency-division multiplexing (OFDM) signals is presented. A novel virtual channel matrix is introduced and an algorithm to extract localization-relevant channel parameters from its atomic norm decomposition is designed. Then, based on the extended invariance principle, a weighted least squares problem is proposed to accurately recover the location and orientation using both line-of-sight and non-line-of-sight channel information. Numerical results highlight performance improvements over a prior method and the resultant performance nearly achieves the Cramer-Rao lower bound.      
### 66.Aura: Privacy-preserving augmentation to improve test set diversity in noise suppression applications  [ :arrow_down: ](https://arxiv.org/pdf/2110.04391.pdf)
>  Noise suppression models running in production environments are commonly trained on publicly available datasets. However, this approach leads to regressions in production environments due to the lack of training/testing on representative customer data. Moreover, due to privacy reasons, developers cannot listen to customer content. This `ears-off' situation motivates augmenting existing datasets in a privacy-preserving manner. In this paper, we present Aura, a solution to make existing noise suppression test sets more challenging and diverse while limiting the sampling budget. Aura is `ears-off' because it relies on a feature extractor and a metric of speech quality, DNSMOS P.835, both pre-trained on data obtained from public sources. As an application of \aura, we augment a current benchmark test set in noise suppression by sampling audio files from a new batch of data of 20K clean speech clips from Librivox mixed with noise clips obtained from AudioSet. Aura makes the existing benchmark test set harder by 100% in DNSMOS P.835, a 26 improvement in Spearman's rank correlation coefficient (SRCC) compared to random sampling and, identifies 73% out-of-distribution samples to augment the test set.      
### 67.Individualized Hear-through For Acoustic Transparency Using PCA-Based Sound Pressure Estimation At The Eardrum  [ :arrow_down: ](https://arxiv.org/pdf/2110.04385.pdf)
>  The hear-through functionality on hearing devices, which allows hearing equivalent to the open-ear while providing the possibility to modify the sound pressure at the eardrum in a desired manner, has drawn great attention from researchers in recent years. To this end, the output of the device is processed by means of an equalization filter, such that the transfer function between external sound sources and the eardrum is equivalent for the open-ear and the aided condition with the device in the ear. To achieve an ideal performance, the equalization filter design assumes the exact knowledge of all the relevant acoustic transfer functions. A particular challenge is the transfer function between the hearing device receiver and the eardrum, which is difficult to obtain in practice as it requires additional probe-tube measurements. In this work, we address this issue by proposing an individualized hear-through equalization filter design that leverages the measurement of the so-called secondary path to predict the sound pressure at the eardrum. Experimental results using real-ear measured transfer functions confirm that the proposed method achieves a good sound quality compared to the open-ear while outperforming filter designs that do not leverage the proposed estimator.      
### 68.Performance optimizations on deep noise suppression models  [ :arrow_down: ](https://arxiv.org/pdf/2110.04378.pdf)
>  We study the role of magnitude structured pruning as an architecture search to speed up the inference time of a deep noise suppression (DNS) model. While deep learning approaches have been remarkably successful in enhancing audio quality, their increased complexity inhibits their deployment in real-time applications. We achieve up to a 7.25X inference speedup over the baseline, with a smooth model performance degradation. Ablation studies indicate that our proposed network re-parameterization (i.e., size per layer) is the major driver of the speedup, and that magnitude structured pruning does comparably to directly training a model in the smaller size. We report inference speed because a parameter reduction does not necessitate speedup, and we measure model quality using an accurate non-intrusive objective speech quality metric.      
### 69.Using Subobservers to Synthesize Opacity-Enforcing Supervisors  [ :arrow_down: ](https://arxiv.org/pdf/2110.04334.pdf)
>  In discrete-event system control, the worst-case time complexity for computing a system's observer is exponential in the number of that system's states. This results in practical difficulties since some problems require calculating multiple observers for a changing system, e.g., synthesizing an opacity-enforcing supervisor. Although calculating these observers in an iterative manner allows us to synthesize an opacity-enforcing supervisor and although methods have been proposed to reduce the computational demands, room exists for a practical and intuitive solution. Here we extend the subautomaton relationship to the notion of a subobserver and demonstrate its use in reducing the computations required for iterated observer calculations. We then demonstrate the subobserver relationship's power by simplifying state-of-the-art synthesis approaches for opacity-enforcing supervisors under realistic assumptions.      
### 70.MusicNet: Compact Convolutional Neural Network for Real-time Background Music Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.04331.pdf)
>  With the recent growth of remote and hybrid work, online meetings often encounter challenging audio contexts such as background noise, music, and echo. Accurate real-time detection of music events can help to improve the user experience in such scenarios, e.g., by switching to high-fidelity music-specific codec or selecting the optimal noise suppression model. <br>In this paper, we present MusicNet -- a compact high-performance model for detecting background music in the real-time communications pipeline. In online video meetings, which is our main use case, music almost always co-occurs with speech and background noises, making the accurate classification quite challenging. <br>The proposed model is a binary classifier that consists of a compact convolutional neural network core preceded by an in-model featurization layer. It takes 9 seconds of raw audio as input and does not require any model-specific featurization on the client. <br>We train our model on a balanced subset of the AudioSet data and use 1000 crowd-sourced real test clips to validate the model. Finally, we compare MusicNet performance to 20 other state-of-the-art models. <br>Our classifier gives a true positive rate of 81.3% at a 0.1% false positive rate, which is significantly better than any other model in the study. Our model is also 10x smaller and has 4x faster inference than the comparable baseline.      
### 71.Near Optimal Interpolation based Time-Limited Model Order Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2110.04326.pdf)
>  This paper presents an interpolatory framework for time-limited $H_2$ optimal model order reduction named Limited Time Iterative Rational Krylov Algorithm (LT-IRKA). The algorithm yields high fidelity reduced order models over limited time intervals of the form, $\begin{bmatrix}0 &amp; \tau \end{bmatrix}$ with $\tau &lt; \infty$ for linear time invariant (LTI) systems. Using the time limited $H_2$ norm, we derive interpolation based $H_{2,\tau}$ optimality conditions. The LT-IRKA yields a near optimal $H_2(\tau)$ reduced order system. The nearness to the exact $H_2(\tau)$ optimal reduced system is quantized in terms of the errors in the interpolation based $H_2(\tau)$ optimality conditions. We demonstrate with numerical examples how the proposed algorithm nearly satisfies the time-limited optimality conditions and also how it performs with respect to the Time-Limited Two sided Iteration Algorithm (TL-TSIA), the Time-Limited Balanced Truncation (TL-BT), the Iterative Rational Krylov Algorithm (IRKA) and the Time-Limited Pseudo Optimal Rational Krylov (TL-PORK) Algorithm over a finite time interval.      
### 72.Zero-CPU Collection with Direct Telemetry Access  [ :arrow_down: ](https://arxiv.org/pdf/2110.05438.pdf)
>  Programmable switches are driving a massive increase in fine-grained measurements. This puts significant pressure on telemetry collectors that have to process reports from many switches. Past research acknowledged this problem by either improving collectors' stack performance or by limiting the amount of data sent from switches. In this paper, we take a different and radical approach: switches are responsible for directly inserting queryable telemetry data into the collectors' memory, bypassing their CPU, and thereby improving their collection scalability. We propose to use a method we call \emph{direct telemetry access}, where switches jointly write telemetry reports directly into the same collector's memory region, without coordination. Our solution, DART, is probabilistic, trading memory redundancy and query success probability for CPU resources at collectors. We prototype DART using commodity hardware such as P4 switches and RDMA NICs and show that we get high query success rates with a reasonable memory overhead. For example, we can collect INT path tracing information on a fat tree topology without a collector's CPU involvement while achieving 99.9\% query success probability and using just 300 bytes per flow.      
### 73.Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.05354.pdf)
>  Text-only adaptation of an end-to-end (E2E) model remains a challenging task for automatic speech recognition (ASR). Language model (LM) fusion-based approaches require an additional external LM during inference, significantly increasing the computation cost. To overcome this, we propose an internal LM adaptation (ILMA) of the E2E model using text-only data. Trained with audio-transcript pairs, an E2E model implicitly learns an internal LM that characterizes the token sequence probability which is approximated by the E2E model output after zeroing out the encoder contribution. During ILMA, we fine-tune the internal LM, i.e., the E2E components excluding the encoder, to minimize a cross-entropy loss. To make ILMA effective, it is essential to train the E2E model with an internal LM loss besides the standard E2E loss. Furthermore, we propose to regularize ILMA by minimizing the Kullback-Leibler divergence between the output distributions of the adapted and unadapted internal LMs. ILMA is the most effective when we update only the last linear layer of the joint network. ILMA enables a fast text-only adaptation of the E2E model without increasing the run-time computational cost. Experimented with 30K-hour trained transformer transducer models, ILMA achieves up to 34.9% relative word error rate reduction from the unadapted baseline.      
### 74.Efficient Training of High-Resolution Representation Seismic Image Fault Segmentation Network by Weakening Anomaly Labels  [ :arrow_down: ](https://arxiv.org/pdf/2110.05319.pdf)
>  Seismic data fault detection has recently been regarded as a 3D image segmentation task. The nature of fault structures in seismic image makes it difficult to manually label faults. Manual labeling often has many false negative labels (abnormal labels), which will seriously harm the training process. In this work, we find that region-based loss significantly outperforms distribution-based loss when dealing with falsenegative labels, therefore we propose Mask Dice loss (MD loss), which is the first reported region-based loss function for training 3D image segmentation models using sparse 2D slice labels. In addition, fault is an edge feature, and the current network widely used for fault segmentation downsamples the features multiple times, which is not conducive to edge characterization and thus requires many parameters and computational effort to preserve the features. We propose Fault-Net, which always maintains the high-resolution features of seismic images, and the inference process preserves the edge information of faults and performs effective feature fusion to achieve high-quality fault segmentation with only a few parameters and computational effort. Experimental results show that MD loss can clearly weaken the effect of anomalous labels. The Fault-Net parameter is only 0.42MB, support up to 528^3(1.5x10^8, Float32) size cuboid inference on 16GB video ram, and its inference speed on CPU and GPU is significantly faster than other networks, but the result of our method is the state-of-the-art in the FORCE fault identification competition.      
### 75.Unsupervised Source Separation via Bayesian Inference in the Latent Domain  [ :arrow_down: ](https://arxiv.org/pdf/2110.05313.pdf)
>  State of the art audio source separation models rely on supervised data-driven approaches, which can be expensive in terms of labeling resources. On the other hand, approaches for training these models without any direct supervision are typically high-demanding in terms of memory and time requirements, and remain impractical to be used at inference time. We aim to tackle these limitations by proposing a simple yet effective unsupervised separation algorithm, which operates directly on a latent representation of time-domain signals. Our algorithm relies on deep Bayesian priors in the form of pre-trained autoregressive networks to model the probability distributions of each source. We leverage the low cardinality of the discrete latent space, trained with a novel loss term imposing a precise arithmetic structure on it, to perform exact Bayesian inference without relying on an approximation strategy. We validate our approach on the Slakh dataset <a class="link-https" data-arxiv-id="1909.08494" href="https://arxiv.org/abs/1909.08494">arXiv:1909.08494</a>, demonstrating results in line with state of the art supervised approaches while requiring fewer resources with respect to other unsupervised methods.      
### 76.Simultaneous Transmitting and ReflectingIntelligent Surfaces-Empowered NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.05311.pdf)
>  In this paper, we propose simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted non-orthogonal multiple access (NOMA) networks. The considered STAR-RIS utilizes the mode switching (MS) protocol to serve multiple NOMA users located on both sides of the RIS surface. Based on the MS protocol, each STAR-RIS element can operate in full transmission or reflection mode. Within this perspective, we propose a novel algorithm to partition the STAR-RIS surface among the available users. This algorithm aims to determine the proper number of transmitting/reflecting elements needs to be assigned to each user in order to maximize the system sum-rate while guaranteeing the quality-of-service requirements for individual users. For the proposed system, we derive closed-form analytical expressions for the outage probability (OP) and its corresponding asymptotic behavior under different user deployments. Finally, Monte Carlo simulations are performed in order to verify the correctness of the theoretical analysis. It is shown that the proposed system outperforms the classical NOMA and orthogonal multiple access systems in terms of OP and sum-rate.      
### 77.Phase Collapse in Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.05283.pdf)
>  Deep convolutional image classifiers progressively transform the spatial variability into a smaller number of channels, which linearly separates all classes. A fundamental challenge is to understand the role of rectifiers together with convolutional filters in this transformation. Rectifiers with biases are often interpreted as thresholding operators which improve sparsity and discrimination. This paper demonstrates that it is a different phase collapse mechanism which explains the ability to progressively eliminate spatial variability, while improving linear class separation. This is explained and shown numerically by defining a simplified complex-valued convolutional network architecture. It implements spatial convolutions with wavelet filters and uses a complex modulus to collapse phase variables. This phase collapse network reaches the classification accuracy of ResNets of similar depths, whereas its performance is considerably degraded when replacing the phase collapse with thresholding operators. This is justified by explaining how iterated phase collapses progressively improve separation of class means, as opposed to thresholding non-linearities.      
### 78.Chaos as an interpretable benchmark for forecasting and data-driven modelling  [ :arrow_down: ](https://arxiv.org/pdf/2110.05266.pdf)
>  The striking fractal geometry of strange attractors underscores the generative nature of chaos: like probability distributions, chaotic systems can be repeatedly measured to produce arbitrarily-detailed information about the underlying attractor. Chaotic systems thus pose a unique challenge to modern statistical learning techniques, while retaining quantifiable mathematical properties that make them controllable and interpretable as benchmarks. Here, we present a growing database currently comprising 131 known chaotic dynamical systems spanning fields such as astrophysics, climatology, and biochemistry. Each system is paired with precomputed multivariate and univariate time series. Our dataset has comparable scale to existing static time series databases; however, our systems can be re-integrated to produce additional datasets of arbitrary length and granularity. Our dataset is annotated with known mathematical properties of each system, and we perform feature analysis to broadly categorize the diverse dynamics present across the collection. Chaotic systems inherently challenge forecasting models, and across extensive benchmarks we correlate forecasting performance with the degree of chaos present. We also exploit the unique generative properties of our dataset in several proof-of-concept experiments: surrogate transfer learning to improve time series classification, importance sampling to accelerate model training, and benchmarking symbolic regression algorithms.      
### 79.Combining Image Features and Patient Metadata to Enhance Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.05239.pdf)
>  In this work, we compare the performance of six state-of-the-art deep neural networks in classification tasks when using only image features, to when these are combined with patient metadata. We utilise transfer learning from networks pretrained on ImageNet to extract image features from the ISIC HAM10000 dataset prior to classification. Using several classification performance metrics, we evaluate the effects of including metadata with the image features. Furthermore, we repeat our experiments with data augmentation. Our results show an overall enhancement in performance of each network as assessed by all metrics, only noting degradation in a vgg16 architecture. Our results indicate that this performance enhancement may be a general property of deep networks and should be explored in other areas. Moreover, these improvements come at a negligible additional cost in computation time, and therefore are a practical method for other applications.      
### 80.Performance Analysis of Fractional Learning Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2110.05201.pdf)
>  Fractional learning algorithms are trending in signal processing and adaptive filtering recently. However, it is unclear whether the proclaimed superiority over conventional algorithms is well-grounded or is a myth as their performance has never been extensively analyzed. In this article, a rigorous analysis of fractional variants of the least mean squares and steepest descent algorithms is performed. Some critical schematic kinks in fractional learning algorithms are identified. Their origins and consequences on the performance of the learning algorithms are discussed and swift ready-witted remedies are proposed. Apposite numerical experiments are conducted to discuss the convergence and efficiency of the fractional learning algorithms in stochastic environments.      
### 81.Dynamic Binary Neural Network by learning channel-wise thresholds  [ :arrow_down: ](https://arxiv.org/pdf/2110.05185.pdf)
>  Binary neural networks (BNNs) constrain weights and activations to +1 or -1 with limited storage and computational cost, which is hardware-friendly for portable devices. Recently, BNNs have achieved remarkable progress and been adopted into various fields. However, the performance of BNNs is sensitive to activation distribution. The existing BNNs utilized the Sign function with predefined or learned static thresholds to binarize activations. This process limits representation capacity of BNNs since different samples may adapt to unequal thresholds. To address this problem, we propose a dynamic BNN (DyBNN) incorporating dynamic learnable channel-wise thresholds of Sign function and shift parameters of PReLU. The method aggregates the global information into the hyper function and effectively increases the feature expression ability. The experimental results prove that our method is an effective and straightforward way to reduce information loss and enhance performance of BNNs. The DyBNN based on two backbones of ReActNet (MobileNetV1 and ResNet18) achieve 71.2% and 67.4% top1-accuracy on ImageNet dataset, outperforming baselines by a large margin (i.e., 1.8% and 1.5% respectively).      
### 82.Learning High-Speed Flight in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2110.05113.pdf)
>  Quadrotors are agile. Unlike most other machines, they can traverse extremely complex environments at high speeds. To date, only expert human pilots have been able to fully exploit their capabilities. Autonomous operation with on-board sensing and computation has been limited to low speeds. State-of-the-art methods generally separate the navigation problem into subtasks: sensing, mapping, and planning. While this approach has proven successful at low speeds, the separation it builds upon can be problematic for high-speed navigation in cluttered environments. Indeed, the subtasks are executed sequentially, leading to increased processing latency and a compounding of errors through the pipeline. Here we propose an end-to-end approach that can autonomously fly quadrotors through complex natural and man-made environments at high speeds, with purely onboard sensing and computation. The key principle is to directly map noisy sensory observations to collision-free trajectories in a receding-horizon fashion. This direct mapping drastically reduces processing latency and increases robustness to noisy and incomplete perception. The sensorimotor mapping is performed by a convolutional network that is trained exclusively in simulation via privileged learning: imitating an expert with access to privileged information. By simulating realistic sensor noise, our approach achieves zero-shot transfer from simulation to challenging real-world environments that were never experienced during training: dense forests, snow-covered terrain, derailed trains, and collapsed buildings. Our work demonstrates that end-to-end policies trained in simulation enable high-speed autonomous flight through challenging environments, outperforming traditional obstacle avoidance pipelines.      
### 83.A Multi-Resolution Front-End for End-to-End Speech Anti-Spoofing  [ :arrow_down: ](https://arxiv.org/pdf/2110.05087.pdf)
>  The choice of an optimal time-frequency resolution is usually a difficult but important step in tasks involving speech signal classification, e.g., speech anti-spoofing. The variations of the performance with different choices of timefrequency resolutions can be as large as those with different model architectures, which makes it difficult to judge what the improvement actually comes from when a new network architecture is invented and introduced as the classifier. In this paper, we propose a multi-resolution front-end for feature extraction in an end-to-end classification framework. Optimal weighted combinations of multiple time-frequency resolutions will be learned automatically given the objective of a classification task. Features extracted with different time-frequency resolutions are weighted and concatenated as inputs to the successive networks, where the weights are predicted by a learnable neural network inspired by the weighting block in squeeze-and-excitation networks (SENet). Furthermore, the refinement of the chosen timefrequency resolutions is investigated by pruning the ones with relatively low importance, which reduces the complexity and size of the model. The proposed method is evaluated on the tasks of speech anti-spoofing in ASVSpoof 2019 and its superiority has been justified by comparing with similar baselines.      
### 84.Efficiently and Globally Solving Joint Beamforming and Compression Problem in the Cooperative Cellular Network via Lagrangian Duality  [ :arrow_down: ](https://arxiv.org/pdf/2110.05085.pdf)
>  Consider the joint beamforming and quantization problem in the cooperative cellular network, where multiple relay-like base stations (BSs) connected to the central processor (CP) via rate-limited fronthaul links cooperatively serve the users. This problem can be formulated as the minimization of the total transmit power, subject to all users' signal-to-interference-plus-noise-ratio (SINR) constraints and all relay-like BSs' fronthaul rate constraints. In this paper, we first show that there is no duality gap between the considered problem and its Lagrangian dual by showing the tightness of the semidefinite relaxation (SDR) of the considered problem. Then we propose an efficient algorithm based on Lagrangian duality for solving the considered problem. The proposed algorithm judiciously exploits the special structure of the Karush-Kuhn-Tucker (KKT) conditions of the considered problem and finds the solution that satisfies the KKT conditions via two fixed-point iterations. The proposed algorithm is highly efficient (as evaluating the functions in both fixed-point iterations are computationally cheap) and is guaranteed to find the global solution of the problem. Simulation results show the efficiency and the correctness of the proposed algorithm.      
### 85.Efficient Training of Audio Transformers with Patchout  [ :arrow_down: ](https://arxiv.org/pdf/2110.05069.pdf)
>  The great success of transformer-based models in natural language processing (NLP) has led to various attempts at adapting these architectures to other domains such as vision and audio. Recent work has shown that transformers can outperform Convolutional Neural Networks (CNNs) on vision and audio tasks. However, one of the main shortcomings of transformer models, compared to the well-established CNNs, is the computational complexity. Compute and memory complexity grow quadratically with the input length. Therefore, there has been extensive work on optimizing transformers, but often at the cost of lower predictive performance. In this work, we propose a novel method to optimize and regularize transformers on audio spectrograms. The proposed models achieve a new state-of-the-art performance on Audioset and can be trained on a single consumer-grade GPU. Furthermore, we propose a transformer model that outperforms CNNs in terms of both performance and training speed.      
### 86.Amicable examples for informed source separation  [ :arrow_down: ](https://arxiv.org/pdf/2110.05059.pdf)
>  This paper deals with the problem of informed source separation (ISS), where the sources are accessible during the so-called \textit{encoding} stage. Previous works computed side-information during the encoding stage and source separation models were designed to utilize the side-information to improve the separation performance. In contrast, in this work, we improve the performance of a pretrained separation model that does not use any side-information. To this end, we propose to adopt an adversarial attack for the opposite purpose, i.e., rather than computing the perturbation to degrade the separation, we compute an imperceptible perturbation called amicable noise to improve the separation. Experimental results show that the proposed approach selectively improves the performance of the targeted separation model by 2.23 dB on average and is robust to signal compression. Moreover, we propose multi-model multi-purpose learning that control the effect of the perturbation on different models individually.      
### 87.Source Mixing and Separation Robust Audio Steganography  [ :arrow_down: ](https://arxiv.org/pdf/2110.05054.pdf)
>  Audio steganography aims at concealing secret information in carrier audio with imperceptible modification on the carrier. Although previous works addressed the robustness of concealed message recovery against distortions introduced during transmission, they do not address the robustness against aggressive editing such as mixing of other audio sources and source separation. In this work, we propose for the first time a steganography method that can embed information into individual sound sources in a mixture such as instrumental tracks in music. To this end, we propose a time-domain model and curriculum learning essential to learn to decode the concealed message from the separated sources. Experimental results show that the proposed method successfully conceals the information in an imperceptible perturbation and that the information can be correctly recovered even after mixing of other sources and separation by a source separation algorithm. Furthermore, we show that the proposed method can be applied to multiple sources simultaneously without interfering with the decoder for other sources even after the sources are mixed and separated.      
### 88.Multi-query multi-head attention pooling and Inter-topK penalty for speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2110.05042.pdf)
>  This paper describes the multi-query multi-head attention (MQMHA) pooling and inter-topK penalty methods which were first proposed in our submitted system description for VoxCeleb speaker recognition challenge (VoxSRC) 2021. Most multi-head attention pooling mechanisms either attend to the whole feature through multiple heads or attend to several split parts of the whole feature. Our proposed MQMHA combines both these two mechanisms and gain more diversified information. The margin-based softmax loss functions are commonly adopted to obtain discriminative speaker representations. To further enhance the inter-class discriminability, we propose a method that adds an extra inter-topK penalty on some confused speakers. By adopting both the MQMHA and inter-topK penalty, we achieved state-of-the-art performance in all of the public VoxCeleb test sets.      
### 89.Pitch Preservation In Singing Voice Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.05033.pdf)
>  Suffering from limited singing voice corpus, existing singing voice synthesis (SVS) methods that build encoder-decoder neural networks to directly generate spectrogram could lead to out-of-tune issues during the inference phase. To attenuate these issues, this paper presents a novel acoustic model with independent pitch encoder and phoneme encoder, which disentangles the phoneme and pitch information from music score to fully utilize the corpus. Specifically, according to equal temperament theory, the pitch encoder is constrained by a pitch metric loss that maps distances between adjacent input pitches into corresponding frequency multiples between the encoder outputs. For the phoneme encoder, based on the analysis that same phonemes corresponding to varying pitches can produce similar pronunciations, this encoder is followed by an adversarially trained pitch classifier to enforce the identical phonemes with different pitches mapping into the same phoneme feature space. By these means, the sparse phonemes and pitches in original input spaces can be transformed into more compact feature spaces respectively, where the same elements cluster closely and cooperate mutually to enhance synthesis quality. Then, the outputs of the two encoders are summed together to pass through the following decoder in the acoustic model. Experimental results indicate that the proposed approaches can characterize intrinsic structure between pitch inputs to obtain better pitch synthesis accuracy and achieve superior singing synthesis performance against the advanced baseline system.      
### 90.Online Graph Learning in Dynamic Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.05023.pdf)
>  Inferring the underlying graph topology that characterizes structured data is pivotal to many graph-based models when pre-defined graphs are not available. This paper focuses on learning graphs in the case of sequential data in dynamic environments. For sequential data, we develop an online version of classic batch graph learning method. To better track graphs in dynamic environments, we assume graphs evolve in certain patterns such that dynamic priors might be embedded in the online graph learning framework. When the information of these hidden patterns is not available, we use history data to predict the evolution of graphs. Furthermore, dynamic regret analysis of the proposed method is performed and illustrates that our online graph learning algorithms can reach sublinear dynamic regret. Experimental results support the fact that our method is superior to the state-of-art methods.      
### 91.MELONS: generating melody with long-term structure using transformers and structure graph  [ :arrow_down: ](https://arxiv.org/pdf/2110.05020.pdf)
>  The creation of long melody sequences requires effective expression of coherent musical structure. However, there is no clear representation of musical structure. Recent works on music generation have suggested various approaches to deal with the structural information of music, but generating a full-song melody with clear long-term structure remains a challenge. In this paper, we propose MELONS, a melody generation framework based on a graph representation of music structure which consists of eight types of bar-level relations. MELONS adopts a multi-step generation method with transformer-based networks by factoring melody generation into two sub-problems: structure generation and structure conditional melody generation. Experimental results show that MELONS can produce structured melodies with high quality and rich contents.      
### 92.Time-varying Graph Learning Under Structured Temporal Priors  [ :arrow_down: ](https://arxiv.org/pdf/2110.05018.pdf)
>  This paper endeavors to learn time-varying graphs by using structured temporal priors that assume underlying relations between arbitrary two graphs in the graph sequence. Different from many existing chain structure based methods in which the priors like temporal homogeneity can only describe the variations of two consecutive graphs, we propose a structure named \emph{temporal graph} to characterize the underlying real temporal relations. Under this framework, the chain structure is actually a special case of our temporal graph. We further proposed Alternating Direction Method of Multipliers (ADMM), a distributed algorithm, to solve the induced optimization problem. Numerical experiments demonstrate the superiorities of our method.      
### 93.An Information-Theoretic Analysis of The Cost of Decentralization for Learning and Inference Under Privacy Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2110.05014.pdf)
>  In vertical federated learning (FL), the features of a data sample are distributed across multiple agents. As such, inter-agent collaboration can be beneficial not only during the learning phase, as is the case for standard horizontal FL, but also during the inference phase. A fundamental theoretical question in this setting is how to quantify the cost, or performance loss, of decentralization for learning and/or inference. In this paper, we consider general supervised learning problems with any number of agents, and provide a novel information-theoretic quantification of the cost of decentralization in the presence of privacy constraints on inter-agent communication within a Bayesian framework. The cost of decentralization for learning and/or inference is shown to be quantified in terms of conditional mutual information terms involving features and label variables.      
### 94.Kernel Learning For Sound Field Estimation With L1 and L2 Regularizations  [ :arrow_down: ](https://arxiv.org/pdf/2110.04972.pdf)
>  A method to estimate an acoustic field from discrete microphone measurements is proposed. A kernel-interpolation-based method using the kernel function formulated for sound field interpolation has been used in various applications. The kernel function with directional weighting makes it possible to incorporate prior information on source directions to improve estimation accuracy. However, in prior studies, parameters for directional weighting have been empirically determined. We propose a method to optimize these parameters using observation values, which is particularly useful when prior information on source directions is uncertain. The proposed algorithm is based on discretization of the parameters and representation of the kernel function as a weighted sum of sub-kernels. Two types of regularization for the weights, $L_1$ and $L_2$, are investigated. Experimental results indicate that the proposed method achieves higher estimation accuracy than the method without kernel learning.      
### 95.Revisit Dictionary Learning for Video Compressive Sensing under the Plug-and-Play Framework  [ :arrow_down: ](https://arxiv.org/pdf/2110.04966.pdf)
>  Aiming at high-dimensional (HD) data acquisition and analysis, snapshot compressive imaging (SCI) obtains the 2D compressed measurement of HD data with optical imaging systems and reconstructs HD data using compressive sensing algorithms. While the Plug-and-Play (PnP) framework offers an emerging solution to SCI reconstruction, its intrinsic denoising process is still a challenging problem. Unfortunately, existing denoisers in the PnP framework either suffer limited performance or require extensive training data. In this paper, we propose an efficient and effective shallow-learning-based algorithm for video SCI reconstruction. Revisiting dictionary learning methods, we empower the PnP framework with a new denoiser, the kernel singular value decomposition (KSVD). Benefited from the advent of KSVD, our algorithm retains a good trade-off among quality, speed, and training difficulty. On a variety of datasets, both quantitative and qualitative evaluations of our simulation results demonstrate the effectiveness of our proposed method. In comparison to a typical baseline using total variation, our method achieves around $2$ dB improvement in PSNR and 0.2 in SSIM. We expect that our proposed PnP-KSVD algorithm can serve as a new baseline for video SCI reconstruction.      
### 96.Uplink Performance of Cell-Free Massive MIMO with Multi-Antenna Users Over Jointly-Correlated Rayleigh Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2110.04962.pdf)
>  In this paper, we investigate a cell-free massive MIMO system with both access points (APs) and user equipments (UEs) equipped with multiple antennas over jointly correlated Rayleigh fading channels. We study four uplink implementations, from fully centralized processing to fully distributed processing, and derive achievable spectral efficiency (SE) expressions with minimum mean-squared error successive interference cancellation (MMSE-SIC) detectors and arbitrary combining schemes. Furthermore, the global and local MMSE combining schemes are derived based on full and local channel state information (CSI) obtained under pilot contamination, which can maximize the achievable SE for the fully centralized and distributed implementation, respectively. We study a two-layer decoding implementation with an arbitrary combining scheme in the first layer and optimal large-scale fading decoding in the second layer. Besides, we compute novel closed-form SE expressions for the two-layer decoding implementation with maximum ratio combining. We compare the SE of different implementation levels and combining schemes and investigate the effect of having additional UE antennas. Note that increasing the number of antennas per UE may degrade the SE performance and the optimal number of UE antennas maximizing the SE is related to the implementation levels, the length of the resource block, and the number of UEs.      
### 97.Optimal Stochastic Evasive Maneuvers Using the Schrodinger's Equation  [ :arrow_down: ](https://arxiv.org/pdf/2110.04956.pdf)
>  In this paper, preys with stochastic evasion policies are considered. The stochasticity adds unpredictable changes to the prey's path for avoiding predator's attacks. The prey's cost function is composed of two terms balancing the unpredictability factor (by using stochasticity to make the task of forecasting its future positions by the predator difficult) and energy consumption (the least amount of energy required for performing a maneuver). The optimal probability density functions of the actions of the prey for trading-off unpredictability and energy consumption is shown to be characterized by the stationary Schrodinger's equation.      
### 98.LaughNet: synthesizing laughter utterances from waveform silhouettes and a single laughter example  [ :arrow_down: ](https://arxiv.org/pdf/2110.04946.pdf)
>  Emotional and controllable speech synthesis is a topic that has received much attention. However, most studies focused on improving the expressiveness and controllability in the context of linguistic content, even though natural verbal human communication is inseparable from spontaneous non-speech expressions such as laughter, crying, or grunting. We propose a model called LaughNet for synthesizing laughter by using waveform silhouettes as inputs. The motivation is not simply synthesizing new laughter utterances but testing a novel synthesis-control paradigm that uses an abstract representation of the waveform. We conducted basic listening test experiments, and the results showed that LaughNet can synthesize laughter utterances with moderate quality and retain the characteristics of the training example. More importantly, the generated waveforms have shapes similar to the input silhouettes. For future work, we will test the same method on other types of human nonverbal expressions and integrate it into more elaborated synthesis systems.      
### 99.Wav2vec-Switch: Contrastive Learning from Original-noisy Speech Pairs for Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.04934.pdf)
>  The goal of self-supervised learning (SSL) for automatic speech recognition (ASR) is to learn good speech representations from a large amount of unlabeled speech for the downstream ASR task. However, most SSL frameworks do not consider noise robustness which is crucial for real-world applications. In this paper we propose wav2vec-Switch, a method to encode noise robustness into contextualized representations of speech via contrastive learning. Specifically, we feed original-noisy speech pairs simultaneously into the wav2vec 2.0 network. In addition to the existing contrastive learning task, we switch the quantized representations of the original and noisy speech as additional prediction targets of each other. By doing this, it enforces the network to have consistent predictions for the original and noisy speech, thus allows to learn contextualized representation with noise robustness. Our experiments on synthesized and real noisy data show the effectiveness of our method: it achieves 2.9--4.9% relative word error rate (WER) reduction on the synthesized noisy LibriSpeech data without deterioration on the original data, and 5.7% on CHiME-4 real 1-channel noisy data compared to a data augmentation baseline even with a strong language model for decoding. Our results on CHiME-4 can match or even surpass those with well-designed speech enhancement components.      
### 100.Crack detection using tap-testing and machine learning techniques to prevent potential rockfall incidents  [ :arrow_down: ](https://arxiv.org/pdf/2110.04923.pdf)
>  Rockfalls are a hazard for the safety of infrastructure as well as people. Identifying loose rocks by inspection of slopes adjacent to roadways and other infrastructure and removing them in advance can be an effective way to prevent unexpected rockfall incidents. This paper proposes a system towards an automated inspection for potential rockfalls. A robot is used to repeatedly strike or tap on the rock surface. The sound from the tapping is collected by the robot and subsequently classified with the intent of identifying rocks that are broken and prone to fall. Principal Component Analysis (PCA) of the collected acoustic data is used to recognize patterns associated with rocks of various conditions, including intact as well as rock with different types and locations of cracks. The PCA classification was first demonstrated simulating sounds of different characteristics that were automatically trained and tested. Secondly, a laboratory test was conducted tapping rock specimens with three different levels of discontinuity in depth and shape. A real microphone mounted on the robot recorded the sound and the data were classified in three clusters within 2D space. A model was created using the training data to classify the reminder of the data (the test data). The performance of the method is evaluated with a confusion matrix.      
### 101.Increasing a microscope's effective field of view via overlapped imaging and machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.04921.pdf)
>  This work demonstrates a multi-lens microscopic imaging system that overlaps multiple independent fields of view on a single sensor for high-efficiency automated specimen analysis. Automatic detection, classification and counting of various morphological features of interest is now a crucial component of both biomedical research and disease diagnosis. While convolutional neural networks (CNNs) have dramatically improved the accuracy of counting cells and sub-cellular features from acquired digital image data, the overall throughput is still typically hindered by the limited space-bandwidth product (SBP) of conventional microscopes. Here, we show both in simulation and experiment that overlapped imaging and co-designed analysis software can achieve accurate detection of diagnostically-relevant features for several applications, including counting of white blood cells and the malaria parasite, leading to multi-fold increase in detection and processing throughput with minimal reduction in accuracy.      
### 102.Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.04891.pdf)
>  Hybrid and end-to-end (E2E) systems have their individual advantages, with different error patterns in the speech recognition results. By jointly modeling audio and text, the E2E model performs better in matched scenarios and scales well with a large amount of paired audio-text training data. The modularized hybrid model is easier for customization, and better to make use of a massive amount of unpaired text data. This paper proposes a two-pass hybrid and E2E cascading (HEC) framework to combine the hybrid and E2E model in order to take advantage of both sides, with hybrid in the first pass and E2E in the second pass. We show that the proposed system achieves 8-10% relative word error rate reduction with respect to each individual system. More importantly, compared with the pure E2E system, we show the proposed system has the potential to keep the advantages of hybrid system, e.g., customization and segmentation capabilities. We also show the second pass E2E model in HEC is robust with respect to the change in the first pass hybrid model.      
### 103.Haar Wavelet Feature Compression for Quantized Graph Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2110.04824.pdf)
>  Graph Convolutional Networks (GCNs) are widely used in a variety of applications, and can be seen as an unstructured version of standard Convolutional Neural Networks (CNNs). As in CNNs, the computational cost of GCNs for large input graphs (such as large point clouds or meshes) can be high and inhibit the use of these networks, especially in environments with low computational resources. To ease these costs, quantization can be applied to GCNs. However, aggressive quantization of the feature maps can lead to a significant degradation in performance. On a different note, Haar wavelet transforms are known to be one of the most effective and efficient approaches to compress signals. Therefore, instead of applying aggressive quantization to feature maps, we propose to utilize Haar wavelet compression and light quantization to reduce the computations and the bandwidth involved with the network. We demonstrate that this approach surpasses aggressive feature quantization by a significant margin, for a variety of problems ranging from node classification to point cloud classification and part and semantic segmentation.      
### 104.Application of Graph Convolutions in a Lightweight Model for Skeletal Human Motion Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2110.04810.pdf)
>  Prediction of movements is essential for successful cooperation with intelligent systems. We propose a model that integrates organized spatial information as given through the moving body's skeletal structure. This inherent structure is exploited in our model through application of Graph Convolutions and we demonstrate how this allows leveraging the structured spatial information into competitive predictions that are based on a lightweight model that requires a comparatively small number of parameters.      
### 105.Self-Supervised 3D Face Reconstruction via Conditional Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2110.04800.pdf)
>  We present a conditional estimation (CEST) framework to learn 3D facial parameters from 2D single-view images by self-supervised training from videos. CEST is based on the process of analysis by synthesis, where the 3D facial parameters (shape, reflectance, viewpoint, and illumination) are estimated from the face image, and then recombined to reconstruct the 2D face image. In order to learn semantically meaningful 3D facial parameters without explicit access to their labels, CEST couples the estimation of different 3D facial parameters by taking their statistical dependency into account. Specifically, the estimation of any 3D facial parameter is not only conditioned on the given image, but also on the facial parameters that have already been derived. Moreover, the reflectance symmetry and consistency among the video frames are adopted to improve the disentanglement of facial parameters. Together with a novel strategy for incorporating the reflectance symmetry and consistency, CEST can be efficiently trained with in-the-wild video clips. Both qualitative and quantitative experiments demonstrate the effectiveness of CEST.      
### 106.A Novel Negative $\ell_1$ Penalty Approach for Multiuser One-Bit Massive MIMO Downlink with PSK Signaling  [ :arrow_down: ](https://arxiv.org/pdf/2110.04768.pdf)
>  This paper considers the one-bit precoding problem for the multiuser downlink massive multiple-input multiple-output (MIMO) system with phase shift keying (PSK) modulation and focuses on the celebrated constructive interference (CI)-based problem formulation. The existence of the discrete one-bit constraint makes the problem generally hard to solve. In this paper, we propose an efficient negative $\ell_1$ penalty approach for finding a high-quality solution of the considered problem. Specifically, we first propose a novel negative $\ell_1$ penalty model, which penalizes the one-bit constraint into the objective with a negative $\ell_1$-norm term, and show the equivalence between (global and local) solutions of the original problem and the penalty problem when the penalty parameter is sufficiently large. We further transform the penalty model into an equivalent min-max problem and propose an efficient alternating optimization (AO) algorithm for solving it. The AO algorithm enjoys low per-iteration complexity and is guaranteed to converge to the stationary point of the min-max problem. Numerical results show that, compared against the state-of-the-art CI-based algorithms, the proposed algorithm generally achieves better bit-error-rate (BER) performance with lower computational cost.      
### 107.Multi-task Learning with Metadata for Music Mood Classification  [ :arrow_down: ](https://arxiv.org/pdf/2110.04765.pdf)
>  Mood recognition is an important problem in music informatics and has key applications in music discovery and recommendation. These applications have become even more relevant with the rise of music streaming. Our work investigates the research question of whether we can leverage audio metadata such as artist and year, which is readily available, to improve the performance of mood classification models. To this end, we propose a multi-task learning approach in which a shared model is simultaneously trained for mood and metadata prediction tasks with the goal to learn richer representations. Experimentally, we demonstrate that applying our technique on the existing state-of-the-art convolutional neural networks for mood classification improves their performances consistently. We conduct experiments on multiple datasets and report that our approach can lead to improvements in the average precision metric by up to 8.7 points.      
### 108.Towards High-fidelity Singing Voice Conversion with Acoustic Reference and Contrastive Predictive Coding  [ :arrow_down: ](https://arxiv.org/pdf/2110.04754.pdf)
>  Recently, phonetic posteriorgrams (PPGs) based methods have been quite popular in non-parallel singing voice conversion systems. However, due to the lack of acoustic information in PPGs, style and naturalness of the converted singing voices are still limited. To solve these problems, in this paper, we utilize an acoustic reference encoder to implicitly model singing characteristics. We experiment with different auxiliary features, including mel spectrograms, HuBERT, and the middle hidden feature (PPG-Mid) of pretrained automatic speech recognition (ASR) model, as the input of the reference encoder, and finally find the HuBERT feature is the best choice. In addition, we use contrastive predictive coding (CPC) module to further smooth the voices by predicting future observations in latent space. Experiments show that, compared with the baseline models, our proposed model can significantly improve the naturalness of converted singing voices and the similarity with the target singer. Moreover, our proposed model can also make the speakers with just speech data sing.      
### 109.Can Audio Captions Be Evaluated with Image Caption Metrics?  [ :arrow_down: ](https://arxiv.org/pdf/2110.04684.pdf)
>  Automated audio captioning aims at generating textual descriptions for an audio clip. To evaluate the quality of generated audio captions, previous works directly adopt image captioning metrics like SPICE and CIDEr, without justifying their suitability in this new domain, which may mislead the development of advanced models. This problem is still unstudied due to the lack of human judgment datasets on caption quality. Therefore, we firstly construct two evaluation benchmarks, AudioCaps-Eval and Clotho-Eval. They are established with pairwise comparison instead of absolute rating to achieve better inter-annotator agreement. Current metrics are found in poor correlation with human annotations on these datasets. To overcome their limitations, we propose a metric named FENSE, where we combine the strength of Sentence-BERT in capturing similarity, and a novel Error Detector to penalize erroneous sentences for robustness. On the newly established benchmarks, FENSE outperforms current metrics by 14-25% accuracy. Code, data and web demo available at: <a class="link-external link-https" href="https://github.com/blmoistawinde/fense" rel="external noopener nofollow">this https URL</a>      
### 110.Mixture Model Auto-Encoders: Deep Clustering through Dictionary Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.04683.pdf)
>  State-of-the-art approaches for clustering high-dimensional data utilize deep auto-encoder architectures. Many of these networks require a large number of parameters and suffer from a lack of interpretability, due to the black-box nature of the auto-encoders. We introduce Mixture Model Auto-Encoders (MixMate), a novel architecture that clusters data by performing inference on a generative model. Derived from the perspective of sparse dictionary learning and mixture models, MixMate comprises several auto-encoders, each tasked with reconstructing data in a distinct cluster, while enforcing sparsity in the latent space. Through experiments on various image datasets, we show that MixMate achieves competitive performance compared to state-of-the-art deep clustering algorithms, while using orders of magnitude fewer parameters.      
### 111.An Overview of Techniques for Biomarker Discovery in Voice Signal  [ :arrow_down: ](https://arxiv.org/pdf/2110.04678.pdf)
>  This paper reflects on the effect of several categories of medical conditions on human voice, focusing on those that may be hypothesized to have effects on voice, but for which the changes themselves may be subtle enough to have eluded observation in standard analytical examinations of the voice signal. It presents three categories of techniques that can potentially uncover such elusive biomarkers and allow them to be measured and used for predictive and diagnostic purposes. These approaches include proxy techniques, model-based analytical techniques and data-driven AI techniques.      
### 112.Competitive Perimeter Defense of Conical Environments  [ :arrow_down: ](https://arxiv.org/pdf/2110.04667.pdf)
>  We consider a perimeter defense problem in a planar conical environment in which a single vehicle, having a finite capture radius, aims to defend a concentric perimeter from mobile intruders. The intruders are arbitrarily released at the circumference of the environment and move radially toward the perimeter with fixed speed. We present a competitive analysis approach to this problem by measuring the performance of multiple online algorithms for the vehicle against arbitrary inputs, relative to an optimal offline algorithm that has access to all future inputs. In particular, we first establish a necessary condition on the parameter space to guarantee finite competitiveness of any algorithm, and then characterize a parameter regime in which the competitive ratio is guaranteed to be at least 2 for any algorithm. We then design and analyze three online algorithms and characterize parameter regimes for which they have finite competitive ratios. Specifically, our first two algorithms are provably 1, and 2-competitive, respectively, whereas our third algorithm exhibits a finite competitive ratio that depends on the problem parameters. Finally, we provide numerous parameter space plots providing insights into the relative performance of our algorithms.      
### 113.Streaming on-device detection of device directed speech from voice and touch-based invocation  [ :arrow_down: ](https://arxiv.org/pdf/2110.04656.pdf)
>  When interacting with smart devices such as mobile phones or wearables, the user typically invokes a virtual assistant (VA) by saying a keyword or by pressing a button on the device. However, in many cases, the VA can accidentally be invoked by the keyword-like speech or accidental button press, which may have implications on user experience and privacy. To this end, we propose an acoustic false-trigger-mitigation (FTM) approach for on-device device-directed speech detection that simultaneously handles the voice-trigger and touch-based invocation. To facilitate the model deployment on-device, we introduce a new streaming decision layer, derived using the notion of temporal convolutional networks (TCN) [1], known for their computational efficiency. To the best of our knowledge, this is the first approach that can detect device-directed speech from more than one invocation type in a streaming fashion. We compare this approach with streaming alternatives based on vanilla Average layer, and canonical LSTMs, and show: (i) that all the models show only a small degradation in accuracy compared with the invocation-specific models, and (ii) that the newly introduced streaming TCN consistently performs better or comparable with the alternatives, while mitigating device undirected speech faster in time, and with (relative) reduction in runtime peak-memory over the LSTM-based approach of 33% vs. 7%, when compared to a non-streaming counterpart.      
### 114.Topological Data Analysis (TDA) Techniques Enhance Hand Pose Classification from ECoG Neural Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2110.04653.pdf)
>  Electrocorticogram (ECoG) well characterizes hand movement intentions and gestures. In the present work we aim to investigate the possibility to enhance hand pose classification, in a Rock-Paper-Scissor - and Rest - task, by introducing topological descriptors of time series data. We hypothesized that an innovative approach based on topological data analysis can extract hidden information that are not detectable with standard Brain Computer Interface (BCI)techniques. To investigate this hypothesis, we integrate topological features together with power band features and feed them to several standard classifiers, e.g. Random Forest,Gradient Boosting. Model selection is thus completed after a meticulous phase of bayesian hyperparameter optimization. With our method, we observed robust results in terms of ac-curacy for a four-labels classification problem, with limited available data. Through feature importance investigation, we conclude that topological descriptors are able to extract useful discriminative information and provide novel insights.Since our data are restricted to single-patient recordings, generalization might be limited. Nevertheless, our method can be extended and applied to a wide range of neurophysiological recordings and it might be an intriguing point of departure for future studies.      
### 115.Universal Paralinguistic Speech Representations Using Self-Supervised Conformers  [ :arrow_down: ](https://arxiv.org/pdf/2110.04621.pdf)
>  Many speech applications require understanding aspects beyond the words being spoken, such as recognizing emotion, detecting whether the speaker is wearing a mask, or distinguishing real from synthetic speech. In this work, we introduce a new state-of-the-art paralinguistic representation derived from large-scale, fully self-supervised training of a 600M+ parameter Conformer-based architecture. We benchmark on a diverse set of speech tasks and demonstrate that simple linear classifiers trained on top of our time-averaged representation outperform nearly all previous results, in some cases by large margins. Our analyses of context-window size demonstrate that, surprisingly, 2 second context-windows achieve 98% the performance of the Conformers that use the full long-term context. Furthermore, while the best per-task representations are extracted internally in the network, stable performance across several layers allows a single universal representation to reach near optimal performance on all tasks.      
### 116.An Exploration of Self-Supervised Pretrained Representations for End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2110.04590.pdf)
>  Self-supervised pretraining on speech data has achieved a lot of progress. High-fidelity representation of the speech signal is learned from a lot of untranscribed data and shows promising performance. Recently, there are several works focusing on evaluating the quality of self-supervised pretrained representations on various tasks without domain restriction, e.g. SUPERB. However, such evaluations do not provide a comprehensive comparison among many ASR benchmark corpora. In this paper, we focus on the general applications of pretrained speech representations, on advanced end-to-end automatic speech recognition (E2E-ASR) models. We select several pretrained speech representations and present the experimental results on various open-source and publicly available corpora for E2E-ASR. Without any modification of the back-end model architectures or training strategy, some of the experiments with pretrained representations, e.g., WSJ, WSJ0-2mix with HuBERT, reach or outperform current state-of-the-art (SOTA) recognition performance. Moreover, we further explore more scenarios for whether the pretraining representations are effective, such as the cross-language or overlapped speech. The scripts, configuratons and the trained models have been released in ESPnet to let the community reproduce our experiments and improve them.      
### 117.Temporally Consistent Video Colorization with Deep Feature Propagation and Self-regularization Learning  [ :arrow_down: ](https://arxiv.org/pdf/2110.04562.pdf)
>  Video colorization is a challenging and highly ill-posed problem. Although recent years have witnessed remarkable progress in single image colorization, there is relatively less research effort on video colorization and existing methods always suffer from severe flickering artifacts (temporal inconsistency) or unsatisfying colorization performance. We address this problem from a new perspective, by jointly considering colorization and temporal consistency in a unified framework. Specifically, we propose a novel temporally consistent video colorization framework (TCVC). TCVC effectively propagates frame-level deep features in a bidirectional way to enhance the temporal consistency of colorization. Furthermore, TCVC introduces a self-regularization learning (SRL) scheme to minimize the prediction difference obtained with different time steps. SRL does not require any ground-truth color videos for training and can further improve temporal consistency. Experiments demonstrate that our method can not only obtain visually pleasing colorized video, but also achieve clearly better temporal consistency than state-of-the-art methods.      
### 118.Adaptive Variable Impedance Control for a Modular Soft Robot Manipulator in Configuration Space  [ :arrow_down: ](https://arxiv.org/pdf/2110.04553.pdf)
>  Compliance is a strong requirement for human-robot interactions. Soft-robots provide an opportunity to cover the lack of compliance in conventional actuation mechanisms, however, the control of them is very challenging given their intrinsic complex motions. Therefore, soft-robots require new approaches to e.g., modeling, control, dynamics, and planning. One of the control strategies that ensures compliance is the impedance control. During the task execution in the presence of coupling force and position constraints, a dynamic behavior increases the flexibility of the impedance control. This imposes some additional constraints on the stability of the control system. To tackle them, we propose a variable impedance control in configuration space for a modular soft robot manipulator (MSRM) in the presence of model uncertainties and external forces. The external loads are estimated in configuration space using a momentum-based approach in order to reduce the calculation complexity, and the adaptive back-stepping sliding mode (ABSM) controller is designed to guard against uncertainties. Stability analysis is performed using Lyapunov theory which guarantees not only the exponential stability of each state under the designed control law, but also the global stability of the closed-loop system. The system performance is benchmarked against other conventional control methods, such as the sliding mode (SM) and inverse dynamics PD controllers. The results show the effectiveness of the proposed variable impedance control in stabilizing the position error and diminishing the impact of the external load compared to SM and PD controllers.      
### 119.A Mutual learning framework for Few-shot Sound Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2110.04474.pdf)
>  Although prototypical network (ProtoNet) has proved to be an effective method for few-shot sound event detection, two problems still exist. Firstly, the small-scaled support set is insufficient so that the class prototypes may not represent the class center accurately. Secondly, the feature extractor is task-agnostic (or class-agnostic): the feature extractor is trained with base-class data and directly applied to unseen-class data. To address these issues, we present a novel mutual learning framework with transductive learning, which aims at iteratively updating the class prototypes and feature extractor. More specifically, we propose to update class prototypes with transductive inference to make the class prototypes as close to the true class center as possible. To make the feature extractor to be task-specific, we propose to use the updated class prototypes to fine-tune the feature extractor. After that, a fine-tuned feature extractor further helps produce better class prototypes. Our method achieves the F-score of 38.4$\%$ on the DCASE 2021 Task 5 evaluation set, which won the first place in the few-shot bioacoustic event detection task of Detection and Classification of Acoustic Scenes and Events (DCASE) 2021 Challenge.      
### 120.ProductAE: Towards Training Larger Channel Codes based on Neural Product Codes  [ :arrow_down: ](https://arxiv.org/pdf/2110.04466.pdf)
>  There have been significant research activities in recent years to automate the design of channel encoders and decoders via deep learning. Due the dimensionality challenge in channel coding, it is prohibitively complex to design and train relatively large neural channel codes via deep learning techniques. Consequently, most of the results in the literature are limited to relatively short codes having less than 100 information bits. In this paper, we construct ProductAEs, a computationally efficient family of deep-learning driven (encoder, decoder) pairs, that aim at enabling the training of relatively large channel codes (both encoders and decoders) with a manageable training complexity. We build upon the ideas from classical product codes, and propose constructing large neural codes using smaller code components. More specifically, instead of directly training the encoder and decoder for a large neural code of dimension $k$ and blocklength $n$, we provide a framework that requires training neural encoders and decoders for the code parameters $(k_1,n_1)$ and $(k_2,n_2)$ such that $k_1 k_2=k$ and $n_1 n_2=n$. Our training results show significant gains, over all ranges of signal-to-noise ratio (SNR), for a code of parameters $(100,225)$ and a moderate-length code of parameters $(196,441)$, over polar codes under successive cancellation (SC) decoder. Moreover, our results demonstrate meaningful gains over Turbo Autoencoder (TurboAE) and state-of-the-art classical codes. This is the first work to design product autoencoders and a pioneering work on training large channel codes.      
### 121.Using multiple reference audios and style embedding constraints for speech synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2110.04451.pdf)
>  The end-to-end speech synthesis model can directly take an utterance as reference audio, and generate speech from the text with prosody and speaker characteristics similar to the reference audio. However, an appropriate acoustic embedding must be manually selected during inference. Due to the fact that only the matched text and speech are used in the training process, using unmatched text and speech for inference would cause the model to synthesize speech with low content quality. In this study, we propose to mitigate these two problems by using multiple reference audios and style embedding constraints rather than using only the target audio. Multiple reference audios are automatically selected using the sentence similarity determined by Bidirectional Encoder Representations from Transformers (BERT). In addition, we use ''target'' style embedding from a Pre-trained encoder as a constraint by considering the mutual information between the predicted and ''target'' style embedding. The experimental results show that the proposed model can improve the speech naturalness and content quality with multiple reference audios and can also outperform the baseline model in ABX preference tests of style similarity.      
### 122.Towards Lightweight Applications: Asymmetric Enroll-Verify Structure for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2110.04438.pdf)
>  With the development of deep learning, automatic speaker verification has made considerable progress over the past few years. However, to design a lightweight and robust system with limited computational resources is still a challenging problem. Traditionally, a speaker verification system is symmetrical, indicating that the same embedding extraction model is applied for both enrollment and verification in inference. In this paper, we come up with an innovative asymmetric structure, which takes the large-scale ECAPA-TDNN model for enrollment and the small-scale ECAPA-TDNNLite model for verification. As a symmetrical system, our proposed ECAPA-TDNNLite model achieves an EER of 3.07% on the Voxceleb1 original test set with only 11.6M FLOPS. Moreover, the asymmetric structure further reduces the EER to 2.31%, without increasing any computational costs during verification.      
### 123.A Framework for Private Communication with Secret Block Structure  [ :arrow_down: ](https://arxiv.org/pdf/2110.04345.pdf)
>  Harnessing a block-sparse prior to recover signals through underdetermined linear measurements has been extensively shown to allow exact recovery in conditions where classical compressed sensing would provably fail. We exploit this result to propose a novel private communication framework where the secrecy is achieved by transmitting instances of an unidentifiable compressed sensing problem over a public channel. The legitimate receiver can attempt to overcome this ill-posedness by leveraging secret knowledge of a block structure that was used to encode the transmitter's message. We study the privacy guarantees of this communication protocol to a single transmission, and to multiple transmissions without refreshing the shared secret. Additionally, we propose an algorithm for an eavesdropper to learn the block structure via the method of moments and highlight the privacy benefits of this framework through numerical experiments.      
### 124.Large Scale Audio Understanding without Transformers/ Convolutions/ BERTs/ Mixers/ Attention/ RNNs or ....  [ :arrow_down: ](https://arxiv.org/pdf/2110.03183.pdf)
>  This paper presents a way of doing large scale audio understanding without traditional state of the art neural architectures. Ever since the introduction of deep learning for understanding audio signals in the past decade, convolutional architectures have been able to achieve state of the art results surpassing traditional hand-crafted features. In the recent past, there has been a similar shift away from traditional convolutional and recurrent neural networks towards purely end-to-end Transformer architectures. We, in this work, explore an approach, based on Bag-of-Words model. Our approach does not have any convolutions, recurrence, attention, transformers or other approaches such as BERT. We utilize micro and macro level clustered vanilla embeddings, and use a MLP head for classification. We only use feed-forward encoder-decoder models to get the bottlenecks of spectral envelops, spectral patches and slices as well as multi-resolution spectra. A classification head (a feed-forward layer), similar to the approach in SimCLR is trained on a learned representation. Using simple codes learned on latent representations, we show how we surpass traditional convolutional neural network architectures, and come strikingly close to outperforming powerful Transformer architectures. This work hopefully would pave way for exciting advancements in the field of representation learning without massive, end-to-end neural architectures.      
