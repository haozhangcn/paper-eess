# ArXiv eess --Mon, 6 Sep 2021
### 1.The Singular Angle of Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.01629.pdf)
>  In this paper, we introduce an angle notion, called the singular angle, for stable nonlinear systems from an input-output perspective. The proposed system singular angle, based on the angle between $\mathcal{L}_2$-signals, describes an upper bound for the "rotating effect" from the system input to output signals. It is, thus, different from the recently appeared nonlinear system phase which adopts the complexification of real-valued signals using the Hilbert transform. It can quantify the passivity and serve as an angular counterpart to the system $\mathcal{L}_2$-gain. It also provides an alternative to the nonlinear system phase. A nonlinear small angle theorem, which involves a comparison of the loop system angle with $\pi$, is established for feedback stability analysis. When dealing with multi-input multi-output linear time-invariant (LTI) systems, we further come up with the frequency-wise and $\mathcal{H}_\infty$ singular angle notions based on the matrix singular angle, and develop corresponding LTI small angle theorems.      
### 2.On the Interplay between Self-Driving Cars and Public Transportation  [ :arrow_down: ](https://arxiv.org/pdf/2109.01627.pdf)
>  Cities worldwide struggle with overloaded transportation systems and their externalities, such as traffic congestion and emissions. The emerging autonomous transportation technology has a potential to alleviate these issues. Yet, the decisions of profit-maximizing operators running large autonomous fleets could have a negative impact on other stakeholders, e.g., by disproportionately cannibalizing public transport, and therefore could make the transportation system even less efficient and sustainable. A careful analysis of these tradeoffs requires modeling the main modes of transportation, including public transport, within a unified framework. In this paper, we propose such a framework, which allows us to study the interplay among mobility service providers, public transport authorities, and customers. Our framework combines a graph-theoretic network model for the transportation system with a game-theoretic market model in which mobility service providers are profit-maximizers, while customers select individually-optimal transportation options. We apply our framework to data for the city of Berlin, Germany, and present sensitivity analyses to study parameters that mobility service providers or municipalities can influence to steer the system. We show that depending on market conditions and policy restrictions, autonomous ride-hailing systems may complement or cannibalize a public transportation system, serving between 7% and 80% of all customers. We discuss the main factors behind differences in these outcomes as well as strategic design options available to policymakers. Among others, we show that the monopolistic and the competitive cases yield similar modal shares, but differ in the profit outcome of each mobility service provider.      
### 3.Learning-based Motion Artifact Removal Networks (LEARN) for Quantitative $R_2^\ast$ Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2109.01622.pdf)
>  Purpose: To introduce two novel learning-based motion artifact removal networks (LEARN) for the estimation of quantitative motion- and $B0$-inhomogeneity-corrected $R_2^\ast$ maps from motion-corrupted multi-Gradient-Recalled Echo (mGRE) MRI data. <br>Methods: We train two convolutional neural networks (CNNs) to correct motion artifacts for high-quality estimation of quantitative $B0$-inhomogeneity-corrected $R_2^\ast$ maps from mGRE sequences. The first CNN, LEARN-IMG, performs motion correction on complex mGRE images, to enable the subsequent computation of high-quality motion-free quantitative $R_2^\ast$ (and any other mGRE-enabled) maps using the standard voxel-wise analysis or machine-learning-based analysis. The second CNN, LEARN-BIO, is trained to directly generate motion- and $B0$-inhomogeneity-corrected quantitative $R_2^\ast$ maps from motion-corrupted magnitude-only mGRE images by taking advantage of the biophysical model describing the mGRE signal decay. We show that both CNNs trained on synthetic MR images are capable of suppressing motion artifacts while preserving details in the predicted quantitative $R_2^\ast$ maps. Significant reduction of motion artifacts on experimental in vivo motion-corrupted data has also been achieved by using our trained models. <br>Conclusion: Both LEARN-IMG and LEARN-BIO can enable the computation of high-quality motion- and $B0$-inhomogeneity-corrected $R_2^\ast$ maps. LEARN-IMG performs motion correction on mGRE images and relies on the subsequent analysis for the estimation of $R_2^\ast$ maps, while LEARN-BIO directly performs motion- and $B0$-inhomogeneity-corrected $R_2^\ast$ estimation. Both LEARN-IMG and LEARN-BIO jointly process all the available gradient echoes, which enables them to exploit spatial patterns available in the data. The high computational speed of LEARN-BIO is an advantage that can lead to a broader clinical application.      
### 4.Musical Tempo Estimation Using a Multi-scale Network  [ :arrow_down: ](https://arxiv.org/pdf/2109.01607.pdf)
>  Recently, some single-step systems without onset detection have shown their effectiveness in automatic musical tempo estimation. Following the success of these systems, in this paper we propose a Multi-scale Grouped Attention Network to further explore the potential of such methods. A multi-scale structure is introduced as the overall network architecture where information from different scales is aggregated to strengthen contextual feature learning. Furthermore, we propose a Grouped Attention Module as the key component of the network. The proposed module separates the input feature into several groups along the frequency axis, which makes it capable of capturing long-range dependencies from different frequency positions on the spectrogram. In comparison experiments, the results on public datasets show that the proposed model outperforms existing state-of-the-art methods on Accuracy1.      
### 5.Continuous-Time Behavior Trees as Discontinuous Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.01575.pdf)
>  Behavior trees represent a hierarchical and modular way of combining several low-level control policies into a high-level task-switching policy. Hybrid dynamical systems can also be seen in terms of task switching between different policies, and therefore several comparisons between behavior trees and hybrid dynamical systems have been made, but only informally, and only in discrete time. A formal continuous-time formulation of behavior trees has been lacking. Additionally, convergence analyses of specific classes of behavior tree designs have been made, but not for general designs. <br>In this letter, we provide the first continuous-time formulation of behavior trees, show that they can be seen as discontinuous dynamical systems (a subclass of hybrid dynamical systems), which enables the application of existence and uniqueness results to behavior trees, and finally, provide sufficient conditions under which such systems will converge to a desired region of the state space for general designs. With these results, a large body of results on continuous-time dynamical systems can be brought to use when designing behavior tree controllers.      
### 6.Phone Duration Modeling for Speaker Age Estimation in Children  [ :arrow_down: ](https://arxiv.org/pdf/2109.01568.pdf)
>  Automatic inference of important paralinguistic information such as age from speech is an important area of research with numerous spoken language technology based applications. Speaker age estimation has applications in enabling personalization and age-appropriate curation of information and content. However, research in speaker age estimation in children is especially challenging due to paucity of relevant speech data representing the developmental spectrum, and the high signal variability especially intra age variability that complicates modeling. Most approaches in children speaker age estimation adopt methods directly from research on adult speech processing. In this paper, we propose features specific to children and focus on speaker's phone duration as an important biomarker of children's age. We propose phone duration modeling for predicting age from child's speech. To enable that, children speech is first forced aligned with the corresponding transcription to derive phone duration distributions. Statistical functionals are computed from phone duration distributions for each phoneme which are in turn used to train regression models to predict speaker age. Two children speech datasets are employed to demonstrate the robustness of phone duration features. We perform age regression experiments on age categories ranging from children studying in kindergarten to grade 10. Experimental results suggest phone durations contain important development-related information of children. Phonemes contributing most to estimation of children speaker age are analyzed and presented.      
### 7.Risk Assessment for Connected Vehicles under Stealthy Attacks on Vehicle-to-Vehicle Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.01553.pdf)
>  Cooperative Adaptive Cruise Control (CACC) is an autonomous vehicle-following technology that allows groups of vehicles on the highway to form in tightly-coupled platoons. This is accomplished by exchanging inter-vehicle data through Vehicle-to-Vehicle (V2V) wireless communication networks. CACC increases traffic throughput and safety, and decreases fuel consumption. However, the surge of vehicle connectivity has brought new security challenges as vehicular networks increasingly serve as new access points for adversaries trying to deteriorate the platooning performance or even cause collisions. In this manuscript, we propose a novel attack detection scheme that leverage real-time sensor/network data and physics-based mathematical models of vehicles in the platoon. Nevertheless, even the best detection scheme could lead to conservative detection results because of unavoidable modelling uncertainties, network effects (delays, quantization, communication dropouts), and noise. It is hard (often impossible) for any detector to distinguish between these different perturbation sources and actual attack signals. This enables adversaries to launch a range of attack strategies that can surpass the detection scheme by hiding within the system uncertainty. Here, we provide risk assessment tools (in terms of semidefinite programs) for Connected and Automated Vehicles (CAVs) to quantify the potential effect of attacks that remain hidden from the detector (referred here as \emph{stealthy attacks}). A numerical case-study is presented to illustrate the effectiveness of our methods.      
### 8.Mitosis Detection for Breast Cancer Pathology Images using UV-Net  [ :arrow_down: ](https://arxiv.org/pdf/2109.01526.pdf)
>  The difficulty of detecting mitosis and its similarity to non-mitosis objects has remained a challenge in computational pathology. The lack of publicly available data has added more complexity. Deep learning algorithms have shown potentials in mitosis detection tasks. However, they face challenges when applied to pathology images with dense medium and diverse dataset. This paper introduces an optimized UV-Net architecture, developed to focus on mitosis details with high-resolution through feature preservation. Stain normalization methods are used to generalize the trained network. An F1 score of 0.6721 is achieved using this network.      
### 9.Track Coalescence and Repulsion: MHT, JPDA, and BP  [ :arrow_down: ](https://arxiv.org/pdf/2109.01523.pdf)
>  Joint probabilistic data association (JPDA) and multiple hypothesis tracking (MHT) introduced in the 70s, are still widely used methods for multitarget tracking (MTT). Extensive studies over the last few decades have revealed undesirable behavior of JPDA and MHT type methods in tracking scenarios with targets in close proximity. In particular, JPDA suffers from the track coalescence effect, i.e., estimated tracks of targets in close proximity tend to merge and can become indistinguishable. Interestingly, in MHT, an opposite effect to track coalescence called track repulsion can be observed. In this paper, we review the estimation strategies of the MHT, JPDA, and the recently introduced belief propagation (BP) framework for MTT and we investigate if BP also suffers from these two detrimental effects. Our numerical results indicate that BP-based MTT can mostly avoid both track repulsion and coalescence.      
### 10.Multi-source Domain Adaptation Using Gradient Reversal Layer for Mitotic Cell Detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.01503.pdf)
>  This is a write-up of our method submitted to Mitosis Domain Generalization (MIDOG 2021) Challenge held in MICCAI2021 conference.      
### 11.A Scalable Track-Before-Detect Method With Poisson/Multi-Bernoulli Model  [ :arrow_down: ](https://arxiv.org/pdf/2109.01490.pdf)
>  We propose a scalable track-before-detect (TBD) tracking method based on a Poisson/multi-Bernoulli model. To limit computational complexity, we approximate the exact multi-Bernoulli mixture posterior probability density function (pdf) by a multi-Bernoulli pdf. Data association based on the sum-product algorithm and recycling of Bernoulli components enable the detection and tracking of low-observable objects with limited computational resources. Our simulation results demonstrate a significantly improved tracking performance compared to a state-of-the-art TBD method.      
### 12.Studying the Effects of Self-Attention for Medical Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2109.01486.pdf)
>  When the trained physician interprets medical images, they understand the clinical importance of visual features. By applying cognitive attention, they apply greater focus onto clinically relevant regions while disregarding unnecessary features. The use of computer vision to automate the classification of medical images is widely studied. However, the standard convolutional neural network (CNN) does not necessarily employ subconscious feature relevancy evaluation techniques similar to the trained medical specialist and evaluates features more generally. Self-attention mechanisms enable CNNs to focus more on semantically important regions or aggregated relevant context with long-range dependencies. By using attention, medical image analysis systems can potentially become more robust by focusing on more important clinical feature regions. In this paper, we provide a comprehensive comparison of various state-of-the-art self-attention mechanisms across multiple medical image analysis tasks. Through both quantitative and qualitative evaluations along with a clinical user-centric survey study, we aim to provide a deeper understanding of the effects of self-attention in medical computer vision tasks.      
### 13.MitoDet: Simple and robust mitosis detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.01485.pdf)
>  Mitotic figure detection is a challenging task in digital pathology that has a direct impact on therapeutic decisions. While automated methods often achieve acceptable results under laboratory conditions, they frequently fail in the clinical deployment phase. This problem can be mainly attributed to a phenomenon called domain shift. An important source of a domain shift is introduced by different microscopes and their camera systems, which noticeably change the color representation of digitized images. In this method description we present our submitted algorithm for the Mitosis Domain Generalization Challenge, which employs a RetinaNet trained with strong data augmentation and achieves an F1 score of 0.7138 on the preliminary test set.      
### 14.Detailed analysis and comparison of different activity metrics  [ :arrow_down: ](https://arxiv.org/pdf/2109.01468.pdf)
>  Actigraphic measurements are an important part of research in different disciplines, yet the procedure of determining activity values is unexpectedly not standardized in the literature. Although the measured raw acceleration signal can be diversely processed, and then the activity values can be calculated by different activity calculation methods, the documentations of them are generally incomplete or vary by manufacturer. These numerous activity metrics may require different types of preprocessing of the acceleration signal. For example, digital filtering of the acceleration signals can have various parameters; moreover, both the filter and the activity metrics can also be applied per axis or on the magnitudes of the acceleration vector. Level crossing-based activity metrics also depend on unclearly determined threshold level values. Due to the serious inconsistency of determining activity values, we created a detailed and comprehensive comparison of the different available activity calculation procedures because, up to the present, it was lacking in the literature. We assessed the different methods by analysing the triaxial acceleration signals measured during a 10-day movement of 42 subjects. We calculated 148 different activity signals for each subject's movement using the combinations of various types of preprocessing and 7 different activity metrics applied on both axial and magnitude data. We determined the linear relationship between the metrics by correlation analysis, while we also examined the effects of the preprocessing steps. Moreover, we established that the standard deviation of the data series can be used as an appropriate, adaptive and generalized threshold level for the level intersection-based metrics. On the basis of these results, our work also serves as a general guide on how to proceed if one wants to determine activity from the raw acceleration data.      
### 15.Early Detection of Retinopathy of Prematurity stage using Deep Learning approach  [ :arrow_down: ](https://arxiv.org/pdf/2109.01442.pdf)
>  Retinopathy of Prematurity (ROP) is a fibrovascular proliferative disorder, which affects the developing peripheral retinal vasculature of premature infants. Early detection of ROP is possible in stage 1 and stage 2 characterized by demarcation line and ridge with width, which separates vascularised retina and the peripheral retina. To detect demarcation line/ ridge from neonatal retinal images is a complex task because of low contrast images. In this paper we focus on detection of ridge, the important landmark in ROP diagnosis, using Convolutional Neural Network(CNN). Our contribution is to use a CNN-based model Mask R-CNN for demarcation line/ridge detection allowing clinicians to detect ROP stage 2 better. The proposed system applies a pre-processing step of image enhancement to overcome poor image quality. In this study we use labelled neonatal images and we explore the use of CNN to localize ridge in these images. We used a dataset of 220 images of 45 babies from the KIDROP project. The system was trained on 175 retinal images with ground truth segmentation of ridge region. The system was tested on 45 images and reached detection accuracy of 0.88, showing that deep learning detection with pre-processing by image normalization allows robust detection of ROP in early stages.      
### 16.Style Transfer based Coronary Artery Segmentation in X-ray Angiogram  [ :arrow_down: ](https://arxiv.org/pdf/2109.01441.pdf)
>  X-ray coronary angiography (XCA) is a principal approach employed for identifying coronary disorders. Deep learning-based networks have recently shown tremendous promise in the diagnosis of coronary disorder from XCA scans. A deep learning-based edge adaptive instance normalization style transfer technique for segmenting the coronary arteries, is presented in this paper. The proposed technique combines adaptive instance normalization style transfer with the dense extreme inception network and convolution block attention module to get the best artery segmentation performance. We tested the proposed method on two publicly available XCA datasets, and achieved a segmentation accuracy of 0.9658 and Dice coefficient of 0.71. We believe that the proposed method shows that the prediction can be completed in the fastest time with training on the natural images, and can be reliably used to diagnose and detect coronary disorders.      
### 17.Automatic Foot Ulcer segmentation Using an Ensemble of Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.01408.pdf)
>  Foot ulcer is a common complication of diabetes mellitus; it is associated with substantial morbidity and mortality and remains a major risk factor for lower leg amputation. Extracting accurate morphological features from the foot wounds is crucial for proper treatment. Although visual and manual inspection by medical professionals is the common approach to extract the features, this method is subjective and error-prone. Computer-mediated approaches are the alternative solutions to segment the lesions and extract related morphological features. Among various proposed computer-based approaches for image segmentation, deep learning-based methods and more specifically convolutional neural networks (CNN) have shown excellent performances for various image segmentation tasks including medical image segmentation. In this work, we proposed an ensemble approach based on two encoder-decoder-based CNN models, namely LinkNet and UNet, to perform foot ulcer segmentation. To deal with limited training samples, we used pre-trained weights (EfficientNetB1 for the LinkNet model and EfficientNetB2 for the UNet model) and further pre-training by the Medetec dataset. We also applied a number of morphological-based and colour-based augmentation techniques to train the models. We integrated five-fold cross-validation, test time augmentation and result fusion in our proposed ensemble approach to boost the segmentation performance. Applied on a publicly available foot ulcer segmentation dataset and the MICCAI 2021 Foot Ulcer Segmentation (FUSeg) Challenge, our method achieved state-of-the-art data-based Dice scores of 92.07% and 88.80%, respectively. Our developed method achieved the first rank in the FUSeg challenge leaderboard. The Dockerised guideline, inference codes and saved trained models are publicly available in the published GitHub repository: <a class="link-external link-https" href="https://github.com/masih4/Foot_Ulcer_Segmentation" rel="external noopener nofollow">this https URL</a>      
### 18.Deep Learning Approach for Hyperspectral Image Demosaicking, Spectral Correction and High-resolution RGB Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2109.01403.pdf)
>  Hyperspectral imaging is one of the most promising techniques for intraoperative tissue characterisation. Snapshot mosaic cameras, which can capture hyperspectral data in a single exposure, have the potential to make a real-time hyperspectral imaging system for surgical decision-making possible. However, optimal exploitation of the captured data requires solving an ill-posed demosaicking problem and applying additional spectral corrections to recover spatial and spectral information of the image. In this work, we propose a deep learning-based image demosaicking algorithm for snapshot hyperspectral images using supervised learning methods. Due to the lack of publicly available medical images acquired with snapshot mosaic cameras, a synthetic image generation approach is proposed to simulate snapshot images from existing medical image datasets captured by high-resolution, but slow, hyperspectral imaging devices. Image reconstruction is achieved using convolutional neural networks for hyperspectral image super-resolution, followed by cross-talk and leakage correction using a sensor-specific calibration matrix. The resulting demosaicked images are evaluated both quantitatively and qualitatively, showing clear improvements in image quality compared to a baseline demosaicking method using linear interpolation. Moreover, the fast processing time of~45\,ms of our algorithm to obtain super-resolved RGB or oxygenation saturation maps per image frame for a state-of-the-art snapshot mosaic camera demonstrates the potential for its seamless integration into real-time surgical hyperspectral imaging applications.      
### 19.Optimal output feedback control of a class of linear systems with quasi-colored control-dependent multiplicative noise  [ :arrow_down: ](https://arxiv.org/pdf/2109.01358.pdf)
>  This paper addresses the mean-square optimal control problem for \a class of discrete-time linear systems with a quasi-colored control-dependent multiplicative noise via output feedback. The noise under study is novel and shown to have advantage on modeling a class of network phenomena such as random transmission delays. The optimal output feedback controller is designed using an optimal mean-square state feedback gain and two observer gains, which are determined by the mean-square stabilizing solution to a modified algebraic Riccati equation (MARE), provided that the plant is minimum-phase and left-invertible. A necessary and sufficient condition for the existence of the stabilizing solution to the MARE is explicitly presented. It shows that the separation principle holds in a certain sense for the optimal control design of the work. The result is also applied to the optimal control problems in networked systems with random transmission delays and analog erasure channels, respectively.      
### 20.Ground-Assisted Federated Learning in LEO Satellite Constellations  [ :arrow_down: ](https://arxiv.org/pdf/2109.01348.pdf)
>  In Low Earth Orbit (LEO) mega constellations, there are relevant use cases, such as inference based on satellite imaging, in which a large number of satellites collaboratively train a machine learning model without sharing their local data sets. To address this problem, we propose a new set of algorithms based of Federated learning (FL). Our approach differs substantially from the standard FL algorithms, as it takes into account the predictable connectivity patterns that are immanent to the LEO constellations. Extensive numerical evaluations highlight the fast convergence speed and excellent asymptotic test accuracy of the proposed method. In particular, the achieved test accuracy is within 96% to 99.6% of the centralized solution and the proposed algorithm has less hyperparameters to tune than state-of-the-art asynchronous FL methods.      
### 21.Cooperative Target Capture using Predefined-time Consensus over Fixed and Switching Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.01338.pdf)
>  We propose predefined-time consensus-based cooperative guidance laws for a swarm of interceptors to simultaneously capture a target capable of executing various kinds of motions. Unlike leader-follower cooperative guidance techniques, the swarm of interceptors has no leader and each interceptor executes its own guidance command in a distributive fashion, thus obviating the residency of the mission over a single interceptor. We first design cooperative guidance commands subject to target's mobility, followed by the same when the target is stationary, and also account for interceptors' changing topologies. We further show through rigorous analysis that the proposed cooperative guidance laws guarantee consensus in the interceptors' time-to-go values within a predefined-time. The proposed design allows a feasible time of consensus in time-to-go to be set arbitrarily at will during the design regardless of the interceptors' initial time-to-go values, thereby ensuring a simultaneous target interception. We also demonstrate the efficacy of the proposed design via simulations for interceptors connected over static and dynamic networks.      
### 22.Unsupervised multi-latent space reinforcement learning framework for video summarization in ultrasound imaging  [ :arrow_down: ](https://arxiv.org/pdf/2109.01309.pdf)
>  The COVID-19 pandemic has highlighted the need for a tool to speed up triage in ultrasound scans and provide clinicians with fast access to relevant information. The proposed video-summarization technique is a step in this direction that provides clinicians access to relevant key-frames from a given ultrasound scan (such as lung ultrasound) while reducing resource, storage and bandwidth requirements. We propose a new unsupervised reinforcement learning (RL) framework with novel rewards that facilitates unsupervised learning avoiding tedious and impractical manual labelling for summarizing ultrasound videos to enhance its utility as a triage tool in the emergency department (ED) and for use in telemedicine. Using an attention ensemble of encoders, the high dimensional image is projected into a low dimensional latent space in terms of: a) reduced distance with a normal or abnormal class (classifier encoder), b) following a topology of landmarks (segmentation encoder), and c) the distance or topology agnostic latent representation (convolutional autoencoders). The decoder is implemented using a bi-directional long-short term memory (Bi-LSTM) which utilizes the latent space representation from the encoder. Our new paradigm for video summarization is capable of delivering classification labels and segmentation of key landmarks for each of the summarized keyframes. Validation is performed on lung ultrasound (LUS) dataset, that typically represent potential use cases in telemedicine and ED triage acquired from different medical centers across geographies (India, Spain and Canada).      
### 23.Multi-centred Strong Augmentation via Contrastive Learning for Unsupervised Lesion Detection and Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2109.01303.pdf)
>  The scarcity of high quality medical image annotations hinders the implementation of accurate clinical applications for detecting and segmenting abnormal lesions. To mitigate this issue, the scientific community is working on the development of unsupervised anomaly detection (UAD) systems that learn from a training set containing only normal (i.e., healthy) images, where abnormal samples (i.e., unhealthy) are detected and segmented based on how much they deviate from the learned distribution of normal samples. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations that are sensitive enough to detect and segment abnormal lesions of varying size, appearance and shape. To address this challenge, we propose a novel self-supervised UAD pre-training algorithm, named Multi-centred Strong Augmentation via Contrastive Learning (MSACL). MSACL learns representations by separating several types of strong and weak augmentations of normal image samples, where the weak augmentations represent normal images and strong augmentations denote synthetic abnormal images. To produce such strong augmentations, we introduce MedMix, a novel data augmentation strategy that creates new training images with realistic looking lesions (i.e., anomalies) in normal images. The pre-trained representations from MSACL are generic and can be used to improve the efficacy of different types of off-the-shelf state-of-the-art (SOTA) UAD models. Comprehensive experimental results show that the use of MSACL largely improves these SOTA UAD models on four medical imaging datasets from diverse organs, namely colonoscopy, fundus screening and covid-19 chest-ray datasets.      
### 24.Spectrum Learning-Aided Reconfigurable Intelligent Surfaces for 'Green' 6G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.01287.pdf)
>  In the sixth-generation (6G) era, emerging large-scale computing based applications (for example processing enormous amounts of images in real-time in autonomous driving) tend to lead to excessive energy consumption for the end users, whose devices are usually energy-constrained. In this context, energy-efficiency becomes a critical challenge to be solved for harnessing these promising applications to realize 'green' 6G networks. As a remedy, reconfigurable intelligent surfaces (RIS) have been proposed for improving the energy efficiency by beneficially reconfiguring the wireless propagation environment. In conventional RIS solutions, however, the received signal-to-interference-plus-noise ratio (SINR) sometimes may even become degraded. This is because the signals impinging upon an RIS are typically contaminated by interfering signals which are usually dynamic and unknown. To address this issue, `learning' the properties of the surrounding spectral environment is a promising solution, motivating the convergence of artificial intelligence and spectrum sensing, termed here as spectrum learning (SL). Inspired by this, we develop an SL-aided RIS framework for intelligently exploiting the inherent characteristics of the radio frequency (RF) spectrum for green 6G networks. Given the proposed framework, the RIS controller becomes capable of intelligently `{think-and-decide}' whether to reflect or not the incident signals. Therefore, the received SINR can be improved by dynamically configuring the binary ON-OFF status of the RIS elements. The energy-efficiency benefits attained are validated with the aid of a specific case study. Finally, we conclude with a list of promising future research directions.      
### 25.Non-intrusive load decomposition based on CNN-LSTM hybrid deep learning model  [ :arrow_down: ](https://arxiv.org/pdf/2109.01236.pdf)
>  With the rapid development of science and technology, the problem of energy load monitoring and decomposition of electrical equipment has been receiving widespread attention from academia and industry. For the purpose of improving the performance of non-intrusive load decomposition, a non-intrusive load decomposition method based on a hybrid deep learning model is proposed. In this method, first of all, the data set is normalized and preprocessed. Secondly, a hybrid deep learning model integrating convolutional neural network (CNN) with long short-term memory network (LSTM) is constructed to fully excavate the spatial and temporal characteristics of load data. Finally, different evaluation indicators are used to analyze the mixture. The model is fully evaluated, and contrasted with the traditional single deep learning model. Experimental results on the open dataset UK-DALE show that the proposed algorithm improves the performance of the whole network system. In this paper, the proposed decomposition method is compared with the existing traditional deep learning load decomposition method. At the same time, compared with the obtained methods: spectral decomposition, EMS, LSTM-RNN, and other algorithms, the accuracy of load decomposition is significantly improved, and the test accuracy reaches 98%.      
### 26.Resilience to Denial-of-Service and Integrity Attacks: A Structured Systems Approach  [ :arrow_down: ](https://arxiv.org/pdf/2109.01224.pdf)
>  The resilience of cyberphysical systems to denial-of-service (DoS) and integrity attacks is studied in this paper. The cyberphysical system is modeled as a linear structured system, and its resilience to an attack is interpreted in a graph theoretical framework. The structural resilience of the system is characterized in terms of unmatched vertices in maximum matchings of the bipartite graph and connected components of directed graph representations of the system under attack. We first present conditions for the system to be resilient to DoS attacks when an adversary may block access or turn off certain inputs to the system. We extend this analysis to characterize resilience of the system when an adversary might additionally have the ability to affect the implementation of state-feedback control strategies. This is termed an integrity attack. We establish conditions under which a system that is structurally resilient to a DoS attack will also be resilient to a certain class of integrity attacks. Finally, we formulate an extension to the case of switched linear systems, and derive conditions for such systems to be structurally resilient to a DoS attack.      
### 27.Scalable Data Annotation Pipeline for High-Quality Large Speech Datasets Development  [ :arrow_down: ](https://arxiv.org/pdf/2109.01164.pdf)
>  This paper introduces a human-in-the-loop (HITL) data annotation pipeline to generate high-quality, large-scale speech datasets. The pipeline combines human and machine advantages to more quickly, accurately, and cost-effectively annotate datasets with machine pre-labeling and fully manual auditing. Quality control mechanisms such as blind testing, behavior monitoring, and data validation have been adopted in the annotation pipeline to mitigate potential bias introduced by machine-generated labels. Our A/B testing and pilot results demonstrated the HITL pipeline can improve annotation speed and capacity by at least 80% and quality is comparable to or higher than manual double pass annotation. We are leveraging this scalable pipeline to create and continuously grow ultra-high volume off-the-shelf (UHV-OTS) speech corpora for multiple languages, with the capability to expand to 10,000+ hours per language annually. Customized datasets can be produced from the UHV-OTS corpora using dynamic packaging. UHV-OTS is a long-term Appen project to support commercial and academic research data needs in speech processing. Appen will donate a number of free speech datasets from the UHV-OTS each year to support academic and open source community research under the CC-BY-SA license. We are also releasing the code of the data pre-processing and pre-tagging pipeline under the Apache 2.0 license to allow reproduction of the results reported in the paper.      
### 28.Efficient conformer: Progressive downsampling and grouped attention for automatic speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2109.01163.pdf)
>  The recently proposed Conformer architecture has shown state-of-the-art performances in Automatic Speech Recognition by combining convolution with attention to model both local and global dependencies. In this paper, we study how to reduce the Conformer architecture complexity with a limited computing budget, leading to a more efficient architecture design that we call Efficient Conformer. We introduce progressive downsampling to the Conformer encoder and propose a novel attention mechanism named grouped attention, allowing us to reduce attention complexity from $O(n^{2}d)$ to $O(n^{2}d / g)$ for sequence length $n$, hidden dimension $d$ and group size parameter $g$. We also experiment the use of strided multi-head self-attention as a global downsampling operation. Our experiments are performed on the LibriSpeech dataset with CTC and RNN-Transducer losses. We show that within the same computing budget, the proposed architecture achieves better performances with faster training and decoding compared to the Conformer. Our 13M parameters CTC model achieves competitive WERs of 3.6%/9.0% without using a language model and 2.7%/6.7% with an external n-gram language model on the test-clean/test-other sets while being 29% faster than our CTC Conformer baseline at inference and 36% faster to train.      
### 29.Instabilities in Plug-and-Play (PnP) algorithms from a learned denoiser  [ :arrow_down: ](https://arxiv.org/pdf/2109.01655.pdf)
>  It's well-known that inverse problems are ill-posed and to solve them meaningfully, one has to employ regularization methods. Traditionally, popular regularization methods are the penalized Variational approaches. In recent years, the classical regularization approaches have been outclassed by the so-called plug-and-play (PnP) algorithms, which copy the proximal gradient minimization processes, such as ADMM or FISTA, but with any general denoiser. However, unlike the traditional proximal gradient methods, the theoretical underpinnings, convergence, and stability results have been insufficient for these PnP-algorithms. Hence, the results obtained from these algorithms, though empirically outstanding, can't always be completely trusted, as they may contain certain instabilities or (hallucinated) features arising from the denoiser, especially when using a pre-trained learned denoiser. In fact, in this paper, we show that a PnP-algorithm can induce hallucinated features, when using a pre-trained deep-learning-based (DnCNN) denoiser. We show that such instabilities are quite different than the instabilities inherent to an ill-posed problem. We also present methods to subdue these instabilities and significantly improve the recoveries. We compare the advantages and disadvantages of a learned denoiser over a classical denoiser (here, BM3D), as well as, the effectiveness of the FISTA-PnP algorithm vs. the ADMM-PnP algorithm. In addition, we also provide an algorithm to combine these two denoisers, the learned and the classical, in a weighted fashion to produce even better results. We conclude with numerical results which validate the developed theories.      
### 30.Multi-agent Natural Actor-critic Reinforcement Learning Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2109.01654.pdf)
>  Both single-agent and multi-agent actor-critic algorithms are an important class of Reinforcement Learning algorithms. In this work, we propose three fully decentralized multi-agent natural actor-critic (MAN) algorithms. The agents' objective is to collectively learn a joint policy that maximizes the sum of averaged long-term returns of these agents. In the absence of a central controller, agents communicate the information to their neighbors via a time-varying communication network while preserving privacy. We prove the convergence of all the 3 MAN algorithms to a globally asymptotically stable point of the ODE corresponding to the actor update; these use linear function approximations. We use the Fisher information matrix to obtain the natural gradients. The Fisher information matrix captures the curvature of the Kullback-Leibler (KL) divergence between polices at successive iterates. We also show that the gradient of this KL divergence between policies of successive iterates is proportional to the objective function's gradient. Our MAN algorithms indeed use this \emph{representation} of the objective function's gradient. Under certain conditions on the Fisher information matrix, we prove that at each iterate, the optimal value via MAN algorithms can be better than that of the multi-agent actor-critic (MAAC) algorithm using the standard gradients. To validate the usefulness of our proposed algorithms, we implement all the 3 MAN algorithms on a bi-lane traffic network to reduce the average network congestion. We observe an almost 25% reduction in the average congestion in 2 MAN algorithms; the average congestion in another MAN algorithm is on par with the MAAC algorithm. We also consider a generic 15 agent MARL; the performance of the MAN algorithms is again as good as the MAAC algorithm. We attribute the better performance of the MAN algorithms to their use of the above representation.      
### 31.Optimizing the Energy Efficiency of Unreliable Memories for Quantized Kalman Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2109.01520.pdf)
>  This paper presents a quantized Kalman filter implemented using unreliable memories. We consider that both the quantization and the unreliable memories introduce errors in the computations, and develop an error propagation model that takes into account these two sources of errors. In addition to providing updated Kalman filter equations, the proposed error model accurately predicts the covariance of the estimation error and gives a relation between the performance of the filter and its energy consumption, depending on the noise level in the memories. Then, since memories are responsible for a large part of the energy consumption of embedded systems, optimization methods are introduced so as to minimize the memory energy consumption under a desired estimation performance of the filter. The first method computes the optimal energy levels allocated to each memory bank individually, and the second one optimizes the energy allocation per groups of memory banks. Simulations show a close match between the theoretical analysis and experimental results. Furthermore, they demonstrate an important reduction in energy consumption of more than 50%.      
### 32.The full Low-carbon Expansion Generation Optimization (LEGO) model  [ :arrow_down: ](https://arxiv.org/pdf/2109.01368.pdf)
>  This paper introduces the full Low-carbon Expansion Generation Optimization (LEGO) model available on Github (<a class="link-external link-https" href="https://github.com/wogrin/LEGO" rel="external noopener nofollow">this https URL</a>). LEGO is a mixed-integer quadratically constrained optimization problem and has been designed to be a multi-purpose tool, like a Swiss army knife, that can be employed to study many different aspects of the energy sector. Ranging from short-term unit commitment to long-term generation and transmission expansion planning. The underlying modeling philosophies are: modularity and flexibility. Its unique temporal structure allows LEGO to function with either chronological hourly data, or all kinds of representative periods. LEGO is also composed of thematic modules that can be added or removed from the model easily via data options depending on the scope of the study. Those modules include: unit commitment constraints; DC- or AC-OPF formulations; battery degradation; rate of change of frequency inertia constraints; demand-side management; or the hydrogen sector. LEGO also provides a plethora of model outputs (both primal and dual), which is the basis for both technical but also economic analyses. To our knowledge, there is no model that combines all of these capabilities, which we hereby make freely available to the scientific community.      
### 33.Low-Latency and Secure Computation Offloading Assisted by Hybrid Relay-Reflecting Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2109.01335.pdf)
>  Recently, the hybrid relay-reflecting intelligent surface (HRRIS) has been introduced as a spectral- and energy-efficient architecture to assist wireless communication systems. In the HRRIS, a single or few active relay elements are deployed along with a large number of passive reflecting elements, allowing it to not only reflect but also amplify the incident signals. In this work, we investigate the potential of the HRRIS in aiding the computation offloading in a single-user mobile edge computing system. The objective is to minimize the offloading latency while ensuring the secrecy of user data against a malicious eavesdropper. We develop efficient solutions to this latency minimization problem based on alternating optimization. Through numerical results, we show that the deployment of the HRRIS can result in a considerable reduction in latency. Furthermore, the latency reduction gain offered by the HRRIS is much more significant than that of the conventional reconfigurable intelligent surface (RIS).      
### 34.Estimating Demand Flexibility Using Siamese LSTM Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.01258.pdf)
>  There is an opportunity in modern power systems to explore the demand flexibility by incentivizing consumers with dynamic prices. In this paper, we quantify demand flexibility using an efficient tool called time-varying elasticity, whose value may change depending on the prices and decision dynamics. This tool is particularly useful for evaluating the demand response potential and system reliability. Recent empirical evidences have highlighted some abnormal features when studying demand flexibility, such as delayed responses and vanishing elasticities after price spikes. Existing methods fail to capture these complicated features because they heavily rely on some predefined (often over-simplified) regression expressions. Instead, this paper proposes a model-free methodology to automatically and accurately derive the optimal estimation pattern. We further develop a two-stage estimation process with Siamese long short-term memory (LSTM) networks. Here, a LSTM network encodes the price response, while the other network estimates the time-varying elasticities. In the case study, the proposed framework and models are validated to achieve higher overall estimation accuracy and better description for various abnormal features when compared with the state-of-the-art methods.      
### 35.Provably Safe Model-Based Meta Reinforcement Learning: An Abstraction-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2109.01255.pdf)
>  While conventional reinforcement learning focuses on designing agents that can perform one task, meta-learning aims, instead, to solve the problem of designing agents that can generalize to different tasks (e.g., environments, obstacles, and goals) that were not considered during the design or the training of these agents. In this spirit, in this paper, we consider the problem of training a provably safe Neural Network (NN) controller for uncertain nonlinear dynamical systems that can generalize to new tasks that were not present in the training data while preserving strong safety guarantees. Our approach is to learn a set of NN controllers during the training phase. When the task becomes available at runtime, our framework will carefully select a subset of these NN controllers and compose them to form the final NN controller. Critical to our approach is the ability to compute a finite-state abstraction of the nonlinear dynamical system. This abstract model captures the behavior of the closed-loop system under all possible NN weights, and is used to train the NNs and compose them when the task becomes available. We provide theoretical guarantees that govern the correctness of the resulting NN. We evaluated our approach on the problem of controlling a wheeled robot in cluttered environments that were not present in the training data.      
### 36.A Max-Min Task Offloading Algorithm for Mobile Edge Computing Using Non-Orthogonal Multiple Access  [ :arrow_down: ](https://arxiv.org/pdf/2109.01239.pdf)
>  To mitigate computational power gap between the network core and edges, mobile edge computing (MEC) is poised to play a fundamental role in future generations of wireless networks. In this letter, we consider a non-orthogonal multiple access (NOMA) transmission model to maximize the worst task to be offloaded among all users to the network edge server. A provably convergent and efficient algorithm is developed to solve the considered non-convex optimization problem for maximizing the minimum number of offloaded bits in a multi-user NOMAMEC system. Compared to the approach of optimized orthogonal multiple access (OMA), for given MEC delay, power and energy limits, the NOMA-based system considerably outperforms its OMA-based counterpart in MEC settings. Numerical results demonstrate that the proposed algorithm for NOMA-based MEC is particularly useful for delay sensitive applications.      
### 37.DeepTracks: Geopositioning Maritime Vehicles in Video Acquired from a Moving Platform  [ :arrow_down: ](https://arxiv.org/pdf/2109.01235.pdf)
>  Geopositioning and tracking a moving boat at sea is a very challenging problem, requiring boat detection, matching and estimating its GPS location from imagery with no common features. The problem can be stated as follows: given imagery from a camera mounted on a moving platform with known GPS location as the only valid sensor, we predict the geoposition of a target boat visible in images. Our solution uses recent ML algorithms, the camera-scene geometry and Bayesian filtering. The proposed pipeline first detects and tracks the target boat's location in the image with the strategy of tracking by detection. This image location is then converted to geoposition to the local sea coordinates referenced to the camera GPS location using plane projective geometry. Finally, target boat local coordinates are transformed to global GPS coordinates to estimate the geoposition. To achieve a smooth geotrajectory, we apply unscented Kalman filter (UKF) which implicitly overcomes small detection errors in the early stages of the pipeline. We tested the performance of our approach using GPS ground truth and show the accuracy and speed of the estimated geopositions. Our code is publicly available at <a class="link-external link-https" href="https://github.com/JianliWei1995/AI-Track-at-Sea" rel="external noopener nofollow">this https URL</a>.      
### 38.Online Distributed Optimization in Radial Power Distribution Systems: Closed-Form Expressions  [ :arrow_down: ](https://arxiv.org/pdf/2109.01208.pdf)
>  The limitations of centralized optimization methods in managing power distribution systems operations motivate distributed control and optimization algorithms. However, the existing distributed optimization algorithms are inefficient in managing fast varying phenomena, resulting from highly variable distributed energy resources (DERs). Related online distributed control methods are equally limited in their applications. They require thousands of time-steps to track the network-level optimal solutions, resulting in slow performance. We have previously developed an online distributed controller that leverages the system's radial topology to achieve network-level optimal solutions within a few time steps. However, it requires solving a node-level nonlinear programming problem at each time step. This paper analyzes the solution space for the node-level optimization problem and derives the analytical closed-form solutions for the decision variables. The theoretical analysis of the node-level optimization problem and obtained closed-form optimal solutions eliminate the need for embedded optimization solvers at each distributed agent and significantly reduce the computational time and optimization costs.      
### 39.Remote Multilinear Compressive Learning with Adaptive Compression  [ :arrow_down: ](https://arxiv.org/pdf/2109.01184.pdf)
>  Multilinear Compressive Learning (MCL) is an efficient signal acquisition and learning paradigm for multidimensional signals. The level of signal compression affects the detection or classification performance of a MCL model, with higher compression rates often associated with lower inference accuracy. However, higher compression rates are more amenable to a wider range of applications, especially those that require low operating bandwidth and minimal energy consumption such as Internet-of-Things (IoT) applications. Many communication protocols provide support for adaptive data transmission to maximize the throughput and minimize energy consumption. By developing compressive sensing and learning models that can operate with an adaptive compression rate, we can maximize the informational content throughput of the whole application. In this paper, we propose a novel optimization scheme that enables such a feature for MCL models. Our proposal enables practical implementation of adaptive compressive signal acquisition and inference systems. Experimental results demonstrated that the proposed approach can significantly reduce the amount of computations required during the training phase of remote learning systems but also improve the informational content throughput via adaptive-rate sensing.      
