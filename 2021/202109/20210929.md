# ArXiv eess --Wed, 29 Sep 2021
### 1.Establishment and placement of a Multi-purpose Phasor measurement unit to improve parallel state estimation in distribution Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.13873.pdf)
>  Today, microgrids in distribution networks are in dire need of improvement to cope with economic challenges, human losses, and equipment placement issues. Today, there is the issue of scattered resources in distribution systems, which has created many problems in the areas of environment, economy, and human and animal losses. The most important challenge in this section is the existence of voltage and frequency fluctuations during the occurrence of possible events such as severe load changes or errors in distribution networks. Having such a big problem can call a distribution network into question and destroy it. Therefore, it is necessary to provide an optimal method that can meet and cover these challenges. For this purpose, the present research deals with the problem of establishing and placing a multifunctional phasor measurement unit to improve the parallel state estimation in distribution networks, which offers a control approach. This approach determines the time of occurrence of internal and external disturbances after using the phasor unit. The approach of this research is to use a neural-fuzzy method because there is uncertainty in the distribution network due to the mentioned challenges, and training in the system is needed to accurately deploy and place possible errors. Do not occur. When setting up and placing the phasor measuring unit, the most important issue is the proper distribution of the load in the distribution network. The simulation results in the MATLAB / Simulink environment show the improvement of the results according to the proposed approach. Keywords: Distribution Network, Neural-Fuzzy Network, Optimal Load Distribution, Parallel State Estimation, Phasor Measurement Unit.      
### 2.Index Modulation with Circularly-Shifted Chirps for Dual-Function Radar and Communications  [ :arrow_down: ](https://arxiv.org/pdf/2109.13865.pdf)
>  In this study, we propose index modulation (IM) with circularly-shifted chirps (CSCs) (CSC-IM) for dual-function radar and communication (DFRC) systems. The proposed scheme encodes the information bits with the CSC indices and the phase-shift keying (PSK) symbols. It allows the receiver to exploit the frequency selectivity naturally in fading channels by combining IM and wideband CSCs. It also leverages the fact that a CSC is a constant-envelope signal to achieve a controllable peak-to-mean envelope power ratio (PMEPR). For radar functionality, CSC-IM maintains the good autocorrelation (AC) properties of a chirp by ensuring that the transmitted CSCs are separated apart sufficiently in the time domain through index separation (IS). We investigate the impact of IS on spectral efficiency (SE) and obtain the corresponding mapping functions. For theoretical results, we derive the union bound (UB) of the block error rate (BLER) for arbitrary chirps and the Cramer-Rao lower bounds (CRLBs) for the range and reflection coefficients for the matched filter (MF)-based estimation. We also prove that complementary sequences (CSs) can be constructed through CSCs by linearly combining the Fourier series of CSCs. Finally, through comprehensive comparisons, we demonstrate the efficacy of the proposed scheme for DFRC scenarios.      
### 3.3N-GAN: Semi-Supervised Classification of X-Ray Images with a 3-Player Adversarial Framework  [ :arrow_down: ](https://arxiv.org/pdf/2109.13862.pdf)
>  The success of deep learning for medical imaging tasks, such as classification, is heavily reliant on the availability of large-scale datasets. However, acquiring datasets with large quantities of labeled data is challenging, as labeling is expensive and time-consuming. Semi-supervised learning (SSL) is a growing alternative to fully-supervised learning, but requires unlabeled samples for training. In medical imaging, many datasets lack unlabeled data entirely, so SSL can't be conventionally utilized. We propose 3N-GAN, or 3 Network Generative Adversarial Networks, to perform semi-supervised classification of medical images in fully-supervised settings. We incorporate a classifier into the adversarial relationship such that the generator trains adversarially against both the classifier and discriminator. Our preliminary results show improved classification performance and GAN generations over various algorithms. Our work can seamlessly integrate with numerous other medical imaging model architectures and SSL methods for greater performance.      
### 4.Optimal Sensor Gain Control for Minimum-Information Estimation of Continuous-Time Gauss-Markov Processes  [ :arrow_down: ](https://arxiv.org/pdf/2109.13854.pdf)
>  We consider the scenario in which a continuous-time Gauss-Markov process is estimated by the Kalman-Bucy filter over a Gaussian channel (sensor) with a variable sensor gain. The problem of scheduling the sensor gain over a finite time interval to minimize the weighted sum of the data rate (the mutual information between the sensor output and the underlying Gauss-Markov process) and the distortion (the mean-square estimation error) is formulated as an optimal control problem. A necessary optimality condition for a scheduled sensor gain is derived based on Pontryagin's minimum principle. For a scalar problem, we show that an optimal sensor gain control is of bang-bang type, except the possibility of taking an intermediate value when there exists a stationary point on the switching surface in the phase space of canonical dynamics. Furthermore, we show that the number of switches is at most two and the time instants at which the optimal gain must be switched can be computed from the analytical solutions to the canonical equations.      
### 5.Neural networks based post-equalization in coherent optical systems: regression versus classification  [ :arrow_down: ](https://arxiv.org/pdf/2109.13843.pdf)
>  In this paper, we address the question of which type of predictive modeling, classification, or regression, fits better the task of equalization using neural networks (NN) based post-processing in coherent optical communication, where the transmission channel is nonlinear and dispersive. For the first time, we presented some possible drawbacks in using each type of predictive task in a machine learning context for the nonlinear channel equalization problem. We studied two types of equalizers based on the feed-forward and recurrent neural networks over several different transmission scenarios, in linear and nonlinear regimes of the optical channel. We observed in all those cases that the training based on regression results in faster convergence and finally a superior performance, in terms of Q-factor and achievable information rate.      
### 6.Cross-layer Design for Real-Time Grid Operation: Estimation, Optimization and Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2109.13842.pdf)
>  In this paper we propose a combined Online Feedback Optimization (OFO) and dynamic estimation approach for a real-time power grid operation under time-varying conditions. A dynamic estimation uses grid measurements to generate the information required by an OFO controller, that incrementally steers the controllable power injections set-points towards the solutions of a time-varying AC Optimal Power Flow (AC-OPF). More concretely, we propose a quadratic-programming-based OFO that guarantees satisfying the grid operational constraints, like admissible voltage limits. \r{Within the estimation, we design} an online power flow solver that efficiently computes power flow approximations in real time. Finally, we certify the stability and convergence of this combined approach under time-varying conditions, and we validate its effectiveness on a simulation with a test feeder and high resolution consumption data.      
### 7.Convex Optimization of Speed and Energy Management System for Fuel Cell Hybrid Trains  [ :arrow_down: ](https://arxiv.org/pdf/2109.13833.pdf)
>  We look into minimizing the hydrogen fuel consumption of hydrogen hybrid trains by optimizing their operation. The powertrain considered is a fuel cell charge-sustaining hybrid. Convex optimization is utilized to compute optimal speed and energy management trajectories. The barrier method is used to solve the optimization problems quickly on the order of tens of seconds for the entire journey. Simulations show a considerable reduction in fuel consumption when both trajectories -- speed and energy management -- are optimized concurrently within a single optimization problem in comparison to being optimized separately in a sequential manner -- optimizing energy management after optimizing speed. It is concluded that the concurrent method greatly benefits from its holistic powertrain knowledge while optimizing all trajectories together within a single optimization problem.      
### 8.Compositional Construction of Abstractions for Infinite Networks of Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.13832.pdf)
>  We construct compositional continuous approximations for an interconnection of infinitely many discrete-time switched systems. An approximation (known as abstraction) is itself a continuous-space system, which can be used as a replacement of the original (known as concrete) system in a controller design process. Having synthesized a controller for the abstract system, the controller is refined to a more detailed controller for the concrete system. To quantify the mismatch between the output trajectory of the approximation and of that the original system, we use the notion of so-called simulation functions. In particular, each subsystem in the concrete network and its corresponding one in the abstract network is related through a local simulation function. We show that if the local simulation functions satisfy a certain small-gain type condition developed for a network of infinitely many subsystems, then the aggregation of the individual simulation functions provides an overall simulation function between the overall abstraction and the concrete network. For a network of linear switched systems, we systematically construct local abstractions and local simulation functions, where the required conditions are expressed in terms of linear matrix inequalities and can be efficiently computed. We illustrate the effectiveness of our approach through an application to frequency control in a power gird with a switched (i.e. time-varying) topology.      
### 9.EEG Signal Processing using Wavelets for Accurate Seizure Detection through Cost Sensitive Data Mining  [ :arrow_down: ](https://arxiv.org/pdf/2109.13818.pdf)
>  Epilepsy is one of the most common and yet diverse set of chronic neurological disorders. This excessive or synchronous neuronal activity is termed seizure. Electroencephalogram signal processing plays a significant role in detection and prediction of epileptic seizures. In this paper we introduce an approach that relies upon the properties of wavelets for seizure detection. We utilise the Maximum Overlap Discrete Wavelet Transform which enables us to reduce signal noise Then from the variance exhibited in wavelet coefficients we develop connectivity and communication efficiency between the electrodes as these properties differ significantly during a seizure period in comparison to a non-seizure period. We use basic statistical parameters derived from the reconstructed noise reduced signal, electrode connectivity and the efficiency of information transfer to build the attribute space. <br>We have utilised data that are publicly available to test our method that is found to be significantly better than some existing approaches.      
### 10.Articulatory Coordination for Speech Motor Tracking in Huntington Disease  [ :arrow_down: ](https://arxiv.org/pdf/2109.13815.pdf)
>  Huntington Disease (HD) is a progressive disorder which often manifests in motor impairment. Motor severity (captured via motor score) is a key component in assessing overall HD severity. However, motor score evaluation involves in-clinic visits with a trained medical professional, which are expensive and not always accessible. Speech analysis provides an attractive avenue for tracking HD severity because speech is easy to collect remotely and provides insight into motor changes. HD speech is typically characterized as having irregular articulation. With this in mind, acoustic features that can capture vocal tract movement and articulatory coordination are particularly promising for characterizing motor symptom progression in HD. In this paper, we present an experiment that uses Vocal Tract Coordination (VTC) features extracted from read speech to estimate a motor score. When using an elastic-net regression model, we find that VTC features significantly outperform other acoustic features across varied-length audio segments, which highlights the effectiveness of these features for both short- and long-form reading tasks. Lastly, we analyze the F-value scores of VTC features to visualize which channels are most related to motor score. This work enables future research efforts to consider VTC features for acoustic analyses which target HD motor symptomatology tracking.      
### 11.An Efficient Epileptic Seizure Detection Technique using Discrete Wavelet Transform and Machine Learning Classifiers  [ :arrow_down: ](https://arxiv.org/pdf/2109.13811.pdf)
>  This paper presents an epilepsy detection method based on discrete wavelet transform (DWT) and Machine learning classifiers. Here DWT has been used for feature extraction as it provides a better decomposition of the signals in different frequency bands. At first, DWT has been applied to the EEG signal to extract the detail and approximate coefficients or different sub-bands. After the extraction of the coefficients, principal component analysis (PCA) has been applied on different sub-bands and then a feature level fusion technique is used to extract the important features in low dimensional feature space. Three classifiers namely: Support Vector Machine (SVM) classifier, K-Nearest-Neighbor (KNN) classifier, and Naive Bayes (NB) Classifiers have been used in the proposed work for classifying the EEG signals. The proposed method is tested on Bonn databases and provides a maximum of 100% recognition accuracy for KNN, SVM, NB classifiers.      
### 12.Cluster Synchronization of Networks via a Canonical Transformation for Simultaneous Block Diagonalization of Matrices  [ :arrow_down: ](https://arxiv.org/pdf/2109.13792.pdf)
>  We study cluster synchronization of networks and propose a canonical transformation for simultaneous block diagonalization of matrices that we use to analyze stability of the cluster synchronous solution. Our approach has several advantages as it allows us to: (1) decouple the stability problem into subproblems of minimal dimensionality while preserving physically meaningful information; (2) study stability of both orbital and equitable partitions of the network nodes and (3) obtain a parametrization of the problem in a small number of parameters. For the last point, we show how the canonical transformation decouples the problem into blocks that preserve key physical properties of the original system. We also apply our proposed algorithm to analyze several real networks of interest, and we find that it runs faster than alternative algorithms from the literature.      
### 13.MSR-NV: Neural vocoder using multiple sampling rates  [ :arrow_down: ](https://arxiv.org/pdf/2109.13714.pdf)
>  The development of neural vocoders (NVs) has resulted in the high-quality and fast generation of waveforms. However, conventional NVs target a single sampling rate and require re-training when applied to different sampling rates. A suitable sampling rate varies from application to application due to the trade-off between speech quality and generation speed. In this study, we propose a method to handle multiple sampling rates in a single NV, called the MSR-NV. By generating waveforms step-by-step starting from a low sampling rate, MSR-NV can efficiently learn the characteristics of each frequency band and synthesize high-quality speech at multiple sampling rates. It can be regarded as an extension of the previously proposed NVs, and in this study, we extend the structure of Parallel WaveGAN (PWG). Experimental evaluation results demonstrate that the proposed method achieves remarkably higher subjective quality than the original PWG trained separately at 16, 24, and 48 kHz, without increasing the inference time. We also show that MSR-NV can leverage speech with lower sampling rates to further improve the quality of the synthetic speech.      
### 14.THz Band Channel Measurements and Statistical Modeling for Urban D2D Environments  [ :arrow_down: ](https://arxiv.org/pdf/2109.13693.pdf)
>  THz band is envisioned to be used in 6G systems to meet the ever-increasing demand for data rate. However, before an eventual system design and deployment can proceed, detailed channel sounding measurements are required to understand key channel characteristics. In this paper, we present a first extensive set of channel measurements for urban outdoor environments that are ultra-wideband (1 GHz 3dB bandwidth), and double-directional where both the transmitter and receiver are at the same height. In all, we present measurements at 38 Tx/Rx location pairs, consisting of a total of nearly 50,000 impulse responses, at both line-of-sight (LoS) and non-line-of-sight (NLoS) cases in the 1-100 m range. We provide modeling for path loss, shadowing, delay spread, angular spread and multipath component (MPC) power distribution. We find, among other things, that outdoor communication over tens of meters is feasible in this frequency range even in NLoS scenarios, that omni-directional delay spreads of up to 100 ns, and directional delay spreads of up to 10 ns are observed, while angular spreads are also quite significant, and a surprisingly large number of MPCs are observed for 1 GHz bandwidth and 13 degree beamwidth. These results constitute an important first step towards better understanding the wireless channel in the THz band.      
### 15.Mechanical Normal Form of First Order State-Space Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.13687.pdf)
>  In this work a state transformation is presented that transforms a given state-space system to a normal form related to mechanical systems. The underlying state-space system must meet certain requirements such that a transformation exist. If the requirements are satisfied one obtains second order differential equations which allow the application of customized and specialized algorithms.      
### 16.On the Topological Aspects of UAV-Assisted Post-Disaster Wireless Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.13671.pdf)
>  In the context of sixth-generation (6G) networks, emergency management systems (EMSs) based on wireless communications have recently gained increasing interest. Hereby, fundamentals and open problems of post-disaster communications are discussed, especially focusing on their topological aspects. The motivation behind this choice is due to the fact that, whenever a natural or a man-made disaster occurs, there is a high chance that the terrestrial communication infrastructure is compromised, and therefore alternative networks need to be deployed efficiently in order to enable the majority of the civilians and the first responders (FRs) to communicate. In this paper, we first provide a brief review of existing aerial ad-hoc networks for post-disaster communications. Next, we shed light on some new aspects of this problem, which are related to the topology of the network supporting the impacted area. Finally, with the aid of selected simulation results, we show how the cellular infrastructure requirements for a disaster-struck region significantly depend on its location and its extension.      
### 17.DeepPSL: End-to-end perception and reasoning with applications to zero shot learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.13662.pdf)
>  We introduce DeepPSL a variant of Probabilistic Soft Logic (PSL) to produce an end-to-end trainable system that integrates reasoning and perception. PSL represents first-order logic in terms of a convex graphical model -- Hinge Loss Markov random fields (HL-MRFs). PSL stands out among probabilistic logic frameworks due to its tractability having been applied to systems of more than 1 billion ground rules. The key to our approach is to represent predicates in first-order logic using deep neural networks and then to approximately back-propagate through the HL-MRF and thus train every aspect of the first-order system being represented. We believe that this approach represents an interesting direction for the integration of deep learning and reasoning techniques with applications to knowledge base learning, multi-task learning, and explainability. We evaluate DeepPSL on a zero shot learning problem in image classification. State of the art results demonstrate the utility and flexibility of our approach.      
### 18.Hyperparameter selection for the Discrete Mumford-Shah functional  [ :arrow_down: ](https://arxiv.org/pdf/2109.13651.pdf)
>  This work focuses on joint piecewise smooth image reconstruction and contour detection, formulated as the minimization of a discrete Mumford-Shah functional, performed via a theoretically grounded alternating minimization scheme. The bottleneck of such variational approaches lies in the need to finetune their hyperparameters, while not having access to ground truth data. To that aim, a Stein-like strategy providing optimal hyperparameters is designed, based on the minimization of an unbiased estimate of the quadratic risk. Efficient and automated minimization of the estimate of the risk crucially relies on an unbiased estimate of the gradient of the risk with respect to hyperparameters, whose practical implementation is performed thanks to a forward differentiation of the alternating scheme minimizing the Mumford-Shah functional, requiring exact differentiation of the proximity operators involved. Intensive numerical experiments are performed on synthetic images with different geometries and noise levels, assessing the accuracy and the robustness of the proposed procedure. The resulting parameterfree piecewise-smooth reconstruction and contour detection procedure, not requiring prior image processing expertise, is thus amenable to real-world applications.      
### 19.Unsupervised Diffeomorphic Surface Registration and Non-Linear Modelling  [ :arrow_down: ](https://arxiv.org/pdf/2109.13630.pdf)
>  Registration is an essential tool in image analysis. Deep learning based alternatives have recently become popular, achieving competitive performance at a faster speed. However, many contemporary techniques are limited to volumetric representations, despite increased popularity of 3D surface and shape data in medical image analysis. We propose a one-step registration model for 3D surfaces that internalises a lower dimensional probabilistic deformation model (PDM) using conditional variational autoencoders (CVAE). The deformations are constrained to be diffeomorphic using an exponentiation layer. The one-step registration model is benchmarked against iterative techniques, trading in a slightly lower performance in terms of shape fit for a higher compactness. We experiment with two distance metrics, Chamfer distance (CD) and Sinkhorn divergence (SD), as specific distance functions for surface data in real-world registration scenarios. The internalised deformation model is benchmarked against linear principal component analysis (PCA) achieving competitive results and improved generalisability from lower dimensions.      
### 20.Real-Time Glaucoma Detection from Digital Fundus Images using Self-ONNs  [ :arrow_down: ](https://arxiv.org/pdf/2109.13604.pdf)
>  Glaucoma leads to permanent vision disability by damaging the optical nerve that transmits visual images to the brain. The fact that glaucoma does not show any symptoms as it progresses and cannot be stopped at the later stages, makes it critical to be diagnosed in its early stages. Although various deep learning models have been applied for detecting glaucoma from digital fundus images, due to the scarcity of labeled data, their generalization performance was limited along with high computational complexity and special hardware requirements. In this study, compact Self-Organized Operational Neural Networks (Self- ONNs) are proposed for early detection of glaucoma in fundus images and their performance is compared against the conventional (deep) Convolutional Neural Networks (CNNs) over three benchmark datasets: ACRIMA, RIM-ONE, and ESOGU. The experimental results demonstrate that Self-ONNs not only achieve superior detection performance but can also significantly reduce the computational complexity making it a potentially suitable network model for biomedical datasets especially when the data is scarce.      
### 21.Compositional Abstractions of Interconnected Discrete-Time Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.13599.pdf)
>  In this paper, we introduce a compositional method for the construction of finite abstractions of interconnected discrete-time switched systems. Particularly, we use a notion of so-called alternating simulation function as a relation between each switched subsystem and its finite abstraction. Based on some small-gain type conditions, we use those alternating simulation functions to construct compositionally an overall alternating simulation function as a relation between an interconnection of finite abstractions and that of switched subsystems. This overall alternating simulation function allows one to quantify the mismatch between the output behavior of the interconnection of switched subsystems and that of their finite abstractions. Additionally, we provide an approach to construct finite abstractions together with their corresponding alternating simulation functions for discrete-time switched subsystems under standard assumptions ensuring incremental input-to-state stability of a switched subsystem. Finally, we apply our results to a model of road traffic by constructing compositionally a finite abstraction of the network containing $50$ cells of $1000$ meters each. We use the constructed finite abstractions as substitutes to design controllers compositionally keeping the density of traffic lower than $30$ vehicles per cell.      
### 22.Detecting Central Nodes from Low-rank Excited Graph Signals via Structured Factor Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2109.13573.pdf)
>  This paper treats a blind detection problem to identify the central nodes in a graph from filtered graph signals. Unlike prior works which impose strong restrictions on the data model, we only require the underlying graph filter to satisfy a low pass property with a generic low-rank excitation model. We treat two cases depending on the low pass graph filter's strength. When the graph filter is strong low pass, i.e., it has a frequency response that drops sharply at the high frequencies, we show that the principal component analysis (PCA) method detects central nodes with high accuracy. For general low pass graph filter, we show that the graph signals can be described by a structured factor model featuring the product between a low-rank plus sparse factor and an unstructured factor. We propose a two-stage decomposition algorithm to learn the structured factor model via a judicious combination of the non-negative matrix factorization and robust PCA algorithms. We analyze the identifiability conditions for the model which lead to accurate central nodes detection. Numerical experiments on synthetic and real data are provided to support our findings. We demonstrate significant performance gains over prior works.      
### 23.North America Bixby Speaker Diarization System for the VoxCeleb Speaker Recognition Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2109.13518.pdf)
>  This paper describes the submission to the speaker diarization track of VoxCeleb Speaker Recognition Challenge 2021 done by North America Bixby Lab of Samsung Research America. Our speaker diarization system consists of four main components such as overlap speech detection and speech separation, robust speaker embedding extraction, spectral clustering with fused affinity matrix, and leakage filtering-based postprocessing. We evaluated our system on the VoxConverse dataset and the challenge evaluation set, which contain natural conversations of multiple talkers collected from YouTube. Our system obtained 4.46%, 6.39%, and 6.16% of the diarization error rate on the VoxConverse development, test, and the challenge evaluation set, respectively.      
### 24.Metal Artifact Reduction in 2D CT Images with Self-supervised Cross-domain Learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.13483.pdf)
>  The presence of metallic implants often introduces severe metal artifacts in the X-ray CT images, which could adversely influence clinical diagnosis or dose calculation in radiation therapy. In this work, we present a novel deep-learning-based approach for metal artifact reduction (MAR). In order to alleviate the need for anatomically identical CT image pairs (i.e., metal artifact-corrupted CT image and metal artifact-free CT image) for network learning, we propose a self-supervised cross-domain learning framework. Specifically, we train a neural network to restore the metal trace region values in the given metal-free sinogram, where the metal trace is identified by the forward projection of metal masks. We then design a novel FBP reconstruction loss to encourage the network to generate more perfect completion results and a residual-learning-based image refinement module to reduce the secondary artifacts in the reconstructed CT images. To preserve the fine structure details and fidelity of the final MAR image, instead of directly adopting CNN-refined images as output, we incorporate the metal trace replacement into our framework and replace the metal-affected projections of the original sinogram with the prior sinogram generated by the forward projection of the CNN output. We then use the filtered backward projection (FBP) algorithms for final MAR image reconstruction. We conduct an extensive evaluation on simulated and real artifact data to show the effectiveness of our design. Our method produces superior MAR results and outperforms other compelling methods. We also demonstrate the potential of our framework for other organ sites.      
### 25.Transfer Learning based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2109.13479.pdf)
>  The performance of a deep neural network (DNN) for fault diagnosis is very much dependent on the network architecture. Also, the diagnostic performance is reduced if the model trained on a laboratory case machine is used on a test dataset from an industrial machine running under variable operating conditions. Thus there are two challenges for the intelligent fault diagnosis of industrial machines: (i) selection of suitable DNN architecture and (ii) domain adaptation for the change in operating conditions. Therefore, we propose an evolutionary Net2Net transformation (EvoNet2Net) that finds the best suitable DNN architecture for the given dataset. Nondominated sorting genetic algorithm II has been used to optimize the depth and width of the DNN architecture. We have formulated a transfer learning-based fitness evaluation scheme for faster evolution. It uses the concept of domain adaptation for quick learning of the data pattern in the target domain. Also, we have introduced a hybrid crossover technique for optimization of the depth and width of the deep neural network encoded in a chromosome. We have used the Case Western Reserve University dataset and Paderborn university dataset to demonstrate the effectiveness of the proposed framework for the selection of the best suitable architecture capable of excellent diagnostic performance, classification accuracy almost up to 100\%.      
### 26.The JHU submission to VoxSRC-21: Track 3  [ :arrow_down: ](https://arxiv.org/pdf/2109.13425.pdf)
>  This technical report describes Johns Hopkins University speaker recognition system submitted to Voxceleb Speaker Recognition Challenge 2021 Track 3: Self-supervised speaker verification (closed). Our overall training process is similar to the proposed one from the first place team in the last year's VoxSRC2020 challenge. The main difference is a recently proposed non-contrastive self-supervised method in computer vision (CV), distillation with no labels (DINO), is used to train our initial model, which outperformed the last year's contrastive learning based on momentum contrast (MoCo). Also, this requires only a few iterations in the iterative clustering stage, where pseudo labels for supervised embedding learning are updated based on the clusters of the embeddings generated from a model that is continually fine-tuned over iterations. In the final stage, Res2Net50 is trained on the final pseudo labels from the iterative clustering stage. This is our best submitted model to the challenge, showing 1.89, 6.50, and 6.89 in EER(%) in voxceleb1 test o, VoxSRC-21 validation, and test trials, respectively.      
### 27.Safety-Critical Control Synthesis for Unknown Sampled-Data Systems via Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2109.13415.pdf)
>  As the complexity of control systems increases, safety becomes an increasingly important property since safety violations can damage the plant and put the system operator in danger. When the system dynamics are unknown, safety-critical synthesis becomes more challenging. Additionally, modern systems are controlled digitally and hence behave as sampled-data systems, i.e., the system dynamics evolve continuously while the control input is applied at discrete time steps. In this paper, we study the problem of control synthesis for safety-critical sampled-data systems with unknown dynamics. We overcome the challenges introduced by sampled-data implementation and unknown dynamics by constructing a set of control barrier function (CBF)-based constraints. By satisfying the constructed CBF constraint at each sampling time, we guarantee the unknown sampled-data system is safe for all time. We formulate a non-convex program to solve for the control signal at each sampling time. We decompose the non-convex program into two convex sub-problems. We illustrate the proposed approach using a numerical case study.      
### 28.Model-Free Reinforcement Learning for Optimal Control of MarkovDecision Processes Under Signal Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2109.13377.pdf)
>  We present a model-free reinforcement learning algorithm to find an optimal policy for a finite-horizon Markov decision process while guaranteeing a desired lower bound on the probability of satisfying a signal temporal logic (STL) specification. We propose a method to effectively augment the MDP state space to capture the required state history and express the STL objective as a reachability objective. The planning problem can then be formulated as a finite-horizon constrained Markov decision process (CMDP). For a general finite horizon CMDP problem with unknown transition probability, we develop a reinforcement learning scheme that can leverage any model-free RL algorithm to provide an approximately optimal policy out of the general space of non-stationary randomized policies. We illustrate the effectiveness of our approach in the context of robotic motion planning for complex missions under uncertainty and performance objectives.      
### 29.GNSS Radio Occultation on Aerial Platforms with Commercial Off-The-Shelf Receivers  [ :arrow_down: ](https://arxiv.org/pdf/2109.13328.pdf)
>  In recent decades, GNSS Radio Occultation soundings have proven an invaluable input to global weather forecasting. The success of government-sponsored programs such as COSMIC is now complemented by commercial low-cost cubesat implementations. The result is access to more than 10,000 soundings per day and improved weather forecasting accuracy. This movement towards commercialization has been supported by several agencies, including the National Aeronautics and Space Administration (NASA), National Oceanic and Atmospheric Administration (NOAA) and the U.S. Air Force (USAF) with programs such as the Commercial Weather Data Pilot (CWDP). This has resulted in further interest in commercially deploying GNSS-RO on complementary platforms. Here, we examine a so far underutilized platform: the high-altitude weather balloon. Such meteorological radiosondes are deployed twice daily at over 900 locations globally and form an essential in-situ data source as a long-standing input to weather forecasting models. Adding GNSS-RO capability to existing radiosonde platforms would greatly expand capability, allowing for persistent and local area monitoring, a feature particularly useful for hurricane and other severe weather monitoring. A prohibitive barrier to entry to this inclusion is cost and complexity as GNSS-RO traditionally requires highly specialized and sensitive equipment. This paper describes a multi-year effort to develop a low-cost and scalable approach to balloon GNSS-RO based on Commercial-Off-The-Shelf (COTS) GNSS receivers. We present hardware prototypes and data processing techniques which demonstrate the technical feasibility of the approach through results from several flight testing campaigns.      
### 30.LSTM-based approach to detect cyber attacks on market-based congestion management methods  [ :arrow_down: ](https://arxiv.org/pdf/2109.13312.pdf)
>  Market-based congestion management methods adopt Demand Side Management (DSM) techniques to alleviate congestion in the day-ahead market. Reliance of these methods on the communication layer makes it prone to cyber attacks affecting the security, reliability, and economic operation of the distribution network. In this paper, we focus on Load Altering Attacks that would compromise the operation of market-based congestion management methods. A detection technique is proposed using Long Short-term Memory (LSTM) Recurrent Neural Networks (RNN). IEEE 33 bus system is used as a case study to demonstrate the effectiveness of the proposed technique. An accuracy of 97% was obtained proving the capability of using LSTM-RNN to detect a load altering cyber attack compromising aggregators in the network.      
### 31.Nonlinear modeling and feedback control of boom barrier automation  [ :arrow_down: ](https://arxiv.org/pdf/2109.13291.pdf)
>  We address modeling and control of a gate access automation system. A model of the mechatronic system is derived and identified. Then an approximate explicit feedback linearization scheme is proposed, which ensures almost linear response between the external input and the delivered torque. A nonlinear optimization problem is solved offline to generate a feasible trajectory associated with a feedforward action and a low level feedback controller is designed to track it. The feedback gains can be conveniently tuned by solving a set of convex linear matrix inequalities, performing a multi-objective trade-off between disturbances attenuation and closed-loop performance. Finally, the proposed control strategy is tested on the real system and experimental results show that it can effectively meet the requirements in terms of robustness, load disturbance rejection and tracking performance.      
### 32.The Impact of Domain Shift on Left and Right Ventricle Segmentation in Short Axis Cardiac MR Images  [ :arrow_down: ](https://arxiv.org/pdf/2109.13230.pdf)
>  Domain shift refers to the difference in the data distribution of two datasets, normally between the training set and the test set for machine learning algorithms. Domain shift is a serious problem for generalization of machine learning models and it is well-established that a domain shift between the training and test sets may cause a drastic drop in the model's performance. In medical imaging, there can be many sources of domain shift such as different scanners or scan protocols, different pathologies in the patient population, anatomical differences in the patient population (e.g. men vs women) etc. Therefore, in order to train models that have good generalization performance, it is important to be aware of the domain shift problem, its potential causes and to devise ways to address it. In this paper, we study the effect of domain shift on left and right ventricle blood pool segmentation in short axis cardiac MR images. Our dataset contains short axis images from 4 different MR scanners and 3 different pathology groups. The training is performed with nnUNet. The results show that scanner differences cause a greater drop in performance compared to changing the pathology group, and that the impact of domain shift is greater on right ventricle segmentation compared to left ventricle segmentation. Increasing the number of training subjects increased cross-scanner performance more than in-scanner performance at small training set sizes, but this difference in improvement decreased with larger training set sizes. Training models using data from multiple scanners improved cross-domain performance.      
### 33.Stable training of autoencoders for hyperspectral unmixing  [ :arrow_down: ](https://arxiv.org/pdf/2109.13748.pdf)
>  Neural networks, autoencoders in particular, are one of the most promising solutions for unmixing hyperspectral data, i.e. reconstructing the spectra of observed substances (endmembers) and their relative mixing fractions (abundances). Unmixing is needed for effective hyperspectral analysis and classification. However, as we show in this paper, the training of autoencoders for unmixing is highly dependent on weights initialisation. Some sets of weights lead to degenerate or low performance solutions, introducing negative bias in expected performance. In this work we present the results of experiments investigating autoencoders' stability, verifying the dependence of reconstruction error on initial weights and exploring conditions needed for successful optimisation of autoencoder parameters.      
### 34.IRMAC: Interpretable Refined Motifs and Binary Classification for Rooftops PV Owners  [ :arrow_down: ](https://arxiv.org/pdf/2109.13732.pdf)
>  In this paper, we seek to identify residential rooftop solar PV owners using imported energy data. To solve this problem with an interpretable, fast, secure, and maintainable solution, we propose Interpretable Refined Motifs And binary Classification (IRMAC) method, which includes a shape-based dimensionality reduction technique we call Refined Motif (RM), and a classification technique with linear complexity to identify solar owners. Furthermore, with the real data from Australia and Denmark, the proposed method is tested and verified in identifying PV owners as well as identifying electrical heating system users. The performances of the proposed method is studied and compared with various of state-of-the-art methods, where the proposed method outperformed the alternatives.      
### 35.VoiceFixer: Toward General Speech Restoration With Neural Vocoder  [ :arrow_down: ](https://arxiv.org/pdf/2109.13731.pdf)
>  Speech restoration aims to remove distortions in speech signals. Prior methods mainly focus on single-task speech restoration(SSR), such as speech enhancement or speech declipping. However, SSR systems only focus on one task and do not address the general speech restoration problem. Previous SSR systems also have limited performance in speech restoration tasks such as speech super-resolution. To overcome those limitations, we propose a general speech restoration(GSR) task that attempts to remove multiple distortions simultaneously. Furthermore, we propose VoiceFixer, a generative framework to address the GSR tasks. VoiceFixer consists of an analysis stage and a synthesis stage to mimic the speech analysis and comprehension of the human auditory system. We employ a ResUNet to model the analysis module and a neural vocoder to model the synthesis module. We evaluate VoiceFixer with additive noise, room reverberation, low-resolution, and clipping distortions. Our baseline GSR model achieves a 0.499 higher mean opinion score(MOS) than the speech enhancement SSR model. VoiceFixer further surpasses the GSR baseline model on the MOS score by 0.256. In addition, we observe that VoiceFixer generalizes well to severely degraded real speech recordings, indicating its potential in restoring old movies and historical speeches. The source code is available at <a class="link-external link-https" href="https://github.com/haoheliu/voicefixer_main" rel="external noopener nofollow">this https URL</a>.      
### 36.FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2109.13675.pdf)
>  Recently, non-autoregressive neural vocoders have provided remarkable performance in generating high-fidelity speech and have been able to produce synthetic speech in real-time. However, non-autoregressive neural vocoders such as WaveGlow are far behind autoregressive neural vocoders like WaveFlow in terms of modeling audio signals due to their limitation in expressiveness. In addition, though NanoFlow is a state-of-the-art autoregressive neural vocoder that has immensely small parameters, its performance is marginally lower than WaveFlow. Therefore, in this paper, we propose a new type of autoregressive neural vocoder called FlowVocoder, which has a small memory footprint and is able to generate high-fidelity audio in real-time. Our proposed model improves the expressiveness of flow blocks by operating a mixture of Cumulative Distribution Function(CDF) for bipartite transformation. Hence, the proposed model is capable of modeling waveform signals as well as WaveFlow, while its memory footprint is much smaller thanWaveFlow. As shown in experiments, FlowVocoder achieves competitive results with baseline methods in terms of both subjective and objective evaluation, also, it is more suitable for real-time text-to-speech applications.      
### 37.Nana-HDR: A Non-attentive Non-autoregressive Hybrid Model for TTS  [ :arrow_down: ](https://arxiv.org/pdf/2109.13673.pdf)
>  This paper presents Nana-HDR, a new non-attentive non-autoregressive model with hybrid Transformer-based Dense-fuse encoder and RNN-based decoder for TTS. It mainly consists of three parts: Firstly, a novel Dense-fuse encoder with dense connections between basic Transformer blocks for coarse feature fusion and a multi-head attention layer for fine feature fusion. Secondly, a single-layer non-autoregressive RNN-based decoder. Thirdly, a duration predictor instead of an attention model that connects the above hybrid encoder and decoder. Experiments indicate that Nana-HDR gives full play to the advantages of each component, such as strong text encoding ability of Transformer-based encoder, stateful decoding without being bothered by exposure bias and local information preference, and stable alignment provided by duration predictor. Due to these advantages, Nana-HDR achieves competitive performance in naturalness and robustness on two Mandarin corpora.      
### 38.Intelligent Reflecting Surface Aided Wireless Networks: From Single-Reflection to Multi-Reflection Design and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2109.13641.pdf)
>  Intelligent reflecting surface (IRS) has emerged as a promising technique for wireless communication networks. By dynamically tuning the reflection amplitudes/phase shifts of a large number of passive elements, IRS enables flexible wireless channel control and configuration, and thereby enhances the wireless signal transmission rate and reliability significantly. Despite the vast literature on designing and optimizing assorted IRS-aided wireless systems, prior works have mainly focused on enhancing wireless links with single signal reflection only by one or multiple IRSs, which may be insufficient to boost the wireless link capacity under some harsh propagation conditions (e.g., indoor environment with dense blockages/obstructions). This issue can be tackled by employing two or more IRSs to assist each wireless link and jointly exploiting their single as well as multiple signal reflections over them. However, the resultant double-/multi-IRS aided wireless systems face more complex design issues as well as new practical challenges for implementation as compared to the conventional single-IRS counterpart, in terms of IRS reflection optimization, channel acquisition, as well as IRS deployment and association/selection. As such, a new paradigm for designing multi-IRS cooperative passive beamforming and joint active/passive beam routing arises which calls for innovative design approaches and optimization methods. In this paper, we give a tutorial overview of multi-IRS aided wireless networks, with an emphasis on addressing the new challenges due to multi-IRS signal reflection and routing. Moreover, we point out important directions worthy of research and investigation in the future.      
### 39.Weighted Secrecy Coverage Analysis and the Impact of Friendly Jamming over UAV-Enabled Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.13629.pdf)
>  In 5G and beyond networks, Unmanned Aerial Vehicles (UAV) are an attractive solution to enhance the secrecy of a wireless systems by exploiting their predominant LOS links and spacial manoeuvrability to introduce a friendly jamming. In this work, we investigate the impact of two cooperative UAV-based jammers on the secrecy performance of a ground wireless wiretap channel by considering secrecy-area related metrics, the jamming coverage and jamming efficiency. Moreover, we propose a hybrid metric, the so-called Weighted Secrecy Coverage (WSC) that can be used as a metric for gaining insights on the optimal deployments of the UAV jammers to provide the best exploration of jamming signals. For evaluating these metrics, we derive a closed-form position-based metric, the secrecy improvement, and propose an analogous computationally simpler metric. Our simulations show that a balanced power allocation between the two UAVs leads to the best performances, as well as a symmetrical positioning behind the line of sight between the legitimate transmitter and receiver. Moreover, there exist an optimal UAV height for the jammers. Finally, we propose a sub-optimal and simpler problem for the maximisation of the WSC.      
### 40.Efficient Global-Local Memory for Real-time Instrument Segmentation of Robotic Surgical Video  [ :arrow_down: ](https://arxiv.org/pdf/2109.13593.pdf)
>  Performing a real-time and accurate instrument segmentation from videos is of great significance for improving the performance of robotic-assisted surgery. We identify two important clues for surgical instrument perception, including local temporal dependency from adjacent frames and global semantic correlation in long-range duration. However, most existing works perform segmentation purely using visual cues in a single frame. Optical flow is just used to model the motion between only two frames and brings heavy computational cost. We propose a novel dual-memory network (DMNet) to wisely relate both global and local spatio-temporal knowledge to augment the current features, boosting the segmentation performance and retaining the real-time prediction capability. We propose, on the one hand, an efficient local memory by taking the complementary advantages of convolutional LSTM and non-local mechanisms towards the relating reception field. On the other hand, we develop an active global memory to gather the global semantic correlation in long temporal range to current one, in which we gather the most informative frames derived from model uncertainty and frame similarity. We have extensively validated our method on two public benchmark surgical video datasets. Experimental results demonstrate that our method largely outperforms the state-of-the-art works on segmentation accuracy while maintaining a real-time speed.      
### 41.On the sensitivity of linear resource sharing problems to the arrival of new agents  [ :arrow_down: ](https://arxiv.org/pdf/2109.13580.pdf)
>  We consider a multi-agent optimal resource sharing problem that is represented by a linear program. The amount of resource to be shared is fixed, and agents belong to a population that is characterized probabilistically so as to allow heterogeneity among the agents. In this paper, we provide a characterization of the probability that the arrival of a new agent affects the resource share of other agents, which means that accommodating the new agent request at the detriment of the other agents allocation provides some payoff. This probability represents a sensitivity index for the optimal solution of a linear programming resource sharing problem when a new agent shows up, and it is of fundamental importance for a correct and profitable operation of the multi-agent system. Our developments build on the equivalence between the resource sharing problem and certain dual reformulations which can be interpreted as scenario programs with the number of scenarios corresponding to the number of agents in the primal problem. The recent "wait-and-judge" scenario approach is then used to obtain the sought sensitivity index. Our theoretical findings are demonstrated through a numerical example on optimal cargo aircraft loading.      
### 42.A Note on Nussbaum-type Control and Lie-bracket Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2109.13559.pdf)
>  In this paper, we propose an adaptive control law for completely unknown scalar linear systems based on Lie-bracket approximation methods. We investigate stability and convergence properties for the resulting Lie-bracket system, compare our proposal with existing Nussbaum-type solutions and demonstrate our results with an example. Even though we prove global stability properties of the Lie-bracket system, the stability properties of the proposed dynamics remain open, making the proposed control law an object of further studies. We elaborate the difficulties of establishing stability results by investigating connections to partial stability as well as studying the corresponding Chen-Fliess expansion.      
### 43.A multi-stage semi-supervised improved deep embedded clustering (MS-SSIDEC) method for bearing fault diagnosis under the situation of insufficient labeled samples  [ :arrow_down: ](https://arxiv.org/pdf/2109.13521.pdf)
>  Intelligent data-driven fault diagnosis methods have been widely applied, but most of these methods need a large number of high-quality labeled samples. It costs a lot of labor and time to label data in actual industrial processes, which challenges the application of intelligent fault diagnosis methods. To solve this problem, a multi-stage semi-supervised improved deep embedded clustering (MS-SSIDEC) method is proposed for the bearing fault diagnosis under the insufficient labeled samples situation. This method includes three stages: pre-training, deep clustering and enhanced supervised learning. In the first stage, a skip-connection based convolutional auto-encoder (SCCAE) is proposed and pre-trained to automatically learn low-dimensional representations. In the second stage, a semi-supervised improved deep embedded clustering (SSIDEC) model that integrates the pre-trained auto-encoder with a clustering layer is proposed for deep clustering. Additionally, virtual adversarial training (VAT) is introduced as a regularization term to overcome the overfitting in the model's training. In the third stage, high-quality clustering results obtained in the second stage are assigned to unlabeled samples as pseudo labels. The labeled dataset is augmented by those pseudo-labeled samples and used to train a bearing fault discriminative model. The effectiveness of the method is evaluated on the Case Western Reserve University (CWRU) bearing dataset. The results show that the method can not only satisfy the semi-supervised learning under a small number of labeled samples, but also solve the problem of unsupervised learning, and has achieved better results than traditional diagnosis methods. This method provides a new research idea for fault diagnosis with limited labeled samples by effectively using unsupervised data.      
### 44.VoxCeleb Enrichment for Age and Gender Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2109.13510.pdf)
>  VoxCeleb datasets are widely used in speaker recognition studies. Our work serves two purposes. First, we provide speaker age labels and (an alternative) annotation of speaker gender. Second, we demonstrate the use of this metadata by constructing age and gender recognition models with different features and classifiers. We query different celebrity databases and apply consensus rules to derive age and gender labels. We also compare the original VoxCeleb gender labels with our labels to identify records that might be mislabeled in the original VoxCeleb data. On modeling side, we design a comprehensive study of multiple features and models for recognizing gender and age. Our best system, using i-vector features, achieved an F1-score of 0.9829 for gender recognition task using logistic regression, and the lowest mean absolute error (MAE) in age regression, 9.443 years, is obtained with ridge regression. This indicates challenge in age estimation from in-the-wild style speech data.      
### 45.FastMVAE2: On improving and accelerating the fast variational autoencoder-based source separation algorithm for determined mixtures  [ :arrow_down: ](https://arxiv.org/pdf/2109.13496.pdf)
>  This paper proposes a new source model and training scheme to improve the accuracy and speed of the multichannel variational autoencoder (MVAE) method. The MVAE method is a recently proposed powerful multichannel source separation method. It consists of pretraining a source model represented by a conditional VAE (CVAE) and then estimating separation matrices along with other unknown parameters so that the log-likelihood is non-decreasing given an observed mixture signal. Although the MVAE method has been shown to provide high source separation performance, one drawback is the computational cost of the backpropagation steps in the separation-matrix estimation algorithm. To overcome this drawback, a method called "FastMVAE" was subsequently proposed, which uses an auxiliary classifier VAE (ACVAE) to train the source model. By using the classifier and encoder trained in this way, the optimal parameters of the source model can be inferred efficiently, albeit approximately, in each step of the algorithm. However, the generalization capability of the trained ACVAE source model was not satisfactory, which led to poor performance in situations with unseen data. To improve the generalization capability, this paper proposes a new model architecture (called the "ChimeraACVAE" model) and a training scheme based on knowledge distillation. The experimental results revealed that the proposed source model trained with the proposed loss function achieved better source separation performance with less computation time than FastMVAE. We also confirmed that our methods were able to separate 18 sources with a reasonably good accuracy.      
### 46.Two-Stage Channel Estimation Approach for Cell-Free IoT With Massive Random Access  [ :arrow_down: ](https://arxiv.org/pdf/2109.13450.pdf)
>  We investigate the activity detection and channel estimation issues for cell-free Internet of Things (IoT) networks with massive random access. In each time slot, only partial devices are active and communicate with neighboring access points (APs) using non-orthogonal random pilot sequences. Different from the centralized processing in cellular networks, the activity detection and channel estimation in cell-free IoT is more challenging due to the distributed and user-centric architecture. We propose a two-stage approach to detect the random activities of devices and estimate their channel states. In the first stage, the activity of each device is jointly detected by its adjacent APs based on the vector approximate message passing (Vector AMP) algorithm. In the second stage, each AP re-estimates the channel using the linear minimum mean square error (LMMSE) method based on the detected activities to improve the channel estimation accuracy. We derive closed-form expressions for the activity detection error probability and the mean-squared channel estimation errors for a typical device. Finally, we analyze the performance of the entire cell-free IoT network in terms of coverage probability. Simulation results validate the derived closed-form expressions and show that the cell-free IoT significantly outperforms the collocated massive MIMO and small-cell schemes in terms of coverage probability.      
### 47.Lithium-ion Battery State of Health Estimation based on Cycle Synchronization using Dynamic Time Warping  [ :arrow_down: ](https://arxiv.org/pdf/2109.13448.pdf)
>  The state of health (SOH) estimation plays an essential role in battery-powered applications to avoid unexpected breakdowns due to battery capacity fading. However, few studies have paid attention to the problem of uneven length of degrading cycles, simply employing manual operation or leaving to the automatic processing mechanism of advanced machine learning models, like long short-term memory (LSTM). As a result, this causes information loss and caps the full capability of the data-driven SOH estimation models. To address this challenge, this paper proposes an innovative cycle synchronization way to change the existing coordinate system using dynamic time warping, not only enabling the equal length inputs of the estimation model but also preserving all information. By exploiting the time information of the time series, the proposed method embeds the time index and the original measurements into a novel indicator to reflect the battery degradation status, which could have the same length over cycles. Adopting the LSTM as the basic estimation model, the cycle synchronization-based SOH model could significantly improve the prediction accuracy by more than 30% compared to the traditional LSTM.      
### 48.Runtime Safety Assurance for Learning-enabled Control of Autonomous Driving Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2109.13446.pdf)
>  Providing safety guarantees for Autonomous Vehicle (AV) systems with machine-learning-based controllers remains a challenging issue. In this work, we propose Simplex-Drive, a framework that can achieve runtime safety assurance for machine-learning enabled controllers of AVs. The proposed Simplex-Drive consists of an unverified Deep Reinforcement Learning (DRL)-based advanced controller (AC) that achieves desirable performance in complex scenarios, a Velocity-Obstacle (VO) based baseline safe controller (BC) with provably safety guarantees, and a verified mode management unit that monitors the operation status and switches the control authority between AC and BC based on safety-related conditions. We provide a formal correctness proof of Simplex-Drive and conduct a lane-changing case study in dense traffic scenarios. The simulation experiment results demonstrate that Simplex-Drive can always ensure operation safety without sacrificing control performance, even if the DRL policy may lead to deviations from the safe status.      
### 49.The Role of Lookahead and Approximate Policy Evaluation in Policy Iteration with Linear Value Function Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2109.13419.pdf)
>  When the sizes of the state and action spaces are large, solving MDPs can be computationally prohibitive even if the probability transition matrix is known. So in practice, a number of techniques are used to approximately solve the dynamic programming problem, including lookahead, approximate policy evaluation using an m-step return, and function approximation. In a recent paper, (Efroni et al. 2019) studied the impact of lookahead on the convergence rate of approximate dynamic programming. In this paper, we show that these convergence results change dramatically when function approximation is used in conjunction with lookout and approximate policy evaluation using an m-step return. Specifically, we show that when linear function approximation is used to represent the value function, a certain minimum amount of lookahead and multi-step return is needed for the algorithm to even converge. And when this condition is met, we characterize the finite-time performance of policies obtained using such approximate policy iteration. Our results are presented for two different procedures to compute the function approximation: linear least-squares regression and gradient descent.      
### 50.Interactive Dynamic Walking: Learning Gait Switching Policies with Generalization Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2109.13417.pdf)
>  In this paper, we consider the problem of adapting a dynamically walking bipedal robot to follow a leading co-worker while engaging in tasks that require physical interaction. Our approach relies on switching among a family of Dynamic Movement Primitives (DMPs) as governed by a supervisor. We train the supervisor to orchestrate the switching among the DMPs in order to adapt to the leader's intentions, which are only implicitly available in the form of interaction forces. The primary contribution of our approach is its ability to furnish certificates of generalization to novel leader intentions for the trained supervisor. This is achieved by leveraging the Probably Approximately Correct (PAC)-Bayes bounds from generalization theory. We demonstrate the efficacy of our approach by training a neural-network supervisor to adapt the gait of a dynamically walking biped to a leading collaborator whose intended trajectory is not known explicitly.      
### 51.Multi-Agent Recurrent Rendezvous Using Drive-Based Motivation  [ :arrow_down: ](https://arxiv.org/pdf/2109.13408.pdf)
>  Recent papers have introduced the Motivation Dynamics framework, which uses bifurcations to encode decision-making behavior in an autonomous mobile agent. In this paper, we consider the multi-agent extension of the Motivation Dynamics framework and show how the framework can be extended to encode persistent multi-agent rendezvous behaviors. We analytically characterize the bifurcation properties of the resulting system, and numerically show that it exhibits complex recurrent behavior suggestive of a strange attractor.      
### 52.CRANE: a 10 Degree-of-Freedom, Tele-surgical System for Dexterous Manipulation within Imaging Bores  [ :arrow_down: ](https://arxiv.org/pdf/2109.13407.pdf)
>  Physicians perform minimally invasive percutaneous procedures under Computed Tomography (CT) image guidance both for the diagnosis and treatment of numerous diseases. For these procedures performed within Computed Tomography Scanners, robots can enable physicians to more accurately target sub-dermal lesions while increasing safety. However, existing robots for this application have limited dexterity, workspace, or accuracy. This paper describes the design, manufacture, and performance of a highly dexterous, low-profile, 8+2 Degree-ofFreedom (DoF) robotic arm for CT guided percutaneous needle biopsy. In this article, we propose CRANE: CT Robot and Needle Emplacer. The design focuses on system dexterity with high accuracy: extending physicians' ability to manipulate and insert needles within the scanner bore while providing the high accuracy possible with a robot. We also propose and validate a system architecture and control scheme for low profile and highly accurate image-guided robotics, that meets the clinical requirements for target accuracy during an in-situ evaluation. The accuracy is additionally evaluated through a trajectory tracking evaluation resulting in &lt;0.2mm and &lt;0.71degree tracking error. Finally, we present a novel needle driving and grasping mechanism with controlling electronics that provides simple manufacturing, sterilization, and adaptability to accommodate different sizes and types of needles.      
### 53.Automated Estimation of Construction Equipment Emission using Inertial Sensors and Machine Learning Models  [ :arrow_down: ](https://arxiv.org/pdf/2109.13375.pdf)
>  The construction industry is one of the main producers of greenhouse gasses (GHG). Quantifying the amount of air pollutants including GHG emissions during a construction project has become an additional project objective to traditional metrics such as time, cost, and safety in many parts of the world. A major contributor to air pollution during construction is the use of heavy equipment and thus their efficient operation and management can substantially reduce the harm to the environment. Although the on-road vehicle emission prediction is a widely researched topic, construction equipment emission measurement and reduction have received very little attention. This paper describes the development and deployment of a novel framework that uses machine learning (ML) methods to predict the level of emissions from heavy construction equipment monitored via an Internet of Things (IoT) system comprised of accelerometer and gyroscope sensors. The developed framework was validated using an excavator performing real-world construction work. A portable emission measurement system (PEMS) was employed along with the inertial sensors to record data including the amount of CO, NOX, CO2, SO2, and CH4 pollutions emitted by the equipment. Different ML algorithms were developed and compared to identify the best model to predict emission levels from inertial sensors data. The results showed that Random Forest with the coefficient of determination (R2) of 0.94, 0.91 and 0.94 for CO, NOX, CO2, respectively was the best algorithm among different models evaluated in this study.      
### 54.Audio-to-Image Cross-Modal Generation  [ :arrow_down: ](https://arxiv.org/pdf/2109.13354.pdf)
>  Cross-modal representation learning allows to integrate information from different modalities into one representation. At the same time, research on generative models tends to focus on the visual domain with less emphasis on other domains, such as audio or text, potentially missing the benefits of shared representations. Studies successfully linking more than one modality in the generative setting are rare. In this context, we verify the possibility to train variational autoencoders (VAEs) to reconstruct image archetypes from audio data. Specifically, we consider VAEs in an adversarial training framework in order to ensure more variability in the generated data and find that there is a trade-off between the consistency and diversity of the generated images - this trade-off can be governed by scaling the reconstruction loss up or down, respectively. Our results further suggest that even in the case when the generated images are relatively inconsistent (diverse), features that are critical for proper image classification are preserved.      
### 55.Control Barrier Functions for Singularity Avoidance in Passivity-Based Manipulator Control  [ :arrow_down: ](https://arxiv.org/pdf/2109.13349.pdf)
>  Task-space Passivity-Based Control (PBC) for manipulation has numerous appealing properties, including robustness to modeling error and safety for human-robot interaction. Existing methods perform poorly in singular configurations, however, such as when all the robot's joints are fully extended. Additionally, standard methods for constrained task-space PBC guarantee passivity only when constraints are not active. We propose a convex-optimization-based control scheme that provides guarantees of singularity avoidance, passivity, and feasibility. This work paves the way for PBC with passivity guarantees under other types of constraints as well, including joint limits and contact/friction constraints. The proposed methods are validated in simulation experiments on a 7 degree-of-freedom manipulator.      
### 56.Enhanced Audit Bit Based Distributed Bayesian Detection in the Presence of Strategic Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2109.13325.pdf)
>  This paper employs an audit bit based mechanism to mitigate the effect of Byzantine attacks. In this framework, the optimal attacking strategy for intelligent attackers is investigated for the traditional audit bit based scheme (TAS) to evaluate the robustness of the system. We show that it is possible for an intelligent attacker to degrade the performance of TAS to the system without audit bits. To enhance the robustness of the system in the presence of intelligent attackers, we propose an enhanced audit bit based scheme (EAS). The optimal fusion rule for the proposed scheme is derived and the detection performance of the system is evaluated via the probability of error for the system. Simulation results show that the proposed EAS improves the robustness and the detection performance of the system. Moreover, based on EAS, another new scheme called the reduced audit bit based scheme (RAS) is proposed which further improves system performance. We derive the new optimal fusion rule and the simulation results show that RAS outperforms EAS and TAS in terms of both robustness and detection performance of the system. Then, we extend the proposed RAS for a wide-area cluster based distributed wireless sensor networks (CWSNs). Simulation results show that the proposed RAS significantly reduces the communication overhead between the sensors and the FC, which prolongs the lifetime of the network.      
### 57.Induced transparency: interference or polarization?  [ :arrow_down: ](https://arxiv.org/pdf/2109.13322.pdf)
>  The polarization of optical fields is a crucial degree of freedom in the all-optical analogue of electromagnetically induced transparency (EIT). However, the physical origins of EIT and polarization induced phenomena have not been well distinguished, which can lead to confusion in associated applications such as slow light and optical/quantum storage. Here we study the polarization effects in various optical EIT systems. We find that a polarization mismatch between whispering gallery modes in two indirectly coupled resonators can induce a narrow transparency window in the transmission spectrum resembling the EIT lineshape. However, such polarization induced transparency (PIT) is distinct from EIT: it originates from strong polarization rotation effects and shows unidirectional feature. The coexistence of PIT and EIT provides new routes for the manipulation of light flow in optical resonator systems.      
