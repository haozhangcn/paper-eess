# ArXiv eess --Fri, 10 Sep 2021
### 1.Tube-Certified Trajectory Tracking for Nonlinear Systems With Robust Control Contraction Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2109.04453.pdf)
>  This paper presents an approach to guaranteed trajectory tracking for nonlinear control-affine systems subject to external disturbances based on robust control contraction metrics (CCM) that aim to minimize the $\mathcal{L}_\infty$ gain from the disturbances to the deviation of actual variables of interests from their nominal counterparts. The guarantee is in the form of invariant tubes, computed offline, around any nominal trajectories in which the actual states and inputs of the system are guaranteed to stay despite disturbances. Under mild assumptions, we prove that the proposed robust CCM (RCCM) approach yields tighter tubes than an existing approach based on CCM and input-to-state stability analysis. We show how the RCCM-based tracking controller together with tubes can be incorporated into a feedback motion planning framework to plan safe-guaranteed trajectories for robotic systems. Simulation results for a planar quadrotor illustrate the effectiveness of the proposed method and also empirically demonstrate significantly reduced conservatism compared to the CCM-based approach.      
### 2.Low-Dispersive Permittivity Measurement Based on Transmitted Power Only  [ :arrow_down: ](https://arxiv.org/pdf/2109.04417.pdf)
>  This paper presents a complex permittivity measurement method for low-dispersive materials as a function of frequency. The introduced method relies only on transmitted power signals which are collected using a spectrum analyzer/power meter, removing the need for phase measurements and a vector network analyzer. This method provides a very good accuracy along with easy and inexpensive permittivity measurements.      
### 3.Non-autoregressive End-to-end Speech Translation with Parallel Autoregressive Rescoring  [ :arrow_down: ](https://arxiv.org/pdf/2109.04411.pdf)
>  This article describes an efficient end-to-end speech translation (E2E-ST) framework based on non-autoregressive (NAR) models. End-to-end speech translation models have several advantages over traditional cascade systems such as inference latency reduction. However, conventional AR decoding methods are not fast enough because each token is generated incrementally. NAR models, however, can accelerate the decoding speed by generating multiple tokens in parallel on the basis of the token-wise conditional independence assumption. We propose a unified NAR E2E-ST framework called Orthros, which has an NAR decoder and an auxiliary shallow AR decoder on top of the shared encoder. The auxiliary shallow AR decoder selects the best hypothesis by rescoring multiple candidates generated from the NAR decoder in parallel (parallel AR rescoring). We adopt conditional masked language model (CMLM) and a connectionist temporal classification (CTC)-based model as NAR decoders for Orthros, referred to as Orthros-CMLM and Orthros-CTC, respectively. We also propose two training methods to enhance the CMLM decoder. Experimental evaluations on three benchmark datasets with six language directions demonstrated that Orthros achieved large improvements in translation quality with a very small overhead compared with the baseline NAR model. Moreover, the Conformer encoder architecture enabled large quality improvements, especially for CTC-based models. Orthros-CTC with the Conformer encoder increased decoding speed by 3.63x on CPU with translation quality comparable to that of an AR model.      
### 4.Fair Conformal Predictors for Applications in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2109.04392.pdf)
>  Deep learning has the potential to augment many components of the clinical workflow, such as medical image interpretation. However, the translation of these black box algorithms into clinical practice has been marred by the relative lack of transparency compared to conventional machine learning methods, hindering in clinician trust in the systems for critical medical decision-making. Specifically, common deep learning approaches do not have intuitive ways of expressing uncertainty with respect to cases that might require further human review. Furthermore, the possibility of algorithmic bias has caused hesitancy regarding the use of developed algorithms in clinical settings. To these ends, we explore how conformal methods can complement deep learning models by providing both clinically intuitive way (by means of confidence prediction sets) of expressing model uncertainty as well as facilitating model transparency in clinical workflows. In this paper, we conduct a field survey with clinicians to assess clinical use-cases of conformal predictions. Next, we conduct experiments with a mammographic breast density and dermatology photography datasets to demonstrate the utility of conformal predictions in "rule-in" and "rule-out" disease scenarios. Further, we show that conformal predictors can be used to equalize coverage with respect to patient demographics such as race and skin tone. We find that a conformal predictions to be a promising framework with potential to increase clinical usability and transparency for better collaboration between deep learning algorithms and clinicians.      
### 5.On Measurement Number of Phase-only Signal Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2109.04365.pdf)
>  This work establishes a theoretical framework for signal reconstruction from phase of linear measurement or affine linear measurement, and obtains some results on measurement number. We consider d-dimensional complex signals. In the scenario of linear measurement, at least 2d but no more than 4d-2 measurements are required to recover all signals up to a positive scalar. Moreover, we prove that 2d-1 generic measurements can recover generic signals or a specific signal, and 2d-1 is minimal in the sense that 2d-2 measurements can hardly recover signals. In the scenario of affine linear measurement, at least 2d+1 measurements but no more than 3d measurements are required to recover all signals exactly, while no less than 2d generic measurements can handle generic signals. Throughout the paper, we employ our theoretical results to understand existing results and algorithms of phase-only signal reconstruction.      
### 6.Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier, Autoencoders and Fuzzy Entropies  [ :arrow_down: ](https://arxiv.org/pdf/2109.04364.pdf)
>  Epilepsy is one of the most crucial neurological disorders, and its early diagnosis will help the clinicians to provide accurate treatment for the patients. The electroencephalogram (EEG) signals are widely used for epileptic seizures detection, which provides specialists with substantial information about the functioning of the brain. In this paper, a novel diagnostic procedure using fuzzy theory and deep learning techniques are introduced. The proposed method is evaluated on the Bonn University dataset with six classification combinations and also on the Freiburg dataset. The tunable-Q wavelet transform (TQWT) is employed to decompose the EEG signals into different sub-bands. In the feature extraction step, 13 different fuzzy entropies are calculated from different sub-bands of TQWT, and their computational complexities are calculated to help researchers choose the best feature sets. In the following, an autoencoder (AE) with six layers is employed for dimensionality reduction. Finally, the standard adaptive neuro-fuzzy inference system (ANFIS), and also its variants with grasshopper optimization algorithm (ANFIS-GOA), particle swarm optimization (ANFIS-PSO), and breeding swarm optimization (ANFIS-BS) methods are used for classification. Using our proposed method, ANFIS-BS method has obtained an accuracy of 99.74% in classifying into two classes and an accuracy of 99.46% in ternary classification on the Bonn dataset and 99.28% on the Freiburg dataset, reaching state-of-the-art performances on both of them.      
### 7.Optical Channel Aggregation by Coherent Spectral Superposition with Electro-Optic Modulators  [ :arrow_down: ](https://arxiv.org/pdf/2109.04363.pdf)
>  As the bit rates of routed data streams exceed the throughput of single wavelength-division multiplexing channels, spectral traffic aggregation becomes essential for optical network scaling. Here we propose a scheme for all-optical aggregation of several low bitrate channels to fewer channels with higher spectral efficiency. The method is based on optical vector summation facilitated by coherent spectral superposition. Thereby it does not need any optical nonlinearities and is based on linear signal processing with an electro-optic modulator. Furthermore, optical phase tuning required for vector addition can be easily achieved by a phase tuning of the radio frequency signal driving the modulator. We experimentally demonstrate the aggregation of two 10 Gbaud BPSK signals into one 10 Gbaud QPSK and one 10 Gbaud PAM-4 signal, the aggregation of two 10 Gbaud QPSK signals into 10 Gbaud QAM-16, as well as the aggregation of sinc-shaped Nyquist signals. The presented concept of in-line all-optical aggregation demonstrates considerable improvement in network spectrum utilization and can significantly enhance the operational capacity with reduced complexity. It provides a new way for realizing the flexible optical transmission of advanced modulation format signals, and suits for future dynamically reconfigurable optical networks. Since the method is based on linear signal processing with electro-optic modulator, integration into any integrated photonic platform is straightforward.      
### 8.Characterization of the frequency response of channel-interleaved photonic ADCs based on the optical time-division demultiplexer  [ :arrow_down: ](https://arxiv.org/pdf/2109.04362.pdf)
>  We characterize the frequency response of channel-interleaved photonic analog-to-digital converters (CI-PADCs) theoretically and experimentally. The CI-PADC is composed of a photonic frontend for photonic sampling and an electronic backend for quantization. The photonic frontend includes a photonic sampling pulse generator for directly high-speed sampling and an optical time-division demultiplexer (OTDM) for channel demultiplexing. It is found that the frequency response of the CI-PADC is influenced by both the photonic sampling pulses and the OTDM, of which the combined impact can be characterized through demultiplexed pulse trains. First, the frequency response can be divided into multiple frequency intervals and the range of the frequency interval equals the repetition rate of demultiplexed pulse trains. Second, the analog bandwidth of the CI-PADC is determined by the optical spectral bandwidth of demultiplexed pulse trains which is broadened in the OTDM. Further, the effect of the OTDM is essential for enlarging the analog bandwidth of the CI-PADC employing the photonic sampling pulses with a limited optical spectral bandwidth.      
### 9.MutualGraphNet: A novel model for motor imagery classification  [ :arrow_down: ](https://arxiv.org/pdf/2109.04361.pdf)
>  Motor imagery classification is of great significance to humans with mobility impairments, and how to extract and utilize the effective features from motor imagery electroencephalogram(EEG) channels has always been the focus of attention. There are many different methods for the motor imagery classification, but the limited understanding on human brain requires more effective methods for extracting the features of EEG data. Graph neural networks(GNNs) have demonstrated its effectiveness in classifying graph structures; and the use of GNN provides new possibilities for brain structure connection feature extraction. In this paper we propose a novel graph neural network based on the mutual information of the raw EEG channels called MutualGraphNet. We use the mutual information as the adjacency matrix combined with the spatial temporal graph convolution network(ST-GCN) could extract the transition rules of the motor imagery electroencephalogram(EEG) channels data more effectively. Experiments are conducted on motor imagery EEG data set and we compare our model with the current state-of-the-art approaches and the results suggest that MutualGraphNet is robust enough to learn the interpretable features and outperforms the current state-of-the-art methods.      
### 10.Measuring Uncertainty in Signal Fingerprinting with Gaussian Processes Going Deep  [ :arrow_down: ](https://arxiv.org/pdf/2109.04360.pdf)
>  In indoor positioning, signal fluctuation is highly location-dependent. However, signal uncertainty is one critical yet commonly overlooked dimension of the radio signal to be fingerprinted. This paper reviews the commonly used Gaussian Processes (GP) for probabilistic positioning and points out the pitfall of using GP to model signal fingerprint uncertainty. This paper also proposes Deep Gaussian Processes (DGP) as a more informative alternative to address the issue. How DGP better measures uncertainty in signal fingerprinting is evaluated via simulated and realistically collected datasets.      
### 11.Wind Turbine Gearbox Condition Based Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2109.04359.pdf)
>  The main objective of this paper is finding effective gearbox condition monitoring methods by using continuously recorded monitoring SCADA (Supervisory Control and Data Accusation) data points. Typically for wind turbine gearbox condition monitoring; temperature readings, high frequency sounds and vibrations in addition to lubricant condition monitoring have been used. However, collection of such data, require shutting down equipment for installation of costly sensors and measuring lubricant quality. Meanwhile, operational data usually collected every 10 minutes, comprised of wind speed, power generated, pitch angle and similar performance parameters can be used for monitoring health of wind turbine components such as blades, gearbox and generator. This paper uses gear rotational speed for monitoring health of gearbox teeth; since gearbox teeth deterioration can be measured by monitoring rotor to generator rotation ratios over extended period of time. As nature of wind is turbulent with rapid fluctuations, a wind turbine may operate in variety of modes within relatively short period of time. Monitoring rotational speed ratio over time, requires consistent operational conditions such as wind speed and torques within the gearbox. This paper also introduces the concept of clustering such as Normal Mixture algorithm for dividing operating datasets into consistent subgroups, which are used for long term monitoring.      
### 12.Multi-dimensional graph fractional Fourier transform and its application  [ :arrow_down: ](https://arxiv.org/pdf/2109.04358.pdf)
>  Many multi-dimensional signals appear in the real world, such as digital images and data that has spatial and temporal dimensions. How to show the spectrum of these multi-dimensional signals correctly is a key challenge in the field of graph signal processing. This paper investigates the novel transform for multi-dimensional signals defined on Cartesian product graph and studies several related properties. Our work includes: (i) defining the multi-dimensional graph fractional Fourier transform (MGFRFT) based on Laplacian matrix and adjacency matrix; (ii) exploring the advantages of MGFRFT in processing multi-dimensional signals in terms of spectrum and computational time; (iii) applying the proposed transform to data compression to highlight the utility and effectiveness of it.      
### 13.Rainbow-link: Beam-Alignment-Free and Grant-Free mmW Multiple Access using True-Time-Delay Array  [ :arrow_down: ](https://arxiv.org/pdf/2109.04357.pdf)
>  In this paper we propose a novel millimeter wave (mmW) multiple access method that exploits unique frequency dependent beamforming capabilities of True Time Delay (TTD) array architecture. The proposed protocol combines a contentionbased grant-free access and orthogonal frequency-division multiple access (OFDMA) scheme for uplink machine type communications. By exploiting abundant time-frequency resource blocks in mmW spectrum, we design a simple protocol that can achieve low collision rate and high network reliability for short packets and sporadic transmissions. We analyze the impact of various system parameters on system performance during synchronization and contention period. We exploit unique advantages of frequency dependent beamforming, referred as rainbow beam, to eliminate beam training overhead and analyze its impact on rates, latency, and coverage. The proposed system and protocol can flexibly accommodate different low latency applications with moderate rate requirements for a very large number of narrowband single antenna devices. By harnessing abundant resources in mmW spectrum and beamforming gain of TTD arrays rainbow link based system can simultaneously satisfy ultra-reliability and massive multiple access requirements.      
### 14.Assessing Machine Learning Approaches to Address IoT Sensor Drift  [ :arrow_down: ](https://arxiv.org/pdf/2109.04356.pdf)
>  The proliferation of IoT sensors and their deployment in various industries and applications has brought about numerous analysis opportunities in this Big Data era. However, drift of those sensor measurements poses major challenges to automate data analysis and the ability to effectively train and deploy models on a continuous basis. In this paper we study and test several approaches from the literature with regard to their ability to cope with and adapt to sensor drift under realistic conditions. Most of these approaches are recent and thus are representative of the current state-of-the-art. The testing was performed on a publicly available gas sensor dataset exhibiting drift over time. The results show substantial drops in sensing performance due to sensor drift in spite of the approaches. We then discuss several issues identified with current approaches and outline directions for future research to tackle them.      
### 15.Multi-sensor Joint Adaptive Birth Sampler for Labeled Random Finite Set Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2109.04355.pdf)
>  This paper provides a scalable, multi-sensor measurement adaptive track initiation technique for labeled random finite set filters. A naive construction of the multi-sensor measurement adaptive birth set leads to an exponential number of newborn components in the number of sensors. A truncation criterion is established for a multi-sensor measurement-generated labeled multi-Bernoulli random finite set that provably minimizes the L1-truncation error in the generalized labeled multi-Bernoulli posterior distribution. This criterion is used to construct a Gibbs sampler that produces a truncated measurement-generated labeled multi-Bernoulli birth distribution with quadratic complexity in the number of sensors. A closed form solution of the conditional sampling distribution assuming linear (or linearized) Gaussian likelihoods is provided, alongside an approximate solution using Monte Carlo importance sampling. Multiple simulation results are provided to verify the efficacy of the truncation criterion, as well as the reduction in complexity.      
### 16.Applications of Reconfigurable Intelligent Surface in Smart High Speed Train Communications  [ :arrow_down: ](https://arxiv.org/pdf/2109.04354.pdf)
>  Reconfigurable intelligent surface (RIS) is one of the most promising technologies for 5G-Adv and 6G. It has the characteristics of low cost, low complexity, and easy deployment, which provides a new opportunity to develop intelligent high-speed railway communications. The typical applications of RIS-assisted smart high-speed railway communications are introduced in detail, including suppressing the Doppler shift effect, solving frequent handoff problems, overcoming high penetration loss problems, and supporting high-precision train positioning. The key technologies of RIS-assisted smart high-speed railway communications are discussed in-depth, including channel measurement and modeling, channel estimation and feedback, beamforming, network architecture, and network deployment. It is believed that the combination of the new intelligent high-speed railway infrastructure and the new electromagnetic infrastructure built by RIS will bring broad industrial prospects to the intelligent high-speed railway in the future.      
### 17.PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery  [ :arrow_down: ](https://arxiv.org/pdf/2109.04352.pdf)
>  Correctly capturing intraoperative brain shift in image-guided neurosurgical procedures is a critical task for aligning preoperative data with intraoperative geometry, ensuring effective surgical navigation and optimal surgical precision. While the finite element method (FEM) is a proven technique to effectively approximate soft tissue deformation through biomechanical formulations, their degree of success boils down to a trade-off between accuracy and speed. To circumvent this problem, the most recent works in this domain have proposed leveraging data-driven models obtained by training various machine learning algorithms, e.g. random forests, artificial neural networks (ANNs), with the results of finite element analysis (FEA) to speed up tissue deformation approximations by prediction. These methods, however, do not account for the structure of the finite element (FE) mesh during training that provides information on node connectivities as well as the distance between them, which can aid with approximating tissue deformation based on the proximity of force load points with the rest of the mesh nodes. Therefore, this work proposes a novel framework, PhysGNN, a data-driven model that approximates the solution of FEA by leveraging graph neural networks (GNNs), which are capable of accounting for the mesh structural information and inductive learning over unstructured grids and complex topological structures. Empirically, we demonstrate that the proposed architecture, PhysGNN, promises accurate and fast soft tissue deformation approximations while remaining computationally feasible, suitable for neurosurgical settings.      
### 18.Robust single- and multi-loudspeaker least-squares-based equalization for hearing devices  [ :arrow_down: ](https://arxiv.org/pdf/2109.04241.pdf)
>  To improve the sound quality of hearing devices, equalization filters can be used that aim at achieving acoustic transparency, i.e., listening with the device in the ear is perceptually similar to the open ear. The equalization filter needs to ensure that the superposition of the equalized signal played by the device and the signal leaking through the device into the ear canal matches a processed version of the signal reaching the eardrum of the open ear. Depending on the processing delay of the hearing device, comb-filtering artifacts can occur due to this superposition, which may degrade the perceived sound quality. In this paper we propose a unified least-squares-based procedure to design single- and multi-loudspeaker equalization filters for hearing devices aiming at achieving acoustic transparency. To account for non-minimum phase components, we introduce a so-called acausality management. To reduce comb-filtering artifacts, we propose to use a frequency-dependent regularization. Experimental results using measured acoustic transfer functions from a multi-loudspeaker earpiece show that the proposed equalization filter design procedure enables to achieve robust acoustic transparency and reduces the impact of comb-filtering artifacts. A comparison between single- and multi-loudspeaker equalization shows that for both cases a robust equalization performance can be achieved for different desired open ear transfer functions.      
### 19.EEGDnet: Fusing Non-Local and Local Self-Similarity for 1-D EEG Signal Denoising with 2-D Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2109.04235.pdf)
>  Electroencephalogram (EEG) has shown a useful approach to produce a brain-computer interface (BCI). One-dimensional (1-D) EEG signal is yet easily disturbed by certain artifacts (a.k.a. noise) due to the high temporal resolution. Thus, it is crucial to remove the noise in received EEG signal. Recently, deep learning-based EEG signal denoising approaches have achieved impressive performance compared with traditional ones. It is well known that the characteristics of self-similarity (including non-local and local ones) of data (e.g., natural images and time-domain signals) are widely leveraged for denoising. However, existing deep learning-based EEG signal denoising methods ignore either the non-local self-similarity (e.g., 1-D convolutional neural network) or local one (e.g., fully connected network and recurrent neural network). To address this issue, we propose a novel 1-D EEG signal denoising network with 2-D transformer, namely EEGDnet. Specifically, we comprehensively take into account the non-local and local self-similarity of EEG signal through the transformer module. By fusing non-local self-similarity in self-attention blocks and local self-similarity in feed forward blocks, the negative impact caused by noises and outliers can be reduced significantly. Extensive experiments show that, compared with other state-of-the-art models, EEGDnet achieves much better performance in terms of both quantitative and qualitative metrics.      
### 20.Detection of Abrupt Change in Channel Covariance Matrix for Multi-Antenna Communication  [ :arrow_down: ](https://arxiv.org/pdf/2109.04192.pdf)
>  The knowledge of channel covariance matrices is of paramount importance to the estimation of instantaneous channels and the design of beamforming vectors in multi-antenna systems. In practice, an abrupt change in channel covariance matrices may occur due to the change in the environment and the user location. Although several works have proposed efficient algorithms to estimate the channel covariance matrices after any change occurs, how to detect such a change accurately and quickly is still an open problem in the literature. In this paper, we focus on channel covariance change detection between a multi-antenna base station (BS) and a single-antenna user equipment (UE). To provide theoretical performance limit, we first propose a genie-aided change detector based on the log-likelihood ratio (LLR) test assuming the channel covariance matrix after change is known, and characterize the corresponding missed detection and false alarm probabilities. Then, this paper considers the practical case where the channel covariance matrix after change is unknown. The maximum likelihood (ML) estimation technique is used to predict the covariance matrix based on the received pilot signals over a certain number of coherence blocks, building upon which the LLR-based change detector is employed. Numerical results show that our proposed scheme can detect the change with low error probability even when the number of channel samples is small such that the estimation of the covariance matrix is not that accurate. This result verifies the possibility to detect the channel covariance change both accurately and quickly in practice.      
### 21.Towards Fully Automated Segmentation of Rat Cardiac MRI by Leveraging Deep Learning Frameworks  [ :arrow_down: ](https://arxiv.org/pdf/2109.04188.pdf)
>  Automated segmentation of human cardiac magnetic resonance datasets has been steadily improving during recent years. However, these methods are not directly applicable in preclinical context due to limited datasets and lower image resolution. Successful application of deep architectures for rat cardiac segmentation, although of critical importance for preclinical evaluation of cardiac function, has to our knowledge not yet been reported. We developed segmentation models that expand on the standard U-Net architecture and evaluated separate models for systole and diastole phases, 2MSA, and one model for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a Gaussian Process (GP)-based prior to improve phase selection. Resulting models approach human performance in terms of left ventricular segmentation quality and ejection fraction (EF) estimation in both 1MSA and 2MSA settings (SÃ¸rensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA achieved a mean absolute difference between estimated and reference EF of 3.5 +/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to 1MSA allows to automate the selection of systole and diastole phases. Combined with a novel cardiac phase selection strategy, our work presents an important first step towards a fully automated segmentation pipeline in the context of rat cardiac analysis.      
### 22.Integrating Low-Complexity and Flexible Sensing into Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.04109.pdf)
>  Integrating sensing into standardized communication systems can potentially benefit many consumer applications that require both radio frequency functions. However, without an effective sensing method, such integration may not achieve the expected gains of cost and energy efficiency. Existing sensing methods, which use communication payload signals, either have limited sensing performance or suffer from high complexity. In this paper, we develop a novel and flexible sensing framework which has a complexity only dominated by a Fourier transform and also provides the flexibility in adapting for different sensing needs. We propose to segment a whole block of echo signal evenly into sub-blocks; adjacent ones are allowed to overlap. We design a virtual cyclic prefix (VCP) for each sub-block that allows us to employ two common ways of removing communication data symbols and generate two types of range-Doppler maps (RDMs) for sensing. We perform a comprehensive analysis of the signal components in the RDMs, proving that their interference-plus-noise (IN) terms are approximately Gaussian distributed. The statistical properties of the distributions are derived, which leads to the analytical comparisons between the two RDMs as well as between the prior and our sensing methods. Moreover, the impact of the lengths of sub-block, VCP and overlapping signal on sensing performance is analyzed. Criteria for designing these lengths for better sensing performance are also provided. Extensive simulations validate the superiority of the proposed sensing framework over prior methods in terms of signal-to-IN ratios in RDMs, detecting performance and flexibility.      
### 23.The IDLAB VoxCeleb Speaker Recognition Challenge 2021 System Description  [ :arrow_down: ](https://arxiv.org/pdf/2109.04070.pdf)
>  This technical report describes the IDLab submission for track 1 and 2 of the VoxCeleb Speaker Recognition Challenge 2021 (VoxSRC-21). This speaker verification competition focuses on short duration test recordings and cross-lingual trials. Currently, both Time Delay Neural Networks (TDNNs) and ResNets achieve state-of-the-art results in speaker verification. We opt to use a system fusion of hybrid architectures in our final submission. An ECAPA-TDNN baseline is enhanced with a 2D convolutional stem to transfer some of the strong characteristics of a ResNet based model to this hybrid CNN-TDNN architecture. Similarly, we incorporate absolute frequency positional information in the SE-ResNet architectures. All models are trained with a special mini-batch data sampling technique which constructs mini-batches with data that is the most challenging for the system on the level of intra-speaker variability. This intra-speaker variability is mainly caused by differences in language and background conditions between the speaker's utterances. The cross-lingual effects on the speaker verification scores are further compensated by introducing a binary cross-linguality trial feature in the logistic regression based system calibration. The final system fusion with two ECAPA CNN-TDNNs and three SE-ResNets enhanced with frequency positional information achieved a third place on the VoxSRC-21 leaderboard for both track 1 and 2 with a minDCF of 0.1291 and 0.1313 respectively.      
### 24.Stochastic Maximum-Likelihood DOA Estimation and Source Enumeration in the Presence of Nonuniform Noise  [ :arrow_down: ](https://arxiv.org/pdf/2109.04060.pdf)
>  In this paper, the problem of determining the number of signal sources impinging on an array of sensors and estimating their directions-of-arrival (DOAs) in the presence of spatially white nonuniform noise is considered. It is known that, in the case of nonuniform noise, the stochastic likelihood function cannot be concentrated with respect to the diagonal elements of noise covariance matrix. Therefore, the stochastic maximum-likelihood (SML) DOA estimation and source enumeration in the presence of nonuniform noise requires multidimensional search with very high computational complexity. Recently, two algorithms for estimating noise covariance matrix in the presence of nonuniform noise have been proposed in the literature. Using these new estimates of noise covariance matrix, an approach for obtaining the SML estimate of signal DOAs is proposed. In addition, new approaches are proposed for SML source enumeration with information criteria in the presence of nonuniform noise. The important feature of the proposed SML approaches for DOA estimation and source enumeration is that they have admissible computational complexity. In addition, some of them are robust against correlation between source signals. The performance of the proposed DOA estimation and source enumeration approaches are investigated using computer simulations.      
### 25.Learning Performance Bounds for Safety-Critical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.04026.pdf)
>  As the complexity of control systems increases, the need for systematic methods to guarantee their efficacy grows as well. However, direct testing of these systems is oftentimes costly, difficult, or impractical. As a result, the test and evaluation ideal would be to verify the efficacy of a system simulator and use this verification result to make a statement on true system performance. This paper formalizes that performance translation for a specific class of desired system behaviors. In that vein, our contribution is twofold. First, we detail a variant on existing Bayesian Optimization Algorithms that identifies minimal upper bounds to maximization problems, with some minimum probability. Second, we use this Algorithm to $i)$ lower bound the minimum simulator robustness and $ii)$ upper bound the expected deviance between true and simulated systems. Then, for the specific class of desired behaviors studied, we leverage these bounds to lower bound the minimum true system robustness, without directly testing the true system. Finally, we compare a high-fidelity ROS simulator of a Segway, with a significantly noisier version of itself, and show that our probabilistic verification bounds are indeed satisfied.      
### 26.Can a conventional optical camera realize turbulence-free imaging?  [ :arrow_down: ](https://arxiv.org/pdf/2109.03995.pdf)
>  Atmospheric turbulence is a serious problem for traditional optical imaging, especially for satellite and aircraft-to-ground imaging. Here, we report a novel and practical phenomenon in which turbulence-free images can be reconstructed on a conventional optical camera based on the accumulation of sunlight intensity and photon number fluctuation autocorrelation. Different from conventional ghost imaging, this method can obtain turbulence-free images, and its imaging speed is comparable to that of traditional optical imaging. Moreover, by adding photon number fluctuation autocorrelation algorithm software, almost all optical cameras, including mobile phone cameras, can realize this function without changing the structure of the original camera.      
### 27.A Novel Method to Estimate the Coordinates of LEDs in Wireless Optical Positioning Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.03990.pdf)
>  Traditional visible light positioning (VLP) systems estimate receivers' coordinates based on the known light-emitting diode (LED) coordinates. However, the LED coordinates are not always known accurately. Because of the structural changes of the buildings due to temperature, humidity or material aging, even measured by highly accurate laser range finders, the LED coordinates may change unpredictably. In this paper, we propose an easy and low-cost method to update the position information of the LEDs. We use two optical angle-of-arrival (AOA) estimators to detect the beam directions of the LEDs. Each AOA estimator has four differently oriented photodiodes (PDs). Considering the additive noises of the PDs, we derive the closed-form error expression for the proposed LED coordinates estimator. Both analytical and Monte Carlo experimental results show that the layout of the AOA estimators could affect the estimation error. These results may provide intuitive insights for the design of the optical indoor positioning systems.      
### 28.Learning-based Moving Horizon Estimation through Differentiable Convex Optimization Layers  [ :arrow_down: ](https://arxiv.org/pdf/2109.03962.pdf)
>  For control it is essential to obtain an accurate estimate of the current system state, based on uncertain sensor measurements and existing system knowledge. An optimization-based moving horizon estimation (MHE) approach uses a dynamical model of the system, and further allows to integrate physical constraints on system states and uncertainties, to obtain a trajectory of state estimates. In this work, we address the problem of state estimation in case of constrained linear systems with parametric uncertainty. The proposed approach makes use of differentiable convex optimization layers to formulate an MHE state estimator, for systems with uncertain parameters. This formulation allows us to obtain the gradient of a squared output error, based on sensor measurements and state estimates, with respect to the uncertain system parameters, and update the believe of the parameters online using stochastic gradient descent (SGD). In a numerical example of estimating temperatures of a group of manufacturing machines, we show the performance of learning the unknown system parameters and the benefits of integrating physical state constraints in the MHE formulation.      
### 29.A Generalized Theory of Power  [ :arrow_down: ](https://arxiv.org/pdf/2109.03907.pdf)
>  The complex representation of real-valued instantaneous power may be written as the sum of two complex powers, one Hermitian and the other non-Hermitian, or complementary. A virtue of this representation is that it consists of a power triangle rotating around a fixed phasor, thus clarifying what should be meant by the power triangle. The in-phase and quadrature components of complementary power encode for active and non-active power. When instantaneous power is defined for a Thevenin equivalent circuit, these are time-varying real and reactive power components. These claims hold for sinusoidal voltage and current, and for non-sinusoidal voltage and current. Spectral representations of Hermitian, complementary, and instantaneous power show that, frequency-by-frequency, these powers behave exactly as they behave in the single frequency sinusoidal case. Simple hardware diagrams show how instantaneous active and non-active power may be extracted from metered voltage and current, even in certain non-sinusoidal cases.      
### 30.Time-frequency analysis of microwave signals based on stimulated Brillouin scattering  [ :arrow_down: ](https://arxiv.org/pdf/2109.03904.pdf)
>  A novel photonic approach to the time-frequency analysis of microwave signals is proposed based on the stimulated Brillouin scattering (SBS)-assisted frequency-to-time mapping (FTTM). Two types of time-frequency analysis links, namely parallel SBS link and time-division SBS link are proposed. The parallel SBS link can be utilized to perform real-time time-frequency analysis of microwave signal, which provides a promising solution for real-time time-frequency analysis, especially when it is combined with the photonic integration technique. A simulation is made to verify its feasibility by analyzing signals in multiple formats. The time-division SBS link has a simpler and reconfigurable structure, which can realize an ultra-high-resolution time-frequency analysis for periodic signals using the time segmentation and accumulation technique. An experiment is performed for the time-division SBS link. The multi-dimensional reconfigurability of the system is experimentally studied. An analysis bandwidth of 3.9 GHz, an analysis frequency up to 20 GHz, and a frequency resolution of 15 MHz are demonstrated, respectively.      
### 31.Integrated and Adaptive Guidance and Control for Endoatmospheric Missiles via Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.03880.pdf)
>  We apply the meta reinforcement learning framework to optimize an integrated and adaptive guidance and flight control system for an air-to-air missile, implementing the system as a deep neural network (the policy). The policy maps observations directly to commanded rates of change for the missile's control surface deflections, with the observations derived with minimal processing from the computationally stabilized line of sight unit vector measured by a strap down seeker, estimated rotational velocity from rate gyros, and control surface deflection angles. The system induces intercept trajectories against a maneuvering target that satisfy control constraints on fin deflection angles, and path constraints on look angle and load. We test the optimized system in a six degrees-of-freedom simulator that includes a non-linear radome model and a strapdown seeker model. Through extensive simulation, we demonstrate that the system can adapt to a large flight envelope and off nominal flight conditions that include perturbation of aerodynamic coefficient parameters and center of pressure locations. Moreover, we find that the system is robust to the parasitic attitude loop induced by radome refraction, imperfect seeker stabilization, and sensor scale factor errors. Finally, we compare our system's performance to two benchmarks: a proportional navigation guidance system benchmark in a simplified 3-DOF environment, which we take as an upper bound on performance attainable with separate guidance and flight control systems, and a longitudinal model of proportional navigation coupled with a three loop autopilot. We find that our system moderately outperforms the former, and outperforms the latter by a large margin.      
### 32.Recurrent Neural Network Controllers Synthesis with Stability Guarantees for Partially Observed Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.03861.pdf)
>  Neural network controllers have become popular in control tasks thanks to their flexibility and expressivity. Stability is a crucial property for safety-critical dynamical systems, while stabilization of partially observed systems, in many cases, requires controllers to retain and process long-term memories of the past. We consider the important class of recurrent neural networks (RNN) as dynamic controllers for nonlinear uncertain partially-observed systems, and derive convex stability conditions based on integral quadratic constraints, S-lemma and sequential convexification. To ensure stability during the learning and control process, we propose a projected policy gradient method that iteratively enforces the stability conditions in the reparametrized space taking advantage of mild additional information on system dynamics. Numerical experiments show that our method learns stabilizing controllers while using fewer samples and achieving higher final performance compared with policy gradient.      
### 33.A deep learned nanowire segmentation model using synthetic data augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2109.04429.pdf)
>  Automatized object identification and feature analysis of experimental image data are indispensable for data-driven material science; deep-learning-based segmentation algorithms have been shown to be a promising technique to achieve this goal. However, acquiring high-resolution experimental images and assigning labels in order to train such algorithms is challenging and costly in terms of both time and labor. In the present work, we apply synthetic images, which resemble the experimental image data in terms of geometrical and visual features, to train state-of-art deep learning-based Mask R-CNN algorithms to segment vanadium pentoxide (V2O5) nanowires, a canonical cathode material, within optical intensity-based images from spectromicroscopy. The performance evaluation demonstrates that even though the deep learning model is trained on pure synthetically generated structures, it can segment real optical intensity-based spectromicroscopy images of complex V2O5 nanowire structures in overlapped particle networks, thus providing reliable statistical information. The model can further be used to segment nanowires in scanning electron microscopy (SEM) images, which are fundamentally different from the training dataset known to the model. The proposed methodology of using a purely synthetic dataset to train the deep learning model can be extended to any optical intensity-based images of variable particle morphology, extent of agglomeration, material class, and beyond.      
### 34.An Accelerated Proximal Gradient-based Robust Model Predictive Control Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2109.04405.pdf)
>  In this letter, an accelerated robust model predictive control (RMPC) algorithm for linear systems with additive disturbance is proposed based on the tube technique and the proximal gradient method. Our study consists of two parts. First, the tube cross sections are minimized in the RMPC objective, which make the description of the additive disturbance less conservative. Then, such RMPC problem is solved iteratively by a novel proximal gradient-based algorithm, which can accelerate the iteration convergence rate. A case study and several numerical experiments are provided to show the effectiveness of the proposed approach.      
### 35.UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2109.04335.pdf)
>  Most recent semantic segmentation methods adopt a U-Net framework with an encoder-decoder architecture. It is still challenging for U-Net with a simple skip connection scheme to model the global multi-scale context: 1) Not each skip connection setting is effective due to the issue of incompatible feature sets of encoder and decoder stage, even some skip connection negatively influence the segmentation performance; 2) The original U-Net is worse than the one without any skip connection on some datasets. Based on our findings, we propose a new segmentation framework, named UCTransNet (with a proposed CTrans module in U-Net), from the channel perspective with attention mechanism. Specifically, the CTrans module is an alternate of the U-Net skip connections, which consists of a sub-module to conduct the multi-scale Channel Cross fusion with Transformer (named CCT) and a sub-module Channel-wise Cross-Attention (named CCA) to guide the fused multi-scale channel-wise information to effectively connect to the decoder features for eliminating the ambiguity. Hence, the proposed connection consisting of the CCT and CCA is able to replace the original skip connection to solve the semantic gaps for an accurate automatic medical image segmentation. The experimental results suggest that our UCTransNet produces more precise segmentation performance and achieves consistent improvements over the state-of-the-art for semantic segmentation across different datasets and conventional architectures involving transformer or U-shaped framework. Code: <a class="link-external link-https" href="https://github.com/McGregorWwww/UCTransNet" rel="external noopener nofollow">this https URL</a>.      
### 36.Towards Robust Cross-domain Image Understanding with Unsupervised Noise Removal  [ :arrow_down: ](https://arxiv.org/pdf/2109.04284.pdf)
>  Deep learning models usually require a large amount of labeled data to achieve satisfactory performance. In multimedia analysis, domain adaptation studies the problem of cross-domain knowledge transfer from a label rich source domain to a label scarce target domain, thus potentially alleviates the annotation requirement for deep learning models. However, we find that contemporary domain adaptation methods for cross-domain image understanding perform poorly when source domain is noisy. Weakly Supervised Domain Adaptation (WSDA) studies the domain adaptation problem under the scenario where source data can be noisy. Prior methods on WSDA remove noisy source data and align the marginal distribution across domains without considering the fine-grained semantic structure in the embedding space, which have the problem of class misalignment, e.g., features of cats in the target domain might be mapped near features of dogs in the source domain. In this paper, we propose a novel method, termed Noise Tolerant Domain Adaptation, for WSDA. Specifically, we adopt the cluster assumption and learn cluster discriminatively with class prototypes in the embedding space. We propose to leverage the location information of the data points in the embedding space and model the location information with a Gaussian mixture model to identify noisy source data. We then design a network which incorporates the Gaussian mixture noise model as a sub-module for unsupervised noise removal and propose a novel cluster-level adversarial adaptation method which aligns unlabeled target data with the less noisy class prototypes for mapping the semantic structure across domains. We conduct extensive experiments to evaluate the effectiveness of our method on both general images and medical images from COVID-19 and e-commerce datasets. The results show that our method significantly outperforms state-of-the-art WSDA methods.      
### 37.An optimal decision support framework for vaccine distribution across a multi-tier cold chain network  [ :arrow_down: ](https://arxiv.org/pdf/2109.04204.pdf)
>  The importance of vaccination and the logistics involved in the procurement, storage and distribution of vaccines across their cold chain has come to the forefront during the COVID-19 pandemic. In this paper, we present a decision support framework for optimizing multiple aspects of vaccine distribution across a multi-tier cold chain network. We propose two multi-period optimization formulations within this framework: first to minimize inventory, ordering, transportation, personnel and shortage costs associated with a single vaccine; the second being an extension of the first for the case when multiple vaccines with differing efficacies and costs are available for the same disease. Vaccine transportation and administration lead times are also incorporated within the models. We use the case of the Indian state of Bihar and COVID-19 vaccines to illustrate the implementation of the framework. We present computational experiments to demonstrate: (a) the organization of the model outputs; (b) how the models can be used to assess the impact of storage capacities at the cold chain points, transportation vehicle capacities, and manufacturer capacities on the optimal vaccine distribution pattern; and (c) the impact of vaccine efficacies and associated costs such as ordering and transportation costs on the vaccine selection decision informed by the model. We then consider the computational expense of the framework for realistic problem instances, and suggest multiple preprocessing techniques to reduce their computational burden. Our study presents public health authorities and other stakeholders with a vaccine distribution and capacity planning tool for multi-tier cold chain networks.      
### 38.IMG2SMI: Translating Molecular Structure Images to Simplified Molecular-input Line-entry System  [ :arrow_down: ](https://arxiv.org/pdf/2109.04202.pdf)
>  Like many scientific fields, new chemistry literature has grown at a staggering pace, with thousands of papers released every month. A large portion of chemistry literature focuses on new molecules and reactions between molecules. Most vital information is conveyed through 2-D images of molecules, representing the underlying molecules or reactions described. In order to ensure reproducible and machine-readable molecule representations, text-based molecule descriptors like SMILES and SELFIES were created. These text-based molecule representations provide molecule generation but are unfortunately rarely present in published literature. In the absence of molecule descriptors, the generation of molecule descriptors from the 2-D images present in the literature is necessary to understand chemistry literature at scale. Successful methods such as Optical Structure Recognition Application (OSRA), and ChemSchematicResolver are able to extract the locations of molecules structures in chemistry papers and infer molecular descriptions and reactions. While effective, existing systems expect chemists to correct outputs, making them unsuitable for unsupervised large-scale data mining. Leveraging the task formulation of image captioning introduced by DECIMER, we introduce IMG2SMI, a model which leverages Deep Residual Networks for image feature extraction and an encoder-decoder Transformer layers for molecule description generation. Unlike previous Neural Network-based systems, IMG2SMI builds around the task of molecule description generation, which enables IMG2SMI to outperform OSRA-based systems by 163% in molecule similarity prediction as measured by the molecular MACCS Fingerprint Tanimoto Similarity. Additionally, to facilitate further research on this task, we release a new molecule prediction dataset. including 81 million molecules for molecule description generation      
### 39.Novel Time Domain Based Upper-Limb Prosthesis Control using Incremental Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2109.04194.pdf)
>  The upper limb of the body is a vital for various kind of activities for human. The complete or partial loss of the upper limb would lead to a significant impact on daily activities of the amputees. EMG carries important information of human physique which helps to decode the various functionalities of human arm. EMG signal based bionics and prosthesis have gained huge research attention over the past decade. Conventional EMG-PR based prosthesis struggles to give accurate performance due to off-line training used and incapability to compensate for electrode position shift and change in arm position. This work proposes online training and incremental learning based system for upper limb prosthetic application. This system consists of ADS1298 as AFE (analog front end) and a 32 bit arm cortex-m4 processor for DSP (digital signal processing). The system has been tested for both intact and amputated subjects. Time derivative moment based features have been implemented and utilized for effective pattern classification. Initially, system have been trained for four classes using the on-line training process later on the number of classes have been incremented on user demand till eleven, and system performance has been evaluated. The system yielded a completion rate of 100% for healthy and amputated subjects when four motions have been considered. Further 94.33% and 92% completion rate have been showcased by the system when the number of classes increased to eleven for healthy and amputees respectively. The motion efficacy test is also evaluated for all the subjects. The highest efficacy rate of 91.23% and 88.64% are observed for intact and amputated subjects respectively.      
### 40.Safe, Deterministic Trajectory Planning for Unstructured and Partially Occluded Environments  [ :arrow_down: ](https://arxiv.org/pdf/2109.04175.pdf)
>  Ensuring safe behavior for automated vehicles in unregulated traffic areas poses a complex challenge for the industry. It is an open problem to provide scalable and certifiable solutions to this challenge. We derive a trajectory planner based on model predictive control which interoperates with a monitoring system for pedestrian safety based on cellular automata. The combined planner-monitor system is demonstrated on the example of a narrow indoor parking environment. The system features deterministic behavior, mitigating the immanent risk of black boxes and offering full certifiability. By using fundamental and conservative prediction models of pedestrians the monitor is able to determine a safe drivable area in the partially occluded and unstructured parking environment. The information is fed to the trajectory planner which ensures the vehicle remains in the safe drivable area at any time through constrained optimization. We show how the approach enables solving plenty of situations in tight parking garage scenarios. Even though conservative prediction models are applied, evaluations indicate a performant system for the tested low-speed navigation.      
### 41.Machine Learning-Enabled Data Rate Prediction for 5G NSA Vehicle-to-Cloud Communications  [ :arrow_down: ](https://arxiv.org/pdf/2109.04117.pdf)
>  In order to satisfy the ever-growing Quality of Service (QoS) requirements of innovative services, cellular communication networks are constantly evolving. Recently, the 5G NonStandalone (NSA) mode has been deployed as an intermediate strategy to deliver high-speed connectivity to early adopters of 5G by incorporating Long Term Evolution (LTE) network infrastructure. In addition to the technological advancements, novel communication paradigms such as anticipatory mobile networking aim to achieve a more intelligent usage of the available network resources through exploitation of context knowledge. For this purpose, novel methods for proactive prediction of the end-to-end behavior are seen as key enablers. In this paper, we present a first empirical analysis of client-based end-to-end data rate prediction for 5G NSA vehicle-to-cloud communications. Although this operation mode is characterized by massive fluctuations of the observed data rate, the results show that conventional machine learning methods can utilize locally acquirable measurements for achieving comparably accurate estimations of the end-to-end behavior.      
### 42.Risk-Averse Decision Making Under Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2109.04082.pdf)
>  A large class of decision making under uncertainty problems can be described via Markov decision processes (MDPs) or partially observable MDPs (POMDPs), with application to artificial intelligence and operations research, among others. Traditionally, policy synthesis techniques are proposed such that a total expected cost or reward is minimized or maximized. However, optimality in the total expected cost sense is only reasonable if system behavior in the large number of runs is of interest, which has limited the use of such policies in practical mission-critical scenarios, wherein large deviations from the expected behavior may lead to mission failure. In this paper, we consider the problem of designing policies for MDPs and POMDPs with objectives and constraints in terms of dynamic coherent risk measures, which we refer to as the constrained risk-averse problem. For MDPs, we reformulate the problem into a infsup problem via the Lagrangian framework and propose an optimization-based method to synthesize Markovian policies. For MDPs, we demonstrate that the formulated optimization problems are in the form of difference convex programs (DCPs) and can be solved by the disciplined convex-concave programming (DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. For POMDPs, we show that, if the coherent risk measures can be defined as a Markov risk transition mapping, an infinite-dimensional optimization can be used to design Markovian belief-based policies. For stochastic finite-state controllers (FSCs), we show that the latter optimization simplifies to a (finite-dimensional) DCP and can be solved by the DCCP framework. We incorporate these DCPs in a policy iteration algorithm to design risk-averse FSCs for POMDPs.      
### 43.DeepEMO: Deep Learning for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2109.04081.pdf)
>  We proposed the industry level deep learning approach for speech emotion recognition task. In industry, carefully proposed deep transfer learning technology shows real results due to mostly low amount of training data availability, machine training cost, and specialized learning on dedicated AI tasks. The proposed speech recognition framework, called DeepEMO, consists of two main pipelines such that preprocessing to extract efficient main features and deep transfer learning model to train and recognize. Main source code is in <a class="link-external link-https" href="https://github.com/enkhtogtokh/deepemo" rel="external noopener nofollow">this https URL</a> repository      
### 44.BeamTransformer: Microphone Array-based Overlapping Speech Detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.04049.pdf)
>  We propose BeamTransformer, an efficient architecture to leverage beamformer's edge in spatial filtering and transformer's capability in context sequence modeling. BeamTransformer seeks to optimize modeling of sequential relationship among signals from different spatial direction. Overlapping speech detection is one of the tasks where such optimization is favorable. In this paper we effectively apply BeamTransformer to detect overlapping segments. Comparing to single-channel approach, BeamTransformer exceeds in learning to identify the relationship among different beam sequences and hence able to make predictions not only from the acoustic signals but also the localization of the source. The results indicate that a successful incorporation of microphone array signals can lead to remarkable gains. Moreover, BeamTransformer takes one step further, as speech from overlapped speakers have been internally separated into different beams.      
### 45.Multilingual Speech Recognition for Low-Resource Indian Languages using Multi-Task conformer  [ :arrow_down: ](https://arxiv.org/pdf/2109.03969.pdf)
>  Transformers have recently become very popular for sequence-to-sequence applications such as machine translation and speech recognition. In this work, we propose a multi-task learning-based transformer model for low-resource multilingual speech recognition for Indian languages. Our proposed model consists of a conformer [1] encoder and two parallel transformer decoders. We use a phoneme decoder (PHN-DEC) for the phoneme recognition task and a grapheme decoder (GRP-DEC) to predict grapheme sequence. We consider the phoneme recognition task as an auxiliary task for our multi-task learning framework. We jointly optimize the network for both phoneme and grapheme recognition tasks using Joint CTC-Attention [2] training. We use a conditional decoding scheme to inject the language information into the model before predicting the grapheme sequence. Our experiments show that our proposed approach can obtain significant improvement over previous approaches [4]. We also show that our conformer-based dual-decoder approach outperforms both the transformer-based dual-decoder approach and single decoder approach. Finally, We compare monolingual ASR models with our proposed multilingual ASR approach.      
### 46.Moving Object Detection for Event-based Vision using k-means Clustering  [ :arrow_down: ](https://arxiv.org/pdf/2109.01879.pdf)
>  Moving object detection is a crucial task in computer vision. Event-based cameras are bio-inspired cameras that work by mimicking the working of the human eye. These cameras have multiple advantages over conventional frame-based cameras, like reduced latency, HDR, reduced motion blur during high motion, low power consumption, etc. However, these advantages come at a high cost, as event-based cameras are noise sensitive and have low resolution. Moreover, the task of moving object detection in these cameras is difficult, as event-based sensors capture only the binary changes in brightness of a scene, lacking useful visual features like texture and color. In this paper, we investigate the application of the k-means clustering technique in detecting moving objects in event-based data. Experimental results in publicly available datasets using k-means show significant improvement in performance over the state-of-the-art methods.      
