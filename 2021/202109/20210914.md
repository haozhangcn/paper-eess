# ArXiv eess --Tue, 14 Sep 2021
### 1.Blood vessel segmentation in en-face OCTA images: a frequency based method  [ :arrow_down: ](https://arxiv.org/pdf/2109.06116.pdf)
>  Optical coherence tomography angiography (OCTA) is a novel noninvasive imaging modality for visualization of retinal blood flow in the human retina. Using specific OCTA imaging biomarkers for the identification of pathologies, automated image segmentations of the blood vessels can improve subsequent analysis and diagnosis. We present a novel method for the vessel identification based on frequency representations of the image, in particular, using so-called Gabor filter banks. The algorithm is evaluated on an OCTA image data set from $10$ eyes acquired by a Cirrus HD-OCT device. The segmentation outcomes received very good qualitative visual evaluation feedback and coincide well with device-specific values concerning vessel density. Concerning locality our segmentations are even more reliable and accurate. Therefore, we suggest the computation of adaptive local vessel density maps that allow straightforward analysis of retinal blood flow.      
### 2.Challenging Current Semi-Supervised Anomaly Segmentation Methods for Brain MRI  [ :arrow_down: ](https://arxiv.org/pdf/2109.06023.pdf)
>  In this work, we tackle the problem of Semi-Supervised Anomaly Segmentation (SAS) in Magnetic Resonance Images (MRI) of the brain, which is the task of automatically identifying pathologies in brain images. Our work challenges the effectiveness of current Machine Learning (ML) approaches in this application domain by showing that thresholding Fluid-attenuated inversion recovery (FLAIR) MR scans provides better anomaly segmentation maps than several different ML-based anomaly detection models. Specifically, our method achieves better Dice similarity coefficients and Precision-Recall curves than the competitors on various popular evaluation data sets for the segmentation of tumors and multiple sclerosis lesions.      
### 3.Studying squeeze-and-excitation used in CNN for speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2109.05977.pdf)
>  In speaker verification, the extraction of voice representations is mainly based on the Residual Neural Network (ResNet) architecture. ResNet is built upon convolution layers which learn filters to capture local spatial patterns along all the input, then generate feature maps that jointly encode the spatial and channel information. Unfortunately, all feature maps in a convolution layer are learnt independently (the convolution layer does not exploit the dependencies between feature maps) and locally. This problem has first been tackled in image processing. A channel attention mechanism, called squeeze-and-excitation (SE), has recently been proposed in convolution layers and applied to speaker verification. This mechanism re-weights the information extracted across features maps. In this paper, we first propose an original qualitative study about the influence and the role of the SE mechanism applied to the speaker verification task at different stages of the ResNet, and then evaluate several SE architectures. We finally propose to improve the SE approach with a new pool- ing variant based on the concatenation of mean- and standard- deviation-pooling. Results showed that applying SE only on the first stages of the ResNet allows to better capture speaker information for the verification task, and that significant discrimination gains on Voxceleb1-E, Voxceleb1-H and SITW evaluation tasks have been noted using the proposed pooling variant.      
### 4.Distributed Control of Descriptor Networks: A Convex Procedure for Augmented Sparsity  [ :arrow_down: ](https://arxiv.org/pdf/2109.05954.pdf)
>  For networks of interconnected systems, which are not restricted to having strictly proper or even proper transfer function matrices, we present a design framework which enables $\mathcal{H}_\infty$ optimization, while also imposing sparsity constraints on the controller's coprime factors. We propose a convex and iterative optimization procedure with guaranteed convergence to obtain the aforementioned distributed controllers. By exploiting the robustness-oriented nature of the approach, we discuss the means by which to ensure sparse representations for our control law which are not supported by the network's nominal model.      
### 5.Beamformer Design and Optimization for Full-Duplex Joint Communication and Sensing at mm-Waves  [ :arrow_down: ](https://arxiv.org/pdf/2109.05932.pdf)
>  In this article, we study the joint communication and sensing (JCAS) paradigm in the context of millimeter-wave (mm-wave) mobile communication networks. We specifically address the JCAS challenges stemming from the full-duplex operation and from the co-existence of multiple simultaneous beams for communications and sensing purposes. To this end, we first formulate and solve beamforming optimization problems for hybrid beamforming based multiuser multiple-input and multiple-output JCAS systems. The cost function to be maximized is the beamformed power at the sensing direction while constraining the beamformed power at the communications directions, suppressing interuser interference and cancelling full-duplexing related self-interference (SI). We then also propose new transmitter and receiver beamforming solutions for purely analog beamforming based JCAS systems that maximize the beamforming gain at the sensing direction while controlling the beamformed power at the communications direction(s), cancelling the SI as well as eliminating the potential reflection from the communication direction and optimizing the combined radar pattern (CRP). Both closed-form and numerical optimization based formulations are provided. We analyze and evaluate the performance through extensive simulations, and show that substantial gains and benefits in terms of radar transmit gain, CRP, and SI suppression can be achieved with the proposed beamforming methods.      
### 6.Low-Light Image Enhancement with Normalizing Flow  [ :arrow_down: ](https://arxiv.org/pdf/2109.05923.pdf)
>  To enhance low-light images to normally-exposed ones is highly ill-posed, namely that the mapping relationship between them is one-to-many. Previous works based on the pixel-wise reconstruction losses and deterministic processes fail to capture the complex conditional distribution of normally exposed images, which results in improper brightness, residual noise, and artifacts. In this paper, we investigate to model this one-to-many relationship via a proposed normalizing flow model. An invertible network that takes the low-light images/features as the condition and learns to map the distribution of normally exposed images into a Gaussian distribution. In this way, the conditional distribution of the normally exposed images can be well modeled, and the enhancement process, i.e., the other inference direction of the invertible network, is equivalent to being constrained by a loss function that better describes the manifold structure of natural images during the training. The experimental results on the existing benchmark datasets show our method achieves better quantitative and qualitative results, obtaining better-exposed illumination, less noise and artifact, and richer colors.      
### 7.List-encoding CCDM: A Nonlinearity-tolerant Shaper Aided by Energy Dispersion Index  [ :arrow_down: ](https://arxiv.org/pdf/2109.05905.pdf)
>  Recently, a metric called energy dispersion index (EDI) was proposed to indicate the nonlinear interference (NLI) induced by correlated symbols during optical transmission. In this paper, we propose a new shaper architecture to decrease the EDI of transmitted symbols and thus, increase the signal-to-noise ratio (SNR). We call this shaper the list-encoding constant-composition distribution matcher (L-CCDM). L-CCDM consists of an additional EDI selecting module, which is compatible with standard probabilistic amplitude shaping (PAS) architecture. Numerical results obtained from a multi-span multi-channel system show that when compared to standard CCDM with 256-ary quadrature amplitude modulation (256QAM), the proposed architecture offers an effective SNR gain of 0.35 dB, an achievable information rate gain of 0.22 bit/4D-symbol, or equivalently an 8% reach extension.      
### 8.WeakSTIL: Weak whole-slide image level stromal tumor infiltrating lymphocyte scores are all you need  [ :arrow_down: ](https://arxiv.org/pdf/2109.05892.pdf)
>  We present WeakSTIL, an interpretable two-stage weak label deep learning pipeline for scoring the percentage of stromal tumor infiltrating lymphocytes (sTIL%) in H&amp;E-stained whole-slide images (WSIs) of breast cancer tissue. The sTIL% score is a prognostic and predictive biomarker for many solid tumor types. However, due to the high labeling efforts and high intra- and interobserver variability within and between expert annotators, this biomarker is currently not used in routine clinical decision making. WeakSTIL compresses tiles of a WSI using a feature extractor pre-trained with self-supervised learning on unlabeled histopathology data and learns to predict precise sTIL% scores for each tile in the tumor bed by using a multiple instance learning regressor that only requires a weak WSI-level label. By requiring only a weak label, we overcome the large annotation efforts required to train currently existing TIL detection methods. We show that WeakSTIL is at least as good as other TIL detection methods when predicting the WSI-level sTIL% score, reaching a coefficient of determination of $0.45\pm0.15$ when compared to scores generated by an expert pathologist, and an AUC of $0.89\pm0.05$ when treating it as the clinically interesting sTIL-high vs sTIL-low classification task. Additionally, we show that the intermediate tile-level predictions of WeakSTIL are highly interpretable, which suggests that WeakSTIL pays attention to latent features related to the number of TILs and the tissue type. In the future, WeakSTIL may be used to provide consistent and interpretable sTIL% predictions to stratify breast cancer patients into targeted therapy arms.      
### 9.Closed-Loop Neural Prostheses with On-Chip Intelligence: A Review and A Low-Latency Machine Learning Model for Brain State Detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.05848.pdf)
>  The application of closed-loop approaches in systems neuroscience and therapeutic stimulation holds great promise for revolutionizing our understanding of the brain and for developing novel neuromodulation therapies to restore lost functions. Neural prostheses capable of multi-channel neural recording, on-site signal processing, rapid symptom detection, and closed-loop stimulation are critical to enabling such novel treatments. However, the existing closed-loop neuromodulation devices are too simplistic and lack sufficient on-chip processing and intelligence. In this paper, we first discuss both commercial and investigational closed-loop neuromodulation devices for brain disorders. Next, we review state-of-the-art neural prostheses with on-chip machine learning, focusing on application-specific integrated circuits (ASIC). System requirements, performance and hardware comparisons, design trade-offs, and hardware optimization techniques are discussed. To facilitate a fair comparison and guide design choices among various on-chip classifiers, we propose a new energy-area (E-A) efficiency figure of merit that evaluates hardware efficiency and multi-channel scalability. Finally, we present several techniques to improve the key design metrics of tree-based on-chip classifiers, both in the context of ensemble methods and oblique structures.      
### 10.IceNet for Interactive Contrast Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2109.05838.pdf)
>  A CNN-based interactive contrast enhancement algorithm, called IceNet, is proposed in this work, which enables a user to adjust image contrast easily according to his or her preference. Specifically, a user provides a parameter for controlling the global brightness and two types of scribbles to darken or brighten local regions in an image. Then, given these annotations, IceNet estimates a gamma map for the pixel-wise gamma correction. Finally, through color restoration, an enhanced image is obtained. The user may provide annotations iteratively to obtain a satisfactory image. IceNet is also capable of producing a personalized enhanced image automatically, which can serve as a basis for further adjustment if so desired. Moreover, to train IceNet effectively and reliably, we propose three differentiable losses. Extensive experiments show that IceNet can provide users with satisfactorily enhanced images.      
### 11.Error performance analysis of different modulations over TWDP fading channel  [ :arrow_down: ](https://arxiv.org/pdf/2109.05825.pdf)
>  Two-wave with diffuse power (TWDP) is one of the most promising distribution for description of a small-scale fading in the emerging mmWave band. However, traditional error performance analysis in these channels faces two fundamental issues. It is mostly based on conventional TWDP parameterization which is not in accordance with the model's underlying physical mechanisms and which hinders accurate observation of the impact of a model parameters on a system's performance metrics. In addition, the existing average bit/symbol error probability (ABEP/ASEP) expressions for most modulations and diversity schemes are available as approximations, which are accurate only for specific combinations of TWDP parameters. Accordingly, in this paper, the exact ASEP expressions are derived for M-ary rectangular quadrature amplitude modulation (RQAM) with coherent detection and for M-ary DPSK modulation, and are given in terms of physically justified parameters. Besides, in order to relax computational complexity of proposed exact ASEPs in high signal-to-noise ratio (SNR) region, their asymptotic counterparts are derived as the simple closed-form expressions, matching the exact ones for SNR&gt;30dB. Results are verified by Monte-Carlo simulation.      
### 12.Self supervised learning improves dMMR/MSI detection from histology slides across multiple cancers  [ :arrow_down: ](https://arxiv.org/pdf/2109.05819.pdf)
>  Microsatellite instability (MSI) is a tumor phenotype whose diagnosis largely impacts patient care in colorectal cancers (CRC), and is associated with response to immunotherapy in all solid tumors. Deep learning models detecting MSI tumors directly from H&amp;E stained slides have shown promise in improving diagnosis of MSI patients. Prior deep learning models for MSI detection have relied on neural networks pretrained on ImageNet dataset, which does not contain any medical image. In this study, we leverage recent advances in self-supervised learning by training neural networks on histology images from the TCGA dataset using MoCo V2. We show that these networks consistently outperform their counterparts pretrained using ImageNet and obtain state-of-the-art results for MSI detection with AUCs of 0.92 and 0.83 for CRC and gastric tumors, respectively. These models generalize well on an external CRC cohort (0.97 AUC on PAIP) and improve transfer from one organ to another. Finally we show that predictive image regions exhibit meaningful histological patterns, and that the use of MoCo features highlighted more relevant patterns according to an expert pathologist.      
### 13.PyProD: A Machine Learning-Friendly Platform for Protection Analytics in Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.05802.pdf)
>  This paper introduces PyProD, a Python-based machine learning (ML)-compatible test-bed for evaluating the efficacy of protection schemes in electric distribution grids. This testbed is designed to bridge the gap between conventional power distribution grid analysis and growing capability of ML-based decision making algorithms, in particular in the context of protection system design and configuration. PyProD is shown to be capable of facilitating efficient design and evaluation of ML-based decision making algorithms for protection devices in the future electric distribution grid, in which many distributed energy resources and pro-sumers permeate the system.      
### 14.A distributed framework for linear adaptive MPC  [ :arrow_down: ](https://arxiv.org/pdf/2109.05777.pdf)
>  Adaptive model predictive control (MPC) robustly ensures safety while reducing uncertainty during operation. In this paper, a distributed version is proposed to deal with network systems featuring multiple agents and limited communication. To solve the problem in a distributed manner, structure is imposed on the control design ingredients without sacrificing performance. Decentralized and distributed adaptation schemes that allow for a reduction of the uncertainty online compatibly with the network topology are also proposed. The algorithm ensures robust constraint satisfaction, recursive feasibility and finite gain $\ell_2$ stability, and yields lower closed-loop cost compared to robust distributed MPC in simulations.      
### 15.Frequency Response Data Based LPV Controller Synthesis Applied to a Control Moment Gyroscope  [ :arrow_down: ](https://arxiv.org/pdf/2109.05774.pdf)
>  Control of systems with operating condition-dependent dynamics, including control moment gyroscopes, often requires operating condition-dependent controllers to achieve high control performance. The aim of this paper is to develop a frequency response data-driven linear parameter-varying control design approach for single-input single-output systems, which allows improved performance for a control moment gyroscope. A stability theory using closed-loop frequency response function data is developed, which is subsequently used in a synthesis procedure that guarantees local stability and performance. Experimental results on a control moment gyroscope demonstrate the performance improvements.      
### 16.Storage and Transmission Capacity Requirements of a Remote Solar Power Generation System  [ :arrow_down: ](https://arxiv.org/pdf/2109.05766.pdf)
>  Large solar power stations usually locate in remote areas and connect to the main grid via a long transmission line. Energy storage unit is deployed locally with the solar plant to smooth its output. Capacities of the grid-connection transmission line and the energy storage unit have a significant impact on the utilization rate of solar energy, as well as the investment cost. This paper characterizes the feasible set of capacity parameters under a given solar spillage rate and a fixed investment budget. A linear programming based projection algorithm is proposed to obtain such a feasible set, offering valuable references for system planning and policy making.      
### 17.Performance of UAV assisted Multiuser Terrestrial-Satellite Communication System over Mixed FSO/RF Channels  [ :arrow_down: ](https://arxiv.org/pdf/2109.05762.pdf)
>  In this work, performance of a multi-antenna multiuser unmanned aerial vehicle (UAV) assisted terrestrial-satellite communication system over mixed free space optics (FSO)/ radio frequency (RF) channels is analyzed. Downlink transmission from the satellite to the UAV is completed through FSO link which follows Gamma-Gamma distribution with pointing error impairments. Both the heterodyne detection and intensity modulation direct detection techniques are considered at the FSO receiver. To avail the antenna diversity, multiple transmit antennas are considered at the UAV. Selective decode-and-forward scheme is assumed at the UAV and opportunistic user scheduling is performed while considering the practical constraints of outdated channel state information (CSI) during the user selection and transmission phase. The RF links are assumed to follow Nakagami-m distribution due to its versatile nature. In this context, for the performance analysis, analytical expressions of outage probability, asymptotic outage probability, ergodic capacity, effective capacity, and generalized average symbol-error-rate expressions of various quadrature amplitude modulation (QAM) schemes such as hexagonal-QAM, cross-QAM, and rectangular QAM are derived. A comparison of various modulation schemes is presented. Further, the impact of pointing error, number of antennas, delay constraint, fading severity, and imperfect CSI are highlighted on the system performance. Finally, all the analytical results are verified through the Monte-Carlo simulations.      
### 18.A Novel Solution for Uu Interface Based C-V2X  [ :arrow_down: ](https://arxiv.org/pdf/2109.05684.pdf)
>  After 20 years of development, V2X has been facing industrialization challenges from DSRC to C-V2X. On the one hand, the new requirements for spectrum, chips, equipment, and networks introduced by the PC5 interface have caused high technical barriers to industrialization. On the other hand, the penetration rate of V2X terminals, application ecology and business models are difficult to implement in industrialization. Aiming at the Uu interface based C-V2X solution (UC-V2X), this paper introduces a risk filtering algorithm through the V2X levels of capability, and proposes a software-defined C-V2X solution (SUC-V2X), which systematically solves the C-V2X problems of industrialization. This paper further preliminarily verifies the performance of SUC-V2X.      
### 19.Multi-User Scheduling in Hybrid Millimeter Wave Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.05681.pdf)
>  While mmWave bands provide a large bandwidth for mobile broadband services, they suffer from severe path loss and shadowing. Multiple-antenna techniques such as beamforming (BF) can be applied to compensate the signal attenuation. We consider a special case of hybrid BF called per-stream hybrid BF (PSHBF) which is easier to implement than the general hybrid BF because it circumvents the need for joint analog-digital beamformer optimization. Employing BF at the base station enables the transmission of multiple data streams to several users in the same resource block. In this paper, we provide an offline study of proportional fair multi-user scheduling in a mmWave system with PSHBF to understand the impact of various system parameters on the performance. We formulate multi-user scheduling as an optimization problem. To tackle the non-convexity, we provide a feasible solution and show through numerical examples that the performance of the provided solution is very close to an upper-bound. Using this framework, we provide extensive numerical investigations revealing several engineering insights.      
### 20.Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05676.pdf)
>  The domain gap caused mainly by variable medical image quality renders a major obstacle on the path between training a segmentation model in the lab and applying the trained model to unseen clinical data. To address this issue, domain generalization methods have been proposed, which however usually use static convolutions and are less flexible. In this paper, we propose a multi-source domain generalization model, namely domain and content adaptive convolution (DCAC), for medical image segmentation. Specifically, we design the domain adaptive convolution (DAC) module and content adaptive convolution (CAC) module and incorporate both into an encoder-decoder backbone. In the DAC module, a dynamic convolutional head is conditioned on the predicted domain code of the input to make our model adapt to the unseen target domain. In the CAC module, a dynamic convolutional head is conditioned on the global image features to make our model adapt to the test image. We evaluated the DCAC model against the baseline and four state-of-the-art domain generalization methods on the prostate segmentation, COVID-19 lesion segmentation, and optic cup/optic disc segmentation tasks. Our results indicate that the proposed DCAC model outperforms all competing methods on each segmentation task, and also demonstrate the effectiveness of the DAC and CAC modules.      
### 21.Real-Time EMG Signal Classification via Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.05674.pdf)
>  Real-time classification of Electromyography signals is the most challenging part of controlling a prosthetic hand. Achieving a high classification accuracy of EMG signals in a short delay time is still challenging. Recurrent neural networks (RNNs) are artificial neural network architectures that are appropriate for sequential data such as EMG. In this paper, after extracting features from a hybrid time-frequency domain (discrete Wavelet transform), we utilize a set of recurrent neural network-based architectures to increase the classification accuracy and reduce the prediction delay time. The performances of these architectures are compared and in general outperform other state-of-the-art methods by achieving 96% classification accuracy in 600 msec.      
### 22.Successive Convex Approximation for Phase Retrieval with Dictionary Learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.05646.pdf)
>  Phase retrieval aims at reconstructing unknown signals from magnitude measurements of linear mixtures. In this paper, we consider the phase retrieval with dictionary learning problem, which includes an additional prior information that the measured signal admits a sparse representation over an unknown dictionary. The task is to jointly estimate the dictionary and the sparse representation from magnitude-only measurements. To this end, we study two complementary formulations and propose efficient parallel algorithms based on the successive convex approximation framework. The first algorithm is termed compact-SCAphase and is preferable in the case of less diverse mixture models. It employs a compact formulation that avoids the use of auxiliary variables. The proposed algorithm is highly scalable and has reduced parameter tuning cost. The second algorithm, referred to as SCAphase, uses auxiliary variables and is favorable in the case of highly diverse mixture models. It also renders simple incorporation of additional side constraints. The performance of both methods is evaluated when applied to blind sparse channel estimation from subband magnitude measurements in a multi-antenna random access network. Simulation results demonstrate the efficiency of the proposed techniques compared to state-of-the-art methods.      
### 23.Differential Diagnosis of Frontotemporal Dementia and Alzheimer's Disease using Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2109.05627.pdf)
>  Frontotemporal dementia and Alzheimer's disease are two common forms of dementia and are easily misdiagnosed as each other due to their similar pattern of clinical symptoms. Differentiating between the two dementia types is crucial for determining disease-specific intervention and treatment. Recent development of Deep-learning-based approaches in the field of medical image computing are delivering some of the best performance for many binary classification tasks, although its application in differential diagnosis, such as neuroimage-based differentiation for multiple types of dementia, has not been explored. In this study, a novel framework was proposed by using the Generative Adversarial Network technique to distinguish FTD, AD and normal control subjects, using volumetric features extracted at coarse-to-fine structural scales from Magnetic Resonance Imaging scans. Experiments of 10-folds cross-validation on 1,954 images achieved high accuracy. With the proposed framework, we have demonstrated that the combination of multi-scale structural features and synthetic data augmentation based on generative adversarial network can improve the performance of challenging tasks such as differentiating Dementia sub-types.      
### 24.A Joint Graph and Image Convolution Network for Automatic Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05580.pdf)
>  We present a joint graph convolution-image convolution neural network as our submission to the Brain Tumor Segmentation (BraTS) 2021 challenge. We model each brain as a graph composed of distinct image regions, which is initially segmented by a graph neural network (GNN). Subsequently, the tumorous volume identified by the GNN is further refined by a simple (voxel) convolutional neural network (CNN), which produces the final segmentation. This approach captures both global brain feature interactions via the graphical representation and local image details through the use of convolutional filters. We find that the GNN component by itself can effectively identify and segment the brain tumors. The addition of the CNN further improves the median performance of the model by 2 percent across all metrics evaluated. On the validation set, our joint GNN-CNN model achieves mean Dice scores of 0.89, 0.81, 0.73 and mean Hausdorff distances (95th percentile) of 6.8, 12.6, 28.2mm on the whole tumor, core tumor, and enhancing tumor, respectively.      
### 25.A Priority-Aware Replanning and Resequencing Framework for Coordination of Connected and Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2109.05573.pdf)
>  Deploying optimal control strategies for coordination of connected and automated vehicles (CAVs) often requires re-evaluating the strategies in order to respond to unexpected changes in the presence of disturbances and uncertainties. In this paper, we first extend a decentralized framework that we developed earlier for coordination of CAVs at a signal-free intersection to incorporate replanning. Then, we further enhance the framework by introducing a priority-aware resequencing mechanism which designates the order of decision making of CAVs based on theory from the job-shop scheduling problem. Our enhanced framework relaxes the first-come-first-serve decision order which has been used extensively in these problems. We illustrate the effectiveness of our proposed approach through several numerical simulations.      
### 26.Modeling of A Realistic DC Source in A CVSR  [ :arrow_down: ](https://arxiv.org/pdf/2109.05568.pdf)
>  Continuously Variable Series Reactor (CVSR) can adjust the total reactance in an ac circuit using the saturation characteristic of the ferromagnetic core, shared by an ac and a dc winding. The bias magnetic flux produced by the dc winding can regulate the equivalent ac inductance in order to control power flow, damp oscillations, or limit fault currents. Gyrator-Capacitor approach is used to model the interface between the magnetic and the electric circuits. Two different dc control source models are considered: the usual ideal dc source and a realistic dc source composed of a power electronics-based converter and an ac voltage source. This paper investigates CVSR's behaviour in terms of induced voltage across ac winding, flux densities (B) throughout the CVSR core, and power interchange with the dc control circuit during normal conditions in both cases.      
### 27.Link Scheduling using Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.05536.pdf)
>  Efficient scheduling of transmissions is a key problem in wireless networks. The main challenge stems from the fact that optimal link scheduling involves solving a maximum weighted independent set (MWIS) problem, which is known to be NP-hard. For practical link scheduling schemes, centralized and distributed greedy heuristics are commonly used to approximate the solution to the MWIS problem. However, these greedy schemes mostly ignore important topological information of the wireless network. To overcome this limitation, we propose fast heuristics based on graph convolutional networks (GCNs) that can be implemented in centralized and distributed manners. Our centralized MWIS solver is based on tree search guided by a trainable GCN module and 1-step rollout. In our distributed MWIS solver, a trainable GCN module learns topology-aware node embeddings that are combined with the network weights before calling a distributed greedy solver. Test results on medium-sized wireless networks show that a GCN-based centralized MWIS solver can reach a near-optimal solution quickly. Moreover, we demonstrate that a shallow GCN-based distributed MWIS scheduler can reduce by nearly half the suboptimality gap of the distributed greedy solver with minimal increase in complexity. The proposed scheduling solutions also exhibit good generalizability across graph and weight distributions.      
### 28.A Complex Constrained Total Variation Image Denoising Algorithm with Application to Phase Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2109.05496.pdf)
>  This paper considers the constrained total variation (TV) denoising problem for complex-valued images. We extend the definition of TV seminorms for real-valued images to dealing with complex-valued ones. In particular, we introduce two types of complex TV in both isotropic and anisotropic forms. To solve the constrained denoising problem, we adopt a dual approach and derive an accelerated gradient projection algorithm. We further generalize the proposed denoising algorithm as a key building block of the proximal gradient scheme to solve a vast class of complex constrained optimization problems with TV regularizers. As an example, we apply the proposed algorithmic framework to phase retrieval. We combine the complex TV regularizer with the conventional projection-based method within the constraint complex TV model. Initial results from both simulated and optical experiments demonstrate the validity of the constrained TV model in extracting sparsity priors within complex-valued images, while also utilizing physically tractable constraints that help speed up convergence.      
### 29.Efficient Re-parameterization Residual Attention Network For Nonhomogeneous Image Dehazing  [ :arrow_down: ](https://arxiv.org/pdf/2109.05479.pdf)
>  This paper proposes an end-to-end Efficient Re-parameterizationResidual Attention Network(ERRA-Net) to directly restore the nonhomogeneous hazy image. The contribution of this paper mainly has the following three aspects: 1) A novel Multi-branch Attention (MA) block. The spatial attention mechanism better reconstructs high-frequency features, and the channel attention mechanism treats the features of different channels differently. Multi-branch structure dramatically improves the representation ability of the model and can be changed into a single path structure after re-parameterization to speed up the process of inference. Local Residual Connection allows the low-frequency information in the nonhomogeneous area to pass through the block without processing so that the block can focus on detailed features. 2) A lightweight network structure. We use cascaded MA blocks to extract high-frequency features step by step, and the Multi-layer attention fusion tail combines the shallow and deep features of the model to get the residual of the clean image finally. 3)We propose two novel loss functions to help reconstruct the hazy image ColorAttenuation loss and Laplace Pyramid loss. ERRA-Net has an impressive speed, processing 1200x1600 HD quality images with an average runtime of 166.11 fps. Extensive evaluations demonstrate that ERSANet performs favorably against the SOTA approaches on the real-world hazy images.      
### 30.Graph Attention Network Based Single-Pixel Compressive Direction of Arrival Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05466.pdf)
>  In this paper, we present a single-pixel compressive direction of arrival (DoA) estimation technique leveraging a graph attention network (GAT) based deep-learning framework. The physical layer compression is achieved using a coded-aperture technique, probing the spectrum of far-field sources incident on the aperture using a set of spatio-temporally incoherent modes. This information is then encoded and compressed into the channel of the coded-aperture. The coded-aperture based receiver exhibits a single-channel, replacing the conventional multichannel raster scan based solutions for DoA estimation. The GAT network enables the compressive DoA estimation framework to learn the DoA information directly from the measurements acquired using the coded-aperture. This step eliminates the need for an additional reconstruction step and significantly simplifies the processing layer to obtain the DoA estimate. We show that the presented GAT integrated single-pixel radar framework can retrieve high fidelity DoA information even under relatively low signal-to-noise ratio (SNR) levels.      
### 31.Sliding-mode theory under feedback constraints and the problem of epidemic control  [ :arrow_down: ](https://arxiv.org/pdf/2109.05464.pdf)
>  One of the most important branches of nonlinear control theory is the so-called sliding-mode. Its aim is the design of a (nonlinear) feedback law that brings and maintains the state trajectory of a dynamic system on a given sliding surface. Here, dynamics becomes completely independent of the model parameters and can be tuned accordingly to the desired target. In this paper we study this problem when the feedback law is subject to strong structural constraints. In particular, we assume that the control input may take values only over two bounded and disjoint sets. Such sets could be also non perfectly known a priori. An example is a control input allowed to switch only between two values. Under these peculiarities, we derive the necessary and sufficient conditions that guarantee sliding-mode control effectiveness for a class of time-varying continuous-time linear systems that includes all the stationary state-space linear models. Our analysis covers several scientific fields. It is only apparently confined to the linear setting and allows also to study an important set of nonlinear models. We describe fundamental examples related to epidemiology where the control input is the level of contact rate among people and the sliding surface permits to control the number of infected. For popular epidemiological models we prove the global convergence of control schemes based on the introduction of severe restrictions, like lockdowns, to contain epidemic. This greatly generalizes previous results obtained in the literature by casting them within a general sliding-mode theory.      
### 32.Transmissive Reconfigurable Meta-surface Empowered 6G Ultra Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2109.05462.pdf)
>  In this paper, we investigate a more efficient transmissive reconfigurable meta-surface (RMS) transmitter, which is potential to realize the sixth-generation (6G) mobile communication ultra massive multiple input multiple output (MIMO) due to its low cost and low power consumption. Since RMS is passive, it can reduce power consumption while satisfying the high-capacity requirements of 6G networks. For the proposed architecture, we elaborate transmissive RMS transmitter architecture, channel model, channel estimation, downlink (DL) signal modulation, and beamforming design, etc.. Finally, several potential research directions in the future are given.      
### 33.CAN3D: Fast 3D Medical Image Segmentation via Compact Context Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05443.pdf)
>  Direct automatic segmentation of objects from 3D medical imaging, such as magnetic resonance (MR) imaging, is challenging as it often involves accurately identifying a number of individual objects with complex geometries within a large volume under investigation. To address these challenges, most deep learning approaches typically enhance their learning capability by substantially increasing the complexity or the number of trainable parameters within their models. Consequently, these models generally require long inference time on standard workstations operating clinical MR systems and are restricted to high-performance computing hardware due to their large memory requirement. Further, to fit 3D dataset through these large models using limited computer memory, trade-off techniques such as patch-wise training are often used which sacrifice the fine-scale geometric information from input images which could be clinically significant for diagnostic purposes. To address these challenges, we present a compact convolutional neural network with a shallow memory footprint to efficiently reduce the number of model parameters required for state-of-art performance. This is critical for practical employment as most clinical environments only have low-end hardware with limited computing power and memory. The proposed network can maintain data integrity by directly processing large full-size 3D input volumes with no patches required and significantly reduces the computational time required for both training and inference. We also propose a novel loss function with extra shape constraint to improve the accuracy for imbalanced classes in 3D MR images.      
### 34.HYPERION: Hyperspectral Penetrating-type Ellipsoidal Reconstruction for Terahertz Blind Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05425.pdf)
>  Terahertz (THz) technology has been a great candidate for applications, including pharmaceutic analysis, chemical identification, and remote sensing and imaging due to its non-invasive and non-destructive properties. Among those applications, penetrating-type hyperspectral THz signals, which provide crucial material information, normally involve a noisy, complex mixture system. Additionally, the measured THz signals could be ill-conditioned due to the overlap of the material absorption peak in the measured bands. To address those issues, we consider penetrating-type signal mixtures and aim to develop a \textit{blind} hyperspectral unmixing (HU) method without requiring any information from a prebuilt database. The proposed HYperspectral Penetrating-type Ellipsoidal ReconstructION (HYPERION) algorithm is unsupervised, not relying on collecting extensive data or sophisticated model training. Instead, it is developed based on elegant ellipsoidal geometry under a very mild requirement on data purity, whose excellent efficacy is experimentally demonstrated.      
### 35.Team NeuroPoly: Description of the Pipelines for the MICCAI 2021 MS New Lesions Segmentation Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2109.05409.pdf)
>  This paper gives a detailed description of the pipelines used for the 2nd edition of the MICCAI 2021 Challenge on Multiple Sclerosis Lesion Segmentation. An overview of the data preprocessing steps applied is provided along with a brief description of the pipelines used, in terms of the architecture and the hyperparameters. Our code for this work can be found at: <a class="link-external link-https" href="https://github.com/ivadomed/ms-challenge-2021" rel="external noopener nofollow">this https URL</a>.      
### 36.From Instantaneous Schedulability to Worst Case Schedulability: A Significant Moment Approach  [ :arrow_down: ](https://arxiv.org/pdf/2109.05375.pdf)
>  The method of significant moment analysis has been employed to derive instantaneous schedulability tests for real-time systems. However, the instantaneous schedulability can only be checked within a finite time window. On the other hand, worst-case schedulability guarantees schedulability of systems for infinite time. This paper derives the classical worst-case schedulability conditions for preemptive periodic systems starting from instantaneous schedulability, hence unifying the two notions of schedulability. The results provide a rigorous justification on the critical time instants being the worst case for scheduling of preemptive periodic systems. The paper also show that the critical time instant is not the only worst case moments.      
### 37.Sickle Cell Disease Severity Prediction from Percoll Gradient Images using Graph Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.05372.pdf)
>  Sickle cell disease (SCD) is a severe genetic hemoglobin disorder that results in premature destruction of red blood cells. Assessment of the severity of the disease is a challenging task in clinical routine since the causes of broad variance in SCD manifestation despite the common genetic cause remain unclear. Identification of the biomarkers that would predict the severity grade is of importance for prognosis and assessment of responsiveness of patients to therapy. Detection of the changes in red blood cell (RBC) density through separation of Percoll density gradient could be such marker as it allows to resolve intercellular differences and follow the most damaged dense cells prone to destruction and vaso-occlusion. Quantification of the images obtained from the distribution of RBCs in Percoll gradient and interpretation of the obtained is an important prerequisite for establishment of this approach. Here, we propose a novel approach combining a graph convolutional network, a convolutional neural network, fast Fourier transform, and recursive feature elimination to predict the severity of SCD directly from a Percoll image. Two important but expensive laboratory blood test parameters measurements are used for training the graph convolutional network. To make the model independent from such tests during prediction, the two parameters are estimated by a neural network from the Percoll image directly. On a cohort of 216 subjects, we achieve a prediction performance that is only slightly below an approach where the groundtruth laboratory measurements are used. Our proposed method is the first computational approach for the difficult task of SCD severity prediction. The two-step approach relies solely on inexpensive and simple blood analysis tools and can have a significant impact on the patients' survival in underdeveloped countries where access to medical instruments and doctors is limited      
### 38.Agent-Supervisor Coordination for Decentralized Event-Triggered Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2109.05356.pdf)
>  This paper proposes decentralized resource-aware coordination schemes for solving network optimization problems defined by objective functions which combine locally evaluable costs with network-wide coupling components. These methods are well suited for a group of supervised agents trying to solve an optimization problem under mild coordination requirements. Each agent has information on its local cost and coordinates with the network supervisor for information about the coupling term of the cost. The proposed approach is feedback-based and asynchronous by design, guarantees anytime feasibility, and ensures the asymptotic convergence of the network state to the desired optimizer. Numerical simulations on a power system example illustrate our results.      
### 39.Energy-Efficient Backscatter Aided Uplink NOMA Roadside Sensor Communications under Channel Estimation Errors  [ :arrow_down: ](https://arxiv.org/pdf/2109.05341.pdf)
>  This work presents non-orthogonal multiple access (NOMA) enabled energy-efficient alternating optimization framework for backscatter aided wireless powered uplink sensors communications for beyond 5G intelligent transportation system (ITS). Specifically, the transmit power of carrier emitter (CE) and reflection coefficients (RCs) of backscatter aided roadside sensors (RSs) are optimized with channel uncertainties for the maximization of the energy efficiency (EE) of the network. The formulated problem is tackled by the proposed two-stage alternating optimization algorithm named AOBWS (alternating optimization for backscatter aided wireless powered sensors). In the first stage, AOBWS employs an iterative algorithm to obtain optimal CE transmit power through simplified closed-form computed through Cardano's formulae. In the second stage, AOBWS uses a non-iterative algorithm that provides a closed-form expression for the computation of optimal RC for RSs under their quality of service (QoS) and a circuit power constraint. The global optimal exhaustive search (ES) algorithm is used as a benchmark. Simulation results demonstrate that the AOBWS algorithm can achieve near-optimal performance with very low complexity, which makes it suitable for practical implementations.      
### 40.An Efficient Labeled/Unlabeled Random Finite Set Algorithm for Multiobject Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2109.05337.pdf)
>  We propose an efficient random finite set (RFS) based algorithm for multiobject tracking in which the object states are modeled by a combination of a labeled multi-Bernoulli (LMB) RFS and a Poisson RFS. The less computationally demanding Poisson part of the algorithm is used to track potential objects whose existence is unlikely. Only if a quantity characterizing the plausibility of object existence is above a threshold, a new LMB component is created and the object is tracked by the more accurate but more computationally demanding LMB part of the algorithm. Conversely, an LMB component is transferred back to the Poisson RFS if the corresponding existence probability falls below a threshold. Contrary to existing hybrid algorithms based on multi-Bernoulli and Poisson RFSs, the proposed method facilitates track continuity and implements complexity-reducing features. Simulation results demonstrate a large complexity reduction relative to other RFS-based algorithms with comparable performance.      
### 41.InDuDoNet: An Interpretable Dual Domain Network for CT Metal Artifact Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2109.05298.pdf)
>  For the task of metal artifact reduction (MAR), although deep learning (DL)-based methods have achieved promising performances, most of them suffer from two problems: 1) the CT imaging geometry constraint is not fully embedded into the network during training, leaving room for further performance improvement; 2) the model interpretability is lack of sufficient consideration. Against these issues, we propose a novel interpretable dual domain network, termed as InDuDoNet, which combines the advantages of model-driven and data-driven methodologies. Specifically, we build a joint spatial and Radon domain reconstruction model and utilize the proximal gradient technique to design an iterative algorithm for solving it. The optimization algorithm only consists of simple computational operators, which facilitate us to correspondingly unfold iterative steps into network modules and thus improve the interpretablility of the framework. Extensive experiments on synthesized and clinical data show the superiority of our InDuDoNet. Code is available in \url{<a class="link-external link-https" href="https://github.com/hongwang01/InDuDoNet" rel="external noopener nofollow">this https URL</a>}.%method on the tasks of MAR and downstream multi-class pelvic fracture segmentation.      
### 42.Dual-view Snapshot Compressive Imaging via Optical Flow Aided Recurrent Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2109.05287.pdf)
>  Dual-view snapshot compressive imaging (SCI) aims to capture videos from two field-of-views (FoVs) using a 2D sensor (detector) in a single snapshot, achieving joint FoV and temporal compressive sensing, and thus enjoying the advantages of low-bandwidth, low-power, and low-cost. However, it is challenging for existing model-based decoding algorithms to reconstruct each individual scene, which usually require exhaustive parameter tuning with extremely long running time for large scale data. In this paper, we propose an optical flow-aided recurrent neural network for dual video SCI systems, which provides high-quality decoding in seconds. Firstly, we develop a diversity amplification method to enlarge the differences between scenes of two FoVs, and design a deep convolutional neural network with dual branches to separate different scenes from the single measurement. Secondly, we integrate the bidirectional optical flow extracted from adjacent frames with the recurrent neural network to jointly reconstruct each video in a sequential manner. Extensive results on both simulation and real data demonstrate the superior performance of our proposed model in a short inference time. The code and data are available at <a class="link-external link-https" href="https://github.com/RuiyingLu/OFaNet-for-Dual-view-SCI" rel="external noopener nofollow">this https URL</a>.      
### 43.Follow the Curve: Robotic-Ultrasound Navigation with Learning Based Localization of Spinous Processes for Scoliosis Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2109.05196.pdf)
>  The scoliosis progression in adolescents requires close monitoring to timely take treatment measures. Ultrasound imaging is a radiation-free and low-cost alternative in scoliosis assessment to X-rays, which are typically used in clinical practice. However, ultrasound images are prone to speckle noises, making it challenging for sonographers to detect bony features and follow the spine's curvature. This paper introduces a robotic-ultrasound approach for spinal curvature tracking and automatic navigation. A fully connected network with deconvolutional heads is developed to locate the spinous process efficiently with real-time ultrasound images. We use this machine learning-based method to guide the motion of the robot-held ultrasound probe and follow the spinal curvature while capturing ultrasound images and correspondent position. We developed a new force-driven controller that automatically adjusts the probe's pose relative to the skin surface to ensure a good acoustic coupling between the probe and skin. After the scanning, the acquired data is used to reconstruct the coronal spinal image, where the deformity of the scoliosis spine can be assessed and measured. To evaluate the performance of our methodology, we conducted an experimental study with human subjects where the deviations from the image center during the robotized procedure are compared to that obtained from manual scanning. The angles of spinal deformity measured on spinal reconstruction images were similar for both methods, implying that they equally reflect human anatomy.      
### 44.OFDM-guided Deep Joint Source Channel Coding for Wireless Multipath Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2109.05194.pdf)
>  We investigate joint source channel coding (JSCC) for wireless image transmission over multipath fading channels. Inspired by recent works on deep learning based JSCC and model-based learning methods, we combine an autoencoder with orthogonal frequency division multiplexing (OFDM) to cope with multipath fading. The proposed encoder and decoder use convolutional neural networks (CNNs) and directly map the source images to complex-valued baseband samples for OFDM transmission. The multipath channel and OFDM are represented by non-trainable (deterministic) but differentiable layers so that the system can be trained end-to-end. Furthermore, our JSCC decoder further incorporates explicit channel estimation, equalization, and additional subnets to enhance the performance. The proposed method exhibits 2.5 -- 4 dB SNR gain for the equivalent image quality compared to conventional schemes that employ state-of-the-art but separate source and channel coding such as BPG and LDPC. The performance further improves when the system incorporates the channel state information (CSI) feedback. The proposed scheme is robust against OFDM signal clipping and parameter mismatch for the channel model used in training and evaluation.      
### 45.Incorporating Real-world Noisy Speech in Neural-network-based Speech Enhancement Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.05172.pdf)
>  Supervised speech enhancement relies on parallel databases of degraded speech signals and their clean reference signals during training. This setting prohibits the use of real-world degraded speech data that may better represent the scenarios where such systems are used. In this paper, we explore methods that enable supervised speech enhancement systems to train on real-world degraded speech data. Specifically, we propose a semi-supervised approach for speech enhancement in which we first train a modified vector-quantized variational autoencoder that solves a source separation task. We then use this trained autoencoder to further train an enhancement network using real-world noisy speech data by computing a triplet-based unsupervised loss function. Experimental results show promising results for incorporating real-world data in training speech enhancement systems.      
### 46.Space-and-time-synchronized simultaneous vehicle tracking/formation using cascaded prescribed-time control  [ :arrow_down: ](https://arxiv.org/pdf/2109.05162.pdf)
>  In this paper, we present a space-and-time-synchronized control method with application to the simultaneous tracking/formation. In the framework of polar coordinates, through correlating and decoupling the reference/actual kinematics between the self vehicle and target, time and space are separated, controlled independently. As such, the specified state can be achieved at the predetermined terminal time, meanwhile, the relative trajectory in space is independent of time. In addition, for the stabilization before the predesigned time, a cascaded prescribed-time control theorem is provided as the preliminary of vehicle tracking control. The obtained results can be directly extended to the simultaneous tracking/formation of multiple vehicles. Finally, numerical examples are provided to verify the effectiveness and superiority of the proposed scheme.      
### 47.Co-Correcting: Noise-tolerant Medical Image Classification via mutual Label Correction  [ :arrow_down: ](https://arxiv.org/pdf/2109.05159.pdf)
>  With the development of deep learning, medical image classification has been significantly improved. However, deep learning requires massive data with labels. While labeling the samples by human experts is expensive and time-consuming, collecting labels from crowd-sourcing suffers from the noises which may degenerate the accuracy of classifiers. Therefore, approaches that can effectively handle label noises are highly desired. Unfortunately, recent progress on handling label noise in deep learning has gone largely unnoticed by the medical image. To fill the gap, this paper proposes a noise-tolerant medical image classification framework named Co-Correcting, which significantly improves classification accuracy and obtains more accurate labels through dual-network mutual learning, label probability estimation, and curriculum label correcting. On two representative medical image datasets and the MNIST dataset, we test six latest Learning-with-Noisy-Labels methods and conduct comparative studies. The experiments show that Co-Correcting achieves the best accuracy and generalization under different noise ratios in various tasks. Our project can be found at: <a class="link-external link-https" href="https://github.com/JiarunLiu/Co-Correcting" rel="external noopener nofollow">this https URL</a>.      
### 48.Interactive multi-modal motion planning with Branch Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2109.05128.pdf)
>  Motion planning for autonomous robots and vehicles in presence of uncontrolled agents remains a challenging problem as the reactive behaviors of the uncontrolled agents must be considered. Since the uncontrolled agents usually demonstrate multimodal reactive behavior, the motion planner needs to solve a continuous motion planning problem under multimodal behaviors of the uncontrolled agents, which contains a discrete element. We propose a branch Model Predictive Control (MPC) framework that plans over feedback policies to leverage the reactive behavior of the uncontrolled agent. In particular, a scenario tree is constructed from a finite set of policies of the uncontrolled agent, and the branch MPC solves for a feedback policy in the form of a trajectory tree, which shares the same topology as the scenario tree. Moreover, coherent risk measures such as the Conditional Value at Risk (CVaR) are used as a tuning knob to adjust the tradeoff between performance and robustness. The proposed branch MPC framework is tested on an \textit{overtake and lane change} task and a \textit{merging} task for autonomous vehicles in simulation, and on the motion planning of an autonomous quadruped robot alongside an uncontrolled quadruped in experiments. The result demonstrates interesting human-like behaviors, achieving a balance between safety and performance.      
### 49.On the Feasibility of Modeling OFDM Communication Signals with Unsupervised Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.05107.pdf)
>  High-quality recordings of radio frequency (RF) emissions from commercial communication hardware in realistic environments are often needed to develop and assess spectrum-sharing technologies and practices, e.g., for training and testing spectrum sensing algorithms and for interference testing. Unfortunately, the time-consuming, expensive nature of such data collections together with data-sharing restrictions pose significant challenges that limit dataset availability. Furthermore, developing accurate models of real-world RF emissions from first principles is often very difficult because system parameters and implementation details are at best only partially known, and complex system dynamics are difficult to characterize. Hence, there is a need for flexible, data-driven methods that can leverage existing datasets to synthesize additional similar waveforms. One promising machine learning approach is unsupervised deep generative modeling with generative adversarial networks (GANs). To date, GANs for RF communication signals have not been studied thoroughly. In this paper, we present the first in-depth investigation of generated signal fidelity for GANs trained with baseband orthogonal frequency-division multiplexing (OFDM) signals, where each subcarrier is digitally modulated with quadrature amplitude modulation (QAM). Building on prior GAN methods, we propose two novel GAN models and evaluate their performance using simulated datasets with known ground truth. Specifically, we investigate model performance with respect to increasing dataset complexity over a range of OFDM parameters and conditions, including fading channels. The findings presented here inform the feasibility of use-cases and provide a foundation for further investigations into deep generative models for RF communication signals.      
### 50.Minimizing AoI in Resource-Constrained Multi-Source Relaying Systems with Stochastic Arrivals  [ :arrow_down: ](https://arxiv.org/pdf/2109.05106.pdf)
>  We consider a multi-source relaying system where the sources independently and randomly generate status update packets which are sent to the destination with the aid of a bufferaided relay through unreliable links. We formulate a stochastic optimization problem aiming to minimize the sum average age of information (AAoI) of sources under per-slot transmission capacity constraints and a long-run average resource constraint. To solve the problem, we recast it as a constrained Markov decision process (CMDP) problem and adopt the Lagrangian method. We analyze the structure of an optimal policy for the resulting MDP problem that possesses a switching-type structure. We propose an algorithm that obtains a stationary deterministic near-optimal policy, establishing a benchmark for the system. Simulation results show the effectiveness of our algorithm compared to benchmark algorithms.      
### 51.Remember the context! ASR slot error correction through memorization  [ :arrow_down: ](https://arxiv.org/pdf/2109.05092.pdf)
>  Accurate recognition of slot values such as domain specific words or named entities by automatic speech recognition (ASR) systems forms the core of the Goal-oriented Dialogue Systems. Although it is a critical step with direct impact on downstream tasks such as language understanding, many domain agnostic ASR systems tend to perform poorly on domain specific or long tail words. They are often supplemented with slot error correcting systems but it is often hard for any neural model to directly output such rare entity words. To address this problem, we propose k-nearest neighbor (k-NN) search that outputs domain-specific entities from an explicit datastore. We improve error correction rate by conveniently augmenting a pretrained joint phoneme and text based transformer sequence to sequence model with k-NN search during inference. We evaluate our proposed approach on five different domains containing long tail slot entities such as full names, airports, street names, cities, states. Our best performing error correction model shows a relative improvement of 7.4% in word error rate (WER) on rare word entities over the baseline and also achieves a relative WER improvement of 9.8% on an out of vocabulary (OOV) test set.      
### 52.Data Generation Method for Learning a Low-dimensional Safe Region in Safe Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.05077.pdf)
>  Safe reinforcement learning aims to learn a control policy while ensuring that neither the system nor the environment gets damaged during the learning process. For implementing safe reinforcement learning on highly nonlinear and high-dimensional dynamical systems, one possible approach is to find a low-dimensional safe region via data-driven feature extraction methods, which provides safety estimates to the learning algorithm. As the reliability of the learned safety estimates is data-dependent, we investigate in this work how different training data will affect the safe reinforcement learning approach. By balancing between the learning performance and the risk of being unsafe, a data generation method that combines two sampling methods is proposed to generate representative training data. The performance of the method is demonstrated with a three-link inverted pendulum example.      
### 53.Medulloblastoma Tumor Classification using Deep Transfer Learning with Multi-Scale EfficientNets  [ :arrow_down: ](https://arxiv.org/pdf/2109.05025.pdf)
>  Medulloblastoma (MB) is the most common malignant brain tumor in childhood. The diagnosis is generally based on the microscopic evaluation of histopathological tissue slides. However, visual-only assessment of histopathological patterns is a tedious and time-consuming task and is also affected by observer variability. Hence, automated MB tumor classification could assist pathologists by promoting consistency and robust quantification. Recently, convolutional neural networks (CNNs) have been proposed for this task, while transfer learning has shown promising results. In this work, we propose an end-to-end MB tumor classification and explore transfer learning with various input sizes and matching network dimensions. We focus on differentiating between the histological subtypes classic and desmoplastic/nodular. For this purpose, we systematically evaluate recently proposed EfficientNets, which uniformly scale all dimensions of a CNN. Using a data set with 161 cases, we demonstrate that pre-trained EfficientNets with larger input resolutions lead to significant performance improvements compared to commonly used pre-trained CNN architectures. Also, we highlight the importance of transfer learning, when using such large architectures. Overall, our best performing method achieves an F1-Score of 80.1%.      
### 54.Real-time multimodal image registration with partial intraoperative point-set data  [ :arrow_down: ](https://arxiv.org/pdf/2109.05023.pdf)
>  We present Free Point Transformer (FPT) - a deep neural network architecture for non-rigid point-set registration. Consisting of two modules, a global feature extraction module and a point transformation module, FPT does not assume explicit constraints based on point vicinity, thereby overcoming a common requirement of previous learning-based point-set registration methods. FPT is designed to accept unordered and unstructured point-sets with a variable number of points and uses a "model-free" approach without heuristic constraints. Training FPT is flexible and involves minimizing an intuitive unsupervised loss function, but supervised, semi-supervised, and partially- or weakly-supervised training are also supported. This flexibility makes FPT amenable to multimodal image registration problems where the ground-truth deformations are difficult or impossible to measure. In this paper, we demonstrate the application of FPT to non-rigid registration of prostate magnetic resonance (MR) imaging and sparsely-sampled transrectal ultrasound (TRUS) images. The registration errors were 4.71 mm and 4.81 mm for complete TRUS imaging and sparsely-sampled TRUS imaging, respectively. The results indicate superior accuracy to the alternative rigid and non-rigid registration algorithms tested and substantially lower computation time. The rapid inference possible with FPT makes it particularly suitable for applications where real-time registration is beneficial.      
### 55.A Deep Learning-Based Unified Framework for Red Lesions Detection on Retinal Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2109.05021.pdf)
>  Red-lesions, i.e., microaneurysms (MAs) and hemorrhages (HMs), are the early signs of diabetic retinopathy (DR). The automatic detection of MAs and HMs on retinal fundus images is a challenging task. Most of the existing methods detect either only MAs or only HMs because of the difference in their texture, sizes, and morphology. Though some methods detect both MAs and HMs, they suffer from the curse of dimensionality of shape and colors features and fail to detect all shape variations of HMs such as flame-shaped HM. Leveraging the progress in deep learning, we proposed a two-stream red lesions detection system dealing simultaneously with small and large red lesions. For this system, we introduced a new ROIs candidates generation method for large red lesions fundus images; it is based on blood vessel segmentation and morphological operations, and reduces the computational complexity, and enhances the detection accuracy by generating a small number of potential candidates. For detection, we adapted the Faster RCNN framework with two streams. We used pre-trained VGGNet as a bone model and carried out several extensive experiments to tune it for vessels segmentation and candidates generation, and finally learning the appropriate mapping, which yields better detection of the red lesions comparing with the state-of-the-art methods. The experimental results validated the effectiveness of the system in the detection of both MAs and HMs; the method yields higher performance for per lesion detection according to sensitivity under 4 FPIs on DiaretDB1-MA and DiaretDB1-HM datasets, and 1 FPI on e-ophtha and ROCh datasets than the state of the art methods w.r.t. various evaluation metrics. For DR screening, the system outperforms other methods on DiaretDB1-MA, DiaretDB1-HM, and e-ophtha datasets.      
### 56.A Framework for Developing Algorithms for Estimating Propagation Parameters from Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2109.06131.pdf)
>  A framework is proposed for developing and evaluating algorithms for extracting multipath propagation components (MPCs) from measurements collected by sounders at millimeter-wave (mmW) frequencies. To focus on algorithmic performance, an idealized model is proposed for the spatial frequency response of the propagation environment measured by a sounder. The input to the sounder model is a pre-determined set of MPC parameters that serve as the "ground truth." A three-dimensional angle-delay (beamspace) representation of the measured spatial frequency response serves as a natural domain for implementing and analyzing MPC extraction algorithms. Metrics for quantifying the error in estimated MPC parameters are introduced. Initial results are presented for a greedy matching pursuit algorithm that performs a least-squares (LS) reconstruction of the MPC path gains within the iterations. The results indicate that the simple greedy-LS algorithm has the ability to extract MPCs over a large dynamic range, and suggest several avenues for further performance improvement through extensions of the greedy-LS algorithm as well as by incorporating features of other algorithms, such as SAGE and RIMAX.      
### 57.LiDAR Odometry Methodologies for Autonomous Driving: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2109.06120.pdf)
>  Vehicle odometry is an essential component of an automated driving system as it computes the vehicle's position and orientation. The odometry module has a higher demand and impact in urban areas where the global navigation satellite system (GNSS) signal is weak and noisy. Traditional visual odometry methods suffer from the diverse illumination status and get disparities during pose estimation, which results in significant errors as the error accumulates. Odometry using light detection and ranging (LiDAR) devices has attracted increasing research interest as LiDAR devices are robust to illumination variations. In this survey, we examine the existing LiDAR odometry methods and summarize the pipeline and delineate the several intermediate steps. Additionally, the existing LiDAR odometry methods are categorized by their correspondence type, and their advantages, disadvantages, and correlations are analyzed across-category and within-category in each step. Finally, we compare the accuracy and the running speed among these methodologies evaluated over the KITTI odometry dataset and outline promising future research directions.      
### 58.Beyond Isolated Utterances: Conversational Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2109.06112.pdf)
>  Speech emotion recognition is the task of recognizing the speaker's emotional state given a recording of their utterance. While most of the current approaches focus on inferring emotion from isolated utterances, we argue that this is not sufficient to achieve conversational emotion recognition (CER) which deals with recognizing emotions in conversations. In this work, we propose several approaches for CER by treating it as a sequence labeling task. We investigated transformer architecture for CER and, compared it with ResNet-34 and BiLSTM architectures in both contextual and context-less scenarios using IEMOCAP corpus. Based on the inner workings of the self-attention mechanism, we proposed DiverseCatAugment (DCA), an augmentation scheme, which improved the transformer model performance by an absolute 3.3% micro-f1 on conversations and 3.6% on isolated utterances. We further enhanced the performance by introducing an interlocutor-aware transformer model where we learn a dictionary of interlocutor index embeddings to exploit diarized conversations.      
### 59.Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data  [ :arrow_down: ](https://arxiv.org/pdf/2109.06094.pdf)
>  In this paper, we propose an efficient and generalizable framework based on deep convolutional neural network (CNN) for multi-source remote sensing data joint classification. While recent methods are mostly based on multi-stream architectures, we use group convolution to construct equivalent network architectures efficiently within a single-stream network. We further adopt and improve dynamic grouping convolution (DGConv) to make group convolution hyperparameters, and thus the overall network architecture, learnable during network training. The proposed method therefore can theoretically adjust any modern CNN models to any multi-source remote sensing data set, and can potentially avoid sub-optimal solutions caused by manually decided architecture hyperparameters. In the experiments, the proposed method is applied to ResNet and UNet, and the adjusted networks are verified on three very diverse benchmark data sets (i.e., Houston2018 data, Berlin data, and MUUFL data). Experimental results demonstrate the effectiveness of the proposed single-stream CNNs, and in particular ResNet18-DGConv improves the state-of-the-art classification overall accuracy (OA) on HS-SAR Berlin data set from $62.23\%$ to $68.21\%$. In the experiments we have two interesting findings. First, using DGConv generally reduces test OA variance. Second, multi-stream is harmful to model performance if imposed to the first few layers, but becomes beneficial if applied to deeper layers. Altogether, the findings imply that multi-stream architecture, instead of being a strictly necessary component in deep learning models for multi-source remote sensing data, essentially plays the role of model regularizer. Our code is publicly available at <a class="link-external link-https" href="https://github.com/yyyyangyi/Multi-source-RS-DGConv" rel="external noopener nofollow">this https URL</a>. We hope our work can inspire novel research in the future.      
### 60.How is Time Frequency Space Modulation Related to Short Time Fourier Signaling?  [ :arrow_down: ](https://arxiv.org/pdf/2109.06047.pdf)
>  We investigate the relationship between Orthogonal Time Frequency Space (OTFS) modulation and Orthogonal Short Time Fourier (OSTF) signaling. OTFS was recently proposed as a new scheme for high Doppler scenarios and builds on OSTF. We first show that the two schemes are unitarily equivalent in the digital domain. However, OSTF defines the analog-digital interface with the waveform domain. We then develop a critically sampled matrix-vector model for the two systems and consider linear minimum mean-squared error (MMSE) filtering at the receiver to suppress inter-symbol interference. Initial comparison of capacity and (uncoded) probability of error reveals a surprising observation: OTFS under-performs OSTF in capacity but over-performs in probability of error. This result can be attributed to characteristics of the channel matrices induced by the two systems. In particular, the diagonal entries of OTFS matrix exhibit nearly identical magnitude, whereas those of the OSTF matrix exhibit wild fluctuations induced by multipath randomness. It is observed that by simply replacing the unitary matrix, relating OTFS to OSTF, by an arbitrary unitary matrix results in performance nearly identical to OTFS. We then extend our analysis to orthogonal frequency division multiplexing (OFDM) and also consider a more extreme scenario of relatively large delay and Doppler spreads. Our results demonstrate the significance of using OSTF basis waveforms rather than sinusoidal ones in OFDM in highly dynamic environments, and also highlight the impact of the level of channel state information used at the receiver.      
### 61.Planning a Return to Normal after the COVID-19 Pandemic: Identifying Safe Contact Levels via Online Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2109.06025.pdf)
>  Since the early months of 2020, non-pharmaceutical interventions (NPIs) -- implemented at varying levels of severity and based on widely-divergent perspectives of risk tolerance -- have been the primary means to control SARS-CoV-2 transmission. We seek to identify how risk tolerance and vaccination rates impact the rate at which a population can return to pre-pandemic contact behavior. To this end, we develop a novel feedback control method for data-driven decision-making to identify optimal levels of NPIs across geographical regions in order to guarantee that hospitalizations will not exceed a given risk tolerance. Results are shown for the state of Colorado, and they suggest that: coordination in decision-making across regions is essential to maintain the daily number of hospitalizations below the desired limits; increasing risk tolerance can decrease the number of days required to discontinue NPIs, at the cost of an increased number of deaths; and if vaccination uptake is less than 70\%, at most levels of risk tolerance, return to pre-pandemic contact behaviors before the early months of 2022 may newly jeopardize the healthcare system.      
### 62.RWP+: A New Random Waypoint Model for High-Speed Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2109.05978.pdf)
>  In this letter, we emulate real-world statistics for mobility patterns on road systems. We then propose modifications to the assumptions of the random waypoint (RWP) model to better represent high-mobility profiles. We call the model under our new framework as RWP+. Specifically, we show that the lengths of the transitions which constitute a trip, are best represented by a lognormal distribution, and that the velocities are best described by a linear combination of normal distributions with different mean values. Compared to the assumptions used in the literature for mobile cellular networks, our modeling provides mobility metrics, such as handoff rates, that better characterize actual emulated trips from the collected statistics.      
### 63.Two-population SIR model and strategies to reduce mortality in pandemics  [ :arrow_down: ](https://arxiv.org/pdf/2109.05964.pdf)
>  Despite many studies on the transmission mechanism of the Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), it remains still challenging to efficiently reduce mortality. In this work, we apply a two-population Susceptible-Infected-Removed (SIR) model to investigate the COVID-19 spreading when contacts between elderly and non-elderly individuals are reduced due to the high mortality risk of elderly people. We discover that the reduction of connections between two populations can delay the death curve but cannot well reduce the final mortality. We propose a merged SIR model, which advises elderly individuals to interact less with their non-elderly connections at the initial stage but interact more with their non-elderly relationships later, to reduce the final mortality. Finally, immunizing elderly hub individuals can also significantly decrease mortality.      
### 64.Towards Stochastic Fault-tolerant Control using Precision Learning and Active Inference  [ :arrow_down: ](https://arxiv.org/pdf/2109.05870.pdf)
>  This work presents a fault-tolerant control scheme for sensory faults in robotic manipulators based on active inference. In the majority of existing schemes, a binary decision of whether a sensor is healthy (functional) or faulty is made based on measured data. The decision boundary is called a threshold and it is usually deterministic. Following a faulty decision, fault recovery is obtained by excluding the malfunctioning sensor. We propose a stochastic fault-tolerant scheme based on active inference and precision learning which does not require a priori threshold definitions to trigger fault recovery. Instead, the sensor precision, which represents its health status, is learned online in a model-free way allowing the system to gradually, and not abruptly exclude a failing unit. Experiments on a robotic manipulator show promising results and directions for future work are discussed.      
### 65.Whittle Index Based Scheduling Policy for Minimizing the Cost of Age of Information  [ :arrow_down: ](https://arxiv.org/pdf/2109.05869.pdf)
>  We design a new scheduling policy to minimize the general non-decreasing cost function of age of information (AoI) in a multiuser system. In this system, the base station stochastically generates time-sensitive packets and transmits them to corresponding user equipments via an unreliable channel. We first formulate the transmission scheduling problem as an average cost constrained Markov decision process problem. Through introducing the service charge, we derive the closed-form expression for the Whittle index, based on which we design the scheduling policy. Using numerical results, we demonstrate the performance gain of our designed scheduling policy compared to the existing policies, such as the optimal policy, the on-demand Whittle index policy, and the age greedy policy.      
### 66.Leveraging Clinical Characteristics for Improved Deep Learning-Based Kidney Tumor Segmentation on CT  [ :arrow_down: ](https://arxiv.org/pdf/2109.05816.pdf)
>  This paper assesses whether using clinical characteristics in addition to imaging can improve automated segmentation of kidney cancer on contrast-enhanced computed tomography (CT). A total of 300 kidney cancer patients with contrast-enhanced CT scans and clinical characteristics were included. A baseline segmentation of the kidney cancer was performed using a 3D U-Net. Input to the U-Net were the contrast-enhanced CT images, output were segmentations of kidney, kidney tumors, and kidney cysts. A cognizant sampling strategy was used to leverage clinical characteristics for improved segmentation. To this end, a Least Absolute Shrinkage and Selection Operator (LASSO) was used. Segmentations were evaluated using Dice and Surface Dice. Improvement in segmentation was assessed using Wilcoxon signed rank test. The baseline 3D U-Net showed a segmentation performance of 0.90 for kidney and kidney masses, i.e., kidney, tumor, and cyst, 0.29 for kidney masses, and 0.28 for kidney tumor, while the 3D U-Net trained with cognizant sampling enhanced the segmentation performance and reached Dice scores of 0.90, 0.39, and 0.38 respectively. To conclude, the cognizant sampling strategy leveraging the clinical characteristics significantly improved kidney cancer segmentation.      
### 67.Epidemic Management with Admissible and Robust Invariant Sets  [ :arrow_down: ](https://arxiv.org/pdf/2109.05754.pdf)
>  We present a detailed set-based analysis of the well-known SIR and SEIR epidemic models subjected to hard caps on the proportion of infective individuals, and bounds on the allowable intervention strategies, such as social distancing, quarantining and vaccination. We describe the admissible and maximal robust positively invariant (MRPI) sets of these two models via the theory of barriers. We show how the sets may be used in the management of epidemics, for both perfect and imperfect/uncertain models, detailing how intervention strategies may be specified such that the hard infection cap is never breached, regardless of the basic reproduction number. The results are clarified with detailed examples.      
### 68.URLLC and eMBB Coexistence in MIMO Non-orthogonal Multiple Access Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.05725.pdf)
>  Enhanced mobile broadband (eMBB) and ultrareliable and low-latency communications (URLLC) are two major expected services in the fifth-generation mobile communication systems (5G). Specifically, eMBB applications support extremely high data rate communications, while URLLC services aim to provide stringent latency with high reliability communications. Due to their differentiated quality-of-service (QoS) requirements, the spectrum sharing between URLLC and eMBB services becomes a challenging scheduling issue. In this paper, we aim to investigate the URLLC and eMBB coscheduling/coexistence problem under a puncturing technique in multiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA) systems. The objective function is formulated to maximize the data rate of eMBB users while satisfying the latency requirements of URLLC users through joint user selection and power allocation scheduling. To solve this problem, we first introduce an eMBB user clustering mechanism to balance the system performance and computational complexity. Thereafter, we decompose the original problem into two subproblems, namely the scheduling problem of user selection and power allocation. We introduce a Gale-Shapley (GS) theory to solve with the user selection problem, and a successive convex approximation (SCA) and a difference of convex (D.C.) programming to deal with the power allocation problem. Finally, an iterative algorithm is utilized to find the global solution with low computational complexity. Numerical results show the effectiveness of the proposed algorithms, and also verify the proposed approach outperforms other baseline methods.      
### 69.Vision-Aided Autonomous Navigation of Bipedal Robots in Height-Constrained Environments  [ :arrow_down: ](https://arxiv.org/pdf/2109.05714.pdf)
>  Navigating a large-scaled robot in unknown and cluttered height-constrained environments is challenging. Not only is a fast and reliable planning algorithm required to go around obstacles, the robot should also be able to change its intrinsic dimension by crouching in order to travel underneath height constrained regions. There are few mobile robots that are capable of handling such a challenge, and bipedal robots provide a solution. However, as bipedal robots have nonlinear and hybrid dynamics, trajectory planning while ensuring dynamic feasibility and safety on these robots is challenging. This paper presents an end-to-end vision-aided autonomous navigation framework which leverages three layers of planners and a variable walking height controller to enable bipedal robots to safely explore height-constrained environments. A vertically actuated Spring-Loaded Inverted Pendulum (vSLIP) model is introduced to capture the robot coupled dynamics of planar walking and vertical walking height. This reduced-order model is utilized to optimize for long-term and short-term safe trajectory plans. A variable walking height controller is leveraged to enable the bipedal robot to maintain stable periodic walking gaits while following the planned trajectory. The entire framework is tested and experimentally validated using a bipedal robot Cassie. This demonstrates reliable autonomy to drive the robot to safely avoid obstacles while walking to the goal location in various kinds of height-constrained cluttered environments.      
### 70.Robust Stability of Neural-Network Controlled Nonlinear Systems with Parametric Variability  [ :arrow_down: ](https://arxiv.org/pdf/2109.05710.pdf)
>  Stability certification and identification of the stabilizable operating region of a system are two important concerns to ensure its operational safety/security and robustness. With the advent of machine-learning tools, these issues are specially important for systems with machine-learned components in the feedback loop. Here we develop a theory for stability and stabilizability of a class of neural-network controlled nonlinear systems, where the equilibria can drift when parametric changes occur. A Lyapunov based convex stability certificate is developed and is further used to devise an estimate for a local Lipschitz upper bound for a neural-network (NN) controller and a corresponding operating domain on the state space, containing an initialization set from where the closed-loop (CL) local asymptotic stability of each system in the class is guaranteed under the same controller, while the system trajectories remain confined to the operating domain. For computing such a robust stabilizing NN controller, a stability guaranteed training (SGT) algorithm is also proposed. The effectiveness of the proposed framework is demonstrated using illustrative examples.      
### 71.Exploiting Heterogeneity in Robust Federated Best-Arm Identification  [ :arrow_down: ](https://arxiv.org/pdf/2109.05700.pdf)
>  We study a federated variant of the best-arm identification problem in stochastic multi-armed bandits: a set of clients, each of whom can sample only a subset of the arms, collaborate via a server to identify the best arm (i.e., the arm with the highest mean reward) with prescribed confidence. For this problem, we propose Fed-SEL, a simple communication-efficient algorithm that builds on successive elimination techniques and involves local sampling steps at the clients. To study the performance of Fed-SEL, we introduce a notion of arm-heterogeneity that captures the level of dissimilarity between distributions of arms corresponding to different clients. Interestingly, our analysis reveals the benefits of arm-heterogeneity in reducing both the sample- and communication-complexity of Fed-SEL. As a special case of our analysis, we show that for certain heterogeneous problem instances, Fed-SEL outputs the best-arm after just one round of communication. Our findings have the following key implication: unlike federated supervised learning where recent work has shown that statistical heterogeneity can lead to poor performance, one can provably reap the benefits of both local computation and heterogeneity for federated best-arm identification. As our final contribution, we develop variants of Fed-SEL, both for federated and peer-to-peer settings, that are robust to the presence of Byzantine clients, and hence suitable for deployment in harsh, adversarial environments.      
### 72.Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.05664.pdf)
>  Liver segmentation on images acquired using computed tomography (CT) and magnetic resonance imaging (MRI) plays an important role in clinical management of liver diseases. Compared to MRI, CT images of liver are more abundant and readily available. However, MRI can provide richer quantitative information of the liver compared to CT. Thus, it is desirable to achieve unsupervised domain adaptation for transferring the learned knowledge from the source domain containing labeled CT images to the target domain containing unlabeled MR images. In this work, we report a novel unsupervised domain adaptation framework for cross-modality liver segmentation via joint adversarial learning and self-learning. We propose joint semantic-aware and shape-entropy-aware adversarial learning with post-situ identification manner to implicitly align the distribution of task-related features extracted from the target domain with those from the source domain. In proposed framework, a network is trained with the above two adversarial losses in an unsupervised manner, and then a mean completer of pseudo-label generation is employed to produce pseudo-labels to train the next network (desired model). Additionally, semantic-aware adversarial learning and two self-learning methods, including pixel-adaptive mask refinement and student-to-partner learning, are proposed to train the desired model. To improve the robustness of the desired model, a low-signal augmentation function is proposed to transform MRI images as the input of the desired model to handle hard samples. Using the public data sets, our experiments demonstrated the proposed unsupervised domain adaptation framework outperformed four supervised learning methods with a Dice score 0.912 plus or minus 0.037 (mean plus or minus standard deviation).      
### 73.Sequential Detection and Estimation of Multipath Channel Parameters Using Belief Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05623.pdf)
>  This paper proposes a belief propagation (BP)-based algorithm for sequential detection and estimation of multipath components (MPCs) parameters based on radio signals. Under dynamic channel conditions with moving transmitter and/or receiver, the number of MPCs reflected from visible geometric features, the MPC dispersion parameters (delay, angle, Doppler frequency, etc), and the number of false alarm contributions are unknown and time-varying. We develop a Bayesian model for sequential detection and estimation of MPC dispersion parameters, and represent it by a factor graph enabling the use of BP for efficient computation of the marginal posterior distributions. At each time instance, a snapshot-based channel estimator provides parameter estimates of a set of MPCs which are used as noisy measurements by the proposed BP-based algorithm. It performs joint probabilistic data association, estimation of the time-varying MPC parameters, and the mean number of false alarm measurements by means of the sum-product algorithm rules. The results using synthetic measurements show that the proposed algorithm is able to cope with a high number of false alarm measurements originating from the snapshot-based channel estimator and to sequentially detect and estimate MPCs parameters with very low signal-to-noise ratio (SNR). The performance of the proposed algorithm compares well to existing algorithms for high SNR MPCs, but significantly it outperforms them for medium or low SNR MPCs. In particular, we show that our algorithm outperforms the Kalman enhanced super resolution tracking (KEST) algorithm, a state-of-the-art sequential channel parameters estimation method. Furthermore, results with real radio measurements demonstrate the excellent performance of the algorithm in realistic and challenging scenarios.      
### 74.MSGDD-cGAN: Multi-Scale Gradients Dual Discriminator Conditional Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2109.05614.pdf)
>  Conditional Generative Adversarial Networks (cGANs) have been used in many image processing tasks. However, they still have serious problems maintaining the balance between conditioning the output on the input and creating the output with the desired distribution based on the corresponding ground truth. The traditional cGANs, similar to most conventional GANs, suffer from vanishing gradients, which backpropagate from the discriminator to the generator. Moreover, the traditional cGANs are sensitive to architectural changes due to previously mentioned gradient problems. Therefore, balancing the architecture of the cGANs is almost impossible. Recently MSG-GAN has been proposed to stabilize the performance of the GANs by applying multiple connections between the generator and discriminator. In this work, we propose a method called MSGDD-cGAN, which first stabilizes the performance of the cGANs using multi-connections gradients flow. Secondly, the proposed network architecture balances the correlation of the output to input and the fitness of the output on the target distribution. This balance is generated by using the proposed dual discrimination procedure. We tested our model by segmentation of fetal ultrasound images. Our model shows a 3.18% increase in the F1 score comparing to the pix2pix version of cGANs.      
### 75.A study and design of localization system for mobile robot based on ROS  [ :arrow_down: ](https://arxiv.org/pdf/2109.05551.pdf)
>  In recent years, the mobile robot has been the concern of numerous researcher since they are widely applied in various fields of daily life. This paper applies a virtual robot operating system (ROS) platform to develop a localization system for robot motion. The proposed system is based on the combination of relative and absolute measurement methods, in which the data from the encoder, digital compass, and laser scanner sensor are fused using the extended Kalman filter (EKF). The system also successfully eliminates the errors caused by the environment as well as the error accumulation. The experimental results show good accuracy and stability of position and orientation which can be further applied for the robot working in the indoor environment.      
### 76.Encoding Distributional Soft Actor-Critic for Autonomous Driving in Multi-lane Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2109.05540.pdf)
>  In this paper, we propose a new reinforcement learning (RL) algorithm, called encoding distributional soft actor-critic (E-DSAC), for decision-making in autonomous driving. Unlike existing RL-based decision-making methods, E-DSAC is suitable for situations where the number of surrounding vehicles is variable and eliminates the requirement for manually pre-designed sorting rules, resulting in higher policy performance and generality. We first develop an encoding distributional policy iteration (DPI) framework by embedding a permutation invariant module, which employs a feature neural network (NN) to encode the indicators of each vehicle, in the distributional RL framework. The proposed DPI framework is proved to exhibit important properties in terms of convergence and global optimality. Next, based on the developed encoding DPI framework, we propose the E-DSAC algorithm by adding the gradient-based update rule of the feature NN to the policy evaluation process of the DSAC algorithm. Then, the multi-lane driving task and the corresponding reward function are designed to verify the effectiveness of the proposed algorithm. Results show that the policy learned by E-DSAC can realize efficient, smooth, and relatively safe autonomous driving in the designed scenario. And the final policy performance learned by E-DSAC is about three times that of DSAC. Furthermore, its effectiveness has also been verified in real vehicle experiments.      
### 77.Unsupervised Domain Adaptation Schemes for Building ASR in Low-resource Languages  [ :arrow_down: ](https://arxiv.org/pdf/2109.05494.pdf)
>  Building an automatic speech recognition (ASR) system from scratch requires a large amount of annotated speech data, which is difficult to collect in many languages. However, there are cases where the low-resource language shares a common acoustic space with a high-resource language having enough annotated data to build an ASR. In such cases, we show that the domain-independent acoustic models learned from the high-resource language through unsupervised domain adaptation (UDA) schemes can enhance the performance of the ASR in the low-resource language. We use the specific example of Hindi in the source domain and Sanskrit in the target domain. We explore two architectures: i) domain adversarial training using gradient reversal layer (GRL) and ii) domain separation networks (DSN). The GRL and DSN architectures give absolute improvements of 6.71% and 7.32%, respectively, in word error rate over the baseline deep neural network model when trained on just 5.5 hours of data in the target domain. We also show that choosing a proper language (Telugu) in the source domain can bring further improvement. The results suggest that UDA schemes can be helpful in the development of ASR systems for low-resource languages, mitigating the hassle of collecting large amounts of annotated speech data.      
### 78.Facial Anatomical Landmark Detection using Regularized Transfer Learning with Application to Fetal Alcohol Syndrome Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2109.05485.pdf)
>  Fetal alcohol syndrome (FAS) caused by prenatal alcohol exposure can result in a series of cranio-facial anomalies, and behavioral and neurocognitive problems. Current diagnosis of FAS is typically done by identifying a set of facial characteristics, which are often obtained by manual examination. Anatomical landmark detection, which provides rich geometric information, is important to detect the presence of FAS associated facial anomalies. This imaging application is characterized by large variations in data appearance and limited availability of labeled data. Current deep learning-based heatmap regression methods designed for facial landmark detection in natural images assume availability of large datasets and are therefore not wellsuited for this application. To address this restriction, we develop a new regularized transfer learning approach that exploits the knowledge of a network learned on large facial recognition datasets. In contrast to standard transfer learning which focuses on adjusting the pre-trained weights, the proposed learning approach regularizes the model behavior. It explicitly reuses the rich visual semantics of a domain-similar source model on the target task data as an additional supervisory signal for regularizing landmark detection optimization. Specifically, we develop four regularization constraints for the proposed transfer learning, including constraining the feature outputs from classification and intermediate layers, as well as matching activation attention maps in both spatial and channel levels. Experimental evaluation on a collected clinical imaging dataset demonstrate that the proposed approach can effectively improve model generalizability under limited training samples, and is advantageous to other approaches in the literature.      
### 79.EMVLight: A Decentralized Reinforcement Learning Framework for EfficientPassage of Emergency Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2109.05429.pdf)
>  Emergency vehicles (EMVs) play a crucial role in responding to time-critical events such as medical emergencies and fire outbreaks in an urban area. The less time EMVs spend traveling through the traffic, the more likely it would help save people's lives and reduce property loss. To reduce the travel time of EMVs, prior work has used route optimization based on historical traffic-flow data and traffic signal pre-emption based on the optimal route. However, traffic signal pre-emption dynamically changes the traffic flow which, in turn, modifies the optimal route of an EMV. In addition, traffic signal pre-emption practices usually lead to significant disturbances in traffic flow and subsequently increase the travel time for non-EMVs. In this paper, we propose EMVLight, a decentralized reinforcement learning (RL) framework for simultaneous dynamic routing and traffic signal control. EMVLight extends Dijkstra's algorithm to efficiently update the optimal route for the EMVs in real time as it travels through the traffic network. The decentralized RL agents learn network-level cooperative traffic signal phase strategies that not only reduce EMV travel time but also reduce the average travel time of non-EMVs in the network. This benefit has been demonstrated through comprehensive experiments with synthetic and real-world maps. These experiments show that EMVLight outperforms benchmark transportation engineering techniques and existing RL-based signal control methods.      
### 80.Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration  [ :arrow_down: ](https://arxiv.org/pdf/2109.05426.pdf)
>  Given a piece of speech and its transcript text, text-based speech editing aims to generate speech that can be seamlessly inserted into the given speech by editing the transcript. Existing methods adopt a two-stage approach: synthesize the input text using a generic text-to-speech (TTS) engine and then transform the voice to the desired voice using voice conversion (VC). A major problem of this framework is that VC is a challenging problem which usually needs a moderate amount of parallel training data to work satisfactorily. In this paper, we propose a one-stage context-aware framework to generate natural and coherent target speech without any training data of the target speaker. In particular, we manage to perform accurate zero-shot duration prediction for the inserted text. The predicted duration is used to regulate both text embedding and speech embedding. Then, based on the aligned cross-modality input, we directly generate the mel-spectrogram of the edited speech with a transformer-based decoder. Subjective listening tests show that despite the lack of training data for the speaker, our method has achieved satisfactory results. It outperforms a recent zero-shot TTS engine by a large margin.      
### 81.Decoupling Magnitude and Phase Estimation with Deep ResUNet for Music Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2109.05418.pdf)
>  Deep neural network based methods have been successfully applied to music source separation. They typically learn a mapping from a mixture spectrogram to a set of source spectrograms, all with magnitudes only. This approach has several limitations: 1) its incorrect phase reconstruction degrades the performance, 2) it limits the magnitude of masks between 0 and 1 while we observe that 22% of time-frequency bins have ideal ratio mask values of over~1 in a popular dataset, MUSDB18, 3) its potential on very deep architectures is under-explored. Our proposed system is designed to overcome these. First, we propose to estimate phases by estimating complex ideal ratio masks (cIRMs) where we decouple the estimation of cIRMs into magnitude and phase estimations. Second, we extend the separation method to effectively allow the magnitude of the mask to be larger than 1. Finally, we propose a residual UNet architecture with up to 143 layers. Our proposed system achieves a state-of-the-art MSS result on the MUSDB18 dataset, especially, a SDR of 8.98~dB on vocals, outperforming the previous best performance of 7.24~dB. The source code is available at: <a class="link-external link-https" href="https://github.com/bytedance/music_source_separation" rel="external noopener nofollow">this https URL</a>      
### 82.Cost-Effective Federated Learning in Mobile Edge Networks  [ :arrow_down: ](https://arxiv.org/pdf/2109.05411.pdf)
>  Federated learning (FL) is a distributed learning paradigm that enables a large number of mobile devices to collaboratively learn a model under the coordination of a central server without sharing their raw data. Despite its practical efficiency and effectiveness, the iterative on-device learning process (e.g., local computations and global communications with the server) incurs a considerable cost in terms of learning time and energy consumption, which depends crucially on the number of selected clients and the number of local iterations in each training round. In this paper, we analyze how to design adaptive FL in mobile edge networks that optimally chooses these essential control variables to minimize the total cost while ensuring convergence. We establish the analytical relationship between the total cost and the control variables with the convergence upper bound. To efficiently solve the cost minimization problem, we develop a low-cost sampling-based algorithm to learn the convergence related unknown parameters. We derive important solution properties that effectively identify the design principles for different optimization metrics. Practically, we evaluate our theoretical results both in a simulated environment and on a hardware prototype. Experimental evidence verifies our derived properties and demonstrates that our proposed solution achieves near-optimal performance for different optimization metrics for various datasets and heterogeneous system and statistical settings.      
### 83.Hermite Expansion Model and LMMSE Analysis for Low-Resolution Quantized MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.05334.pdf)
>  In this paper, the Hermite polynomials are employed to study linear approximation models of narrowband multiantenna signal reception (i.e., MIMO) with low-resolution quantizations. This study results in a novel linear approximation using the second-order Hermite expansion (SOHE). The SOHE model is not based on those assumptions often used in existing linear approximations. Instead, the quantization distortion is characterized by the second-order Hermite kernel, and the signal term is characterized by the first-order Hermite kernel. It is shown that the SOHE model can explain almost all phenomena and characteristics observed so far in the low-resolution MIMO signal reception. When the SOHE model is employed to analyze the linear minimum-mean-square-error (LMMSE) channel equalizer, it is revealed that the current LMMSE algorithm can be enhanced by incorporating a symbol-level normalization mechanism. The performance of the enhanced LMMSE algorithm is demonstrated through computer simulations for narrowband MIMO systems in Rayleigh fading channels.      
### 84.MLReal: Bridging the gap between training on synthetic data and real data applications in machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2109.05294.pdf)
>  Among the biggest challenges we face in utilizing neural networks trained on waveform data (i.e., seismic, electromagnetic, or ultrasound) is its application to real data. The requirement for accurate labels forces us to develop solutions using synthetic data, where labels are readily available. However, synthetic data often do not capture the reality of the field/real experiment, and we end up with poor performance of the trained neural network (NN) at the inference stage. We describe a novel approach to enhance supervised training on synthetic data with real data features (domain adaptation). Specifically, for tasks in which the absolute values of the vertical axis (time or depth) of the input data are not crucial, like classification, or can be corrected afterward, like velocity model building using a well-log, we suggest a series of linear operations on the input so the training and application data have similar distributions. This is accomplished by applying two operations on the input data to the NN model: 1) The crosscorrelation of the input data (i.e., shot gather, seismic image, etc.) with a fixed reference trace from the same dataset. 2) The convolution of the resulting data with the mean (or a random sample) of the autocorrelated data from another domain. In the training stage, the input data are from the synthetic domain and the auto-correlated data are from the real domain, and random samples from real data are drawn at every training epoch. In the inference/application stage, the input data are from the real subset domain and the mean of the autocorrelated sections are from the synthetic data subset domain. Example applications on passive seismic data for microseismic event source location determination and active seismic data for predicting low frequencies are used to demonstrate the power of this approach in improving the applicability of trained models to real data.      
### 85.Fundamental limits of over-the-air optimization: Are analog schemes optimal?  [ :arrow_down: ](https://arxiv.org/pdf/2109.05222.pdf)
>  We consider over-the-air convex optimization on a $d-$dimensional space where coded gradients are sent over an additive Gaussian noise channel with variance $\sigma^2$. The codewords satisfy an average power constraint $P$, resulting in the signal-to-noise ratio (SNR) of $P/\sigma^2$. We derive bounds for the convergence rates for over-the-air optimization. Our first result is a lower bound for the convergence rate showing that any code must slowdown the convergence rate by a factor of roughly $\sqrt{d/\log(1+\mathtt{SNR})}$. Next, we consider a popular class of schemes called $analog$ $coding$, where a linear function of the gradient is sent. We show that a simple scaled transmission analog coding scheme results in a slowdown in convergence rate by a factor of $\sqrt{d(1+1/\mathtt{SNR})}$. This matches the previous lower bound up to constant factors for low SNR, making the scaled transmission scheme optimal at low SNR. However, we show that this slowdown is necessary for any analog coding scheme. In particular, a slowdown in convergence by a factor of $\sqrt{d}$ for analog coding remains even when SNR tends to infinity. Remarkably, we present a simple quantize-and-modulate scheme that uses $Amplitude$ $Shift$ $Keying$ and almost attains the optimal convergence rate at all SNRs.      
### 86.Autonomous Underwater Vehicle-Manipulator Systems Path Planning with RRTAUVMS Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2109.05208.pdf)
>  Autonomous Underwater Vehicle-Manipulator systems (AUVMS) is a new tool for ocean exploration, the AUVMS path planning problem is addressed in this paper. AUVMS is a high dimension system with a large difference in inertia distribution, also it works in a complex environment with obstacles. By integrating the rapidly-exploring random tree(RRT) algorithm with the AUVMS kinematics model, the proposed RRTAUVMS algorithm could randomly sample in the configuration space(C-Space), and also grow the tree directly towards the workspace goal in the task space. The RRTAUVMS can also deal with the redundant mapping of workspace planning goal and configuration space goal. Compared with the traditional RRT algorithm, the efficiency of the AUVMS path planning can be significantly improved.      
### 87.On the Intercept Probability and Secure Outage Analysis of Mixed ($α$-$κ$-$μ$)-shadowed and Málaga Turbulent Model  [ :arrow_down: ](https://arxiv.org/pdf/2109.05171.pdf)
>  This work deals with the secrecy performance analysis of a dual-hop RF-FSO DF relaying network composed of a source, a relay, a destination, and an eavesdropper. We assume the eavesdropper is located close to the destination and overhears the relay's transmitted optical signal. The RF and FSO links undergo ($\alpha$-$\kappa$-$\mu$)-shadowed fading and unified Málaga turbulence with pointing error. The secrecy performance of the mixed system is studied by deriving closed-form analytical expressions of secure outage probability (SOP), strictly positive secrecy capacity (SPSC), and intercept probability (IP). Besides, we also derive the asymptotic SOP, SPSC, and IP upon utilizing the unfolding of Meijer's G function where the electrical SNR of the FSO link tends to infinity. Finally, the Monte-Carlo simulation is performed to corroborate the analytical expressions. Our results illustrate that fading, shadowing, detection techniques (i.e., heterodyne detection (HD) and intensity modulation and direct detection (IM/DD)), atmospheric turbulence, and pointing error significantly affect the secrecy performance. In addition, better performance is obtained exploiting the HD technique at the destination relative to IM/DD technique.      
### 88.Two-timescale Mechanism-and-Data-Driven Control for Aggressive Driving of Autonomous Cars  [ :arrow_down: ](https://arxiv.org/pdf/2109.05170.pdf)
>  The control for aggressive driving of autonomous cars is challenging due to the presence of significant tyre slip. Data-driven and mechanism-based methods for the modeling and control of autonomous cars under aggressive driving conditions are limited in data efficiency and adaptability respectively. This paper is an attempt toward the fusion of the two classes of methods. By means of a modular design that is consisted of mechanism-based and data-driven components, and aware of the two-timescale phenomenon in the car model, our approach effectively improves over previous methods in terms of data efficiency, ability of transfer and final performance. The hybrid mechanism-and-data-driven approach is verified on TORCS (The Open Racing Car Simulator). Experiment results demonstrate the benefit of our approach over purely mechanism-based and purely data-driven methods.      
### 89.Efficient Noise Mitigation Technique for Quantum Computing  [ :arrow_down: ](https://arxiv.org/pdf/2109.05136.pdf)
>  Quantum computers have enabled solving problems beyond the current computers' capabilities. However, this requires handling noise arising from unwanted interactions in these systems. Several protocols have been proposed to address efficient and accurate quantum noise profiling and mitigation. In this work, we propose a novel protocol that efficiently estimates the average output of a noisy quantum device to be used for quantum noise mitigation. The multi-qubit system average behavior is approximated as a special form of a Pauli Channel where Clifford gates are used to estimate the average output for circuits of different depths. The characterized Pauli channel error rates, and state preparation and measurement errors are then used to construct the outputs for different depths thereby eliminating the need for large simulations and enabling efficient mitigation. We demonstrate the efficiency of the proposed protocol on four IBM Q 5-qubit quantum devices. Our method demonstrates improved accuracy with efficient noise characterization. We report up to 88\% and 69\% improvement for the proposed approach compared to the unmitigated, and pure measurement error mitigation approaches, respectively.      
### 90.Discretization of Annular-Ring Diffraction Pattern for Large-Scale Photonics Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2109.05118.pdf)
>  A solid-state active beamformer based on the annular-ring diffraction pattern is proposed for an integrated photonic platform. Such a circularly symmetric annular-ring aperture achieves radiating element limited FOV. Furthermore, it is demonstrated that a multi-annular-ring aperture with a fixed linear density of elements maintains the beam efficiency for larger apertures while reducing the beamwidth and side-lobe-level (SLL). A 255-element multi-annular-ring OPA with active beamforming is implemented in a standard photonics process. 510 phase and amplitude modulators enable beamforming and beam steering using this aperture. A row-column drive methodology reduces the required electrical drivers by more than a factor of 5.      
### 91.On the Compression of Neural Networks Using $\ell_0$-Norm Regularization and Weight Pruning  [ :arrow_down: ](https://arxiv.org/pdf/2109.05075.pdf)
>  Despite the growing availability of high-capacity computational platforms, implementation complexity still has been a great concern for the real-world deployment of neural networks. This concern is not exclusively due to the huge costs of state-of-the-art network architectures, but also due to the recent push towards edge intelligence and the use of neural networks in embedded applications. In this context, network compression techniques have been gaining interest due to their ability for reducing deployment costs while keeping inference accuracy at satisfactory levels. The present paper is dedicated to the development of a novel compression scheme for neural networks. To this end, a new $\ell_0$-norm-based regularization approach is firstly developed, which is capable of inducing strong sparseness in the network during training. Then, targeting the smaller weights of the trained network with pruning techniques, smaller yet highly effective networks can be obtained. The proposed compression scheme also involves the use of $\ell_2$-norm regularization to avoid overfitting as well as fine tuning to improve the performance of the pruned network. Experimental results are presented aiming to show the effectiveness of the proposed scheme as well as to make comparisons with competing approaches.      
### 92.Simultaneous Perception-Action Design via Invariant Finite Belief Sets  [ :arrow_down: ](https://arxiv.org/pdf/2109.05073.pdf)
>  Although perception is an increasingly dominant portion of the overall computational cost for autonomous systems, only a fraction of the information perceived is likely to be relevant to the current task. To alleviate these perception costs, we develop a novel simultaneous perception-action design framework wherein an agent senses only the task-relevant information. This formulation differs from that of a partially observable Markov decision process, since the agent is free to synthesize not only its policy for action selection but also its belief-dependent observation function. The method enables the agent to balance its perception costs with those incurred by operating in its environment. To obtain a computationally tractable solution, we approximate the value function using a novel method of invariant finite belief sets, wherein the agent acts exclusively on a finite subset of the continuous belief space. We solve the approximate problem through value iteration in which a linear program is solved individually for each belief state in the set, in each iteration. Finally, we prove that the value functions, under an assumption on their structure, converge to their continuous state-space values as the sample density increases.      
### 93.Speaker Turn Modeling for Dialogue Act Classification  [ :arrow_down: ](https://arxiv.org/pdf/2109.05056.pdf)
>  Dialogue Act (DA) classification is the task of classifying utterances with respect to the function they serve in a dialogue. Existing approaches to DA classification model utterances without incorporating the turn changes among speakers throughout the dialogue, therefore treating it no different than non-interactive written text. In this paper, we propose to integrate the turn changes in conversations among speakers when modeling DAs. Specifically, we learn conversation-invariant speaker turn embeddings to represent the speaker turns in a conversation; the learned speaker turn embeddings are then merged with the utterance embeddings for the downstream task of DA classification. With this simple yet effective mechanism, our model is able to capture the semantics from the dialogue content while accounting for different speaker turns in a conversation. Validation on three benchmark public datasets demonstrates superior performance of our model.      
### 94.Symbiotic Hybrid Neural Network Watchdog For Outlier Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.00582.pdf)
>  Neural networks are largely black boxes. A neural network trained to classify fruit may classify a picture of a giraffe as a banana. A neural network watchdog's job is to identify such inputs, allowing a classifier to disregard such data. We investigate whether the watchdog should be separate from the neural network or symbiotically attached. We present empirical evidence that the symbiotic watchdog performs better than when the neural networks are disjoint.      
