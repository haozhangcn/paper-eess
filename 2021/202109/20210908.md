# ArXiv eess --Wed, 8 Sep 2021
### 1.The Convergence of Blockchain, IoT and 6G: Potential, Opportunities, Challenges and Research Roadmap  [ :arrow_down: ](https://arxiv.org/pdf/2109.03184.pdf)
>  The world is undergoing a profound transformation with the advent of intelligent information era. 6G networks envisioned being the game changer in next generation wireless communication systems that will address the challenges of limited information speed escalated with the augmentation of billions of data applications encountered by the current fifth generation (5G) networks. Some key radical technologies in 6G together with existing 5G candidate schemes will guarantee the expected quality of experience (QoE) to attain ubiquitous wireless connectivity for the Internet of Everything (IoE) ranging from the telecom industry to digital smart industries. Blockchain technology (BCT) has gained significant attention due to undertake the decentralization, transparency, spectrum resource scarcity, inherent privacy and security, poor interoperability, confidentiality, and emerging smart applications domains including Industrial IoT and Industry 4.0. The mismatch between the requirements of many data intensive disruptive IoT applications and 5G network capabilities steered the demand of decentralized BCT based 6G architecture. Inspired by these facts, this paper studies an extensive survey to draw a new direction of blockchain integration into 6G mobile networks, IoT technologies, and smart industries focusing the potential merits and challenges in terms of infrastructure sharing, computational loads, latency, bandwidth overhead, business model, sustainability goals, and edge intelligence. We highlighted the convergence of IoT in blockchain to enable intelligent distribution in future industrial IoT and the technical model of 6G networks to realize the successful deployment of BCT schemes. This paper pointed out the current intriguing challenges, canvassed the mitigation techniques, and plausible future research opportunities that may benefit the pursuit of this vision.      
### 2.A Dynamic Population Model of Strategic Interaction and Migration under Epidemic Risk  [ :arrow_down: ](https://arxiv.org/pdf/2109.03182.pdf)
>  In this paper, we show how a dynamic population game can model the strategic interaction and migration decisions made by a large population of agents in response to epidemic prevalence. Specifically, we consider a modified susceptible-asymptomatic-infected-recovered (SAIR) epidemic model over multiple zones. Agents choose whether to activate (i.e., interact with others), how many other agents to interact with, and which zone to move to in a time-scale which is comparable with the epidemic evolution. We define and analyze the notion of equilibrium in this game, and investigate the transient behavior of the epidemic spread in a range of numerical case studies, providing insights on the effects of the agents' degree of future awareness, strategic migration decisions, as well as different levels of lockdown and other interventions. One of our key findings is that the strategic behavior of agents plays an important role in the progression of the epidemic and can be exploited in order to design suitable epidemic control measures.      
### 3.IEEE BigData 2021 Cup: Soft Sensing at Scale  [ :arrow_down: ](https://arxiv.org/pdf/2109.03181.pdf)
>  IEEE BigData 2021 Cup: Soft Sensing at Scale is a data mining competition organized by Seagate Technology, in association with the IEEE BigData 2021 conference. The scope of this challenge is to tackle the task of classifying soft sensing data with machine learning techniques. In this paper we go into the details of the challenge and describe the data set provided to participants. We define the metrics of interest, baseline models, and describe approaches we found meaningful which may be a good starting point for further analysis. We discuss the results obtained with our approaches and give insights on what potential challenges participants may run into. Students, researchers, and anyone interested in working on a major industrial problem are welcome to participate in the challenge!      
### 4.Learning-Based Downlink Power Allocation in Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.03128.pdf)
>  This paper considers a cell-free massive multiple-input multiple-output (MIMO) system that consists of a large number of geographically distributed access points (APs) serving multiple users via coherent joint transmission. The downlink performance of the system is evaluated, with maximum ratio and regularized zero-forcing precoding, under two optimization objectives for power allocation: sum spectral efficiency (SE) maximization and proportional fairness. We present iterative centralized algorithms for solving these problems. Aiming at a less computationally complex and also distributed scalable solution, we train a deep neural network (DNN) to approximate the same network-wide power allocation. Instead of training our DNN to mimic the actual optimization procedure, we use a heuristic power allocation, based on large-scale fading (LSF) parameters, as the pre-processed input to the DNN. We train the DNN to refine the heuristic scheme, thereby providing higher SE, using only local information at each AP. Another distributed DNN that exploits side information assumed to be available at the central processing unit is designed for improved performance. Further, we develop a clustered DNN model where the LSF parameters of a small number of APs, forming a cluster within a relatively large network, are used to jointly approximate the power coefficients of the cluster.      
### 5.Power Management of Microgrid Integrated with Electric Vehicles in Residential Parking Station  [ :arrow_down: ](https://arxiv.org/pdf/2109.03088.pdf)
>  Lately, increasing number of electric vehicles (EVs) in residential parking station has become an important issue, because excessive number of EVs can destabilize the power system during peak hours with high charging power requested. When the power system of the residential parking station takes the structure of microgrid (MG), power provision for the EVs requires efficient power management scheme. To minimize the maintenance cost of the MG and maintain the grid stability, the MG needs to balance the charging/discharging power of EVs in the parking station. To achieve these goals, this paper proposes a charging/discharging algorithm suitable for the power management of the MG configured with EVs. Multi-objective optimization is taken to MG to minimize the maintenance cost and the grid dependency while maximizing the use of photovoltaic (PV) power and the utilization of EVs as energy storage systems (ESSs). In our approach, to increase the usefulness of discharging power of EVs, the base load and the PV power production are considered together for power management to mitigate imbalances incurred between them. As a result, proposed approach demonstrates superior power management performance as compared to other comparable ones.      
### 6.Perceptual Learned Video Compression with Recurrent Conditional GAN  [ :arrow_down: ](https://arxiv.org/pdf/2109.03082.pdf)
>  This paper proposes a Perceptual Learned Video Compression (PLVC) approach with recurrent conditional generative adversarial network. In our approach, the recurrent auto-encoder-based generator learns to fully explore the temporal correlation for compressing video. More importantly, we propose a recurrent conditional discriminator, which judges raw and compressed video conditioned on both spatial and temporal information, including the latent representation, temporal motion and hidden states in recurrent cells. This way, in the adversarial training, it pushes the generated video to be not only spatially photo-realistic but also temporally consistent with groundtruth and coherent among video frames. The experimental results show that the proposed PLVC model learns to compress video towards good perceptual quality at low bit-rate, and outperforms the previous traditional and learned approaches on several perceptual quality metrics. The user study further validates the outstanding perceptual performance of PLVC in comparison with the latest learned video compression approaches and the official HEVC test model (HM 16.20). The codes will be released at <a class="link-external link-https" href="https://github.com/RenYang-home/PLVC" rel="external noopener nofollow">this https URL</a>.      
### 7.Photonics-assisted wideband RF self-interference cancellation with digital domain amplitude and delay pre-matching  [ :arrow_down: ](https://arxiv.org/pdf/2109.02992.pdf)
>  A photonics-based digital and analog self-interference cancellation approach for in-band full-duplex communication systems and frequency-modulated continuous-wave radar systems is reported. One dual-drive Mach-Zehnder modulator is used to implement the analog self-interference cancellation by pre-adjusting the delay and amplitude of the reference signal applied to the dual-drive Mach-Zehnder modulator in the digital domain. The amplitude is determined via the received signal power, while the delay is searched by the cross-correlation and bisection methods. Furthermore, recursive least squared or normalized least mean square algorithms are used to suppress the residual self-interference in the digital domain. Quadrature phase-shift keying modulated signals and linearly frequency-modulated signals are used to experimentally verify the proposed method. The analog cancellation depth is around 20 dB, and the total cancellation depth is more than 36 dB for the 2-Gbaud quadrature phase-shift keying modulated signals. For the linearly frequency-modulated signals, the analog and total cancellation depths are around 19 dB and 34 dB, respectively.      
### 8.FDA: Feature Decomposition and Aggregation for Robust Airway Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2109.02920.pdf)
>  3D Convolutional Neural Networks (CNNs) have been widely adopted for airway segmentation. The performance of 3D CNNs is greatly influenced by the dataset while the public airway datasets are mainly clean CT scans with coarse annotation, thus difficult to be generalized to noisy CT scans (e.g. COVID-19 CT scans). In this work, we proposed a new dual-stream network to address the variability between the clean domain and noisy domain, which utilizes the clean CT scans and a small amount of labeled noisy CT scans for airway segmentation. We designed two different encoders to extract the transferable clean features and the unique noisy features separately, followed by two independent decoders. Further on, the transferable features are refined by the channel-wise feature recalibration and Signed Distance Map (SDM) regression. The feature recalibration module emphasizes critical features and the SDM pays more attention to the bronchi, which is beneficial to extracting the transferable topological features robust to the coarse labels. Extensive experimental results demonstrated the obvious improvement brought by our proposed method. Compared to other state-of-the-art transfer learning methods, our method accurately segmented more bronchi in the noisy CT scans.      
### 9.BioNetExplorer: Architecture-Space Exploration of Bio-Signal Processing Deep Neural Networks for Wearables  [ :arrow_down: ](https://arxiv.org/pdf/2109.02909.pdf)
>  In this work, we propose the BioNetExplorer framework to systematically generate and explore multiple DNN architectures for bio-signal processing in wearables. Our framework adapts key neural architecture parameters to search for an embedded DNN with a low hardware overhead, which can be deployed in wearable edge devices to analyse the bio-signal data and to extract the relevant information, such as arrhythmia and seizure. Our framework also enables hardware-aware DNN architecture search using genetic algorithms by imposing user requirements and hardware constraints (storage, FLOPs, etc.) during the exploration stage, thereby limiting the number of networks explored. Moreover, BioNetExplorer can also be used to search for DNNs based on the user-required output classes; for instance, a user might require a specific output class due to genetic predisposition or a pre-existing heart condition. The use of genetic algorithms reduces the exploration time, on average, by 9x, compared to exhaustive exploration. We are successful in identifying Pareto-optimal designs, which can reduce the storage overhead of the DNN by ~30MB for a quality loss of less than 0.5%. To enable low-cost embedded DNNs, BioNetExplorer also employs different model compression techniques to further reduce the storage overhead of the network by up to 53x for a quality loss of &lt;0.2%.      
### 10.Bayesian Multidimensional Scaling for Location Awareness in Hybrid-Internet of Underwater Things  [ :arrow_down: ](https://arxiv.org/pdf/2109.02886.pdf)
>  Localization of sensor nodes in the Internet of Underwater Things (IoUT) is of considerable significance due to its various applications, such as navigation, data tagging, and detection of underwater objects. Therefore, in this paper, we propose a hybrid Bayesian multidimensional scaling (BMDS) based localization technique that can work on a fully hybrid IoUT network where the nodes can communicate using either optical, magnetic induction, and acoustic technologies. These technologies are already used for communication in the underwater environment; however, lacking localization solutions. Optical and magnetic induction communication achieves higher data rates for short communication. On the contrary, acoustic waves provide a low data rate for long-range underwater communication. The proposed method collectively uses optical, magnetic induction, and acoustic communication-based ranging to estimate the underwater sensor nodes' final locations. Moreover, we also analyze the proposed scheme by deriving the hybrid Cramer Rao lower bound (HCRLB). Simulation results provide a complete comparative analysis of the proposed method with the literature.      
### 11.The DKU-DukeECE System for the Self-Supervision Speaker Verification Task of the 2021 VoxCeleb Speaker Recognition Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2109.02853.pdf)
>  This report describes the submission of the DKU-DukeECE team to the self-supervision speaker verification task of the 2021 VoxCeleb Speaker Recognition Challenge (VoxSRC). Our method employs an iterative labeling framework to learn self-supervised speaker representation based on a deep neural network (DNN). The framework starts with training a self-supervision speaker embedding network by maximizing agreement between different segments within an utterance via a contrastive loss. Taking advantage of DNN's ability to learn from data with label noise, we propose to cluster the speaker embedding obtained from the previous speaker network and use the subsequent class assignments as pseudo labels to train a new DNN. Moreover, we iteratively train the speaker network with pseudo labels generated from the previous step to bootstrap the discriminative power of a DNN. Also, visual modal data is incorporated in this self-labeling framework. The visual pseudo label and the audio pseudo label are fused with a cluster ensemble algorithm to generate a robust supervisory signal for representation learning. Our submission achieves an equal error rate (EER) of 5.58% and 5.59% on the challenge development and test set, respectively.      
### 12.Near-Field Millimeter-Wave Imaging via Arrays in the Shape of Polyline  [ :arrow_down: ](https://arxiv.org/pdf/2109.02842.pdf)
>  This paper proposes a polyline shaped array based system scheme, associated with mechanical scanning along the perpendicular direction of the array, for near-field millimeter-wave (MMW) imaging. Each section of the polyline is a chord of a circle with equal length. The polyline array, which can be realized as a monostatic array or a multistatic one, is capable of providing more observation angles than the linear or planar arrays. Further, we present the related three-dimensional (3-D) imaging algorithms based on a hybrid processing in the time domain and the spatial frequency domain. The nonuniform fast Fourier transform (NUFFT) is utilized to improve the computational efficiency. Simulations and experimental results are provided to demonstrate the efficacy of the proposed method in comparison with the back-projection (BP) algorithm.      
### 13.A Recursive Delay Estimation Algorithm for Linear Multivariable Systems with Time-varying Delays  [ :arrow_down: ](https://arxiv.org/pdf/2109.02767.pdf)
>  Time delay estimation plays a critical role in control, stabilization and state estimation of many practical system with time delay. In this paper, we propose a method to estimate delay for discrete time linear multiple-input multiple-output systems with time-varying input delays. This method is purposefully given for situations where only a limited amount of information is available for the system. Although, this approach is primarily developed in a deterministic framework, it can also be applied to noisy data under special circumstances. In addition, switched linear autoregressive models with exogenous inputs are introduced as possible applications of the presented algorithm provided that the switching frequencies are small. Finally, effectiveness of the algorithm is illustrated by two numerical examples.      
### 14.Motion Artifact Reduction In Photoplethysmography For Reliable Signal Selection  [ :arrow_down: ](https://arxiv.org/pdf/2109.02755.pdf)
>  Photoplethysmography (PPG) is a non-invasive and economical technique to extract vital signs of the human body. Although it has been widely used in consumer and research grade wrist devices to track a user's physiology, the PPG signal is very sensitive to motion which can corrupt the signal's quality. Existing Motion Artifact (MA) reduction techniques have been developed and evaluated using either synthetic noisy signals or signals collected during high-intensity activities - both of which are difficult to generalize for real-life scenarios. Therefore, it is valuable to collect realistic PPG signals while performing Activities of Daily Living (ADL) to develop practical signal denoising and analysis methods. In this work, we propose an automatic pseudo clean PPG generation process for reliable PPG signal selection. For each noisy PPG segment, the corresponding pseudo clean PPG reduces the MAs and contains rich temporal details depicting cardiac features. Our experimental results show that 71% of the pseudo clean PPG collected from ADL can be considered as high quality segment where the derived MAE of heart rate and respiration rate are 1.46 BPM and 3.93 BrPM, respectively. Therefore, our proposed method can determine the reliability of the raw noisy PPG by considering quality of the corresponding pseudo clean PPG signal.      
### 15.End to end hyperspectral imaging system with coded compression imaging process  [ :arrow_down: ](https://arxiv.org/pdf/2109.02643.pdf)
>  Hyperspectral images (HSIs) can provide rich spatial and spectral information with extensive application prospects. Recently, several methods using convolutional neural networks (CNNs) to reconstruct HSIs have been developed. However, most deep learning methods fit a brute-force mapping relationship between the compressive and standard HSIs. Thus, the learned mapping would be invalid when the observation data deviate from the training data. To recover the three-dimensional HSIs from two-dimensional compressive images, we present dual-camera equipment with a physics-informed self-supervising CNN method based on a coded aperture snapshot spectral imaging system. Our method effectively exploits the spatial-spectral relativization from the coded spectral information and forms a self-supervising system based on the camera quantum effect model. The experimental results show that our method can be adapted to a wide imaging environment with good performance. In addition, compared with most of the network-based methods, our system does not require a dedicated dataset for pre-training. Therefore, it has greater scenario adaptability and better generalization ability. Meanwhile, our system can be constantly fine-tuned and self-improved in real-life scenarios.      
### 16.Subsystem-Based Control with Modularity for Strict-Feedback Form Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2109.03222.pdf)
>  This study proposes an adaptive subsystem-based control (SBC) for systematic and straightforward nonlinear~control of nth-order strict-feedback form (SFF) systems.~By decomposing the SFF system to subsystems, a generic~term (namely stability connector) can be created to address dynamic interactions between the subsystems. This 1) enables modular control design with global asymptotic stability, 2) such that both the control design and the stability analysis can be performed locally at a subsystem level, 3) while avoiding an excessive growth of the control design complexity when the system order n increases. The latter property makes the method suitable especially for high-dimensional systems. We also design a smooth projection function for addressing system parametric uncertainties. Numerical simulations demonstrate the efficiency of the method.      
### 17.Fruit-CoV: An Efficient Vision-based Framework for Speedy Detection and Diagnosis of SARS-CoV-2 Infections Through Recorded Cough Sounds  [ :arrow_down: ](https://arxiv.org/pdf/2109.03219.pdf)
>  SARS-CoV-2 is colloquially known as COVID-19 that had an initial outbreak in December 2019. The deadly virus has spread across the world, taking part in the global pandemic disease since March 2020. In addition, a recent variant of SARS-CoV-2 named Delta is intractably contagious and responsible for more than four million deaths over the world. Therefore, it is vital to possess a self-testing service of SARS-CoV-2 at home. In this study, we introduce Fruit-CoV, a two-stage vision framework, which is capable of detecting SARS-CoV-2 infections through recorded cough sounds. Specifically, we convert sounds into Log-Mel Spectrograms and use the EfficientNet-V2 network to extract its visual features in the first stage. In the second stage, we use 14 convolutional layers extracted from the large-scale Pretrained Audio Neural Networks for audio pattern recognition (PANNs) and the Wavegram-Log-Mel-CNN to aggregate feature representations of the Log-Mel Spectrograms. Finally, we use the combined features to train a binary classifier. In this study, we use a dataset provided by the AICovidVN 115M Challenge, which includes a total of 7371 recorded cough sounds collected throughout Vietnam, India, and Switzerland. Experimental results show that our proposed model achieves an AUC score of 92.8% and ranks the 1st place on the leaderboard of the AICovidVN Challenge. More importantly, our proposed framework can be integrated into a call center or a VoIP system to speed up detecting SARS-CoV-2 infections through online/recorded cough sounds.      
### 18.Improving Phenotype Prediction using Long-Range Spatio-Temporal Dynamics of Functional Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2109.03115.pdf)
>  The study of functional brain connectivity (FC) is important for understanding the underlying mechanisms of many psychiatric disorders. Many recent analyses adopt graph convolutional networks, to study non-linear interactions between functionally-correlated states. However, although patterns of brain activation are known to be hierarchically organised in both space and time, many methods have failed to extract powerful spatio-temporal features. To overcome those challenges, and improve understanding of long-range functional dynamics, we translate an approach, from the domain of skeleton-based action recognition, designed to model interactions across space and time. We evaluate this approach using the Human Connectome Project (HCP) dataset on sex classification and fluid intelligence prediction. To account for subject topographic variability of functional organisation, we modelled functional connectomes using multi-resolution dual-regressed (subject-specific) ICA nodes. Results show a prediction accuracy of 94.4% for sex classification (an increase of 6.2% compared to other methods), and an improvement of correlation with fluid intelligence of 0.325 vs 0.144, relative to a baseline model that encodes space and time separately. Results suggest that explicit encoding of spatio-temporal dynamics of brain functional activity may improve the precision with which behavioural and cognitive phenotypes may be predicted in the future.      
### 19.On the Effective Rate of NOMA in Underlay Spectrum Sharing  [ :arrow_down: ](https://arxiv.org/pdf/2109.03058.pdf)
>  In this paper, we present the delay-constrained performance analysis of a multi-antenna-assisted multiuser non-orthogonal multiple access (NOMA) based spectrum sharing system over Rayleigh fading channels. We derive analytical expressions for the sum effective rate (ER) for the downlink NOMA system under a peak interference constraint. In particular, we show the effect of the availability of different levels of channel state information (instantaneous and statistical) on the system performance. We also show the effect of different parameters of interest, including the peak tolerable interference power, the delay exponent, the number of antennas and the number of users, on the sum ER of the system under consideration. An excellent agreement between simulation and theoretical results confirms the accuracy of the analysis.      
### 20.A drl based distributed formation control scheme with stream based collision avoidance  [ :arrow_down: ](https://arxiv.org/pdf/2109.03037.pdf)
>  Formation and collision avoidance abilities are essential for multi-agent systems. Conventional methods usually require a central controller and global information to achieve collaboration, which is impractical in an unknown environment. In this paper, we propose a deep reinforcement learning (DRL) based distributed formation control scheme for autonomous vehicles. A modified stream-based obstacle avoidance method is applied to smoothen the optimal trajectory, and onboard sensors such as Lidar and antenna arrays are used to obtain local relative distance and angle information. The proposed scheme obtains a scalable distributed control policy which jointly optimizes formation tracking error and average collision rate with local observations. Simulation results demonstrate that our method outperforms two other state-of-the-art algorithms on maintaining formation and collision avoidance.      
### 21.High-Resolution Waveform Capture Device on a Cyclone-V FPGA  [ :arrow_down: ](https://arxiv.org/pdf/2109.03026.pdf)
>  We introduce the waveform capture device (WCD), a flexible measurement system capable of recording complex digital signals on trillionth-of-a-second (ps) time scales. The WCD is implemented via modular code on an off-the-shelf field-programmable gate-array (FPGA, Intel/Altera Cyclone V), and incorporates both time-to-digital converter (TDC) and digital storage oscilloscope (DSO) functionality. The device captures a waveform by taking snapshots of a signal as it propagates down an ultra-fast transmission line known as a carry chain (CC). It is calibrated via a novel dynamic phase-shifting (DPS) method that requires substantially less data and resources than the state-of-the-art. Using DPS, we find the measurement resolution - or mean propagation delay from one CC element to the next - to be 4.91 +/- 0.04 ps (4.54 +/- 0.02 ps) for a pulse of logic high (low). Similarly, we find the single-shot precision - or mean error on the timing of the waveform - to be 29.52 ps (27.14 ps) for pulses of logic high (low). We verify these findings by reproducing commercial oscilloscope measurements of asynchronous ring-oscillators on FPGAs, finding the mean pulse width to be 0.240 +/- 0.002 ns per inverter gate. Finally, we present a careful analysis of design constraints, introduce a novel error correction algorithm, and sketch a simple extension to the analog domain. We also provide the Verilog code instantiating the our design on an FPGA in an Appendix, and make our methods available as an open-source Python library at <a class="link-external link-https" href="https://github.com/Noeloikeau/fpyga" rel="external noopener nofollow">this https URL</a>.      
### 22.Evaluation of an Audio-Video Multimodal Deepfake Dataset using Unimodal and Multimodal Detectors  [ :arrow_down: ](https://arxiv.org/pdf/2109.02993.pdf)
>  Significant advancements made in the generation of deepfakes have caused security and privacy issues. Attackers can easily impersonate a person's identity in an image by replacing his face with the target person's face. Moreover, a new domain of cloning human voices using deep-learning technologies is also emerging. Now, an attacker can generate realistic cloned voices of humans using only a few seconds of audio of the target person. With the emerging threat of potential harm deepfakes can cause, researchers have proposed deepfake detection methods. However, they only focus on detecting a single modality, i.e., either video or audio. On the other hand, to develop a good deepfake detector that can cope with the recent advancements in deepfake generation, we need to have a detector that can detect deepfakes of multiple modalities, i.e., videos and audios. To build such a detector, we need a dataset that contains video and respective audio deepfakes. We were able to find a most recent deepfake dataset, Audio-Video Multimodal Deepfake Detection Dataset (FakeAVCeleb), that contains not only deepfake videos but synthesized fake audios as well. We used this multimodal deepfake dataset and performed detailed baseline experiments using state-of-the-art unimodal, ensemble-based, and multimodal detection methods to evaluate it. We conclude through detailed experimentation that unimodals, addressing only a single modality, video or audio, do not perform well compared to ensemble-based methods. Whereas purely multimodal-based baselines provide the worst performance.      
### 23.Stealthy Cyber-Attack Design Using Dynamic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2109.02954.pdf)
>  This paper addresses the issue of data injection attacks on control systems. We consider attacks which aim at maximizing system disruption while staying undetected in the finite horizon. The maximum possible disruption caused by such attacks is formulated as a non-convex optimization problem whose dual problem is a convex semi-definite program. We show that the duality gap is zero using S-lemma. To determine the optimal attack vector, we formulate a soft-constrained optimization problem using the Lagrangian dual function. The framework of dynamic programming for indefinite cost functions is used to solve the soft-constrained optimization problem and determine the attack vector. Using the Karush-Kuhn-Tucker conditions, we also provide necessary and sufficient conditions under which the obtained attack vector is optimal to the primal problem.      
### 24.Exploiting Simultaneous Low-Rank and Sparsity in Delay-Angular Domain for Millimeter-Wave/Terahertz Wideband Massive Access  [ :arrow_down: ](https://arxiv.org/pdf/2109.02911.pdf)
>  Millimeter-wave (mmW)/Terahertz (THz) wideband communication employing a large-scale antenna array is a promising technique of the sixth-generation (6G) wireless network for realizing massive machine-type communications (mMTC). To reduce the access latency and the signaling overhead, we design a grant-free random access scheme based on joint active device detection and channel estimation (JADCE) for mmW/THz wideband massive access. In particular, by exploiting the simultaneously sparse and low-rank structure of mmW/THz channels with spreads in the delay-angular domain, we propose two multi-rank aware JADCE algorithms via applying the quotient geometry of product of complex rank-$L$ matrices with the number of clusters $L$. It is proved that the proposed algorithms require a smaller number of measurements than the currently known bounds on measurements of conventional simultaneously sparse and low-rank recovery algorithms. Statistical analysis also shows that the proposed algorithms can linearly converge to the ground truth with low computational complexity. Finally, extensive simulation results confirm the superiority of the proposed algorithms in terms of the accuracy of both activity detection and channel estimation.      
### 25.Analysis of MRI Biomarkers for Brain Cancer Survival Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2109.02785.pdf)
>  Prediction of Overall Survival (OS) of brain cancer patients from multi-modal MRI is a challenging field of research. Most of the existing literature on survival prediction is based on Radiomic features, which does not consider either non-biological factors or the functional neurological status of the patient(s). Besides, the selection of an appropriate cut-off for survival and the presence of censored data create further problems. Application of deep learning models for OS prediction is also limited due to the lack of large annotated publicly available datasets. In this scenario we analyse the potential of two novel neuroimaging feature families, extracted from brain parcellation atlases and spatial habitats, along with classical radiomic and geometric features; to study their combined predictive power for analysing overall survival. A cross validation strategy with grid search is proposed to simultaneously select and evaluate the most predictive feature subset based on its predictive power. A Cox Proportional Hazard (CoxPH) model is employed for univariate feature selection, followed by the prediction of patient-specific survival functions by three multivariate parsimonious models viz. Coxnet, Random survival forests (RSF) and Survival SVM (SSVM). The brain cancer MRI data used for this research was taken from two open-access collections TCGA-GBM and TCGA-LGG available from The Cancer Imaging Archive (TCIA). Corresponding survival data for each patient was downloaded from The Cancer Genome Atlas (TCGA). A high cross validation $C-index$ score of $0.82\pm.10$ was achieved using RSF with the best $24$ selected features. Age was found to be the most important biological predictor. There were $9$, $6$, $6$ and $2$ features selected from the parcellation, habitat, radiomic and region-based feature groups respectively.      
### 26.FastAudio: A Learnable Audio Front-End for Spoof Speech Detection  [ :arrow_down: ](https://arxiv.org/pdf/2109.02774.pdf)
>  Voice assistants, such as smart speakers, have exploded in popularity. It is currently estimated that the smart speaker adoption rate has exceeded 35% in the US adult population. Manufacturers have integrated speaker identification technology, which attempts to determine the identity of the person speaking, to provide personalized services to different members of the same family. Speaker identification can also play an important role in controlling how the smart speaker is used. For example, it is not critical to correctly identify the user when playing music. However, when reading the user's email out loud, it is critical to correctly verify the speaker that making the request is the authorized user. Speaker verification systems, which authenticate the speaker identity, are therefore needed as a gatekeeper to protect against various spoofing attacks that aim to impersonate the enrolled user. This paper compares popular learnable front-ends which learn the representations of audio by joint training with downstream tasks (End-to-End). We categorize the front-ends by defining two generic architectures and then analyze the filtering stages of both types in terms of learning constraints. We propose replacing fixed filterbanks with a learnable layer that can better adapt to anti-spoofing tasks. The proposed FastAudio front-end is then tested with two popular back-ends to measure the performance on the LA track of the ASVspoof 2019 dataset. The FastAudio front-end achieves a relative improvement of 27% when compared with fixed front-ends, outperforming all other learnable front-ends on this task.      
### 27.Complementing Handcrafted Features with Raw Waveform Using a Light-weight Auxiliary Model  [ :arrow_down: ](https://arxiv.org/pdf/2109.02773.pdf)
>  An emerging trend in audio processing is capturing low-level speech representations from raw waveforms. These representations have shown promising results on a variety of tasks, such as speech recognition and speech separation. Compared to handcrafted features, learning speech features via backpropagation provides the model greater flexibility in how it represents data for different tasks theoretically. However, results from empirical study shows that, in some tasks, such as voice spoof detection, handcrafted features are more competitive than learned features. Instead of evaluating handcrafted features and raw waveforms independently, this paper proposes an Auxiliary Rawnet model to complement handcrafted features with features learned from raw waveforms. A key benefit of the approach is that it can improve accuracy at a relatively low computational cost. The proposed Auxiliary Rawnet model is tested using the ASVspoof 2019 dataset and the results from this dataset indicate that a light-weight waveform encoder can potentially boost the performance of handcrafted-features-based encoders in exchange for a small amount of additional computational work.      
### 28.Binaural SoundNet: Predicting Semantics, Depth and Motion with Binaural Sounds  [ :arrow_down: ](https://arxiv.org/pdf/2109.02763.pdf)
>  Humans can robustly recognize and localize objects by using visual and/or auditory cues. While machines are able to do the same with visual data already, less work has been done with sounds. This work develops an approach for scene understanding purely based on binaural sounds. The considered tasks include predicting the semantic masks of sound-making objects, the motion of sound-making objects, and the depth map of the scene. To this aim, we propose a novel sensor setup and record a new audio-visual dataset of street scenes with eight professional binaural microphones and a 360-degree camera. The co-existence of visual and audio cues is leveraged for supervision transfer. In particular, we employ a cross-modal distillation framework that consists of multiple vision teacher methods and a sound student method -- the student method is trained to generate the same results as the teacher methods do. This way, the auditory system can be trained without using human annotations. To further boost the performance, we propose another novel auxiliary task, coined Spatial Sound Super-Resolution, to increase the directional resolution of sounds. We then formulate the four tasks into one end-to-end trainable multi-tasking network aiming to boost the overall performance. Experimental results show that 1) our method achieves good results for all four tasks, 2) the four tasks are mutually beneficial -- training them together achieves the best performance, 3) the number and orientation of microphones are both important, and 4) features learned from the standard spectrogram and features obtained by the classic signal processing pipeline are complementary for auditory perception tasks. The data and code are released.      
### 29.Proportional-Integral Projected Gradient Method for Infeasibility Detection in Conic Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2109.02756.pdf)
>  A constrained optimization problem is primal infeasible if its constraints cannot be satisfied, and dual infeasible if the constraints of its dual problem cannot be satisfied. We propose a novel iterative method, named proportional-integral projected gradient method (PIPG), for detecting primal and dual infeasiblity in convex optimization with quadratic objective function and conic constraints. The iterates of PIPG either asymptotically provide a proof of primal or dual infeasibility, or asymptotically satisfy a set of primal-dual optimality conditions. Unlike existing methods, PIPG does not compute matrix inverse, which makes it better suited for large-scale and real-time applications. We demonstrate the application of PIPG in quasiconvex and mixed-integer optimization using examples in constrained optimal control.      
### 30.OKSP: A Novel Deep Learning Automatic Event Detection Pipeline for Seismic Monitoringin Costa Rica  [ :arrow_down: ](https://arxiv.org/pdf/2109.02723.pdf)
>  Small magnitude earthquakes are the most abundant but the most difficult to locate robustly and well due to their low amplitudes and high frequencies usually obscured by heterogeneous noise sources. They highlight crucial information about the stress state and the spatio-temporal behavior of fault systems during the earthquake cycle, therefore, its full characterization is then crucial for improving earthquake hazard assessment. Modern DL algorithms along with the increasing computational power are exploiting the continuously growing seismological databases, allowing scientists to improve the completeness for earthquake catalogs, systematically detecting smaller magnitude earthquakes and reducing the errors introduced mainly by human intervention. In this work, we introduce OKSP, a novel automatic earthquake detection pipeline for seismic monitoring in Costa Rica. Using Kabre supercomputer from the Costa Rica High Technology Center, we applied OKSP to the day before and the first 5 days following the Puerto Armuelles, M6.5, earthquake that occurred on 26 June, 2019, along the Costa Rica-Panama border and found 1100 more earthquakes previously unidentified by the Volcanological and Seismological Observatory of Costa Rica. From these events, a total of 23 earthquakes with magnitudes below 1.0 occurred a day to hours prior to the mainshock, shedding light about the rupture initiation and earthquake interaction leading to the occurrence of this productive seismic sequence. Our observations show that for the study period, the model was 100% exhaustive and 82% precise, resulting in an F1 score of 0.90. This effort represents the very first attempt for automatically detecting earthquakes in Costa Rica using deep learning methods and demonstrates that, in the near future, earthquake monitoring routines will be carried out entirely by AI algorithms.      
### 31.Large-Scale System Identification Using a Randomized SVD  [ :arrow_down: ](https://arxiv.org/pdf/2109.02703.pdf)
>  Learning a dynamical system from input/output data is a fundamental task in the control design pipeline. In the partially observed setting there are two components to identification: parameter estimation to learn the Markov parameters, and system realization to obtain a state space model. In both sub-problems it is implicitly assumed that standard numerical algorithms such as the singular value decomposition (SVD) can be easily and reliably computed. When trying to fit a high-dimensional model to data, for example in the cyber-physical system setting, even computing an SVD is intractable. In this work we show that an approximate matrix factorization obtained using randomized methods can replace the standard SVD in the realization algorithm while maintaining the non-asymptotic (in data-set size) performance and robustness guarantees of classical methods. Numerical examples illustrate that for large system models, this is the only method capable of producing a model.      
### 32.Machine Learning: Challenges, Limitations, and Compatibility for Audio Restoration Processes  [ :arrow_down: ](https://arxiv.org/pdf/2109.02692.pdf)
>  In this paper machine learning networks are explored for their use in restoring degraded and compressed speech audio. The project intent is to build a new trained model from voice data to learn features of compression artifacting distortion introduced by data loss from lossy compression and resolution loss with an existing algorithm presented in SEGAN: Speech Enhancement Generative Adversarial Network. The resulting generator from the model was then to be used to restore degraded speech audio. This paper details an examination of the subsequent compatibility and operational issues presented by working with deprecated code, which obstructed the trained model from successfully being developed. This paper further serves as an examination of the challenges, limitations, and compatibility in the current state of machine learning.      
