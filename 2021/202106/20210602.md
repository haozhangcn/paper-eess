# ArXiv eess --Wed, 2 Jun 2021
### 1.High Resolution Time-Frequency Generation with Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00668.pdf)
>  Signal representation in Time-Frequency (TF) domain is valuable in many applications including radar imaging and inverse synthetic aparture radar. TF representation allows us to identify signal components or features in a mixed time and frequency plane. There are several well-known tools, such as Wigner-Ville Distribution (WVD), Short-Time Fourier Transform (STFT) and various other variants for such a purpose. The main requirement for a TF representation tool is to give a high-resolution view of the signal such that the signal components or features are identifiable. A commonly used method is the reassignment process which reduces the cross-terms by artificially moving smoothed WVD values from their actual location to the center of the gravity for that region. In this article, we propose a novel reassignment method using the Conditional Generative Adversarial Network (CGAN). We train a CGAN to perform the reassignment process. Through examples, it is shown that the method generates high-resolution TF representations which are better than the current reassignment methods.      
### 2.Hyperspectral Band Selection for Multispectral Image Classification with Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00645.pdf)
>  In recent years, Hyperspectral Imaging (HSI) has become a powerful source for reliable data in applications such as remote sensing, agriculture, and biomedicine. However, hyperspectral images are highly data-dense and often benefit from methods to reduce the number of spectral bands while retaining the most useful information for a specific application. We propose a novel band selection method to select a reduced set of wavelengths, obtained from an HSI system in the context of image classification. Our approach consists of two main steps: the first utilizes a filter-based approach to find relevant spectral bands based on a collinearity analysis between a band and its neighbors. This analysis helps to remove redundant bands and dramatically reduces the search space. The second step applies a wrapper-based approach to select bands from the reduced set based on their information entropy values, and trains a compact Convolutional Neural Network (CNN) to evaluate the performance of the current selection. We present classification results obtained from our method and compare them to other feature selection methods on two hyperspectral image datasets. Additionally, we use the original hyperspectral data cube to simulate the process of using actual filters in a multispectral imager. We show that our method produces more suitable results for a multispectral sensor design.      
### 3.Multi-modal Point-of-Care Diagnostics for COVID-19 Based On Acoustics and Symptoms  [ :arrow_down: ](https://arxiv.org/pdf/2106.00639.pdf)
>  The research direction of identifying acoustic bio-markers of respiratory diseases has received renewed interest following the onset of COVID-19 pandemic. In this paper, we design an approach to COVID-19 diagnostic using crowd-sourced multi-modal data. The data resource, consisting of acoustic signals like cough, breathing, and speech signals, along with the data of symptoms, are recorded using a web-application over a period of ten months. We investigate the use of statistical descriptors of simple time-frequency features for acoustic signals and binary features for the presence of symptoms. Unlike previous works, we primarily focus on the application of simple linear classifiers like logistic regression and support vector machines for acoustic data while decision tree models are employed on the symptoms data. We show that a multi-modal integration of acoustics and symptoms classifiers achieves an area-under-curve (AUC) of 92.40, a significant improvement over any individual modality. Several ablation experiments are also provided which highlight the acoustic and symptom dimensions that are important for the task of COVID-19 diagnostics.      
### 4.Decoupling Shape and Density for Liver Lesion Synthesis Using Conditional Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00629.pdf)
>  Lesion synthesis received much attention with the rise of efficient generative models for augmenting training data, drawing lesion evolution scenarios, or aiding expert training. The quality and diversity of synthesized data are highly dependent on the annotated data used to train the models, which not rarely struggle to derive very different yet realistic samples from the training ones. That adds an inherent bias to lesion segmentation algorithms and limits synthesizing lesion evolution scenarios efficiently. This paper presents a method for decoupling shape and density for liver lesion synthesis, creating a framework that allows straight-forwardly driving the synthesis. We offer qualitative results that show the synthesis control by modifying shape and density individually, and quantitative results that demonstrate that embedding the density information in the generator model helps to increase lesion segmentation performance compared to using the shape solely.      
### 5.Meta-HAR: Federated Representation Learning for Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.00615.pdf)
>  Human activity recognition (HAR) based on mobile sensors plays an important role in ubiquitous computing. However, the rise of data regulatory constraints precludes collecting private and labeled signal data from personal devices at scale. Federated learning has emerged as a decentralized alternative solution to model training, which iteratively aggregates locally updated models into a shared global model, therefore being able to leverage decentralized, private data without central collection. However, the effectiveness of federated learning for HAR is affected by the fact that each user has different activity types and even a different signal distribution for the same activity type. Furthermore, it is uncertain if a single global model trained can generalize well to individual users or new users with heterogeneous data. In this paper, we propose Meta-HAR, a federated representation learning framework, in which a signal embedding network is meta-learned in a federated manner, while the learned signal representations are further fed into a personalized classification network at each user for activity prediction. In order to boost the representation ability of the embedding network, we treat the HAR problem at each user as a different task and train the shared embedding network through a Model-Agnostic Meta-learning framework, such that the embedding network can generalize to any individual user. Personalization is further achieved on top of the robustly learned representations in an adaptation procedure. We conducted extensive experiments based on two publicly available HAR datasets as well as a newly created HAR dataset. Results verify that Meta-HAR is effective at maintaining high test accuracies for individual users, including new users, and significantly outperforms several baselines, including Federated Averaging, Reptile and even centralized learning in certain cases.      
### 6.Pattern Discovery in Time Series with Byte Pair Encoding  [ :arrow_down: ](https://arxiv.org/pdf/2106.00614.pdf)
>  The growing popularity of wearable sensors has generated large quantities of temporal physiological and activity data. Ability to analyze this data offers new opportunities for real-time health monitoring and forecasting. However, temporal physiological data presents many analytic challenges: the data is noisy, contains many missing values, and each series has a different length. Most methods proposed for time series analysis and classification do not handle datasets with these characteristics nor do they offer interpretability and explainability, a critical requirement in the health domain. We propose an unsupervised method for learning representations of time series based on common patterns identified within them. The patterns are, interpretable, variable in length, and extracted using Byte Pair Encoding compression technique. In this way the method can capture both long-term and short-term dependencies present in the data. We show that this method applies to both univariate and multivariate time series and beats state-of-the-art approaches on a real world dataset collected from wearable sensors.      
### 7.A Compact and Interpretable Convolutional Neural Network for Cross-Subject Driver Drowsiness Detection from Single-Channel EEG  [ :arrow_down: ](https://arxiv.org/pdf/2106.00613.pdf)
>  Driver drowsiness is one of main factors leading to road fatalities and hazards in the transportation industry. Electroencephalography (EEG) has been considered as one of the best physiological signals to detect drivers drowsy states, since it directly measures neurophysiological activities in the brain. However, designing a calibration-free system for driver drowsiness detection with EEG is still a challenging task, as EEG suffers from serious mental and physical drifts across different subjects. In this paper, we propose a compact and interpretable Convolutional Neural Network (CNN) to discover shared EEG features across different subjects for driver drowsiness detection. We incorporate the Global Average Pooling (GAP) layer in the model structure, allowing the Class Activation Map (CAM) method to be used for localizing regions of the input signal that contribute most for classification. Results show that the proposed model can achieve an average accuracy of 73.22% on 11 subjects for 2-class cross-subject EEG signal classification, which is higher than conventional machine learning methods and other state-of-art deep learning methods. It is revealed by the visualization technique that the model has learned biologically explainable features, e.g., Alpha spindles and Theta burst, as evidence for the drowsy state. It is also interesting to see that the model uses artifacts that usually dominate the wakeful EEG, e.g., muscle artifacts and sensor drifts, to recognize the alert state. The proposed model illustrates a potential direction to use CNN models as a powerful tool to discover shared features related to different mental states across different subjects from EEG signals.      
### 8.Weak target detection with multi-bit quantization in colocated MIMO radar  [ :arrow_down: ](https://arxiv.org/pdf/2106.00612.pdf)
>  We consider the weak target detection problem with unknown parameter in colocated multiple-input multiple-output (MIMO) radar. To cope with the sheer amount of data for large-size systems, a multi-bit quantizer is utilized in the sampling process. As a low-complexity alternative to classic generalized likelihood ratio test (GLRT) for quantized data, we propose the multi-bit detector on Rao test with a closed-form test statistic, whose theoretical asymptotic distribution is provided to generalize the actual detection performance. Besides, we refine the design of quantizer by optimized quantization thresholds, which are obtained resorting to the popular particle swarm optimization algorithmthe (PSOA). The simulation is conducted to demonstrate the performance variations of detectors based on unquantized and quantized data. The numerical results corroborate our theoretical analyses and show that the performance with 3-bit quantization approaches the case without quantization.      
### 9.Deep Learning for EEG Seizure Detection in Preterm Infants  [ :arrow_down: ](https://arxiv.org/pdf/2106.00611.pdf)
>  EEG is the gold standard for seizure detection in the newborn infant, but EEG interpretation in the preterm group is particularly challenging; trained experts are scarce and the task of interpreting EEG in real-time is arduous. Preterm infants are reported to have a higher incidence of seizures compared to term infants. Preterm EEG morphology differs from that of term infants, which implies that seizure detection algorithms trained on term EEG may not be appropriate. The task of developing preterm specific algorithms becomes extra-challenging given the limited amount of annotated preterm EEG data available. This paper explores novel deep learning (DL) architectures for the task of neonatal seizure detection in preterm infants. The study tests and compares several approaches to address the problem: training on data from full-term infants; training on data from preterm infants; training on age-specific preterm data and transfer learning. The system performance is assessed on a large database of continuous EEG recordings of 575h in duration. It is shown that the accuracy of a validated term-trained EEG seizure detection algorithm, based on a support vector machine classifier, when tested on preterm infants falls well short of the performance achieved for full-term infants. An AUC of 88.3% was obtained when tested on preterm EEG as compared to 96.6% obtained when tested on term EEG. When re-trained on preterm EEG, the performance marginally increases to 89.7%. An alternative DL approach shows a more stable trend when tested on the preterm cohort, starting with an AUC of 93.3% for the term-trained algorithm and reaching 95.0% by transfer learning from the term model using available preterm data.      
### 10.Deep Learning for Depression Recognition with Audiovisual Cues: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2106.00610.pdf)
>  With the acceleration of the pace of work and life, people have to face more and more pressure, which increases the possibility of suffering from depression. However, many patients may fail to get a timely diagnosis due to the serious imbalance in the doctor-patient ratio in the world. Promisingly, physiological and psychological studies have indicated some differences in speech and facial expression between patients with depression and healthy individuals. Consequently, to improve current medical care, many scholars have used deep learning to extract a representation of depression cues in audio and video for automatic depression detection. To sort out and summarize these works, this review introduces the databases and describes objective markers for automatic depression estimation (ADE). Furthermore, we review the deep learning methods for automatic depression detection to extract the representation of depression from audio and video. Finally, this paper discusses challenges and promising directions related to automatic diagnosing of depression using deep learning technologies.      
### 11.Dynamic-Deep: ECG Task-Aware Compression  [ :arrow_down: ](https://arxiv.org/pdf/2106.00606.pdf)
>  Monitoring medical data, e.g., Electrocardiogram (ECG) signals, is a common application of Internet of Things (IoT) devices. Compression methods are often applied on the massive amounts of sensor data generated before sending it to the Cloud to reduce storage and delivery costs. A lossy compression provides high compression gain (CG) but may reduce the performance of an ECG application (downstream task) due to information loss. Previous works on ECG monitoring focus either on optimizing the signal reconstruction or the task's performance. Instead, we advocate a lossy compression solution that allows configuring a desired performance level on the downstream tasks while maintaining an optimized CG. <br>We propose Dynamic-Deep, a task-aware compression that uses convolutional autoencoders. The compression level is dynamically selected to yield an optimized compression without violating tasks' performance requirements. We conduct an extensive evaluation of our approach on common ECG datasets using two popular ECG applications, which includes heart rate (HR) arrhythmia classification. We demonstrate that Dynamic-Deep improves HR classification F1-score by a factor of 3 and increases CG by up to 83% compared to the previous state-of-the-art (autoencoder-based) compressor. Additionally, Dynamic-Deep has a 67% lower memory footprint. Analyzing Dynamic-Deep on the Google Cloud Platform, we observe a 97% reduction in cloud costs compared to a no compression solution. <br>To the best of our knowledge, Dynamic-Deep is the first proposal to focus on balancing the need for high performance of cloud-based downstream tasks and the desire to achieve optimized compression in IoT ECG monitoring settings.      
### 12.Deep Reinforcement Learning for Radio Resource Allocation and Management in Next Generation Heterogeneous Wireless Networks: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2106.00574.pdf)
>  Next generation wireless networks are expected to be extremely complex due to their massive heterogeneity in terms of the types of network architectures they incorporate, the types and numbers of smart IoT devices they serve, and the types of emerging applications they support. In such large-scale and heterogeneous networks (HetNets), radio resource allocation and management (RRAM) becomes one of the major challenges encountered during system design and deployment. In this context, emerging Deep Reinforcement Learning (DRL) techniques are expected to be one of the main enabling technologies to address the RRAM in future wireless HetNets. In this paper, we conduct a systematic in-depth, and comprehensive survey of the applications of DRL techniques in RRAM for next generation wireless networks. Towards this, we first overview the existing traditional RRAM methods and identify their limitations that motivate the use of DRL techniques in RRAM. Then, we provide a comprehensive review of the most widely used DRL algorithms to address RRAM problems, including the value- and policy-based algorithms. The advantages, limitations, and use-cases for each algorithm are provided. We then conduct a comprehensive and in-depth literature review and classify existing related works based on both the radio resources they are addressing and the type of wireless networks they are investigating. To this end, we carefully identify the types of DRL algorithms utilized in each related work, the elements of these algorithms, and the main findings of each related work. Finally, we highlight important open challenges and provide insights into several future research directions in the context of DRL-based RRAM. This survey is intentionally designed to guide and stimulate more research endeavors towards building efficient and fine-grained DRL-based RRAM schemes for future wireless networks.      
### 13.Supervised Speech Representation Learning for Parkinson's Disease Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.00531.pdf)
>  Recently proposed automatic pathological speech classification techniques use unsupervised auto-encoders to obtain a high-level abstract representation of speech. Since these representations are learned based on reconstructing the input, there is no guarantee that they are robust to pathology-unrelated cues such as speaker identity information. Further, these representations are not necessarily discriminative for pathology detection. In this paper, we exploit supervised auto-encoders to extract robust and discriminative speech representations for Parkinson's disease classification. To reduce the influence of speaker variabilities unrelated to pathology, we propose to obtain speaker identity-invariant representations by adversarial training of an auto-encoder and a speaker identification task. To obtain a discriminative representation, we propose to jointly train an auto-encoder and a pathological speech classifier. Experimental results on a Spanish database show that the proposed supervised representation learning methods yield more robust and discriminative representations for automatically classifying Parkinson's disease speech, outperforming the baseline unsupervised representation learning system.      
### 14.Two-stage domain adapted training for better generalization in real-world image restoration and super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.00504.pdf)
>  It is well-known that in inverse problems, end-to-end trained networks overfit the degradation model seen in the training set, i.e., they do not generalize to other types of degradations well. Recently, an approach to first map images downsampled by unknown filters to bicubicly downsampled look-alike images was proposed to successfully super-resolve such images. In this paper, we show that any inverse problem can be formulated by first mapping the input degraded images to an intermediate domain, and then training a second network to form output images from these intermediate images. Furthermore, the best intermediate domain may vary according to the task. Our experimental results demonstrate that this two-stage domain-adapted training strategy does not only achieve better results on a given class of unknown degradations but can also generalize to other unseen classes of degradations better.      
### 15.RAI-Net: Range-Adaptive LiDAR Point Cloud Frame Interpolation Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.00496.pdf)
>  LiDAR point cloud frame interpolation, which synthesizes the intermediate frame between the captured frames, has emerged as an important issue for many applications. Especially for reducing the amounts of point cloud transmission, it is by predicting the intermediate frame based on the reference frames to upsample data to high frame rate ones. However, due to high-dimensional and sparse characteristics of point clouds, it is more difficult to predict the intermediate frame for LiDAR point clouds than videos. In this paper, we propose a novel LiDAR point cloud frame interpolation method, which exploits range images (RIs) as an intermediate representation with CNNs to conduct the frame interpolation process. Considering the inherited characteristics of RIs differ from that of color images, we introduce spatially adaptive convolutions to extract range features adaptively, while a high-efficient flow estimation method is presented to generate optical flows. The proposed model then warps the input frames and range features, based on the optical flows to synthesize the interpolated frame. Extensive experiments on the KITTI dataset have clearly demonstrated that our method consistently achieves superior frame interpolation results with better perceptual quality to that of using state-of-the-art video frame interpolation methods. The proposed method could be integrated into any LiDAR point cloud compression systems for inter prediction.      
### 16.COV-ECGNET: COVID-19 detection using ECG trace images with deep convolutional neural network  [ :arrow_down: ](https://arxiv.org/pdf/2106.00436.pdf)
>  The reliable and rapid identification of the COVID-19 has become crucial to prevent the rapid spread of the disease, ease lockdown restrictions and reduce pressure on public health infrastructures. Recently, several methods and techniques have been proposed to detect the SARS-CoV-2 virus using different images and data. However, this is the first study that will explore the possibility of using deep convolutional neural network (CNN) models to detect COVID-19 from electrocardiogram (ECG) trace images. In this work, COVID-19 and other cardiovascular diseases (CVDs) were detected using deep-learning techniques. A public dataset of ECG images consists of 1937 images from five distinct categories, such as Normal, COVID-19, myocardial infarction (MI), abnormal heartbeat (AHB), and recovered myocardial infarction (RMI) were used in this study. Six different deep CNN models (ResNet18, ResNet50, ResNet101, InceptionV3, DenseNet201, and MobileNetv2) were used to investigate three different classification schemes: two-class classification (Normal vs COVID-19); three-class classification (Normal, COVID-19, and Other CVDs), and finally, five-class classification (Normal, COVID-19, MI, AHB, and RMI). For two-class and three-class classification, Densenet201 outperforms other networks with an accuracy of 99.1%, and 97.36%, respectively; while for the five-class classification, InceptionV3 outperforms others with an accuracy of 97.83%. ScoreCAM visualization confirms that the networks are learning from the relevant area of the trace images. Since the proposed method uses ECG trace images which can be captured by smartphones and are readily available facilities in low-resources countries, this study will help in faster computer-aided diagnosis of COVID-19 and other cardiac abnormalities.      
### 17.Noise will be noise: Or phase optimized recursive filters for interference suppression, signal differentiation and state estimation (extended version)  [ :arrow_down: ](https://arxiv.org/pdf/2106.00434.pdf)
>  The increased temporal and spectral resolution of oversampled systems allows many sensor-signal analysis tasks to be performed (e.g. detection, classification and tracking) using a filterbank of low-pass digital differentiators. Such filters are readily designed via flatness constraints on the derivatives of the complex frequency response at dc, pi and at the centre frequencies of narrowband interferers, i.e. using maximally-flat (MaxFlat) designs. Infinite-impulse-response (IIR) filters are ideal in embedded online systems with high data-rates because computational complexity is independent of their (fading) memory. A novel procedure for the design of MaxFlat IIR filterbanks with improved passband phase linearity is presented in this paper, as a possible alternative to Kalman and Wiener filters in a class of derivative-state estimation problems with uncertain signal models. Butterworth poles are used for configurable bandwidth and guaranteed stability. Flatness constraints of arbitrary order are derived for temporal derivatives of arbitrary order and a prescribed group delay. As longer lags (in samples) are readily accommodated in oversampled systems, an expression for the optimal group delay that minimizes the white-noise gain (i.e. the error variance of the derivative estimate at steady state) is derived. Filter zeros are optimally placed for the required passband phase response and the cancellation of narrowband interferers in the stopband, by solving a linear system of equations. Low complexity filterbank realizations are discussed then their behaviour is analysed in a Teager-Kaiser operator to detect pulsed signals and in a state observer to track manoeuvring targets in simulated scenarios.      
### 18.End-to-end Learning of a Constellation Shape Robust to Variations in SNR and Laser Linewidth  [ :arrow_down: ](https://arxiv.org/pdf/2106.00431.pdf)
>  We propose an autoencoder-based geometric shaping that learns a constellation robust to SNR and laser linewidth estimation errors. This constellation maintains shaping gain in mutual information (up to 0.3 bits/symbol) with respect to QAM over various SNR and laser linewidth values.      
### 19.Age of Loop for Wireless Networked Control Systems Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.00415.pdf)
>  Joint design of control and communication in Wireless Networked Control Systems (WNCS) is a promising approach for future wireless industrial applications. In this context, Age of Information (AoI) has been increasingly utilized as a metric that is more representative than latency in the context of systems with a sense-compute-actuate cycle. Nevertheless, AoI is commonly defined for a single communication direction, Downlink or Uplink, which does not capture the closed-loop dynamics. In this paper, we extend the concept of AoI by defining a new metric, Age of Loop (AoL), relevant for WNCS closed-loop systems. The AoL is defined as the time elapsed since the piece of information causing the latest action or state (depending on the selected time origin) was generated. We then use the proposed metric to learn the WNCS latency and freshness bounds and we apply such learning methodology to minimize the long term WNCS cost with the least amount of bandwidth. We show that, using the AoL, we can learn the control system requirement and use this information to optimize network resources.      
### 20.Time Division Multiplexing: From a Co-Prime Sampling Point of View  [ :arrow_down: ](https://arxiv.org/pdf/2106.00405.pdf)
>  Co-prime sampling is a strategy for acquiring the signal below the Nyquist rate. The prototype and extended co-prime samplers require two low rate sub-samplers. One of the sub-samplers in the extended co-prime scheme is not utilized for every alternate co-prime period. Therefore, this paper proposes a time multiplexing strategy to utilize the vacant slots. It describes the deviation from the existing theory. Closed-form expressions for weight functions are provided. Acquisition of two signals is described with three samplers as well as two samplers. A generalized structure is also proposed with an extremely sparse co-prime sampling strategy.      
### 21.Single-Pixel Compressive Imaging in Shift-Invariant Spaces via Exact Wavelet Frames  [ :arrow_down: ](https://arxiv.org/pdf/2106.00404.pdf)
>  This paper introduces a novel framework for single-pixel imaging via compressive sensing (CS) in shift-invariant (SI) spaces by exploiting the sparsity property of a wavelet representation. We reinterpret the acquisition procedure of a single-pixel camera as filtering of the observed signal with continuous-domain functions that lie in an SI subspace spanned by the integer shifts of the box function. The signal is modeled by an arbitrary SI generator whose special case is the box function, which, as we show in the paper, is conventionally used in single-pixel imaging. We propose to use separable B-spline generators which are intuitively complemented by sparsity-inducing spline wavelets. The SI models of the acquisition and the underlying signal lead to an exact discretization of an inherently continuous-domain inverse problem to a finite-dimensional problem of CS type. By solving the CS optimization problem, a parametric representation of the signal is obtained. Such a representation offers many practical advantages in image processing applications. We propose an efficient matrix-free implementation of the framework and conduct it on the standard test images and real-world measurement data. Experimental results show that the proposed framework achieves a significant improvement of the reconstruction quality relative to the conventional CS setting.      
### 22.A Question of Time: Revisiting the Use of Recursive Filtering for Temporal Calibration of Multisensor Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.00391.pdf)
>  We examine the problem of time delay estimation, or temporal calibration, in the context of multisensor data fusion. Differences in processing intervals and other factors typically lead to a relative delay between measurement from two disparate sensors. Correct (optimal) data fusion demands that the relative delay must either be known in advance or identified online. There have been several recent proposals in the literature to determine the delay parameter using recursive, causal filters such as the extended Kalman filter (EKF). We carefully review this formulation and show that there are fundamental issues with the structure of the EKF (and related algorithms) when the delay is included in the filter state vector as a value to be estimated. These structural issues, in turn, leave recursive filters prone to bias and inconsistency. Our theoretical analysis is supported by simulation studies that demonstrate the implications in terms of filter performance; although tuning of the filter noise variances may reduce the chance of inconsistency or divergence, the underlying structural concerns remain. We offer brief suggestions for ways to maintain the computational efficiency of recursive filtering for temporal calibration while avoiding the drawbacks of the standard algorithms.      
### 23.Hybrid Deep Neural Network for Brachial Plexus Nerve Segmentation in Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.00373.pdf)
>  Ultrasound-guided regional anesthesia (UGRA) can replace general anesthesia (GA), improving pain control and recovery time. This method can be applied on the brachial plexus (BP) after clavicular surgeries. However, identification of the BP from ultrasound (US) images is difficult, even for trained professionals. To address this problem, convolutional neural networks (CNNs) and more advanced deep neural networks (DNNs) can be used for identification and segmentation of the BP nerve region. In this paper, we propose a hybrid model consisting of a classification model followed by a segmentation model to segment BP nerve regions in ultrasound images. A CNN model is employed as a classifier to precisely select the images with the BP region. Then, a U-net or M-net model is used for the segmentation. Our experimental results indicate that the proposed hybrid model significantly improves the segmentation performance over a single segmentation model.      
### 24.Refined Transformation Approach for Stabilization of MIMO System by Pole Placement  [ :arrow_down: ](https://arxiv.org/pdf/2106.00355.pdf)
>  The paper presents a distinctive and straightforward technique for stabilization of multi-variable systems. The idea is to decouple the system state matrix depending on different inputs and outputs. Refined special canonical transformations are described for the design of controller and observer for a single-input and single-output (SISO) case and are extended to multi-input multi-output (MIMO) systems. These transformations help in the stabilization of the error dynamics of the observer and in placing the closed loop poles of the system. The idea is not only in the transformations taken but also how the gain matrices are selected which simplifies the computation.      
### 25.3D WaveUNet: 3D Wavelet Integrated Encoder-Decoder Network for Neuron Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00259.pdf)
>  3D neuron segmentation is a key step for the neuron digital reconstruction, which is essential for exploring brain circuits and understanding brain functions. However, the fine line-shaped nerve fibers of neuron could spread in a large region, which brings great computational cost to the segmentation in 3D neuronal images. Meanwhile, the strong noises and disconnected nerve fibers in the image bring great challenges to the task. In this paper, we propose a 3D wavelet and deep learning based 3D neuron segmentation method. The neuronal image is first partitioned into neuronal cubes to simplify the segmentation task. Then, we design 3D WaveUNet, the first 3D wavelet integrated encoder-decoder network, to segment the nerve fibers in the cubes; the wavelets could assist the deep networks in suppressing data noise and connecting the broken fibers. We also produce a Neuronal Cube Dataset (NeuCuDa) using the biggest available annotated neuronal image dataset, BigNeuron, to train 3D WaveUNet. Finally, the nerve fibers segmented in cubes are assembled to generate the complete neuron, which is digitally reconstructed using an available automatic tracing algorithm. The experimental results show that our neuron segmentation method could completely extract the target neuron in noisy neuronal images. The integrated 3D wavelets can efficiently improve the performance of 3D neuron segmentation and reconstruction. The code and pre-trained models for this work will be available at <a class="link-external link-https" href="https://github.com/LiQiufu/3D-WaveUNet" rel="external noopener nofollow">this https URL</a>.      
### 26.UAV Aided Over-the-Air Computation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00254.pdf)
>  Over-the-air computation (AirComp) seamlessly integrates communication and computation by exploiting the waveform superposition property of multiple-access channels. Different from the existing works that focus on transceiver design of AirComp over static networks, this paper considers an unmanned aerial vehicle (UAV) aided AirComp system, where the UAV as a flying base station aggregates data from mobile sensors. The trajectory design of the UAV provides an additional degree of freedom to improve the performance of AirComp. Our goal is to minimize the time-averaged mean-squared error (MSE) of AirComp by jointly optimizing the UAV trajectory, receive normalizing factors, and sensors' transmit power. To this end, we first propose a novel and equivalent problem transformation by introducing intermediate variables. This reformulation leads to a convex subproblem when fixing any other two blocks of variables, thereby enabling efficient algorithm design based on the principle of block coordinate descent and alternating direction method of multipliers (ADMM) techniques. In particular, we derive the optimal closed-form solutions for normalizing factors and intermediate variables optimization subproblems. We also recast the convex trajectory design subproblem into an ADMM form and obtain the closed-form expressions for each variable updating. Simulation results show that the proposed algorithm achieves a smaller time-averaged MSE while reducing the simulation time by orders of magnitude compared to state-of-the-art algorithms.      
### 27.Proactive Scheduling of Hydrogen Systems for Resilience Enhancement of Distribution Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00253.pdf)
>  Recent advances in smart grid technologies bring opportunities to better control the modern and complex power grids with renewable integration. The operation of power systems, especially distribution network (DN), is facing with preeminent challenges from cyber-physical-human (CPH) threats and natural disasters. In order to provide better response against threats and improve the resilience of power grid, proactive plans and operational schemes are required by system operators to minimize the damages caused by CPH threats. To that end, this paper proposes a proactive plan for DN operation by using hydrogen (H2) systems to enhance the resilience through cost-effective long-term energy storage. Unlike batteries, H2 energy can be stored in the storage tanks days before the extreme event, and transformed into power by fuel cell units in the post-event time to reduce load curtailment caused by CPH threats. The proposed framework is validated by testing on 33-node test feeder. Simulation results demonstrate that H2 systems can improve the resilience of DN during $N-m$ outages lasting for more than 10 hours.      
### 28.Comprehensive Nonlinear Optimal Energy Management Scheme for Electrified Powertrains: Application and Implementation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00243.pdf)
>  In this paper we present a benchmark solution with higher number of continuous and discrete states and control levers using validated powertrain component models, where DP fails due to exponential rise in the computation time. The problem involves 13 states and 4 control levers, with complex interactions between multiple subsystems. Some of these variables are discrete while some are continuous. Some have slow dynamics while some have fast dynamics. A novel three step PS3 algorithm which is presented in our prequel paper is used to obtain a near-optimal solution. PS3 algorithm makes use of pseudo spectral method for accurate state estimations. We present three scenarios where only fuel is minimized, only emissions are minimized and, lastly a combination of both fuel and emissions are minimized. All three cases are analyzed for their performance and computation time. The optimal compromise between fuel consumption and emissions are analyzed using a Pareto-front study. This large-scale powertrain optimization problem is solved for a P2 parallel hybrid architecture on a class 6 pick-up &amp; delivery truck.      
### 29.Game-Theoretic Frameworks for Epidemic Spreading and Human Decision Making: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2106.00214.pdf)
>  This review presents and reviews various solved and open problems in developing, analyzing, and mitigating epidemic spreading processes under human decision-making. We provide a review of a range of epidemic models and explain the pros and cons of different epidemic models. We exhibit the art of coupling epidemic models and decision models in the existing literature. More specifically, fundamental questions in human decision-making amid epidemics such as what interventions are taken to combat the disease, who are decision-makers, when interventions are taken, and how interventions are modeled. Among many decision models, game-theoretic models have become increasingly crucial in modeling human responses/behavior amid epidemics in the last decade. <br>In this review, we motivate the game-theoretic approach to human decision-making amid epidemics. This review provides an overview of the existing literature by developing a multi-dimensional taxonomy, which categorizes existing works based on multiple dimensions, including 1) types of games, such as differential games, stochastic games, evolutionary games, and static games; 2) types of interventions, such as social distancing, vaccination, quarantine, taking antidotes, etc.; 3) the types of decision-makers, such as individuals, adversaries, and central authorities at different hierarchical levels. A fine-grained dynamic game framework is proposed to capture the essence of game-theoretic decision-making amid epidemics. From a vast body of works, we showcase three representative works with unique ways of integrating game-theoretic decision-making into the epidemic models. The uniqueness of each of these three works distinguishes themselves from each other regarding their models, analytical approaches, and results. In the end, we identify several main open problems and research gaps left to be addressed and filled.      
### 30.Robust multi-sensor GLMB filter: An application to multi-target tracking with bearing-only sensors  [ :arrow_down: ](https://arxiv.org/pdf/2106.00208.pdf)
>  This paper proposes an efficient and robust algorithm to estimate target trajectories via multi-sensor bearing-only measurements with unknown target detection profiles and clutter rates. In particular, we propose to combine the multi-sensor Generalized Labeled Multi-Bernoulli (MS-GLMB) filter to estimate target trajectories and robust Cardinalized Probability Hypothesis Density (CPHD) filters to estimate the clutter rates. Experimental results show that the proposed robust filter exhibits near-optimal performance in the sense that it is comparable to the optimal MS-GLMB operating with the true clutter rate. More importantly, it outperforms other studied filters when the detection profile and clutter rate are unknown an time-variant. This is attributed to the ability of the robust filter to learn the background parameters on-the-fly.      
### 31.AIRIS: Artificial Intelligence Enhanced Signal Processing in Reconfigurable Intelligent Surface Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.00171.pdf)
>  Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beamforming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.      
### 32.Regularization by Adversarial Learning for Ultrasound Elasticity Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2106.00167.pdf)
>  Classical model-based imaging methods for ultrasound elasticity inverse problem require prior constraints about the underlying elasticity patterns, while finding the appropriate hand-crafted prior for each tissue type is a challenge. In contrast, standard data-driven methods count solely on supervised learning on the training data pairs leading to massive network parameters for unnecessary physical model relearning which might not be consistent with the governing physical models of the imaging system. Fusing the physical forward model and noise statistics with data-adaptive priors leads to a united reconstruction framework that guarantees the learned reconstruction agrees with the physical models while coping with the limited training data. In this paper, we propose a new methodology for estimating the elasticity image by solving a regularized optimization problem which benefits from the physics-based modeling via a data-fidelity term and adversarially learned priors via a regularization term. In this method, the regularizer is trained based on the Wasserstein Generative Adversarial Network (WGAN) objective function which tries to distinguish the distribution of clean and noisy images. Leveraging such an adversarial regularizer for parameterizing the distribution of latent images and using gradient descent (GD) for solving the corresponding regularized optimization task leads to stability and convergence of the reconstruction compared to pixel-wise supervised learning schemes. Our simulation results verify the effectiveness and robustness of the proposed methodology with limited training datasets.      
### 33.Risk-Aware Dimensioning and Procurement of Contingency Reserve  [ :arrow_down: ](https://arxiv.org/pdf/2106.00144.pdf)
>  Current contingency reserve criteria ignore the likelihood of individual contingencies and, thus, their impact on system reliability and risk. This paper develops an iterative approach, inspired by the current security-constrained unit commitment (SCUC) practice, enabling system operators to determine risk-cognizant contingency reserve requirements and their allocation with minimal alterations to the current SCUC practice. The proposed approach uses generator and transmission system reliability models, including failure-to synchronize and adverse conditions, to compute contingency probabilities, which inform a risk-based system reliability assessment, and ensures reserve deliverability by learning the response of generators to post-contingency states within the SCUC. The effectiveness of the proposed approach is demonstrated using the Grid Modernization Lab Consortium update of the Reliability Test System.      
### 34.A Schottky-Diode-Based Wake-Up Receiver for IoT Applications  [ :arrow_down: ](https://arxiv.org/pdf/2106.00140.pdf)
>  This paper presents an always-on low-power wake-up receiver (WuRx) that activates the remainder of the system when a wake-up signal is detected. The proposed receiver has two phases of waking up. The first phase uses an integrated CMOS Schottky diodes to detect the signal power at a low bias current. The approach dissipates low quiescent power and allows the reuse of the design in multiple frequency bands with only modifying the matching network. In the second phase, a data-locked startable oscillator is proposed to correlate the received data with a target signature. This design eliminates the area and power dissipation of an external crystal oscillator and only turns on when the second phase is activated. By correlating to a target signature, the second phase also reduces the probability of a false alarm (PFA) that would otherwise wake up the high-power bulk of the system. The two-phase approach leads to significant reduction in average power consumption when compared to a single-phase design. This implementation targets sub-ms wake-up latency and operates in the unlicensed band at a 750-MHz carrier frequency with a data rate of 200 kbps. The design achieves $\sim$8.45pJ/bit and $&lt;$-50 dBm of input sensitivity and average power of 1.69$\mu$W. The system is implemented in 65-nm CMOS technology and occupies an area of 1mm$\times$0.75mm.      
### 35.Evaluating the Performance of Distributed Optimal Power Flow Algorithms with Nonideal Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.00135.pdf)
>  Power system operators are increasingly looking toward distributed optimization to address various challenges facing electric power systems. To assess their capabilities in environments with nonideal communications, this paper investigates the impacts of data quality on the performance of distributed optimization algorithms. Specifically, this paper compares the performance of the Alternating Direction Method of Multipliers (ADMM), Analytic Target Cascading (ATC), and Auxiliary Principal Problem (APP) algorithms in the context of DC Optimal Power Flow (DC OPF) problems. Using several test cases, this paper characterizes the performance of these algorithms in terms of their convergence rates and solution quality under three data quality nonidealities: (1) additive Gaussian noise, (2) false data, and (3) intermittent communication failure.      
### 36.Suppressing the endemic equilibrium in SIS epidemics: A state dependent approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.00122.pdf)
>  This paper considers the susceptible-infected-susceptible (SIS) epidemic model with an underlying network structure among subpopulations and focuses on the effect of social distancing to regulate the epidemic level. We demonstrate that if each subpopulation is informed of its infection rate and reduces interactions accordingly, the fraction of the subpopulation infected can remain below half for all time instants. To this end, we first modify the basic SIS model by introducing a state dependent parameter representing the frequency of interactions between subpopulations. Thereafter, we show that for this modified SIS model, the spectral radius of a suitably-defined matrix being not greater than one causes all the agents, regardless of their initial sickness levels, to converge to the healthy state; assuming non-trivial disease spread, the spectral radius being greater than one leads to the existence of a unique endemic equilibrium, which is also asymptotically stable. Finally, by leveraging the aforementioned results, we show that the fraction of (sub)populations infected never exceeds half.      
### 37.Trac alternant detector for grading hypoxic-ischemic encephalopathy in neonatal EEG  [ :arrow_down: ](https://arxiv.org/pdf/2106.00061.pdf)
>  Electroencephalography (EEG) is an important clinical tool to capture sleep-wake cycling. It can also be used for grading injury, known as hypoxic-ischaemic encephalopathy(HIE), caused by lack of oxygen or blood to the brain during birth. Trac alternant (TA) is a distinctive component of normal quiet sleep which consists of alternating periods of high-voltage activity (bursts) separated by lower-voltage activity (inter-bursts). This study presents an automated method to grade the severity of injury in HIE, using an automated method to first detect activity. The TA detector uses the output of an existing method to detect inter-bursts. Features are extracted from a processed output and then combined in a support vector machine (SVM). Next, we develop an HIE grading system using the TA detector by combining different features from the temporal organisation of the detected TA mask, again using an SVM. Training and testing for both models use a leave-one-baby-out cross-validation procedure, with model hyper-parameters selected from nested cross validations. The TA detector, tested on EEG from 71 healthy term neonates, has an accuracy of 79.1% (Cohen's \k{appa}=0.55). the grading system, tested on EEG from 54 term neonates in intensive care, has an accuracy of 81.5% (\k{appa}=0.74). These results validate how detecting the presence or absence of TA can be used to quantify the grade of HIE injury in neonatal EEG and open up the possibility of a clinically-meaningful grading system.      
### 38.Low-Resource Spoken Language Identification Using Self-Attentive Pooling and Deep 1D Time-Channel Separable Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2106.00052.pdf)
>  This memo describes NTR/TSU winning submission for Low Resource ASR challenge at Dialog2021 conference, language identification track. <br>Spoken Language Identification (LID) is an important step in a multilingual Automated Speech Recognition (ASR) system pipeline. Traditionally, the ASR task requires large volumes of labeled data that are unattainable for most of the world's languages, including most of the languages of Russia. In this memo, we show that a convolutional neural network with a Self-Attentive Pooling layer shows promising results in low-resource setting for the language identification task and set up a SOTA for the Low Resource ASR challenge dataset. <br>Additionally, we compare the structure of confusion matrices for this and significantly more diverse VoxForge dataset and state and substantiate the hypothesis that whenever the dataset is diverse enough so that the other classification factors, like gender, age etc. are well-averaged, the confusion matrix for LID system bears the language similarity measure.      
### 39.StarGAN-ZSVC: Towards Zero-Shot Voice Conversion in Low-Resource Contexts  [ :arrow_down: ](https://arxiv.org/pdf/2106.00043.pdf)
>  Voice conversion is the task of converting a spoken utterance from a source speaker so that it appears to be said by a different target speaker while retaining the linguistic content of the utterance. Recent advances have led to major improvements in the quality of voice conversion systems. However, to be useful in a wider range of contexts, voice conversion systems would need to be (i) trainable without access to parallel data, (ii) work in a zero-shot setting where both the source and target speakers are unseen during training, and (iii) run in real time or faster. Recent techniques fulfil one or two of these requirements, but not all three. This paper extends recent voice conversion models based on generative adversarial networks (GANs), to satisfy all three of these conditions. We specifically extend the recent StarGAN-VC model by conditioning it on a speaker embedding (from a potentially unseen speaker). This allows the model to be used in a zero-shot setting, and we therefore call it StarGAN-ZSVC. We compare StarGAN-ZSVC against other voice conversion techniques in a low-resource setting using a small 9-minute training set. Compared to AutoVC -- another recent neural zero-shot approach -- we observe that StarGAN-ZSVC gives small improvements in the zero-shot setting, showing that real-time zero-shot voice conversion is possible even for a model trained on very little data. Further work is required to see whether scaling up StarGAN-ZSVC will also improve zero-shot voice conversion quality in high-resource contexts.      
### 40.Fidelity Estimation Improves Noisy-Image Classification with Pretrained Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00673.pdf)
>  Image classification has significantly improved using deep learning. This is mainly due to convolutional neural networks (CNNs) that are capable of learning rich feature extractors from large datasets. However, most deep learning classification methods are trained on clean images and are not robust when handling noisy ones, even if a restoration preprocessing step is applied. While novel methods address this problem, they rely on modified feature extractors and thus necessitate retraining. We instead propose a method that can be applied on a pretrained classifier. Our method exploits a fidelity map estimate that is fused into the internal representations of the feature extractor, thereby guiding the attention of the network and making it more robust to noisy data. We improve the noisy-image classification (NIC) results by significantly large margins, especially at high noise levels, and come close to the fully retrained approaches. Furthermore, as proof of concept, we show that when using our oracle fidelity map we even outperform the fully retrained methods, whether trained on noisy or restored images.      
### 41.SoK: Oracles from the Ground Truth to Market Manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00667.pdf)
>  One fundamental limitation of blockchain-based smart contracts is that they execute in a closed environment and only have access to the data and functionality that is either already on the blockchain or fed into the blockchain. Thus any interactions with the real world need to be mediated by a bridge service, which is called an oracle. As decentralized applications mature, oracles are playing an increasingly prominent role. With their evolution comes more attacks, necessitating a greater attention to the trust model of using oracles. In this SoK, we systemize the design alternatives for oracles, showcase attacks, and discuss attack mitigation strategies.      
### 42.An occupation kernel approach to optimal control  [ :arrow_down: ](https://arxiv.org/pdf/2106.00663.pdf)
>  In this effort, a novel operator theoretic framework is developed for data-driven solution of optimal control problems. The developed methods focus on the use of trajectories (i.e., time-series) as the fundamental unit of data for the resolution of optimal control problems in dynamical systems. Trajectory information in the dynamical systems is embedded in a reproducing kernel Hilbert space (RKHS) through what are called occupation kernels. The occupation kernels are tied to the dynamics of the system through the densely defined Liouville operator. The pairing of Liouville operators and occupation kernels allows for lifting of nonlinear finite-dimensional optimal control problems into the space of infinite-dimensional linear programs over RKHSs.      
### 43.A reinforcement learning approach to improve communication performance and energy utilization in fog-based IoT  [ :arrow_down: ](https://arxiv.org/pdf/2106.00654.pdf)
>  Recent research has shown the potential of using available mobile fog devices (such as smartphones, drones, domestic and industrial robots) as relays to minimize communication outages between sensors and destination devices, where localized Internet-of-Things services (e.g., manufacturing process control, health and security monitoring) are delivered. However, these mobile relays deplete energy when they move and transmit to distant destinations. As such, power-control mechanisms and intelligent mobility of the relay devices are critical in improving communication performance and energy utilization. In this paper, we propose a Q-learning-based decentralized approach where each mobile fog relay agent (MFRA) is controlled by an autonomous agent which uses reinforcement learning to simultaneously improve communication performance and energy utilization. Each autonomous agent learns based on the feedback from the destination and its own energy levels whether to remain active and forward the message, or become passive for that transmission phase. We evaluate the approach by comparing with the centralized approach, and observe that with lesser number of MFRAs, our approach is able to ensure reliable delivery of data and reduce overall energy cost by 56.76\% -- 88.03\%.      
### 44.A normal form for grid forming power grid components  [ :arrow_down: ](https://arxiv.org/pdf/2106.00644.pdf)
>  Future power grids will be operating a large number of heterogeneous dynamical actors. Many ofthese will contribute to the fundamental dynamical stability of the system. By taking a complexitytheoretic perspective we derive a normal form for grid forming components in power grids. Thisallows analyzing the grids systemic properties without the need for detailed technical models.Our approach is based on the physics of the power flow in the grid on the one hand, and on thecommon symmetry that is inherited from the control objectives grid-forming power grid componentsare trying to achieve. We provide a first experimental validation that this normal form can capturethe behavior of complex grid forming inverters without any knowledge of the underlying technology,and show that it can be used to make technology independent statements on the stability of futuregrids.      
### 45.Choroidal vasculature imaging with laser Doppler holography  [ :arrow_down: ](https://arxiv.org/pdf/2106.00608.pdf)
>  The choroid is a highly vascularized tissues supplying the retinal pigment epithelium and photoreceptors. Its implication in retinal diseases is gaining increasing interest. However, investigating the anatomy and flow of the choroid remains challenging. Here we show that laser Doppler holography provides high contrast imaging of choroidal vessels in humans, with a spatial resolution comparable to state of the art indocyanine green angiography and optical coherence tomography. Additionally, laser Doppler holography contributes to sort out choroidal arteries and veins by using a power Doppler spectral analysis. We thus demonstrate the potential of laser Doppler holography to improve our understanding of the anatomy and flow of the choroidal vascular network.      
### 46.A General Framework for Learning-Based Distributionally Robust MPC of Markov Jump Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.00561.pdf)
>  We present a data-driven model predictive control (MPC) scheme for chance-constrained Markov jump systems with unknown switching probabilities. Using samples of the underlying Markov chain, ambiguity sets of transition probabilities are estimated which include the true conditional probability distributions with high probability. These sets are updated online and used to formulate a time-varying, risk-averse optimal control problem. We prove recursive feasibility of the resulting MPC scheme and show that the original chance constraints remain satisfied at every time step. Furthermore, we show that under sufficient decrease of the confidence levels, the resulting MPC scheme renders the closed-loop system mean-square stable with respect to the true-but-unknown distributions, while remaining less conservative than a fully robust approach. Finally, we show that the data-driven value function converges to its nominal counterpart as the sample size grows to infinity. We illustrate our approach on a numerical example.      
### 47.Towards Interpretable Attention Networks for Cervical Cancer Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.00557.pdf)
>  Recent advances in deep learning have enabled the development of automated frameworks for analysing medical images and signals, including analysis of cervical cancer. Many previous works focus on the analysis of isolated cervical cells, or do not offer sufficient methods to explain and understand how the proposed models reach their classification decisions on multi-cell images. Here, we evaluate various state-of-the-art deep learning models and attention-based frameworks for the classification of images of multiple cervical cells. As we aim to provide interpretable deep learning models to address this task, we also compare their explainability through the visualization of their gradients. We demonstrate the importance of using images that contain multiple cells over using isolated single-cell images. We show the effectiveness of the residual channel attention model for extracting important features from a group of cells, and demonstrate this model's efficiency for this classification task. This work highlights the benefits of channel attention mechanisms in analyzing multiple-cell images for potential relations and distributions within a group of cells. It also provides interpretable models to address the classification of cervical cells.      
### 48.Topology and Admittance Estimation: Precision Limits and Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2106.00532.pdf)
>  Distribution grid topology and admittance information are essential for system planning, operation, and protection. In many distribution grids, missing or inaccurate topology and admittance data call for efficient estimation methods. However, measurement data may be insufficient or contaminated with large noise, which will introduce fundamental limits to the estimation accuracy. This work explores the theoretical precision limits of the topology and admittance estimation (TAE) problem, with different measurement devices, noise levels, and the number of measurements. On this basis, we propose a conservative progressive self-adaptive (CPS) algorithm to estimate the topology and admittance. Results on IEEE 33 and 141-bus systems validate that the proposed CPS method can approach the theoretical precision limits under various measurement settings.      
### 49.Towards Efficient Compressive Data Collection in the Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2106.00509.pdf)
>  It is of paramount importance to achieve efficient data collection in the Internet of Things (IoT). Due to the inherent structural properties (e.g., sparsity) existing in many signals of interest, compressive sensing (CS) technology has been extensively used for data collection in IoT to improve both accuracy and energy efficiency. Apart from the existing works which leverage CS as a channel coding scheme to deal with data loss during transmission, some recent results have started to employ CS as a source coding strategy. The frequently used projection matrices in these CS-based source coding schemes include dense random matrices (e.g., Gaussian matrices or Bernoulli matrices) and structured matrices (e.g., Toeplitz matrices). However, these matrices are either difficult to be implemented on resource-constrained IoT sensor nodes or have limited applicability. To address these issues, in this paper, we design a novel simple and efficient projection matrix, named sparse Gaussian matrix, which is easy and resource-saving to be implemented in practical IoT applications. We conduct both theoretical analysis and experimental evaluation of the designed sparse Gaussian matrix. The results demonstrate that employing the designed projection matrix to perform CS-based source coding could significantly save time and memory cost while ensuring satisfactory signal recovery performance.      
### 50.A Unified Cognitive Learning Framework for Adapting to Dynamic Environment and Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00501.pdf)
>  Many machine learning frameworks have been proposed and used in wireless communications for realizing diverse goals. However, their incapability of adapting to the dynamic wireless environment and tasks and of self-learning limit their extensive applications and achievable performance. Inspired by the great flexibility and adaptation of primate behaviors due to the brain cognitive mechanism, a unified cognitive learning (CL) framework is proposed for the dynamic wireless environment and tasks. The mathematical framework for our proposed CL is established. Using the public and authoritative dataset, we demonstrate that our proposed CL framework has three advantages, namely, the capability of adapting to the dynamic environment and tasks, the self-learning capability and the capability of 'good money driving out bad money' by taking modulation recognition as an example. The proposed CL framework can enrich the current learning frameworks and widen the applications.      
### 51.Omnizart: A General Toolbox for Automatic Music Transcription  [ :arrow_down: ](https://arxiv.org/pdf/2106.00497.pdf)
>  We present and release Omnizart, a new Python library that provides a streamlined solution to automatic music transcription (AMT). Omnizart encompasses modules that construct the life-cycle of deep learning-based AMT, and is designed for ease of use with a compact command-line interface. To the best of our knowledge, Omnizart is the first transcription toolkit which offers models covering a wide class of instruments ranging from solo, instrument ensembles, percussion instruments to vocal, as well as models for chord recognition and beat/downbeat tracking, two music information retrieval (MIR) tasks highly related to AMT.      
### 52.Low-Complexity Symbol-Level Precoding for MU-MISO Downlink Systems with QAM Signals  [ :arrow_down: ](https://arxiv.org/pdf/2106.00433.pdf)
>  This study proposes the construction of a transmit signal for large-scale antenna systems with cost-effective 1-bit digital-to-analog converters in the downlink. Under quadrature-amplitude-modulation constellations, it is still an open problem to overcome a severe error floor problem caused by its nature property. To this end, we first present a feasibility condition which guarantees that each user's noiseless signal is placed in the desired decision region. For robustness to additive noise, we formulate an optimization problem, we then transform the feasibility conditions to cascaded matrix form. We propose a low-complexity algorithm to generate a 1-bit transmit signal based on the proposed optimization problem formulated as a well-defined mixed-integer-linear-programming. Numerical results validate the superiority of the proposed method in terms of detection performance and computational complexity.      
### 53.Nora: The Well-Being Coach  [ :arrow_down: ](https://arxiv.org/pdf/2106.00410.pdf)
>  The current pandemic has forced people globally to remain in isolation and practice social distancing, which creates the need for a system to combat the resulting loneliness and negative emotions. In this paper we propose Nora, a virtual coaching platform designed to utilize natural language understanding in its dialogue system and suggest other recommendations based on user interactions. It is intended to provide assistance and companionship to people undergoing self-quarantine or work-from-home routines. Nora helps users gauge their well-being by detecting and recording the user's emotion, sentiment, and stress. Nora also recommends various workout, meditation, or yoga exercises to users in support of developing a healthy daily routine. In addition, we provide a social community inside Nora, where users can connect and share their experiences with others undergoing a similar isolation procedure. Nora can be accessed from anywhere via a web link and has support for both English and Mandarin.      
### 54.Distance and Position Estimation in Visible Light Systems with RGB LEDs  [ :arrow_down: ](https://arxiv.org/pdf/2106.00396.pdf)
>  In this manuscript, distance and position estimation problems are investigated for visible light positioning (VLP) systems with red-green-blue (RGB) light emitting diodes (LEDs). The accuracy limits on distance and position estimation are calculated in terms of the Cramer-Rao lower bound (CRLB) for three different scenarios. Scenario~1 and Scenario~2 correspond to synchronous and asynchronous systems, respectively, with known channel attenuation formulas at the receiver. In Scenario~3, a synchronous system is considered but channel attenuation formulas are not known at the receiver. The derived CRLB expressions reveal the relations among distance/position estimation accuracies in the considered scenarios and lead to intuitive explanations for the benefits of using RGB LEDs. In addition, maximum likelihood (ML) estimators are derived in all scenarios, and it is shown that they can achieve close performance to the CRLBs in some cases for sufficiently high source optical powers.      
### 55.Learning Football Body-Orientation as a Matter of Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.00359.pdf)
>  Orientation is a crucial skill for football players that becomes a differential factor in a large set of events, especially the ones involving passes. However, existing orientation estimation methods, which are based on computer-vision techniques, still have a lot of room for improvement. To the best of our knowledge, this article presents the first deep learning model for estimating orientation directly from video footage. By approaching this challenge as a classification problem where classes correspond to orientation bins, and by introducing a cyclic loss function, a well-known convolutional network is refined to provide player orientation data. The model is trained by using ground-truth orientation data obtained from wearable EPTS devices, which are individually compensated with respect to the perceived orientation in the current frame. The obtained results outperform previous methods; in particular, the absolute median error is less than 12 degrees per player. An ablation study is included in order to show the potential generalization to any kind of football video footage.      
### 56.A Non-commutative Extension of Lee-Seung's Algorithm for Positive Semidefinite Factorizations  [ :arrow_down: ](https://arxiv.org/pdf/2106.00293.pdf)
>  Given a matrix $X\in \mathbb{R}_+^{m\times n}$ with nonnegative entries, a Positive Semidefinite (PSD) factorization of $X$ is a collection of $r \times r$-dimensional PSD matrices $\{A_i\}$ and $\{B_j\}$ satisfying $X_{ij}= \mathrm{tr}(A_i B_j)$ for all $\ i\in [m],\ j\in [n]$. PSD factorizations are fundamentally linked to understanding the expressiveness of semidefinite programs as well as the power and limitations of quantum resources in information theory. The PSD factorization task generalizes the Non-negative Matrix Factorization (NMF) problem where we seek a collection of $r$-dimensional nonnegative vectors $\{a_i\}$ and $\{b_j\}$ satisfying $X_{ij}= a_i^\top b_j$, for all $i\in [m],\ j\in [n]$ -- one can recover the latter problem by choosing matrices in the PSD factorization to be diagonal. The most widely used algorithm for computing NMFs of a matrix is the Multiplicative Update algorithm developed by Lee and Seung, in which nonnegativity of the updates is preserved by scaling with positive diagonal matrices. In this paper, we describe a non-commutative extension of Lee-Seung's algorithm, which we call the Matrix Multiplicative Update (MMU) algorithm, for computing PSD factorizations. The MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that Lee-Seung's algorithm enjoys. Building on the Majorization-Minimization framework, we show that under our update scheme the squared loss objective is non-increasing and fixed points correspond to critical points. The analysis relies on Lieb's Concavity Theorem. Beyond PSD factorizations, we use the MMU algorithm as a primitive to calculate block-diagonal PSD factorizations and tensor PSD factorizations. We demonstrate the utility of our method with experiments on real and synthetic data.      
### 57.AAPM DL-Sparse-View CT Challenge Submission Report: Designing an Iterative Network for Fanbeam-CT with Unknown Geometry  [ :arrow_down: ](https://arxiv.org/pdf/2106.00280.pdf)
>  This report is dedicated to a short motivation and description of our contribution to the AAPM DL-Sparse-View CT Challenge (team name: "robust-and-stable"). The task is to recover breast model phantom images from limited view fanbeam measurements using data-driven reconstruction techniques. The challenge is distinctive in the sense that participants are provided with a collection of ground truth images and their noiseless, subsampled sinograms (as well as the associated limited view filtered backprojection images), but not with the actual forward model. Therefore, our approach first estimates the fanbeam geometry in a data-driven geometric calibration step. In a subsequent two-step procedure, we design an iterative end-to-end network that enables the computation of near-exact solutions.      
### 58.Adversarial Defense for Automatic Speaker Verification by Self-Supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.00273.pdf)
>  Previous works have shown that automatic speaker verification (ASV) is seriously vulnerable to malicious spoofing attacks, such as replay, synthetic speech, and recently emerged adversarial attacks. Great efforts have been dedicated to defending ASV against replay and synthetic speech; however, only a few approaches have been explored to deal with adversarial attacks. All the existing approaches to tackle adversarial attacks for ASV require the knowledge for adversarial samples generation, but it is impractical for defenders to know the exact attack algorithms that are applied by the in-the-wild attackers. This work is among the first to perform adversarial defense for ASV without knowing the specific attack algorithms. Inspired by self-supervised learning models (SSLMs) that possess the merits of alleviating the superficial noise in the inputs and reconstructing clean samples from the interrupted ones, this work regards adversarial perturbations as one kind of noise and conducts adversarial defense for ASV by SSLMs. Specifically, we propose to perform adversarial defense from two perspectives: 1) adversarial perturbation purification and 2) adversarial perturbation detection. Experimental results show that our detection module effectively shields the ASV by detecting adversarial samples with an accuracy of around 80%. Moreover, since there is no common metric for evaluating the adversarial defense performance for ASV, this work also formalizes evaluation metrics for adversarial defense considering both purification and detection based approaches into account. We sincerely encourage future works to benchmark their approaches based on the proposed evaluation framework.      
### 59.A unified PAC-Bayesian framework for machine unlearning via information risk minimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.00265.pdf)
>  Machine unlearning refers to mechanisms that can remove the influence of a subset of training data upon request from a trained model without incurring the cost of re-training from scratch. This paper develops a unified PAC-Bayesian framework for machine unlearning that recovers the two recent design principles - variational unlearning (Nguyen <a class="link-external link-http" href="http://et.al" rel="external noopener nofollow">this http URL</a>., 2020) and forgetting Lagrangian (Golatkar <a class="link-external link-http" href="http://et.al" rel="external noopener nofollow">this http URL</a>., 2020) - as information risk minimization problems (Zhang,2006). Accordingly, both criteria can be interpreted as PAC-Bayesian upper bounds on the test loss of the unlearned model that take the form of free energy metrics.      
### 60.Information-Theoretic Analysis of Epistemic Uncertainty in Bayesian Meta-learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.00252.pdf)
>  The overall predictive uncertainty of a trained predictor can be decomposed into separate contributions due to epistemic and aleatoric uncertainty. Under a Bayesian formulation, assuming a well-specified model, the two contributions can be exactly expressed (for the log-loss) or bounded (for more general losses) in terms of information-theoretic quantities (Xu and Raginsky, 2020). This paper addresses the study of epistemic uncertainty within an information-theoretic framework in the broader setting of Bayesian meta-learning. A general hierarchical Bayesian model is assumed in which hyperparameters determine the per-task priors of the model parameters. Exact characterizations (for the log-loss) and bounds (for more general losses) are derived for the epistemic uncertainty - quantified by the minimum excess meta-risk (MEMR)- of optimal meta-learning rules. This characterization is leveraged to bring insights into the dependence of the epistemic uncertainty on the number of tasks and on the amount of per-task training data. Experiments are presented that compare the proposed information-theoretic bounds, evaluated via neural mutual information estimators, with the performance of a novel approximate fully Bayesian meta-learning strategy termed Langevin-Stein Bayesian Meta-Learning (LS-BML).      
### 61.Multilingual Speech Translation with Unified Transformer: Huawei Noah's Ark Lab at IWSLT 2021  [ :arrow_down: ](https://arxiv.org/pdf/2106.00197.pdf)
>  This paper describes the system submitted to the IWSLT 2021 Multilingual Speech Translation (MultiST) task from Huawei Noah's Ark Lab. We use a unified transformer architecture for our MultiST model, so that the data from different modalities (i.e., speech and text) and different tasks (i.e., Speech Recognition, Machine Translation, and Speech Translation) can be exploited to enhance the model's ability. Specifically, speech and text inputs are firstly fed to different feature extractors to extract acoustic and textual features, respectively. Then, these features are processed by a shared encoder--decoder architecture. We apply several training techniques to improve the performance, including multi-task learning, task-level curriculum learning, data augmentation, etc. Our final system achieves significantly better results than bilingual baselines on supervised language pairs and yields reasonable results on zero-shot language pairs.      
### 62.Quantification of Carbon Sequestration in Urban Forests  [ :arrow_down: ](https://arxiv.org/pdf/2106.00182.pdf)
>  Vegetation, trees in particular, sequester carbon by absorbing carbon dioxide from the atmosphere, however, the lack of efficient quantification methods of carbon stored in trees renders it difficult to track the process. Here we present an approach to estimate the carbon storage in trees based on fusing multispectral aerial imagery and LiDAR data to identify tree coverage, geometric shape, and tree species, which are crucial attributes in carbon storage quantification. We demonstrate that tree species information and their three-dimensional geometric shapes can be estimated from remote imagery in order to calculate the tree's biomass. Specifically, for Manhattan, New York City, we estimate a total of $52,000$ tons of carbon sequestered in trees.      
### 63.Dual Normalization Multitasking for Audio-Visual Sounding Object Localization  [ :arrow_down: ](https://arxiv.org/pdf/2106.00180.pdf)
>  Although several research works have been reported on audio-visual sound source localization in unconstrained videos, no datasets and metrics have been proposed in the literature to quantitatively evaluate its performance. Defining the ground truth for sound source localization is difficult, because the location where the sound is produced is not limited to the range of the source object, but the vibrations propagate and spread through the surrounding objects. Therefore we propose a new concept, Sounding Object, to reduce the ambiguity of the visual location of sound, making it possible to annotate the location of the wide range of sound sources. With newly proposed metrics for quantitative evaluation, we formulate the problem of Audio-Visual Sounding Object Localization (AVSOL). We also created the evaluation dataset (AVSOL-E dataset) by manually annotating the test set of well-known Audio-Visual Event (AVE) dataset. To tackle this new AVSOL problem, we propose a novel multitask training strategy and architecture called Dual Normalization Multitasking (DNM), which aggregates the Audio-Visual Correspondence (AVC) task and the classification task for video events into a single audio-visual similarity map. By efficiently utilize both supervisions by DNM, our proposed architecture significantly outperforms the baseline methods.      
### 64.Towards Explainable Convolutional Features for Music Audio Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2106.00110.pdf)
>  Audio signals are often represented as spectrograms and treated as 2D images. In this light, deep convolutional architectures are widely used for music audio tasks even though these two data types have very different structures. In this work, we attempt to "open the black-box" on deep convolutional models to inform future architectures for music audio tasks, and explain the excellent performance of deep convolutions that model spectrograms as 2D images. To this end, we expand recent explainability discussions in deep learning for natural image data to music audio data through systematic experiments using the deep features learned by various convolutional architectures. We demonstrate that deep convolutional features perform well across various target tasks, whether or not they are extracted from deep architectures originally trained on that task. Additionally, deep features exhibit high similarity to hand-crafted wavelet features, whether the deep features are extracted from a trained or untrained model.      
### 65.3D map creation using crowdsourced GNSS data  [ :arrow_down: ](https://arxiv.org/pdf/2106.00107.pdf)
>  3D maps are increasingly useful for many applications such as drone navigation, emergency services, and urban planning. However, creating 3D maps and keeping them up-to-date using existing technologies, such as laser scanners, is expensive. This paper proposes and implements a novel approach to generate 2.5D (otherwise known as 3D level-of-detail (LOD) 1) maps for free using Global Navigation Satellite Systems (GNSS) signals, which are globally available and are blocked only by obstacles between the satellites and the receivers. This enables us to find the patterns of GNSS signal availability and create 3D maps. The paper applies algorithms to GNSS signal strength patterns based on a boot-strapped technique that iteratively trains the signal classifiers while generating the map. Results of the proposed technique demonstrate the ability to create 3D maps using automatically processed GNSS data. The results show that the third dimension, i.e. height of the buildings, can be estimated with below 5 metre accuracy, which is the benchmark recommended by the CityGML standard.      
### 66.Anti-Koopmanism  [ :arrow_down: ](https://arxiv.org/pdf/2106.00106.pdf)
>  This article addresses several longstanding misconceptions concerning Koopman operators, including the existence of lattices of eigenfunctions, common eigenfunctions between Koopman operators, and boundedness and compactness of Koopman operators, among others. Counterexamples are provided for each misconception. This manuscript also proves that the Gaussian RBF's native space only supports bounded Koopman operator corresponding to affine dynamics, which shows that the assumption of boundedness is very limiting. A framework for DMD is presented that requires only densely defined Koopman operators over reproducing kernel Hilbert spaces, and the effectiveness of this approach is demonstrated through reconstruction examples.      
### 67.Control Occupation Kernel Regression for Nonlinear Control-Affine Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.00103.pdf)
>  This manuscript presents an algorithm for obtaining an approximation of nonlinear high order control affine dynamical systems, that leverages the controlled trajectories as the central unit of information. As the fundamental basis elements leveraged in approximation, higher order control occupation kernels represent iterated integration after multiplication by a given controller in a vector valued reproducing kernel Hilbert space. In a regularized regression setting, the unique optimizer for a particular optimization problem is expressed as a linear combination of these occupation kernels, which converts an infinite dimensional optimization problem to a finite dimensional optimization problem through the representer theorem. Interestingly, the vector valued structure of the Hilbert space allows for simultaneous approximation of the drift and control effectiveness components of the control affine system. Several experiments are performed to demonstrate the effectiveness of the approach.      
### 68.Generalized AdaGrad (G-AdaGrad) and Adam: A State-Space Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2106.00092.pdf)
>  Accelerated gradient-based methods are being extensively used for solving non-convex machine learning problems, especially when the data points are abundant or the available data is distributed across several agents. Two of the prominent accelerated gradient algorithms are AdaGrad and Adam. AdaGrad is the simplest accelerated gradient method, which is particularly effective for sparse data. Adam has been shown to perform favorably in deep learning problems compared to other methods. In this paper, we propose a new fast optimizer, Generalized AdaGrad (G-AdaGrad), for accelerating the solution of potentially non-convex machine learning problems. Specifically, we adopt a state-space perspective for analyzing the convergence of gradient acceleration algorithms, namely G-AdaGrad and Adam, in machine learning. Our proposed state-space models are governed by ordinary differential equations. We present simple convergence proofs of these two algorithms in the deterministic settings with minimal assumptions. Our analysis also provides intuition behind improving upon AdaGrad's convergence rate. We provide empirical results on MNIST dataset to reinforce our claims on the convergence and performance of G-AdaGrad and Adam.      
### 69.Node-Variant Graph Filters in Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.00089.pdf)
>  Graph neural networks (GNNs) have been successfully employed in a myriad of applications involving graph-structured data. Theoretical findings establish that GNNs use nonlinear activation functions to create low-eigenvalue frequency content that can be processed in a stable manner by subsequent graph convolutional filters. However, the exact shape of the frequency content created by nonlinear functions is not known, and thus, it cannot be learned nor controlled. In this work, node-variant graph filters (NVGFs) are shown to be capable of creating frequency content and are thus used in lieu of nonlinear activation functions. This results in a novel GNN architecture that, although linear, is capable of creating frequency content as well. Furthermore, this new frequency content can be either designed or learned from data. In this way, the role of frequency creation is separated from the nonlinear nature of traditional GNNs. Extensive simulations are carried out to differentiate the contributions of frequency creation from those of the nonlinearity.      
### 70.PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00058.pdf)
>  The dictionary learning problem, representing data as a combination of few atoms, has long stood as a popular method for learning representations in statistics and signal processing. The most popular dictionary learning algorithm alternates between sparse coding and dictionary update steps, and a rich literature has studied its theoretical convergence. The growing popularity of neurally plausible unfolded sparse coding networks has led to the empirical finding that backpropagation through such networks performs dictionary learning. This paper offers the first theoretical proof for these empirical results through PUDLE, a Provable Unfolded Dictionary LEarning method. We highlight the impact of loss, unfolding, and backpropagation on convergence. We discover an implicit acceleration: as a function of unfolding, the backpropagated gradient converges faster and is more accurate than the gradient from alternating minimization. We complement our findings through synthetic and image denoising experiments. The findings support the use of accelerated deep learning optimizers and unfolded networks for dictionary learning.      
### 71.Constrained Deep Reinforcement Based Functional Split Optimization in Virtualized RANs  [ :arrow_down: ](https://arxiv.org/pdf/2106.00011.pdf)
>  Virtualized Radio Access Network (vRAN) brings agility to Next-Generation RAN through functional split. It allows decomposing the base station (BS) functions into virtualized components and hosts it either at the distributed-unit (DU) or central-unit (CU). However, deciding which functions to deploy at DU or CU to minimize the total network cost is challenging. In this paper, a constrained deep reinforcement based functional split optimization (CDRS) is proposed to optimize the locations of functions in vRAN. Our formulation results in a combinatorial and NP-hard problem for which finding the exact solution is computationally expensive. Hence, in our proposed approach, a policy gradient method with Lagrangian relaxation is applied that uses a penalty signal to lead the policy toward constraint satisfaction. It utilizes a neural network architecture formed by an encoder-decoder sequence-to-sequence model based on stacked Long Short-term Memory (LSTM) networks to approximate the policy. Greedy decoding and temperature sampling methods are also leveraged for a search strategy to infer the best solution among candidates from multiple trained models that help to avoid a severe suboptimality. Simulations are performed to evaluate the performance of the proposed solution in both synthetic and real network datasets. Our findings reveal that CDRS successfully learns the optimal decision, solves the problem with the accuracy of 0.05\% optimality gap and becomes the most cost-effective compared to the available RAN setups. Moreover, altering the routing cost and traffic load does not significantly degrade the optimality. The results also show that all of our CDRS settings have faster computational time than the optimal baseline solver. Our proposed method fills the gap of optimizing the functional split offering a near-optimal solution, faster computational time and minimal hand-engineering.      
### 72.Multi-Scale Attention Neural Network for Acoustic Echo Cancellation  [ :arrow_down: ](https://arxiv.org/pdf/2106.00010.pdf)
>  Acoustic Echo Cancellation (AEC) plays a key role in speech interaction by suppressing the echo received at microphone introduced by acoustic reverberations from loudspeakers. Since the performance of linear adaptive filter (AF) would degrade severely due to nonlinear distortions, background noises, and microphone clipping in real scenarios, deep learning has been employed for AEC for its good nonlinear modelling ability. In this paper, we constructed an end-to-end multi-scale attention neural network for AEC. Temporal convolution is first used to transform waveform into spectrogram. The spectrograms of the far-end reference and the near-end mixture are concatenated, and fed to a temporal convolution network (TCN) with stacked dilated convolution layers. Attention mechanism is performed among these representations from different layers to adaptively extract relevant features by referring to the previous hidden state in the encoder long short-term memory (LSTM) unit. The representations are weighted averaged and fed to the encoder LSTM for the near-end speech estimation. Experiments show the superiority of our method in terms of the echo return loss enhancement (ERLE) for single-talk periods and the perceptual evaluation of speech quality (PESQ) score for double-talk periods in background noise and nonlinear distortion scenarios.      
