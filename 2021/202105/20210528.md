# ArXiv eess --Fri, 28 May 2021
### 1.A High-Dynamic-Range Digital RF-Over-Fiber Link for MRI Receive Coils Using Delta-Sigma Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2105.13305.pdf)
>  The coaxial cables commonly used to connect RF coil arrays with the control console of an MRI scanner are susceptible to electromagnetic coupling. As the number of RF channel increases, such coupling could result in severe heating and pose a safety concern. Non-conductive transmission solutions based on fiber-optic cables are considered to be one of the alternatives, but are limited by the high dynamic range ($&gt;80$~dB) of typical MRI signals. A new digital fiber-optic transmission system based on delta-sigma modulation (DSM) is developed to address this problem. A DSM-based optical link is prototyped using off-the-shelf components and bench-tested at different signal oversampling rates (OSR). An end-to-end dynamic range (DR) of 81~dB, which is sufficient for typical MRI signals, is obtained over a bandwidth of 200~kHz, which corresponds to $OSR=50$. A fully-integrated custom fourth-order continuous-time DSM (CT-DSM) is designed in 180~nm CMOS technology to enable transmission of full-bandwidth MRI signals (up to 1~MHz) with adequate DR. Initial electrical test results from this custom chip are also presented.      
### 2.Intelligent Reflecting Surface-assisted Free-space Optical Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.13297.pdf)
>  Free-space optical (FSO) systems are able to offer the high data-rate, secure, and cost-efficient communication links required for applications such as wireless front- and backhauling for 5G and 6G communication networks. Despite the substantial advancement of FSO systems over the past decades, the requirement of a line-of-sight connection between transmitter and receiver remains a key limiting factor for their deployment. In this paper, we discuss the potential role of intelligent reflecting surfaces (IRSs) as a solution to relax this requirement. We present an overview of existing optical IRS technologies; compare optical IRSs with radio-frequency IRSs and optical relays; and identify various open problems for future research on IRS-assisted FSO communications.      
### 3.Federated Meta Learning Enhanced Acoustic Radio Cooperative Framework for Ocean of Things Underwater Acoustic Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.13296.pdf)
>  Sixth-generation wireless communication (6G) will be an integrated architecture of "space, air, ground and sea". One of the most difficult part of this architecture is the underwater information acquisition which need to transmitt information cross the interface between water and <a class="link-external link-http" href="http://air.In" rel="external noopener nofollow">this http URL</a> this senario, ocean of things (OoT) will play an important role, because it can serve as a hub connecting Internet of things (IoT) and Internet of underwater things (IoUT). OoT device not only can collect data through underwater methods, but also can utilize radio frequence over the air. For underwater communications, underwater acoustic communications (UWA COMMs) is the most effective way for OoT devices to exchange information, but it is always tormented by doppler shift and synchronization errors. In this paper, in order to overcome UWA tough conditions, a deep neural networks based receiver for underwater acoustic chirp communication, called C-DNN, is proposed. Moreover, to improve the performance of DL-model and solve the problem of model generalization, we also proposed a novel federated meta learning (FML) enhanced acoustic radio cooperative (ARC) framework, dubbed ARC/FML, to do transfer. Particularly, tractable expressions are derived for the convergence rate of FML in a wireless setting, accounting for effects from both scheduling ratio, local epoch and the data amount on a single node.From our analysis and simulation results, it is shown that, the proposed C-DNN can provide a better BER performance and lower complexity than classical matched filter (MF) in underwater acoustic communications scenario. The ARC/FML framework has good convergence under a variety of channels than federated learning (FL). In summary, the proposed ARC/FML for OoT is a promising scheme for information exchange across water and air.      
### 4.A Modular and Transferable Reinforcement Learning Framework for the Fleet Rebalancing Problem  [ :arrow_down: ](https://arxiv.org/pdf/2105.13284.pdf)
>  Mobility on demand (MoD) systems show great promise in realizing flexible and efficient urban transportation. However, significant technical challenges arise from operational decision making associated with MoD vehicle dispatch and fleet rebalancing. For this reason, operators tend to employ simplified algorithms that have been demonstrated to work well in a particular setting. To help bridge the gap between novel and existing methods, we propose a modular framework for fleet rebalancing based on model-free reinforcement learning (RL) that can leverage an existing dispatch method to minimize system cost. In particular, by treating dispatch as part of the environment dynamics, a centralized agent can learn to intermittently direct the dispatcher to reposition free vehicles and mitigate against fleet imbalance. We formulate RL state and action spaces as distributions over a grid partitioning of the operating area, making the framework scalable and avoiding the complexities associated with multiagent RL. Numerical experiments, using real-world trip and network data, demonstrate that this approach has several distinct advantages over baseline methods including: improved system cost; high degree of adaptability to the selected dispatch method; and the ability to perform scale-invariant transfer learning between problem instances with similar vehicle and request distributions.      
### 5.Detection of a rank-one signal with limited training data  [ :arrow_down: ](https://arxiv.org/pdf/2105.13282.pdf)
>  In this paper, we reconsider the problem of detecting a matrix-valued rank-one signal in unknown Gaussian noise, which was previously addressed for the case of sufficient training data. We relax the above assumption to the case of limited training data. We re-derive the corresponding generalized likelihood ratio test (GLRT) and two-step GLRT (2S--GLRT) based on certain unitary transformation on the test data. It is shown that the re-derived detectors can work with low sample support. Moreover, in sample-abundant environments the re-derived GLRT is the same as the previously proposed GLRT and the re-derived 2S--GLRT has better detection performance than the previously proposed 2S--GLRT. Numerical examples are provided to demonstrate the effectiveness of the re-derived detectors.      
### 6.OpenSerDes: An Open Source Process-Portable All-Digital Serial Link  [ :arrow_down: ](https://arxiv.org/pdf/2105.13256.pdf)
>  In the last decade, the growing influence of open source software has necessitated the need to reduce the abstraction levels in hardware design. Open source hardware significantly reduces the development time, increasing the probability of first-pass success and enable developers to optimize software solutions based on hardware features, thereby reducing the design costs. The recent introduction of open source Process Development Kit (OpenPDK) by Skywater technologies in June 2020 has eliminated the barriers to Application-Specific Integrated Circuit (ASIC) design, which is otherwise considered expensive and not easily accessible. The OpenPDK is the first concrete step towards achieving the goal of open source circuit blocks that can be imported to reuse and modify in ASIC design. With process technologies scaling down for better performance, the need for entirely digital designs, which can be synthesized in any standard Automatic Place-and-Route (APR) tool, has increased considerably, for mapping physical design to the new process technology. This work presents the first open source all-digital Serializer/Deserializer (SerDes) for multi-GHz serial links designed using Skywater OpenPDK 130nm process node. To ensure that the design is fully synthesizable, the SerDes uses CMOS inverter-based drivers at the Tx, while the Rx front end comprises a resistive feedback inverter as a sensing element, followed by sampling elements. A fully digital oversampling CDR at the Rx recovers the Tx clock for proper decoding of data bits. The physical design flow utilizes OpenLANE, which is an end-to-end tool for generating GDS from RTL. Virtuoso has been used for extracting parasitics for post-layout simulations, which exhibit the SerDes functionality at 2 Gbps for 34 dB channel loss while consuming 438 mW power. The GDS and netlist files of the SerDes are uploaded in a GitHub repository for public access.      
### 7.High Tension Lines: Predicting robustness of high-voltage power-grids to cascading failure using network embedding  [ :arrow_down: ](https://arxiv.org/pdf/2105.13224.pdf)
>  This paper explores whether graph embedding methods can be used as a tool for analysing the robustness of power-grids within the framework of network science. The paper focuses on the strain elevation tension spring embedding (SETSe) algorithm and compares it to node2vec and Deep Graph Infomax, and the measures mean edge capacity and line load. These five methods are tested on how well they can predict the collapse point of the giant component of a network under random attack. The analysis uses seven power-grid networks, ranging from 14 to 2000 nodes. In total, 3456 load profiles are created for each network by loading the edges of the network to have a range of tolerances and concentrating network capacity into fewer edges. One hundred random attack sequences are generated for each load profile, and the mean number of attacks required for the giant component to collapse for each profile is recorded. The relationship between the embedding values for each load profile and the mean collapse point is then compared across all five methods. It is found that only SETSe and line load perform well as proxies for robustness with $R^2 = 0.89$ for both measures. When tested on a time series normal operating conditions line load performs exceptionally well ($R=0.99$). However, the SETSe algorithm provides valuable qualitative insight into the state of the power-grid by leveraging its method local smoothing and global weighting of node features to provide an interpretable geographical embedding. This paper shows that graph representation algorithms can be used to analyse network properties such as robustness to cascading failure attacks, even when the network is embedded at node level.      
### 8.Deep Learning Techniques for Compressive Sensing-Based Reconstruction and Inference -- A Ubiquitous Systems Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2105.13191.pdf)
>  Compressive sensing (CS) is a mathematically elegant tool for reducing the sampling rate, potentially bringing context-awareness to a wider range of devices. Nevertheless, practical issues with the sampling and reconstruction algorithms prevent further proliferation of CS in real world domains, especially among heterogeneous ubiquitous devices. Deep learning (DL) naturally complements CS for adapting the sampling matrix, reconstructing the signal, and learning form the compressed samples. While the CS-DL integration has received substantial research interest recently, it has not yet been thoroughly surveyed, nor has the light been shed on practical issues towards bringing the CS-DL to real world implementations in the ubicomp domain. In this paper we identify main possible ways in which CS and DL can interplay, extract key ideas for making CS-DL efficient, identify major trends in CS-DL research space, and derive guidelines for future evolution of CS-DL within the ubicomp domain.      
### 9.On the Concept of Frequency in Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2105.13177.pdf)
>  Frequency is a central concept in Mathematics, Physics, and Signal Processing. It is the main tool for describing the oscillatory behavior of signals, which is usually argued to be the manifestation of some of their key features, depending on their nature. For instance, this is the case of Electroencephalographic signals. Hence, frequency is substantially present in the most common methodologies for analyzing signals, as the Fourier Analysis or the Time-Frequency Analysis. However, in spite of its importance as a keystone in Signal Processing, and its seemingly simple meaning, its mathematical foundation is not as straightforward as it may seem at first glance. A naive interpretation of the different mathematical concepts modelling frequency can be misleading, as their actual meanings essentially differ from the intuitive notion which are supposed to represent. In our opinion, this circumstance should be taken into account in order to develop appropriate signal analyzing and processing tools in some applications. In the current text we discuss this topic, with the main goal to draw the attention of the mathematical and engineering community to this point,often overlooked.      
### 10.Mobile Wireless Power Transfer Using A Self-Aligned Resonant Beam  [ :arrow_down: ](https://arxiv.org/pdf/2105.13174.pdf)
>  Wireless charging for a moving electronic device such as smartphone is extremely difficult. Owing to energy dissipation during wireless transmission, sophisticated tracking control is typically required for simultaneously efficient and remote energy transfer in mobile scenarios. However, reaching the necessary tracking accuracy and reliability is very hard or even impossible. Here, inspired by the structures of optical resonator and retroreflector, we develop a self-aligned light beam system for mobile energy transfer with simultaneous high efficiency and long distance by exploring radiative resonances inside a double-retroreflector cavity. This system eliminates the requirement for any tracking control. To reduce transmission loss in mobile scenarios, we combine the advantages of energy-concentration using an optical resonant beam and self-alignment using a double-retroreflector cavity. We demonstrate above 5-watt optical power transfer with nearly 100% efficiency to a few-centimeter-size receiver for charging a smartphone, which is moving arbitrarily in the range of 2-meter distance and 6-degree field of view from the transmitter. This charging system empowers a smartphone in mobile operation with unlimited battery life, where cable charging is no longer needed. We validate the simultaneous high efficiency and long distance of the mobile energy transfer system through theoretical analyses and systematic experiments.      
### 11.Wireless Link Scheduling via Interference-aware Symmetric Positive Definite Connectivity Manifolds  [ :arrow_down: ](https://arxiv.org/pdf/2105.13163.pdf)
>  In this paper, we investigate the fundamental problem of wireless link scheduling in device-to-device (D2D) networks, through the lens of Riemannian geometry. Our goal is to find a novel metric to characterize interference among D2D pairs, which can pave the way towards efficient and fast scheduling algorithms. Towards achieving this goal, we first model the connectivity pattern of each D2D pair, including its interference links, as a positively-shifted Laplacian matrix, which is a symmetric positive definite (SPD) one. Noting that SPD matrices constitute a non-Euclidean manifold, we represent each of the D2D pairs as a point on the SPD (i.e., conic) manifold, which is analyzed via Riemannian geometry. Accordingly we employ Riemannian metrics (e.g., Log-Euclidean metric "LEM"), which are suitable measures of distances on manifolds, to characterize the interference among D2D points on the SPD manifold. <br>To validate the effectiveness of the proposed LEM-based interference measure, we propose a sequential link selection algorithm that schedules D2D pairs in a descending order of their signal-to-noise ratio (SNR), while keeping their LEM distances towards the already-scheduled pairs on the Riemannian manifold to be greater than a certain LEM threshold. Such LEM-based condition is equivalent to limiting the interference from potential D2D pairs to be below certain threshold. We show that the proposed LEM-based scheduling algorithm achieves sum rate of more than 86% of state-of-the-art ones (e.g., FPLinQ), while only requiring spatial locations of D2D pairs, as opposed to requiring full channel state information (CSI).      
### 12.Cardiac Segmentation on CT Images through Shape-Aware Contour Attentions  [ :arrow_down: ](https://arxiv.org/pdf/2105.13153.pdf)
>  Cardiac segmentation of atriums, ventricles, and myocardium in computed tomography (CT) images is an important first-line task for presymptomatic cardiovascular disease diagnosis. In several recent studies, deep learning models have shown significant breakthroughs in medical image segmentation tasks. Unlike other organs such as the lungs and liver, the cardiac organ consists of multiple substructures, i.e., ventricles, atriums, aortas, arteries, veins, and myocardium. These cardiac substructures are proximate to each other and have indiscernible boundaries (i.e., homogeneous intensity values), making it difficult for the segmentation network focus on the boundaries between the substructures. In this paper, to improve the segmentation accuracy between proximate organs, we introduce a novel model to exploit shape and boundary-aware features. We primarily propose a shape-aware attention module, that exploits distance regression, which can guide the model to focus on the edges between substructures so that it can outperform the conventional contour-based attention method. In the experiments, we used the Multi-Modality Whole Heart Segmentation dataset that has 20 CT cardiac images for training and validation, and 40 CT cardiac images for testing. The experimental results show that the proposed network produces more accurate results than state-of-the-art networks by improving the Dice similarity coefficient score by 4.97%. Our proposed shape-aware contour attention mechanism demonstrates that distance transformation and boundary features improve the actual attention map to strengthen the responses in the boundary area. Moreover, our proposed method significantly reduces the false-positive responses of the final output, resulting in accurate segmentation.      
### 13.Optimal control of centrifugal spreader  [ :arrow_down: ](https://arxiv.org/pdf/2105.13124.pdf)
>  Achieving an evenly distributed fertilization spread pattern is a complex technical task. A corresponding control algorithm must account for the tractor movement, the settings of the spreader, the prescribed dosage as well as machine constraints. It dictates, in particular, the fertilization process needs be estimated ahead to achieve an optimized spread pattern. The presented work is concerned with the development of a predictive control scheme for optimized fertilizer application using modeling of the tractor moving on the field and the spread pattern in form of a crescent behind the tractor. In particular, the form of the spread pattern is modeled via four normal distributions, two for each side of the pattern. The control goal is to achieve a desired fertilizer distribution on the field. The study presents three algorithms for comparison: a one-step optimization and two approaches using model-predictive control, one with a simplified model of the spread pattern in the prediction horizon, and one with a comprehensive one model, respectively. The best results are obtained with model-predictive control using the comprehensive model.      
### 14.Joint Channel Estimation and Device Activity Detection in Heterogeneous Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.13118.pdf)
>  Internet of Things (IoT) has triggered a rapid increase in the number of connected devices and new use cases of wireless communications. To meet the new demands, the fifth generation (5G) of wireless communication systems features native machine type communication (MTC) services in addition to traditional human type communication (HTC) services. Some of the main challenges are the heterogeneous requirements and the sporadic traffic of massive MTC (mMTC), which makes the orthogonal allocation of resources infeasible. To overcome this problem, grant free non-orthogonal multiple access schemes have been proposed alongside with sparse signal recovery algorithms. While most of the related works have considered only homogeneous networks, we focus on a scenario where an enhanced mobile broadband (eMBB) device and multiple MTC devices share the same radio resources. We exploit the approximate message passing (AMP) algorithm for joint device activity detection and channel estimation of MTC devices in the presence of interference from eMBB, and evaluate the system performance in terms of receiver operating characteristics (ROC) and channel estimation errors. Moreover, we also propose two new pilot sequence generation strategies which improve the detection capabilities of the MTC receiver without affecting the eMBB service.      
### 15.Rethinking Grid-Forming and Grid-Following Inverters: The Duality Theory  [ :arrow_down: ](https://arxiv.org/pdf/2105.13094.pdf)
>  Grid-forming and grid-following inverters are recognized as two main types of power electronic converters for integrating renewable energy resources into power systems. They hold certain similarities, but more differences, which makes their relationship quite subtle and ambiguous. In this article, a new perspective called duality is proposed to overcome this problem, which successfully unifies the grid interfacing characteristics and grid synchronization of them in a very symmetric and graceful form. As analyzed, the grid-forming and grid-following inverters are essentially dual to each other, which is further based on the duality of a) synchronization controllers: frequency droop control and phase-locked loop (PLL); b) grid-interfacing characteristics: current-following voltage-forming and voltage-following current-forming; c) swing characteristics: current-angle swing and voltage-angle swing; d) controllers: output impedance shaping and output admittance shaping; e) grid strength: strong-grid instability and weak-grid instability; etc. The detailed swing characteristics are also derived in dual form for both inverters, which reveals the dynamic interaction among grid strength, synchronization controllers, and inner-loop controllers, as well as their effects on stability. Typical cases, namely single-inverter-infinite-bus systems and multi-inverter power systems, are studied and simulated to validate the theoretical analysis.      
### 16.Beam Focusing for Near-Field Multi-User MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.13087.pdf)
>  Large antenna arrays and high-frequency bands are two key features of future wireless communication systems. The combination of large-scale antennas with high transmission frequencies often results in the communicating devices operating in the near-field (Fresnel) region. In this paper, we study the potential of beam focusing, feasible in near-field operation, in facilitating high-rate multi-user downlink multiple-input multiple-output (MIMO) systems. As the ability to achieve beam focusing is dictated by the transmit antenna, we study near-field signaling considering different antenna structures, including fully-digital architectures, hybrid phase shifter-based precoders, and the emerging dynamic metasurface antenna (DMA) architecture for massive MIMO arrays. We first provide a mathematical model to characterize near-field wireless channels as well as the transmission pattern for the considered antenna architectures. Then, we formulate the beam focusing problem for the goal of maximizing the achievable sum-rate in multi-user networks. We propose efficient solutions based on the sum-rate maximization task for fully-digital, (phase shifters based-) hybrid and DMA architectures. Simulation results show the feasibility of the proposed beam focusing scheme for both single- and multi-user scenarios. In particular, the designed focused beams are such that users residing at the same angular direction can communicate reliably without interfering with each other, which is not achievable using conventional far-field beam steering.      
### 17.HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization  [ :arrow_down: ](https://arxiv.org/pdf/2105.13084.pdf)
>  Most consumer-grade digital cameras can only capture a limited range of luminance in real-world scenes due to sensor constraints. Besides, noise and quantization errors are often introduced in the imaging process. In order to obtain high dynamic range (HDR) images with excellent visual quality, the most common solution is to combine multiple images with different exposures. However, it is not always feasible to obtain multiple images of the same scene and most HDR reconstruction methods ignore the noise and quantization loss. In this work, we propose a novel learning-based approach using a spatially dynamic encoder-decoder network, HDRUNet, to learn an end-to-end mapping for single image HDR reconstruction with denoising and dequantization. The network consists of a UNet-style base network to make full use of the hierarchical multi-scale information, a condition network to perform pattern-specific modulation and a weighting network for selectively retaining information. Moreover, we propose a Tanh_L1 loss function to balance the impact of over-exposed values and well-exposed values on the network learning. Our method achieves the state-of-the-art performance in quantitative comparisons and visual quality. The proposed HDRUNet model won the second place in the single frame track of NITRE2021 High Dynamic Range Challenge.      
### 18.An Improved Measure of Musical Noise Based on Spectral Kurtosis  [ :arrow_down: ](https://arxiv.org/pdf/2105.13079.pdf)
>  Audio processing methods operating on a time-frequency representation of the signal can introduce unpleasant sounding artifacts known as musical noise. These artifacts are observed in the context of audio coding, speech enhancement, and source separation. The change in kurtosis of the power spectrum introduced during the processing was shown to correlate with the human perception of musical noise in the context of speech enhancement, leading to the proposal of measures based on it. These baseline measures are here shown to correlate with human perception only in a limited manner. As ground truth for the human perception, the results from two listening tests are considered: one involving audio coding and one involving source separation. Simple but effective perceptually motivated improvements are proposed and the resulting new measure is shown to clearly outperform the baselines in terms of correlation with the results of both listening tests. Moreover, with respect to the listening test on musical noise in audio coding, the exhibited correlation is nearly as good as the one exhibited by the Artifact-related Perceptual Score (APS), which was found to be the best objective measure for this task. The APS is however computationally very expensive. The proposed measure is easily computed, requiring only a fraction of the computational cost of the APS.      
### 19.Efficient High-Resolution Image-to-Image Translation using Multi-Scale Gradient U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2105.13067.pdf)
>  Recently, Conditional Generative Adversarial Network (Conditional GAN) have shown very promising performance in several image-to-image translation applications. However, the uses of these conditional GANs are quite limited to low-resolution images, such as 256X256.The Pix2Pix-HD is a recent attempt to utilize the conditional GAN for high-resolution image synthesis. In this paper, we propose a Multi-Scale Gradient based U-Net (MSG U-Net) model for high-resolution image-to-image translation up to 2048X1024 resolution. The proposed model is trained by allowing the flow of gradients from multiple-discriminators to a single generator at multiple scales. The proposed MSG U-Net architecture leads to photo-realistic high-resolution image-to-image translation. Moreover, the proposed model is computationally efficient as com-pared to the Pix2Pix-HD with an improvement in the inference time nearly by 2.5 times. We provide the code of MSG U-Net model at <a class="link-external link-https" href="https://github.com/laxmaniron/MSG-U-Net" rel="external noopener nofollow">this https URL</a>.      
### 20.Conditional generator and multi-sourcecorrelation guided brain tumor segmentation with missing MR modalities  [ :arrow_down: ](https://arxiv.org/pdf/2105.13013.pdf)
>  Brain tumor is one of the most high-risk cancers which causes the 5-year survival rate of only about 36%. Accurate diagnosis of brain tumor is critical for the treatment planning. However, complete data are not always available in clinical scenarios. In this paper, we propose a novel brain tumor segmentation network to deal with the missing data issue. To compensate for missing data, we propose to use a conditional generator to generate the missing modality under the condition of the available modalities. As the multi-modality has a strong correlation in tumor region, we design a correlation constraint network to leverage the multi-source information. On the one hand, the correlation constraint network can help the conditional generator to generate the missing modality which should keep the multi-source correlation with the available modalities. On the other hand, it can guide the segmentation network to learn the correlated feature representations to improve the segmentation performance. The proposed network consists of a conditional generator, a correlation constraint network and a segmentation network. We carried out extensive experiments on BraTS 2018 dataset to evaluate the proposed method.The experimental results demonstrate the importance of the proposed components and the superior performance of the proposed method com-pared with the state-of-the-art methods      
### 21.IRS-Assisted Massive MIMO-NOMA Networks with Polarization Diversity  [ :arrow_down: ](https://arxiv.org/pdf/2105.12952.pdf)
>  In this paper, the appealing features of a dual-polarized intelligent reflecting surface (IRS) are exploited to improve the performance of dual-polarized massive multiple-input multiple-output (MIMO) with non-orthogonal multiple access (NOMA) under imperfect successive interference cancellation (SIC). By considering the downlink of a multi-cluster scenario, the IRSs assist the base station (BS) to multiplex subsets of users in the polarization domain. Our novel strategy alleviates the impact of imperfect SIC and enables users to exploit polarization diversity with near-zero inter-subset interference. Our results show that when the IRSs are large enough, the proposed scheme always outperforms conventional massive MIMO-NOMA and MIMO-OMA systems even if SIC error propagation is present. It is also confirmed that dual-polarized IRSs can make cross-polar transmissions beneficial to the users, allowing them to improve their performance through polarization diversity.      
### 22.VeniBot: Towards Autonomous Venipuncture with Automatic Puncture Area and Angle Regression from NIR Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.12951.pdf)
>  Venipucture is a common step in clinical scenarios, and is with highly practical value to be automated with robotics. Nowadays, only a few on-shelf robotic systems are developed, however, they can not fulfill practical usage due to varied reasons. In this paper, we develop a compact venipucture robot -- VeniBot, with four parts, six motors and two imaging devices. For the automation, we focus on the positioning part and propose a Dual-In-Dual-Out network based on two-step learning and two-task learning, which can achieve fully automatic regression of the suitable puncture area and angle from near-infrared(NIR) images. The regressed suitable puncture area and angle can further navigate the positioning part of VeniBot, which is an important step towards a fully autonomous venipucture robot. Validation on 30 VeniBot-collected volunteers shows a high mean dice coefficient(DSC) of 0.7634 and a low angle error of 15.58Â° on suitable puncture area and angle regression respectively, indicating its potentially wide and practical application in the future.      
### 23.VeniBot: Towards Autonomous Venipuncture with Semi-supervised Vein Segmentation from Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.12945.pdf)
>  In the modern medical care, venipuncture is an indispensable procedure for both diagnosis and treatment. In this paper, unlike existing solutions that fully or partially rely on professional assistance, we propose VeniBot -- a compact robotic system solution integrating both novel hardware and software developments. For the hardware, we design a set of units to facilitate the supporting, positioning, puncturing and imaging functionalities. For the software, to move towards a full automation, we propose a novel deep learning framework -- semi-ResNeXt-Unet for semi-supervised vein segmentation from ultrasound images. From which, the depth information of vein is calculated and used to enable automated navigation for the puncturing unit. VeniBot is validated on 40 volunteers, where ultrasound images can be collected successfully. For the vein segmentation validation, the proposed semi-ResNeXt-Unet improves the dice similarity coefficient (DSC) by 5.36%, decreases the centroid error by 1.38 pixels and decreases the failure rate by 5.60%, compared to fully-supervised ResNeXt-Unet.      
### 24.MR elasticity reconstruction using statistical physical modeling and explicit data-driven denoising regularizer  [ :arrow_down: ](https://arxiv.org/pdf/2105.12922.pdf)
>  Elasticity image, visualizing the quantitative map of tissue stiffness, can be reconstructed by solving an inverse problem. Classical methods for magnetic resonance elastography (MRE) try to solve a regularized optimization problem comprising a deterministic physical model and a prior constraint as data-fidelity term and regularization term, respectively. For improving the elasticity reconstructions, appropriate prior about the underlying elasticity distribution is required which is not unique. This article proposes an infused approach for MRE reconstruction by integrating the statistical representation of the physical laws of harmonic motions and learning-based prior. For data-fidelity term, we use a statistical linear-algebraic model of equilibrium equations and for the regularizer, data-driven regularization by denoising (RED) is utilized. In the proposed optimization paradigm, the regularizer gradient is simply replaced by the residual of learned denoiser leading to time-efficient computation and convex explicit objective function. Simulation results of elasticity reconstruction verify the effectiveness of the proposed approach.      
### 25.Compositional Thinking in Cyber-Physical Systems Theory  [ :arrow_down: ](https://arxiv.org/pdf/2105.12911.pdf)
>  Engineering safe and secure cyber-physical systems requires system engineers to develop and maintain a number of model views, both dynamic and static, which can be seen as algebras. We posit that verifying the composition of requirement, behavioral, and architectural models using category theory gives rise to a strictly compositional interpretation of cyber-physical systems theory, which can assist in the modeling and analysis of safety-critical cyber-physical systems.      
### 26.MIG Median Detectors with Manifold Filter  [ :arrow_down: ](https://arxiv.org/pdf/2105.12889.pdf)
>  In this paper, we propose a class of median-based matrix information geometry (MIG) detectors with a manifold filter and apply them to signal detection in nonhomogeneous environments. As customary, the sample data is assumed to be modeled as Hermitian positive-definite (HPD) matrices, and the geometric median of a set of HPD matrices is interpreted as an estimate of the clutter covariance matrix (CCM). Then, the problem of signal detection can be reformulated as discriminating two points on the manifold of HPD matrices, one of which is the HPD matrix in the cell under test while the other represents the CCM. By manifold filter, we map a set of HPD matrices to another set of HPD matrices by weighting them, that consequently improves the discriminative power by reducing the intra-class distances while increasing the inter-class distances. Three MIG median detectors are designed by resorting to three geometric measures on the matrix manifold, and the corresponding geometric medians are shown to be robust to outliers. Numerical simulations show the advantage of the proposed MIG median detectors in comparison with their state-of-the-art counterparts as well as the conventional detectors in nonhomogeneous environments.      
### 27.Quantitative phase imaging of single particles from a cryoEM micrograph  [ :arrow_down: ](https://arxiv.org/pdf/2105.12777.pdf)
>  We show that de-focused single particle images recorded using a cryo-electron microscope (cryoEM) system may be processed like a Fresnel zone in-line hologram to obtain physically meaningful quantitative phase maps associated with individual particles. In particular, a region-of-interest (ROI) of the de-focused image surrounding a particle can be numerically back-propagated, in order to determine accurate de-focus information based on the sparsity-of-gradient merit function. Further with the knowledge of de-focus information, an iterative Fresnel zone phase retrieval algorithm using image sparsity constraints can accurately estimate the quantitative phase information associated with a single particle. The proposed methodology which can correct for both de-focus and spherical aberrations is a deviation from the image processing chain currently used in single particle cryoEM reconstructions. Our illustrations as presented here suggest that the phase retrieval approach applies uniformly to de-focused image data recorded using the traditional CCD detectors as well as the newer direct electron detectors.      
### 28.Structurally Adaptive Multi-Derivative Regularization for Image Recovery from Sparse Fourier Samples  [ :arrow_down: ](https://arxiv.org/pdf/2105.12775.pdf)
>  The importance of regularization has been well established in image reconstruction -- which is the computational inversion of imaging forward model -- with applications including deconvolution for microscopy, tomographic reconstruction, magnetic resonance imaging and so on. Originally, the primary role of the regularization was to stabilize the computational inversion of the imaging forward model against noise. However, a recent framework pioneered by Donoho and others, known as compressive sensing, brought the role of regularization beyond the stabilization of inversion. It established a possibility that regularization can recover full images from measurements that are highly undersampled. However, it was observed that the quality of reconstruction yielded by compressive sensing methods fall abruptly when the under-sampling and/or measurement noise goes beyond certain threshold. Recently developed learning based methods are believed to outperform the compressive sensing methods without abrupt drop in the reconstruction quality under such imaging conditions. However, the need for training data limits their applicability. In this paper, we develop a regularization method that outperforms compressive sensing methods as well as selected learning-based methods, without any need for training data. The regularization is constructed as a spatially varying weighted sum of first- and canonical second-order derivatives, with the weights determined to be adaptive to the image structure such that the attenuation of sharp image features -- which is inevitable with use of any regularization -- is minimized. We demonstrate the effectiveness of the proposed method by performing reconstruction on sparse Fourier samples simulated from a variety of MRI images.      
### 29.Quantization and Deployment of Deep Neural Networks on Microcontrollers  [ :arrow_down: ](https://arxiv.org/pdf/2105.13331.pdf)
>  Embedding Artificial Intelligence onto low-power devices is a challenging task that has been partly overcome with recent advances in machine learning and hardware design. Presently, deep neural networks can be deployed on embedded targets to perform different tasks such as speech recognition,object detection or Human Activity Recognition. However, there is still room for optimization of deep neural networks onto embedded devices. These optimizations mainly address power consumption,memory and real-time constraints, but also an easier deployment at the edge. Moreover, there is still a need for a better understanding of what can be achieved for different use cases. This work focuses on quantization and deployment of deep neural networks onto low-power 32-bit microcontrollers. The quantization methods, relevant in the context of an embedded execution onto a microcontroller, are first outlined. Then, a new framework for end-to-end deep neural networks training, quantization and deployment is presented. This framework, called MicroAI, is designed as an alternative to existing inference engines (TensorFlow Lite for Microcontrollers and <a class="link-external link-http" href="http://STM32Cube.AI" rel="external noopener nofollow">this http URL</a>). Our framework can indeed be easily adjusted and/or extended for specific use cases. Execution using single precision 32-bit floating-point as well as fixed-point on 8- and 16-bit integers are supported. The proposed quantization method is evaluated with three different datasets (UCI-HAR, Spoken MNIST and GTSRB). Finally, a comparison study between MicroAI and both existing embedded inference engines is provided in terms of memory and power efficiency. On-device evaluation is done using ARM Cortex-M4F-based microcontrollers (Ambiq Apollo3 and STM32L452RE).      
### 30.Application of Monte Carlo algorithms to cardiac imaging reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.13324.pdf)
>  Monte Carlo algorithms have a growing impact on nuclear medicine reconstruction processes. One of the main limitations of myocardial perfusion imaging (MPI) is the effective mitigation of the scattering component, which is particularly challenging in Single Photon Emission Computed Tomography (SPECT). In SPECT, no timing information can be retrieved to locate the primary source photons. Monte Carlo methods allow an event-by-event simulation of the scattering kinematics, which can be incorporated into a model of the imaging system response. This approach was adopted since the late Nineties by several authors, and recently took advantage of the increased computational power made available by high-performance CPUs and GPUs. These recent developments enable a fast image reconstruction with an improved image quality, compared to deterministic approaches. Deterministic approaches are based on energy-windowing of the detector response, and on the cumulative estimate and subtraction of the scattering component. In this paper, we review the main strategies and algorithms to correct for the scattering effect in SPECT and focus on Monte Carlo developments, which nowadays allow the three-dimensional reconstruction of SPECT cardiac images in a few seconds.      
### 31.Characterizing the SLOPE Trade-off: A Variational Perspective and the Donoho-Tanner Limit  [ :arrow_down: ](https://arxiv.org/pdf/2105.13302.pdf)
>  Sorted l1 regularization has been incorporated into many methods for solving high-dimensional statistical estimation problems, including the SLOPE estimator in linear regression. In this paper, we study how this relatively new regularization technique improves variable selection by characterizing the optimal SLOPE trade-off between the false discovery proportion (FDP) and true positive proportion (TPP) or, equivalently, between measures of type I error and power. Assuming a regime of linear sparsity and working under Gaussian random designs, we obtain an upper bound on the optimal trade-off for SLOPE, showing its capability of breaking the Donoho-Tanner power limit. To put it into perspective, this limit is the highest possible power that the Lasso, which is perhaps the most popular l1-based method, can achieve even with arbitrarily strong effect sizes. Next, we derive a tight lower bound that delineates the fundamental limit of sorted l1 regularization in optimally trading the FDP off for the TPP. Finally, we show that on any problem instance, SLOPE with a certain regularization sequence outperforms the Lasso, in the sense of having a smaller FDP, larger TPP and smaller l2 estimation risk simultaneously. Our proofs are based on a novel technique that reduces a variational calculus problem to a class of infinite-dimensional convex optimization problems and a very recent result from approximate message passing theory.      
### 32.GoSafe: Globally Optimal Safe Robot Learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.13281.pdf)
>  When learning policies for robotic systems from data, safety is a major concern, as violation of safety constraints may cause hardware damage. SafeOpt is an efficient Bayesian optimization (BO) algorithm that can learn policies while guaranteeing safety with high probability. However, its search space is limited to an initially given safe region. We extend this method by exploring outside the initial safe area while still guaranteeing safety with high probability. This is achieved by learning a set of initial conditions from which we can recover safely using a learned backup controller in case of a potential failure. We derive conditions for guaranteed convergence to the global optimum and validate GoSafe in hardware experiments.      
### 33.Evaluation of concept drift adaptation for acoustic scene classifier based on Kernel Density Drift Detection and Combine Merge Gaussian Mixture Model  [ :arrow_down: ](https://arxiv.org/pdf/2105.13220.pdf)
>  Based on the experimental results, all concepts drift types have their respective hyperparameter configurations. Simple and gradual concept drift have similar pattern which requires a smaller {\alpha} value than recurring concept drift because, in this type of drift, a new concept appear continuously, so it needs a high-frequency model adaptation. However, in recurring concepts, the new concept may repeat in the future, so the lower frequency adaptation is better. Furthermore, high-frequency model adaptation could lead to an overfitting problem. Implementing CMGMM component pruning mechanism help to control the number of the active component and improve model performance.      
### 34.Hamiltonian Deep Neural Networks Guaranteeing Non-vanishing Gradients by Design  [ :arrow_down: ](https://arxiv.org/pdf/2105.13205.pdf)
>  Deep Neural Networks (DNNs) training can be difficult due to vanishing and exploding gradients during weight optimization through backpropagation. To address this problem, we propose a general class of Hamiltonian DNNs (H-DNNs) that stem from the discretization of continuous-time Hamiltonian systems and include several existing architectures based on ordinary differential equations. Our main result is that a broad set of H-DNNs ensures non-vanishing gradients by design for an arbitrary network depth. This is obtained by proving that, using a semi-implicit Euler discretization scheme, the backward sensitivity matrices involved in gradient computations are symplectic. We also provide an upper bound to the magnitude of sensitivity matrices, and show that exploding gradients can be either controlled through regularization or avoided for special architectures. Finally, we enable distributed implementations of backward and forward propagation algorithms in H-DNNs by characterizing appropriate sparsity constraints on the weight matrices. The good performance of H-DNNs is demonstrated on benchmark classification problems, including image classification with the MNIST dataset.      
### 35.Sparse recovery based on the generalized error function  [ :arrow_down: ](https://arxiv.org/pdf/2105.13189.pdf)
>  In this paper, we propose a novel sparse recovery method based on the generalized error function. Both the theoretical analysis and the practical algorithms are presented. Numerical experiments are conducted to demonstrate the advantageous performance of the proposed approach over the state-of-the-art sparse recovery methods. Its practical application in magnetic resonance imaging (MRI) reconstruction is studied as well.      
### 36.Generalized solutions to opinion dynamics models with discontinuities  [ :arrow_down: ](https://arxiv.org/pdf/2105.13159.pdf)
>  Social dynamics models may present discontinuities in the right-hand side of the dynamics for multiple reasons, including topology changes and quantization. Several concepts of generalized solutions for discontinuous equations are available in the literature and are useful to analyze these models. In this chapter, we study Caratheodory and Krasovsky generalized solutions for discontinuous models of opinion dynamics with state dependent interactions. We consider two definitions of "bounded confidence" interactions, which we respectively call metric and topological: in the former, individuals interact if their opinions are closer than a threshold; in the latter, individuals interact with a fixed number of nearest neighbors. We compare the dynamics produced by the two kinds of interactions, in terms of existence, uniqueness and asymptotic behavior of different types of solutions.      
### 37.Diverse and Controllable Speech Synthesis with GMM-Based Phone-Level Prosody Modelling  [ :arrow_down: ](https://arxiv.org/pdf/2105.13086.pdf)
>  Generating natural speech with diverse and smooth prosody pattern is a challenging task. Although random sampling with phone-level prosody distribution has been investigated to generate different prosody patterns, the diversity of the generated speech is still very limited and far from what can be achieved by human. This is largely due to the use of uni-modal distribution, such as single Gaussian, in the prior works of phone-level prosody modelling. In this work, we propose a novel approach that models phone-level prosodies with a GMM-based mixture density network and then extend it for multi-speaker TTS using speaker adaptation transforms of Gaussian means and variances. Furthermore, we show that we can clone the prosodies from a reference speech by sampling prosodies from the Gaussian components that produce the reference prosodies. Our experiments on LJSpeech and LibriTTS dataset show that the proposed GMM-based method not only achieves significantly better diversity than using a single Gaussian in both single-speaker and multi-speaker TTS, but also provides better naturalness. The prosody cloning experiments demonstrate that the prosody similarity of the proposed GMM-based method is comparable to recent proposed fine-grained VAE while the target speaker similarity is better.      
### 38.LVD-NMPC: A Learning-based Vision Dynamics Approach to Nonlinear Model Predictive Control for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2105.13038.pdf)
>  In this paper, we introduce a learning-based vision dynamics approach to nonlinear model predictive control for autonomous vehicles, coined LVD-NMPC. LVD-NMPC uses an a-priori process model and a learned vision dynamics model used to calculate the dynamics of the driving scene, the controlled system's desired state trajectory and the weighting gains of the quadratic cost function optimized by a constrained predictive controller. The vision system is defined as a deep neural network designed to estimate the dynamics of the images scene. The input is based on historic sequences of sensory observations and vehicle states, integrated by an Augmented Memory component. Deep Q-Learning is used to train the deep network, which once trained can be used to also calculate the desired trajectory of the vehicle. We evaluate LVD-NMPC against a baseline Dynamic Window Approach (DWA) path planning executed using standard NMPC, as well as against the PilotNet neural network. Performance is measured in our simulation environment GridSim, on a real-world 1:8 scaled model car, as well as on a real size autonomous test vehicle and the nuScenes computer vision dataset.      
### 39.Robust learning from corrupted EEG with dynamic spatial filtering  [ :arrow_down: ](https://arxiv.org/pdf/2105.12916.pdf)
>  Building machine learning models using EEG recorded outside of the laboratory setting requires methods robust to noisy data and randomly missing channels. This need is particularly great when working with sparse EEG montages (1-6 channels), often encountered in consumer-grade or mobile EEG devices. Neither classical machine learning models nor deep neural networks trained end-to-end on EEG are typically designed or tested for robustness to corruption, and especially to randomly missing channels. While some studies have proposed strategies for using data with missing channels, these approaches are not practical when sparse montages are used and computing power is limited (e.g., wearables, cell phones). To tackle this problem, we propose dynamic spatial filtering (DSF), a multi-head attention module that can be plugged in before the first layer of a neural network to handle missing EEG channels by learning to focus on good channels and to ignore bad ones. We tested DSF on public EEG data encompassing ~4,000 recordings with simulated channel corruption and on a private dataset of ~100 at-home recordings of mobile EEG with natural corruption. Our proposed approach achieves the same performance as baseline models when no noise is applied, but outperforms baselines by as much as 29.4% accuracy when significant channel corruption is present. Moreover, DSF outputs are interpretable, making it possible to monitor channel importance in real-time. This approach has the potential to enable the analysis of EEG in challenging settings where channel corruption hampers the reading of brain signals.      
### 40.Neural Enhanced Belief Propagation for Cooperative Localization  [ :arrow_down: ](https://arxiv.org/pdf/2105.12903.pdf)
>  Location-aware networks will introduce innovative services and applications for modern convenience, applied ocean sciences, and public safety. In this paper, we establish a hybrid method for model-based and data-driven inference. We consider a cooperative localization (CL) scenario where the mobile agents in a wireless network aim to localize themselves by performing pairwise observations with other agents and by exchanging location information. A traditional method for distributed CL in large agent networks is belief propagation (BP) which is completely model-based and is known to suffer from providing inconsistent (overconfident) estimates. The proposed approach addresses these limitations by complementing BP with learned information provided by a graph neural network (GNN). We demonstrate numerically that our method can improve estimation accuracy and avoid overconfident beliefs, while its computational complexity remains comparable to BP. Notably, more consistent beliefs are obtained by not explicitly addressing overconfidence in the loss function used for training of the GNN.      
### 41.Developing Robust Digital Twins and Reinforcement Learning for Accelerator Control Systems at the Fermilab Booster  [ :arrow_down: ](https://arxiv.org/pdf/2105.12847.pdf)
>  We describe the offline machine learning (ML) development for an effort to precisely regulate the Gradient Magnet Power Supply (GMPS) at the Fermilab Booster accelerator complex via a Field-Programmable Gate Array (FPGA). As part of this effort, we created a digital twin of the Booster-GMPS control system by training a Long Short-Term Memory (LSTM) to capture its full dynamics. We outline the path we took to carefully validate our digital twin before deploying it as a reinforcement learning (RL) environment. Additionally, we demonstrate the use of a Deep Q-Network (DQN) policy model with the capability to regulate the GMPS against realistic time-varying perturbations.      
### 42.Information Harvesting for Far-Field Wireless Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2105.12838.pdf)
>  Considering ubiquitous connectivity and advanced information processing capability, huge amount of low-power IoT devices are deployed nowadays and the maintenance of those devices which includes firmware/software updates and recharging the units has become a bottleneck for IoT systems. For addressing limited battery constraints, wireless power transfer is a promising approach such that it does not require any physical link between energy harvester and power transfer. Furthermore, combining wireless power transfer with information transmission has become more appealing. In the systems that apply radio signals the wireless power transfer has become a popular trend to harvest RF-radiated energy from received information signal in IoT devices. For those systems, design frameworks mainly deal with the trade-off between information capacity and energy harvesting efficiency. Therein various signaling design frameworks have been proposed for different system preferences between power and information. In addition to this, protecting the information part from potential eavesdropping activity in a service area introduces security considerations for those systems. In this paper, we propose a novel concept, Information Harvesting, for wireless power transfer systems. It introduces a novel protocol design from opposite perspective compared to the existing studies. Particularly, Information Harvesting aims to transmit information through existing wireless power transfer mechanism without interfering/interrupting power transfer.      
### 43.Self-attending RNN for Speech Enhancement to Improve Cross-corpus Generalization  [ :arrow_down: ](https://arxiv.org/pdf/2105.12831.pdf)
>  Deep neural networks (DNNs) represent the mainstream methodology for supervised speech enhancement, primarily due to their capability to model complex functions using hierarchical representations. However, a recent study revealed that DNNs trained on a single corpus fail to generalize to untrained corpora, especially in low signal-to-noise ratio (SNR) conditions. Developing a noise, speaker, and corpus independent speech enhancement algorithm is essential for real-world applications. In this study, we propose a self-attending recurrent neural network(SARNN) for time-domain speech enhancement to improve cross-corpus generalization. SARNN comprises of recurrent neural networks (RNNs) augmented with self-attention blocks and feedforward blocks. We evaluate SARNN on different corpora with nonstationary noises in low SNR conditions. Experimental results demonstrate that SARNN substantially outperforms competitive approaches to time-domain speech enhancement, such as RNNs and dual-path SARNNs. Additionally, we report an important finding that the two popular approaches to speech enhancement: complex spectral mapping and time-domain enhancement, obtain similar results for RNN and SARNN with large-scale training. We also provide a challenging subset of the test set used in this study for evaluating future algorithms and facilitating direct comparisons.      
### 44.Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.12827.pdf)
>  The paper describes an online deep learning algorithm for the adaptive modulation and coding in 5G Massive MIMO. The algorithm is based on a fully-connected neural network, which is initially trained on the output of the traditional algorithm and then is incrementally retrained by the service feedback of its own output. We show advantage of our solution over the state-of-the-art Q-Learning approach. We provide system-level simulation results to support this conclusion in various scenarios with different channel characteristics and different user speed. Compared with traditional OLLA the proposal shows 10% to 20% improvement of user throughput in full buffer case.      
### 45.Issues in Object Detection in Videos using Common Single-Image CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2105.12822.pdf)
>  A growing branch of computer vision is object detection. Object detection is used in many applications such as industrial process, medical imaging analysis, and autonomous vehicles. The ability to detect objects in videos is crucial. Object detection systems are trained on large image datasets. For applications such as autonomous vehicles, it is crucial that the object detection system can identify objects through multiple frames in video. There are many problems with applying these systems to video. Shadows or changes in brightness that can cause the system to incorrectly identify objects frame to frame and cause an unintended system response. There are many neural networks that have been used for object detection and if there was a way of connecting objects between frames then these problems could be eliminated. For these neural networks to get better at identifying objects in video, they need to be re-trained. A dataset must be created with images that represent consecutive video frames and have matching ground-truth layers. A method is proposed that can generate these datasets. The ground-truth layer contains only moving objects. To generate this layer, FlowNet2-Pytorch was used to create the flow mask using the novel Magnitude Method. As well, a segmentation mask will be generated using networks such as Mask R-CNN or Refinenet. These segmentation masks will contain all objects detected in a frame. By comparing this segmentation mask to the flow mask ground-truth layer, a loss function is generated. This loss function can be used to train a neural network to be better at making consistent predictions on video. The system was tested on multiple video samples and a loss was generated for each frame, proving the Magnitude Method's ability to be used to train object detection neural networks in future work.      
### 46.On the Achievable Max-Min User Rates in Multi-Carrier Centralized NOMA-VLC Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.12821.pdf)
>  Visible light communications (VLC) is gaining interest as one of the enablers of short-distance, high-data-rate applications, in future beyond 5G networks. Moreover, non-orthogonal multiple-access (NOMA)-enabled schemes have recently emerged as a promising multiple-access scheme for these networks that would allow realization of the target spectral efficiency and user fairness requirements. The integration of NOMA in the widely adopted orthogonal frequency-division multiplexing (OFDM)-based VLC networks would require an optimal resource allocation for the pair or the cluster of users sharing the same subcarrier(s). In this paper, the max-min rate of a multi-cell indoor centralized VLC network is maximized through optimizing user pairing, subcarrier allocation, and power allocation. The joint complex optimization problem is tackled using a low-complexity solution. At first, the user pairing is assumed to follow the divide-and-next-largest-difference user-pairing algorithm (D-NLUPA) that can ensure fairness among the different clusters. Then, subcarrier allocation and power allocation are solved iteratively through both the Simulated Annealing (SA) meta-heuristic algorithm and the bisection method. The obtained results quantify the achievable max-min user rates for the different relevant variants of NOMA-enabled schemes and shed new light on both the performance and design of multi-user multi-carrier NOMA-enabled centralized VLC networks.      
### 47.Direct Detection Under Tukey Signalling  [ :arrow_down: ](https://arxiv.org/pdf/2105.12802.pdf)
>  A new direct-detection-compatible signalling scheme is proposed for fiber-optic communication over short distances. Controlled inter-symbol interference is exploited to extract phase information, thereby achieving data rates within one bit per channel-use of those of a coherent detector.      
### 48.DFPN: Deformable Frame Prediction Network  [ :arrow_down: ](https://arxiv.org/pdf/2105.12794.pdf)
>  Learned frame prediction is a current problem of interest in computer vision and video compression. Although several deep network architectures have been proposed for learned frame prediction, to the best of our knowledge, there is no work based on using deformable convolutions for frame prediction. To this effect, we propose a deformable frame prediction network (DFPN) for task oriented implicit motion modeling and next frame prediction. Experimental results demonstrate that the proposed DFPN model achieves state of the art results in next frame prediction. Our models and results are available at <a class="link-external link-https" href="https://github.com/makinyilmaz/DFPN" rel="external noopener nofollow">this https URL</a>.      
