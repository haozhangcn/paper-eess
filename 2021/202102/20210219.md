# ArXiv eess --Fri, 19 Feb 2021
### 1.Vision-Aided 6G Wireless Communications: Blockage Prediction and Proactive Handoff  [ :arrow_down: ](https://arxiv.org/pdf/2102.09527.pdf)
>  The sensitivity to blockages is a key challenge for the high-frequency (5G millimeter wave and 6G sub-terahertz) wireless networks. Since these networks mainly rely on line-of-sight (LOS) links, sudden link blockages highly threatens the reliability of the networks. Further, when the LOS link is blocked, the network typically needs to hand off the user to another LOS basestation, which may incur critical time latency, especially if a search over a large codebook of narrow beams is needed. A promising way to tackle the reliability and latency challenges lies in enabling proaction in wireless networks. Proaction basically allows the network to anticipate blockages, especially dynamic blockages, and initiate user hand-off beforehand. This paper presents a complete machine learning framework for enabling proaction in wireless networks relying on visual data captured, for example, by RGB cameras deployed at the base stations. In particular, the paper proposes a vision-aided wireless communication solution that utilizes bimodal machine learning to perform proactive blockage prediction and user hand-off. The bedrock of this solution is a deep learning algorithm that learns from visual and wireless data how to predict incoming blockages. The predictions of this algorithm are used by the wireless network to proactively initiate hand-off decisions and avoid any unnecessary latency. The algorithm is developed on a vision-wireless dataset generated using the ViWi data-generation framework. Experimental results on two basestations with different cameras indicate that the algorithm is capable of accurately detecting incoming blockages more than $\sim 90\%$ of the time. Such blockage prediction ability is directly reflected in the accuracy of proactive hand-off, which also approaches $87\%$. This highlights a promising direction for enabling high reliability and low latency in future wireless networks.      
### 2.Evolving Fuzzy System Applied to Battery Charge Capacity Prediction for Fault Prognostics  [ :arrow_down: ](https://arxiv.org/pdf/2102.09521.pdf)
>  This paper addresses the use of data-driven evolving techniques applied to fault prognostics. In such problems, accurate predictions of multiple steps ahead are essential for the Remaining Useful Life (RUL) estimation of a given asset. The fault prognostics' solutions must be able to model the typical nonlinear behavior of the degradation processes of these assets, and be adaptable to each unit's particularities. In this context, the Evolving Fuzzy Systems (EFSs) are models capable of representing such behaviors, in addition of being able to deal with non-stationary behavior, also present in these problems. Moreover, a methodology to recursively track the model's estimation error is presented as a way to quantify uncertainties that are propagated in the long-term predictions. The well-established NASA's Li-ion batteries data set is used to evaluate the models. The experiments indicate that generic EFSs can take advantage of both historical and stream data to estimate the RUL and its uncertainty.      
### 3.Incremental Learning and State-Space Evolving Fuzzy Control of Nonlinear Time-Varying Systems with Unknown Model  [ :arrow_down: ](https://arxiv.org/pdf/2102.09503.pdf)
>  We present a method for incremental modeling and time-varying control of unknown nonlinear systems. The method combines elements of evolving intelligence, granular machine learning, and multi-variable control. We propose a State-Space Fuzzy-set-Based evolving Modeling (SS-FBeM) approach. The resulting fuzzy model is structurally and parametrically developed from a data stream with focus on memory and data coverage. The fuzzy controller also evolves, based on the data instances and fuzzy model parameters. Its local gains are redesigned in real-time -- whenever the corresponding local fuzzy models change -- from the solution of a linear matrix inequality problem derived from a fuzzy Lyapunov function and bounded input conditions. We have shown one-step prediction and asymptotic stabilization of the Henon chaos.      
### 4.MSR-GAN: Multi-Segment Reconstruction via Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.09494.pdf)
>  Multi-segment reconstruction (MSR) is the problem of estimating a signal given noisy partial observations. Here each observation corresponds to a randomly located segment of the signal. While previous works address this problem using template or moment-matching, in this paper we address MSR from an unsupervised adversarial learning standpoint, named MSR-GAN. We formulate MSR as a distribution matching problem where the goal is to recover the signal and the probability distribution of the segments such that the distribution of the generated measurements following a known forward model is close to the real observations. This is achieved once a min-max optimization involving a generator-discriminator pair is solved. MSR-GAN is mainly inspired by CryoGAN [1]. However, in MSR-GAN we no longer assume the probability distribution of the latent variables, i.e. segment locations, is given and seek to recover it alongside the unknown signal. For this purpose, we show that the loss at the generator side originally is non-differentiable with respect to the segment distribution. Thus, we propose to approximate it using Gumbel-Softmax reparametrization trick. Our proposed solution is generalizable to a wide range of inverse problems. Our simulation results and comparison with various baselines verify the potential of our approach in different settings.      
### 5.Inferring Graph Signal Translations as Invariant Transformations for Classification Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2102.09493.pdf)
>  The field of Graph Signal Processing (GSP) has proposed tools to generalize harmonic analysis to complex domains represented through graphs. Among these tools are translations, which are required to define many others. Most works propose to define translations using solely the graph structure (i.e. edges). Such a problem is ill-posed in general as a graph conveys information about neighborhood but not about directions. In this paper, we propose to infer translations as edge-constrained operations that make a supervised classification problem invariant using a deep learning framework. As such, our methodology uses both the graph structure and labeled signals to infer translations. We perform experiments with regular 2D images and abstract hyperlink networks to show the effectiveness of the proposed methodology in inferring meaningful translations for signals supported on graphs.      
### 6.Equivariant Spherical Deconvolution: Learning Sparse Orientation Distribution Functions from Spherical Data  [ :arrow_down: ](https://arxiv.org/pdf/2102.09462.pdf)
>  We present a rotation-equivariant unsupervised learning framework for the sparse deconvolution of non-negative scalar fields defined on the unit sphere. Spherical signals with multiple peaks naturally arise in Diffusion MRI (dMRI), where each voxel consists of one or more signal sources corresponding to anisotropic tissue structure such as white matter. Due to spatial and spectral partial voluming, clinically-feasible dMRI struggles to resolve crossing-fiber white matter configurations, leading to extensive development in spherical deconvolution methodology to recover underlying fiber directions. However, these methods are typically linear and struggle with small crossing-angles and partial volume fraction estimation. In this work, we improve on current methodologies by nonlinearly estimating fiber structures via unsupervised spherical convolutional networks with guaranteed equivariance to spherical rotation. Experimentally, we first validate our proposition via extensive single and multi-shell synthetic benchmarks demonstrating competitive performance against common baselines. We then show improved downstream performance on fiber tractography measures on the Tractometer benchmark dataset. Finally, we show downstream improvements in terms of tractography and partial volume estimation on a multi-shell dataset of human subjects.      
### 7.Testing Robustness of Camera Fingerprint (PRNU) Detectors  [ :arrow_down: ](https://arxiv.org/pdf/2102.09444.pdf)
>  In the field of forensic imaging, it is important to be able to extract a 'camera fingerprint' from one or a small set of images known to have been taken by the same camera. Ideally, that fingerprint would be used to identify an individual source camera. Camera fingerprint is based on certain kind of random noise present in all image sensors that is due to manufacturing imperfections and thus unique and impossible to avoid. PRNU (Photo-Response Non-Uniformity) has become the most widely used method for SCI (Source Camera Identification). In this paper, we design a set of 'attacks' to a PRNU based SCI system and we measure the success of each method. We understand an attack method as any processing that alters minimally image quality and that is designed to fool PRNU detectors (or, generalizing, any camera fingerprint detector). The PRNU based SCI system was taken from an outstanding reference that is publicly available.      
### 8.Highway Traffic Control via Smart e-Mobility -- Part II: Dutch A$13$ Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2102.09433.pdf)
>  In this paper, we study how to alleviate highway traffic congestions by encouraging plug-in electric and hybrid vehicles to stop at charging stations around peak congestion times. Specifically, we focus on a case study and simulate the adoption of a dynamic charging price depending on the traffic congestion. We use real traffic data of the A13 highway stretch between The Hague and Rotterdam, in The Netherlands, to identify the Cell Transmission Model. Then, we apply the algorithm proposed in (Part I: Theory) to different scenarios, validating the theoretical results and showing the benefits of our strategy in terms of traffic congestion alleviation. Finally, we carry out a sensitivity analysis of the proposed algorithm and discuss how to optimize its performance.      
### 9.Gradient-Tracking over Directed Graphs for solving Leaderless Multi-Cluster Games  [ :arrow_down: ](https://arxiv.org/pdf/2102.09406.pdf)
>  We are concerned with finding Nash Equilibria in agent-based multi-cluster games, where agents are separated into distinct clusters. While the agents inside each cluster collaborate to achieve a common goal, the clusters are considered to be virtual players that compete against each other in a non-cooperative game with respect to a coupled cost function. In such scenarios, the inner-cluster problem and the game between the clusters need to be solved simultaneously. Therefore, the resulting inter-cluster Nash Equilibrium should also be a minimizer of the social welfare problem inside the clusters. In this work, this setup is cast as a distributed optimization problem with sparse state information. Hence, critical information, such as the agent's cost functions, remain private. We present a distributed algorithm that converges with a linear rate to the optimal solution. Furthermore, we apply our algorithm to an extended cournot game to verify our theoretical results.      
### 10.Transient Performance of Tube-based Robust Economic Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2102.09404.pdf)
>  In this paper, we provide non-averaged and transient performance guarantees for recently developed, tube-based robust economic model predictive control (MPC) schemes. In particular, we consider both tube-based MPC schemes with and without terminal conditions. We show that the closed-loop performance obtained by applying such MPC schemes is approximately optimal when evaluated both on finite and infinite time horizons. These performance bounds are similar to those derived previously for nominal economic MPC.      
### 11.Enhanced Magnetic Resonance Image Synthesis with Contrast-Aware Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.09386.pdf)
>  A Magnetic Resonance Imaging (MRI) exam typically consists of the acquisition of multiple MR pulse sequences, which are required for a reliable diagnosis. Each sequence can be parameterized through multiple acquisition parameters affecting MR image contrast, signal-to-noise ratio, resolution, or scan time. With the rise of generative deep learning models, approaches for the synthesis of MR images are developed to either synthesize additional MR contrasts, generate synthetic data, or augment existing data for AI training. However, current generative approaches for the synthesis of MR images are only trained on images with a specific set of acquisition parameter values, limiting the clinical value of these methods as various sets of acquisition parameter settings are used in clinical practice. Therefore, we trained a generative adversarial network (GAN) to generate synthetic MR knee images conditioned on various acquisition parameters (repetition time, echo time, image orientation). This approach enables us to synthesize MR images with adjustable image contrast. In a visual Turing test, two experts mislabeled 40.5% of real and synthetic MR images, demonstrating that the image quality of the generated synthetic and real MR images is comparable. This work can support radiologists and technologists during the parameterization of MR sequences by previewing the yielded MR contrast, can serve as a valuable tool for radiology training, and can be used for customized data generation to support AI training.      
### 12.Distributed control of multi-consensus  [ :arrow_down: ](https://arxiv.org/pdf/2102.09383.pdf)
>  We consider the problem of steering a multi-agent system to multi-consensus, namely a regime where groups of agents agree on a given value which may be different from group to group. We first address the problem by using distributed proportional controllers that implement additional links in the network modeling the communication protocol among agents and introduce a procedure for the optimal selection of them. Both the cases of single integrators and of second-order dynamics are taken into account and the stability for the multi-consensus state is studied, ultimately providing conditions for the gain of the controllers. We then extend the approach to controllers that either add or remove links in the original structure, by preserving eventually the weak connectedness of the resulting graph.      
### 13.NFCNN: Toward a Noise Fusion Convolutional Neural Network for Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2102.09376.pdf)
>  Deep learning based methods have achieved the state-of-the-art performance in image denoising. In this paper, a deep learning based denoising method is proposed and a module called fusion block is introduced in the convolutional neural network. For this so-called Noise Fusion Convolutional Neural Network (NFCNN), there are two branches in its multi-stage architecture. One branch aims to predict the latent clean image, while the other one predicts the residual image. A fusion block is contained between every two stages by taking the predicted clean image and the predicted residual image as a part of inputs, and it outputs a fused result to the next stage. NFCNN has an attractive texture preserving ability because of the fusion block. To train NFCNN, a stage-wise supervised training strategy is adopted to avoid the vanishing gradient and exploding gradient problems. Experimental results show that NFCNN is able to perform competitive denoising results when compared with some state-of-the-art algorithms.      
### 14.Highway Traffic Control via Smart e-Mobility -- Part I: Theory  [ :arrow_down: ](https://arxiv.org/pdf/2102.09354.pdf)
>  In this paper, we study how to alleviate highway traffic congestion by encouraging plug-in hybrid and electric vehicles to stop at a charging station around peak congestion times. Specifically, we design a pricing policy to make the charging price dynamic and dependent on the traffic congestion, predicted via the cell transmission model, and the availability of charging spots. Furthermore, we develop a novel framework to model how this policy affects the drivers' decisions by formulating a mixed-integer potential game. Technically, we introduce the concept of "road-to-station" (r2s) and "station-to-road" (s2r) flows, and show that the selfish actions of the drivers converge to charging schedules that are individually optimal in the sense of Nash. In the second part of this work, submitted as a separate paper (Part II: Case Study), we validate the proposed strategy on a simulated highway stretch between The Hague and Rotterdam, in The Netherlands.      
### 15.RF PIX2PIX Unsupervised Wi-Fi to Video Translation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09345.pdf)
>  With the proliferation of Wi-Fi devices in the environment, our surroundings are increasingly illuminated with low-level RF scatter. This scatter illuminates objects in the environment much like radar or LIDAR. We show that a novel unsupervised network, based on the PIX2PIX GAN architecture, can recover and visually reconstruct scene information solely from Wi-Fi background energy; in contrast to a significantly less accurate approach by Kefayati (et. all) which requires careful object labeling to recover object location from a scene. This is accomplished by learning a more robust mapping function between the channel state information (CSI) from Wi-Fi packets and Video image sample distributions.      
### 16.Supervisory Control Synthesis of Timed Automata Using Forcible Events  [ :arrow_down: ](https://arxiv.org/pdf/2102.09338.pdf)
>  Considering real-valued clocks in timed automata (TA) makes it a practical modeling framework for discrete-event systems. However, the infinite state space brings challenges to the control of TA. To synthesize a supervisor for TA using the conventional supervisory control theory, existing methods abstract TA to finite automata (FA). For many applications, the abstraction of real-time values results in an explosion in the state space of FA. This paper presents a supervisory control synthesis algorithm directly applicable to the TA without any abstraction. The plant is given as a TA with a set of uncontrollable events and a set of forcible events. Forcible events can preempt the passage of time when needed. The synthesis algorithm works by iteratively strengthening the guards of edges labeled by controllable events and invariants of locations where the progression of time can be preempted by forcible events. The synthesized supervisor, which is also a TA, is guaranteed to be controllable, maximally permissive, and results in a nonblocking and safe supervised plant.      
### 17.Mobility-Enhanced Simultaneous Lightwave Information and Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2102.09306.pdf)
>  Simultaneous lightwave information and power transfer (SLIPT) has been regarded as a promising technology to deal with the ever-growing energy consumption and data-rate demands in the Internet of Things (IoT). We propose a resonant beam based SLIPT system (RB-SLIPT), which deals with the conflict of high deliverable power and mobile receiver positioning with the existing SLIPT schemes. At first, we establish a mobile transmission channel model and depict the energy distribution in the channel. Then, we present a practical design and evaluate the energy/data transfer performance within the moving range of the RB-SLIPT. Numerical evaluation demonstrates that the RB-SLIPT can deliver 5 W charging power and enable 1.5 Gbit/s achievable data rate with the moving range of 20-degree field of view (FOV) over 3 m distance. Thus, RB-SLIPT can simultaneously provide high-power energy and high-rate data transfer, and mobile receiver positioning capability.      
### 18.Interplay of MPC and the Viability Kernel  [ :arrow_down: ](https://arxiv.org/pdf/2102.09290.pdf)
>  In this paper we consider the problem of steering a state and input constrained differential drive robot to a desired position and orientation using model-predictive control (MPC). The viability kernel of the system is determined using the theory of barriers. Moreover, local asymptotic stability of the origin under the MPC closed-loop solution without stabilizing conditions is shown. We then present numerical experiments to examine the dependency of the required prediction horizon length in MPC near the origin, as well as at parts of the kernel's boundary. It is found that the horizon increases as initial conditions approach the boundary and, in particular, non-differentiable parts of the boundary.      
### 19.A Heuristic Method for Load Retrievals Route Programming in Puzzle-based Storage Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09274.pdf)
>  Recently, many enterprises are facing the difficulties brought out by the limitation of warehouse land and the increase of loan cost. As a promising approach to improve space utilization rate, puzzle-based storage systems (PBSSs) are drawing more attention from logistics researchers. In previous research about PBSS, concentration has been paid to single target item problems. However, there are no consensus algorithms to solve load retrievals route programming in PBSSs with multiple target items. In this paper, a heuristic algorithm is proposed to solve load retrievals route programming in PBSSs with multiple target items, multiple escorts and multiple IOs. In this paper, new concepts about the proposed algorithm are defined, including target IOs, target position of escorts, number of escorts required, et al. Then, the decision procedures are designed according to these concepts. Based on Markov decision process, the proposed algorithm makes the decision of the next action by analyzing the current status, until all the target items arrive at the IOs. The case study results have shown the effectiveness and efficiency of the proposed heuristic algorithm.      
### 20.Networked Supervisory Control Synthesis of Timed Discrete-Event Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09255.pdf)
>  Conventional supervisory control theory assumes full synchronization between the supervisor and the plant. This assumption is violated in a networked-based communication setting due to the presence of delays, and this may result in incorrect behavior of a supervisor obtained from conventional supervisory control theory. This paper presents a technique to synthesize a networked supervisor handling communication delays. For this purpose, first, a networked supervisory control framework is provided, where the supervisor interacts with the plant through control and observation channels, both of which introduce delays. The control channel is FIFO, but the observation channel is assumed to be non-FIFO so that the observation of events may not necessarily be received by the supervisor in the same order as they occurred in the plant. It is assumed that a global clock exists in the networked control system, and so the communication delays are represented in terms of time. Based on the proposed framework, a networked plant automaton is achieved, which models the behavior of the plant under the effects of communication delays and disordered observations. Based on the networked plant, the networked supervisor is synthesized, which is guaranteed to be (timed networked) controllable, nonblocking, time-lock free, (timed networked) maximally permissive, and satisfies control requirements for the plant.      
### 21.Alternative Chirp Spread Spectrum Techniques for LPWANs  [ :arrow_down: ](https://arxiv.org/pdf/2102.09250.pdf)
>  Chirp spread spectrum (CSS) is the modulation technique currently employed by Long-Range (LoRa), which is one of the most prominent Internet of things wireless communications standards. The LoRa physical layer (PHY) employs CSS on top of a variant of frequency shift keying, and non-coherent detection is employed at the receiver. While it offers a good trade-off among coverage, data rate and device simplicity, its maximum achievable data rate is still a limiting factor for some applications. Moreover, the current LoRa standard does not fully exploit the CSS generic case, i.e., when data to be transmitted is encoded in different waveform parameters. Therefore, the goal of this paper is to investigate the performance of CSS while exploring different parameter settings aiming to increase the maximum achievable throughput, and hence increase spectral efficiency. Moreover, coherent and non-coherent reception algorithm design is presented under the framework of maximum likelihood estimation. For the practical receiver design, the formulation of a channel estimation technique is also presented. The performance evaluation of the different variants of CSS is carried out by inspection of the symbol error ratio as a function of the signal-to-noise ratio together with the maximum achievable throughput each scheme can achieve.      
### 22.Gaussian Kernelized Self-Attention for Long Sequence Data and Its Application to CTC-based Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.09168.pdf)
>  Self-attention (SA) based models have recently achieved significant performance improvements in hybrid and end-to-end automatic speech recognition (ASR) systems owing to their flexible context modeling capability. However, it is also known that the accuracy degrades when applying SA to long sequence data. This is mainly due to the length mismatch between the inference and training data because the training data are usually divided into short segments for efficient training. To mitigate this mismatch, we propose a new architecture, which is a variant of the Gaussian kernel, which itself is a shift-invariant kernel. First, we mathematically demonstrate that self-attention with shared weight parameters for queries and keys is equivalent to a normalized kernel function. By replacing this kernel function with the proposed Gaussian kernel, the architecture becomes completely shift-invariant with the relative position information embedded using a frame indexing technique. The proposed Gaussian kernelized SA was applied to connectionist temporal classification (CTC) based ASR. An experimental evaluation with the Corpus of Spontaneous Japanese (CSJ) and TEDLIUM 3 benchmarks shows that the proposed SA achieves a significant improvement in accuracy (e.g., from 24.0% WER to 6.0% in CSJ) in long sequence data without any windowing techniques.      
### 23.Online Optimization and Learning in Uncertain Dynamical Environments with Performance Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2102.09111.pdf)
>  We propose a new framework to solve online optimization and learning problems in unknown and uncertain dynamical environments. This framework enables us to simultaneously learn the uncertain dynamical environment while making online decisions in a quantifiably robust manner. The main technical approach relies on the theory of distributional robust optimization that leverages adaptive probabilistic ambiguity sets. However, as defined, the ambiguity set usually leads to online intractable problems, and the first part of our work is directed to find reformulations in the form of online convex problems for two sub-classes of objective functions. To solve the resulting problems in the proposed framework, we further introduce an online version of the Nesterov accelerated-gradient algorithm. We determine how the proposed solution system achieves a probabilistic regret bound under certain conditions. Two applications illustrate the applicability of the proposed framework.      
### 24.Fundamental Frequency Feature Normalization and Data Augmentation for Child Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.09106.pdf)
>  Automatic speech recognition (ASR) systems for young children are needed due to the importance of age-appropriate educational technology. Because of the lack of publicly available young child speech data, feature extraction strategies such as feature normalization and data augmentation must be considered to successfully train child ASR systems. This study proposes a novel technique for child ASR using both feature normalization and data augmentation methods based on the relationship between formants and fundamental frequency ($f_o$). Both the $f_o$ feature normalization and data augmentation techniques are implemented as a frequency shift in the Mel domain. These techniques are evaluated on a child read speech ASR task. Child ASR systems are trained by adapting a BLSTM-based acoustic model trained on adult speech. Using both $f_o$ normalization and data augmentation results in a relative word error rate (WER) improvement of 19.3% over the baseline when tested on the OGI Kids' Speech Corpus, and the resulting child ASR system achieves the best WER currently reported on this corpus.      
### 25.Reinforcement Learning for Beam Pattern Design in Millimeter Wave and Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09084.pdf)
>  Employing large antenna arrays is a key characteristic of millimeter wave (mmWave) and terahertz communication systems. However, due to the adoption of fully analog or hybrid analog/digital architectures, as well as non-ideal hardware or arbitrary/unknown array geometries, the accurate channel state information becomes hard to acquire. This impedes the design of beamforming/combining vectors that are crucial to fully exploit the potential of large-scale antenna arrays in providing sufficient receive signal power. In this paper, we develop a novel framework that leverages deep reinforcement learning (DRL) and a Wolpertinger-variant architecture and learns how to iteratively optimize the beam pattern (shape) for serving one or a small set of users relying only on the receive power measurements and without requiring any explicit channel knowledge. The proposed model accounts for key hardware constraints such as the phase-only, constant-modulus, and quantized-angle constraints. Further, the proposed framework can efficiently optimize the beam patterns for systems with non-ideal hardware and for arrays with unknown or arbitrary array geometries. Simulation results show that the developed solution is capable of finding near-optimal beam patterns based only on the receive power measurements.      
### 26.SRDTI: Deep learning-based super-resolution for diffusion tensor MRI  [ :arrow_down: ](https://arxiv.org/pdf/2102.09069.pdf)
>  High-resolution diffusion tensor imaging (DTI) is beneficial for probing tissue microstructure in fine neuroanatomical structures, but long scan times and limited signal-to-noise ratio pose significant barriers to acquiring DTI at sub-millimeter resolution. To address this challenge, we propose a deep learning-based super-resolution method entitled "SRDTI" to synthesize high-resolution diffusion-weighted images (DWIs) from low-resolution DWIs. SRDTI employs a deep convolutional neural network (CNN), residual learning and multi-contrast imaging, and generates high-quality results with rich textural details and microstructural information, which are more similar to high-resolution ground truth than those from trilinear and cubic spline interpolation.      
### 27.Analysis of EEG data using complex geometric structurization  [ :arrow_down: ](https://arxiv.org/pdf/2102.09061.pdf)
>  Electroencephalogram (EEG) is a common tool used to understand brain activities. The data are typically obtained by placing electrodes at the surface of the scalp and recording the oscillations of currents passing through the electrodes. These oscillations can sometimes lead to various interpretations, depending on the subject's health condition, the experiment carried out, the sensitivity of the tools used, human manipulations etc. The data obtained over time can be considered a time series. There is evidence in the literature that epilepsy EEG data may be chaotic. Either way, the embedding theory in dynamical systems suggests that time series from a complex system could be used to reconstruct its phase space under proper conditions. In this paper, we propose an analysis of epilepsy electroencephalogram time series data based on a novel approach dubbed complex geometric structurization. Complex geometric structurization stems from the construction of strange attractors using embedding theory from dynamical systems. The complex geometric structures are themselves obtained using a geometry tool, namely the $\alpha$-shapes from shape analysis. Initial analyses show a proof of concept in that these complex structures capture the expected changes brain in lobes under consideration. Further, a deeper analysis suggests that these complex structures can be used as biomarkers for seizure changes.      
### 28.End-to-end learnable EEG channel selection with deep neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.09050.pdf)
>  Many electroencephalography (EEG) applications rely on channel selection methods to remove the least informative channels, e.g., to reduce the amount of electrodes to be mounted, to decrease the computational load, or to reduce overfitting effects and improve performance. Wrapper-based channel selection methods aim to match the channel selection step to the target model, yet they require to re-train the model multiple times on different candidate channel subsets, which often leads to an unacceptably high computational cost, especially when said model is a (deep) neural network. To alleviate this, we propose a framework to embed the EEG channel selection in the neural network itself to jointly learn the network weights and optimal channels in an end-to-end manner by traditional backpropagation algorithms. We deal with the discrete nature of this new optimization problem by employing continuous relaxations of the discrete channel selection parameters based on the Gumbel-softmax trick. We also propose a regularization method that discourages selecting channels more than once. This generic approach is evaluated on two different EEG tasks: motor imagery brain-computer interfaces and auditory attention decoding. The results demonstrate that our framework is generally applicable, while being competitive with state-of-the art EEG channel selection methods, tailored to these tasks.      
### 29.Efficient Reservoir Computing using Field Programmable Gate Array and Electro-optic Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09049.pdf)
>  We experimentally demonstrate a hybrid reservoir computing system consisting of an electro-optic modulator and field programmable gate array (FPGA). It implements delay lines and filters digitally for flexible dynamics and high connectivity, while supporting a large number of reservoir nodes. To evaluate the system's performance and versatility, three benchmark tests are performed. The first is the 10th order Nonlinear Auto-Regressive Moving Average test (NARMA-10), where the predictions of 1000 and 25,000 steps yield impressively low normalized root mean square errors (NRMSE's) of 0.142 and 0.148, respectively. Such accurate predictions over into the far future speak to its capability of large sample size processing, as enabled by the present hybrid design. The second is the Santa Fe laser data prediction, where a normalized mean square error (NMSE) of 6.73x10-3 is demonstrated. The third is the isolate spoken digit recognition, with a word error rate close to 0.34%. Accurate, versatile, flexibly reconfigurable, and capable of long-term prediction, this reservoir computing system could find a wealth of impactful applications in real-time information processing, weather forecasting, and financial analysis.      
### 30.Design, Implementation, Comparison, and Performance analysis between Analog Butterworth and Chebyshev-I Low Pass Filter Using Approximation, Python and Proteus  [ :arrow_down: ](https://arxiv.org/pdf/2102.09048.pdf)
>  Filters are broadly used in signal processing and communication systems in noise reduction. Butterworth, Chebyshev-I Analog Low Pass Filters are developed and implemented in this paper. The filters are manually calculated using approximations and verified using Python Programming Language. Filters are also simulated in Proteus 8 Professional and implemented in the Hardware Lab using the necessary components. This paper also denotes the comparison and performance analysis of filters using Manual Computations, Hardware, and Software.      
### 31.Optimizing Unlicensed Band Spectrum Sharing With Subspace-Based Pareto Tracing  [ :arrow_down: ](https://arxiv.org/pdf/2102.09047.pdf)
>  In order to meet the ever-growing demands of data throughput for forthcoming and deployed wireless networks, new wireless technologies like Long-Term Evolution License-Assisted Access (LTE-LAA) operate in shared and unlicensed bands. However, the LAA network must co-exist with incumbent IEEE 802.11 Wi-Fi systems. We consider a coexistence scenario where multiple LAA and Wi-Fi links share an unlicensed band. We aim to improve this coexistence by maximizing the key performance indicators (KPIs) of these networks simultaneously via dimension reduction and multi-criteria optimization. These KPIs are network throughputs as a function of medium access control protocols and physical layer parameters. We perform an exploratory analysis of coexistence behavior by approximating active subspaces to identify low-dimensional structure of the optimization criteria, i.e., few linear combinations of parameters for simultaneously maximizing LAA throughput and Wi-Fi throughput. We take advantage of an aggregate low-dimensional subspace parametrized by approximated active subspaces of both throughputs to facilitate multi-criteria optimization. The low-dimensional subspace approximations enable visualizations suggesting a predominantly convex set of KPIs over active coordinates leading to an analytic Pareto trace of near-optimal solutions.      
### 32.Statistical Channel Modeling for Long-Range Ground-to-Air FSO Links  [ :arrow_down: ](https://arxiv.org/pdf/2102.09046.pdf)
>  To provide high data rate aerial links for 5G and beyond wireless networks, the integration of free-space optical (FSO) communications and aerial platforms has been recently suggested as a practical solution. To fully reap the benefit of aerial-based FSO systems, in this paper, an analytical channel model for a long-range ground-to-air FSO link under the assumption of plane wave optical beam profile at the receiver is derived. Particularly, the model includes the combined effects of transmitter divergence angle, random wobbling of the receiver, jitter due to beam wander, attenuation loss, and atmospheric turbulence. Furthermore, a closed-form expression for the outage probability of the considered link is derived which makes it possible to evaluate the performance of such systems. Numerical results are then provided to corroborate the accuracy of the proposed analytical expressions and to prove the superiority of the proposed channel model over the previous models in long-range aerial FSO links.      
### 33.Robust Model Predictive Path Integral Control: Analysis and Performance Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2102.09027.pdf)
>  In this paper we propose a novel decision making architecture for Robust Model Predictive Path Integral control (RMPPI) and investigate its performance guarantees and applicability to off-road navigation. Key building blocks of the proposed architecture are an augmented state space representation of the system consisting of nominal and actual dynamics, a placeholder for different types of tracking controllers, a safety logic for nominal state propagation, and an importance sampling scheme that takes into account the capabilities of the underlying tracking control. Using these ingredients, we derive a bound on the free energy growth of the dynamical system which is a function of task constraint satisfaction level, the performance of the underlying tracking controller, and the sampling error of the stochastic optimization used within RMPPI. To validate the bound on free energy growth, we perform experiments in simulation using two types of tracking controllers, namely the iterative Linear Quadratic Gaussian and Contraction-Metric based control. We further demonstrate the applicability of RMPPI in real hardware using the GT AutoRally vehicle. Our experiments demonstrate that RMPPI outperforms MPPI and Tube-MPPI by alleviating issues of the aforementioned model predictive controllers related to either lack of robustness or excessive conservatism. RMPPI provides the best of the two worlds in terms of agility and robustness to disturbances.      
### 34.Coordinated Receding-Horizon Control of Battery Electric Vehicle Speed and Gearshift Using Relaxed Mixed Integer Nonlinear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2102.09014.pdf)
>  In this paper, we propose an approach to coordinated receding-horizon control of vehicle speed and transmission gearshift for automated battery electric vehicles (BEVs) to achieve improved energy efficiency. The introduction of multi-speed transmissions in BEVs creates an opportunity to manipulate the operating point of electric motors under given vehicle speed and acceleration command, thus providing the potential to further improve the energy efficiency. However, co-optimization of vehicle speed and transmission gearshift leads to a mixed integer nonlinear program (MINLP), solving which can be computationally very challenging. In this paper, we propose a novel continuous relaxation technique to treat such MINLPs that makes it possible to compute solutions with conventional nonlinear programming solvers. After analyzing its theoretical properties, we use it to solve the optimization problem involved in coordinated receding-horizon control of BEV speed and gearshift. Through simulation studies, we show that co-optimizing vehicle speed and transmission gearshift can achieve considerably greater energy efficiency than optimizing them sequentially, and the proposed relaxation technique can reduce the online computational cost to a level that is comparable to the time available for real-time implementation.      
### 35.RFI Mitigation for One-bit UWB Radar Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.08987.pdf)
>  Radio frequency interference (RFI) mitigation is critical to the proper operation of ultra-wideband (UWB) radar systems since RFI can severely degrade the radar imaging capability and target detection performance. In this paper, we address the RFI mitigation problem for one-bit UWB radar systems. A one-bit UWB system obtains its signed measurements via a low-cost and high rate sampling scheme, referred to as the Continuous Time Binary Value (CTBV) technology. This sampling strategy compares the signal to a known threshold varying with slow-time and therefore can be used to achieve a rather high sampling rate and quantization resolution with rather simple and affordable hardware. This paper establishes a proper data model for the RFI sources and proposes a novel RFI mitigation method for the one-bit UWB radar system that uses the CTBV sampling technique. Specifically, we first model the RFI sources as a sum of sinusoids with frequencies fixed during the coherent processing interval (CPI) and we exploit the sparsity of the RFI spectrum. We extend a majorization-minimization based 1bRELAX algorithm, referred to as 1bMMRELAX, to estimate the RFI source parameters from the signed measurements obtained by using the CTBV sampling strategy. We also devise a new fast frequency initialization method based on the Alternating Direction Method of Multipliers (ADMM) methodology for the extended 1bMMRELAX algorithm to significantly improve its computational efficiency. Moreover, an ADMM-based sparse method is introduced to recover the desired radar echoes using the estimated RFI parameters. Both simulated and experimental results are presented to demonstrate that our proposed algorithm outperforms the existing digital integration method, especially for severe RFI cases.      
### 36.EEG-based Texture Roughness Classification in Active Tactile Exploration with Invariant Representation Learning Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.08976.pdf)
>  During daily activities, humans use their hands to grasp surrounding objects and perceive sensory information which are also employed for perceptual and motor goals. Multiple cortical brain regions are known to be responsible for sensory recognition, perception and motor execution during sensorimotor processing. While various research studies particularly focus on the domain of human sensorimotor control, the relation and processing between motor execution and sensory processing is not yet fully understood. Main goal of our work is to discriminate textured surfaces varying in their roughness levels during active tactile exploration using simultaneously recorded electroencephalogram (EEG) data, while minimizing the variance of distinct motor exploration movement patterns. We perform an experimental study with eight healthy participants who were instructed to use the tip of their dominant hand index finger while rubbing or tapping three different textured surfaces with varying levels of roughness. We use an adversarial invariant representation learning neural network architecture that performs EEG-based classification of different textured surfaces, while simultaneously minimizing the discriminability of motor movement conditions (i.e., rub or tap). Results show that the proposed approach can discriminate between three different textured surfaces with accuracies up to 70%, while suppressing movement related variability from learned representations.      
### 37.Domain Adaptation for Medical Image Analysis: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2102.09508.pdf)
>  Machine learning techniques used in computer-aided medical image analysis usually suffer from the domain shift problem caused by different distributions between source/reference data and target data. As a promising solution, domain adaptation has attracted considerable attention in recent years. The aim of this paper is to survey the recent advances of domain adaptation methods in medical image analysis. We first present the motivation of introducing domain adaptation techniques to tackle domain heterogeneity issues for medical image analysis. Then we provide a review of recent domain adaptation models in various medical image analysis tasks. We categorize the existing methods into shallow and deep models, and each of them is further divided into supervised, semi-supervised and unsupervised methods. We also provide a brief summary of the benchmark medical image datasets that support current domain adaptation research. This survey will enable researchers to gain a better understanding of the current status, challenges.      
### 38.Gifsplanation via Latent Shift: A Simple Autoencoder Approach to Progressive Exaggeration on Chest X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2102.09475.pdf)
>  Motivation: Traditional image attribution methods struggle to satisfactorily explain predictions of neural networks. Prediction explanation is important, especially in the medical imaging, for avoiding the unintended consequences of deploying AI systems when false positive predictions can impact patient care. Thus, there is a pressing need to develop improved models for model explainability and introspection. <br>Specific Problem: A new approach is to transform input images to increase or decrease features which cause the prediction. However, current approaches are difficult to implement as they are monolithic or rely on GANs. These hurdles prevent wide adoption. <br>Our approach: Given an arbitrary classifier, we propose a simple autoencoder and gradient update (Latent Shift) that can transform the latent representation of an input image to exaggerate or curtail the features used for prediction. We use this method to study chest X-ray classifiers and evaluate their performance. We conduct a reader study with two radiologists assessing 240 chest X-ray predictions to identify which ones are false positives (half are) using traditional attribution maps or our proposed method. <br>Results: We found low overlap with ground truth pathology masks for models with reasonably high accuracy. However, the results from our reader study indicate that these models are generally looking at the correct features. We also found that the Latent Shift explanation allows a user to have more confidence in true positive predictions compared to traditional approaches (0.15$\pm$0.95 in a 5 point scale with p=0.01) with only a small increase in false positive predictions (0.04$\pm$1.06 with p=0.57). <br>Accompanying webpage: <a class="link-external link-https" href="https://mlmed.org/gifsplanation" rel="external noopener nofollow">this https URL</a> <br>Source code: <a class="link-external link-https" href="https://github.com/mlmed/gifsplanation" rel="external noopener nofollow">this https URL</a>      
### 39.A Reinforcement learning method for Optical Thin-Film Design  [ :arrow_down: ](https://arxiv.org/pdf/2102.09398.pdf)
>  Machine learning, especially deep learning, is dramatically changing the methods associated with optical thin-film inverse design. The vast majority of this research has focused on the parameter optimization (layer thickness, and structure size) of optical thin-films. A challenging problem that arises is an automated material search. In this work, we propose a new end-to-end algorithm for optical thin-film inverse design. This method combines the ability of unsupervised learning, reinforcement learning(RL) and includes a genetic algorithm to design an optical thin-film without any human intervention. Furthermore, with several concrete examples, we have shown how one can use this technique to optimize the spectra of a multi-layer solar absorber device.      
### 40.A Comprehensive Review of Deep Learning-based Single Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2102.09351.pdf)
>  Image super-resolution (SR) is one of the vital image processing methods that improve the resolution of an image in the field of computer vision. In the last two decades, significant progress has been made in the field of super-resolution, especially utilizing deep learning methods. This survey is an effort to provide a detailed survey of recent progress in the field of super-resolution in the perspective of deep learning while also informing about the initial classical methods used for achieving super-resolution. The survey classifies the image SR methods into four categories, i.e., classical methods, supervised learning-based methods, unsupervised learning-based methods, and domain-specific SR methods. We also introduce the problem of SR to provide intuition about image quality metrics, available reference datasets, and SR challenges. Deep learning-based approaches of SR are evaluated using a reference dataset. Finally, this survey is concluded with future directions and trends in the field of SR and open problems in SR to be addressed by the researchers.      
### 41.A two-layer model for coevolving opinion dynamics and collective decision-making in complex social systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09285.pdf)
>  Motivated by the literature on opinion dynamics and evolutionary game theory, we propose a novel mathematical framework to model the intertwined coevolution of opinions and decision-making in a complex social system. In the proposed framework, the members of a social community update their opinions and revise their actions as they learn of others' opinions shared on a communication channel, and observe of others' actions through an influence channel; these interactions determine a two-layer network structure. We offer an application of the proposed framework by tailoring it to study the adoption of a novel social norm, demonstrating that the model is able to capture the emergence of several real-world collective phenomena such as paradigm shifts and unpopular norms. Through the establishment of analytical conditions and Monte Carlo numerical simulations, we shed light on the role of the coupling between opinion dynamics and decision-making, and of the network structure, in shaping the emergence of complex collective behavior in social systems.      
### 42.Reduced-Order Neural Network Synthesis with Robustness Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2102.09284.pdf)
>  In the wake of the explosive growth in smartphones and cyberphysical systems, there has been an accelerating shift in how data is generated away from centralised data towards on-device generated data. In response, machine learning algorithms are being adapted to run locally on board, potentially hardware limited, devices to improve user privacy, reduce latency and be more energy efficient. However, our understanding of how these device orientated algorithms behave and should be trained is still fairly limited. To address this issue, a method to automatically synthesize reduced-order neural networks (having fewer neurons) approximating the input/output mapping of a larger one is introduced. The reduced-order neural network's weights and biases are generated from a convex semi-definite programme that minimises the worst-case approximation error with respect to the larger network. Worst-case bounds for this approximation error are obtained and the approach can be applied to a wide variety of neural networks architectures. What differentiates the proposed approach to existing methods for generating small neural networks, e.g. pruning, is the inclusion of the worst-case approximation error directly within the training cost function, which should add robustness. Numerical examples highlight the potential of the proposed approach. The overriding goal of this paper is to generalise recent results in the robustness analysis of neural networks to a robust synthesis problem for their weights and biases.      
### 43.DINO: A Conditional Energy-Based GAN for Domain Translation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09281.pdf)
>  Domain translation is the process of transforming data from one domain to another while preserving the common semantics. Some of the most popular domain translation systems are based on conditional generative adversarial networks, which use source domain data to drive the generator and as an input to the discriminator. However, this approach does not enforce the preservation of shared semantics since the conditional input can often be ignored by the discriminator. We propose an alternative method for conditioning and present a new framework, where two networks are simultaneously trained, in a supervised manner, to perform domain translation in opposite directions. Our method is not only better at capturing the shared information between two domains but is more generic and can be applied to a broader range of problems. The proposed framework performs well even in challenging cross-modal translations, such as video-driven speech reconstruction, for which other systems struggle to maintain correspondence.      
### 44.Low Resource Audio-to-Lyrics Alignment From Polyphonic Music Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2102.09202.pdf)
>  Lyrics alignment in long music recordings can be memory exhaustive when performed in a single pass. In this study, we present a novel method that performs audio-to-lyrics alignment with a low memory consumption footprint regardless of the duration of the music recording. The proposed system first spots the anchoring words within the audio signal. With respect to these anchors, the recording is then segmented and a second-pass alignment is performed to obtain the word timings. We show that our audio-to-lyrics alignment system performs competitively with the state-of-the-art, while requiring much less computational resources. In addition, we utilise our lyrics alignment system to segment the music recordings into sentence-level chunks. Notably on the segmented recordings, we report the lyrics transcription scores on a number of benchmark test sets. Finally, our experiments highlight the importance of the source separation step for good performance on the transcription and alignment tasks. For reproducibility, we publicly share our code with the research community.      
### 45.Minimizing false negative rate in melanoma detection and providing insight into the causes of classification  [ :arrow_down: ](https://arxiv.org/pdf/2102.09199.pdf)
>  Our goal is to bridge human and machine intelligence in melanoma detection. We develop a classification system exploiting a combination of visual pre-processing, deep learning, and ensembling for providing explanations to experts and to minimize false negative rate while maintaining high accuracy in melanoma detection. Source images are first automatically segmented using a U-net CNN. The result of the segmentation is then used to extract image sub-areas and specific parameters relevant in human evaluation, namely center, border, and asymmetry measures. These data are then processed by tailored neural networks which include structure searching algorithms. Partial results are then ensembled by a committee machine. Our evaluation on the largest skin lesion dataset which is publicly available today, ISIC-2019, shows improvement in all evaluated metrics over a baseline using the original images only. We also showed that indicative scores computed by the feature classifiers can provide useful insight into the various features on which the decision can be based.      
### 46.Edge Sparse Basis Network: An Deep Learning Framework for EEG Source Localization  [ :arrow_down: ](https://arxiv.org/pdf/2102.09188.pdf)
>  EEG source localization is an important technical issue in EEG analysis. Despite many numerical methods existed for EEG source localization, they all rely on strong priors and the deep sources are intractable. Here we propose a deep learning framework using spatial basis function decomposition for EEG source localization. This framework combines the edge sparsity prior and Gaussian source basis, called Edge Sparse Basis Network (ESBN). The performance of ESBN is validated by both synthetic data and real EEG data during motor tasks. The results suggest that the supervised ESBN outperforms the traditional numerical methods in synthetic data and the unsupervised fine-tuning provides more focal and accurate localizations in real data. Our proposed deep learning framework can be extended to account for other source priors, and the real-time property of ESBN can facilitate the applications of EEG in brain-computer interfaces and clinics.      
### 47.Closing the Closed-Loop Distribution Shift in Safe Imitation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.09161.pdf)
>  Commonly used optimization-based control strategies such as model-predictive and control Lyapunov/barrier function based controllers often enjoy provable stability, robustness, and safety properties. However, implementing such approaches requires solving optimization problems online at high-frequencies, which may not be possible on resource-constrained commodity hardware. Furthermore, how to extend the safety guarantees of such approaches to systems that use rich perceptual sensing modalities, such as cameras, remains unclear. In this paper, we address this gap by treating safe optimization-based control strategies as experts in an imitation learning problem, and train a learned policy that can be cheaply evaluated at run-time and that provably satisfies the same safety guarantees as the expert. In particular, we propose Constrained Mixing Iterative Learning (CMILe), a novel on-policy robust imitation learning algorithm that integrates ideas from stochastic mixing iterative learning, constrained policy optimization, and nonlinear robust control. Our approach allows us to control errors introduced by both the learning task of imitating an expert and by the distribution shift inherent to deviating from the original expert policy. The value of using tools from nonlinear robust control to impose stability constraints on learned policies is shown through sample-complexity bounds that are independent of the task time-horizon. We demonstrate the usefulness of CMILe through extensive experiments, including training a provably safe perception-based controller using a state-feedback-based expert.      
### 48.Can Massive MIMO Support URLLC?  [ :arrow_down: ](https://arxiv.org/pdf/2102.09156.pdf)
>  We investigate the feasibility of using Massive MIMO to support URLLC in both coherence interval based and 3GPP compliant pilot settings. We consider grant-free uplink transmission with MMSE receiver and adopt 3GPP channel models. In the coherence interval based pilot setting, by extensive system level simulations, we find that using a Massive MIMO base station with 128 antennas and MMSE receiver, URLLC requirements can be achieved in Urban Macro (UMa) Non-Line of Sight (NLoS) with orthogonal pilots and Neyman-Pearson detector. However, in the 3GPP compliant pilot setting, even by using the covariance matrix of Physical Resource Block (PRB) subcarriers for active UE detection and channel estimation as well as open-loop power control, we find that URLLC requirements are still challenging to achieve due to the insufficient pilot length and pilot symbol location regulations in a PRB.      
### 49.Distributed Algorithms for Linearly-Solvable Optimal Control in Networked Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09104.pdf)
>  Distributed algorithms for both discrete-time and continuous-time linearly solvable optimal control (LSOC) problems of networked multi-agent systems (MASs) are investigated in this paper. A distributed framework is proposed to partition the optimal control problem of a networked MAS into several local optimal control problems in factorial subsystems, such that each (central) agent behaves optimally to minimize the joint cost function of a subsystem that comprises a central agent and its neighboring agents, and the local control actions (policies) only rely on the knowledge of local observations. Under this framework, we not only preserve the correlations between neighboring agents, but moderate the communication and computational complexities by decentralizing the sampling and computational processes over the network. For discrete-time systems modeled by Markov decision processes, the joint Bellman equation of each subsystem is transformed into a system of linear equations and solved using parallel programming. For continuous-time systems modeled by It diffusion processes, the joint optimality equation of each subsystem is converted into a linear partial differential equation, whose solution is approximated by a path integral formulation and a sample-efficient relative entropy policy search algorithm, respectively. The learned control policies are generalized to solve the unlearned tasks by resorting to the compositionality principle, and illustrative examples of cooperative UAV teams are provided to verify the effectiveness and advantages of these algorithms.      
### 50.Communication-free Cohesive Flexible-Object Transport using Decentralized Robot Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.09056.pdf)
>  Decentralized network theories focus on achieving consensus and in speeding up the rate of convergence to consensus. However, network cohesion (i.e., maintaining consensus) during transitions between consensus values is also important when transporting flexible structures. Deviations in the robot positions due to loss of cohesion when moving flexible structures from one position to another, such as uncuredcomposite aircraft wings, can cause large deformations, which in turn, can result in potential damage. The major contribution of this work is to develop a decentralized approach to transport flexible objects in a cohesive manner using local force measurements, without the need for additional communication between the robots. Additionally, stability conditions are developed for discrete-time implementation of the proposed cohesive transition approach, and experimental results are presented, which show that the proposed cohesive transportation approach can reduce the relative deformations by 85% when compared to the case without it.      
### 51.Joint Continuous and Discrete Model Selection via Submodularity  [ :arrow_down: ](https://arxiv.org/pdf/2102.09029.pdf)
>  In model selection problems for machine learning, the desire for a well-performing model with meaningful structure is typically expressed through a regularized optimization problem. In many scenarios, however, the meaningful structure is specified in some discrete space, leading to difficult nonconvex optimization problems. In this paper, we relate the model selection problem with structure-promoting regularizers to submodular function minimization defined with continuous and discrete arguments. In particular, we leverage submodularity theory to identify a class of these problems that can be solved exactly and efficiently with an agnostic combination of discrete and continuous optimization routines. We show how simple continuous or discrete constraints can also be handled for certain problem classes, motivated by robust optimization. Finally, we numerically validate our theoretical results with several proof-of-concept examples, comparing against state-of-the-art algorithms.      
### 52.Estimate Three-Phase Distribution Line Parameters With Physics-Informed Graphical Learning Method  [ :arrow_down: ](https://arxiv.org/pdf/2102.09023.pdf)
>  Accurate estimates of network parameters are essential for modeling, monitoring, and control in power distribution systems. In this paper, we develop a physics-informed graphical learning algorithm to estimate network parameters of three-phase power distribution systems. Our proposed algorithm uses only readily available smart meter data to estimate the three-phase series resistance and reactance of the primary distribution line segments. We first develop a parametric physics-based model to replace the black-box deep neural networks in the conventional graphical neural network (GNN). Then we derive the gradient of the loss function with respect to the network parameters and use stochastic gradient descent (SGD) to estimate the physical parameters. Prior knowledge of network parameters is also considered to further improve the accuracy of estimation. Comprehensive numerical study results show that our proposed algorithm yields high accuracy and outperforms existing methods.      
### 53.Power Minimization in Vehicular Cloud Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2102.09011.pdf)
>  Modern vehicles equipped with on-board units (OBU) are playing an essential role in the smart city revolution. The vehicular processing resources, however, are not used to their fullest potential. The concept of vehicular clouds is proposed to exploit the underutilized vehicular resources to supplement cloud computing services to relieve the burden on cloud data centers and improve quality of service. In this paper we introduce a vehicular cloud architecture supported by fixed edge computing nodes and the central cloud. A mixed integer linear programming (MLP) model is developed to optimize the allocation of the computing demands in the distributed architecture while minimizing power consumption. The results show power savings as high as 84% over processing in the conventional cloud. A heuristic with performance approaching that of the MILP model is developed to allocate computing demands in real time.      
### 54.Mobile Computational Photography: A Tour  [ :arrow_down: ](https://arxiv.org/pdf/2102.09000.pdf)
>  The first mobile camera phone was sold only 20 years ago, when taking pictures with one's phone was an oddity, and sharing pictures online was unheard of. Today, the smartphone is more camera than phone. How did this happen? This transformation was enabled by advances in computational photography -the science and engineering of making great images from small form factor, mobile cameras. Modern algorithmic and computing advances, including machine learning, have changed the rules of photography, bringing to it new modes of capture, post-processing, storage, and sharing. In this paper, we give a brief history of mobile computational photography and describe some of the key technological components, including burst photography, noise reduction, and super-resolution. At each step, we may draw naive parallels to the human visual system.      
### 55.Scanning the Cycle: Timing-based Authentication on PLCs  [ :arrow_down: ](https://arxiv.org/pdf/2102.08985.pdf)
>  Programmable Logic Controllers (PLCs) are a core component of an Industrial Control System (ICS). However, if a PLC is compromised or the commands sent across a network from the PLCs are spoofed, consequences could be catastrophic. In this work, a novel technique to authenticate PLCs is proposed that aims at raising the bar against powerful attackers while being compatible with real-time systems. The proposed technique captures timing information for each controller in a non-invasive manner. It is argued that Scan Cycle is a unique feature of a PLC that can be approximated passively by observing network traffic. An attacker that spoofs commands issued by the PLCs would deviate from such fingerprints. To detect replay attacks a PLC Watermarking technique is proposed. PLC Watermarking models the relationship between the scan cycle and the control logic by modeling the input/output as a function of request/response messages of a PLC. The proposed technique is validated on an operational water treatment plant (SWaT) and smart grid (EPIC) testbed. Results from experiments indicate that PLCs can be distinguished based on their scan cycle timing characteristics.      
