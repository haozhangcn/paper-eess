# ArXiv eess --Mon, 22 Nov 2021
### 1.Data-driven verification and synthesis of stochastic systems through barrier certificates  [ :arrow_down: ](https://arxiv.org/pdf/2111.10330.pdf)
>  In this work, we study verification and synthesis problems for safety specifications over unknown discrete-time stochastic systems. When a model of the system is available, barrier certificates have been successfully applied for ensuring the satisfaction of safety specifications. In this work, we formulate the computation of barrier certificates as a robust convex program (RCP). Solving the acquired RCP is hard in general because the model of the system that appears in one of the constraints of the RCP is unknown. We propose a data-driven approach that replaces the uncountable number of constraints in the RCP with a finite number of constraints by taking finitely many random samples from the trajectories of the system. We thus replace the original RCP with a scenario convex program (SCP) and show how to relate their optimizers. We guarantee that the solution of the SCP is a solution of the RCP with a priori guaranteed confidence when the number of samples is larger than a pre-computed value. This provides a lower bound on the safety probability of the original unknown system together with a controller in the case of synthesis. We also discuss an extension of our verification approach to a case where the associated robust program is non-convex and show how a similar methodology can be applied. Finally, the applicability of our proposed approach is illustrated through three case studies.      
### 2.Optimization of Quantized Phase Shifts for Reconfigurable Smart Surfaces Assisted Communications  [ :arrow_down: ](https://arxiv.org/pdf/2111.10319.pdf)
>  Reconfigurable Smart Surface (RSS) is assumed to be a key enabler for future wireless communication systems due to its ability to control the wireless propagation environment and, thus, enhance communications quality. Although optimal and continuous phase-shift configuration can be analytically obtained, practical RSS systems are prone to both channel estimation errors, discrete control, and curse of dimensionality. This leads to relaying on a finite number of phase-shift configurations that is expected to degrade the system's performances. In this paper, we tackle the problem of quantized RSS phase-shift configuration, aiming to maximize the data rate of an orthogonal frequency division multiplexing (OFDM) point-to-point RSS-assisted communication. Due to the complexity of optimally solving the formulated problem, we propose here a sub-optimal greedy algorithm to solve it. Simulation results illustrate the performance superiority of the proposed algorithm compared to baseline approaches. Finally, the impact of several parameters ,e.g., quantization resolution and RSS placement, is investigated.      
### 3.Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set  [ :arrow_down: ](https://arxiv.org/pdf/2111.10302.pdf)
>  We introduce a video compression algorithm based on instance-adaptive learning. On each video sequence to be transmitted, we finetune a pretrained compression model. The optimal parameters are transmitted to the receiver along with the latent code. By entropy-coding the parameter updates under a suitable mixture model prior, we ensure that the network parameters can be encoded efficiently. This instance-adaptive compression algorithm is agnostic about the choice of base model and has the potential to improve any neural video codec. On UVG, HEVC, and Xiph datasets, our codec improves the performance of a low-latency scale-space flow model by between 21% and 26% BD-rate savings, and that of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also demonstrate that instance-adaptive finetuning improves the robustness to domain shift. Finally, our approach reduces the capacity requirements on compression models. We show that it enables a state-of-the-art performance even after reducing the network size by 72%.      
### 4.A Risk-Managed Steady-State Analysis to Assess The Impact of Power Grid Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2111.10290.pdf)
>  Increased levels of randomness and variability are introducing new uncertainties into power systems that can impact system operability and reliability. Existing planning and operational methods for assessing operability and reliability are primarily deterministic, therefore, ill-suited to capture randomness and variability. This work proposes an approach to model, propagate, and measure the impact of uncertainties in power flow caused by stochastic grid resources. Using system sensitivities, statistical circuit analysis methods, and convex optimization, we demonstrate that we can accurately estimate the worst-case impact of stochastic resources on the health of a grid. We compare our method's performance to Monte Carlo analyses, and our results demonstrate an increase in efficiency of more than 2 to 3 orders of magnitude for the same probabilistic accuracy.      
### 5.Over-the-Air Federated Learning with Retransmissions (Extended Version)  [ :arrow_down: ](https://arxiv.org/pdf/2111.10267.pdf)
>  Motivated by increasing computational capabilities of wireless devices, as well as unprecedented levels of user- and device-generated data, new distributed machine learning (ML) methods have emerged. In the wireless community, Federated Learning (FL) is of particular interest due to its communication efficiency and its ability to deal with the problem of non-IID data. FL training can be accelerated by a wireless communication method called Over-the-Air Computation (AirComp) which harnesses the interference of simultaneous uplink transmissions to efficiently aggregate model updates. However, since AirComp utilizes analog communication, it introduces inevitable estimation errors. In this paper, we study the impact of such estimation errors on the convergence of FL and propose retransmissions as a method to improve FL convergence over resource-constrained wireless networks. First, we derive the optimal AirComp power control scheme with retransmissions over static channels. Then, we investigate the performance of Over-the-Air FL with retransmissions and find two upper bounds on the FL loss function. Finally, we propose a heuristic for selecting the optimal number of retransmissions, which can be calculated before training the ML model. Numerical results demonstrate that the introduction of retransmissions can lead to improved ML performance, without incurring extra costs in terms of communication or computation. Additionally, we provide simulation results on our heuristic which indicate that it can correctly identify the optimal number of retransmissions for different wireless network setups and machine learning problems.      
### 6.An Analysis of the Influence of Transfer Learning When Measuring the Tortuosity of Blood Vessels  [ :arrow_down: ](https://arxiv.org/pdf/2111.10255.pdf)
>  Characterizing blood vessels in digital images is important for the diagnosis of many types of diseases as well as for assisting current researches regarding vascular systems. The automated analysis of blood vessels typically requires the identification, or segmentation, of the blood vessels in an image or a set of images, which is usually a challenging task. Convolutional Neural Networks (CNNs) have been shown to provide excellent results regarding the segmentation of blood vessels. One important aspect of CNNs is that they can be trained on large amounts of data and then be made available, for instance, in image processing software for wide use. The pre-trained CNNs can then be easily applied in downstream blood vessel characterization tasks such as the calculation of the length, tortuosity, or caliber of the blood vessels. Yet, it is still unclear if pre-trained CNNs can provide robust, unbiased, results on downstream tasks when applied to datasets that they were not trained on. Here, we focus on measuring the tortuosity of blood vessels and investigate to which extent CNNs may provide biased tortuosity values even after fine-tuning the network to the new dataset under study. We show that the tortuosity values obtained by a CNN trained from scratch on a dataset may not agree with those obtained by a fine-tuned network that was pre-trained on a dataset having different tortuosity statistics. In addition, we show that the improvement in segmentation performance when fine-tuning the network does not necessarily lead to a respective improvement on the estimation of the tortuosity. To mitigate the aforementioned issues, we propose the application of specific data augmentation techniques even in situations where they do not improve segmentation performance.      
### 7.Learning-Based Repetitive Precision Motion Control with Mismatch Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10246.pdf)
>  Learning-based control methods utilize run-time data from the underlying process to improve the controller performance under model mismatch and unmodeled disturbances. This is beneficial for optimizing industrial processes, where the dynamics are difficult to model, and the repetitive nature of the process can be exploited. In this work, we develop an iterative approach for repetitive precision motion control problems where the objective is to follow a reference geometry with minimal tracking error. Our method utilizes a nominal model of the process and learns the mismatch using Gaussian Process Regression (GPR). The control input and the GPR data are updated after each iteration to improve the performance in a run-to-run fashion. We provide a preliminary convergence analysis, implementation details of the proposed controller for minimizing different error types, and a case study where we demonstrate improved tracking performance with simulation and experimental results.      
### 8.Benchmarks of Extended Basis Reachability Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2111.10218.pdf)
>  In this note, we want to provide a comparison among the efficiency of different approaches for the verification of K-step and infinite-step opacity based on three different graphs: the Extended Basis Reachability Graph (EBRG), the Basis Reachability Graph (BRG) when applicable, and the Reachability Graph (RG).      
### 9.Attention based end to end Speech Recognition for Voice Search in Hindi and English  [ :arrow_down: ](https://arxiv.org/pdf/2111.10208.pdf)
>  We describe here our work with automatic speech recognition (ASR) in the context of voice search functionality on the Flipkart e-Commerce platform. Starting with the deep learning architecture of Listen-Attend-Spell (LAS), we build upon and expand the model design and attention mechanisms to incorporate innovative approaches including multi-objective training, multi-pass training, and external rescoring using language models and phoneme based losses. We report a relative WER improvement of 15.7% on top of state-of-the-art LAS models using these modifications. Overall, we report an improvement of 36.9% over the phoneme-CTC system. The paper also provides an overview of different components that can be tuned in a LAS-based system.      
### 10.Comparative Study of Speech Analysis Methods to Predict Parkinson's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2111.10207.pdf)
>  One of the symptoms observed in the early stages of Parkinson's Disease (PD) is speech impairment. Speech disorders can be used to detect this disease before it degenerates. This work analyzes speech features and machine learning approaches to predict PD. Acoustic features such as shimmer and jitter variants, and Mel Frequency Cepstral Coefficients (MFCC) are extracted from speech signals. We use two datasets in this work: the MDVR-KCL and the Italian Parkinson's Voice and Speech database. To separate PD and non-PD speech signals, seven classification models were implemented: K-Nearest Neighbor, Decision Trees, Support Vector Machines, Naive Bayes, Logistic Regression, Gradient Boosting, Random Forests. Three feature sets were used for each of the models: (a) Acoustic features only, (b) All the acoustic features and MFCC, (c) Selected subset of features from acoustic features and MFCC. Using all the acoustic features and MFCC, together with SVM produced the highest performance with an accuracy of 98% and F1-Score of 99%. When compared with prior art, this shows a better performance. Our code and related documentation is available in a public domain repository.      
### 11.Multimodal Emotion Recognition with High-level Speech and Text Features  [ :arrow_down: ](https://arxiv.org/pdf/2111.10202.pdf)
>  Automatic emotion recognition is one of the central concerns of the Human-Computer Interaction field as it can bridge the gap between humans and machines. Current works train deep learning models on low-level data representations to solve the emotion recognition task. Since emotion datasets often have a limited amount of data, these approaches may suffer from overfitting, and they may learn based on superficial cues. To address these issues, we propose a novel cross-representation speech model, inspired by disentanglement representation learning, to perform emotion recognition on wav2vec 2.0 speech features. We also train a CNN-based model to recognize emotions from text features extracted with Transformer-based models. We further combine the speech-based and text-based results with a score fusion approach. Our method is evaluated on the IEMOCAP dataset in a 4-class classification problem, and it surpasses current works on speech-only, text-only, and multimodal emotion recognition.      
### 12.Backstepping-based Integral Sliding Mode Control with Time Delay Estimation for Autonomous Underwater Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2111.10179.pdf)
>  The aim of this paper is to propose a high performance control approach for trajectory tracking of Autonomous Underwater Vehicles (AUVs). However, the controller performance can be affected by the unknown perturbations including model uncertainties and external time-varying disturbances in an undersea environment. To address this problem, a Backstepping-based Integral Sliding Mode Control with Time Delay Estimation (BS-ISMC-TDE) is designed. To improve the performance of a conventional backstepping control algorithm, an Integral Sliding Mode Control (ISMC) approach is adopted in the backstepping design to attenuate the steady-state error. Moreover, an adaptive Time Delay Estimation (TDE) strategy is proposed to provide an estimation of perturbations by observing the inputs and the states of the AUV one step into the past without an exact knowledge of the dynamics and the upper bound of uncertainties. From the simulation results, it is shown that the proposed control approach using both adaptive and conventional TDE parts outperforms a Backstepping-based Integral Sliding Mode Control (BS-ISMC).      
### 13.Integrated Sensing and Communications for V2I Networks: Dynamic Predictive Beamforming for Extended Vehicle Targets  [ :arrow_down: ](https://arxiv.org/pdf/2111.10152.pdf)
>  We investigate sensing-assisted predictive beamforming schemes for vehicle-to-infrastructure (V2I) communication by exploiting the integrated sensing and communication (ISAC) functionalities at the roadside unit (RSU). The RSU deploys a massive multi-input-multi-output (mMIMO) array and operates at millimeter wave (mmWave) frequencies. The pencil-sharp mMIMO beams and fine range resolution achieved at mmWave, implicates that the point target assumption is impractical in such V2I networks, as the volume and shape of the vehicles become essential for beamforming. Simply pointing a beam to the vehicle may result in the communication receiver (CR) never lying in the beam, even when the vehicle's trajectory is accurately tracked. To tackle this problem, we consider the extended vehicle target with two novel beam tracking schemes. For the first scheme, the beamwidth is adjusted in real-time to cover the entire vehicle, followed by an extended Kalman filtering (EKF) algorithm to predict and track the position of CR according to the resolved high-resolution scatterers. An upgraded scheme is further proposed by splitting each transmission block into two stages. The first stage is exploited for ISAC transmission, where a wide beam is adopted for both communication and sensing. Based on the sensed results at the first stage, the second stage is dedicated to communication by adopting a pencil-sharp beam, yielding a significant improvement of the achievable rate. We further reveal the inherent tradeoff between the two stages in terms of their durations, and develop an optimal time allocation strategy that maximizes the average achievable rate. Finally, numerical results are provided to verify the superiorities of proposed schemes over the state-of-the-art methods.      
### 14.A Semi-Distributed Interior Point Algorithm for Optimal Coordination of Automated Vehicles at Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2111.10125.pdf)
>  In this paper, we consider the optimal coordination of automated vehicles at intersections under fixed crossing orders. We formulate the problem using direct optimal control and exploit the structure to construct a semi-distributed primal-dual interior-point algorithm to solve it by parallelizing most of the computations. Differently from standard distributed optimization algorithms, where the optimization problem is split, in our approach we split the linear algebra steps, such that the algorithm takes the same steps as a fully centralized one, while still performing computations in a distributed fashion. We analyze the communication requirements of the algorithm, and propose an approximation scheme which can significantly reduce the data exchange. We demonstrate the effectiveness of the algorithm in hard but realistic scenarios, which show that the approximation leads to reductions in communicated data of almost 99\% of the exact formulation, at the expense of less than 1\% suboptimality.      
### 15.Fast Spatio-temporal Compression of Dynamic 3D Meshes  [ :arrow_down: ](https://arxiv.org/pdf/2111.10105.pdf)
>  3D representations of highly deformable 3D models, such as dynamic 3D meshes, have recently become very popular due to their wide applicability in various domains. This trend inevitably leads to a demand for storage and transmission of voluminous data sets, making the need for the design of a robust and reliable compression scheme a necessity. In this work, we present an approach for dynamic 3D mesh compression, that effectively exploits the spatio-temporal coherence of animated sequences, achieving low compression ratios without noticeably affecting the visual quality of the animation. We show that, on contrary to mainstream approaches that either exploit spatial (e.g., spectral coding) or temporal redundancies (e.g., PCA-based method), the proposed scheme, achieves increased efficiency, by projecting the differential coordinates sequence to the subspace of the covariance of the point trajectories. An extensive evaluation study, using different dynamic 3D models, highlights the benefits of the proposed approach in terms of both execution time and reconstruction quality, providing extremely low bit-per-vertex per-frame (bpvf) rates.      
### 16.Varifocal Multiview Images: Capturing and Visual Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2111.10099.pdf)
>  Multiview images have flexible field of view (FoV) but inflexible depth of field (DoF). To overcome the limitation of multiview images on visual tasks, in this paper, we present varifocal multiview (VFMV) images with flexible DoF. VFMV images are captured by focusing a scene on distinct depths by varying focal planes, and each view only focused on one single plane.Therefore, VFMV images contain more information in focal dimension than multiview images, and can provide a rich representation for 3D scene by considering both FoV and DoF. The characteristics of VFMV images are useful for visual tasks to achieve high quality scene representation. Two experiments are conducted to validate the advantages of VFMV images in 4D light field feature detection and 3D reconstruction. Experiment results show that VFMV images can detect more light field features and achieve higher reconstruction quality due to informative focus cues. This work demonstrates that VFMV images have definite advantages over multiview images in visual tasks.      
### 17.Beamforming using Digital Piezoelectric MEMS Microphone Array  [ :arrow_down: ](https://arxiv.org/pdf/2111.10087.pdf)
>  The recent explosion in low-cost, low-power wireless microcontrollers, coupled with low-power, robust MEMS sensors has opened up the opportunity to create new forms of low-cost Industrial Internet-of-Things (IIoT) devices for condition monitoring. Piezoelectric MEMS microphones constructed with a cantilever diaphragm are a potential solution against failure modes, such as water and dust ingress, that have challenged the use of capacitive MEMS microphones in industrial applications. In this paper, we couple a pair of piezoelectric MEMS microphones to a COTS microcontroller to create a stand-alone microphone array capable of discerning the direction of a noise source. The microphone array is designed to acquire sound data without aliasing at frequencies of 2000 Hz or below. Testing is conducted in an anechoic chamber. We compare the performance of this microphone array to a simple idealized theoretical model. The experimental results obtained in the anechoic chamber compare well with the theoretical model. The work stands as a proof-of-principle. By providing detailed information on how we coupled the sensors to a COTS microcontroller, and the open-source code used to process the data, we hope that others will be able to build upon this work by expanding on both the number and type of sensors used.      
### 18.Semi-supervised transfer learning for language expansion of end-to-end speech recognition models to low-resource languages  [ :arrow_down: ](https://arxiv.org/pdf/2111.10047.pdf)
>  In this paper, we propose a three-stage training methodology to improve the speech recognition accuracy of low-resource languages. We explore and propose an effective combination of techniques such as transfer learning, encoder freezing, data augmentation using Text-To-Speech (TTS), and Semi-Supervised Learning (SSL). To improve the accuracy of a low-resource Italian ASR, we leverage a well-trained English model, unlabeled text corpus, and unlabeled audio corpus using transfer learning, TTS augmentation, and SSL respectively. In the first stage, we use transfer learning from a well-trained English model. This primarily helps in learning the acoustic information from a resource-rich language. This stage achieves around 24% relative Word Error Rate (WER) reduction over the baseline. In stage two, We utilize unlabeled text data via TTS data-augmentation to incorporate language information into the model. We also explore freezing the acoustic encoder at this stage. TTS data augmentation helps us further reduce the WER by ~ 21% relatively. Finally, In stage three we reduce the WER by another 4% relative by using SSL from unlabeled audio data. Overall, our two-pass speech recognition system with a Monotonic Chunkwise Attention (MoChA) in the first pass and a full-attention in the second pass achieves a WER reduction of ~ 42% relative to the baseline.      
### 19.A comparison of streaming models and data augmentation methods for robust speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.10043.pdf)
>  In this paper, we present a comparative study on the robustness of two different online streaming speech recognition models: Monotonic Chunkwise Attention (MoChA) and Recurrent Neural Network-Transducer (RNN-T). We explore three recently proposed data augmentation techniques, namely, multi-conditioned training using an acoustic simulator, Vocal Tract Length Perturbation (VTLP) for speaker variability, and SpecAugment. Experimental results show that unidirectional models are in general more sensitive to noisy examples in the training set. It is observed that the final performance of the model depends on the proportion of training examples processed by data augmentation techniques. MoChA models generally perform better than RNN-T models. However, we observe that training of MoChA models seems to be more sensitive to various factors such as the characteristics of training sets and the incorporation of additional augmentations techniques. On the other hand, RNN-T models perform better than MoChA models in terms of latency, inference time, and the stability of training. Additionally, RNN-T models are generally more robust against noise and reverberation. All these advantages make RNN-T models a better choice for streaming on-device speech recognition compared to MoChA models.      
### 20.Modeling Flash Memory Channels Using Conditional Generative Nets  [ :arrow_down: ](https://arxiv.org/pdf/2111.10039.pdf)
>  Understanding the NAND flash memory channel has become more and more challenging due to the continually increasing density and the complex distortions arising from the write and read mechanisms. In this work, we propose a data-driven generative modeling method to characterize the flash memory channel. The learned model can reconstruct the read voltage from an individual memory cell based on the program levels of the cell and its surrounding array of cells. Experimental results show that the statistical distribution of the reconstructed read voltages accurately reflects the measured distribution on a commercial flash memory chip, both qualitatively and as quantified by the total variation distance. Moreover, we observe that the learned model can capture precise inter-cell interference (ICI) effects, as verified by comparison of the error probabilities of specific patterns in wordlines and bitlines.      
### 21.Novel Real-Time EMT-TS Modeling Architecture for Feeder Blackstart Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2111.10031.pdf)
>  This paper presents the development and benchmarking of a novel real-time electromagnetic-transient and transient-stability (EMT-TS) modeling architecture for distribution feeder restoration studies. The work presents for the first time in the literature a real-time EMT-TS testbed in which the grid-forming unit is simulated in EMT domain, operating as the slack bus of the phasor domain while including unbalanced voltage conditions. To evaluate the performance and limitations of the proposed model, an equivalent EMT testbed is developed to serve as a benchmark. First, the co-simulation framework and the domain coupling methodology are introduced. Next, the steady-state operation of the EMT-TS and EMT models are matched. Then, tests are conducted to analyze the transient performance of the proposed EMT-TS model when compared to its EMT benchmark. Results reveal that when utilizing a battery energy storage system (BESS) as the grid-forming unit, the EMT-TS testbed can maintain high accuracy for typical load steps.      
### 22.IC-U-Net: A U-Net-based Denoising Autoencoder Using Mixtures of Independent Components for Automatic EEG Artifact Removal  [ :arrow_down: ](https://arxiv.org/pdf/2111.10026.pdf)
>  Electroencephalography (EEG) signals are often contaminated with artifacts. It is imperative to develop a practical and reliable artifact removal method to prevent misinterpretations of neural signals and underperformance of brain-computer interfaces. This study developed a new artifact removal method, IC-U-Net, which is based on the U-Net architecture for removing pervasive EEG artifacts and reconstructing brain sources. The IC-U-Net was trained using mixtures of brain and non-brain sources decomposed by independent component analysis and employed an ensemble of loss functions to model complex signal fluctuations in EEG recordings. The effectiveness of the proposed method in recovering brain sources and removing various artifacts (e.g., eye blinks/movements, muscle activities, and line/channel noises) was demonstrated in a simulation study and three real-world EEG datasets collected at rest and while driving and walking. IC-U-Net is user-friendly and publicly available, does not require parameter tuning or artifact type designations, and has no limitations on channel numbers. Given the increasing need to image natural brain dynamics in a mobile setting, IC-U-Net offers a promising end-to-end solution for automatically removing artifacts from EEG recordings.      
### 23.Concurrent Transmission and Multiuser Detection of LoRa Signals  [ :arrow_down: ](https://arxiv.org/pdf/2111.10022.pdf)
>  This paper investigates a new model to improve the scalability of low-power long-range (LoRa) networks by allowing multiple end devices (EDs) to simultaneously communicate with multiple multi-antenna gateways on the same frequency band and using the same spreading factor. The maximum likelihood (ML) decision rule is first derived for non-coherent detection of information bits transmitted by multiple devices. To overcome the high complexity of the ML detection, we propose a sub-optimal two-stage detection algorithm to balance the computational complexity and error performance. In the first stage, we identify transmit chirps (without knowing which EDs transmit them). In the second stage, we determine the EDs that transmit the specific chirps identified from the first stage. To improve the detection performance in the second stage, we also optimize the transmit powers of EDs to minimize the similarity, measured by the Jaccard coefficient, between the received powers of any pair of EDs. As the power control optimization problem is non-convex, we use concepts from successive convex approximation to transform it to an approximate convex optimization problem that can be solved iteratively and guaranteed to reach a sub-optimal solution. Simulation results demonstrate and justify the tradeoff between transmit power penalties and network scalability of the proposed LoRa network model. In particular, by allowing concurrent transmission of 2 or 3 EDs, the uplink capacity of the proposed network can be doubled or tripled over that of a conventional LoRa network, albeit at the expense of additional 3.0 or 4.7 dB transmit power.      
### 24.Image enhancement in acoustic-resolution photoacoustic microscopy enabled by a novel directional algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2111.10006.pdf)
>  Acoustic-resolution photoacoustic microscopy (AR-PAM) is a promising tool for microvascular imaging. In the focal region, resolution of AR-PAM is determined by the ultrasound transducer and ultimately limited by acoustic diffraction. In the out-of-focus region, resolution deteriorates with increasing distance from the focal plane, which restricts depth of focus (DOF). Besides, a trade-off exists between resolution and DOF. Previously, synthetic aperture focusing technique (SAFT) and/or deconvolution methods have been demonstrated to enhance AR-PAM images. However, they suffer from issues in low resolution, low signal-to-noise ratio (SNR), and/or poor image fidelity. Here, we propose a novel algorithm for AR-PAM to enhance image resolution, SNR, and fidelity. The algorithm consists of a Fourier accumulation SAFT (FA-SAFT) and a directional model-based (D-MB) deconvolution method. Inspired from Fourier denoising technique and directional SAFT, FA-SAFT mainly compensates for the defocusing effect. Besides, D-MB deconvolution enhances the resolution as well as preserves the image fidelity, especially for the objects with line patterns such as microvasculature. Full width at half maximum of 26-31 um over DOF of 1.8 mm and minimum resolvable distance of 46-49 um are experimentally achieved by imaging tungsten wire phantom. Moreover, imaging of leaf skeleton phantom and in vivo imaging of mouse blood vessels also prove that our algorithm is capable of providing high-resolution, high-SNR, and good-fidelity results for complex structures and for in vivo applications.      
### 25.Boost Distribution System Restoration with Emergency Communication Vehicles Considering Cyber-Physical Interdependence  [ :arrow_down: ](https://arxiv.org/pdf/2111.09986.pdf)
>  Enhancing restoration capabilities of distribution systems is one of the main strategies for resilient power systems to cope with extreme events. However, most of the existing studies assume the communication infrastructures are intact for distribution automation, which is unrealistic. Motivated by the applications of the emergency communication vehicles (ECVs) in quickly setting up wireless communication networks after disasters, in this paper, we propose an integrated distribution system restoration (DSR) framework and optimization models, which can coordinate the repair crews, the distribution system (physical sectors), and the emergency communication (cyber sectors) to pick up unserved customers as quickly as possible. Case studies validated the effectiveness of the proposed models and proved the benefit of considering ECVs and cyber-physical interdependencies in DSR.      
### 26.Towards Measuring Fairness in Speech Recognition: Casual Conversations Dataset Transcriptions  [ :arrow_down: ](https://arxiv.org/pdf/2111.09983.pdf)
>  It is well known that many machine learning systems demonstrate bias towards specific groups of individuals. This problem has been studied extensively in the Facial Recognition area, but much less so in Automatic Speech Recognition (ASR). This paper presents initial Speech Recognition results on "Casual Conversations" -- a publicly released 846 hour corpus designed to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of metadata, including age, gender, and skin tone. The entire corpus has been manually transcribed, allowing for detailed ASR evaluations across these metadata. Multiple ASR models are evaluated, including models trained on LibriSpeech, 14,000 hour transcribed, and over 2 million hour untranscribed social media videos. Significant differences in word error rate across gender and skin tone are observed at times for all models. We are releasing human transcripts from the Casual Conversations dataset to encourage the community to develop a variety of techniques to reduce these statistical biases.      
### 27.COVID-19 Detection on Chest X-Ray Images: A comparison of CNN architectures and ensembles  [ :arrow_down: ](https://arxiv.org/pdf/2111.09972.pdf)
>  COVID-19 quickly became a global pandemic after only four months of its first detection. It is crucial to detect this disease as soon as possible to decrease its spread. The use of chest X-ray (CXR) images became an effective screening strategy, complementary to the reverse transcription-polymerase chain reaction (RT-PCR). Convolutional neural networks (CNNs) are often used for automatic image classification and they can be very useful in CXR diagnostics. In this paper, 21 different CNN architectures are tested and compared in the task of identifying COVID-19 in CXR images. They were applied to the COVIDx8B dataset, which is the largest and more diverse COVID-19 dataset available. Ensembles of CNNs were also employed and they showed better efficacy than individual instances. The best individual CNN instance results were achieved by DenseNet169, with an accuracy of 98.15% and an F1 score of 98.12%. These were further increased to 99.25% and 99.24%, respectively, through an ensemble with five instances of DenseNet169. These results are higher than those obtained in recent works using the same dataset.      
### 28.Learning Robust Output Control Barrier Functions from Safe Expert Demonstrations  [ :arrow_down: ](https://arxiv.org/pdf/2111.09971.pdf)
>  This paper addresses learning safe control laws from expert demonstrations. We assume that appropriate models of the system dynamics and the output measurement map are available, along with corresponding error bounds. We first propose robust output control barrier functions (ROCBFs) as a means to guarantee safety, as defined through controlled forward invariance of a safe set. We then present an optimization problem to learn ROCBFs from expert demonstrations that exhibit safe system behavior, e.g., data collected from a human operator. Along with the optimization problem, we provide verifiable conditions that guarantee validity of the obtained ROCBF. These conditions are stated in terms of the density of the data and on Lipschitz and boundedness constants of the learned function and the models of the system dynamics and the output measurement map. When the parametrization of the ROCBF is linear, then, under mild assumptions, the optimization problem is convex. We validate our findings in the autonomous driving simulator CARLA and show how to learn safe control laws from RGB camera images.      
### 29.A Conformer-based ASR Frontend for Joint Acoustic Echo Cancellation, Speech Enhancement and Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2111.09935.pdf)
>  We present a frontend for improving robustness of automatic speech recognition (ASR), that jointly implements three modules within a single model: acoustic echo cancellation, speech enhancement, and speech separation. This is achieved by using a contextual enhancement neural network that can optionally make use of different types of side inputs: (1) a reference signal of the playback audio, which is necessary for echo cancellation; (2) a noise context, which is useful for speech enhancement; and (3) an embedding vector representing the voice characteristic of the target speaker of interest, which is not only critical in speech separation, but also helpful for echo cancellation and speech enhancement. We present detailed evaluations to show that the joint model performs almost as well as the task-specific models, and significantly reduces word error rate in noisy conditions even when using a large-scale state-of-the-art ASR model. Compared to the noisy baseline, the joint model reduces the word error rate in low signal-to-noise ratio conditions by at least 71% on our echo cancellation dataset, 10% on our noisy dataset, and 26% on our multi-speaker dataset. Compared to task-specific models, the joint model performs within 10% on our echo cancellation dataset, 2% on the noisy dataset, and 3% on the multi-speaker dataset.      
### 30.SLUE: New Benchmark Tasks for Spoken Language Understanding Evaluation on Natural Speech  [ :arrow_down: ](https://arxiv.org/pdf/2111.10367.pdf)
>  Progress in speech processing has been facilitated by shared datasets and benchmarks. Historically these have focused on automatic speech recognition (ASR), speaker identification, or other lower-level tasks. Interest has been growing in higher-level spoken language understanding tasks, including using end-to-end models, but there are fewer annotated datasets for such tasks. At the same time, recent work shows the possibility of pre-training generic representations and then fine-tuning for several tasks using relatively little labeled data. We propose to create a suite of benchmark tasks for Spoken Language Understanding Evaluation (SLUE) consisting of limited-size labeled training sets and corresponding evaluation sets. This resource would allow the research community to track progress, evaluate pre-trained representations for higher-level tasks, and study open questions such as the utility of pipeline versus end-to-end approaches. We present the first phase of the SLUE benchmark suite, consisting of named entity recognition, sentiment analysis, and ASR on the corresponding datasets. We focus on naturally produced (not read or synthesized) speech, and freely available datasets. We provide new transcriptions and annotations on subsets of the VoxCeleb and VoxPopuli datasets, evaluation metrics and results for baseline models, and an open-source toolkit to reproduce the baselines and evaluate new models.      
### 31.Joint Delay and Phase Precoding Under True-Time Delay Constraint for THz Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2111.10365.pdf)
>  A new approach is presented to the problem of compensating the beam squint effect arising in wideband terahertz (THz) hybrid massive multiple-input multiple-output (MIMO) systems, based on the joint optimization of the phase shifter (PS) and true-time delay (TTD) values under per-TTD device time delay constraints. Unlike the prior approaches, the new approach does not require the unbounded time delay assumption; the range of time delay values that a TTD device can produce is strictly limited in our approach. Instead of focusing on the design of TTD values, we jointly optimize both the TTD and PS values to effectively cope with the practical time delay constraint. Simulation results that illustrate the performance benefits of the new method for the beam squint compensation are presented. Through simulations and analysis, we show that our approach is a generalization of the prior TTD-based precoding approaches.      
### 32.Max-algebraic hybrid automata: Modelling and equivalences  [ :arrow_down: ](https://arxiv.org/pdf/2111.10318.pdf)
>  This article introduces the novel framework of max-algebraic hybrid automata as a hybrid modelling language in the max-plus algebra. We show that the modelling framework unifies and extends the switching max-plus linear systems framework and is analogous to the discrete hybrid automata framework in conventional algebra. In addition, we show that the framework serves as a bridge between automata-theoretic models in max-plus algebra and switching max-plus linear systems. In doing so, we formalise the relationship between max-plus automata and switching max-plus linear systems in a behavioural sense. This also serves as another step towards importing tools for analysis and optimal control from conventional time-driven hybrid systems to discrete-event systems in max-plus algebra.      
### 33.A 3D 2D convolutional Neural Network Model for Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.10293.pdf)
>  In the proposed SEHybridSN model, a dense block was used to reuse shallow feature and aimed at better exploiting hierarchical spatial spectral feature. Subsequent depth separable convolutional layers were used to discriminate the spatial information. Further refinement of spatial spectral features was realized by the channel attention method, which were performed behind every 3D convolutional layer and every 2D convolutional layer. Experiment results indicate that our proposed model learn more discriminative spatial spectral features using very few training data. SEHybridSN using only 0.05 and 0.01 labeled data for training, a very satisfactory performance is obtained.      
### 34.Interpreting deep urban sound classification using Layer-wise Relevance Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10235.pdf)
>  After constructing a deep neural network for urban sound classification, this work focuses on the sensitive application of assisting drivers suffering from hearing loss. As such, clear etiology justifying and interpreting model predictions comprise a strong requirement. To this end, we used two different representations of audio signals, i.e. Mel and constant-Q spectrograms, while the decisions made by the deep neural network are explained via layer-wise relevance propagation. At the same time, frequency content assigned with high relevance in both feature sets, indicates extremely discriminative information characterizing the present classification task. Overall, we present an explainable AI framework for understanding deep urban sound classification.      
### 35.Xp-GAN: Unsupervised Multi-object Controllable Video Generation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10233.pdf)
>  Video Generation is a relatively new and yet popular subject in machine learning due to its vast variety of potential applications and its numerous challenges. Current methods in Video Generation provide the user with little or no control over the exact specification of how the objects in the generate video are to be moved and located at each frame, that is, the user can't explicitly control how each object in the video should move. In this paper we propose a novel method that allows the user to move any number of objects of a single initial frame just by drawing bounding boxes over those objects and then moving those boxes in the desired path. Our model utilizes two Autoencoders to fully decompose the motion and content information in a video and achieves results comparable to well-known baseline and state of the art methods.      
### 36.Control-sharing Control Barrier Functions for Intersection Automation under Input Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2111.10205.pdf)
>  This contribution introduces a centralized input constrained optimal control framework based on multiple control barrier functions (CBFs) to coordinate connected and automated agents at intersections. For collision avoidance, we propose a novel CBF which is safe by construction. The given control scheme provides provable guarantees that collision avoidance CBFs and CBFs to constrain the agents' velocity are jointly feasible (referred to as control-sharing property) subject to input constraints. A simulation study finally provides evidence that the proposed control scheme is safe.      
### 37.Real-time Coherency Identification using a Window-Size-Based Recursive Typicality Data Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.10195.pdf)
>  This work presents a data-driven analysis of minimal length necessary for coherency detection considering a recursive form of the typicality-based Data analysis (TDA). It proposes a methodology that encloses the observation of the variance of the typicality ({\tau} ) to asses the minimal window length necessary to determine the coherent buses, where the properties of the TDA approach and the groups of buses are iteratively calculated at every new data point sampled. Once the variance of each group reaches a certain value, the minimal window length is determined. Besides, this method preserves the TDA characteristics of using exclusively measurements, not requiring pre-determination of number of groups, group centers or cut-off constants. The method is applied to the well know 2-area Kundur test system, allowing to corroborate its effectiveness and draw conclusions regarding minimal window length dependence on the slowest inter-area mode.      
### 38.Prosodic Clustering for Phoneme-level Prosody Control in End-to-End Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2111.10177.pdf)
>  This paper presents a method for controlling the prosody at the phoneme level in an autoregressive attention-based text-to-speech system. Instead of learning latent prosodic features with a variational framework as is commonly done, we directly extract phoneme-level F0 and duration features from the speech data in the training set. Each prosodic feature is discretized using unsupervised clustering in order to produce a sequence of prosodic labels for each utterance. This sequence is used in parallel to the phoneme sequence in order to condition the decoder with the utilization of a prosodic encoder and a corresponding attention module. Experimental results show that the proposed method retains the high quality of generated speech, while allowing phoneme-level control of F0 and duration. By replacing the F0 cluster centroids with musical notes, the model can also provide control over the note and octave within the range of the speaker.      
### 39.Word-Level Style Control for Expressive, Non-attentive Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2111.10173.pdf)
>  This paper presents an expressive speech synthesis architecture for modeling and controlling the speaking style at a word level. It attempts to learn word-level stylistic and prosodic representations of the speech data, with the aid of two encoders. The first one models style by finding a combination of style tokens for each word given the acoustic features, and the second outputs a word-level sequence conditioned only on the phonetic information in order to disentangle it from the style information. The two encoder outputs are aligned and concatenated with the phoneme encoder outputs and then decoded with a Non-Attentive Tacotron model. An extra prior encoder is used to predict the style tokens autoregressively, in order for the model to be able to run without a reference utterance. We find that the resulting model gives both word-level and global control over the style, as well as prosody transfer capabilities.      
### 40.Improved Prosodic Clustering for Multispeaker and Speaker-independent Phoneme-level Prosody Control  [ :arrow_down: ](https://arxiv.org/pdf/2111.10168.pdf)
>  This paper presents a method for phoneme-level prosody control of F0 and duration on a multispeaker text-to-speech setup, which is based on prosodic clustering. An autoregressive attention-based model is used, incorporating multispeaker architecture modules in parallel to a prosody encoder. Several improvements over the basic single-speaker method are proposed that increase the prosodic control range and coverage. More specifically we employ data augmentation, F0 normalization, balanced clustering for duration, and speaker-independent prosodic clustering. These modifications enable fine-grained phoneme-level prosody control for all speakers contained in the training set, while maintaining the speaker identity. The model is also fine-tuned to unseen speakers with limited amounts of data and it is shown to maintain its prosody control capabilities, verifying that the speaker-independent prosodic clustering is effective. Experimental results verify that the model maintains high output speech quality and that the proposed method allows efficient prosody control within each speaker's range despite the variability that a multispeaker setting introduces.      
### 41.Lattention: Lattice-attention in ASR rescoring  [ :arrow_down: ](https://arxiv.org/pdf/2111.10157.pdf)
>  Lattices form a compact representation of multiple hypotheses generated from an automatic speech recognition system and have been shown to improve performance of downstream tasks like spoken language understanding and speech translation, compared to using one-best hypothesis. In this work, we look into the effectiveness of lattice cues for rescoring n-best lists in second-pass. We encode lattices with a recurrent network and train an attention encoder-decoder model for n-best rescoring. The rescoring model with attention to lattices achieves 4-5% relative word error rate reduction over first-pass and 6-8% with attention to both lattices and acoustic features. We show that rescoring models with attention to lattices outperform models with attention to n-best hypotheses. We also study different ways to incorporate lattice weights in the lattice encoder and demonstrate their importance for n-best rescoring.      
### 42.IRONWAN: Increasing Reliability of Overlapping Networks in LoRaWAN  [ :arrow_down: ](https://arxiv.org/pdf/2111.10115.pdf)
>  LoRaWAN deployments follow an ad-hoc deployment model that has organically led to overlapping communication networks, sharing the wireless spectrum, and completely unaware of each other. LoRaWAN uses ALOHA-style communication where it is almost impossible to schedule transmission between networks belonging to different owners properly. The inability to schedule overlapping networks will cause inter-network interference, which will increase node-to-gateway message losses and gateway-to-node acknowledgement failures. This problem is likely to get worse as the number of LoRaWAN networks increase. In response to this problem, we propose IRONWAN, a wireless overlay network that shares communication resources without modifications to underlying protocols. It utilises the broadcast nature of radio communication and enables gateway-to-gateway communication to facilitate the search for failed messages and transmit failed acknowledgements already received and cached in overlapping network's gateways. IRONWAN uses two novel algorithms, a Real-time Message Inter-arrival Predictor, to highlight when a server has not received an expected uplink message. The Interference Predictor ensures that extra gateway-to-gateway communication does not negatively impact communication bandwidth. We evaluate IRONWAN on a 1000-node simulator with up to ten gateways and a 10-node testbed with 2-gateways. Results show that IRONWAN can achieve up to 12\% higher packet delivery ratio (PDR) and total messages received per node while increasing the minimum PDR by up to 28\%. These improvements save up to 50\% node's energy. Finally, we demonstrate that IRONWAN has comparable performance to an optimal solution (wired, centralised) but with 2-32 times lower communication costs. IRONWAN also has up to 14\% better PDR when compared to FLIP, a wired-distributed gateway-to-gateway protocol in certain scenarios.      
### 43.Noise-resistant reconstruction algorithm based on the sinogram pattern  [ :arrow_down: ](https://arxiv.org/pdf/2111.10067.pdf)
>  We introduce a new CT image reconstruction algorithm that is less affected by various artifacts. The new reconstruction algorithm is a method of minimizing the difference between synchrotron X-ray tomography data and sinograms generated using Radon transform of CT images. The CT image is iteratively updated to reduce the difference from the sinogram of the data. This method can obtain clean CT images from the projection data, which can create ring artifacts or metal artifacts. Also, even if the sample size is larger than the CCD and/or the projection image does not satisfy the Beer-Lambert law, a clean CT image can be reconstructed. Our new reconstruction algorithm can also be applied to fan beam CT or cone beam CT      
### 44.Assessment of Fetal and Maternal Well-Being During Pregnancy Using Passive Wearable Inertial Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2111.10066.pdf)
>  Assessing the health of both the fetus and mother is vital in preventing and identifying possible complications in pregnancy. This paper focuses on a device that can be used effectively by the mother herself with minimal supervision and provide a reasonable estimation of fetal and maternal health while being safe, comfortable, and easy to use. The device proposed uses a belt with a single accelerometer over the mother's uterus to record the required information. The device is expected to monitor both the mother and the fetus constantly over a long period and provide medical professionals with useful information, which they would otherwise overlook due to the low frequency that health monitoring is carried out at the present. The paper shows that simultaneous measurement of respiratory information of the mother and fetal movement is in fact possible even in the presence of mild interferences, which needs to be accounted for if the device is expected to be worn for extended times.      
### 45.Differentiable Wavetable Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2111.10003.pdf)
>  Differentiable Wavetable Synthesis (DWTS) is a technique for neural audio synthesis which learns a dictionary of one-period waveforms i.e. wavetables, through end-to-end training. We achieve high-fidelity audio synthesis with as little as 10 to 20 wavetables and demonstrate how a data-driven dictionary of waveforms opens up unprecedented one-shot learning paradigms on short audio clips. Notably, we show audio manipulations, such as high quality pitch-shifting, using only a few seconds of input audio. Lastly, we investigate performance gains from using learned wavetables for realtime and interactive audio synthesis.      
### 46.Esophageal virtual disease landscape using mechanics-informed machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.09993.pdf)
>  The pathogenesis of esophageal disorders is related to the esophageal wall mechanics. Therefore, to understand the underlying fundamental mechanisms behind various esophageal disorders, it is crucial to map the esophageal wall mechanics-based parameters onto physiological and pathophysiological conditions corresponding to altered bolus transit and supraphysiologic IBP. In this work, we present a hybrid framework that combines fluid mechanics and machine learning to identify the underlying physics of the various esophageal disorders and maps them onto a parameter space which we call the virtual disease landscape (VDL). A one-dimensional inverse model processes the output from an esophageal diagnostic device called endoscopic functional lumen imaging probe (EndoFLIP) to estimate the mechanical "health" of the esophagus by predicting a set of mechanics-based parameters such as esophageal wall stiffness, muscle contraction pattern and active relaxation of esophageal walls. The mechanics-based parameters were then used to train a neural network that consists of a variational autoencoder (VAE) that generates a latent space and a side network that predicts mechanical work metrics for estimating esophagogastric junction motility. The latent vectors along with a set of discrete mechanics-based parameters define the VDL and form clusters corresponding to the various esophageal disorders. The VDL not only distinguishes different disorders but can also be used to predict disease progression in time. Finally, we also demonstrate the clinical applicability of this framework for estimating the effectiveness of a treatment and track patient condition after a treatment.      
### 47.Second-Order Mirror Descent: Convergence in Games Beyond Averaging and Discounting  [ :arrow_down: ](https://arxiv.org/pdf/2111.09982.pdf)
>  In this paper, we propose a second-order extension of the continuous-time game-theoretic mirror descent (MD) dynamics, referred to as MD2, which converges to mere (but not necessarily strict) variationally stable states (VSS) without using common auxiliary techniques such as averaging or discounting. We show that MD2 enjoys no-regret as well as exponential rate of convergence towards a strong VSS upon a slight modification. Furthermore, MD2 can be used to derive many novel primal-space dynamics. Lastly, using stochastic approximation techniques, we provide a convergence guarantee of discrete-time MD2 with noisy observations towards interior mere VSS. Selected simulations are provided to illustrate our results.      
### 48.Predictive Scheduling of Collaborative Mobile Robots for Improved Crop-transport Logistics of Manually Harvested Crops  [ :arrow_down: ](https://arxiv.org/pdf/2111.09959.pdf)
>  Mechanizing the manual harvesting of fresh market fruits constitutes one of the biggest challenges to the sustainability of the fruit industry. During manual harvesting of some fresh-market crops like strawberries and table grapes, pickers spend significant amounts of time walking to carry full trays to a collection station at the edge of the field. A step toward increasing harvest automation for such crops is to deploy harvest-aid collaborative robots (co-bots) that transport the empty and full trays, thus increasing harvest efficiency by reducing pickers' non-productive walking times. This work presents the development of a co-robotic harvest-aid system and its evaluation during commercial strawberry harvesting. At the heart of the system lies a predictive stochastic scheduling algorithm that minimizes the expected non-picking time, thus maximizing the harvest efficiency. During the evaluation experiments, the co-robots improved the mean harvesting efficiency by around 10% and reduced the mean non-productive time by 60%, when the robot-to-picker ratio was 1:3. The concepts developed in this work can be applied to robotic harvest-aids for other manually harvested crops that involve walking for crop transportation.      
### 49.Rethink Dilated Convolution for Real-time Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.09957.pdf)
>  Recent advances in semantic segmentation generally adapt an ImageNet pretrained backbone with a special context module after it to quickly increase the field-of-view. Although successful, the backbone, in which most of the computation lies, does not have a large enough field-of-view to make the best decisions. Some recent advances tackle this problem by rapidly downsampling the resolution in the backbone while also having one or more parallel branches with higher resolutions. We take a different approach by designing a ResNeXt inspired block structure that uses two parallel 3x3 convolutional layers with different dilation rates to increase the field-of-view while also preserving the local details. By repeating this block structure in the backbone, we do not need to append any special context module after it. In addition, we propose a lightweight decoder that restores local information better than common alternatives. To demonstrate the effectiveness of our approach, our model RegSeg achieves state-of-the-art results on real-time Cityscapes and CamVid datasets. Using a T4 GPU with mixed precision, RegSeg achieves 78.3 mIOU on Cityscapes test set at 30 FPS, and 80.9 mIOU on CamVid test set at 70 FPS, both without ImageNet pretraining.      
### 50.DawDreamer: Bridging the Gap Between Digital Audio Workstations and Python Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2111.09931.pdf)
>  Audio production techniques which previously only existed in GUI-constrained digital audio workstations, livecoding environments, or C++ APIs are now accessible with our new Python module called DawDreamer. DawDreamer therefore bridges the gap between real sound engineers and coders imitating them with offline batch-processing. Like contemporary modules in this domain, DawDreamer can create directed acyclic graphs of audio processors such as VSTs which generate or manipulate audio streams. DawDreamer can also dynamically compile and execute code from Faust, a powerful signal processing language which can be deployed to many platforms and microcontrollers. We discuss DawDreamer's unique features in detail and potential applications across music information retrieval including source separation, transcription, and audio effect parameter inference. We provide fully cross-platform PyPI installers, a Linux Dockerfile, and an example Jupyter notebook.      
### 51.BLUE: A 3D Dynamic Bipedal Robot  [ :arrow_down: ](https://arxiv.org/pdf/2111.09920.pdf)
>  The objective of this work is to design a mechatronic bipedal robot with mobility in 3D environments. The designed robot has a total of six actuated degrees of freedom (DoF), each leg has two DoF located at the hip: one for abduction/adduction and another for thigh flexion/extension, and a third DoF at the knee for the shin flexion/extension. This robot is designed with point-feet legs to achieve a dynamic underactuated walking. Each actuator in the robot includes a DC gear motor, an encoder for position measurement, a flexible joint to form a series flexible actuator, and a feedback controller to ensure trajectory tracking. In order to reduce the total mass of the robot, the shin is designed using topology optimization. The resulting design is fabricated using 3D printed parts, which allows to get a robot's prototype to validate the selection of actuators. The preliminary experiments confirm the robot's ability to maintain a stand-up position and let us drawn future works in dynamic control and trajectory generation for periodic stable walking.      
### 52.Neural Network Kalman filtering for 3D object tracking from linear array ultrasound data  [ :arrow_down: ](https://arxiv.org/pdf/2111.09631.pdf)
>  Many interventional surgical procedures rely on medical imaging to visualise and track instruments. Such imaging methods not only need to be real-time capable, but also provide accurate and robust positional information. In ultrasound applications, typically only two-dimensional data from a linear array are available, and as such obtaining accurate positional estimation in three dimensions is non-trivial. In this work, we first train a neural network, using realistic synthetic training data, to estimate the out-of-plane offset of an object with the associated axial aberration in the reconstructed ultrasound image. The obtained estimate is then combined with a Kalman filtering approach that utilises positioning estimates obtained in previous time-frames to improve localisation robustness and reduce the impact of measurement noise. The accuracy of the proposed method is evaluated using simulations, and its practical applicability is demonstrated on experimental data obtained using a novel optical ultrasound imaging setup. Accurate and robust positional information is provided in real-time. Axial and lateral coordinates for out-of-plane objects are estimated with a mean error of 0.1mm for simulated data and a mean error of 0.2mm for experimental data. Three-dimensional localisation is most accurate for elevational distances larger than 1mm, with a maximum distance of 5mm considered for a 25mm aperture.      
