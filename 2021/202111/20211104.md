# ArXiv eess --Thu, 4 Nov 2021
### 1.A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2111.02392.pdf)
>  The goal of voice conversion is to transform source speech into a target voice, keeping the content unchanged. In this paper, we focus on self-supervised representation learning for voice conversion. Specifically, we compare discrete and soft speech units as input features. We find that discrete representations effectively remove speaker information but discard some linguistic content - leading to mispronunciations. As a solution, we propose soft speech units. To learn soft units, we predict a distribution over discrete speech units. By modeling uncertainty, soft units capture more content information, improving the intelligibility and naturalness of converted speech. Samples available at <a class="link-external link-https" href="https://ubisoft-laforge.github.io/speech/soft-vc/" rel="external noopener nofollow">this https URL</a>      
### 2.Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features  [ :arrow_down: ](https://arxiv.org/pdf/2111.02363.pdf)
>  In this study, we propose a cross-domain multi-objective speech assessment model, i.e., the MOSA-Net, which can estimate multiple speech assessment metrics simultaneously. More specifically, the MOSA-Net is designed to estimate speech quality, intelligibility, and distortion assessment scores based on a test speech signal as input. It comprises a convolutional neural network and bidirectional long short-term memory (CNN-BLSTM) architecture for representation extraction, as well as a multiplicative attention layer and a fully-connected layer for each assessment metric. In addition, cross-domain features (spectral and time-domain features) and latent representations from self-supervised learned models are used as inputs to combine rich acoustic information from different speech representations to obtain more accurate assessments. Experimental results reveal that the MOSA-Net can precisely predict perceptual evaluation of speech quality (PESQ), short-time objective intelligibility (STOI), and speech distortion index (SDI) scores when tested on both noisy and enhanced speech utterances under either seen test conditions (where the test speakers and noise types are involved in the training set) or unseen test conditions (where the test speakers and noise types are not involved in the training set). In light of the confirmed prediction capability, we further adopt the latent representations of the MOSA-Net to guide the speech enhancement (SE) process and derive a quality-intelligibility (QI)-aware SE (QIA-SE) approach accordingly. Experimental results show that QIA-SE provides superior enhancement performance compared with the baseline SE system in terms of objective evaluation metrics and qualitative evaluation test.      
### 3.Multi-Agent Deep Reinforcement Learning For Optimising Energy Efficiency of Fixed-Wing UAV Cellular Access Points  [ :arrow_down: ](https://arxiv.org/pdf/2111.02258.pdf)
>  Unmanned Aerial Vehicles (UAVs) promise to become an intrinsic part of next generation communications, as they can be deployed to provide wireless connectivity to ground users to supplement existing terrestrial networks. The majority of the existing research into the use of UAV access points for cellular coverage considers rotary-wing UAV designs (i.e. quadcopters). However, we expect fixed-wing UAVs to be more appropriate for connectivity purposes in scenarios where long flight times are necessary (such as for rural coverage), as fixed-wing UAVs rely on a more energy-efficient form of flight when compared to the rotary-wing design. As fixed-wing UAVs are typically incapable of hovering in place, their deployment optimisation involves optimising their individual flight trajectories in a way that allows them to deliver high quality service to the ground users in an energy-efficient manner. In this paper, we propose a multi-agent deep reinforcement learning approach to optimise the energy efficiency of fixed-wing UAV cellular access points while still allowing them to deliver high-quality service to users on the ground. In our decentralized approach, each UAV is equipped with a Dueling Deep Q-Network (DDQN) agent which can adjust the 3D trajectory of the UAV over a series of timesteps. By coordinating with their neighbours, the UAVs adjust their individual flight trajectories in a manner that optimises the total system energy efficiency. We benchmark the performance of our approach against a series of heuristic trajectory planning strategies, and demonstrate that our method can improve the system energy efficiency by as much as 70%.      
### 4.Learned Image Compression for Machine Perception  [ :arrow_down: ](https://arxiv.org/pdf/2111.02249.pdf)
>  Recent work has shown that learned image compression strategies can outperform standard hand-crafted compression algorithms that have been developed over decades of intensive research on the rate-distortion trade-off. With growing applications of computer vision, high quality image reconstruction from a compressible representation is often a secondary objective. Compression that ensures high accuracy on computer vision tasks such as image segmentation, classification, and detection therefore has the potential for significant impact across a wide variety of settings. In this work, we develop a framework that produces a compression format suitable for both human perception and machine perception. We show that representations can be learned that simultaneously optimize for compression and performance on core vision tasks. Our approach allows models to be trained directly from compressed representations, and this approach yields increased performance on new tasks and in low-shot learning settings. We present results that improve upon segmentation and detection performance compared to standard high quality JPGs, but with representations that are four to ten times smaller in terms of bits per pixel. Further, unlike naive compression methods, at a level ten times smaller than standard JEPGs, segmentation and detection models trained from our format suffer only minor degradation in performance.      
### 5.Cramér-Rao Bounds for Holographic Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02229.pdf)
>  Multiple antennas arrays play a key role in wireless networks for communications but also for localization and sensing applications. The use of large antenna arrays at high carrier frequencies (in the mmWave range) pushes towards a propagation regime in which the wavefront is no longer plane but spherical. This allows to infer the position and orientation of a transmitting source from the received signal without the need of using multiple anchor nodes, located in known positions. To understand the fundamental limits of large antenna arrays for localization, this paper combines wave propagation theory with estimation theory, and computes the Cramér-Rao Bound (CRB) for the estimation of the source position on the basis of the three Cartesian components of the electric field, observed over a rectangular surface area. The problem is referred to as holographic positioning and is formulated by taking into account the radiation angular pattern of the transmitting source, which is typically ignored in standard signal processing models. We assume that the source is a Hertzian dipole, and address the holographic positioning problem in both cases, that is, with and without a priori knowledge of its orientation. To simplify the analysis and gain further insights, we also consider the case in which the dipole is located on the line perpendicular to the surface center. Numerical and asymptotic results are given to quantify the CRBs, and to quantify the effect of various system parameters on the ultimate estimation accuracy. It turns out that surfaces of practical size may guarantee a centimeter-level accuracy in the mmWave bands.      
### 6.Active Perception and Control from PrSTL Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2111.02226.pdf)
>  Next-generation intelligent systems must plan and execute complex tasks with imperfect information about their environment. As a result, plans must also include actions to learn about the environment. This is known as active perception. Most active perception algorithms rely on reward or cost functions, which are usually challenging to specify and offer few theoretical guarantees. On the other hand, symbolic control methods can account for complex tasks using temporal logic but often do not deal well with uncertainties. This work combines symbolic control with active perception to achieve complex tasks in a partially observed and noisy control system with hybrid dynamics. Our basic idea is to employ a counterexample-guided-inductive-synthesis approach for control from probabilistic signal temporal logic (PrSTL) specifications. Our proposed algorithm combines bounded model checking (BMC) with sampling-based trajectory synthesis for uncertain hybrid systems. Active perception is inherently built into the framework because PrSTL formulas are defined in the chance domain.      
### 7.Swarm intelligence algorithms applied to Virtual Reference Feedback Tuning to increase controller robustness -- a one-shot technique  [ :arrow_down: ](https://arxiv.org/pdf/2111.02212.pdf)
>  This work presents a data-driven one-shot method for increasing robustness of a discrete-time closed-loop system by changing the controller parameters using swarm intelligence algorithms. Four swarm intelligence algorithms - Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Grey Wolf Optimization (GWO), and Improved Grey Wolf Optimization (I-GWO) - are described. Data-driven controller design is commented, focusing on the Virtual Reference Feedback Tuning (VRFT) algorithms. The estimation of the $\mathcal{H}_{\infty}$ norm of $S(z)$ via impulse response is presented. Two illustrative real-world based examples, regarding a Boost-like second order plant and a SEPIC-like fourth order plant, are tested for all commented swarm intelligence algorithms with the proposed method. Each algorithm at each case was run for 50 times, with 100 search agents, and maximum number of iterations limited to 100. For both examples, I-GWO presented the the best desired behavior, with the least number of outliers and no bad outlier in terms of fitness and $||S(z)||_{\infty}$ norm, as well as faster convergence, lowering the $||S(z)||_{\infty}$ norm of the plant from values greater than 2.0 to 1.8, still maintaining a low fitness value.      
### 8.Online Service Provisioning in NFV-enabled Networks Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02209.pdf)
>  In this paper, we study a Deep Reinforcement Learning (DRL) based framework for an online end-user service provisioning in a Network Function Virtualization (NFV)-enabled network. We formulate an optimization problem aiming to minimize the cost of network resource utilization. The main challenge is provisioning the online service requests by fulfilling their Quality of Service (QoS) under limited resource availability. Moreover, fulfilling the stochastic service requests in a large network is another challenge that is evaluated in this paper. To solve the formulated optimization problem in an efficient and intelligent manner, we propose a Deep Q-Network for Adaptive Resource allocation (DQN-AR) in NFV-enable network for function placement and dynamic routing which considers the available network resources as DQN states. Moreover, the service's characteristics, including the service life time and number of the arrival requests, are modeled by the Uniform and Exponential distribution, respectively. In addition, we evaluate the computational complexity of the proposed method. Numerical results carried out for different ranges of parameters reveal the effectiveness of our framework. In specific, the obtained results show that the average number of admitted requests of the network increases by 7 up to 14% and the network utilization cost decreases by 5 and 20 %.      
### 9.Online estimation of biophysical neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02176.pdf)
>  This paper presents an adaptive observer for online state and parameter estimation of a broad class of biophysical models of neuronal networks. The design closely resembles classical solutions of adaptive control, and the convergence proof is based on contraction analysis. Our results include robustness guarantees with respect to unknown parameter dynamics. We discuss the potential of the approach in neurophysiological applications.      
### 10.Unsupervised detection and open-set classification of fast-ramped flexibility activation events  [ :arrow_down: ](https://arxiv.org/pdf/2111.02174.pdf)
>  The continuous electrification of the mobility and heating sector will introduce new challenges to distribution grid operation. Uncoordinated activation of flexible units, e.g. simultaneous charging of electric vehicles as a reaction to price signals, could systematically trigger transformer or line protections. Real-time identification of such fast-ramped flexibility activations would allow taking counteractions to avoid potential social and financial cost. In this work, a novel data processing pipeline for identification of fast-ramped flexibility activation events is proposed. The pipeline combines techniques for unsupervised event detection and open-set classification. The systematic evaluation on real load data demonstrates that main building blocks of the proposed pipeline can be realized with methods that fulfill important requirements for an application in a distributed event detection architecture. For the detection of flexibility activation events an upper performance limit is identified. Moreover, it is demonstrated that application of an open-set classifier for classification of flexibility activation events can improve the performance compared to widely-applied closed-set classifiers.      
### 11.TranSMS: Transformers for Super-Resolution Calibration in Magnetic Particle Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.02163.pdf)
>  Magnetic particle imaging (MPI) is a recent modality that offers exceptional contrast for magnetic nanoparticles (MNP) at high spatio-temporal resolution. A common procedure in MPI starts with a calibration scan to measure the system matrix (SM), which is then used to setup an inverse problem to reconstruct images of the particle distribution during subsequent scans. This calibration enables the reconstruction to sensitively account for various system imperfections. Yet time-consuming SM measurements have to be repeated under notable drifts or changes in system properties. Here, we introduce a novel deep learning approach for accelerated MPI calibration based on transformers for SM super-resolution (TranSMS). Low-resolution SM measurements are performed using large MNP samples for improved signal-to-noise ratio efficiency, and the high-resolution SM is super-resolved via a model-based deep network. TranSMS leverages a vision transformer module to capture contextual relationships in low-resolution input images, a dense convolutional module for localizing high-resolution image features, and a data-consistency module to ensure consistency to measurements. Demonstrations on simulated and experimental data indicate that TranSMS achieves significantly improved SM recovery and image reconstruction in MPI, while enabling acceleration up to 64-fold during two-dimensional calibration.      
### 12.Interpolation Estimator for Infinite Sets of Random Vectors  [ :arrow_down: ](https://arxiv.org/pdf/2111.02141.pdf)
>  We propose an approach to the estimation of infinite sets of random vectors. The problem addressed is as follows. Given two infinite sets of random vectors, find a single estimator <br>that estimates vectors from with a controlled associated error. A new theory for the existence and implementation of such an estimator is studied. In particular, we show that the proposed estimator is asymptotically optimal. Moreover, the estimator is determined in terms of pseudo-inverse matrices and, therefore, it always exists.      
### 13.Homoscatter: Towards efficient connectivity for ZigBee backscatter system  [ :arrow_down: ](https://arxiv.org/pdf/2111.02140.pdf)
>  Recent advances in backscatter open a promising direction for ultra-low power communication. However, the state-of-art ZigBee backscatter system, Interscatter, has several drawbacks to deploy. Its backscatter tag and exciting source, Bluetooth, can hardly decode packets from other ZigBee nodes, which left Interscatter one-way communication. Besides, it adopts instantaneous phase change to modulate information, producing obvious sidelobes and interfering devices working on neighboring channels severely. To address the problems mentioned above, we introduce Homoscatter, a novel ZigBee backscatter system that adopts specific ZigBee devices to generate a single tone and leverages continuous phase change to modulate information, which eliminates spectral leakage. It also does codeword translation on the packet header of exciting packets, improving the utilization of ambient signal. <br>The prototype of Homoscatter consists of a microchip radio, a backscatter tag, and a commodity receiver. The evaluations show that the occupied bandwidth of Homoscatter achieves 3x smaller than Interscatter. When the channel capacity is 17.5 kbps, the continuous phase change modulation achieves 13 kbps with the codeword translation on the excitation header. Based on the widely spread IoT devices, Homoscatter is a practical way to build an efficient connection between IoT devices.      
### 14.End-to-End Learning for Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2111.02106.pdf)
>  Integrated sensing and communication (ISAC) aims to unify radar and communication systems through a combination of joint hardware, joint waveforms, joint signal design, and joint signal processing. At high carrier frequencies, where ISAC is expected to play a major role, joint designs are challenging due to several hardware limitations. Model-based approaches, while powerful and flexible, are inherently limited by how well the models represent reality. Under model deficit, data-driven methods can provide robust ISAC performance. We present a novel approach for data-driven ISAC using an auto-encoder (AE) structure. The approach includes the proposal of the AE architecture, a novel ISAC loss function, and the training procedure. Numerical results demonstrate the power of the proposed AE, in particular under hardware impairments.      
### 15.Distributed Extended Object Tracking Information Filter Over Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02098.pdf)
>  Motivated by the two common limitations on current distributed extended object tracking systems, i.e., the extent is modeled as an ellipse, and each sensor node in network needs to detect the object, this paper considers a multiplicative error model (MEM) to design a distributed information filter (IF) over a realistic network. The MEM reduces the extent of perpendicular axis-symmetric shapes into a 3-D vector, which results in MEM being a nonlinear and state-coupled model with multiplicative noise. To meet the requirement in IF that the state-space model is a linear model with additive noise, we first derive two separate pseudo-linearized models by using the first-order Taylor series expansion. The separation is merely in form, and the cross-correlation between two estimated states is preserved as parameters in each other's model. Thus, the joint estimation is transferred into an iterative operation of two linear filters. Second, we propose a centralized information filter by using the two models, in which the multiple measurements are converted into a summation form of innovation parts. Third, under a sensor network where the communication nodes cannot detect the object, we present two distributed information filters based on the consensus on information (CI) and consensus on measurement (CM) schemes, respectively. Finally, the performance of two distributed filters in terms of accuracy, convergence, and consistency is evaluated in Monte Carlo simulations.      
### 16.Blind inverse problems with isolated spikes  [ :arrow_down: ](https://arxiv.org/pdf/2111.02093.pdf)
>  Assume that an unknown integral operator living in some known subspace is observed indirectly, by evaluating its action on a few Dirac masses at unknown locations. Is this information enough to recover the operator and the impulse responses locations stably? We study this question and answer positively under realistic technical assumptions. We illustrate the well-foundedness of this theory on two challenging optical imaging problems: blind super-resolution and deconvolution. This provides a simple, practical and theoretically grounded approach to solve these long resisting problems.      
### 17.Antenna De-Embedding in FDTD Using Spherical Wave Functions by Exploiting Orthogonality  [ :arrow_down: ](https://arxiv.org/pdf/2111.02087.pdf)
>  De-embedding antennas from the channel using Spherical Wave Functions (SWF) is a useful method to reduce the numerical effort in the simulation of wearable antennas. In this paper an analytical solution to the De-embedding problem is presented in form of surface integrals. This new integral solution is helpful on a theoretical level to derive insights and is also well suited for implementation in Finite Difference Time Domain (FDTD) numerical software. The spherical wave function coefficients are calculated directly from near-field values. Furthermore, the presence of a near-field scatterer in the de-embedding problem is discussed on a theoretical level based on the Huygens Equivalence Theorem. This makes it possible to exploit the degrees of freedom in such a way that it is sufficient to only use out-going spherical wave functions and still obtain correct results.      
### 18.Load Restoration in Islanded Microgrids: Formulation and Solution Strategies  [ :arrow_down: ](https://arxiv.org/pdf/2111.02054.pdf)
>  Extreme weather events induced by climate change can cause significant disruptions to the normal operation of electric distribution systems (DS), including isolation of parts of the DS due to damaged transmission equipment. In this paper, we consider the problem of load restoration in a microgrid (MG) that is islanded from the upstream DS because of an extreme weather event. The MG contains sources of distributed generation such as microturbines and renewable energy sources, in addition to energy storage systems. We formulate the load restoration task as a non-convex optimization problem with complementarity constraints. We propose a convex relaxation of the problem that can be solved via model predictive control. In addition, we propose a data-driven policy-learning method called constrained policy optimization. The solutions from both methods are compared by evaluating their performance in load restoration, which is tested on a 12-bus MG.      
### 19.A Supervised-Learning based Hour-Ahead Demand Response of a Behavior-based HEMS approximating MILP Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2111.01978.pdf)
>  The demand response (DR) program of a traditional HEMS usually intervenes appliances by controlling or scheduling them to achieve multiple objectives such as minimizing energy cost and maximizing user comfort. In this study, instead of intervening appliances and changing resident behavior, our proposed strategy for hour-ahead DR firstly learns appliance use behavior of residents and then silently controls ESS and RES to minimize daily energy cost based on its knowledge. To accomplish the goal, our proposed deep neural networks (DNNs) models approximate MILP optimization by using supervised learning. The datasets for training DNNs are created from optimal outputs of a MILP solver with historical data. After training, at each time slot, these DNNs are used to control ESS and RES with real-time data of the surrounding environment. For comparison, we develop two different strategies named multi-agent reinforcement learning-based strategy, a kind of hour-ahead strategy and forecast-based MILP strategy, a kind of day-ahead strategy. For evaluation and verification, our proposed strategies are applied at three different real-world homes with real-world real-time global horizontal irradiation and real-world real-time prices. Numerical results verify that the proposed MILP-based supervised learning strategy is effective in term of daily energy cost and is the best one among three proposed strategies      
### 20.Optimal Parameter Inflation to Enhance the Availability of Single-Frequency GBAS for Intelligent Air Transportation  [ :arrow_down: ](https://arxiv.org/pdf/2111.01953.pdf)
>  Ground-based Augmentation System (GBAS) augments Global Navigation Satellite Systems (GNSS) to support the precision approach and landing of aircraft. To guarantee integrity, existing single-frequency GBAS utilizes position-domain geometry screening to eliminate potentially unsafe satellite geometries by inflating one or more broadcast GBAS parameters. However, GBAS availability can be drastically impacted in low-latitude regions where severe ionospheric conditions have been observed. Thus, we developed a novel geometry-screening algorithm in this study to improve GBAS availability in low-latitude regions. Simulations demonstrate that the proposed method can provide 5-8 percentage point availability enhancement of GBAS at Galeão airport near Rio de Janeiro, Brazil, compared to existing methods.      
### 21.A MIMO Radar-Based Metric Learning Approach for Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.01939.pdf)
>  Human activity recognition is seen of great importance in the medical and surveillance fields. Radar has shown great feasibility for this field based on the captured micro-Doppler ({\mu}-D) signatures. In this paper, a MIMO radar is used to formulate a novel micro-motion spectrogram for the angular velocity ({\mu}-{\omega}) in non-tangential scenarios. Combining both the {\mu}-D and the {\mu}-{\omega} signatures have shown better performance. Classification accuracy of 88.9% was achieved based on a metric learning approach. The experimental setup was designed to capture micro-motion signatures on different aspect angles and line of sight (LOS). The utilized training dataset was of smaller size compared to the state-of-the-art techniques, where eight activities were captured. A few-shot learning approach is used to adapt the pre-trained model for fall detection. The final model has shown a classification accuracy of 86.42% for ten activities.      
### 22.Verifying Switched System Stability With Logic  [ :arrow_down: ](https://arxiv.org/pdf/2111.01928.pdf)
>  Switched systems are known to exhibit subtle (in)stability behaviors requiring system designers to carefully analyze the stability of closed-loop systems that arise from their proposed switching control laws. This paper presents a formal approach for verifying switched system stability that blends classical ideas from the controls and verification literature using differential dynamic logic (dL), a logic for deductive verification of hybrid systems. From controls, we use standard stability notions for various classes of switching mechanisms and their corresponding Lyapunov function-based analysis techniques. From verification, we use dL's ability to verify quantified properties of hybrid systems and dL models of switched systems as looping hybrid programs whose stability can be formally specified and proven by finding appropriate loop invariants, i.e., properties that are preserved across each loop iteration. This blend of ideas enables a trustworthy implementation of switched system stability verification in the KeYmaera X prover based on dL. For standard classes of switching mechanisms, the implementation provides fully automated stability proofs, including searching for suitable Lyapunov functions. Moreover, the generality of the deductive approach also enables verification of switching control laws that require non-standard stability arguments through the design of loop invariants that suitably express specific intuitions behind those control laws. This flexibility is demonstrated on three case studies: a model for longitudinal flight control by Branicky, an automatic cruise controller, and Brockett's nonholonomic integrator.      
### 23.First experimental evaluation of ambient backscatter communications with massive MIMO reader  [ :arrow_down: ](https://arxiv.org/pdf/2111.01918.pdf)
>  Ambient backscatter communications have been introduced as low-power communications for green networking. This technology is very promising as it recycles ambient radio frequency waves, however such systems have limitations and suffer from poor performance due to their low-power. In this paper, we present and evaluate the performance of an ambient backscatter system equipped with a massive multiple input multiple output (MIMO) antenna at the reader side. A mobile device transmits a signal that is backscattered by a tag and received by the reader. Thanks to the spatial diversity of the massive MIMO antenna, the reader is able to identify, for each received signal, the state of the tag (backscattering or transparent) that corresponds to a bit of the tag message. First, we experimentally determine the channel between the device and the reader for two states of the tag. Then using a minimum mean square error algorithm we evaluate the performance of the ambient backscatter communication. We demonstrate that the performance of the ambient backscatter system is significantly improved by the massive MIMO reader.      
### 24.Robust Ambient Backscatter Communications with Polarization Reconfigurable Tags  [ :arrow_down: ](https://arxiv.org/pdf/2111.01917.pdf)
>  Ambient backscatter communication system is an emerging and promising low-energy technology for Internet of Things. In such system, a device named tag, sends a binary message to a reader by backscattering a radio frequency signal generated by an ambient source. Such tag can operate without battery and without generating additional wave. However, the tag-to-reader link suffers from the source-to-reader direct interference. In this paper, for the first time, we propose to exploit a "polarization reconfigurable" antenna to improve robustness of the tag-to-reader link against the source-to-reader direct interference. Our proposed new tag sends its message by backscattering as an usual tag. However, it repeats its message several times, with a different radiation pattern and polarization, each time. We expect one polarization pattern to be better detected by the reader. We show by simulations and experiments, in line-of-sight and in richly scattering environment, that a polarization reconfigurable tag limited to 4 polarization directions outperforms a nonreconfigurable tag and nearly equals an ideally reconfigurable tag in performance.      
### 25.Reduction of Subjective Listening Effort for TV Broadcast Signals with Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.01914.pdf)
>  Listening to the audio of TV broadcast signals can be challenging for hearing-impaired as well as normal-hearing listeners, especially when background sounds are prominent or too loud compared to the speech signal. This can result in a reduced satisfaction and increased listening effort of the listeners. Since the broadcast sound is usually premixed, we perform a subjective evaluation for quantifying the potential of speech enhancement systems based on audio source separation and recurrent neural networks (RNN). Recently, RNNs have shown promising results in the context of sound source separation and real-time signal processing. In this paper, we separate the speech from the background signals and remix the separated sounds at a higher signal-to-noise ratio. This differs from classic speech enhancement, where usually only the extracted speech signal is exploited. The subjective evaluation with 20 normal-hearing subjects on real TV-broadcast material shows that our proposed enhancement system is able to reduce the listening effort by around 2 points on a 13-point listening effort rating scale and increases the perceived sound quality compared to the original mixture.      
### 26.Stochastic simulation of residential building occupant-driven energy use in a bottom-up model of the U.S. housing stock  [ :arrow_down: ](https://arxiv.org/pdf/2111.01881.pdf)
>  The residential buildings sector is one of the largest electricity consumers worldwide and contributes disproportionally to peak electricity demand in many regions. Strongly driven by occupant activities at home, household energy consumption is stochastic and heterogeneous in nature. However, most residential building energy models applied by industry use homogeneous, deterministic occupant activity schedules, which work well for predictions of annual energy consumption, but can result in unrealistic hourly or sub-hourly electric load profiles, with exaggerated or muted peaks. This mattered less in the past, but the increasing proportion of variable renewable energy generators in power systems means that representing the heterogeneity and stochasticity of occupant behavior is crucial for reliable energy planning. This is particularly true for systems that include distributed energy resources, such as grid-interactive efficient buildings, solar photovoltaics, and battery storage. This work presents a stochastic occupant behavior simulator that models the energy use behavior of individual household members. It also presents an integration with a building stock model to simulate residential building loads more accurately at community, city, state, and national scales. More specifically, we first employ clustering techniques to identify distinct patterns of occupant behavior. Then, we combine time-inhomogeneous Markov chain simulations with probabilistic sampling of event durations to realistically simulate occupant behaviors. This stochastic simulator is integrated with ResStock, a large-scale residential building stock simulation tool, to demonstrate the capability of stochastic residential building load modeling at scale. The simulation results were validated against both American Time Use Survey data and measured end-use electricity data for accuracy and reliability.      
### 27.Resilient Interval Observer for Simultaneous Estimation of States, Modes and Attack Policies  [ :arrow_down: ](https://arxiv.org/pdf/2111.01873.pdf)
>  This paper considers the problem of designing interval observers for hidden mode switched nonlinear systems with bounded noise signals that are compromised by false data injection and switching attacks. The proposed observer consists of three components: i) a bank of mode-matched observers, which simultaneously estimates the corresponding mode-matched continuous states and discrete states (modes), as well as learns a model of the unknown attack policy, ii) a mode observer that eliminates the incompatible modes based on a residual-based set-membership criterion, and iii) a global fusion observer that combines the outputs of i) and ii). Moreover, in addition to showing the correctness, stability and convergence of the mode-matched estimates, we provide sufficient conditions to guarantee that all false modes will be eliminated after sufficiently large finite time steps, i.e., the system is mode-detectable under the proposed observer.      
### 28.3-D PET Image Generation with tumour masks using TGAN  [ :arrow_down: ](https://arxiv.org/pdf/2111.01866.pdf)
>  Training computer-vision related algorithms on medical images for disease diagnosis or image segmentation is difficult due to the lack of training data, labeled samples, and privacy concerns. For this reason, a robust generative method to create synthetic data is highly sought after. However, most three-dimensional image generators require additional image input or are extremely memory intensive. To address these issues we propose adapting video generation techniques for 3-D image generation. Using the temporal GAN (TGAN) architecture, we show we are able to generate realistic head and neck PET images. We also show that by conditioning the generator on tumour masks, we are able to control the geometry and location of the tumour in the generated images. To test the utility of the synthetic images, we train a segmentation model using the synthetic images. Synthetic images conditioned on real tumour masks are automatically segmented, and the corresponding real images are also segmented. We evaluate the segmentations using the Dice score and find the segmentation algorithm performs similarly on both datasets (0.65 synthetic data, 0.70 real data). Various radionomic features are then calculated over the segmented tumour volumes for each data set. A comparison of the real and synthetic feature distributions show that seven of eight feature distributions had statistically insignificant differences (p&gt;0.05). Correlation coefficients were also calculated between all radionomic features and it is shown that all of the strong statistical correlations in the real data set are preserved in the synthetic data set.      
### 29.Distributed Learning over a Wireless Network with FSK-Based Majority Vote  [ :arrow_down: ](https://arxiv.org/pdf/2111.01850.pdf)
>  In this study, we propose an over-the-air computation (AirComp) scheme for federated edge learning (FEEL). The proposed scheme relies on the concept of distributed learning by majority vote (MV) with sign stochastic gradient descend (signSGD). As compared to the state-of-the-art solutions, with the proposed method, edge devices (EDs) transmit the signs of local stochastic gradients by activating one of two orthogonal resources, i.e., orthogonal frequency division multiplexing (OFDM) subcarriers, and the MVs at the edge server (ES) are obtained with non-coherent detectors by exploiting the energy accumulations on the subcarriers. Hence, the proposed scheme eliminates the need for channel state information (CSI) at the EDs and ES. By taking path loss, power control, cell size, and the probabilistic nature of the detected MVs in fading channel into account, we prove the convergence of the distributed learning for a non-convex function. Through simulations, we show that the proposed scheme can provide a high test accuracy in fading channels even when the time-synchronization and the power alignment at the ES are not ideal. We also provide insight into distributed learning for location-dependent data distribution for the MV-based schemes.      
### 30.Necessary and sufficient conditions for the identifiability of loops  [ :arrow_down: ](https://arxiv.org/pdf/2111.01849.pdf)
>  This Letter provides necessary and sufficient conditions on the excitation and measurement pattern (EMP) that guarantee identifiability of a dynamical network that has the structure of a loop. The conditions are extremely simple in their formulation, and they can be checked by visual inspection. They allow one to easily characterize all EMPs that make the loop network identifiable.      
### 31.Exact aggregate models for optimal management of heterogeneous fleets of storage devices  [ :arrow_down: ](https://arxiv.org/pdf/2111.02395.pdf)
>  Future power grids will entail large fleets of storage devices capable of scheduling their charging/discharging profiles so as to achieve lower peak demand and reduce energy bills, by shifting absorption times in sync with the availability of renewable energy sources. Optimal management of such fleets entails large scale optimisation problems which are better dealt with in a hierarchical manner, by clustering together individual devices into fleets. Leveraging on recent results characterizing the set of aggregate demand profiles of a heterogeneous fleet of charging (or, respectively, discharging) devices we propose a way to achieve optimality, in a unit commitment problem, by adopting a simplified formulation with a number of constraints for the fleet that scales linearly in the number of time-slots considered and is independent of the size of the fleet. This is remarkable, as it shows that, under suitable conditions, a heterogeneous fleet of any size can effectively be treated as a single storage unit.      
### 32.Weight, Block or Unit? Exploring Sparsity Tradeoffs for Speech Enhancement on Tiny Neural Accelerators  [ :arrow_down: ](https://arxiv.org/pdf/2111.02351.pdf)
>  We explore network sparsification strategies with the aim of compressing neural speech enhancement (SE) down to an optimal configuration for a new generation of low power microcontroller based neural accelerators (microNPU's). We examine three unique sparsity structures: weight pruning, block pruning and unit pruning; and discuss their benefits and drawbacks when applied to SE. We focus on the interplay between computational throughput, memory footprint and model quality. Our method supports all three structures above and jointly learns integer quantized weights along with sparsity. Additionally, we demonstrate offline magnitude based pruning of integer quantized models as a performance baseline. Although efficient speech enhancement is an active area of research, our work is the first to apply block pruning to SE and the first to address SE model compression in the context of microNPU's. Using weight pruning, we show that we are able to compress an already compact model's memory footprint by a factor of 42x from 3.7MB to 87kB while only losing 0.1 dB SDR in performance. We also show a computational speedup of 6.7x with a corresponding SDR drop of only 0.59 dB SDR using block pruning.      
### 33.Direct data-driven control of linear time-varying systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02342.pdf)
>  An identification-free control design strategy for discrete-time linear time-varying systems with unknown dynamics is introduced. The closed-loop system (under state feedback) is parametrised with data-dependent matrices obtained from an ensemble of input-state trajectories collected offline. Subsequently, controllers guaranteeing bounded closed-loop trajectories, optimal performance and robustness to process and measurement noise are designed via convex feasibility and optimisation problems involving purely data-dependent linear matrix inequalities. For the special case of periodically time-varying systems, performance guarantees are achieved over an infinite horizon, based on data collected over a single, finite duration experiment. The results are demonstrated by means of an illustrative academic example and a practically motivated example involving a voltage source converter.      
### 34.STC speaker recognition systems for the NIST SRE 2021  [ :arrow_down: ](https://arxiv.org/pdf/2111.02298.pdf)
>  This paper presents a description of STC Ltd. systems submitted to the NIST 2021 Speaker Recognition Evaluation for both fixed and open training conditions. These systems consists of a number of diverse subsystems based on using deep neural networks as feature extractors. During the NIST 2021 SRE challenge we focused on the training of the state-of-the-art deep speaker embeddings extractors like ResNets and ECAPA networks by using additive angular margin based loss functions. Additionally, inspired by the recent success of the wav2vec 2.0 features in automatic speech recognition we explored the effectiveness of this approach for the speaker verification filed. According to our observation the fine-tuning of the pretrained large wav2vec 2.0 model provides our best performing systems for open track condition. Our experiments with wav2vec 2.0 based extractors for the fixed condition showed that unsupervised autoregressive pretraining with Contrastive Predictive Coding loss opens the door to training powerful transformer-based extractors from raw speech signals. For video modality we developed our best solution with RetinaFace face detector and deep ResNet face embeddings extractor trained on large face image datasets. The final results for primary systems were obtained by different configurations of subsystems fusion on the score level followed by score calibration.      
### 35.A Self-adaptive LSAC-PID Approach based on Lyapunov Reward Shaping for Mobile Robots  [ :arrow_down: ](https://arxiv.org/pdf/2111.02283.pdf)
>  To solve the coupling problem of control loops and the adaptive parameter tuning problem in the multi-input multi-output (MIMO) PID control system, a self-adaptive LSAC-PID algorithm is proposed based on deep reinforcement learning (RL) and Lyapunov-based reward shaping in this paper. For complex and unknown mobile robot control environment, an RL-based MIMO PID hybrid control strategy is firstly presented. According to the dynamic information and environmental feedback of the mobile robot, the RL agent can output the optimal MIMO PID parameters in real time, without knowing mathematical model and decoupling multiple control loops. Then, to improve the convergence speed of RL and the stability of mobile robots, a Lyapunov-based reward shaping soft actor-critic (LSAC) algorithm is proposed based on Lyapunov theory and potential-based reward shaping method. The convergence and optimality of the algorithm are proved in terms of the policy evaluation and improvement step of soft policy iteration. In addition, for line-following robots, the region growing method is improved to adapt to the influence of forks and environmental interference. Through comparison, test and cross-validation, the simulation and real-environment experimental results all show good performance of the proposed LSAC-PID tuning algorithm.      
### 36.A Portuguese radar tracking sensor for Space Debris monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2111.02232.pdf)
>  The increase in space debris is a threat to space assets, space based-operations and led to a common effort to develop programs for dealing with this increase. As part of the Portuguese Space Surveillance and Tracking (SST) project, led by the Portuguese Ministry of Defense (MoD), the Instituto de Telecomunicações (IT) is developing rAdio TeLescope pAmpilhosa Serra (ATLAS), a new monostatic radar tracking sensor located at the Pampilhosa da Serra Space Observatory (ErPoB), Portugal. The system operates at 5.56 GHz and aims to provide information on objects in low earth orbit (LEO) orbits, with cross sections above 10 cm2 at 1000 km. ErPoB houses all the necessary equipment to connect to the research and development team in IT-Aveiro and to the European Union Space Surveillance and Tracking (EU-SST) network through the Portuguese SST-PT network and operation center. The ATLAS system features digital waveform synthesis, power amplifiers using Gallium Nitride (GaN) technology, fully digital signal processing and a highly modular architecture that follows an Open Systems (OS) philosophy and uses Commercial-Off-The-Shelf (COTS) technologies. ATLAS establishes a modern and versatile platform for fast and easy development, research and innovation. The whole system (except antenna and power amplifiers) was tested in a setup with a major reflector of opportunity at a well defined range. The obtained range profiles show that the target can be easily detected. This marks a major step on the functional testing of the system and on getting closer to an operational system capable of detecting objects in orbit.      
### 37.Automatic Embedding of Stories Into Collections of Independent Media  [ :arrow_down: ](https://arxiv.org/pdf/2111.02216.pdf)
>  We look at how machine learning techniques that derive properties of items in a collection of independent media can be used to automatically embed stories into such collections. To do so, we use models that extract the tempo of songs to make a music playlist follow a narrative arc. Our work specifies an open-source tool that uses pre-trained neural network models to extract the global tempo of a set of raw audio files and applies these measures to create a narrative-following playlist. This tool is available at <a class="link-external link-https" href="https://github.com/dylanashley/playlist-story-builder/releases/tag/v1.0.0" rel="external noopener nofollow">this https URL</a>      
### 38.EASE: Energy-Aware job Scheduling for vehicular Edge networks with renewable energy resources  [ :arrow_down: ](https://arxiv.org/pdf/2111.02186.pdf)
>  The energy sustainability of multi-access edge computing (MEC) platforms is addressed in this paper, by developing Energy-Aware job Scheduling at the Edge (EASE), a computing resource scheduler for edge servers co-powered by renewable energy resources and the power grid. The scenario under study involves the optimal allocation and migration of time-sensitive computing tasks in a resource-constrained internet of vehicles (IoV) context. This is achieved by tackling, as a main objective, the minimization of the carbon footprint of the edge network, whilst delivering adequate quality of service (QoS) to the end users (e.g., meeting task execution deadlines). EASE integrates a i) centralized optimization step, solved through model predictive control (MPC), to manage the renewable energy that is locally collected at the edge servers and their local computing resources, estimating their future availability, and ii) a distributed consensus step, solved via dual ascent in closed form, to reach agreement on service migrations. EASE is compared with existing strategies that always and never migrate the computing tasks. Quantitative results demonstrate the greater energy efficiency achieved by EASE, which often gets close to complete carbon neutrality, while also improving the QoS.      
### 39.EISPY2D: An Open-Source Python Library for the Development and Comparison of Algorithms in Two-Dimensional Electromagnetic Inverse Scattering Problems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02185.pdf)
>  Microwave Imaging is an essential technique for reconstructing the electrical properties of an inaccessible medium. Many approaches have been proposed employing algorithms to solve the Electromagnetic Inverse Scattering Problem associated with this technique. In addition to the algorithm, one needs to implement adequate structures to represent the problem domain, the input data, the results of the adopted metrics, and experimentation routines. We introduce an open-source Python library that offers a modular and standardized framework for implementing and evaluating the performance of algorithms for the problem. Based on the implementation of fundamental components for the execution of algorithms, this library aims to facilitate the development and discussion of new methods. Through a modular structure organized into classes, researchers can design their case studies and benchmarking experiments relying on features such as test randomization, specific metrics, and statistical comparison. To the best of the authors' knowledge, it is the first time that such tools for benchmarking and comparison are introduced for microwave imaging algorithms. In addition, two new metrics for location and shape recovery are presented. In this work, we introduce the principles for the design of the problem components and provide studies to exemplify the main aspects of this library. It is freely distributed through a Github repository that can be accessed from <a class="link-external link-https" href="https://andre-batista.github.io/eispy2d/" rel="external noopener nofollow">this https URL</a>.      
### 40.Discriminator Synthesis: On reusing the other half of Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02175.pdf)
>  Generative Adversarial Networks have long since revolutionized the world of computer vision and, tied to it, the world of art. Arduous efforts have gone into fully utilizing and stabilizing training so that outputs of the Generator network have the highest possible fidelity, but little has gone into using the Discriminator after training is complete. In this work, we propose to use the latter and show a way to use the features it has learned from the training dataset to both alter an image and generate one from scratch. We name this method Discriminator Dreaming, and the full code can be found at <a class="link-external link-https" href="https://github.com/PDillis/stylegan3-fun" rel="external noopener nofollow">this https URL</a>.      
### 41.Power Flow Balancing with Decentralized Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02169.pdf)
>  We propose an end-to-end framework based on a Graph Neural Network (GNN) to balance the power flows in a generic grid. The optimization is framed as a supervised vertex regression task, where the GNN is trained to predict the current and power injections at each grid branch that yield a power flow balance. By representing the power grid as a line graph with branches as vertices, we can train a GNN that is more accurate and robust to changes in the underlying topology. In addition, by using specialized GNN layers, we are able to build a very deep architecture that accounts for large neighborhoods on the graph, while implementing only localized operations. We perform three different experiments to evaluate: i) the benefits of using localized rather than global operations and the tendency to oversmooth when using deep GNN models; ii) the resilience to perturbations in the graph topology; and iii) the capability to train the model simultaneously on multiple grid topologies and the consequential improvement in generalization to new, unseen grids. The proposed framework is efficient and, compared to other solvers based on deep learning, is robust to perturbations not only to the physical quantities on the grid components, but also to the topology.      
### 42.Beyond PRNU: Learning Robust Device-Specific Fingerprint for Source Camera Identification  [ :arrow_down: ](https://arxiv.org/pdf/2111.02144.pdf)
>  Source camera identification tools assist image forensic investigators to associate an image in question with a suspect camera. Various techniques have been developed based on the analysis of the subtle traces left in the images during the acquisition. The Photo Response Non Uniformity (PRNU) noise pattern caused by sensor imperfections has been proven to be an effective way to identify the source camera. The existing literature suggests that the PRNU is the only fingerprint that is device-specific and capable of identifying the exact source device. However, the PRNU is susceptible to camera settings, image content, image processing operations, and counter-forensic attacks. A forensic investigator unaware of counter-forensic attacks or incidental image manipulations is at the risk of getting misled. The spatial synchronization requirement during the matching of two PRNUs also represents a major limitation of the PRNU. In recent years, deep learning based approaches have been successful in identifying source camera models. However, the identification of individual cameras of the same model through these data-driven approaches remains unsatisfactory. In this paper, we bring to light the existence of a new robust data-driven device-specific fingerprint in digital images which is capable of identifying the individual cameras of the same model. It is discovered that the new device fingerprint is location-independent, stochastic, and globally available, which resolve the spatial synchronization issue. Unlike the PRNU, which resides in the high-frequency band, the new device fingerprint is extracted from the low and mid-frequency bands, which resolves the fragility issue that the PRNU is unable to contend with. Our experiments on various datasets demonstrate that the new fingerprint is highly resilient to image manipulations such as rotation, gamma correction, and aggressive JPEG compression.      
### 43.Predictive Auto-scaling with OpenStack Monasca  [ :arrow_down: ](https://arxiv.org/pdf/2111.02133.pdf)
>  Cloud auto-scaling mechanisms are typically based on reactive automation rules that scale a cluster whenever some metric, e.g., the average CPU usage among instances, exceeds a predefined threshold. Tuning these rules becomes particularly cumbersome when scaling-up a cluster involves non-negligible times to bootstrap new instances, as it happens frequently in production cloud services. <br>To deal with this problem, we propose an architecture for auto-scaling cloud services based on the status in which the system is expected to evolve in the near future. Our approach leverages on time-series forecasting techniques, like those based on machine learning and artificial neural networks, to predict the future dynamics of key metrics, e.g., resource consumption metrics, and apply a threshold-based scaling policy on them. The result is a predictive automation policy that is able, for instance, to automatically anticipate peaks in the load of a cloud application and trigger ahead of time appropriate scaling actions to accommodate the expected increase in traffic. <br>We prototyped our approach as an open-source OpenStack component, which relies on, and extends, the monitoring capabilities offered by Monasca, resulting in the addition of predictive metrics that can be leveraged by orchestration components like Heat or Senlin. We show experimental results using a recurrent neural network and a multi-layer perceptron as predictor, which are compared with a simple linear regression and a traditional non-predictive auto-scaling policy. However, the proposed framework allows for the easy customization of the prediction policy as needed.      
### 44.A Novel Actuation Strategy for an Agile Bio-inspired FWAV Performing a Morphing-coupled Wingbeat Pattern  [ :arrow_down: ](https://arxiv.org/pdf/2111.02118.pdf)
>  Flying vertebrates exhibit sophisticated wingbeat kinematics. Their specialized forelimbs allow for the wing morphing motion to couple with the flapping motion during their level flight, Previous flyable bionic platforms have successfully applied bio-inspired wing morphing but cannot yet be propelled by the morphing-coupled wingbeat pattern. Spurred by this, we develop a bio-inspired flapping-wing aerial vehicle (FWAV) entitled RoboFalcon, which is equipped with a novel mechanism to drive the bat-style morphing wings, performs a morphing-coupled wingbeat pattern, and overall manages an appealing flight. The novel mechanism of RoboFalcon allows coupling the morphing and flapping during level flight and decoupling these when maneuvering is required, producing a bilateral asymmetric downstroke affording high rolling agility. The bat-style morphing wing is designed with a tilted mounting angle around the radius at the wrist joint to mimic the wrist supination and pronation effect of flying vertebrates' forelimbs. The agility of RoboFalcon is assessed through several rolling maneuver flight tests, and we demonstrate its well-performing agility capability compared to flying creatures and current flapping-wing platforms. Wind tunnel tests indicate that the roll moment of the asymmetric downstroke is correlated with the flapping frequency, and the wrist mounting angle can be used for tuning the angle of attack and lift-thrust configuration of the equilibrium flight state. We believe that this work yields a well-performing bionic platform and provides a new actuation strategy for the morphing-coupled flapping flight.      
### 45.Streaming Solutions for Time-Varying Optimization Problems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02101.pdf)
>  This paper studies streaming optimization problems that have objectives of the form $ \sum_{t=1}^Tf(\mathbf{x}_{t-1},\mathbf{x}_t)$. In particular, we are interested in how the solution $\hat{\mathbf{x} }_{t|T}$ for the $t$th frame of variables changes as $T$ increases. While incrementing $T$ and adding a new functional and a new set of variables does in general change the solution everywhere, we give conditions under which $\hat{\mathbf{x} }_{t|T}$ converges to a limit point $\mathbf{x}^*_t$ at a linear rate as $T\rightarrow\infty$. As a consequence, we are able to derive theoretical guarantees for algorithms with limited memory, showing that limiting the solution updates to only a small number of frames in the past sacrifices almost nothing in accuracy. We also present a new efficient Newton online algorithm (NOA), inspired by these results, that updates the solution with fixed complexity of $ \mathcal{O}( {3Bn^3})$, independent of $T$, where $B$ corresponds to how far in the past the variables are updated, and $n$ is the size of a single block-vector. Two streaming optimization examples, online reconstruction from non-uniform samples and non-homogeneous Poisson intensity estimation, support the theoretical results and show how the algorithm can be used in practice.      
### 46.Influence of image noise on crack detection performance of deep convolutional neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02079.pdf)
>  Development of deep learning techniques to analyse image data is an expansive and emerging field. The benefits of tracking, identifying, measuring, and sorting features of interest from image data has endless applications for saving cost, time, and improving safety. Much research has been conducted on classifying cracks from image data using deep convolutional neural networks; however, minimal research has been conducted to study the efficacy of network performance when noisy images are used. This paper will address the problem and is dedicated to investigating the influence of image noise on network accuracy. The methods used incorporate a benchmark image data set, which is purposely deteriorated with two types of noise, followed by treatment with image enhancement pre-processing techniques. These images, including their native counterparts, are then used to train and validate two different networks to study the differences in accuracy and performance. Results from this research reveal that noisy images have a moderate to high impact on the network's capability to accurately classify images despite the application of image pre-processing. A new index has been developed for finding the most efficient method for classification in terms of computation timing and accuracy. Consequently, AlexNet was selected as the most efficient model based on the proposed index.      
### 47.Deep-Learning-Based Single-Image Height Reconstruction from Very-High-Resolution SAR Intensity Data  [ :arrow_down: ](https://arxiv.org/pdf/2111.02061.pdf)
>  Originally developed in fields such as robotics and autonomous driving with image-based navigation in mind, deep learning-based single-image depth estimation (SIDE) has found great interest in the wider image analysis community. Remote sensing is no exception, as the possibility to estimate height maps from single aerial or satellite imagery bears great potential in the context of topographic reconstruction. A few pioneering investigations have demonstrated the general feasibility of single image height prediction from optical remote sensing images and motivate further studies in that direction. With this paper, we present the first-ever demonstration of deep learning-based single image height prediction for the other important sensor modality in remote sensing: synthetic aperture radar (SAR) data. Besides the adaptation of a convolutional neural network (CNN) architecture for SAR intensity images, we present a workflow for the generation of training data, and extensive experimental results for different SAR imaging modes and test sites. Since we put a particular emphasis on transferability, we are able to confirm that deep learning-based single-image height estimation is not only possible, but also transfers quite well to unseen data, even if acquired by different imaging modes and imaging parameters.      
### 48.A Comparative Study of Speaker Role Identification in Air Traffic Communication Using Deep Learning Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2111.02041.pdf)
>  Automatic spoken instruction understanding (SIU) of the controller-pilot conversations in the air traffic control (ATC) requires not only recognizing the words and semantics of the speech but also determining the role of the speaker. However, few of the published works on the automatic understanding systems in air traffic communication focus on speaker role identification (SRI). In this paper, we formulate the SRI task of controller-pilot communication as a binary classification problem. Furthermore, the text-based, speech-based, and speech and text based multi-modal methods are proposed to achieve a comprehensive comparison of the SRI task. To ablate the impacts of the comparative approaches, various advanced neural network architectures are applied to optimize the implementation of text-based and speech-based methods. Most importantly, a multi-modal speaker role identification network (MMSRINet) is designed to achieve the SRI task by considering both the speech and textual modality features. To aggregate modality features, the modal fusion module is proposed to fuse and squeeze acoustic and textual representations by modal attention mechanism and self-attention pooling layer, respectively. Finally, the comparative approaches are validated on the ATCSpeech corpus collected from a real-world ATC environment. The experimental results demonstrate that all the comparative approaches are worked for the SRI task, and the proposed MMSRINet shows the competitive performance and robustness than the other methods on both seen and unseen data, achieving 98.56%, and 98.08% accuracy, respectively.      
### 49.The Powerful Use of AI in the Energy Sector: Intelligent Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2111.02026.pdf)
>  Artificial Intelligence (AI) techniques continue to broaden across governmental and public sectors, such as power and energy - which serve as critical infrastructures for most societal operations. However, due to the requirements of reliability, accountability, and explainability, it is risky to directly apply AI-based methods to power systems because society cannot afford cascading failures and large-scale blackouts, which easily cost billions of dollars. To meet society requirements, this paper proposes a methodology to develop, deploy, and evaluate AI systems in the energy sector by: (1) understanding the power system measurements with physics, (2) designing AI algorithms to forecast the need, (3) developing robust and accountable AI methods, and (4) creating reliable measures to evaluate the performance of the AI model. The goal is to provide a high level of confidence to energy utility users. For illustration purposes, the paper uses power system event forecasting (PEF) as an example, which carefully analyzes synchrophasor patterns measured by the Phasor Measurement Units (PMUs). Such a physical understanding leads to a data-driven framework that reduces the dimensionality with physics and forecasts the event with high credibility. Specifically, for dimensionality reduction, machine learning arranges physical information from different dimensions, resulting inefficient information extraction. For event forecasting, the supervised learning model fuses the results of different models to increase the confidence. Finally, comprehensive experiments demonstrate the high accuracy, efficiency, and reliability as compared to other state-of-the-art machine learning methods.      
### 50.A Strongly-Labelled Polyphonic Dataset of Urban Sounds with Spatiotemporal Context  [ :arrow_down: ](https://arxiv.org/pdf/2111.02006.pdf)
>  This paper introduces SINGA:PURA, a strongly labelled polyphonic urban sound dataset with spatiotemporal context. The data were collected via several recording units deployed across Singapore as a part of a wireless acoustic sensor network. These recordings were made as part of a project to identify and mitigate noise sources in Singapore, but also possess a wider applicability to sound event detection, classification, and localization. This paper introduces an accompanying hierarchical label taxonomy, which has been designed to be compatible with other existing datasets for urban sound tagging while also able to capture sound events unique to the Singaporean context. This paper details the data collection, annotation, and processing methodologies for the creation of the dataset. We further perform exploratory data analysis and include the performance of a baseline model on the dataset as a benchmark.      
### 51.Certifiable Artificial Intelligence Through Data Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2111.02001.pdf)
>  This paper reviews and proposes concerns in adopting, fielding, and maintaining artificial intelligence (AI) systems. While the AI community has made rapid progress, there are challenges in certifying AI systems. Using procedures from design and operational test and evaluation, there are opportunities towards determining performance bounds to manage expectations of intended use. A notional use case is presented with image data fusion to support AI object recognition certifiability considering precision versus distance.      
### 52.Machine-Learning Identification of Hemodynamics in Coronary Arteries in the Presence of Stenosis  [ :arrow_down: ](https://arxiv.org/pdf/2111.01950.pdf)
>  Prediction of the blood flow characteristics is of utmost importance for understanding the behavior of the blood arterial network, especially in the presence of vascular diseases such as stenosis. Computational fluid dynamics (CFD) has provided a powerful and efficient tool to determine these characteristics including the pressure and velocity fields within the network. Despite numerous studies in the field, the extremely high computational cost of CFD has led the researchers to develop new platforms including Machine Learning approaches that instead provide faster analyses at a much lower cost. In this study, we put forth a Deep Neural Network framework to predict flow behavior in a coronary arterial network with different properties in the presence of any abnormality like stenosis. To this end, an artificial neural network (ANN) model is trained using synthetic data so that it can predict the pressure and velocity within the arterial network. The data required to train the neural network were obtained from the CFD analysis of several geometries of arteries with specific features in ABAQUS software. Blood pressure drop caused by stenosis, which is one of the most important factors in the diagnosis of heart diseases, can be predicted using our proposed model knowing the geometrical and flow boundary conditions of any section of the coronary arteries. The efficiency of the model was verified using three real geometries of LAD's vessels. The proposed approach precisely predicts the hemodynamic behavior of the blood flow. The average accuracy of the pressure prediction was 98.7% and the average velocity magnitude accuracy was 93.2%. According to the results of testing the model on three patient-specific geometries, model can be considered as an alternative to finite element methods as well as other hard-to-implement and time-consuming numerical simulations.      
### 53.Noise and dose reduction in CT brain perfusion acquisition by projecting time attenuation curves onto lower dimensional spaces  [ :arrow_down: ](https://arxiv.org/pdf/2111.01922.pdf)
>  CT perfusion imaging (CTP) plays an important role in decision making for the treatment of acute ischemic stroke with large vessel occlusion. Since the CT perfusion scan time is approximately one minute, the patient is exposed to a non-negligible dose of ionizing radiation. However, further dose reduction increases the level of noise in the data and the resulting perfusion maps. We present a method for reducing noise in perfusion data based on dimension reduction of time attenuation curves. For dimension reduction, we use either the fit of the first five terms of the trigonometric polynomial or the first five terms of the SVD decomposition of the time attenuation profiles. CTP data from four patients with large vessel occlusion and three control subjects were studied. To compare the noise level in the perfusion maps, we use the wavelet estimation of the noise standard deviation implemented in the scikit-image package. We show that both methods significantly reduce noise in the data while preserving important information about the perfusion deficits. These methods can be used to further reduce the dose in CT perfusion protocols or in perfusion studies using C-arm CT, which are burdened by high noise levels.      
### 54.Trajectory Splitting: A Distributed Formulation for Collision Avoiding Trajectory Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2111.01899.pdf)
>  Efficient trajectory optimization is essential for avoiding collisions in unstructured environments, but it remains challenging to have both speed and quality in the solutions. One reason is that second-order optimality requires calculating Hessian matrices that can grow with $O(N^2)$ with the number of waypoints. Decreasing the waypoints can quadratically decrease computation time. Unfortunately, fewer waypoints result in lower quality trajectories that may not avoid the collision. To have both, dense waypoints and reduced computation time, we took inspiration from recent studies on consensus optimization and propose a distributed formulation of collocated trajectory optimization. It breaks a long trajectory into several segments, where each segment becomes a subproblem of a few waypoints. These subproblems are solved classically, but in parallel, and the solutions are fused into a single trajectory with a consensus constraint that enforces continuity of the segments through a consensus update. With this scheme, the quadratic complexity is distributed to each segment and enables solving for higher-quality trajectories with denser waypoints. Furthermore, the proposed formulation is amenable to using any existing trajectory optimizer for solving the subproblems. We compare the performance of our implementation of trajectory splitting against leading motion planning algorithms and demonstrate the improved computational efficiency of our method.      
### 55.A dataset for multi-sensor drone detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.01888.pdf)
>  The use of small and remotely controlled unmanned aerial vehicles (UAVs), or drones, has increased in recent years. This goes in parallel with misuse episodes, with an evident threat to the safety of people or facilities. As a result, the detection of UAV has also emerged as a research topic. Most studies on drone detection fail to specify the type of acquisition device, the drone type, the detection range, or the dataset. The lack of proper UAV detection studies employing thermal infrared cameras is also an issue, despite its success with other targets. Besides, we have not found any previous study that addresses the detection task as a function of distance to the target. Sensor fusion is indicated as an open research issue as well, although research in this direction is scarce too. To counteract the mentioned issues and allow fundamental studies with a common public benchmark, we contribute with an annotated multi-sensor database for drone detection that includes infrared and visible videos and audio files. The database includes three different drones, of different sizes and other flying objects that can be mistakenly detected as drones, such as birds, airplanes or helicopters. In addition to using several different sensors, the number of classes is higher than in previous studies. To allow studies as a function of the sensor-to-target distance, the dataset is divided into three categories (Close, Medium, Distant) according to the industry-standard Detect, Recognize and Identify (DRI) requirements, built on the Johnson criteria. Given that the drones must be flown within visual range due to regulations, the largest sensor-to-target distance for a drone is 200 m, and acquisitions are made in daylight. The data has been obtained at three airports in Sweden: Halmstad Airport (IATA code: HAD/ICAO code: ESMT), Gothenburg City Airport (GSE/ESGP) and Malmö Airport (MMX/ESMS).      
### 56.Learning to Operate an Electric Vehicle Charging Station Considering Vehicle-grid Integration  [ :arrow_down: ](https://arxiv.org/pdf/2111.01294.pdf)
>  The rapid adoption of electric vehicles (EVs) calls for the widespread installation of EV charging stations. To maximize the profitability of charging stations, intelligent controllers that provide both charging and electric grid services are in great need. However, it is challenging to determine the optimal charging schedule due to the uncertain arrival time and charging demands of EVs. In this paper, we propose a novel centralized allocation and decentralized execution (CADE) reinforcement learning (RL) framework to maximize the charging station's profit. In the centralized allocation process, EVs are allocated to either the waiting or charging spots. In the decentralized execution process, each charger makes its own charging/discharging decision while learning the action-value functions from a shared replay memory. This CADE framework significantly improves the scalability and sample efficiency of the RL algorithm. Numerical results show that the proposed CADE framework is both computationally efficient and scalable, and significantly outperforms the baseline model predictive control (MPC). We also provide an in-depth analysis of the learned action-value function to explain the inner working of the reinforcement learning agent.      
