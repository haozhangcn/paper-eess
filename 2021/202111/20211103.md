# ArXiv eess --Wed, 3 Nov 2021
### 1.Multi-input Architecture and Disentangled Representation Learning for Multi-dimensional Modeling of Music Similarity  [ :arrow_down: ](https://arxiv.org/pdf/2111.01710.pdf)
>  In the context of music information retrieval, similarity-based approaches are useful for a variety of tasks that benefit from a query-by-example scenario. Music however, naturally decomposes into a set of semantically meaningful factors of variation. Current representation learning strategies pursue the disentanglement of such factors from deep representations, resulting in highly interpretable models. This allows the modeling of music similarity perception, which is highly subjective and multi-dimensional. While the focus of prior work is on metadata driven notions of similarity, we suggest to directly model the human notion of multi-dimensional music similarity. To achieve this, we propose a multi-input deep neural network architecture, which simultaneously processes mel-spectrogram, CENS-chromagram and tempogram in order to extract informative features for the different disentangled musical dimensions: genre, mood, instrument, era, tempo, and key. We evaluated the proposed music similarity approach using a triplet prediction task and found that the proposed multi-input architecture outperforms a state of the art method. Furthermore, we present a novel multi-dimensional analysis in order to evaluate the influence of each disentangled dimension on the perception of music similarity.      
### 2.Antenna Optimization for WBAN Based on Spherical Wave Functions De-Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2111.01708.pdf)
>  Antennas for wireless body area networks (WBAN) need to be modeled with adapted methods because the coupling with the body tissue does not allow for a clear separation between antenna and channel. Especially for dynamically varying on-body channels due to changing body poses, e.g. with head-worn antennas, modeling is challenging and design goals for optimal antennas are difficult to determine. Therefore, in this paper, the modeling of WBAN channels using spherical wave functions (SWF) is utilized for antenna de-embedding and for deriving optimal antenna characteristics that maximize the transmission coefficient for the respective channel. It is evaluated how typical factors influencing WBAN channels (different body anatomies, body postures, and varying positions of the communication nodes), can be modeled statistically with SWF. An optimized antenna design is developed based on the derived optimization method, specifically adapted to the channel of on-body links with eye-wear applications. The results with the optimized antenna are compared to other standard antenna designs and validated against measurements.      
### 3.Small-Signal Stability Techniques for Power System Modal Analysis, Control, and Numerical Integration  [ :arrow_down: ](https://arxiv.org/pdf/2111.01694.pdf)
>  This thesis proposes novel Small-Signal Stability Analysis (SSSA)-based techniques that contribute to electric power system modal analysis, automatic control, and numerical integration. Modal analysis is a fundamental tool for power system stability analysis and control. The thesis proposes a SSSA approach to determine the Participation Factors (PFs) of algebraic variables in power system dynamic modes. The thesis also explores SSSA techniques for the design of power system controllers. The contributions on this topic are twofold: i) Investigate a promising control approach, that is to synthesize automatic regulators for power systems based on the theory of fractional calculus. ii) Propose a novel perspective on the potential impact of time delays on power system stability. Through SSSA, the thesis systematically identifies the control parameter settings for which delays in PSSs improve the damping of a power system. Both analytical and simulation-based results are presented. Finally, SSSA is utilized in the thesis to systematically propose a delay-based method to reduce the coupling of the equations of power system models for transient stability analysis. The method consists in identifying the variables that, when subjected to a delay equal to the time step of the numerical integration, leave practically unchanged the system trajectories. Such an one-step-delay approximation increases the sparsity of the system Jacobian matrices and can be used in conjunction with state-of-the-art techniques for the integration of DAEs. The proposed approach is evaluated in terms of accuracy, convergence and computational burden. Throughout the thesis, the proposed techniques are duly validated through numerical tests based on real-world network models.      
### 4.Recent Advances in End-to-End Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.01690.pdf)
>  Recently, the speech community is seeing a significant trend of moving from deep neural network based hybrid modeling to end-to-end (E2E) modeling for automatic speech recognition (ASR). While E2E models achieve the state-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid models are still used in a large proportion of commercial ASR systems at the current time. There are lots of practical factors that affect the production model deployment decision. Traditional hybrid models, being optimized for production for decades, are usually good at these factors. Without providing excellent solutions to all these factors, it is hard for E2E models to be widely commercialized. In this paper, we will overview the recent advances in E2E models, focusing on technologies addressing those challenges from the industry's perspective.      
### 5.Progressive observation of Covid-19 vaccination effects on skin-cellular structures by use of Intelligent Laser Speckle Classification (ILSC)  [ :arrow_down: ](https://arxiv.org/pdf/2111.01682.pdf)
>  We have made a progressive observation of Covid-19 Astra Zeneca Vaccination effect on Skin cellular network and properties by use of well established Intelligent Laser Speckle Classification (ILSC) image based technique and managed to distinguish between three different subjects groups via their laser speckle skin image samplings such as early-vaccinated, late-vaccinated and non-vaccinated individuals. The results have proven that the ILSC technique in association with the optimised Bayesian network is capable of classifying skin changes of vaccinated and non-vaccinated individuals and also of detecting progressive development made on skin cellular properties for a month period.      
### 6.Explainable Medical Image Segmentation via Generative Adversarial Networks and Layer-wise Relevance Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2111.01665.pdf)
>  This paper contributes to automating medical image segmentation by proposing generative adversarial network-based models to segment both polyps and instruments in endoscopy images. A major contribution of this work is to provide explanations for the predictions using a layer-wise relevance propagation approach designating which input image pixels are relevant to the predictions and to what extent. On the polyp segmentation task, the models achieved 0.84 of accuracy and 0.46 on Jaccard index. On the instrument segmentation task, the models achieved 0.96 of accuracy and 0.70 on Jaccard index. The code is available at <a class="link-external link-https" href="https://github.com/Awadelrahman/MedAI" rel="external noopener nofollow">this https URL</a>.      
### 7.Design and Evaluation of Active Noise Control on Machinery Noise  [ :arrow_down: ](https://arxiv.org/pdf/2111.01652.pdf)
>  Construction workers and residents live near around construction sites are exposed to noises that might cause hearing loss, high blood pressure, heart disease, sleep disturbance and stress. Regulations has been carried out by national governments to limit the maximum permissible noise levels for construction works. A four-channel active noise control system mounted on the opening of an enclosure is designed to prevent the machinery noise from spreading around and retaining the heat diffusion path. Multi-channel FxLMS algorithm in time domain is implemented on the main controller. A Genelec speaker is placed inside the box as the primary noise source to play back different types of noises. Analyses and experiments are carried out to investigate the controllable frequency range of this ANC system in detail. Considerable noise reduction performance is achieved for different recorded practical construction noises.      
### 8.Energy and Resource Efficiency by User Traffic Prediction and Classification in Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.01645.pdf)
>  There is a lack of research on the analysis of per-user traffic in cellular networks, for deriving and following traffic-aware network management. \textcolor{black}{In fact, the legacy design approach, in which resource provisioning and operation control are performed based on the cell-aggregated traffic scenarios, are not so energy- and cost-efficient and need to be substituted with user-centric predictive analysis of mobile network traffic and proactive network resource management.} Here, we shed light on this problem by designing traffic prediction tools that utilize standard machine learning (ML) tools, including long short-term memory (LSTM) and autoregressive integrated moving average (ARIMA) on top of per-user data. We present an expansive empirical evaluation of the designed solutions over a real network traffic dataset. Within this analysis, the impact of different parameters, such as the time granularity, the length of future predictions, and feature selection are investigated. As a potential application of these solutions, we present an ML-powered Discontinuous reception (DRX) scheme for energy saving. Towards this end, we leverage the derived ML models for dynamic DRX parameter adaptation to user traffic. The performance evaluation results demonstrate the superiority of LSTM over ARIMA in general, especially when the length of the training time series is high enough, and it is augmented by a \textit{wisely}-selected set of features. Furthermore, the results show that adaptation of DRX parameters by online prediction of future traffic provides much more energy-saving at low latency cost in comparison with the legacy cell-wide DRX parameter adaptation.      
### 9.Design of Tight Minimum-Sidelobe Windows by Riemannian Newton's Method  [ :arrow_down: ](https://arxiv.org/pdf/2111.01593.pdf)
>  The short-time Fourier transform (STFT), or the discrete Gabor transform (DGT), has been extensively used in signal analysis and processing. Their properties are characterized by a window function, and hence window design is a significant topic up to date. For signal processing, designing a pair of analysis and synthesis windows is important because results of processing in the time-frequency domain are affected by both of them. A tight window is a special window that can perfectly reconstruct a signal by using it for both analysis and synthesis. It is known to make time-frequency-domain processing robust to error, and therefore designing a better tight window is desired. In this paper, we propose a method of designing tight windows that minimize the sidelobe energy. It is formulated as an optimization problem on an oblique manifold, and a Riemannian Newton algorithm on this manifold is derived to efficiently obtain a solution.      
### 10.Sub-cortical structure segmentation database for young population  [ :arrow_down: ](https://arxiv.org/pdf/2111.01561.pdf)
>  Segmentation of sub-cortical structures from MRI scans is of interest in many neurological diagnosis. Since this is a laborious task machine learning and specifically deep learning (DL) methods have become explored. The structural complexity of the brain demands a large, high quality segmentation dataset to develop good DL-based solutions for sub-cortical structure segmentation. Towards this, we are releasing a set of 114, 1.5 Tesla, T1 MRI scans with manual delineations for 14 sub-cortical structures. The scans in the dataset were acquired from healthy young (21-30 years) subjects ( 58 male and 56 female) and all the structures are manually delineated by experienced radiology experts. Segmentation experiments have been conducted with this dataset and results demonstrate that accurate results can be obtained with deep-learning methods.      
### 11.PointNu-Net: Simultaneous Multi-tissue Histology Nuclei Segmentation and Classification in the Clinical Wild  [ :arrow_down: ](https://arxiv.org/pdf/2111.01557.pdf)
>  Automatic nuclei segmentation and classification plays a vital role in digital pathology. However, previous works are mostly built on data with limited diversity and small sizes, making the results questionable or misleading in actual downstream tasks. In this paper, we aim to build a reliable and robust method capable of dealing with data from the 'the clinical wild'. Specifically, we study and design a new method to simultaneously detect, segment, and classify nuclei from Haematoxylin and Eosin (H&amp;E) stained histopathology data, and evaluate our approach using the recent largest dataset: PanNuke. We address the detection and classification of each nuclei as a novel semantic keypoint estimation problem to determine the center point of each nuclei. Next, the corresponding class-agnostic masks for nuclei center points are obtained using dynamic instance segmentation. By decoupling two simultaneous challenging tasks, our method can benefit from class-aware detection and class-agnostic segmentation, thus leading to a significant performance boost. We demonstrate the superior performance of our proposed approach for nuclei segmentation and classification across 19 different tissue types, delivering new benchmark results.      
### 12.Accounting for Dependencies in Deep Learning Based Multiple Instance Learning for Whole Slide Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.01556.pdf)
>  Multiple instance learning (MIL) is a key algorithm for classification of whole slide images (WSI). Histology WSIs can have billions of pixels, which create enormous computational and annotation challenges. Typically, such images are divided into a set of patches (a bag of instances), where only bag-level class labels are provided. Deep learning based MIL methods calculate instance features using convolutional neural network (CNN). Our proposed approach is also deep learning based, with the following two contributions: Firstly, we propose to explicitly account for dependencies between instances during training by embedding self-attention Transformer blocks to capture dependencies between instances. For example, a tumor grade may depend on the presence of several particular patterns at different locations in WSI, which requires to account for dependencies between patches. Secondly, we propose an instance-wise loss function based on instance pseudo-labels. We compare the proposed algorithm to multiple baseline methods, evaluate it on the PANDA challenge dataset, the largest publicly available WSI dataset with over 11K images, and demonstrate state-of-the-art results.      
### 13.Comprehensive and Clinically Accurate Head and Neck Organs at Risk Delineation via Stratified Deep Learning: A Large-scale Multi-Institutional Study  [ :arrow_down: ](https://arxiv.org/pdf/2111.01544.pdf)
>  Accurate organ at risk (OAR) segmentation is critical to reduce the radiotherapy post-treatment complications. Consensus guidelines recommend a set of more than 40 OARs in the head and neck (H&amp;N) region, however, due to the predictable prohibitive labor-cost of this task, most institutions choose a substantially simplified protocol by delineating a smaller subset of OARs and neglecting the dose distributions associated with other OARs. In this work we propose a novel, automated and highly effective stratified OAR segmentation (SOARS) system using deep learning to precisely delineate a comprehensive set of 42 H&amp;N OARs. SOARS stratifies 42 OARs into anchor, mid-level, and small &amp; hard subcategories, with specifically derived neural network architectures for each category by neural architecture search (NAS) principles. We built SOARS models using 176 training patients in an internal institution and independently evaluated on 1327 external patients across six different institutions. It consistently outperformed other state-of-the-art methods by at least 3-5% in Dice score for each institutional evaluation (up to 36% relative error reduction in other metrics). More importantly, extensive multi-user studies evidently demonstrated that 98% of the SOARS predictions need only very minor or no revisions for direct clinical acceptance (saving 90% radiation oncologists workload), and their segmentation and dosimetric accuracy are within or smaller than the inter-user variation. These findings confirmed the strong clinical applicability of SOARS for the OAR delineation process in H&amp;N cancer radiotherapy workflows, with improved efficiency, comprehensiveness, and quality.      
### 14.ISP-Agnostic Image Reconstruction for Under-Display Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2111.01511.pdf)
>  Under-display cameras have been proposed in recent years as a way to reduce the form factor of mobile devices while maximizing the screen area. Unfortunately, placing the camera behind the screen results in significant image distortions, including loss of contrast, blur, noise, color shift, scattering artifacts, and reduced light sensitivity. In this paper, we propose an image-restoration pipeline that is ISP-agnostic, i.e. it can be combined with any legacy ISP to produce a final image that matches the appearance of regular cameras using the same ISP. This is achieved with a deep learning approach that performs a RAW-to-RAW image restoration. To obtain large quantities of real under-display camera training data with sufficient contrast and scene diversity, we furthermore develop a data capture method utilizing an HDR monitor, as well as a data augmentation method to generate suitable HDR content. The monitor data is supplemented with real-world data that has less scene diversity but allows us to achieve fine detail recovery without being limited by the monitor resolution. Together, this approach successfully restores color and contrast as well as image detail.      
### 15.Out of distribution detection for skin and malaria images  [ :arrow_down: ](https://arxiv.org/pdf/2111.01505.pdf)
>  Deep neural networks have shown promising results in disease detection and classification using medical image data. However, they still suffer from the challenges of handling real-world scenarios especially reliably detecting out-of-distribution (OoD) samples. We propose an approach to robustly classify OoD samples in skin and malaria images without the need to access labeled OoD samples during training. Specifically, we use metric learning along with logistic regression to force the deep networks to learn much rich class representative features. To guide the learning process against the OoD examples, we generate ID similar-looking examples by either removing class-specific salient regions in the image or permuting image parts and distancing them away from in-distribution samples. During inference time, the K-reciprocal nearest neighbor is employed to detect out-of-distribution samples. For skin cancer OoD detection, we employ two standard benchmark skin cancer ISIC datasets as ID, and six different datasets with varying difficulty levels were taken as out of distribution. For malaria OoD detection, we use the BBBC041 malaria dataset as ID and five different challenging datasets as out of distribution. We achieved state-of-the-art results, improving 5% and 4% in TNR@TPR95% over the previous state-of-the-art for skin cancer and malaria OoD detection respectively.      
### 16.The Multiplicative Compound of a Matrix Pencil with Applications to Difference-Algebraic Equations  [ :arrow_down: ](https://arxiv.org/pdf/2111.01419.pdf)
>  The multiplicative and additive compounds of a matrix have important applications in geometry, linear algebra, and dynamical systems described by difference equations and by ordinary differential equations. Here, we introduce a generalization of the multiplicative compound to matrix pencils. We analyze the properties of this new compound and describe several applications to the analysis of discrete-time dynamical systems described by difference-algebraic equations.      
### 17.Terahertz-Band Non-Orthogonal Multiple Access: System- and Link-Level Considerations  [ :arrow_down: ](https://arxiv.org/pdf/2111.01412.pdf)
>  Non-orthogonal multiple access (NOMA) communications promise high spectral efficiency and massive connectivity, serving multiple users over the same time-frequency-code resources. Higher data rates and massive connectivity are also achieved by leveraging wider bandwidths at higher frequencies, especially in the terahertz (THz) band. This work investigates the prospects and challenges of combining these algorithmic and spectrum enablers in THz-band NOMA communications. We consider power-domain NOMA coupled with successive interference cancellation at the receiver, focusing on multiple-input multiple-output (MIMO) systems as antenna arrays are crucial for THz communications. On the system level, we study the scalability of THz-NOMA beamforming, clustering, and spectrum/power allocation algorithms and motivate stochastic geometry techniques for performance analysis and system modeling. On the link level, we highlight the challenges in channel estimation and data detection and the constraints on computational complexity. We further illustrate future research directions. When properly configured and given sufficient densification, THz-band NOMA communications can significantly improve the performance and capacity of future wireless networks.      
### 18.Constructing High-Order Signed Distance Maps from Computed Tomography Data with Application to Bone Morphometry  [ :arrow_down: ](https://arxiv.org/pdf/2111.01350.pdf)
>  An algorithm is presented for constructing high-order signed distance fields for two phase materials imaged with computed tomography. The signed distance field is high-order in that it is free of the quantization artifact associated with the distance transform of sampled signals. The narrowband is solved using a closest point algorithm extended for implicit embeddings that are not a signed distance field. The high-order fast sweeping algorithm is used to extend the narrowband to the remainder of the domain. The order of accuracy of the narrowband and extension methods are verified on ideal implicit surfaces. The method is applied to ten excised cubes of bovine trabecular bone. Localization of the surface, estimation of phase densities, and local morphometry is validated with these subjects. Since the embedding is high-order, gradients and thus curvatures can be accurately estimated locally in the image data.      
### 19.Federated Split Vision Transformer for COVID-19 CXR Diagnosis using Task-Agnostic Training  [ :arrow_down: ](https://arxiv.org/pdf/2111.01338.pdf)
>  Federated learning, which shares the weights of the neural network across clients, is gaining attention in the healthcare sector as it enables training on a large corpus of decentralized data while maintaining data privacy. For example, this enables neural network training for COVID-19 diagnosis on chest X-ray (CXR) images without collecting patient CXR data across multiple hospitals. Unfortunately, the exchange of the weights quickly consumes the network bandwidth if highly expressive network architecture is employed. So-called split learning partially solves this problem by dividing a neural network into a client and a server part, so that the client part of the network takes up less extensive computation resources and bandwidth. However, it is not clear how to find the optimal split without sacrificing the overall network performance. To amalgamate these methods and thereby maximize their distinct strengths, here we show that the Vision Transformer, a recently developed deep learning architecture with straightforward decomposable configuration, is ideally suitable for split learning without sacrificing performance. Even under the non-independent and identically distributed data distribution which emulates a real collaboration between hospitals using CXR datasets from multiple sources, the proposed framework was able to attain performance comparable to data-centralized training. In addition, the proposed framework along with heterogeneous multi-task clients also improves individual task performances including the diagnosis of COVID-19, eliminating the need for sharing large weights with innumerable parameters. Our results affirm the suitability of Transformer for collaborative learning in medical imaging and pave the way forward for future real-world implementations.      
### 20.Cross-lingual Transfer for Speech Processing using Acoustic Language Similarity  [ :arrow_down: ](https://arxiv.org/pdf/2111.01326.pdf)
>  Speech processing systems currently do not support the vast majority of languages, in part due to the lack of data in low-resource languages. Cross-lingual transfer offers a compelling way to help bridge this digital divide by incorporating high-resource data into low-resource systems. Current cross-lingual algorithms have shown success in text-based tasks and speech-related tasks over some low-resource languages. However, scaling up speech systems to support hundreds of low-resource languages remains unsolved. To help bridge this gap, we propose a language similarity approach that can efficiently identify acoustic cross-lingual transfer pairs across hundreds of languages. We demonstrate the effectiveness of our approach in language family classification, speech recognition, and speech synthesis tasks.      
### 21.AVASpeech-SMAD: A Strongly Labelled Speech and Music Activity Detection Dataset with Label Co-Occurrence  [ :arrow_down: ](https://arxiv.org/pdf/2111.01320.pdf)
>  We propose a dataset, AVASpeech-SMAD, to assist speech and music activity detection research. With frame-level music labels, the proposed dataset extends the existing AVASpeech dataset, which originally consists of 45 hours of audio and speech activity labels. To the best of our knowledge, the proposed AVASpeech-SMAD is the first open-source dataset that features strong polyphonic labels for both music and speech. The dataset was manually annotated and verified via an iterative cross-checking process. A simple automatic examination was also implemented to further improve the quality of the labels. Evaluation results from two state-of-the-art SMAD systems are also provided as a benchmark for future reference.      
### 22.DaDRA: A Python Library for Data-Driven Reachability Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.01312.pdf)
>  Reachability analysis is used to determine all possible states that a system acting under uncertainty may reach. It is a critical component to obtain guarantees of various safety-critical systems both for safety verification and controller synthesis. Though traditional approaches to reachability analysis provide formal guarantees of the reachable set, they involve complex algorithms that require full system information, which is impractical for use in real world settings. We present DaDRA, a Python library that allows for data-driven reachability analysis with arbitrarily robust probabilistic guarantees. We demonstrate the practical functionality of DaDRA on various systems including: an analytically intractable chaotic system, benchmarks for systems with nonlinear dynamics, and a realistic system acting under complex disturbance signals and controlled with an intricate controller across multiple dimensions.      
### 23.Verifying Contracts for Perturbed Control Systems using Linear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2111.01259.pdf)
>  Verifying specifications for large-scale control systems is of utmost importance, but can be hard in practice as most formal verification methods can not handle high-dimensional dynamics. Contract theory has been proposed as a modular alternative to formal verification in which specifications are defined by assumptions on the inputs to a component and guarantees on its outputs. In this paper, we present linear-programming-based tools for verifying contracts for control systems. We first consider the problem of verifying contracts defined by time-invariant inequalities for unperturbed systems. We use $k$-induction to show that contract verification can be achieved by considering a collection of implications between inequalities, which are then recast as linear programs. We then move our attention to perturbed systems. We present a comparison-based framework, verifying that a perturbed system satisfies a contract by checking that the corresponding unperturbed system satisfies a robustified (and $\epsilon$-approximated) contract. In both cases, we present explicit algorithms for contract verification, proving their correctness and analyzing their complexity. We also demonstrate the verification process for two case studies, one considering a two-vehicle autonomous driving scenario, and one considering formation control of a multi-agent system.      
### 24.Beyond Point Clouds: A Knowledge-Aided High Resolution Imaging Radar Deep Detector for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2111.01246.pdf)
>  The potentials of automotive radar for autonomous driving have not been fully exploited. We present a multi-input multi-output (MIMO) radar transmit and receive signal processing chain, a knowledge-aided approach exploiting the radar domain knowledge and signal structure, to generate high resolution radar range-azimuth spectra for object detection and classification using deep neural networks. To achieve waveform orthogonality among a large number of transmit antennas cascaded by four automotive radar transceivers, we propose a staggered time division multiplexing (TDM) scheme and velocity unfolding algorithm using both Chinese remainder theorem and overlapped array. Field experiments with multi-modal sensors were conducted at The University of Alabama. High resolution radar spectra were obtained and labeled using the camera and LiDAR recordings. Initial experiments show promising performance of object detection using an image-oriented deep neural network with an average precision of 96.1% at an intersection of union (IoU) of typically 0.5 on 2,000 radar frames.      
### 25.OPF-Learn: An Open-Source Framework for Creating Representative AC Optimal Power Flow Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2111.01228.pdf)
>  Increasing levels of renewable generation motivate a growing interest in data-driven approaches for AC optimal power flow (AC OPF) to manage uncertainty; however, a lack of disciplined dataset creation and benchmarking prohibits useful comparison among approaches in the literature. To instill confidence, models must be able to reliably predict solutions across a wide range of operating conditions. This paper develops the OPF-Learn package for Julia and Python, which uses a computationally efficient approach to create representative datasets that span a wide spectrum of the AC OPF feasible region. Load profiles are uniformly sampled from a convex set that contains the AC OPF feasible set. For each infeasible point found, the convex set is reduced using infeasibility certificates, found by using properties of a relaxed formulation. The framework is shown to generate datasets that are more representative of the entire feasible space versus traditional techniques seen in the literature, improving machine learning model performance.      
### 26.A Tool for Reliability Assessment of Smart and Active Distribution Systems -- RELSAD  [ :arrow_down: ](https://arxiv.org/pdf/2111.01195.pdf)
>  With increased penetration of new technology in the distribution systems such as renewable energy resources, flexible resources, and information and communication technology, the distribution systems become more complex and dynamic. The traditional reliability analysis methods do not consider the new components and technology and new considerations need to be taken to address these new changes in the distribution system. This paper presents an open-source reliability assessment tool for smart and active distribution systems (RELSAD). The tool aims to function as a foundation for reliability calculation in the smart and active distribution systems, where these new components and technologies are included. The tool is made as a Python package built up based on an object-oriented programming approach. The method will be illustrated on the IEEE 33-bus system with the inclusion of generation, battery, and ICT.      
### 27.Correlation based Imaging for rotating satellites  [ :arrow_down: ](https://arxiv.org/pdf/2111.01184.pdf)
>  We consider imaging of fast moving small objects in space, such as low earth orbit satellites, which are also rotating around a fixed axis. The imaging system consists of ground based, asynchronous sources of radiation and several passive receivers above the dense atmosphere. We use the cross-correlation of the received signals to reduce distortions from ambient medium fluctuations. Imaging with correlations also has the advantage of not requiring any knowledge about the probing pulse and depends weakly on the emitter positions. We account for the target's orbital velocity by introducing the necessary Doppler compensation. To image a fast rotating object we also need to compensate for the rotation. We show that the rotation parameters can be extracted directly from the auto-correlation of the data before the formation of the image. We then investigate and analyze an imaging method that relies on backpropagating the cross-correlation data structure to two points rather than one, thus forming an interference matrix. The proposed imaging method consists of estimating the reflectivity as the top eigenvector of the migrated cross-correlation data interference matrix. We call this the rank-1 image and show that it provides superior image resolution compared to the usual single-point migration scheme for fast moving and rotating objects. Moreover, we observe a significant improvement in resolution due to the rotation leading to a diffraction limited resolution. We carry out a theoretical analysis that illustrates the role of the two point migration method as well as that of the inverse aperture and rotation in improving resolution. Extensive numerical simulations support the theoretical results.      
### 28.Comparing Bayesian Models for Organ Contouring in Headand Neck Radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2111.01134.pdf)
>  Deep learning models for organ contouring in radiotherapy are poised for clinical usage, but currently, there exist few tools for automated quality assessment (QA) of the predicted contours. Using Bayesian models and their associated uncertainty, one can potentially automate the process of detecting inaccurate predictions. We investigate two Bayesian models for auto-contouring, DropOut and FlipOut, using a quantitative measure - expected calibration error (ECE) and a qualitative measure - region-based accuracy-vs-uncertainty (R-AvU) graphs. It is well understood that a model should have low ECE to be considered trustworthy. However, in a QA context, a model should also have high uncertainty in inaccurate regions and low uncertainty in accurate regions. Such behaviour could direct visual attention of expert users to potentially inaccurate regions, leading to a speed up in the QA process. Using R-AvU graphs, we qualitatively compare the behaviour of different models in accurate and inaccurate regions. Experiments are conducted on the MICCAI2015 Head and Neck Segmentation Challenge and on the DeepMindTCIA CT dataset using three models: DropOut-DICE, Dropout-CE (Cross Entropy) and FlipOut-CE. Quantitative results show that DropOut-DICE has the highest ECE, while Dropout-CE and FlipOut-CE have the lowest ECE. To better understand the difference between DropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE has better uncertainty coverage in inaccurate regions than DropOut-CE. Such a combination of quantitative and qualitative metrics explores a new approach that helps to select which model can be deployed as a QA tool in clinical settings.      
### 29.A Framework for Real-World Multi-Robot Systems Running Decentralized GNN-Based Policies  [ :arrow_down: ](https://arxiv.org/pdf/2111.01777.pdf)
>  Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to facilitate the learning of complex multi-agent behaviors. Recent work has demonstrated remarkable performance in tasks such as flocking, multi-agent path planning and cooperative coverage. However, the policies derived through GNN-based learning schemes have not yet been deployed to the real-world on physical multi-robot systems. In this work, we present the design of a system that allows for fully decentralized execution of GNN-based policies. We create a framework based on ROS2 and elaborate its details in this paper. We demonstrate our framework on a case-study that requires tight coordination between robots, and present first-of-a-kind results that show successful real-world deployment of GNN-based policies on a decentralized multi-robot system relying on Adhoc communication. A video demonstration of this case-study can be found online. <a class="link-external link-https" href="https://www.youtube.com/watch?v=COh-WLn4iO4" rel="external noopener nofollow">this https URL</a>      
### 30.Universal Path Gain Laws for Common Wireless Communication Environments  [ :arrow_down: ](https://arxiv.org/pdf/2111.01758.pdf)
>  Simple and accurate expressions for path gain are derived from electromagnetic fundamentals in a wide variety of common environments, including Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS) indoor urban canyons, urban/rural macro, outdoor-indoor and suburban streets with vegetation. Penetration into a scattering region, sometimes aided by guiding, is the "universal" phenomenon shared by the diverse morphologies. Root Mean Square (RMS) errors against extensive measurements are under 5 dB, better than 3GPP models by 1-12 dB RMS, depending on environment. In urban canyons the models have 4.7 dB RMS error, as compared to 7.9 dB from linear fit to data and 13.9/17.2 dB from LOS/NLOS 3GPP models. The theoretical path gains depend on distance as a power law with exponents from a small set {1.5, 2, 2.5, 4}, specific to each morphology. This provides a theoretical justification for widely used power law empirical models. Only coarse environmental data is needed as parameters: street width, building height, vegetation depth, wall material and antenna heights.      
### 31.Spiking Generative Adversarial Networks With a Neural Network Discriminator: Local Training, Bayesian Models, and Continual Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.01750.pdf)
>  Neuromorphic data carries information in spatio-temporal patterns encoded by spikes. Accordingly, a central problem in neuromorphic computing is training spiking neural networks (SNNs) to reproduce spatio-temporal spiking patterns in response to given spiking stimuli. Most existing approaches model the input-output behavior of an SNN in a deterministic fashion by assigning each input to a specific desired output spiking sequence. In contrast, in order to fully leverage the time-encoding capacity of spikes, this work proposes to train SNNs so as to match distributions of spiking signals rather than individual spiking signals. To this end, the paper introduces a novel hybrid architecture comprising a conditional generator, implemented via an SNN, and a discriminator, implemented by a conventional artificial neural network (ANN). The role of the ANN is to provide feedback during training to the SNN within an adversarial iterative learning strategy that follows the principle of generative adversarial network (GANs). In order to better capture multi-modal spatio-temporal distribution, the proposed approach -- termed SpikeGAN -- is further extended to support Bayesian learning of the generator's weight. Finally, settings with time-varying statistics are addressed by proposing an online meta-learning variant of SpikeGAN. Experiments bring insights into the merits of the proposed approach as compared to existing solutions based on (static) belief networks and maximum likelihood (or empirical risk minimization).      
### 32.Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters  [ :arrow_down: ](https://arxiv.org/pdf/2111.01701.pdf)
>  Single-point zeroth-order optimization (SZO) is suitable for solving online black-box optimization and simulation-based learning-to-control problems. However, the vanilla SZO method suffers from a larger variance and slow convergence, which seriously limits its practical application. On the other hand, extremum seeking (ES) control is regarded as the continuous-time version of SZO, while they have been mostly studied separately in the control and optimization communities despite the close relation. In this work, we borrow the idea of high-pass and low-pass filters from ES control to improve the performance of SZO. Specifically, we develop a novel SZO method called HLF-SZO, by integrating a high-pass filter and a low-pass filter into the vanilla SZO method. Interestingly, it turns out that the integration of a high-pass filter coincides with the residual-feedback SZO method, and the integration of a low-pass filter can be interpreted as the momentum method. We prove that HLF-SZO achieves a convergence rate of $O(d/T^{\frac{2}{3}})$ for Lipschitz and smooth objective functions (in both convex and nonconvex cases). Extensive numerical experiments show that the high-pass filter can significantly reduce the variance and the low-pass filter can accelerate the convergence. As a result, the proposed HLF-SZO has a much smaller variance and much faster convergence compared with the vanilla SZO method, and empirically outperforms the state-of-the-art residual-feedback SZO method.      
### 33.Efficient hierarchical Bayesian inference for spatio-temporal regression models in neuroimaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.01692.pdf)
>  Several problems in neuroimaging and beyond require inference on the parameters of multi-task sparse hierarchical regression models. Examples include M/EEG inverse problems, neural encoding models for task-based fMRI analyses, and temperature monitoring of climate or CPU and GPU. In these domains, both the model parameters to be inferred and the measurement noise may exhibit a complex spatio-temporal structure. Existing work either neglects the temporal structure or leads to computationally demanding inference schemes. Overcoming these limitations, we devise a novel flexible hierarchical Bayesian framework within which the spatio-temporal dynamics of model parameters and noise are modeled to have Kronecker product covariance structure. Inference in our framework is based on majorization-minimization optimization and has guaranteed convergence properties. Our highly efficient algorithms exploit the intrinsic Riemannian geometry of temporal autocovariance matrices. For stationary dynamics described by Toeplitz matrices, the theory of circulant embeddings is employed. We prove convex bounding properties and derive update rules of the resulting algorithms. On both synthetic and real neural data from M/EEG, we demonstrate that our methods lead to improved performance.      
### 34.Saliency detection with moving camera via background model completion  [ :arrow_down: ](https://arxiv.org/pdf/2111.01681.pdf)
>  To detect saliency in video is a fundamental step in many computer vision systems. Saliency is the significant target(s) in the video. The object of interest is further analyzed for high-level applications. The segregation of saliency and the background can be made if they exhibit different visual cues. Therefore, saliency detection is often formulated as background subtraction. However, saliency detection is challenging. For instance, dynamic background can result in false positive errors. In another scenario, camouflage will lead to false negative errors. With moving camera, the captured scenes are even more complicated to handle. We propose a new framework, called saliency detection via background model completion (SD-BMC), that comprises of a background modeler and the deep learning background/foreground segmentation network. The background modeler generates an initial clean background image from a short image sequence. Based on the idea of video completion, a good background frame can be synthesized with the co-existence of changing background and moving objects. We adopt the background/foreground segmenter, although pre-trained with a specific video dataset, can also detect saliency in unseen videos. The background modeler can adjust the background image dynamically when the background/foreground segmenter output deteriorates during processing of a long video. To the best of our knowledge, our framework is the first one to adopt video completion for background modeling and saliency detection in videos captured by moving camera. The results, obtained from the PTZ videos, show that our proposed framework outperforms some deep learning-based background subtraction models by 11% or more. With more challenging videos, our framework also outperforms many high ranking background subtraction methods by more than 3%.      
### 35.A Tri-attention Fusion Guided Multi-modal Segmentation Network  [ :arrow_down: ](https://arxiv.org/pdf/2111.01623.pdf)
>  In the field of multimodal segmentation, the correlation between different modalities can be considered for improving the segmentation results. Considering the correlation between different MR modalities, in this paper, we propose a multi-modality segmentation network guided by a novel tri-attention fusion. Our network includes N model-independent encoding paths with N image sources, a tri-attention fusion block, a dual-attention fusion block, and a decoding path. The model independent encoding paths can capture modality-specific features from the N modalities. Considering that not all the features extracted from the encoders are useful for segmentation, we propose to use dual attention based fusion to re-weight the features along the modality and space paths, which can suppress less informative features and emphasize the useful ones for each modality at different positions. Since there exists a strong correlation between different modalities, based on the dual attention fusion block, we propose a correlation attention module to form the tri-attention fusion block. In the correlation attention module, a correlation description block is first used to learn the correlation between modalities and then a constraint based on the correlation is used to guide the network to learn the latent correlated features which are more relevant for segmentation. Finally, the obtained fused feature representation is projected by the decoder to obtain the segmentation results. Our experiment results tested on BraTS 2018 dataset for brain tumor segmentation demonstrate the effectiveness of our proposed method.      
### 36.Detect-and-Segment: a Deep Learning Approach to Automate Wound Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.01590.pdf)
>  Chronic wounds significantly impact quality of life. If not properly managed, they can severely deteriorate. Image-based wound analysis could aid in objectively assessing the wound status by quantifying important features that are related to healing. However, the high heterogeneity of the wound types, image background composition, and capturing conditions challenge the robust segmentation of wound images. We present Detect-and-Segment (DS), a deep learning approach to produce wound segmentation maps with high generalization capabilities. In our approach, dedicated deep neural networks detected the wound position, isolated the wound from the uninformative background, and computed the wound segmentation map. We evaluated this approach using one data set with images of diabetic foot ulcers. For further testing, 4 supplemental independent data sets with larger variety of wound types from different body locations were used. The Matthews' correlation coefficient (MCC) improved from 0.29 when computing the segmentation on the full image to 0.85 when combining detection and segmentation in the same approach. When tested on the wound images drawn from the supplemental data sets, the DS approach increased the mean MCC from 0.17 to 0.85. Furthermore, the DS approach enabled the training of segmentation models with up to 90% less training data while maintaining the segmentation performance.      
### 37.Is RIS-Aided Massive MIMO Promising with ZF Detectors and Imperfect CSI?  [ :arrow_down: ](https://arxiv.org/pdf/2111.01585.pdf)
>  This paper provides a theoretical framework for understanding the performance of reconfigurable intelligent surface (RIS)-aided massive multiple-input multiple-output (MIMO) with zero-forcing (ZF) detectors under imperfect channel state information (CSI). We first propose a low-overhead minimum mean square error (MMSE) channel estimator, and then derive and analyze closed-form expressions for the uplink achievable rate. Our analytical results demonstrate that: $1)$ regardless of the RIS phase shift design, the rate of all users scales at least on the order of $\mathcal{O}\left(\log_2\left(MN\right)\right)$, where $M$ and $N$ are the numbers of antennas and reflecting elements, respectively; $2)$ by aligning the RIS phase shifts to one user, the rate of this user can at most scale on the order of $\mathcal{O}\left(\log_2\left(MN^2\right)\right)$; $3)$ either $M$ or the transmit power can be reduced inversely proportional to $N$, while maintaining a given rate. Furthermore, we propose two low-complexity majorization-minimization (MM)-based algorithms to optimize the sum user rate and the minimum user rate, respectively, where closed-form solutions are obtained in each iteration. Finally, simulation results validate all derived analytical results. Our simulation results also show that the maximum sum rate can be closely approached by simply aligning the RIS phase shifts to an arbitrary user.      
### 38.Physical Channel Modeling for RIS-Empowered Wireless Networks in Sub-6 GHz Bands  [ :arrow_down: ](https://arxiv.org/pdf/2111.01537.pdf)
>  Reconfigurable intelligent surface (RIS)-assisted communications is one of the promising candidates for next generation wireless networks by controlling the propagation environment dynamically. In this study, a channel modeling strategy for RIS-assisted wireless networks is introduced in sub-6 GHz bands by considering both far-field and near-field behaviours in transmission. We also proposed an open-source physical channel simulator for sub-6 GHz bands where operating frequency, propagation environment, terminal locations, RIS location and size can be adjusted. It is demonstrated via extensive computer simulations that an improved achievable rate performance is obtained in the presence of RISs for both near-field and far-field conditions.      
### 39.CycleGAN with Dual Adversarial Loss for Bone-Conducted Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2111.01430.pdf)
>  Compared with air-conducted speech, bone-conducted speech has the unique advantage of shielding background noise. Enhancement of bone-conducted speech helps to improve its quality and intelligibility. In this paper, a novel CycleGAN with dual adversarial loss (CycleGAN-DAL) is proposed for bone-conducted speech enhancement. The proposed method uses an adversarial loss and a cycle-consistent loss simultaneously to learn forward and cyclic mapping, in which the adversarial loss is replaced with the classification adversarial loss and the defect adversarial loss to consolidate the forward mapping. Compared with conventional baseline methods, it can learn feature mapping between bone-conducted speech and target speech without additional air-conducted speech assistance. Moreover, the proposed method also avoids the oversmooth problem which is occurred commonly in conventional statistical based models. Experimental results show that the proposed method outperforms baseline methods such as CycleGAN, GMM, and BLSTM. Keywords: Bone-conducted speech enhancement, dual adversarial loss, Parallel CycleGAN, high frequency speech reconstruction      
### 40.Attention-Guided Generative Adversarial Network for Whisper to Normal Speech Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2111.01342.pdf)
>  Whispered speech is a special way of pronunciation without using vocal cord vibration. A whispered speech does not contain a fundamental frequency, and its energy is about 20dB lower than that of a normal speech. Converting a whispered speech into a normal speech can improve speech quality and intelligibility. In this paper, a novel attention-guided generative adversarial network model incorporating an autoencoder, a Siamese neural network, and an identity mapping loss function for whisper to normal speech conversion (AGAN-W2SC) is proposed. The proposed method avoids the challenge of estimating the fundamental frequency of the normal voiced speech converted from a whispered speech. Specifically, the proposed model is more amendable to practical applications because it does not need to align speech features for training. Experimental results demonstrate that the proposed AGAN-W2SC can obtain improved speech quality and intelligibility compared with dynamic-time-warping-based methods.      
### 41.Attribute-Based Deep Periocular Recognition: Leveraging Soft Biometrics to Improve Periocular Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.01325.pdf)
>  In recent years, periocular recognition has been developed as a valuable biometric identification approach, especially in wild environments (for example, masked faces due to COVID-19 pandemic) where facial recognition may not be applicable. This paper presents a new deep periocular recognition framework called attribute-based deep periocular recognition (ADPR), which predicts soft biometrics and incorporates the prediction into a periocular recognition algorithm to determine identity from periocular images with high accuracy. We propose an end-to-end framework, which uses several shared convolutional neural network (CNN)layers (a common network) whose output feeds two separate dedicated branches (modality dedicated layers); the first branch classifies periocular images while the second branch predicts softn biometrics. Next, the features from these two branches are fused together for a final periocular recognition. The proposed method is different from existing methods as it not only uses a shared CNN feature space to train these two tasks jointly, but it also fuses predicted soft biometric features with the periocular features in the training step to improve the overall periocular recognition performance. Our proposed model is extensively evaluated using four different publicly available datasets. Experimental results indicate that our soft biometric based periocular recognition approach outperforms other state-of-the-art methods for periocular recognition in wild environments.      
### 42.Sequence Transduction with Graph-based Supervision  [ :arrow_down: ](https://arxiv.org/pdf/2111.01272.pdf)
>  The recurrent neural network transducer (RNN-T) objective plays a major role in building today's best automatic speech recognition (ASR) systems for production. Similarly to the connectionist temporal classification (CTC) objective, the RNN-T loss uses specific rules that define how a set of alignments is generated to form a lattice for the full-sum training. However, it is yet largely unknown if these rules are optimal and do lead to the best possible ASR results. In this work, we present a new transducer objective function that generalizes the RNN-T loss to accept a graph representation of the labels, thus providing a flexible and efficient framework to manipulate training lattices, for example for restricting alignments or studying different transition rules. We demonstrate that transducer-based ASR with CTC-like lattice achieves better results compared to standard RNN-T, while also ensuring a strictly monotonic alignment, which will allow better optimization of the decoding procedure. For example, the proposed CTC-like transducer system achieves a word error rate of 5.9% for the test-other condition of LibriSpeech, corresponding to an improvement of 4.8% relative to an equivalent RNN-T based system.      
### 43.Quantifying Shareability in Transportation Networks: The Maximum Network Flow Overlap Problem  [ :arrow_down: ](https://arxiv.org/pdf/2111.01266.pdf)
>  Cities across the world vary in terms of their urban forms, transportation networks, and travel demand patterns with the variation affecting the viability of different shared mobility modes ranging from mass transit to ridesharing. This study proposes a modeling framework to quantify the shareability of person flows in any city as a function of two inputs--the underlying transportation (street) network and origin-destination (OD) travel demand in the network--as a first step toward a deeper understanding of the joint influence of these factors on the viability of shared mobility modes. This study conceptualizes flow overlap to denote, for a person trip traversing a given path, the weighted (by link distance) average number of other travelers sharing the links along the person's path. The study extends this concept and formulates the Maximum Network Flow Overlap Problem (MNFLOP) to assign all O-D person flows to the network paths that maximize flow overlap in the region. The study also proposes an MNFLOP variant with a second objective function term, OD flow detours, to capture the trade-off between minimizing travel distance/time and increasing shareability. The study utilizes the MNFLOP output to calculate measures of shareability at various levels of aggregation, including, single location, single and multiple ODs, individual links, and network level. The study applies the MNFLOP to networks in Sioux Falls and Chicago. Results show that with minor increases in traveler detour, it is possible to significantly increase flow overlap relative to assigning all OD flows to their shortest paths. Origin level measures of flow overlap indicate potential to share trips even from locations with low demand, as long as the trips can be concentrated onto a few paths, showing that critical demand assessment for operating shared mobility modes is guided by both magnitude and directionality of demand.      
### 44.Minimax Optimization: The Case of Convex-Submodular  [ :arrow_down: ](https://arxiv.org/pdf/2111.01262.pdf)
>  Minimax optimization has been central in addressing various applications in machine learning, game theory, and control theory. Prior literature has thus far mainly focused on studying such problems in the continuous domain, e.g., convex-concave minimax optimization is now understood to a significant extent. Nevertheless, minimax problems extend far beyond the continuous domain to mixed continuous-discrete domains or even fully discrete domains. In this paper, we study mixed continuous-discrete minimax problems where the minimization is over a continuous variable belonging to Euclidean space and the maximization is over subsets of a given ground set. We introduce the class of convex-submodular minimax problems, where the objective is convex with respect to the continuous variable and submodular with respect to the discrete variable. Even though such problems appear frequently in machine learning applications, little is known about how to address them from algorithmic and theoretical perspectives. For such problems, we first show that obtaining saddle points are hard up to any approximation, and thus introduce new notions of (near-) optimality. We then provide several algorithmic procedures for solving convex and monotone-submodular minimax problems and characterize their convergence rates, computational complexity, and quality of the final solution according to our notions of optimally. Our proposed algorithms are iterative and combine tools from both discrete and continuous optimization. Finally, we provide numerical experiments to showcase the effectiveness of our purposed methods.      
### 45.Safe Online Gain Optimization for Variable Impedance Control  [ :arrow_down: ](https://arxiv.org/pdf/2111.01258.pdf)
>  Smooth behaviors are preferable for many contact-rich manipulation tasks. Impedance control arises as an effective way to regulate robot movements by mimicking a mass-spring-damping system. Consequently, the robot behavior can be determined by the impedance gains. However, tuning the impedance gains for different tasks is tricky, especially for unstructured environments. Moreover, online adapting the optimal gains to meet the time-varying performance index is even more challenging. In this paper, we present Safe Online Gain Optimization for Variable Impedance Control (Safe OnGO-VIC). By reformulating the dynamics of impedance control as a control-affine system, in which the impedance gains are the inputs, we provide a novel perspective to understand variable impedance control. Additionally, we innovatively formulate an optimization problem with online collected force information to obtain the optimal impedance gains in real-time. Safety constraints are also embedded in the proposed framework to avoid unwanted collisions. We experimentally validated the proposed algorithm on three manipulation tasks. Comparison results with a constant gain baseline and an adaptive control method prove that the proposed algorithm is effective and generalizable to different scenarios.      
### 46.Learning To Generate Piano Music With Sustain Pedals  [ :arrow_down: ](https://arxiv.org/pdf/2111.01216.pdf)
>  Recent years have witnessed a growing interest in research related to the detection of piano pedals from audio signals in the music information retrieval community. However, to our best knowledge, recent generative models for symbolic music have rarely taken piano pedals into account. In this work, we employ the transcription model proposed by Kong et al. to get pedal information from the audio recordings of piano performance in the AILabs1k7 dataset, and then modify the Compound Word Transformer proposed by Hsiao et al. to build a Transformer decoder that generates pedal-related tokens along with other musical tokens. While the work is done by using inferred sustain pedal information as training data, the result shows hope for further improvement and the importance of the involvement of sustain pedal in tasks of piano performance generations.      
### 47.Evaluating robustness of You Only Hear Once(YOHO) Algorithm on noisy audios in the VOICe Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2111.01205.pdf)
>  Sound event detection (SED) in machine listening entails identifying the different sounds in an audio file and identifying the start and end time of a particular sound event in the audio. SED finds use in various applications such as audio surveillance, speech recognition, and context-based indexing and retrieval of data in a multimedia database. However, in real-life scenarios, the audios from various sources are seldom devoid of any interfering noise or disturbance. In this paper, we test the performance of the You Only Hear Once (YOHO) algorithm on noisy audio data. Inspired by the You Only Look Once (YOLO) algorithm in computer vision, the YOHO algorithm can match the performance of the various state-of-the-art algorithms on datasets such as Music Speech Detection Dataset, TUT Sound Event, and Urban-SED datasets but at lower inference times. In this paper, we explore the performance of the YOHO algorithm on the VOICe dataset containing audio files with noise at different sound-to-noise ratios (SNR). YOHO could outperform or at least match the best performing SED algorithms reported in the VOICe dataset paper and make inferences in less time.      
### 48.Unintended Selection: Persistent Qualification Rate Disparities and Interventions  [ :arrow_down: ](https://arxiv.org/pdf/2111.01201.pdf)
>  Realistically -- and equitably -- modeling the dynamics of group-level disparities in machine learning remains an open problem. In particular, we desire models that do not suppose inherent differences between artificial groups of people -- but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. In this paper, agents each have a real-valued feature $X$ (e.g., credit score) informed by a "true" binary label $Y$ representing qualification (e.g., for a loan). Each agent alternately (1) receives a binary classification label $\hat{Y}$ (e.g., loan approval) from a Bayes-optimal machine learning classifier observing $X$ and (2) may update their qualification $Y$ by imitating successful strategies (e.g., seek a raise) within an isolated group $G$ of agents to which they belong. We consider the disparity of qualification rates $\Pr(Y=1)$ between different groups and how this disparity changes subject to a sequence of Bayes-optimal classifiers repeatedly retrained on the global population. We model the evolving qualification rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. We show that differences in qualification rates between subpopulations can persist indefinitely for a set of non-trivial equilibrium states due to uniformed classifier deployments, even when groups are identical in all aspects except initial qualification densities. We next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualification rate disparities. We conclude by discussing the limitations of our model and findings and by outlining potential future work.      
### 49.Safe PDE Backstepping QP Control with High Relative Degree CBFs: Stefan Model with Actuator Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2111.01187.pdf)
>  High-relative-degree control barrier functions (hi-rel-deg CBFs) play a prominent role in automotive safety and in robotics. In this paper we launch a generalization of this concept for PDE control, treating a specific, physically-relevant model of thermal dynamics where the boundary of the PDE moves due to a liquid-solid phase change -- the so-called Stefan model. The familiar QP design is employed to ensure safety but with CBFs that are infinite-dimensional (including one control barrier "functional") and with safe sets that are infinite-dimensional as well. Since, in the presence of actuator dynamics, at the boundary of the Stefan system, this system's main CBF is of relative degree two, an additional CBF is constructed, by backstepping design, which ensures the positivity of all the CBFs without any additional restrictions on the initial conditions. It is shown that the "safety filter" designed in the paper guarantees safety in the presence of an arbitrary operator input. This is similar to an automotive system in which a safety feedback law overrides -- but only when necessary -- the possibly unsafe steering, acceleration, or braking by a vigorous but inexperienced driver. Simulations have been performed for a process in metal additive manufacturing, which show that the operator's heat-and-cool commands to the Stefan model are being obeyed but without the liquid ever freezing.      
