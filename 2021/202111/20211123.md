# ArXiv eess --Tue, 23 Nov 2021
### 1.Impact of Synchronous Condensers on Power System Static Voltage Stability Considering Line Contingencies in the Presence of Renewable Generation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11423.pdf)
>  Ever-growing electrical loads are having a huge impact on the operation and stability of the power system. Moreover, the integration of renewable generation poses various challenges to the future power system, especially, regarding stability. Thus, this paper presents the impact of synchronous condensers (SCs) on static voltage stability analysis for a test transmission network, considering line contingencies, in the presence of renewable generation. The main purpose of this study was to identify critical buses in the power system when line contingencies occur. Both (N-1) and (N-2) contingencies were considered in this study. The impact of renewable generation is also assessed. To analyze the static voltage stability, the conventional power-voltage (P-V) curve method, using continuation power flow (CPF), is applied on the IEEE 14-bus test system. DIgSILENT PowerFactory software simulations are used to obtain the results. The P-V analysis accurately quantifies the critical buses for both cases, considering (N-1) and (N-2) line contingencies.      
### 2.FAZSeg: A New User-Friendly Software for Quantification of the Foveal Avascular Zone  [ :arrow_down: ](https://arxiv.org/pdf/2111.11419.pdf)
>  Various ocular diseases and high myopia influence the anatomical reference point Foveal Avascular Zone (FAZ) dimensions. Therefore, it is important to segment and quantify the FAZs dimensions accurately. To the best of our knowledge, there is no automated tool or algorithms available to segment the FAZ's deep retinal layer. The paper describes a new open-access software with a user-friendly Graphical User Interface (GUI) and compares the results with the ground truth (manual segmentation).      
### 3.4D iterative reconstruction of brain fMRI in the moving fetus  [ :arrow_down: ](https://arxiv.org/pdf/2111.11394.pdf)
>  Resting-state functional Magnetic Resonance Imaging (fMRI) is a powerful imaging technique for studying functional development of the brain in utero. However, unpredictable and excessive movement of fetuses has limited clinical application since it causes substantial signal fluctuations which can systematically alter observed patterns of functional connectivity. Previous studies have focused on the accurate estimation of the motion parameters in case of large fetal head movement and used a 3D single step interpolation approach at each timepoint to recover motion-free fMRI images. This does not guarantee that the reconstructed image corresponds to the minimum error representation of fMRI time series given the acquired data. Here, we propose a novel technique based on four dimensional iterative reconstruction of the scattered slices acquired during fetal fMRI. The accuracy of the proposed method was quantitatively evaluated on a group of real clinical fMRI fetuses. The results indicate improvements of reconstruction quality compared to the conventional 3D interpolation approach.      
### 4.Measurement Based Non-Line-Of-Sight Vehicular Visible Light Communication Channel Characterization  [ :arrow_down: ](https://arxiv.org/pdf/2111.11369.pdf)
>  Vehicular visible light communication (V-VLC) aims to provide secure complementary vehicle to everything communications (V2X) to increase road safety and traffic efficiency. V-VLC provides directional transmissions, mainly enabling line-of-sight (LoS) communications. However, reflections due to nearby objects enable non-line-of-sight (NLoS) transmissions, extending the usage scenarios beyond LoS. In this paper, we propose a wide-band measurement-based NLoS channel characterization and evaluate the performance of direct current biased optical orthogonal frequency division multiplexing (DCO-OFDM) V-VLC scheme for NLoS channel. We propose a distance-based NLoS V-VLC channel path loss model considering reflection surface characteristics and NLoS V-VLC channel impulse response (CIR) incorporating the temporal broadening effect due to vehicle reflections through weighted double gamma function. The proposed path loss model yields higher accuracy up to 14 dB when compared to the single order reflection model whereas the CIR model estimates the full width at half maximum up to 2 ns accuracy. We further demonstrate that the target bit-error-rate of 10^-3 can be achieved up to 7.86 m, 9.79 m, and 17.62 m distances for black, orange, and white vehicle reflection induced measured NLoS V-VLC channels for DCO-OFDM transmissions.      
### 5.An application of reinforcement learning to residential energy storage under real-time pricing  [ :arrow_down: ](https://arxiv.org/pdf/2111.11367.pdf)
>  With the proliferation of advanced metering infrastructure (AMI), more real-time data is available to electric utilities and consumers. Such high volumes of data facilitate innovative electricity rate structures beyond flat-rate and time-of-use (TOU) tariffs. One such innovation is real-time pricing (RTP), in which the wholesale market-clearing price is passed directly to the consumer on an hour-by-hour basis. While rare, RTP exists in parts of the United States and has been observed to reduce electric bills. Although these reductions are largely incidental, RTP may represent an opportunity for large-scale peak shaving, demand response, and economic efficiency when paired with intelligent control systems. Algorithms controlling flexible loads and energy storage have been deployed for demand response elsewhere in the literature, but few studies have investigated these algorithms in an RTP environment. If properly optimized, the dynamic between RTP and intelligent control has the potential to counteract the unwelcome spikes and dips of demand driven by growing penetration of distributed renewable generation and electric vehicles (EV). This paper presents a simple reinforcement learning (RL) application for optimal battery control subject to an RTP signal.      
### 6.Electric Vehicle Attack Impact on Power Grid Operation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11317.pdf)
>  The increasing need for reducing greenhouse gas emissions and the drive for green cities have promoted the use of electric vehicles due to their environmental benefits. In fact, countries have set their own targets and are offering incentives for people to purchase EVs as opposed to traditional gasoline-powered cars. Manufacturers have been hastily deploying charging stations to meet the charging requirements of the EVs on the road. This rapid deployment has contributed to the EV ecosystem's lack of proper security measures, raising multiple questions related to the power grid security and vulnerability. In this paper, we offer a complete examination of the EV ecosystem from the vulnerability to the attacks and finally the solutions. We start by examining the existing vulnerabilities in the EV ecosystem that can be exploited to control the EV charging and launch attacks against the power grid. We then discuss the non-linear nature of the EV charging load and simulate multiple attacks that can be launched against the power grid using these EVs. EV loads have high reactive power demand which can have a larger impact on the grid compared to residential loads. We perform simulations on two power grids and demonstrate that while the grid can recover after a 48 MW attack utilizing traditional residential loads, a smaller 30 MW EV load attack can completely destabilize the system. Finally, we suggest several patches for the existing vulnerabilities and discuss two methods aimed at detecting EV attacks.      
### 7.Universal Efficient Variable-rate Neural Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2111.11305.pdf)
>  Recently, Learning-based image compression has reached comparable performance with traditional image codecs(such as JPEG, BPG, WebP). However, computational complexity and rate flexibility are still two major challenges for its practical deployment. To tackle these problems, this paper proposes two universal modules named Energy-based Channel Gating(ECG) and Bit-rate Modulator(BM), which can be directly embedded into existing end-to-end image compression models. ECG uses dynamic pruning to reduce FLOPs for more than 50\% in convolution layers, and a BM pair can modulate the latent representation to control the bit-rate in a channel-wise manner. By implementing these two modules, existing learning-based image codecs can obtain ability to output arbitrary bit-rate with a single model and reduced computation.      
### 8.Novel EEG based Schizophrenia Detection with IoMT Framework for Smart Healthcare  [ :arrow_down: ](https://arxiv.org/pdf/2111.11298.pdf)
>  In the field of neuroscience, Brain activity analysis is always considered as an important area. Schizophrenia(Sz) is a brain disorder that severely affects the thinking, behaviour, and feelings of people all around the world. Electroencephalography (EEG) is proved to be an efficient biomarker in Sz detection. EEG is a non-linear time-seriesi signal and utilizing it for investigation is rather crucial due to its non-linear structure. This paper aims to improve the performance of EEG based Sz detection using a deep learning approach. A novel hybrid deep learning model known as SzHNN (Schizophrenia Hybrid Neural Network), a combination of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) has been proposed. CNN network is used for local feature extraction and LSTM has been utilized for classification. The proposed model has been compared with CNN only, LSTM only, and machine learning-based models. All the models have been evaluated on two different datasets wherein Dataset 1 consists of 19 subjects and Dataset 2 consists of 16 subjects. Several experiments have been conducted for the same using various parametric settings on different frequency bands and using different sets of electrodes on the scalp. Based on all the experiments, it is evident that the proposed hybrid model (SzHNN) provides the highest classification accuracy of 99.9% in comparison to other existing models. The proposed model overcomes the influence of different frequency bands and even showed a much better accuracy of 91% with only 5 electrodes. The proposed model is also evaluated on the Internet of Medical Things (IoMT) framework for smart healthcare and remote monitoring applications.      
### 9.Uncertainty Inequalities for 3D Octonionic-valued Signals Associated with Octonion Offset Linear Canonical Transform  [ :arrow_down: ](https://arxiv.org/pdf/2111.11292.pdf)
>  he octonion offset linear canonical transform can be defined as a time shifted and frequency modulated version of the octonion linear canonical transform, a more general framework of most existing signal processing tools. In this paper, we first define the and provide its closed-form representation. Based on this fact, we study some fundamental properties of proposed transform including inversion formula, norm split and energy conservation. The crux of the paper lies in the generalization of several well known uncertainty relations for the that include Pitts inequality, logarithmic uncertainty inequality, Hausdorff Young inequality and local uncertainty inequalities.      
### 10.Half-infinite sampling and its FT  [ :arrow_down: ](https://arxiv.org/pdf/2111.11291.pdf)
>  In the digital world, signals are discrete and finite. The Fourier representation of discrete and finite signals is FT convolution of the finite sampling function and the continuous signal. Conventionally, finite sampling is treated as a segment of infinite sampling. Though this approach perfectly solves the difference between finite and infinite sampling, it has caused much trouble for signal processing. Mathematically, there is a kind of sampling between finite and infinite sampling, and we name this kind of sampling as half-infinite sampling. Theoretically, finite sampling can also be treated as a segment of half-infinite sampling. Because we can derive the Fourier representation of discrete and finite signals from half-infinite sampling, the FTs of several half-infinite samplings are studied. The results show that the FT of half-infinite sampling is more concise than that of infinite sampling. A numerical experiment verified the theoretical derivations successfully, during which step sampling was proposed. Besides, several interesting equations were built.      
### 11.Automated cross-sectional view selection in CT angiography of aortic dissections with uncertainty awareness and retrospective clinical annotations  [ :arrow_down: ](https://arxiv.org/pdf/2111.11269.pdf)
>  Objective: Surveillance imaging of chronic aortic diseases, such as dissections, relies on obtaining and comparing cross-sectional diameter measurements at predefined aortic landmarks, over time. Due to a lack of robust tools, the orientation of the cross-sectional planes is defined manually by highly trained operators. We show how manual annotations routinely collected in a clinic can be efficiently used to ease this task, despite the presence of a non-negligible interoperator variability in the measurements. <br>Impact: Ill-posed but repetitive imaging tasks can be eased or automated by leveraging imperfect, retrospective clinical annotations. <br>Methodology: In this work, we combine convolutional neural networks and uncertainty quantification methods to predict the orientation of such cross-sectional planes. We use clinical data randomly processed by 11 operators for training, and test on a smaller set processed by 3 independent operators to assess interoperator variability. <br>Results: Our analysis shows that manual selection of cross-sectional planes is characterized by 95% limits of agreement (LOA) of $10.6^\circ$ and $21.4^\circ$ per angle. Our method showed to decrease static error by $3.57^\circ$ ($40.2$%) and $4.11^\circ$ ($32.8$%) against state of the art and LOA by $5.4^\circ$ ($49.0$%) and $16.0^\circ$ ($74.6$%) against manual processing. <br>Conclusion: This suggests that pre-existing annotations can be an inexpensive resource in clinics to ease ill-posed and repetitive tasks like cross-section extraction for surveillance of aortic dissections.      
### 12.Prediction of Probabilistic Transient Stability Using Support Vector Machine  [ :arrow_down: ](https://arxiv.org/pdf/2111.11242.pdf)
>  Transient stability assessment is an integral part of dynamic security assessment of power systems. Traditional methods of transient stability assessment, such as time domain simulation approach and direct methods, are appropriate for offline studies and thus, cannot be applied for online transient stability prediction, which is a major requirement in modern power systems. This motivated the requirement to apply an artificial intelligence-based approach. In this regard, supervised machine learning is beneficial for predicting transient stability status, in the presence of uncertainties. Therefore, this paper examines the application of a binary support vector machine-based supervised machine learning, for predicting the transient stability status of a power system, considering uncertainties of various factors, such as load, faulted line, fault type, fault location and fault clearing time. The support vector machine is trained using a Gaussian Radial Basis function kernel and its hyperparameters are optimized using Bayesian optimization. Results obtained for the IEEE 14-bus test system demonstrated that the proposed method offers a fast technique for probabilistic transient stability status prediction, with an excellent accuracy. DIgSILENT PowerFactory and MATLAB was utilized for transient stability time-domain simulations (for obtaining training data for support vector machine) and for applying support vector machine, respectively.      
### 13.Light-weight Gesture Sensing Using FMCW Radar Time Series Data  [ :arrow_down: ](https://arxiv.org/pdf/2111.11219.pdf)
>  The paper proposes a novel feature extraction approach for FMCW radar systems in the field of short-range gesture sensing. A light-weight processing is proposed which reduces a series of 3D radar data cubes to four 1D time signals containing information about range, azimuth angle, elevation angle and magnitude. The processing is entirely performed in the time domain without using any Fourier transformation and enables the training of a deep neural network directly on the raw time domain data. It is shown experimentally on real world data, that the proposed processing retains the same expressive power as conventional radar processing to range-, Doppler- and angle-spectrograms. Further, the computational complexity is significantly reduced which makes it perfectly suitable for embedded devices. The system is able to recognize ten different gestures with an accuracy of about 95% and is running in real time on a Raspberry Pi 3 B. The delay between end of gesture and prediction is only 150 ms.      
### 14.Does Oversizing Improve Prosumer Profitability in a Flexibility Market? -- A Sensitivity Analysis using PV-battery System  [ :arrow_down: ](https://arxiv.org/pdf/2111.11193.pdf)
>  The possibilities to involve small-scale prosumers for ancillary services in the distribution grid through aggregators and local flexibility markets question whether it is profitable for prosumers to oversize proactively. In this analysis, a Python model is developed to identify the cost-optimal operation plan of the PV-battery system and to evaluate the device flexibility. An economic assessment is carried out to derive the cost-benefit of sizing based on the mean electricity price. A sensitivity analysis is performed with the above results to study the profitable sizing of PV-battery systems with flexibility services. The results show a promising advantage of oversizing although limitations prevail with the extent of flexibility services offered.      
### 15.Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.11191.pdf)
>  The paper presents a Convolutional Neural Networks (CNN) model for image classification, aiming at increasing predictive performance for COVID-19 diagnosis while avoiding deeper and thus more complex alternatives. The proposed model includes four similar convolutional layers followed by a flattening and two dense layers. This work proposes a less complex solution based on simply classifying 2D CT-Scan slices of images using their pixels via a 2D CNN model. Despite the simplicity in architecture, the proposed model showed improved quantitative results exceeding state-of-the-art on the same dataset of images, in terms of the macro f1 score. In this case study, extracting features from images, segmenting parts of the images, or other more complex techniques, ultimately aiming at images classification, do not yield better results. With that, this paper introduces a simple yet powerful deep learning based solution for automated COVID-19 classification.      
### 16.Sound Field Reproduction With Weighted Mode Matching and Infinite-Dimensional Harmonic Analysis: An Experimental Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11045.pdf)
>  Sound field reproduction methods based on numerical optimization, which aim to minimize the error between synthesized and desired sound fields, are useful in many practical scenarios because of their flexibility in the array geometry of loudspeakers. However, the reproduction performance of these methods in a practical environment has not been sufficiently investigated. We evaluate weighted mode matching, which is a sound field reproduction method based on the spherical wavefunction expansion of the sound field, in comparison with conventional pressure matching. We also introduce a method of infinite-dimensional harmonic analysis for estimating the expansion coefficients of the sound field from microphone measurements. Experimental results indicated that weighted mode matching using the expansion coefficients of the transfer functions estimated by the infinite-dimensional harmonic analysis outperforms conventional pressure matching, especially when the number of microphones is small.      
### 17.Local-Selective Feature Distillation for Single Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2111.10988.pdf)
>  Recent improvements in convolutional neural network (CNN)-based single image super-resolution (SISR) methods rely heavily on fabricating network architectures, rather than finding a suitable training algorithm other than simply minimizing the regression loss. Adapting knowledge distillation (KD) can open a way for bringing further improvement for SISR, and it is also beneficial in terms of model efficiency. KD is a model compression method that improves the performance of Deep Neural Networks (DNNs) without using additional parameters for testing. It is getting the limelight recently for its competence at providing a better capacity-performance tradeoff. In this paper, we propose a novel feature distillation (FD) method which is suitable for SISR. We show the limitations of the existing FitNet-based FD method that it suffers in the SISR task, and propose to modify the existing FD algorithm to focus on local feature information. In addition, we propose a teacher-student-difference-based soft feature attention method that selectively focuses on specific pixel locations to extract feature information. We call our method local-selective feature distillation (LSFD) and verify that our method outperforms conventional FD methods in SISR problems.      
### 18.Extending the Dissipating Energy Flow Method to Flexible AC Transmission Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.10960.pdf)
>  In recent years, the dissipating energy flow (DEF) method has emerged as a promising tool for online localization of oscillation sources. In literature, the mathematical foundations of this method are well-studied for networks with synchronous generators. In this paper, we extend the analysis to flexible AC transmission systems (FACTS). To that end, we derive the DEF-expressions for a thyristor controlled series capacitor (TCSC) and a static synchronous compensator (STATCOM) operating with conventional control strategies. Analyzing their respective DEFs, we obtain the conditions for which these FACTS devices could behave as the sources of oscillation energy. Our findings are structured into propositions and are supported through numerical case studies on IEEE test systems.      
### 19.Identification of Low Rank Vector Processes  [ :arrow_down: ](https://arxiv.org/pdf/2111.10899.pdf)
>  We study modeling and identification of stationary processes with a spectral density matrix of low rank. Equivalently, we consider processes having an innovation of reduced dimension for which Prediction Error Methods (PEM) algorithms are not directly applicable. We show that these processes admit a special feedback structure with a deterministic feedback channel which can be used to split the identification in two steps, one of which can be based on standard algorithms while the other is based on a deterministic least squares fit. Identifiability of the feedback system is analyzed and a unique identifiable structure is characterized. Simulations show that the proposed procedure works well in some simple examples.      
### 20.Deep Image Prior using Stein's Unbiased Risk Estimator: SURE-DIP  [ :arrow_down: ](https://arxiv.org/pdf/2111.10892.pdf)
>  Deep learning algorithms that rely on extensive training data are revolutionizing image recovery from ill-posed measurements. Training data is scarce in many imaging applications, including ultra-high-resolution imaging. The deep image prior (DIP) algorithm was introduced for single-shot image recovery, completely eliminating the need for training data. A challenge with this scheme is the need for early stopping to minimize the overfitting of the CNN parameters to the noise in the measurements. We introduce a generalized Stein's unbiased risk estimate (GSURE) loss metric to minimize the overfitting. Our experiments show that the SURE-DIP approach minimizes the overfitting issues, thus offering significantly improved performance over classical DIP schemes. We also use the SURE-DIP approach with model-based unrolling architectures, which offers improved performance over direct inversion schemes.      
### 21.ARMAS: Active Reconstruction of Missing Audio Segments  [ :arrow_down: ](https://arxiv.org/pdf/2111.10891.pdf)
>  Digital audio signal reconstruction of lost or corrupt segment using deep learning algorithms has been explored intensively in the recent years. Nevertheless, prior traditional methods with linear interpolation, phase coding and tone insertion techniques are still in vogue. However, we found no research work on the reconstruction of audio signals with the fusion of dithering, steganography, and machine learning regressors. Therefore, this paper proposes the combination of steganography, halftoning (dithering), and state-of-the-art shallow (RF- Random Forest and SVR- Support Vector Regression) and deep learning (LSTM- Long Short-Term Memory) methods. The results (including comparison to the SPAIN and Autoregressive methods) are evaluated with four different metrics. The observations from the results show that the proposed solution is effective and can enhance the reconstruction of audio signals performed by the side information (noisy-latent representation) steganography provides. This work may trigger interest in the optimization of this approach and/or in transferring it to different domains (i.e., image reconstruction).      
### 22.Joint alignment and reconstruction of multislice dynamic MRI using variational manifold learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.10889.pdf)
>  Free-breathing cardiac MRI schemes are emerging as competitive alternatives to breath-held cine MRI protocols, enabling applicability to pediatric and other population groups that cannot hold their breath. Because the data from the slices are acquired sequentially, the cardiac/respiratory motion patterns may be different for each slice; current free-breathing approaches perform independent recovery of each slice. In addition to not being able to exploit the inter-slice redundancies, manual intervention or sophisticated post-processing methods are needed to align the images post-recovery for quantification. To overcome these challenges, we propose an unsupervised variational deep manifold learning scheme for the joint alignment and reconstruction of multislice dynamic MRI. The proposed scheme jointly learns the parameters of the deep network as well as the latent vectors for each slice, which capture the motion-induced dynamic variations, from the k-t space data of the specific subject. The variational framework minimizes the non-uniqueness in the representation, thus offering improved alignment and reconstructions.      
### 23.Dynamic imaging using motion-compensated smoothness regularization on manifolds (MoCo-SToRM)  [ :arrow_down: ](https://arxiv.org/pdf/2111.10887.pdf)
>  We introduce an unsupervised deep manifold learning algorithm for motion-compensated dynamic MRI. We assume that the motion fields in a free-breathing lung MRI dataset live on a manifold. The motion field at each time instant is modeled as the output of a deep generative model, driven by low-dimensional time-varying latent vectors that capture the temporal variability. The images at each time instant are modeled as the deformed version of an image template using the above motion fields. The template, the parameters of the deep generator, and the latent vectors are learned from the k-t space data in an unsupervised fashion. The manifold motion model serves as a regularizer, making the joint estimation of the motion fields and images from few radial spokes/frame well-posed. The utility of the algorithm is demonstrated in the context of motion-compensated high-resolution lung MRI.      
### 24.Joint Optimization for Secure Ambient Backscatter Communication in NOMA-enabled IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.10872.pdf)
>  Non-orthogonal multiple access (NOMA) has emerged as a novel air interface technology for massive connectivity in sixth-generation (6G) era. The recent integration of NOMA in backscatter communication (BC) has triggered significant research interest due to its applications in low-powered Internet of Things (IoT) networks. However, the link security aspect of these networks has not been well investigated. This article provides a new optimization framework for improving the physical layer security of the NOMA ambient BC system. Our system model takes into account the simultaneous operation of NOMA IoT users and the backscatter node (BN) in the presence of multiple eavesdroppers (EDs). The EDs in the surrounding area can overhear the communication of base station (BS) and BN due to the wireless broadcast transmission. Thus, the main objective is to enhance the link security by optimizing the BN reflection coefficient and BS transmit power. To gauge the performance of the proposed scheme, we also present the suboptimal NOMA and conventional orthogonal multiple access as benchmark schemes. Monte Carlo simulation results demonstrate the superiority of the NOMA BC scheme over the pure NOMA scheme without BC and conventional orthogonal multiple access scheme in terms of system secrecy rate.      
### 25.Development of Microcontroller Based Smart Grid Framework  [ :arrow_down: ](https://arxiv.org/pdf/2111.10835.pdf)
>  Smart grid technology has been recognized as a promising solution for the next-generation energy efficient electric power systems to mitigate energy crisis. Smart grid provides highly consistent and reliable services, efficient energy management practices, smart metering integration, automation and precision decision support systems and self-healing facilities. The smart power grid introduces a sensing, monitoring, and control system that provides end users with the cost of energy at any moment through real-time pricing. The classical power system operation has no control over the loads except in an emergency situation when a portion of the loads can be dropped as needed to balance the power grid generation with its loads. Furthermore, the smart power grid supplies the platform for the use of renewable energy sources that acts as a safeguard against a complete blackout of the interconnected power grid. In this work, all the concepts involved in smart grid mechanism is implemented with PIC18F452 microcontroller and other supplementary components. A solar module with storage capacity is connected to the proposed system for minimizing grid energy consumption and plays a primary energy source for maximum utilization of green energy. This intelligent device may inherently reduce the consumption of electrical energy during peak hours and allow consumers to sell back electricity into grid using bi-directional technique. Barriers, challenges, benefits and future trends regarding the technologies and the role of users have also been discussed in this paper.      
### 26.Automated Controller Calibration by Kalman Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2111.10832.pdf)
>  This paper proposes a method for calibrating control parameters. Examples of such control parameters are gains of PID controllers, weights of a cost function for optimal control, filter coefficients, the sliding surface of a sliding mode controller, or weights of a neural network. Hence, the proposed method can be applied to a wide range of controllers. The method uses a Kalman filter that estimates control parameters rather than the system's state, using data of closed-loop system operation. The control parameter calibration is driven by a training objective, which encompasses specifications on the performance of the dynamical system. The calibration method tunes the parameters online and robustly, is computationally efficient, has low data storage requirements, and is easy to implement making it appealing for many real-time applications. Simulation results show that the method is able to learn control parameters quickly (approximately 24% average decay factor of closed-loop cost), is able to tune the parameters to compensate for disturbances (approximately 29% improvement on tracking precision), and is robust to noise. Further, a simulation study with the high-fidelity vehicle simulator CarSim shows that the method can calibrate controllers of a complex dynamical system online, which indicates its applicability to a real-world system.      
### 27.Domain Generalization for Mammography Detection via Multi-style and Multi-view Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.10827.pdf)
>  Lesion detection is a fundamental problem in the computer-aided diagnosis scheme for mammography. The advance of deep learning techniques have made a remarkable progress for this task, provided that the training data are large and sufficiently diverse in terms of image style and quality. In particular, the diversity of image style may be majorly attributed to the vendor factor. However, the collection of mammograms from vendors as many as possible is very expensive and sometimes impractical for laboratory-scale studies. Accordingly, to further augment the generalization capability of deep learning model to various vendors with limited resources, a new contrastive learning scheme is developed. Specifically, the backbone network is firstly trained with a multi-style and multi-view unsupervised self-learning scheme for the embedding of invariant features to various vendor-styles. Afterward, the backbone network is then recalibrated to the downstream task of lesion detection with the specific supervised learning. The proposed method is evaluated with mammograms from four vendors and one unseen public dataset. The experimental results suggest that our approach can effectively improve detection performance on both seen and unseen domains, and outperforms many state-of-the-art (SOTA) generalization methods.      
### 28.Automatic Generation of Ice Hockey Defensive Motion via Coverage Control and Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2111.10804.pdf)
>  A successful defensive strategy in ice hockey games is often designed empirically by an experienced professional. The majority of previous work on automating the strategy focuses on analyzing spatial data to decide the most optimal formation and action but cannot generalize the system to real games with real-time capabilities. We propose a novel control logic for generating real-time ice hockey defensive motion based on a control barrier function (CBF) and coverage control to extend our antecessors' logic that succeeds in duplicating ideal formations for specific scenes. To this end, we first present an ellipsoidal CBF to overcome the drawbacks of the existing line-based CBF of our antecessors. We also tune and add a novel density function to reflect real specifications more precisely than the previous work. The control logic is then demonstrated through simulations with offensive motion in real games. It is confirmed that the present logic generates valid defensive movements without specification to these specific scenes. We further exemplify that the logic generates proper motion under ice hockey's man-to-man and zone defense strategies and their intermediate strategies by tuning the logic. This would contribute to reducing the efforts of the practitioners to educate ice hockey players.      
### 29.Structure-Preserving Graph Kernel for Brain Network Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.10803.pdf)
>  This paper presents a novel graph-based kernel learning approach for connectome analysis. Specifically, we demonstrate how to leverage the naturally available structure within the graph representation to encode prior knowledge in the kernel. We first proposed a matrix factorization to directly extract structural features from natural symmetric graph representations of connectome data. We then used them to derive a structure-persevering graph kernel to be fed into the support vector machine. The proposed approach has the advantage of being clinically interpretable. Quantitative evaluations on challenging HIV disease classification (DTI- and fMRI-derived connectome data) and emotion recognition (EEG-derived connectome data) tasks demonstrate the superior performance of our proposed methods against the state-of-the-art. Results showed that relevant EEG-connectome information is primarily encoded in the alpha band during the emotion regulation task.      
### 30.FreqNet: A Frequency-domain Image Super-Resolution Network with Dicrete Cosine Transform  [ :arrow_down: ](https://arxiv.org/pdf/2111.10800.pdf)
>  Single image super-resolution(SISR) is an ill-posed problem that aims to obtain high-resolution (HR) output from low-resolution (LR) input, during which extra high-frequency information is supposed to be added to improve the perceptual quality. Existing SISR works mainly operate in the spatial domain by minimizing the mean squared reconstruction error. Despite the high peak signal-to-noise ratios(PSNR) results, it is difficult to determine whether the model correctly adds desired high-frequency details. Some residual-based structures are proposed to guide the model to focus on high-frequency features implicitly. However, how to verify the fidelity of those artificial details remains a problem since the interpretation from spatial-domain metrics is limited. In this paper, we propose FreqNet, an intuitive pipeline from the frequency domain perspective, to solve this problem. Inspired by existing frequency-domain works, we convert images into discrete cosine transform (DCT) blocks, then reform them to obtain the DCT feature maps, which serve as the input and target of our model. A specialized pipeline is designed, and we further propose a frequency loss function to fit the nature of our frequency-domain task. Our SISR method in the frequency domain can learn the high-frequency information explicitly, provide fidelity and good perceptual quality for the SR images. We further observe that our model can be merged with other spatial super-resolution models to enhance the quality of their original SR output.      
### 31.DuDoTrans: Dual-Domain Transformer Provides More Attention for Sinogram Restoration in Sparse-View CT Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2111.10790.pdf)
>  While Computed Tomography (CT) reconstruction from X-ray sinograms is necessary for clinical diagnosis, iodine radiation in the imaging process induces irreversible injury, thereby driving researchers to study sparse-view CT reconstruction, that is, recovering a high-quality CT image from a sparse set of sinogram views. Iterative models are proposed to alleviate the appeared artifacts in sparse-view CT images, but the computation cost is too expensive. Then deep-learning-based methods have gained prevalence due to the excellent performances and lower computation. However, these methods ignore the mismatch between the CNN's \textbf{local} feature extraction capability and the sinogram's \textbf{global} characteristics. To overcome the problem, we propose \textbf{Du}al-\textbf{Do}main \textbf{Trans}former (\textbf{DuDoTrans}) to simultaneously restore informative sinograms via the long-range dependency modeling capability of Transformer and reconstruct CT image with both the enhanced and raw sinograms. With such a novel design, reconstruction performance on the NIH-AAPM dataset and COVID-19 dataset experimentally confirms the effectiveness and generalizability of DuDoTrans with fewer involved parameters. Extensive experiments also demonstrate its robustness with different noise-level scenarios for sparse-view CT reconstruction. The code and models are publicly available at <a class="link-external link-https" href="https://github.com/DuDoTrans/CODE" rel="external noopener nofollow">this https URL</a>      
### 32.One-shot Weakly-Supervised Segmentation in Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.10773.pdf)
>  Deep neural networks usually require accurate and a large number of annotations to achieve outstanding performance in medical image segmentation. One-shot segmentation and weakly-supervised learning are promising research directions that lower labeling effort by learning a new class from only one annotated image and utilizing coarse labels instead, respectively. Previous works usually fail to leverage the anatomical structure and suffer from class imbalance and low contrast problems. Hence, we present an innovative framework for 3D medical image segmentation with one-shot and weakly-supervised settings. Firstly a propagation-reconstruction network is proposed to project scribbles from annotated volume to unlabeled 3D images based on the assumption that anatomical patterns in different human bodies are similar. Then a dual-level feature denoising module is designed to refine the scribbles based on anatomical- and pixel-level features. After expanding the scribbles to pseudo masks, we could train a segmentation model for the new class with the noisy label training strategy. Experiments on one abdomen and one head-and-neck CT dataset show the proposed method obtains significant improvement over the state-of-the-art methods and performs robustly even under severe class imbalance and low contrast.      
### 33.Orthogonal Delay Scale Space Modulation: A New Technique for Wideband Time-Varying Channels  [ :arrow_down: ](https://arxiv.org/pdf/2111.10765.pdf)
>  Orthogonal Time Frequency Space (OTFS) modulation is a recently proposed scheme for time-varying narrowband channels in terrestrial radio-frequency communications. Underwater acoustic (UWA) and ultra-wideband (UWB) communication systems, on the other hand, confront wideband time-varying channels. Unlike narrowband channels, for which time contractions or dilations due to Doppler effect can be approximated by frequency-shifts, the Doppler effect in wideband channels results in frequency-dependent non uniform shift of signal frequencies across the band. In this paper, we develop an OTFS-like modulation scheme -- Orthogonal Delay Scale Space (ODSS) modulation -- for handling wideband time-varying channels. We derive the ODSS transmission and reception schemes from first principles. In the process, we introduce the notion of $\omega$ convolution in the delay-scale space that parallels the twisted convolution used in the time-frequency space. The preprocessing 2D transformation from the Fourier-Mellin domain to the delay-scale space in ODSS, which plays the role of inverse symplectic Fourier transform (ISFFT) in OTFS, improves the bit error rate performance compared to OTFS and Orthogonal Frequency Division Multiplexing (OFDM) in wideband time-varying channels. Furthermore, since the channel matrix is rendered near-diagonal, ODSS retains the advantage of OFDM in terms of its low-complexity receiver structure.      
### 34.COVID-19 Detection through Deep Feature Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2111.10762.pdf)
>  The SARS-CoV2 virus has caused a lot of tribulation to the human population. Predictive modeling that can accurately determine whether a person is infected with COVID-19 is imperative. The study proposes a novel approach that utilizes deep feature extraction technique, pre-trained ResNet50 acting as the backbone of the network, combined with Logistic Regression as the head model. The proposed model has been trained on Kaggle COVID-19 Radiography Dataset. The proposed model achieves a cross-validation accuracy of 100% on the COVID-19 and Normal X-Ray image classes. Similarly, when tested on combined three classes, the proposed model achieves 98.84% accuracy.      
### 35.Design and Analysis of SWIPT with Safety Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2111.10689.pdf)
>  Simultaneous wireless information and power transfer (SWIPT) has long been proposed as a key solution for charging and communicating with low-cost and low-power devices. However, the employment of radio frequency (RF) signals for information/power transfer needs to comply with international health and safety regulations. In this paper, we provide a complete framework for the design and analysis of far-field SWIPT under safety constraints. In particular, we deal with two RF exposure regulations, namely, the specific absorption rate (SAR) and the maximum permissible exposure (MPE). The state-of-the-art regarding SAR and MPE is outlined together with a description as to how these can be modeled in the context of communication networks. We propose a deep learning approach for the design of robust beamforming subject to specific information, energy harvesting and SAR constraints. Furthermore, we present a thorough analytical study for the performance of large-scale SWIPT systems, in terms of information and energy coverage under MPE constraints. This work provides insights with regards to the optimal SWIPT design as well as the potentials from the proper development of SWIPT systems under health and safety restrictions.      
### 36.A Review on The Division of Magnetic Resonant Prostate Images with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.10683.pdf)
>  Deep learning; it is often used in dividing processes on images in the biomedical field. In recent years, it has been observed that there is an increase in the division procedures performed on prostate images using deep learning compared to other methods of image division. Looking at the literature; It is seen that the process of dividing prostate images, which are carried out with deep learning, is an important step for the diagnosis and treatment of prostate cancer. For this reason, in this study; to be a source for future splitting operations; deep learning splitting procedures on prostate images obtained from magnetic resonance (MRI) imaging devices were examined.      
### 37.Delay Estimation for Ranging and Localization Using Multiband Channel State Information  [ :arrow_down: ](https://arxiv.org/pdf/2111.10682.pdf)
>  In wireless networks, an essential step for precise range-based localization is the high-resolution estimation of multipath channel delays. The resolution of traditional delay estimation algorithms is inversely proportional to the bandwidth of the training signals used for channel probing. Considering that typical training signals have limited bandwidth, delay estimation using these algorithms often leads to poor localization performance. To mitigate these constraints, we exploit the multiband and carrier frequency switching capabilities of wireless transceivers and propose to acquire channel state information (CSI) in multiple bands spread over a large frequency aperture. The data model of the acquired measurements has a multiple shift-invariance structure, and we use this property to develop a high-resolution delay estimation algorithm. We derive the Cramér-Rao Bound (CRB) for the data model and perform numerical simulations of the algorithm using system parameters of the emerging IEEE 802.11be standard. Simulations show that the algorithm is asymptotically efficient and converges to the CRB. To validate modeling assumptions, we test the algorithm using channel measurements acquired in real indoor scenarios. From these results, it is seen that delays (ranges) estimated from multiband CSI with a total bandwidth of 320 MHz show an average RMSE of less than 0.3 ns (10 cm) in 90% of the cases.      
### 38.Location-aware Beamforming for MIMO-enabled UAV Communications: An Unknown Input Observer Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.10665.pdf)
>  Numerous communications and networking challenges prevent deploying unmanned aerial vehicles (UAVs) in extreme environments where the existing wireless technologies are mainly ground-focused; and, as a consequence, the air-to-air channel for UAVs is not fully covered. In this paper, a novel spatial estimation for beamforming is proposed to address UAV-based joint sensing and communications (JSC). The proposed spatial estimation algorithm relies on using a delay tolerant observer-based predictor, which can accurately predict the positions of the target UAVs in the presence of uncertainties due to factors such as wind gust. The solution, which uses discrete-time unknown input observers (UIOs), reduces the joint target detection and communication complication notably by operating on the same device and performs reliably in the presence of channel blockage and interference. The effectiveness of the proposed approach is demonstrated using simulation results.      
### 39.Velocity and Disturbance Robust Non-linear Estimator for Autonomous Surface Vehicles with Reduced Sensing Capabilities  [ :arrow_down: ](https://arxiv.org/pdf/2111.10660.pdf)
>  This paper presents a robust non-linear state estimator for autonomous surface vehicles, where the movement is restricted to the horizontal plane. It is assumed that only the vehicle position and orientation can be measured, being the former affected by bounded noises. Then, under some fair standard assumptions concerning the maximum velocities and acceleration rates of the vehicle, the estimator is able to reconstruct not only the velocities, but also the lumped generalised disturbances, that cluster external disturbances, non-linearities, and unmodelled dynamics. The observer is easily tunable by the user, with a set of four scalars, two of them related to the velocity of convergence of the estimator, and the other two parameters to set the desired trade-off between noise sensitivity and disturbance rejection. Several simulations with a well-known test-bed craft are provided to show how the proposed algorithm outperforms previous ones in the literature.      
### 40.Medical Knowledge-Guided Deep Learning for Imbalanced Medical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.10620.pdf)
>  Deep learning models have gained remarkable performance on a variety of image classification tasks. However, many models suffer from limited performance in clinical or medical settings when data are imbalanced. To address this challenge, we propose a medical-knowledge-guided one-class classification approach that leverages domain-specific knowledge of classification tasks to boost the model's performance. The rationale behind our approach is that some existing prior medical knowledge can be incorporated into data-driven deep learning to facilitate model learning. We design a deep learning-based one-class classification pipeline for imbalanced image classification, and demonstrate in three use cases how we take advantage of medical knowledge of each specific classification task by generating additional middle classes to achieve higher classification performances. We evaluate our approach on three different clinical image classification tasks (a total of 8459 images) and show superior model performance when compared to six state-of-the-art methods. All codes of this work will be publicly available upon acceptance of the paper.      
### 41.PAANet: Progressive Alternating Attention for Automatic Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10618.pdf)
>  Medical image segmentation can provide detailed information for clinical analysis which can be useful for scenarios where the detailed location of a finding is important. Knowing the location of disease can play a vital role in treatment and decision-making. Convolutional neural network (CNN) based encoder-decoder techniques have advanced the performance of automated medical image segmentation systems. Several such CNN-based methodologies utilize techniques such as spatial- and channel-wise attention to enhance performance. Another technique that has drawn attention in recent years is residual dense blocks (RDBs). The successive convolutional layers in densely connected blocks are capable of extracting diverse features with varied receptive fields and thus, enhancing performance. However, consecutive stacked convolutional operators may not necessarily generate features that facilitate the identification of the target structures. In this paper, we propose a progressive alternating attention network (PAANet). We develop progressive alternating attention dense (PAAD) blocks, which construct a guiding attention map (GAM) after every convolutional layer in the dense blocks using features from all scales. The GAM allows the following layers in the dense blocks to focus on the spatial locations relevant to the target region. Every alternate PAAD block inverts the GAM to generate a reverse attention map which guides ensuing layers to extract boundary and edge-related information, refining the segmentation process. Our experiments on three different biomedical image segmentation datasets exhibit that our PAANet achieves favourable performance when compared to other state-of-the-art methods.      
### 42.GMSRF-Net: An improved generalizability with global multi-scale residual fusion network for polyp segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10614.pdf)
>  Colonoscopy is a gold standard procedure but is highly operator-dependent. Efforts have been made to automate the detection and segmentation of polyps, a precancerous precursor, to effectively minimize missed rate. Widely used computer-aided polyp segmentation systems actuated by encoder-decoder have achieved high performance in terms of accuracy. However, polyp segmentation datasets collected from varied centers can follow different imaging protocols leading to difference in data distribution. As a result, most methods suffer from performance drop and require re-training for each specific dataset. We address this generalizability issue by proposing a global multi-scale residual fusion network (GMSRF-Net). Our proposed network maintains high-resolution representations while performing multi-scale fusion operations for all resolution scales. To further leverage scale information, we design cross multi-scale attention (CMSA) and multi-scale feature selection (MSFS) modules within the GMSRF-Net. The repeated fusion operations gated by CMSA and MSFS demonstrate improved generalizability of the network. Experiments conducted on two different polyp segmentation datasets show that our proposed GMSRF-Net outperforms the previous top-performing state-of-the-art method by 8.34% and 10.31% on unseen CVC-ClinicDB and unseen Kvasir-SEG, in terms of dice coefficient.      
### 43.Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.10610.pdf)
>  Medical image data are usually imbalanced across different classes. One-class classification has attracted increasing attention to address the data imbalance problem by distinguishing the samples of the minority class from the majority class. Previous methods generally aim to either learn a new feature space to map training samples together or to fit training samples by autoencoder-like models. These methods mainly focus on capturing either compact or descriptive features, where the information of the samples of a given one class is not sufficiently utilized. In this paper, we propose a novel deep learning-based method to learn compact features by adding constraints on the bottleneck features, and to preserve descriptive features by training an autoencoder at the same time. Through jointly optimizing the constraining loss and the autoencoder's reconstruction loss, our method can learn more relevant features associated with the given class, making the majority and minority samples more distinguishable. Experimental results on three clinical datasets (including the MRI breast images, FFDM breast images and chest X-ray images) obtains state-of-art performance compared to previous methods.      
### 44.Semi-supervised Impedance Inversion by Bayesian Neural Network Based on 2-d CNN Pre-training  [ :arrow_down: ](https://arxiv.org/pdf/2111.10596.pdf)
>  Seismic impedance inversion can be performed with a semi-supervised learning algorithm, which only needs a few logs as labels and is less likely to get overfitted. However, classical semi-supervised learning algorithm usually leads to artifacts on the predicted impedance image. In this artical, we improve the semi-supervised learning from two aspects. First, by replacing 1-d convolutional neural network (CNN) layers in deep learning structure with 2-d CNN layers and 2-d maxpooling layers, the prediction accuracy is improved. Second, prediction uncertainty can also be estimated by embedding the network into a Bayesian inference framework. Local reparameterization trick is used during forward propagation of the network to reduce sampling cost. Tests with Marmousi2 model and SEAM model validate the feasibility of the proposed strategy.      
### 45.Vehicular Visible Light Communications Noise Analysis and Autoencoder Based Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2111.10588.pdf)
>  Vehicular visible light communications (V-VLC) is a promising intelligent transportation systems (ITS) technology for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications with the utilization of light-emitting diodes (LEDs). The main degrading factor for the performance of V-VLC systems is noise. Unlike traditional radio frequency (RF) based systems, V-VLC systems include many noise sources: solar radiation, background lighting from vehicles, streets, parking garages, and tunnel lights. Traditional V-VLC system noise modeling is based on the additive white Gaussian noise assumption in the form of shot and thermal noise. In this paper, to investigate both time-correlated and white noise components of the V-VLC channel, we propose a noise analysis based on Allan variance (AVAR), which provides a time-series analysis method to identify noise from the data. We also propose a generalized Wiener process-based V-VLC channel noise synthesis methodology to generate different noise components. We further propose a convolutional autoencoder(CAE) based denoising scheme to reduce V-VLC signal noise, which achieves reconstruction root mean square error (RMSE) of 0.0442 and 0.0474 for indoor and outdoor channels, respectively.      
### 46.Satellite Based Computing Networks with Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.10586.pdf)
>  Driven by the ever-increasing penetration and proliferation of data-driven applications, a new generation of wireless communication, the sixth-generation (6G) mobile system enhanced by artificial intelligence (AI), has attracted substantial research interests. Among various candidate technologies of 6G, low earth orbit (LEO) satellites have appealing characteristics of ubiquitous wireless access. However, the costs of satellite communication (SatCom) are still high, relative to counterparts of ground mobile networks. To support massively interconnected devices with intelligent adaptive learning and reduce expensive traffic in SatCom, we propose federated learning (FL) in LEO-based satellite communication networks. We first review the state-of-the-art LEO-based SatCom and related machine learning (ML) techniques, and then analyze four possible ways of combining ML with satellite networks. The learning performance of the proposed strategies is evaluated by simulation and results reveal that FL-based computing networks improve the performance of communication overheads and latency. Finally, we discuss future research topics along this research direction.      
### 47.Switching Independent Vector Analysis and Its Extension to Blind and Spatially Guided Convolutional Beamforming Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2111.10574.pdf)
>  This paper develops a framework that can perform denoising, dereverberation, and source separation accurately by using a relatively small number of microphones. It has been empirically confirmed that Independent Vector Analysis (IVA) can blindly separate $N$ sources from their sound mixture even with diffuse noise when a sufficiently large number ($=M$) of microphones are available (i.e., $M\gg N)$. However, the estimation accuracy seriously degrades as the number of microphones, or more specifically $M-N$ $(\ge 0)$, decreases. To overcome this limitation of IVA, we propose switching IVA (swIVA) in this paper. With swIVA, time frames of an observed signal with time-varying characteristics are clustered into several groups, each of which can be well handled by IVA using a small number of microphones, and thus accurate estimation can be achieved by applying {\IVA} individually to each of the groups. Conventionally, a switching mechanism was introduced into a beamformer; however, no blind source separation algorithms with a switching mechanism have been successfully developed until this paper. In order to incorporate dereverberation capability, this paper further extends swIVA to blind Convolutional beamforming algorithm (swCIVA). It integrates swIVA and switching Weighted Prediction Error-based dereverberation (swWPE) in a jointly optimal way. We show that both swIVA and swIVAconv can be optimized effectively based on blind signal processing, and that their performance can be further improved using a spatial guide for the initialization. Experiments show that the both proposed methods largely outperform conventional IVA and its Convolutional beamforming extension (CIVA) in terms of objective signal quality and automatic speech recognition scores when using a relatively small number of microphones.      
### 48.Passivity-based Analysis and Design for Population Dynamics with Conformity Biases  [ :arrow_down: ](https://arxiv.org/pdf/2111.10560.pdf)
>  This paper addresses mechanisms for boundedly rational decision makers in discrete choice problem. First, we introduce two mathematical models of population dynamics with conformity biases. We next analyze the models in terms of delta-passivity, and show that the conformity biases work to break passivity of decision makers. Based on the passivity perspective, we propose mechanisms so as to induce decision makers to a desired population state. Furthermore, we analyze a convergence property of designed mechanisms, and present parameter conditions to guarantee stable inducements.      
### 49.Pre-scaling and Codebook Design for Joint Radar and Communication Based on Index Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10527.pdf)
>  This paper develops an efficient index modulation (IM) approach for the joint radar-communication (JRC) system based on a multi-carrier multiple-input multiple-output (MIMO) radar. The communication information is embedded into the transmitted radar pulses by selecting the corresponding indices of the carrier frequencies and antenna allocations, providing two degrees of freedom. Our contribution involves the development of a novel codebook based minimum Euclidean distance (MED) maximization and a constellation randomization pre-scaling (CRPS) scheme for efficient IM-JRC transmission. It can be inferred that the IM approach integrating the CRPS scheme followed by the codebook design maximizes the signal-to-noise ratio gain. The numerical results support the effectiveness of the proposed approach and show enhanced bit error rate performance when compared to the existing baseline.      
### 50.A Novel Data Segmentation Method for Data-driven Phase Identification  [ :arrow_down: ](https://arxiv.org/pdf/2111.10500.pdf)
>  This paper presents a smart meter phase identification algorithm for two cases: meter-phase-label-known and meter-phase-label-unknown. To improve the identification accuracy, a data segmentation method is proposed to exclude data segments that are collected when the voltage correlation between smart meters on the same phase are weakened. Then, using the selected data segments, a hierarchical clustering method is used to calculate the correlation distances and cluster the smart meters. If the phase labels are unknown, a Connected-Triple-based Similarity (CTS) method is adapted to further improve the phase identification accuracy of the ensemble clustering method. The methods are developed and tested on both synthetic and real feeder data sets. Simulation results show that the proposed phase identification algorithm outperforms the state-of-the-art methods in both accuracy and robustness.      
### 51.TransMorph: Transformer for unsupervised medical image registration  [ :arrow_down: ](https://arxiv.org/pdf/2111.10480.pdf)
>  In the last decade, convolutional neural networks (ConvNets) have dominated the field of medical image analysis. However, it is found that the performances of ConvNets may still be limited by their inability to model long-range spatial relations between voxels in an image. Numerous vision Transformers have been proposed recently to address the shortcomings of ConvNets, demonstrating state-of-the-art performances in many medical imaging applications. Transformers may be a strong candidate for image registration because their self-attention mechanism enables a more precise comprehension of the spatial correspondence between moving and fixed images. In this paper, we present TransMorph, a hybrid Transformer-ConvNet model for volumetric medical image registration. We also introduce three variants of TransMorph, with two diffeomorphic variants ensuring the topology-preserving deformations and a Bayesian variant producing a well-calibrated registration uncertainty estimate. The proposed models are extensively validated against a variety of existing registration methods and Transformer architectures using volumetric medical images from two applications: inter-patient brain MRI registration and phantom-to-CT registration. Qualitative and quantitative results demonstrate that TransMorph and its variants lead to a substantial performance improvement over the baseline methods, demonstrating the effectiveness of Transformers for medical image registration.      
### 52.Fuzzy Lifetime Analysis of a Fault-Tolerant Two-Phase Interleaved Converter  [ :arrow_down: ](https://arxiv.org/pdf/2111.10377.pdf)
>  Interleaved converters are used in photovoltaic (PV) applications to handle high power conditions with high reliability. To improve the reliability of these converters, redundant switch configuration can be employed which reduce the failure rates of the power switches significantly. However, evaluation reliability of the interleaved converters equipped with redundant switch configurations may be complex. This paper aims to simplify the reliability Analysis of interleaved converters considering mission profile and redundant switch configuration. Different possible configurations of the studied converter are shown as Markov chain states in the proposed method, which simplify the reliability and failure rates Analysis. The effect of different parameters such as the converter power level, switch configuration type, and operation modes are derived and a better insight into the effectiveness of the switch configuration on improving the reliability is provided.      
### 53.Diabetic Foot Ulcer Grand Challenge 2021: Evaluation and Summary  [ :arrow_down: ](https://arxiv.org/pdf/2111.10376.pdf)
>  Diabetic foot ulcer classification systems use the presence of wound infection (bacteria present within the wound) and ischaemia (restricted blood supply) as vital clinical indicators for treatment and prediction of wound healing. Studies investigating the use of automated computerised methods of classifying infection and ischaemia within diabetic foot wounds are limited due to a paucity of publicly available datasets and severe data imbalance in those few that exist. The Diabetic Foot Ulcer Challenge 2021 provided participants with a more substantial dataset comprising a total of 15,683 diabetic foot ulcer patches, with 5,955 used for training, 5,734 used for testing and an additional 3,994 unlabelled patches to promote the development of semi-supervised and weakly-supervised deep learning techniques. This paper provides an evaluation of the methods used in the Diabetic Foot Ulcer Challenge 2021, and summarises the results obtained from each network. The best performing network was an ensemble of the results of the top 3 models, with a macro-average F1-score of 0.6307.      
### 54.Resistance-Time Co-Modulated PointNet for Temporal Super-Resolution Simulation of Blood Vessel Flows  [ :arrow_down: ](https://arxiv.org/pdf/2111.10372.pdf)
>  In this paper, a novel deep learning framework is proposed for temporal super-resolution simulation of blood vessel flows, in which a high-temporal-resolution time-varying blood vessel flow simulation is generated from a low-temporal-resolution flow simulation result. In our framework, point-cloud is used to represent the complex blood vessel model, resistance-time aided PointNet model is proposed for extracting the time-space features of the time-varying flow field, and finally we can reconstruct the high-accuracy and high-resolution flow field through the Decoder module. In particular, the amplitude loss and the orientation loss of the velocity are proposed from the vector characteristics of the velocity. And the combination of these two metrics constitutes the final loss function for network training. Several examples are given to illustrate the effective and efficiency of the proposed framework for temporal super-resolution simulation of blood vessel flows.      
### 55.ColDE: A Depth Estimation Framework for Colonoscopy Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2111.10371.pdf)
>  One of the key elements of reconstructing a 3D mesh from a monocular video is generating every frame's depth map. However, in the application of colonoscopy video reconstruction, producing good-quality depth estimation is challenging. Neural networks can be easily fooled by photometric distractions or fail to capture the complex shape of the colon surface, predicting defective shapes that result in broken meshes. Aiming to fundamentally improve the depth estimation quality for colonoscopy 3D reconstruction, in this work we have designed a set of training losses to deal with the special challenges of colonoscopy data. For better training, a set of geometric consistency objectives was developed, using both depth and surface normal information. Also, the classic photometric loss was extended with feature matching to compensate for illumination noise. With the training losses powerful enough, our self-supervised framework named ColDE is able to produce better depth maps of colonoscopy data as compared to the previous work utilizing prior depth knowledge. Used in reconstruction, our network is able to reconstruct good-quality colon meshes in real-time without any post-processing, making it the first to be clinically applicable.      
### 56.Turbo Autoencoder with a Trainable Interleaver  [ :arrow_down: ](https://arxiv.org/pdf/2111.11410.pdf)
>  A critical aspect of reliable communication involves the design of codes that allow transmissions to be robustly and computationally efficiently decoded under noisy conditions. Advances in the design of reliable codes have been driven by coding theory and have been sporadic. Recently, it is shown that channel codes that are comparable to modern codes can be learned solely via deep learning. In particular, Turbo Autoencoder (TURBOAE), introduced by Jiang et al., is shown to achieve the reliability of Turbo codes for Additive White Gaussian Noise channels. In this paper, we focus on applying the idea of TURBOAE to various practical channels, such as fading channels and chirp noise channels. We introduce TURBOAE-TI, a novel neural architecture that combines TURBOAE with a trainable interleaver design. We develop a carefully-designed training procedure and a novel interleaver penalty function that are crucial in learning the interleaver and TURBOAE jointly. We demonstrate that TURBOAE-TI outperforms TURBOAE and LTE Turbo codes for several channels of interest. We also provide interpretation analysis to better understand TURBOAE-TI.      
### 57.Improved Model based Deep Learning using Monotone Operator Learning (MOL)  [ :arrow_down: ](https://arxiv.org/pdf/2111.11380.pdf)
>  Model-based deep learning (MoDL) algorithms that rely on unrolling are emerging as powerful tools for image recovery. In this work, we introduce a novel monotone operator learning framework to overcome some of the challenges associated with current unrolled frameworks, including high memory cost, lack of guarantees on robustness to perturbations, and low interpretability. Unlike current unrolled architectures that use finite number of iterations, we use the deep equilibrium (DEQ) framework to iterate the algorithm to convergence and to evaluate the gradient of the convolutional neural network blocks using Jacobian iterations. This approach significantly reduces the memory demand, facilitating the extension of MoDL algorithms to high dimensional problems. We constrain the CNN to be a monotone operator, which allows us to introduce algorithms with guaranteed convergence properties and robustness guarantees. We demonstrate the utility of the proposed scheme in the context of parallel MRI.      
### 58.Adversarial Examples on Segmentation Models Can be Easy to Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2111.11368.pdf)
>  Deep neural network-based image classification can be misled by adversarial examples with small and quasi-imperceptible perturbations. Furthermore, the adversarial examples created on one classification model can also fool another different model. The transferability of the adversarial examples has recently attracted a growing interest since it makes black-box attacks on classification models feasible. As an extension of classification, semantic segmentation has also received much attention towards its adversarial robustness. However, the transferability of adversarial examples on segmentation models has not been systematically studied. In this work, we intensively study this topic. First, we explore the overfitting phenomenon of adversarial examples on classification and segmentation models. In contrast to the observation made on classification models that the transferability is limited by overfitting to the source model, we find that the adversarial examples on segmentations do not always overfit the source models. Even when no overfitting is presented, the transferability of adversarial examples is limited. We attribute the limitation to the architectural traits of segmentation models, i.e., multi-scale object recognition. Then, we propose a simple and effective method, dubbed dynamic scaling, to overcome the limitation. The high transferability achieved by our method shows that, in contrast to the observations in previous work, adversarial examples on a segmentation model can be easy to transfer to other segmentation models. Our analysis and proposals are supported by extensive experiments.      
### 59.Environment-Aware Beam Selection for IRS-Aided Communication with Channel Knowledge Map  [ :arrow_down: ](https://arxiv.org/pdf/2111.11289.pdf)
>  Intelligent reflecting surface (IRS)-aided communication is a promising technology for beyond 5G (B5G) systems, to reconfigure the radio environment proactively. However, IRS-aided communication in practice requires efficient channel estimation or passive beam training, whose overhead and complexity increase drastically with the number of reflecting elements/beam directions. To tackle this challenge, we propose in this paper a novel environment-aware joint active and passive beam selection scheme for IRS-aided wireless communication, based on the new concept of channel knowledge map (CKM). Specifically, by utilizing both the location information of the user equipment (UE), which is readily available in contemporary wireless systems with ever-increasing accuracy, and the environment information offered by CKM, the proposed scheme achieves efficient beam selection with either no real-time training required (training-free beam selection) or only moderate training overhead (light-training beam selection). Numerical results based on practical channels obtained using commercial ray tracing software are presented, which demonstrate the superior performance of the proposed scheme over various benchmark schemes.      
### 60.BarrierNet: A Safety-Guaranteed Layer for Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.11277.pdf)
>  This paper introduces differentiable higher-order control barrier functions (CBF) that are end-to-end trainable together with learning systems. CBFs are usually overly conservative, while guaranteeing safety. Here, we address their conservativeness by softening their definitions using environmental dependencies without loosing safety guarantees, and embed them into differentiable quadratic programs. These novel safety layers, termed a BarrierNet, can be used in conjunction with any neural network-based controller, and can be trained by gradient descent. BarrierNet allows the safety constraints of a neural controller be adaptable to changing environments. We evaluate them on a series of control problems such as traffic merging and robot navigations in 2D and 3D space, and demonstrate their effectiveness compared to state-of-the-art approaches.      
### 61.Machine Learning-Based Soft Sensors for Vacuum Distillation Unit  [ :arrow_down: ](https://arxiv.org/pdf/2111.11251.pdf)
>  Product quality assessment in the petroleum processing industry can be difficult and time-consuming, e.g. due to a manual collection of liquid samples from the plant and subsequent chemical laboratory analysis of the samples. The product quality is an important property that informs whether the products of the process are within the specifications. In particular, the delays caused by sample processing (collection, laboratory measurements, results analysis, reporting) can lead to detrimental economic effects. One of the strategies to deal with this problem is soft sensors. Soft sensors are a collection of models that can be used to predict and forecast some infrequently measured properties (such as laboratory measurements of petroleum products) based on more frequent measurements of quantities like temperature, pressure and flow rate provided by physical sensors. Soft sensors short-cut the pathway to obtain relevant information about the product quality, often providing measurements as frequently as every minute. One of the applications of soft sensors is for the real-time optimization of a chemical process by a targeted adaptation of operating parameters. Models used for soft sensors can have various forms, however, among the most common are those based on artificial neural networks (ANNs). While soft sensors can deal with some of the issues in the refinery processes, their development and deployment can pose other challenges that are addressed in this paper. Firstly, it is important to enhance the quality of both sets of data (laboratory measurements and physical sensors) in a data pre-processing stage (as described in Methodology section). Secondly, once the data sets are pre-processed, different models need to be tested against prediction error and the model's interpretability. In this work, we present a framework for soft sensor development from raw data to ready-to-use models.      
### 62.Action Recognition with Domain Invariant Features of Skeleton Image  [ :arrow_down: ](https://arxiv.org/pdf/2111.11250.pdf)
>  Due to the fast processing-speed and robustness it can achieve, skeleton-based action recognition has recently received the attention of the computer vision community. The recent Convolutional Neural Network (CNN)-based methods have shown commendable performance in learning spatio-temporal representations for skeleton sequence, which use skeleton image as input to a CNN. Since the CNN-based methods mainly encoding the temporal and skeleton joints simply as rows and columns, respectively, the latent correlation related to all joints may be lost caused by the 2D convolution. To solve this problem, we propose a novel CNN-based method with adversarial training for action recognition. We introduce a two-level domain adversarial learning to align the features of skeleton images from different view angles or subjects, respectively, thus further improve the generalization. We evaluated our proposed method on NTU RGB+D. It achieves competitive results compared with state-of-the-art methods and 2.4$\%$, 1.9$\%$ accuracy gain than the baseline for cross-subject and cross-view.      
### 63.Towards Understanding the Unreasonable Effectiveness of Learning AC-OPF Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2111.11168.pdf)
>  Optimal Power Flow (OPF) is a fundamental problem in power systems. It is computationally challenging and a recent line of research has proposed the use of Deep Neural Networks (DNNs) to find OPF approximations at vastly reduced runtimes when compared to those obtained by classical optimization methods. While these works show encouraging results in terms of accuracy and runtime, little is known on why these models can predict OPF solutions accurately, as well as about their robustness. This paper provides a step forward to address this knowledge gap. The paper connects the volatility of the outputs of the generators to the ability of a learning model to approximate them, it sheds light on the characteristics affecting the DNN models to learn good predictors, and it proposes a new model that exploits the observations made by this paper to produce accurate and robust OPF predictions.      
### 64.Data Sensing and Offloading in Edge Computing Networks: TDMA or NOMA?  [ :arrow_down: ](https://arxiv.org/pdf/2111.11112.pdf)
>  With the development of Internet-of-Things (IoT), we witness the explosive growth in the number of devices with sensing, computing, and communication capabilities, along with a large amount of raw data generated at the network edge. Mobile (multi-access) edge computing (MEC), acquiring and processing data at network edge (like base station (BS)) via wireless links, has emerged as a promising technique for real-time applications. In this paper, we consider the scenario that multiple devices sense then offload data to an edge server/BS, and the offloading throughput maximization problems are studied by joint radio-and-computation resource allocation, based on time-division multiple access (TDMA) and non-orthogonal multiple access (NOMA) multiuser computation offloading. Particularly, we take the sequence of TDMA-based multiuser transmission/offloading into account. The studied problems are NP-hard and non-convex. A set of low-complexity algorithms are designed based on decomposition approach and exploration of valuable insights of problems. They are either optimal or can achieve close-to-optimal performance as shown by simulation. The comprehensive simulation results show that the sequence optimized TDMA scheme achieves better throughput performance than the NOMA scheme, while the NOMA scheme is better under the assumptions of time-sharing strategy and the identical sensing capability of the devices.      
### 65.An Asymptotically Optimal Approximation of the Conditional Mean Channel Estimator based on Gaussian Mixture Models  [ :arrow_down: ](https://arxiv.org/pdf/2111.11064.pdf)
>  This paper investigates a channel estimator based on Gaussian mixture models (GMMs). We fit a GMM to given channel samples to obtain an analytic probability density function (PDF) which approximates the true channel PDF. Then, a conditional mean channel estimator corresponding to this approximating PDF is computed in closed form and used as an approximation of the optimal conditional mean estimator based on the true channel PDF. This optimal estimator cannot be calculated analytically because the true channel PDF is generally not available. To motivate the GMM-based estimator, we show that it converges to the optimal conditional mean estimator as the number of GMM components is increased. In numerical experiments, a reasonable number of GMM components already shows promising estimation results.      
### 66.Comparing the Accuracy of Deep Neural Networks (DNN) and Convolutional Neural Network (CNN) in Music Genre Recognition (MGR): Experiments on Kurdish Music  [ :arrow_down: ](https://arxiv.org/pdf/2111.11063.pdf)
>  Musicologists use various labels to classify similar music styles under a shared title. But, non-specialists may categorize music differently. That could be through finding patterns in harmony, instruments, and form of the music. People usually identify a music genre solely by listening, but now computers and Artificial Intelligence (AI) can automate this process. The work on applying AI in the classification of types of music has been growing recently, but there is no evidence of such research on the Kurdish music genres. In this research, we developed a dataset that contains 880 samples from eight different Kurdish music genres. We evaluated two machine learning approaches, a Deep Neural Network (DNN) and a Convolutional Neural Network (CNN), to recognize the genres. The results showed that the CNN model outperformed the DNN by achieving 92% versus 90% accuracy.      
### 67.Capacity Optimal Generalized Multi-User MIMO: A Theoretical and Practical Framework  [ :arrow_down: ](https://arxiv.org/pdf/2111.11061.pdf)
>  Conventional multi-user multiple-input multiple-output (MU-MIMO) mainly focused on Gaussian signaling, independent and identically distributed (IID) channels, and a limited number of users. It will be laborious to cope with the heterogeneous requirements in next-generation wireless communications, such as various transmission data, complicated communication scenarios, and massive user access. Therefore, this paper studies a generalized MU-MIMO (GMU-MIMO) system with more practical constraints, i.e., non-Gaussian signaling, non-IID channel, and massive users and antennas. These generalized assumptions bring new challenges in theory and practice. For example, there is no accurate capacity analysis for GMU-MIMO. In addition, it is unclear how to achieve the capacity optimal performance with practical complexity. <br>To address these challenges, a unified framework is proposed to derive the GMU-MIMO capacity and design a capacity optimal transceiver, which jointly considers encoding, modulation, detection, and decoding. Group asymmetry is developed to make a tradeoff between user rate allocation and implementation complexity. Specifically, the capacity region of group asymmetric GMU-MIMO is characterized by using the celebrated mutual information and minimum mean-square error (MMSE) lemma and the MMSE optimality of orthogonal approximate message passing (OAMP)/vector AMP (VAMP). Furthermore, a theoretically optimal multi-user OAMP/VAMP receiver and practical multi-user low-density parity-check (MU-LDPC) codes are proposed to achieve the capacity region of group asymmetric GMU-MIMO. Numerical results verify that the gaps between theoretical detection thresholds of the proposed framework with optimized MU-LDPC codes and QPSK modulation and the sum capacity of GMU-MIMO are about 0.2 dB. Moreover, their finite-length performances are about 1~2 dB away from the associated sum capacity.      
### 68.Multi-Channel Multi-Speaker ASR Using 3D Spatial Feature  [ :arrow_down: ](https://arxiv.org/pdf/2111.11023.pdf)
>  Automatic speech recognition (ASR) of multi-channel multi-speaker overlapped speech remains one of the most challenging tasks to the speech community. In this paper, we look into this challenge by utilizing the location information of target speakers in the 3D space for the first time. To explore the strength of proposed the 3D spatial feature, two paradigms are investigated. 1) a pipelined system with a multi-channel speech separation module followed by the state-of-the-art single-channel ASR module; 2) a "All-In-One" model where the 3D spatial feature is directly used as an input to ASR system without explicit separation modules. Both of them are fully differentiable and can be back-propagated end-to-end. We test them on simulated overlapped speech and real recordings. Experimental results show that 1) the proposed ALL-In-One model achieved a comparable error rate to the pipelined system while reducing the inference time by half; 2) the proposed 3D spatial feature significantly outperformed (31\% CERR) all previous works of using the 1D directional information in both paradigms.      
### 69.Imperceptible Transfer Attack and Defense on 3D Point Cloud Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.10990.pdf)
>  Although many efforts have been made into attack and defense on the 2D image domain in recent years, few methods explore the vulnerability of 3D models. Existing 3D attackers generally perform point-wise perturbation over point clouds, resulting in deformed structures or outliers, which is easily perceivable by humans. Moreover, their adversarial examples are generated under the white-box setting, which frequently suffers from low success rates when transferred to attack remote black-box models. In this paper, we study 3D point cloud attacks from two new and challenging perspectives by proposing a novel Imperceptible Transfer Attack (ITA): 1) Imperceptibility: we constrain the perturbation direction of each point along its normal vector of the neighborhood surface, leading to generated examples with similar geometric properties and thus enhancing the imperceptibility. 2) Transferability: we develop an adversarial transformation model to generate the most harmful distortions and enforce the adversarial examples to resist it, improving their transferability to unknown black-box models. Further, we propose to train more robust black-box 3D models to defend against such ITA attacks by learning more discriminative point cloud representations. Extensive evaluations demonstrate that our ITA attack is more imperceptible and transferable than state-of-the-arts and validate the superiority of our defense strategy.      
### 70.Efficient Non-Compression Auto-Encoder for Driving Noise-based Road Surface Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.10985.pdf)
>  Wet weather makes water film over the road and that film causes lower friction between tire and road surface. When a vehicle passes the low-friction road, the accident can occur up to 35% higher frequency than a normal condition road. In order to prevent accidents as above, identifying the road condition in real-time is essential. Thus, we propose a convolutional auto-encoder-based anomaly detection model for taking both less computational resources and achieving higher anomaly detection performance. The proposed model adopts a non-compression method rather than a conventional bottleneck structured auto-encoder. As a result, the computational cost of the neural network is reduced up to 1 over 25 compared to the conventional models and the anomaly detection performance is improved by up to 7.72%. Thus, we conclude the proposed model as a cutting-edge algorithm for real-time anomaly detection.      
### 71.Operations for Autonomous Spacecraft  [ :arrow_down: ](https://arxiv.org/pdf/2111.10970.pdf)
>  Onboard autonomy technologies such as planning and scheduling, identification of scientific targets, and content-based data summarization, will lead to exciting new space science missions. However, the challenge of operating missions with such onboard autonomous capabilities has not been studied to a level of detail sufficient for consideration in mission concepts. These autonomy capabilities will require changes to current operations processes, practices, and tools. We have developed a case study to assess the changes needed to enable operators and scientists to operate an autonomous spacecraft by facilitating a common model between the ground personnel and the onboard algorithms. We assess the new operations tools and workflows necessary to enable operators and scientists to convey their desired intent to the spacecraft, and to be able to reconstruct and explain the decisions made onboard and the state of the spacecraft. Mock-ups of these tools were used in a user study to understand the effectiveness of the processes and tools in enabling a shared framework of understanding, and in the ability of the operators and scientists to effectively achieve mission science objectives.      
### 72.Generation Drawing/Grinding Trajectoy Based on Hierarchical CVAE  [ :arrow_down: ](https://arxiv.org/pdf/2111.10954.pdf)
>  In this study, we propose a method to model the local and global features of the drawing/grinding trajectory with hierarchical Variational Autoencoders (VAEs). By combining two separately trained VAE models in a hierarchical structure, it is possible to generate trajectories with high reproducibility for both local and global features. The hierarchical generation network enables the generation of higher-order trajectories with a relatively small amount of training data. The simulation and experimental results demonstrate the generalization performance of the proposed method. In addition, we confirmed that it is possible to generate new trajectories, which have never been learned in the past, by changing the combination of the learned models.      
### 73.Decentralized Multi-Armed Bandit Can Outperform Classic Upper Confidence Bound  [ :arrow_down: ](https://arxiv.org/pdf/2111.10933.pdf)
>  This paper studies a decentralized multi-armed bandit problem in a multi-agent network. The problem is simultaneously solved by N agents assuming they face a common set of M arms and share the same mean of each arm's reward. Each agent can receive information only from its neighbors, where the neighbor relations among the agents are described by a directed graph whose vertices represent agents and whose directed edges depict neighbor relations. A fully decentralized multi-armed bandit algorithm is proposed for each agent, which twists the classic consensus algorithm and upper confidence bound (UCB) algorithm. It is shown that the algorithm guarantees each agent to achieve a better logarithmic asymptotic regret than the classic UCB provided the neighbor graph is strongly connected. The regret can be further improved if the neighbor graph is undirected.      
### 74.Renewable energy integration and microgrid energy trading using multi-agent deep reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.10898.pdf)
>  In this paper, multi-agent reinforcement learning is used to control a hybrid energy storage system working collaboratively to reduce the energy costs of a microgrid through maximising the value of renewable energy and trading. The agents must learn to control three different types of energy storage system suited for short, medium, and long-term storage under fluctuating demand, dynamic wholesale energy prices, and unpredictable renewable energy generation. Two case studies are considered: the first looking at how the energy storage systems can better integrate renewable energy generation under dynamic pricing, and the second with how those same agents can be used alongside an aggregator agent to sell energy to self-interested external microgrids looking to reduce their own energy bills. This work found that the centralised learning with decentralised execution of the multi-agent deep deterministic policy gradient and its state-of-the-art variants allowed the multi-agent methods to perform significantly better than the control from a single global agent. It was also found that using separate reward functions in the multi-agent approach performed much better than using a single control agent. Being able to trade with the other microgrids, rather than just selling back to the utility grid, also was found to greatly increase the grid's savings.      
### 75.Health Monitoring of Industrial machines using Scene-Aware Threshold Selection  [ :arrow_down: ](https://arxiv.org/pdf/2111.10897.pdf)
>  This paper presents an autoencoder based unsupervised approach to identify anomaly in an industrial machine using sounds produced by the machine. The proposed framework is trained using log-melspectrogram representations of the sound signal. In classification, our hypothesis is that the reconstruction error computed for an abnormal machine is larger than that of the a normal machine, since only normal machine sounds are being used to train the autoencoder. A threshold is chosen to discriminate between normal and abnormal machines. However, the threshold changes as surrounding conditions vary. To select an appropriate threshold irrespective of the surrounding, we propose a scene classification framework, which can classify the underlying surrounding. Hence, the threshold can be selected adaptively irrespective of the surrounding. The experiment evaluation is performed on MIMII dataset for industrial machines namely fan, pump, valve and slide rail. Our experiment analysis shows that utilizing adaptive threshold, the performance improves significantly as that obtained using the fixed threshold computed for a given surrounding only.      
### 76.Geometry-Aware Multi-Task Learning for Binaural Audio Generation from Video  [ :arrow_down: ](https://arxiv.org/pdf/2111.10882.pdf)
>  Binaural audio provides human listeners with an immersive spatial sound experience, but most existing videos lack binaural audio recordings. We propose an audio spatialization method that draws on visual information in videos to convert their monaural (single-channel) audio to binaural audio. Whereas existing approaches leverage visual features extracted directly from video frames, our approach explicitly disentangles the geometric cues present in the visual stream to guide the learning process. In particular, we develop a multi-task framework that learns geometry-aware features for binaural audio generation by accounting for the underlying room impulse response, the visual stream's coherence with the sound source(s) positions, and the consistency in geometry of the sounding objects over time. Furthermore, we introduce a new large video dataset with realistic binaural audio simulated for real-world scanned environments. On two datasets, we demonstrate the efficacy of our method, which achieves state-of-the-art results.      
### 77.A Software Tool for Evaluating Unmanned Autonomous Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.10871.pdf)
>  The North Carolina Agriculture and Technical State University (NC A&amp;T) in collaboration with Georgia Tech Research Institute (GTRI) has developed methodologies for creating simulation-based technology tools that are capable of inferring the perceptions and behavioral states of autonomous systems. These methodologies have the potential to provide the Test and Evaluation (T&amp;E) community at the Department of Defense (DoD) with a greater insight into the internal processes of these systems. The methodologies use only external observations and do not require complete knowledge of the internal processing of and/or any modifications to the system under test. This paper presents an example of one such simulation-based technology tool, named as the Data-Driven Intelligent Prediction Tool (DIPT). DIPT was developed for testing a multi-platform Unmanned Aerial Vehicle (UAV) system capable of conducting collaborative search missions. DIPT's Graphical User Interface (GUI) enables the testers to view the aircraft's current operating state, predicts its current target-detection status, and provides reasoning for exhibiting a particular behavior along with an explanation of assigning a particular task to it.      
### 78.Calibrated Diffusion Tensor Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10847.pdf)
>  It is highly desirable to know how uncertain a model's predictions are, especially for models that are complex and hard to understand as in deep learning. Although there has been a growing interest in using deep learning methods in diffusion-weighted MRI, prior works have not addressed the issue of model uncertainty. Here, we propose a deep learning method to estimate the diffusion tensor and compute the estimation uncertainty. Data-dependent uncertainty is computed directly by the network and learned via loss attenuation. Model uncertainty is computed using Monte Carlo dropout. We also propose a new method for evaluating the quality of predicted uncertainties. We compare the new method with the standard least-squares tensor estimation and bootstrap-based uncertainty computation techniques. Our experiments show that when the number of measurements is small the deep learning method is more accurate and its uncertainty predictions are better calibrated than the standard methods. We show that the estimation uncertainties computed by the new method can highlight the model's biases, detect domain shift, and reflect the strength of noise in the measurements. Our study shows the importance and practical value of modeling prediction uncertainties in deep learning-based diffusion MRI analysis.      
### 79.Reconfigurable Intelligent Surfaces: Performance Assessment Through a System-Level Simulator  [ :arrow_down: ](https://arxiv.org/pdf/2111.10791.pdf)
>  Reconfigurable intelligent surfaces (RISs) are considered a promising technology for boosting the coverage and for enhancing the spectral efficiency of wireless systems, as well as for taming the wireless environment. The potential benefits of RISs are currently being analyzed and various approaches are being proposed to address some challenges for their integration in wireless networks. Currently available studies to quantify the potential gains of deploying RISs in wireless networks are limited to simple network topologies, while no system-level assessments have been reported to date. Network-level, e.g., on the scale of hundreds of square meters, simulations are, however, the first step to quantify the actual value of emerging technologies and the steppingstone before considering large scale system-level experimental evaluations and network deployments. Towards this direction, this article reports the first system-level simulation results and analysis of an RIS deployment in a typical urban city that is served by a fifth-generation cellular network. The obtained system-level simulation results unveil that the benefits of RISs vary depending on the operating frequency and the size of the surfaces. Specifically, we investigate the performance improvement that RISs can provide, in terms of outdoor and indoor coverage and ergodic rate, when deployed in mid (C-band) and high (millimeter-wave) frequency bands. For example, the obtained results unveil that the deployment of RISs enhances the coverage of cell-edge users from 77% to 95% in the C-band and from 46% to 95% in the millimeter-wave band.      
### 80.Automatic Detection of Depression from Stratified Samples of Audio Data  [ :arrow_down: ](https://arxiv.org/pdf/2111.10783.pdf)
>  Depression is a common mental disorder which has been affecting millions of people around the world and becoming more severe with the arrival of COVID-19. Nevertheless proper diagnosis is not accessible in many regions due to a severe shortage of psychiatrists. This scarcity is worsened in low-income countries which have a psychiatrist to population ratio 210 times lower than that of countries with better economies. This study aimed to explore applications of deep learning in diagnosing depression from voice samples. We collected data from the DAIC-WOZ database which contained 189 vocal recordings from 154 individuals. Voice samples from a patient with a PHQ-8 score equal or higher than 10 were deemed as depressed and those with a PHQ-8 score lower than 10 were considered healthy. We applied mel-spectrogram to extract relevant features from the audio. Three types of encoders were tested i.e. 1D CNN, 1D CNN-LSTM, and 1D CNN-GRU. After tuning hyperparameters systematically, we found that 1D CNN-GRU encoder with a kernel size of 5 and 15 seconds of recording data appeared to have the best performance with F1 score of 0.75, precision of 0.64, and recall of 0.92.      
### 81.The KICK-OFF of 6G Research Worldwide: An Overview  [ :arrow_down: ](https://arxiv.org/pdf/2111.10779.pdf)
>  The fifth-generation (5G) mobile system is now being deployed across the world and the scale of 5G subscribers is growing quickly in many countries. The attention of academia and industry is increasingly shifting towards the sixth generation (6G) and many pioneering works are being kicked off, indicating an important milestone in the history of 6G. At this juncture, an overview of the current state of the art of 6G research and a vision of future communications are of great interest. This paper thus investigates up-to-date 6G research programs, ambitions, and main viewpoints of representative countries, institutions, and companies worldwide. Then, the key technologies are outlined and a vision on ``What 6G may look like?" is provided. This paper aims to serve as an enlightening guideline for interested researchers to quickly get an overview when kicking off their 6G research.      
### 82.Design of an Novel Spectrum Sensing Scheme Based on Long Short-Term Memory and Experimental Validation  [ :arrow_down: ](https://arxiv.org/pdf/2111.10769.pdf)
>  Spectrum sensing allows cognitive radio systems to detect relevant signals in despite the presence of severe interference. Most of the existing spectrum sensing techniques use a particular signal-noise model with certain assumptions and derive certain detection performance. To deal with this uncertainty, learning based approaches are being adopted and more recently deep learning based tools have become popular. Here, we propose an approach of spectrum sensing which is based on long short term memory (LSTM) which is a critical element of deep learning networks (DLN). Use of LSTM facilitates implicit feature learning from spectrum data. The DLN is trained using several features and the performance of the proposed sensing technique is validated with the help of an empirical testbed setup using Adalm Pluto. The testbed is trained to acquire the primary signal of a real world radio broadcast taking place using FM. Experimental data show that even at low signal to noise ratio, our approach performs well in terms of detection and classification accuracies, as compared to current spectrum sensing methods.      
### 83.A Pseudo-Inverse for Nonlinear Operators  [ :arrow_down: ](https://arxiv.org/pdf/2111.10755.pdf)
>  The Moore-Penrose inverse is widely used in physics, statistics and various fields of engineering. Among other characteristics, it captures well the notion of inversion of linear operators in the case of overcomplete data. In data science, nonlinear operators are extensively used. In this paper we define and characterize the fundamental properties of a pseudo-inverse for nonlinear operators. <br>The concept is defined broadly. First for general sets, and then a refinement for normed spaces. Our pseudo-inverse for normed spaces yields the Moore-Penrose inverse when the operator is a matrix. We present conditions for existence and uniqueness of a pseudo-inverse and establish theoretical results investigating its properties, such as continuity, its value for operator compositions and projection operators, and others. Analytic expressions are given for the pseudo-inverse of some well-known, non-invertible, nonlinear operators, such as hard- or soft-thresholding and ReLU. Finally, we analyze a neural layer and discuss relations to wavelet thresholding and to regularized loss minimization.      
### 84.Improving Sum-Rate of Cell-Free Massive MIMO with Expanded Compute-and-Forward  [ :arrow_down: ](https://arxiv.org/pdf/2111.10717.pdf)
>  Cell-free massive multiple-input multiple-output (MIMO) employs a large number of distributed access points (APs) to serve a small number of user equipments (UEs) via the same time/frequency resource. Due to the strong macro diversity gain, cell-free massive MIMO can considerably improve the achievable sum-rate compared to conventional cellular massive MIMO. However, the performance of cell-free massive MIMO is upper limited by inter-user interference (IUI) when employing simple maximum ratio combining (MRC) at receivers. To harness IUI, the expanded compute-and-forward (ECF) framework is adopted. In particular, we propose power control algorithms for the parallel computation and successive computation in the ECF framework, respectively, to exploit the performance gain and then improve the system performance. Furthermore, we propose an AP selection scheme and the application of different decoding orders for the successive computation. Finally, numerical results demonstrate that ECF frameworks outperform the conventional CF and MRC frameworks in terms of achievable sum-rate.      
### 85.Network Graph Generation through Adaptive Clustering and Infection Dynamics: A Step Towards Global Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2111.10690.pdf)
>  More than 40% of the world's population is not connected to the internet, majorly due to the lack of adequate infrastructure. Our work aims to bridge this digital divide by proposing solutions for network deployment in remote areas. Specifically, a number of access points (APs) are deployed as an interface between the users and backhaul nodes (BNs). The main challenges include designing the number and location of the APs, and connecting them to the BNs. In order to address these challenges, we first propose a metric called connectivity ratio to assess the quality of the deployment. Next, we propose an agile search algorithm to determine the number of APs that maximizes this metric and perform clustering to find the optimal locations of the APs. Furthermore, we propose a novel algorithm inspired by infection dynamics to connect all the deployed APs to the existing BNs economically. To support the existing terrestrial BNs, we investigate the deployment of non-terrestrial BNs, which further improves the network performance in terms of average hop count, traffic distribution, and backhaul length. Finally, we use real datasets from a remote village to test our solution.      
### 86.VideoPose: Estimating 6D object pose from videos  [ :arrow_down: ](https://arxiv.org/pdf/2111.10677.pdf)
>  We introduce a simple yet effective algorithm that uses convolutional neural networks to directly estimate object poses from videos. Our approach leverages the temporal information from a video sequence, and is computationally efficient and robust to support robotic and AR domains. Our proposed network takes a pre-trained 2D object detector as input, and aggregates visual features through a recurrent neural network to make predictions at each frame. Experimental evaluation on the YCB-Video dataset show that our approach is on par with the state-of-the-art algorithms. Further, with a speed of 30 fps, it is also more efficient than the state-of-the-art, and therefore applicable to a variety of applications that require real-time object pose estimation.      
### 87.Fueling the Next Quantum Leap in Cellular Networks: Embracing AI in 5G Evolution towards 6G  [ :arrow_down: ](https://arxiv.org/pdf/2111.10663.pdf)
>  Cellular networks, such as 5G systems, are becoming increasingly complex for supporting various deployment scenarios and applications. Embracing artificial intelligence (AI) in 5G evolution is critical to managing the complexity and fueling the next quantum leap in 6G cellular networks. In this article, we share our experience and best practices in applying AI in cellular networks. We first present a primer on the state of the art of AI in cellular networks, including basic concepts and recent key advances. Then we discuss 3GPP standardization aspects and share various design rationales influencing standardization. We also present case studies with real network data to showcase how AI can improve network performance and enable network automation.      
### 88.Are Vision Transformers Robust to Patch Perturbations?  [ :arrow_down: ](https://arxiv.org/pdf/2111.10659.pdf)
>  The recent advances in Vision Transformer (ViT) have demonstrated its impressive performance in image classification, which makes it a promising alternative to Convolutional Neural Network (CNN). Unlike CNNs, ViT represents an input image as a sequence of image patches. The patch-wise input image representation makes the following question interesting: How does ViT perform when individual input image patches are perturbed with natural corruptions or adversarial perturbations, compared to CNNs? In this work, we study the robustness of vision transformers to patch-wise perturbations. Surprisingly, we find that vision transformers are more robust to naturally corrupted patches than CNNs, whereas they are more vulnerable to adversarial patches. Furthermore, we conduct extensive qualitative and quantitative experiments to understand the robustness to patch perturbations. We have revealed that ViT's stronger robustness to natural corrupted patches and higher vulnerability against adversarial patches are both caused by the attention mechanism. Specifically, the attention model can help improve the robustness of vision transformers by effectively ignoring natural corrupted patches. However, when vision transformers are attacked by an adversary, the attention mechanism can be easily fooled to focus more on the adversarially perturbed patches and cause a mistake.      
### 89.Implicit Acoustic Echo Cancellation for Keyword Spotting and Device-Directed Speech Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.10639.pdf)
>  In many speech-enabled human-machine interaction scenarios, user speech can overlap with the device playback audio. In these instances, the performance of tasks such as keyword-spotting (KWS) and device-directed speech detection (DDD) can degrade significantly. To address this problem, we propose an implicit acoustic echo cancellation (iAEC) framework where a neural network is trained to exploit the additional information from a reference microphone channel to learn to ignore the interfering signal and improve detection performance. We study this framework for the tasks of KWS and DDD on, respectively, an augmented version of Google Speech Commands v2 and a real-world Alexa device dataset. Notably, we show a $56\%$ reduction in false-reject rate for the DDD task during device playback conditions. We also show comparable or superior performance over a strong end-to-end neural echo cancellation + KWS baseline for the KWS task with an order of magnitude less computational requirements.      
### 90.A Gaussian Process-Based Ground Segmentation for Sloped Terrains  [ :arrow_down: ](https://arxiv.org/pdf/2111.10638.pdf)
>  A Gaussian Process GP based ground segmentation method is proposed in this paper which is fully developed in a probabilistic framework. The proposed method tends to obtain a continuous realistic model of the ground. The LiDAR three-dimensional point cloud data is used as the sole source of the input data. The physical realities of the data are taken into account to properly classify sloped ground as well as the flat ones. Furthermore, unlike conventional ground segmentation methods, no height or distance constraints or limitations are required for the algorithm to be applied to take all the regarding physical behavior of the ground into account. Furthermore, a density-like parameter is defined to handle ground-like obstacle points in the ground candidate set. The non-stationary covariance kernel function is used for the Gaussian Process, by which Bayesian inference is applied using the maximum A Posteriori criterion. The log-marginal likelihood function is assumed to be a multi-task objective function, to represent a whole-frame unbiased view of the ground at each frame. Simulation results show the effectiveness of the proposed method even in an uneven, rough scene which outperforms similar Gaussian process-based ground segmentation methods.      
### 91.HeterPS: Distributed Deep Learning With Reinforcement Learning Based Scheduling in Heterogeneous Environments  [ :arrow_down: ](https://arxiv.org/pdf/2111.10635.pdf)
>  Deep neural networks (DNNs) exploit many layers and a large number of parameters to achieve excellent performance. The training process of DNN models generally handles large-scale input data with many sparse features, which incurs high Input/Output (IO) cost, while some layers are compute-intensive. The training process generally exploits distributed computing resources to reduce training time. In addition, heterogeneous computing resources, e.g., CPUs, GPUs of multiple types, are available for the distributed training process. Thus, the scheduling of multiple layers to diverse computing resources is critical for the training process. To efficiently train a DNN model using the heterogeneous computing resources, we propose a distributed framework, i.e., Paddle-Heterogeneous Parameter Server (Paddle-HeterPS), composed of a distributed architecture and a Reinforcement Learning (RL)-based scheduling method. The advantages of Paddle-HeterPS are three-fold compared with existing frameworks. First, Paddle-HeterPS enables efficient training process of diverse workloads with heterogeneous computing resources. Second, Paddle-HeterPS exploits an RL-based method to efficiently schedule the workload of each layer to appropriate computing resources to minimize the cost while satisfying throughput constraints. Third, Paddle-HeterPS manages data storage and data communication among distributed computing resources. We carry out extensive experiments to show that Paddle-HeterPS significantly outperforms state-of-the-art approaches in terms of throughput (14.5 times higher) and monetary cost (312.3% smaller). The codes of the framework are publicly available at: <a class="link-external link-https" href="https://github.com/PaddlePaddle/Paddle" rel="external noopener nofollow">this https URL</a>.      
### 92.Sparse Tensor-based Multiscale Representation for Point Cloud Geometry Compression  [ :arrow_down: ](https://arxiv.org/pdf/2111.10633.pdf)
>  This study develops a unified Point Cloud Geometry (PCG) compression method through Sparse Tensor Processing (STP) based multiscale representation of voxelized PCG, dubbed as the SparsePCGC. Applying the STP reduces the complexity significantly because it only performs the convolutions centered at Most-Probable Positively-Occupied Voxels (MP-POV). And the multiscale representation facilitates us to compress scale-wise MP-POVs progressively. The overall compression efficiency highly depends on the approximation accuracy of occupancy probability of each MP-POV. Thus, we design the Sparse Convolution based Neural Networks (SparseCNN) consisting of sparse convolutions and voxel re-sampling to extensively exploit priors. We then develop the SparseCNN based Occupancy Probability Approximation (SOPA) model to estimate the occupancy probability in a single-stage manner only using the cross-scale prior or in multi-stage by step-wisely utilizing autoregressive neighbors. Besides, we also suggest the SparseCNN based Local Neighborhood Embedding (SLNE) to characterize the local spatial variations as the feature attribute to improve the SOPA. Our unified approach shows the state-of-art performance in both lossless and lossy compression modes across a variety of datasets including the dense PCGs (8iVFB, Owlii) and the sparse LiDAR PCGs (KITTI, Ford) when compared with the MPEG G-PCC and other popular learning-based compression schemes. Furthermore, the proposed method presents lightweight complexity due to point-wise computation, and tiny storage desire because of model sharing across all scales. We make all materials publicly accessible at <a class="link-external link-https" href="https://github.com/NJUVISION/SparsePCGC" rel="external noopener nofollow">this https URL</a> for reproducible research.      
### 93.Power Control in Cell-Free Massive MIMO Networks for UAVs URLLC under the Finite Blocklength Regime  [ :arrow_down: ](https://arxiv.org/pdf/2111.10613.pdf)
>  In this paper, we concentrate on the employment of a user-centric (UC) cell-free massive MIMO (CFmMIMO) network for providing ultra reliable low latency communication (URLLC) when traditional ground users (GUs) coexists with unmanned aerial vehicles (UAVs). We study power control in both the downlink and the uplink of such a scenario when partial zero-forcing (PZF) transmit/receive beamforming and maximum ratio transmission/combining are utilized. We consider optimization problems where the objective is either to maximize the total users' sum URLLC rate or to maximize the minimum user's URLLC rate. The considered URLLC rate function is both complicated and nonconvex rendering the considered optimization problems nonconvex. Thus, we present two approximations for the URLLC rate function and resort to successive convex optimization (SCO) to tackle the considered optimization problems. Particularly, we present SCO with iterative concave lower bound approximation (SCO-ICBA) and SCO with iterative interference approximation (SCO-IIA). We provide extensive simulations to evaluate SCO-ICBA and SCO-IIA and compare UC CFmMIMO deployment with traditional colocated massive MIMO (COmMIMO) systems.      
### 94.Online Beam Current Estimation in Particle Beam Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2111.10611.pdf)
>  In conventional particle beam microscopy, knowledge of the beam current is essential for accurate micrograph formation and sample milling. This generally necessitates offline calibration of the instrument. In this work, we establish that beam current can be estimated online, from the same secondary electron count data that is used to form micrographs. Our methods depend on the recently introduced time-resolved measurement concept, which combines multiple short measurements at a single pixel and has previously been shown to partially mitigate the effect of beam current variation on micrograph accuracy. We analyze the problem of jointly estimating beam current and secondary electron yield using the Cramer-Rao bound. Joint estimators operating at a single pixel and estimators that exploit models for inter-pixel correlation and Markov beam current variation are proposed and tested on synthetic microscopy data. Our estimates of secondary electron yield that incorporate explicit beam current estimation beat state-of-the-art methods, resulting in micrograph accuracy nearly indistinguishable from what is obtained with perfect beam current knowledge. Our novel beam current estimation could help improve milling outcomes, prevent sample damage, and enable online instrument diagnostics.      
### 95.Deep Spoken Keyword Spotting: An Overview  [ :arrow_down: ](https://arxiv.org/pdf/2111.10592.pdf)
>  Spoken keyword spotting (KWS) deals with the identification of keywords in audio streams and has become a fast-growing technology thanks to the paradigm shift introduced by deep learning a few years ago. This has allowed the rapid embedding of deep KWS in a myriad of small electronic devices with different purposes like the activation of voice assistants. Prospects suggest a sustained growth in terms of social use of this technology. Thus, it is not surprising that deep KWS has become a hot research topic among speech scientists, who constantly look for KWS performance improvement and computational complexity reduction. This context motivates this paper, in which we conduct a literature review into deep spoken KWS to assist practitioners and researchers who are interested in this technology. Specifically, this overview has a comprehensive nature by covering a thorough analysis of deep KWS systems (which includes speech features, acoustic modeling and posterior handling), robustness methods, applications, datasets, evaluation metrics, performance of deep KWS systems and audio-visual KWS. The analysis performed in this paper allows us to identify a number of directions for future research, including directions adopted from automatic speech recognition research and directions that are unique to the problem of spoken KWS.      
### 96.Improving Spectral Efficiency of Wireless Networks through Democratic Spectrum Sharing  [ :arrow_down: ](https://arxiv.org/pdf/2111.10570.pdf)
>  Wireless devices need spectrum to communicate. With the increase in the number of devices competing for the same spectrum, it has become nearly impossible to support the throughput requirements of all the devices through current spectrum sharing methods. In this work, we look at the problem of spectrum resource contention fundamentally, taking inspiration from the principles of globalization. We develop a distributed algorithm whereby the wireless nodes democratically share the spectrum resources and improve their spectral efficiency and throughput without additional power or spectrum resources. We validate the performance of our proposed democratic spectrum sharing (DSS) algorithm over real-world Wi-Fi networks and on synthetically generated networks with varying design parameters. Compared to the greedy approach, DSS achieves significant gains in throughput (~60%), area spectral efficiency ($\sim$50\%) and fairness in datarate distribution (~20%). Due to the distributed nature of the proposed algorithm, we can apply it to wireless networks of any size and density.      
### 97.Optimal Grouping Strategy for Reconfigurable Intelligent Surface Assisted Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2111.10550.pdf)
>  The channel estimation overhead of reconfigurable intelligent surface (RIS) assisted communication systems can be prohibitive. Prior works have demonstrated via simulations that grouping neighbouring RIS elements can help to reduce the pilot overhead and improve achievable rate. In this paper, we present an analytical study of RIS element grouping. We derive a tight closed-form upper bound for the achievable rate and then maximize it with respect to the group size. Our analysis reveals that more coarse-grained grouping is important-when the channel coherence time is low (high mobility scenarios) or the transmit power is large. We also demonstrate that optimal grouping can yield significant performance improvements over simple `On-Off' RIS element switching schemes that have been recently considered.      
### 98.Kalman filters as the steady-state solution of gradient descent on variational free energy  [ :arrow_down: ](https://arxiv.org/pdf/2111.10530.pdf)
>  The Kalman filter is an algorithm for the estimation of hidden variables in dynamical systems under linear Gauss-Markov assumptions with widespread applications across different fields. Recently, its Bayesian interpretation has received a growing amount of attention especially in neuroscience, robotics and machine learning. In neuroscience, in particular, models of perception and control under the banners of predictive coding, optimal feedback control, active inference and more generally the so-called Bayesian brain hypothesis, have all heavily relied on ideas behind the Kalman filter. Active inference, an algorithmic theory based on the free energy principle, specifically builds on approximate Bayesian inference methods proposing a variational account of neural computation and behaviour in terms of gradients of variational free energy. Using this ambitious framework, several works have discussed different possible relations between free energy minimisation and standard Kalman filters. With a few exceptions, however, such relations point at a mere qualitative resemblance or are built on a set of very diverse comparisons based on purported differences between free energy minimisation and Kalman filtering. In this work, we present a straightforward derivation of Kalman filters consistent with active inference via a variational treatment of free energy minimisation in terms of gradient descent. The approach considered here offers a more direct link between models of neural dynamics as gradient descent and standard accounts of perception and decision making based on probabilistic inference, further bridging the gap between hypotheses about neural implementation and computational principles in brain and behavioural sciences.      
### 99.A Distributed Parallel Optimization Algorithm via Alternating Direction Method of Multipliers  [ :arrow_down: ](https://arxiv.org/pdf/2111.10494.pdf)
>  Alternating Direction Method of Multipliers (ADMM) algorithm has been widely adopted for solving the distributed optimization problem (DOP). <br>In this paper, a new distributed parallel ADMM algorithm is proposed, which allows the agents to update their local states and dual variables in a completely distributed and parallel manner by modifying the existing distributed sequential ADMM. <br>Moreover, the updating rules and storage method for variables are illustrated. <br>It is shown that all the agents can reach a consensus by asymptotically converging to the optimal solution. <br>Besides, the global cost function will converge to the optimal value at a rate of O(1/k). <br>Simulation results on a numerical example are given to show the effectiveness of the proposed algorithm.      
### 100.Inter-Domain Fusion for Enhanced Intrusion Detection in Power Systems: An Evidence Theoretic and Meta-Heuristic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.10484.pdf)
>  False alerts due to misconfigured/ compromised IDS in ICS networks can lead to severe economic and operational damage. To solve this problem, research has focused on leveraging deep learning techniques that help reduce false alerts. However, a shortcoming is that these works often require or implicitly assume the physical and cyber sensors to be trustworthy. Implicit trust of data is a major problem with using artificial intelligence or machine learning for CPS security, because during critical attack detection time they are more at risk, with greater likelihood and impact, of also being compromised. To address this shortcoming, the problem is reframed on how to make good decisions given uncertainty. Then, the decision is detection, and the uncertainty includes whether the data used for ML-based IDS is compromised. Thus, this work presents an approach for reducing false alerts in CPS power systems by dealing uncertainty without the knowledge of prior distribution of alerts. Specifically, an evidence theoretic based approach leveraging Dempster Shafer combination rules are proposed for reducing false alerts. A multi-hypothesis mass function model is designed that leverages probability scores obtained from various supervised-learning classifiers. Using this model, a location-cum-domain based fusion framework is proposed and evaluated with different combination rules, that fuse multiple evidence from inter-domain and intra-domain sensors. The approach is demonstrated in a cyber-physical power system testbed with Man-In-The-Middle attack emulation in a large-scale synthetic electric grid. For evaluating the performance, plausibility, belief, pignistic, etc. metrics as decision functions are considered. To improve the performance, a multi-objective based genetic algorithm is proposed for feature selection considering the decision metrics as the fitness function.      
### 101.Identifying Population Movements with Non-Negative Matrix Factorization from Wi-Fi User Counts in Smart and Connected Cities  [ :arrow_down: ](https://arxiv.org/pdf/2111.10459.pdf)
>  Non-Negative Matrix Factorization (NMF) is a valuable matrix factorization technique which produces a "parts-based" decomposition of data sets. Wi-Fi user counts are a privacy-preserving indicator of population movements in smart and connected urban environments. In this paper, we apply NMF with a novel matrix embedding to Wi-Fi user count data from the University of Colorado at Boulder Campus for the purpose of automatically identifying patterns of human movement in a Smart and Connected infrastructure environment.      
### 102.Urine Microscopic Image Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2111.10374.pdf)
>  Urinalysis is a standard diagnostic test to detect urinary system related problems. The automation of urinalysis will reduce the overall diagnostic time. Recent studies used urine microscopic datasets for designing deep learning based algorithms to classify and detect urine cells. But these datasets are not publicly available for further research. To alleviate the need for urine datsets, we prepare our urine sediment microscopic image (UMID) dataset comprising of around 3700 cell annotations and 3 categories of cells namely RBC, pus and epithelial cells. We discuss the several challenges involved in preparing the dataset and the annotations. We make the dataset publicly available.      
