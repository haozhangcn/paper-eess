# ArXiv eess --Tue, 2 Nov 2021
### 1.Predicting Power System Dynamics and Transients: A Frequency Domain Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.01103.pdf)
>  The dynamics of a power grid are governed by a large number of nonlinear ordinary differential equations (ODEs). To safely operate the system, operators need to check that the states described by this set of ODEs stay within prescribed limits after various faults. Limited by the size and stiffness of the ODEs, current numerical integration techniques are often too slow to be useful for real-time or large-scale resource allocation problems. In addition, the detailed system parameters are often not exactly known. Machine learning approaches have been proposed to reduce the computational efforts, but current methods generally suffer from overfitting and failures to predict unstable behaviors. <br>This paper proposes a novel framework for power system dynamic predictions by learning in the frequency domain. The intuition is that although the system behavior is complex in the time domain, there are relatively few dominant modes in the frequency domain. Therefore, we learn to predict by constructing neural networks with Fourier transform and filtering layers. System topology and fault information are encoded by taking a multi-dimensional Fourier transform, allowing us to leverage the fact that the trajectories are sparse both in time and spatial (across different buses) frequencies. We show that the proposed approach does not need detailed system parameters, speeds up prediction computations by orders of magnitude and is highly accurate for different fault types.      
### 2.Correlation between image quality metrics of magnetic resonance images and the neural network segmentation accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2111.01093.pdf)
>  Deep neural networks with multilevel connections process input data in complex ways to learn the information.A networks learning efficiency depends not only on the complex neural network architecture but also on the input training images.Medical image segmentation with deep neural networks for skull stripping or tumor segmentation from magnetic resonance images enables learning both global and local features of the images.Though medical images are collected in a controlled environment,there may be artifacts or equipment based variance that cause inherent bias in the input <a class="link-external link-http" href="http://set.In" rel="external noopener nofollow">this http URL</a> this study, we investigated the correlation between the image quality metrics of MR images with the neural network segmentation accuracy.For that we have used the 3D DenseNet architecture and let the network trained on the same input but applying different methodologies to select the training data set based on the IQM values.The difference in the segmentation accuracy between models based on the random training inputs with IQM based training inputs shed light on the role of image quality metrics on segmentation <a class="link-external link-http" href="http://accuracy.By" rel="external noopener nofollow">this http URL</a> running the image quality metrics to choose the training inputs,further we may tune the learning efficiency of the network and the segmentation accuracy.      
### 3.Fault-Tolerant Performance Enhancement of DC-DC Converters with High-Speed Fault Clearing-unit based Redundant Power Switch Configurations  [ :arrow_down: ](https://arxiv.org/pdf/2111.01092.pdf)
>  Fault detection and reconfiguration in fault-tolerant converters may complicated and necessitate using all-purpose microprocessors and high-speed sensors to guarantee the satisfactory performance of power converters. Therefore, providing fault-clearing feature without increasing the processing and sensing burdens and reducing the transition time between faulty to normal state are of great importance. This research proposes a new redundant-switch configuration to address the mentioned challenges. The proposed configuration uses one diode and two fuses to eliminate the faulty switch and replace the reserve one, spontaneously. Open-circuit fault in the proposed configuration is clarified instantly. Moreover, the short-circuit fault is dealt as an open-circuit fault by using a fuse. Thus, the fault-tolerant feature of the proposed switch configuration is achieved without using a complex, versatile and multifaceted fault managing unit. Resultant behaviors of the case studies are derived using MATLAB/SIMULINK. Also, steady-state thermal distribution of power switches which are implemented on a monolith heat sink, analyzed in COMSOL Multi-physics environment. Finally, the viability of the proposed configuration is demonstrated by a laboratory-scaled prototype.      
### 4.Identification of Stability Regions in Inverter-Based Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2111.01028.pdf)
>  A new method for the stability assessment of inverter-based microgrids is presented in this paper. Directly determining stability boundaries by searching the multidimensional space of inverters' droop gains is a computationally prohibitive task. Instead, we build a certified stability region by utilizing a generalized Laplacian matrix eigenvalues, which are a measure of proximity to stability boundary. We establish an upper threshold for the eigenvalues that determines the stability boundary of the entire system and demonstrate that this value depends only on the network's R/X ratio but does not depend on the grid topology. We also provide a conservative upper threshold of the eigenvalues that are universal for any systems within a reasonable range of R/X ratios. We then construct approximate certified stability regions representing convex sets in the multidimensional space of droop gains that could be utilized for gains optimization. We show how the certified stability region can be maximized by properly choosing droop gains, and we provide closed-form analytic expressions for the certified stability regions. The computational complexity of our method is almost independent of the number of inverters. The proposed methodology has been tested using IEEE 123 node test system with 10 inverters.      
### 5.A critical review of data-driven transient stability assessment of power systems: principles, prospects and challenges  [ :arrow_down: ](https://arxiv.org/pdf/2111.00978.pdf)
>  Transient stability assessment (TSA) has always been a fundamental means for ensuring the secure and stable operation of power systems. Due to the integration of new elements such as power electronics, electric vehicles and renewable power generations, dynamic characteristics of power systems are becoming more and more complex, which makes TSA an increasingly urgent task. Since traditional time-domain simulations and direct method cannot meet the actual operation requirements of power systems, data-driven TSA has attracted growing attention from both academia and industry. This paper makes a comprehensive review from the following four aspects: feature extraction and selection, model construction, online learning and rule extraction; and then, summarizes the challenges and prospects for future research; finally, draws the conclusions of this review. This review will be beneficial for relevant researchers to better understand the research status, key technologies and existing challenges in the field.      
### 6.Achieving increased Phasor POD performance by introducing a Control-Input Model  [ :arrow_down: ](https://arxiv.org/pdf/2111.00968.pdf)
>  In this paper, an enhancement to the well known Phasor Power Oscillation Damper is proposed, aiming to increase its performance. Fundamental to the functioning of this controller is the estimation of a phasor representing oscillatory behaviour at a particular frequency in a measured signal. The phasor is transformed to time domain and applied as a setpoint signal to a controllable device. The contribution in this paper specifically targets the estimation algorithm of the controller: It is found that increased estimation accuracy and thereby enhanced damping performance can be achieved by introducing a prediction-correction scheme for the estimator, in the form of a Kalman Filter. The prediction of the phasor at the next step is performed based on the control signal that is applied at the current step. This enables more precise damping of the targeted mode. <br>The presented results, which are obtained from simulations on a Single-Machine Infinite Bus system and the IEEE 39-Bus system, indicate that the proposed enhancement improves the performance of this type of controller.      
### 7.In-layer Thermal Control of a Multi-layer Selective Laser Melting Process  [ :arrow_down: ](https://arxiv.org/pdf/2111.00890.pdf)
>  Selective Laser Melting (SLM) is an additive manufacturing technology that builds three dimensional parts by melting layers of metal powder together with a laser that traces out a desired geometry. SLM is popular in industry, however the inherent melting and re-solidification of the metal during the process can, if left uncontrolled, cause excessive residual stress, porosity, and other defects in the final printed parts. This paper presents a control-oriented thermal model of a multi-layer SLM process and proposes a structured model reduction methodology with an associated reduced order model based in-layer controller to track temperature references. Simulation studies demonstrate that the controller is able to prevent layer-to-layer heat buildup and that good closed-loop performance is possible using relatively low-order models.      
### 8.Simulating Realistic MRI variations to Improve Deep Learning model and visual explanations using GradCAM  [ :arrow_down: ](https://arxiv.org/pdf/2111.00837.pdf)
>  In the medical field, landmark detection in MRI plays an important role in reducing medical technician efforts in tasks like scan planning, image registration, etc. First, 88 landmarks spread across the brain anatomy in the three respective views -- sagittal, coronal, and axial are manually annotated, later guidelines from the expert clinical technicians are taken sub-anatomy-wise, for better localization of the existing landmarks, in order to identify and locate the important atlas landmarks even in oblique scans. To overcome limited data availability, we implement realistic data augmentation to generate synthetic 3D volumetric data. We use a modified HighRes3DNet model for solving brain MRI volumetric landmark detection problem. In order to visually explain our trained model on unseen data, and discern a stronger model from a weaker model, we implement Gradient-weighted Class Activation Mapping (Grad-CAM) which produces a coarse localization map highlighting the regions the model is focusing. Our experiments show that the proposed method shows favorable results, and the overall pipeline can be extended to a variable number of landmarks and other anatomies.      
### 9.A Modified Dynamic Time Warping (MDTW) Approach and Innovative Average Non-Self Match Distance (ANSD) Method for Anomaly Detection in ECG Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2111.00803.pdf)
>  ECGs objectively reflects the working conditions of the hearts as these signals contain vast physiological and pathological information. In this work, in order to improve the efficiency and accuracy of "best so far" time series analysis-based ECG anomaly detection methods, a novel method, comprising a modified dynamic time warping (MDTW) and an innovative average non-self match distance (ANSD) measure, is proposed for ECG anomaly detection. To evaluate the performance of the proposed method, the proposed method is applied to real ECG data selected from the MIT-BIH heartbeat database. To provide a reference for comparison, two existing anomaly detection methods, namely, brute force discord discovery (BFDD) and adaptive window discord discovery (AWDD), are also applied to the same data. The experimental results show that our proposed method outperforms BFDD and AWD.      
### 10.SNRi Target Training for Joint Speech Enhancement and Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.00764.pdf)
>  This study aims to improve the performance of automatic speech recognition (ASR) under noisy conditions. The use of a speech enhancement (SE) frontend has been widely studied for noise robust ASR. However, most single-channel SE models introduce processing artifacts in the enhanced speech resulting in degraded ASR performance. To overcome this problem, we propose Signal-to-Noise Ratio improvement (SNRi) target training; the SE frontend automatically controls its noise reduction level to avoid degrading the ASR performance due to artifacts. The SE frontend uses an auxiliary scalar input which represents the target SNRi of the output signal. The target SNRi value is estimated by the SNRi prediction network, which is trained to minimize the ASR loss. Experiments using 55,027 hours of noisy speech training data show that SNRi target training enables control of the SNRi of the output signal, and the joint training reduces word error rate by 12% compared to a state-of-the-art Conformer-based ASR model.      
### 11.Quasi-Linear Transfer Function: A New Method for Frequency Domain Analysis of Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.00748.pdf)
>  A new concept, called quasi-linear transfer functions (QLTF), which can be used to characterize the output frequency behaviour of nonlinear systems, is introduced based on the well-known Volterra series representation. By using the new concept of QLTF, it can be proved that the input and output frequency behaviour of a given system can be expressed using a number of one-dimensional functions with a form similar to that of the traditional frequency response function for linear systems. Two algorithms, which can be used to determine the valid range of the associated output frequencies of arbitrary order nonlinear subsystems with both a multitone and general inputs, are provided. The results obtained provide a new important insight into the output frequency characteristics of nonlinear systems and have many potential applications in nonlinear systems analysis and nonlinear structure detection      
### 12.Decentralized On-Ramp Merging Control of Connected and Automated Vehicles in the Mixed Traffic Using Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2111.00746.pdf)
>  The cooperative control of the connected and automated vehicle (CAV) is recognized as an effective approach to alleviate traffic congestion and improve traffic safety, especially for on-ramp bottlenecks. However, in the mixed traffic, the uncertainty of human-driven vehicles (HDVs) makes the on-ramp merging control for CAVs more challenging. This paper proposes a decentralized optimal control method to address the merging control problem of CAVs at highway on-ramps in the mixed traffic. We first formulate the optimal merging control problem, which includes the constraints of safety and vehicle dynamics, with the objectives of minimizing travel time and energy consumption. Then, a control framework, combining control barrier functions (CBFs) and control Lyapunov functions (CLFs) is proposed. CBFs render the system subject to safety-critical constraints, while CLFs stabilize the system to the objectives. In addition, to enable effective control of CAVs in the mixed traffic, a recursive merging control framework is proposed, where HDVs are regarded as disturbances, and CAVs collect surrounding vehicles' states repeatedly and update their trajectories recursively to satisfy strict merging requirements. Finally, the merging problem is reformulated as a quadratic programming problem, which allows for real-time application. Simulation results show that the proposed on-ramp merging control method is robust in resisting disturbance from the HDV with traffic efficiency and energy economy improvement.      
### 13.Redundancy Reduction in Semantic Segmentation of 3D Brain Tumor MRIs  [ :arrow_down: ](https://arxiv.org/pdf/2111.00742.pdf)
>  Another year of the multimodal brain tumor segmentation challenge (BraTS) 2021 provides an even larger dataset to facilitate collaboration and research of brain tumor segmentation methods, which are necessary for disease analysis and treatment planning. A large dataset size of BraTS 2021 and the advent of modern GPUs provide a better opportunity for deep-learning based approaches to learn tumor representation from the data. In this work, we maintained an encoder-decoder based segmentation network, but focused on a modification of network training process that minimizes redundancy under perturbations. Given a set trained networks, we further introduce a confidence based ensembling techniques to further improve the performance. We evaluated the method on BraTS 2021 validation board, and achieved 0.8600, 0.8868 and 0.9265 average dice for enhanced tumor core, tumor core and whole tumor, respectively. Our team (NVAUTO) submission was the top performing in terms of ET and TC scores and within top 10 performing teams in terms of WT scores.      
### 14.SFOL DME Pulse Shaping Through Digital Predistortion for High-Accuracy DME  [ :arrow_down: ](https://arxiv.org/pdf/2111.00717.pdf)
>  The Stretched-FrOnt-Leg (SFOL) pulse is a high-accuracy distance measuring equipment (DME) pulse developed to support alternative positioning and navigation for aircraft during global navigation satellite system outages. To facilitate the use of the SFOL pulse, it is best to use legacy DMEs that are already deployed to transmit the SFOL pulse, rather than the current Gaussian pulse, through software changes only. When attempting to transmit the SFOL pulse in legacy DMEs, the greatest challenge is the pulse shape distortion caused by the pulse-shaping circuits and power amplifiers in the transmission unit such that the original SFOL pulse shape is no longer preserved. This letter proposes an inverse-learning-based DME digital predistortion method and presents successfully transmitted SFOL pulses from a testbed based on a commercial legacy DME that was designed to transmit Gaussian pulses.      
### 15.Energy-efficient Cooperative Offloading for Edge Computing-enabled Vehicular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.00715.pdf)
>  Edge computing technology has great potential to improve various computation-intensive applications in vehicular networks by providing sufficient computation resources for vehicles. However, it is still a challenge to fully unleash the potential of edge computing in edge computing-enabled vehicular networks. In this paper, we develop the energy-efficient cooperative offloading scheme for edge computing-enabled vehicular networks, which splits the task into multiple subtasks and offloads them to different roadside units (RSUs) located ahead along the route of the vehicle. We first establish novel cooperative offloading models for the offline and online scenarios in edge computing-enabled vehicular networks. In each offloading scenario, we formulate the total energy minimization with respect to the task splitting ratio, computation resource, and communication resource. In the offline scenario, we equivalently transform the original problem to a convex problem and obtain optimal solutions for multi-vehicle case and single-vehicle case, respectively. Furthermore, we show that the method proposed for the offline scenario can also be applied to solve the optimization problem in the online scenario. Finally, through numerical results, by analyzing the impact of network parameters on the total energy consumption, we verify that our proposed solution consumes lower energy than baseline schemes.      
### 16.Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2111.00698.pdf)
>  Prototypical network (PN) is a simple yet effective few shot learning strategy. It is a metric-based meta-learning technique where classification is performed by computing Euclidean distances to prototypical representations of each class. Conventional PN attributes equal importance to all samples and generates prototypes by simply averaging the support sample embeddings belonging to each class. In this work, we propose a novel version of PN that attributes weights to support samples corresponding to their influence on the support sample distribution. Influence weights of samples are calculated based on maximum mean discrepancy (MMD) between the mean embeddings of sample distributions including and excluding the sample. Comprehensive evaluation of our proposed influential PN (IPNet) is performed by comparing its performance with other baseline PNs on three different benchmark dermatological datasets. IPNet outperforms all baseline models with compelling results across all three datasets and various N-way, K-shot classification tasks. Findings from cross-domain adaptation experiments further establish the robustness and generalizability of IPNet.      
### 17.Self-Verification in Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2111.00666.pdf)
>  We devise a new regularization, called self-verification, for image denoising. This regularization is formulated using a deep image prior learned by the network, rather than a traditional predefined prior. Specifically, we treat the output of the network as a ``prior'' that we denoise again after ``re-noising''. The comparison between the again denoised image and its prior can be interpreted as a self-verification of the network's denoising ability. We demonstrate that self-verification encourages the network to capture low-level image statistics needed to restore the image. Based on this self-verification regularization, we further show that the network can learn to denoise even if it has not seen any clean images. This learning strategy is self-supervised, and we refer to it as Self-Verification Image Denoising (SVID). SVID can be seen as a mixture of learning-based methods and traditional model-based denoising methods, in which regularization is adaptively formulated using the output of the network. We show the application of SVID to various denoising tasks using only observed corrupted data. It can achieve the denoising performance close to supervised CNNs.      
### 18.A Matched-filter based method in the Synthetic Aperture Radar Images Using FMCW radar  [ :arrow_down: ](https://arxiv.org/pdf/2111.00613.pdf)
>  The stretch processing architecture is commonly used for frequency modulated continuous wave (FMCW) radar due to its inexpensive hardware, low sampling rate, and simple architecture. However, the stretch processing architecture is not able to achieve optimal Signal to Noise ratio (SNR) in comparison to the matched-filter architecture. In this paper, we aim to propose a method whereby stretch processing can achieve optimal SNR. Hence, we develop a novel processing method to enable applying a matched filter to the output of the stretch processing. The proposed architecture achieves optimal SNR while it can operate on a low sampling rate. In addition, the combination of the proposed radar architecture and SAR technique can generate high-quality images. To evaluate the performance of the proposed architecture, four scenarios are considered. Simulation is carried out based on these scenarios. The simulation results show that the proposed radar demonstrates the ability to generate an image with higher quality over stretch processing. This proposed radar can also bring a bigger gain compression.      
### 19.TorchXRayVision: A library of chest X-ray datasets and models  [ :arrow_down: ](https://arxiv.org/pdf/2111.00595.pdf)
>  TorchXRayVision is an open source software library for working with chest X-ray datasets and deep learning models. It provides a common interface and common pre-processing chain for a wide set of publicly available chest X-ray datasets. In addition, a number of classification and representation learning models with different architectures, trained on different data combinations, are available through the library to serve as baselines or feature extractors.      
### 20.Learning to Detect Open Carry and Concealed Object with 77GHz Radar  [ :arrow_down: ](https://arxiv.org/pdf/2111.00551.pdf)
>  Detecting harmful carried objects plays a key role in intelligent surveillance systems and has widespread applications, for example, in airport security. In this paper, we focus on the relatively unexplored area of using low-cost 77GHz mmWave radar for the carried objects detection problem. The proposed system is capable of real-time detecting three classes of objects - laptop, phone, and knife - under open carry and concealed cases where objects are hidden with clothes or bags. This capability is achieved by initial signal processing for localization and generating range-azimuth-elevation image cubes, followed by a deep learning-based prediction network and a multi-shot post-processing module for detecting objects. Extensive experiments for validating the system performance on detecting open carry and concealed objects have been presented with a self-built radar-camera testbed and dataset. Additionally, the influence of different input, factors, and parameters on system performance is analyzed, providing an intuitive understanding of the system. This system would be the very first baseline for other future works aiming to detect carried objects using 77GHz radar.      
### 21.Focal Attention Networks: optimising attention for biomedical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.00534.pdf)
>  In recent years, there has been increasing interest to incorporate attention into deep learning architectures for biomedical image segmentation. The modular design of attention mechanisms enables flexible integration into convolutional neural network architectures, such as the U-Net. Whether attention is appropriate to use, what type of attention to use, and where in the network to incorporate attention modules, are all important considerations that are currently overlooked. In this paper, we investigate the role of the Focal parameter in modulating attention, revealing a link between attention in loss functions and networks. By incorporating a Focal distance penalty term, we extend the Unified Focal loss framework to include boundary-based losses. Furthermore, we develop a simple and interpretable, dataset and model-specific heuristic to integrate the Focal parameter into the Squeeze-and-Excitation block and Attention Gate, achieving optimal performance with fewer number of attention modules on three well-validated biomedical imaging datasets, suggesting judicious use of attention modules results in better performance and efficiency.      
### 22.Incorporating Boundary Uncertainty into loss functions for biomedical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.00533.pdf)
>  Manual segmentation is used as the gold-standard for evaluating neural networks on automated image segmentation tasks. Due to considerable heterogeneity in shapes, colours and textures, demarcating object boundaries is particularly difficult in biomedical images, resulting in significant inter and intra-rater variability. Approaches, such as soft labelling and distance penalty term, apply a global transformation to the ground truth, redefining the loss function with respect to uncertainty. However, global operations are computationally expensive, and neither approach accurately reflects the uncertainty underlying manual annotation. In this paper, we propose the Boundary Uncertainty, which uses morphological operations to restrict soft labelling to object boundaries, providing an appropriate representation of uncertainty in ground truth labels, and may be adapted to enable robust model training where systematic manual segmentation errors are present. We incorporate Boundary Uncertainty with the Dice loss, achieving consistently improved performance across three well-validated biomedical imaging datasets compared to soft labelling and distance-weighted penalty. Boundary Uncertainty not only more accurately reflects the segmentation process, but it is also efficient, robust to segmentation errors and exhibits better generalisation.      
### 23.Calibrating the Dice loss to handle neural network overconfidence for biomedical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.00528.pdf)
>  The Dice similarity coefficient (DSC) is both a widely used metric and loss function for biomedical image segmentation due to its robustness to class imbalance. However, it is well known that the DSC loss is poorly calibrated, resulting in overconfident predictions that cannot be usefully interpreted in biomedical and clinical practice. Performance is often the only metric used to evaluate segmentations produced by deep neural networks, and calibration is often neglected. However, calibration is important for translation into biomedical and clinical practice, providing crucial contextual information to model predictions for interpretation by scientists and clinicians. In this study, we identify poor calibration as an emerging challenge of deep learning based biomedical image segmentation. We provide a simple yet effective extension of the DSC loss, named the DSC++ loss, that selectively modulates the penalty associated with overconfident, incorrect predictions. As a standalone loss function, the DSC++ loss achieves significantly improved calibration over the conventional DSC loss across five well-validated open-source biomedical imaging datasets. Similarly, we observe significantly improved when integrating the DSC++ loss into four DSC-based loss functions. Finally, we use softmax thresholding to illustrate that well calibrated outputs enable tailoring of precision-recall bias, an important post-processing technique to adapt the model predictions to suit the biomedical or clinical task. The DSC++ loss overcomes the major limitation of the DSC, providing a suitable loss function for training deep learning segmentation models for use in biomedical and clinical practice.      
### 24.IGCN: Image-to-graph Convolutional Network for 2D/3D Deformable Registration  [ :arrow_down: ](https://arxiv.org/pdf/2111.00484.pdf)
>  Organ shape reconstruction based on a single-projection image during treatment has wide clinical scope, e.g., in image-guided radiotherapy and surgical guidance. We propose an image-to-graph convolutional network that achieves deformable registration of a 3D organ mesh for a single-viewpoint 2D projection image. This framework enables simultaneous training of two types of transformation: from the 2D projection image to a displacement map, and from the sampled per-vertex feature to a 3D displacement that satisfies the geometrical constraint of the mesh structure. Assuming application to radiation therapy, the 2D/3D deformable registration performance is verified for multiple abdominal organs that have not been targeted to date, i.e., the liver, stomach, duodenum, and kidney, and for pancreatic cancer. The experimental results show shape prediction considering relationships among multiple organs can be used to predict respiratory motion and deformation from digitally reconstructed radiographs with clinically acceptable accuracy.      
### 25.Wireless Federated Learning over MIMO Networks: Joint Device Scheduling and Beamforming Design  [ :arrow_down: ](https://arxiv.org/pdf/2111.00470.pdf)
>  Federated learning (FL) is recognized as a key enabling technology to support distributed artificial intelligence (AI) services in future 6G. By supporting decentralized data training and collaborative model training among devices, FL inherently tames privacy leakage and reduces transmission costs. Whereas, the performance of the wireless FL is typically restricted by the communication latency. Multiple-input multiple-output (MIMO) technique is one promising solution to build up a communication-efficient edge FL system with limited radio resources. In this paper, we propose a novel joint device scheduling and receive beamforming design approach to reduce the FL convergence gap over shared wireless MIMO networks. Specifically, we theoretically establish the convergence analysis of the FL process, and then apply the proposed device scheduling policy to maximize the number of weighted devices under the FL system latency and sum power constraints. Numerical results verify the theoretical analysis of the FL convergence and exhibit the appealing learning performance of the proposed approach.      
### 26.Graph Neural Network based scheduling : Improved throughput under a generalized interference model  [ :arrow_down: ](https://arxiv.org/pdf/2111.00459.pdf)
>  In this work, we propose a Graph Convolutional Neural Networks (GCN) based scheduling algorithm for adhoc networks. In particular, we consider a generalized interference model called the $k$-tolerant conflict graph model and design an efficient approximation for the well-known Max-Weight scheduling algorithm. A notable feature of this work is that the proposed method do not require labelled data set (NP-hard to compute) for training the neural network. Instead, we design a loss function that utilises the existing greedy approaches and trains a GCN that improves the performance of greedy approaches. Our extensive numerical experiments illustrate that using our GCN approach, we can significantly ($4$-$20$ percent) improve the performance of the conventional greedy approach.      
### 27.Intelligent Reflecting Surface-induced Randomness for mmWave Key Generation  [ :arrow_down: ](https://arxiv.org/pdf/2111.00428.pdf)
>  Secret key generation in physical layer security exploits the unpredictable random nature of wireless channels. However, the millimeter wave (mmWave) channels have limited multipath and may not be Gaussian distributed. In this paper, for mmWave secret key generation of physical layer security, we use intelligent reflecting surface (IRS) to produce randomness and induce artificial Rayleigh fading directly in the wireless environments. We first formulate the model of IRS-assisted key generation in mmWave environments. The IRS-assisted reflection channel varies according to the IRS weights' variation and induces randomness. When considering the IRS weights are continuous and discrete uniformly distributed, we find that the reflection channel variance is equal to the number of IRS elements. Besides, we prove that the magnitude and phase are Rayleigh and uniformly distributed when the weights are continuously and discretely distributed with more than one quantization bit. With the simulation results verifying the analytical results, this work explains the mathematical principles behind the IRS-assisted physical layer security secret key generation and lays a foundation for future mmWave key generation evaluation and optimization of channel randomness.      
### 28.Safe Adaptive Learning-based Control for Constrained Linear Quadratic Regulators with Regret Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2111.00411.pdf)
>  We study the adaptive control of an unknown linear system with a quadratic cost function subject to safety constraints on both the states and actions. The challenges of this problem arise from the tension among safety, exploration, performance, and computation. To address these challenges, we propose a polynomial-time algorithm that guarantees feasibility and constraint satisfaction with high probability under proper conditions. Our algorithm is implemented on a single trajectory and does not require system restarts. Further, we analyze the regret of our learning algorithm compared to the optimal safe linear controller with known model information. The proposed algorithm can achieve a $\tilde O(T^{2/3})$ regret, where $T$ is the number of stages and $\tilde O(\cdot)$ absorbs some logarithmic terms of $T$.      
### 29.Kernel-based Impulse Response Identification with Side-Information on Steady-State Gain  [ :arrow_down: ](https://arxiv.org/pdf/2111.00409.pdf)
>  In this paper, we consider the problem of system identification when side-information is available on the steady-state (or DC) gain of the system. We formulate a general nonparametric identification method as an infinite-dimensional constrained convex program over the reproducing kernel Hilbert space (RKHS) of stable impulse responses. The objective function of this optimization problem is the empirical loss regularized with the norm of RKHS, and the constraint is considered for enforcing the integration of the steady-state gain side-information. The proposed formulation addresses both the discrete-time and continuous-time cases. We show that this program has a unique solution obtained by solving an equivalent finite-dimensional convex optimization. This solution has a closed-form when the empirical loss and regularization functions are quadratic and exact side-information is considered. We perform extensive numerical comparisons to verify the efficiency of the proposed identification methodology.      
### 30.Regularized Identification with Internal Positivity Side-Information  [ :arrow_down: ](https://arxiv.org/pdf/2111.00407.pdf)
>  In this paper, we present an impulse response identification scheme that incorporates the internal positivity side-information of the system. The realization theory of positive systems establishes specific criteria for the existence of a positive realization for a given transfer function. These transfer function criteria are translated to a set of suitable conditions on the shape and structure of the impulse responses of positive systems. Utilizing these conditions, the impulse response estimation problem is formulated as a constrained optimization in a reproducing kernel Hilbert space equipped with a stable kernel, and suitable constraints are imposed to encode the internal positivity side-information. The optimization problem is infinite-dimensional with an infinite number of constraints. An equivalent finite-dimensional convex optimization in the form of a convex quadratic program is derived. The resulting equivalent reformulation makes the proposed approach suitable for numerical simulation and practical implementation. A Monte Carlo numerical experiment evaluates the impact of incorporating the internal positivity side-information in the proposed identification scheme. The effectiveness of the proposed method is demonstrated using data from a heating system experiment.      
### 31.Dual Attention Network for Heart Rate and Respiratory Rate Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2111.00390.pdf)
>  Heart rate and respiratory rate measurement is a vital step for diagnosing many diseases. Non-contact camera based physiological measurement is more accessible and convenient in Telehealth nowadays than contact instruments such as fingertip oximeters since non-contact methods reduce risk of infection. However, remote physiological signal measurement is challenging due to environment illumination variations, head motion, facial expression, etc. It's also desirable to have a unified network which could estimate both heart rate and respiratory rate to reduce system complexity and latency. We propose a convolutional neural network which leverages spatial attention and channel attention, which we call it dual attention network (DAN) to jointly estimate heart rate and respiratory rate with camera video as input. Extensive experiments demonstrate that our proposed system significantly improves heart rate and respiratory rate measurement accuracy.      
### 32.A Novel Linear Power Flow Model  [ :arrow_down: ](https://arxiv.org/pdf/2111.00382.pdf)
>  Linear power flow (LPF) models are important for the solution of large-scale problems in power system analysis. This paper proposes a novel LPF method named data-based LPF (DB-LPF). The DB-LPF is distinct from the data-driven LPF (DD-LPF) model because the DB-LPF formulates the definition set first and then discretizes the set into representative data samples, while the DD-LPF directly mines the variable mappings from historical or measurement data. In this paper, the concept of LPF definition set (i.e., the set where the LPF performs well) is proposed and an analytical algorithm is provided to get the set. Meanwhile, a novel form of AC-PF models is provided, which is helpful in deriving the analytical algorithm and directing the formulations of LPF models. The definition set is discretized by a grid sampling approach and the obtained samples are processed by the least-squares method to formulate the DB-LPF model. Moreover, the model for obtaining the error bound of the DB-LPF is proposed, and the network losses of the DB-LPF is also analyzed. Finally, the DB-LPF model is tested on enormous cases, whose branch parameters are also anal-yzed. The test results verify the effectiveness and superiority of the proposed method.      
### 33.Functional Neural Networks for Parametric Image Restoration Problems  [ :arrow_down: ](https://arxiv.org/pdf/2111.00361.pdf)
>  Almost every single image restoration problem has a closely related parameter, such as the scale factor in super-resolution, the noise level in image denoising, and the quality factor in JPEG deblocking. Although recent studies on image restoration problems have achieved great success due to the development of deep neural networks, they handle the parameter involved in an unsophisticated way. Most previous researchers either treat problems with different parameter levels as independent tasks, and train a specific model for each parameter level; or simply ignore the parameter, and train a single model for all parameter levels. The two popular approaches have their own shortcomings. The former is inefficient in computing and the latter is ineffective in performance. In this work, we propose a novel system called functional neural network (FuncNet) to solve a parametric image restoration problem with a single model. Unlike a plain neural network, the smallest conceptual element of our FuncNet is no longer a floating-point variable, but a function of the parameter of the problem. This feature makes it both efficient and effective for a parametric problem. We apply FuncNet to super-resolution, image denoising, and JPEG deblocking. The experimental results show the superiority of our FuncNet on all three parametric image restoration tasks over the state of the arts.      
### 34.Speaker conditioning of acoustic models using affine transformation for multi-speaker speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.00320.pdf)
>  This study addresses the problem of single-channel Automatic Speech Recognition of a target speaker within an overlap speech scenario. In the proposed method, the hidden representations in the acoustic model are modulated by speaker auxiliary information to recognize only the desired speaker. Affine transformation layers are inserted into the acoustic model network to integrate speaker information with the acoustic features. The speaker conditioning process allows the acoustic model to perform computation in the context of target-speaker auxiliary information. The proposed speaker conditioning method is a general approach and can be applied to any acoustic model architecture. Here, we employ speaker conditioning on a ResNet acoustic model. Experiments on the WSJ corpus show that the proposed speaker conditioning method is an effective solution to fuse speaker auxiliary information with acoustic features for multi-speaker speech recognition, achieving +9% and +20% relative WER reduction for clean and overlap speech scenarios, respectively, compared to the original ResNet acoustic model baseline.      
### 35.Real-time Speaker counting in a cocktail party scenario using Attention-guided Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2111.00316.pdf)
>  Most current speech technology systems are designed to operate well even in the presence of multiple active speakers. However, most solutions assume that the number of co-current speakers is known. Unfortunately, this information might not always be available in real-world applications. In this study, we propose a real-time, single-channel attention-guided Convolutional Neural Network (CNN) to estimate the number of active speakers in overlapping speech. The proposed system extracts higher-level information from the speech spectral content using a CNN model. Next, the attention mechanism summarizes the extracted information into a compact feature vector without losing critical information. Finally, the active speakers are classified using a fully connected network. Experiments on simulated overlapping speech using WSJ corpus show that the attention solution is shown to improve the performance by almost 3% absolute over conventional temporal average pooling. The proposed Attention-guided CNN achieves 76.15% for both Weighted Accuracy and average Recall, and 75.80% Precision on speech segments as short as 20 frames (i.e., 200 ms). All the classification metrics exceed 92% for the attention-guided model in offline scenarios where the input signal is more than 100 frames long (i.e., 1s).      
### 36.Cross-Modality Fusion Transformer for Multispectral Object Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.00273.pdf)
>  Multispectral image pairs can provide the combined information, making object detection applications more reliable and robust in the open world. To fully exploit the different modalities, we present a simple yet effective cross-modality feature fusion approach, named Cross-Modality Fusion Transformer (CFT) in this paper. Unlike prior CNNs-based works, guided by the transformer scheme, our network learns long-range dependencies and integrates global contextual information in the feature extraction stage. More importantly, by leveraging the self attention of the transformer, the network can naturally carry out simultaneous intra-modality and inter-modality fusion, and robustly capture the latent interactions between RGB and Thermal domains, thereby significantly improving the performance of multispectral object detection. Extensive experiments and ablation studies on multiple datasets demonstrate that our approach is effective and achieves state-of-the-art detection performance. Our code and models will be released soon at <a class="link-external link-https" href="https://github.com/DocF/multispectral-object-detection" rel="external noopener nofollow">this https URL</a>.      
### 37.Speech Denoising Using Only Single Noisy Audio Samples  [ :arrow_down: ](https://arxiv.org/pdf/2111.00242.pdf)
>  In this paper, we propose a novel Single Noisy Audio De-noising Framework (SNA-DF) for speech denoising using only single noisy audio samples, which overcomes the limi-tation of constructing either noisy-clean training pairs or multiple independent noisy audio samples. The proposed SNA-DF contains two modules: training audio pairs gener-ated module and audio denoising module. The first module adopts a random audio sub-sampler on single noisy audio samples for the generation of training audio pairs. The sub-sampled training audio pairs are then fed into the audio denoising module, which employs a deep complex U-Net incorporating a complex two-stage transformer (cTSTM) to extract both magnitude and phase information for taking full advantage of the complex features of single noisy au-dios. Experimental results show that the proposed SNA-DF not only eliminates the high dependence on clean targets of traditional audio denoising methods, but also outperforms the methods using multiple noisy audio samples.      
### 38.Unpaired Learning for High Dynamic Range Image Tone Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2111.00219.pdf)
>  High dynamic range (HDR) photography is becoming increasingly popular and available by DSLR and mobile-phone cameras. While deep neural networks (DNN) have greatly impacted other domains of image manipulation, their use for HDR tone-mapping is limited due to the lack of a definite notion of ground-truth solution, which is needed for producing training data. <br>In this paper we describe a new tone-mapping approach guided by the distinct goal of producing low dynamic range (LDR) renditions that best reproduce the visual characteristics of native LDR images. This goal enables the use of an unpaired adversarial training based on unrelated sets of HDR and LDR images, both of which are widely available and easy to acquire. <br>In order to achieve an effective training under this minimal requirements, we introduce the following new steps and components: (i) a range-normalizing pre-process which estimates and applies a different level of curve-based compression, (ii) a loss that preserves the input content while allowing the network to achieve its goal, and (iii) the use of a more concise discriminator network, designed to promote the reproduction of low-level attributes native LDR possess. <br>Evaluation of the resulting network demonstrates its ability to produce photo-realistic artifact-free tone-mapped images, and state-of-the-art performance on different image fidelity indices and visual distances.      
### 39.M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation in Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.00193.pdf)
>  Feature reassembly is an essential component in modern CNNs-based segmentation approaches, which includes feature downsampling and upsampling operators. Existing feature reassembly operators reassemble multiple features from a small predefined region into one for each target location independently. This may result in loss of spatial information, which could vanish activations of tiny lesions particularly when they cluster together. In this paper, we propose a many-to-many reassembly of features (M2MRF). It reassembles features in a dimension-reduced feature space and simultaneously aggregates multiple features inside a large predefined region into multiple target features. In this way, long range spatial dependencies are captured to maintain activations on tiny lesions, particularly when multiple lesions coexist. Experimental results on two lesion segmentation benchmarks, i.e. DDR and IDRiD, show that our M2MRF outperforms existing feature reassembly operators.      
### 40.Von Mises Tapering: A New Circular Windowing  [ :arrow_down: ](https://arxiv.org/pdf/2111.00188.pdf)
>  Discrete and continuous standard windowing are revisited and a a new taper is introduced, which is derived from the normal circular distribution by von Mises. Both the continuous-time and the discrete-time windows are considered, and their spectra obtained. A brief comparison with further classical window families is performed in terms of their properties in the spectral domain. These windows can be used in spectral analysis, and in particular, in the design of FIR (finite impulse response) filters as an alternative to the Kaiser window      
### 41.Echopype: A Python library for interoperable and scalable processing of water column sonar data for biological information  [ :arrow_down: ](https://arxiv.org/pdf/2111.00187.pdf)
>  High-frequency sonar systems deployed on a broad variety of ocean observing platforms are creating a deluge of water column sonar data at unprecedented speed from all corners of the ocean. Efficient and integrative analysis of these data, either across different sonar instruments or with other oceanographic datasets, holds the key to monitoring and understanding the response of marine organisms to the rapidly changing environments. In this paper we present echopype, an open-source Python software library designed to address this need. By standardizing water column sonar data from diverse instrument sources following a community convention and utilizing the widely embraced netCDF data model to encode sonar data as labeled, multi-dimensional arrays, echopype facilitates intuitive, user-friendly exploration and use of sonar data in an instrument-agnostic manner. Through leveraging existing open-source Python libraries optimized for distributed computing, echopype directly enables computational interoperability and scalability in both local and cloud computing environments. Echopype's modularized package structure further provides a conceptually unified implementation framework for expanding its support for additional instrument raw data formats and incorporating new data analysis and visualization functionalities. We envision the continued development of echopype as a catalyst for making information derived from water column sonar data an integrated component of regional and global ocean observation strategies.      
### 42.Multi-User Augmented Reality with Infrastructure-free Collaborative Localization  [ :arrow_down: ](https://arxiv.org/pdf/2111.00174.pdf)
>  Multi-user augmented reality (AR) could someday empower first responders with the ability to see team members around corners and through walls. For this vision of people tracking in dynamic environments to be practical, we need a relative localization system that is nearly instantly available across wide-areas without any existing infrastructure or manual setup. In this paper, we present LocAR, an infrastructure-free 6-degrees-of-freedom (6DoF) localization system for AR applications that uses motion estimates and range measurements between users to establish an accurate relative coordinate system. We show that not only is it possible to perform collaborative localization without infrastructure or global coordinates, but that our approach provides nearly the same level of accuracy as fixed infrastructure approaches for AR teaming applications. LocAR uses visual-inertial odometry (VIO) in conjunction with ultra-wideband (UWB) ranging radios to estimate the relative position of each device in an ad-hoc manner. The system leverages a collaborative 6DoF particle filtering formulation that operates on sporadic messages exchanged between nearby users. Unlike map or landmark sharing approaches, this allows for collaborative AR sessions even if users do not overlap the same spaces. LocAR consists of an open-source UWB firmware and reference mobile phone application that can display the location of team members in real-time using mobile AR. We evaluate LocAR across multiple buildings under a wide-variety of conditions including a contiguous 30,000 square foot region spanning multiple floors and find that it achieves median geometric error in 3D of less than 1 meter between five users freely walking across 3 floors.      
### 43.Cross-attention conformer for context modeling in speech enhancement for ASR  [ :arrow_down: ](https://arxiv.org/pdf/2111.00127.pdf)
>  This work introduces \emph{cross-attention conformer}, an attention-based architecture for context modeling in speech enhancement. Given that the context information can often be sequential, and of different length as the audio that is to be enhanced, we make use of cross-attention to summarize and merge contextual information with input features. Building upon the recently proposed conformer model that uses self attention layers as building blocks, the proposed cross-attention conformer can be used to build deep contextual models. As a concrete example, we show how noise context, i.e., short noise-only audio segment preceding an utterance, can be used to build a speech enhancement feature frontend using cross-attention conformer layers for improving noise robustness of automatic speech recognition.      
### 44.Fetal MRI by robust deep generative prior reconstruction and diffeomorphic registration: application to gestational age prediction  [ :arrow_down: ](https://arxiv.org/pdf/2111.00102.pdf)
>  Magnetic resonance imaging of whole fetal body and placenta is limited by different sources of motion affecting the womb. Usual scanning techniques employ single-shot multi-slice sequences where anatomical information in different slices may be subject to different deformations, contrast variations or artifacts. Volumetric reconstruction formulations have been proposed to correct for these factors, but they must accommodate a non-homogeneous and non-isotropic sampling, so regularization becomes necessary. Thus, in this paper we propose a deep generative prior for robust volumetric reconstructions integrated with a diffeomorphic volume to slice registration method. Experiments are performed to validate our contributions and compare with a state of the art method in a cohort of $72$ fetal datasets in the range of $20-36$ weeks gestational age. Results suggest improved image resolution and more accurate prediction of gestational age at scan when comparing to a state of the art reconstruction method. In addition, gestational age prediction results from our volumetric reconstructions compare favourably with existing brain-based approaches, with boosted accuracy when integrating information of organs other than the brain. Namely, a mean absolute error of $0.618$ weeks ($R^2=0.958$) is achieved when combining fetal brain and trunk information.      
### 45.Targeted Hardening of Electric Distribution System Components for Enhanced Resilience against Earthquakes  [ :arrow_down: ](https://arxiv.org/pdf/2111.00080.pdf)
>  Securing the power system from catastrophic natural disasters is a rising problem in power system operation and planning. This paper particularly considers earthquake and aims to evaluate and improve the resilience of power distribution networks by developing a novel hardware hardening framework. In the proposed framework, fragility curves of the network equipment are used to represent equipment failure probabilities when facing an earthquake, and failure scenarios of the distribution network are obtained via the Monte Carlo method. Based on the distribution network topology and the locations of essential loads, various hardware hardening strategies are determined within the proposed framework. Through a series of resilience and economic analyses, the optimal hardening strategy is determined to improve the resilience and supply the essential loads during and after the earthquake. The efficacy of the proposed approach is examined through simulations on an IEEE 33-bus test feeder.      
### 46.Differentiable Tracking-Based Training of Deep Learning Sound Source Localizers  [ :arrow_down: ](https://arxiv.org/pdf/2111.00030.pdf)
>  Data-based and learning-based sound source localization (SSL) has shown promising results in challenging conditions, and is commonly set as a classification or a regression problem. Regression-based approaches have certain advantages over classification-based, such as continuous direction-of-arrival estimation of static and moving sources. However, multi-source scenarios require multiple regressors without a clear training strategy up-to-date, that does not rely on auxiliary information such as simultaneous sound classification. We investigate end-to-end training of such methods with a technique recently proposed for video object detectors, adapted to the SSL setting. A differentiable network is constructed that can be plugged to the output of the localizer to solve the optimal assignment between predictions and references, optimizing directly the popular CLEAR-MOT tracking metrics. Results indicate large improvements over directly optimizing mean squared errors, in terms of localization error, detection metrics, and tracking capabilities.      
### 47.Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model  [ :arrow_down: ](https://arxiv.org/pdf/2111.00009.pdf)
>  In typical multi-talker speech recognition systems, a neural network-based acoustic model predicts senone state posteriors for each speaker. These are later used by a single-talker decoder which is applied on each speaker-specific output stream separately. In this work, we argue that such a scheme is sub-optimal and propose a principled solution that decodes all speakers jointly. We modify the acoustic model to predict joint state posteriors for all speakers, enabling the network to express uncertainty about the attribution of parts of the speech signal to the speakers. We employ a joint decoder that can make use of this uncertainty together with higher-level language information. For this, we revisit decoding algorithms used in factorial generative models in early multi-talker speech recognition systems. In contrast with these early works, we replace the GMM acoustic model with DNN, which provides greater modeling power and simplifies part of the inference. We demonstrate the advantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS dataset.      
### 48.Single Step Phase Optimisation for Coherent Beam Combination using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.00001.pdf)
>  Coherent beam combination of multiple fibres can be used to overcome limitations such as the power handling capability of single fibre configurations. In such a scheme, the focal intensity profile is critically dependent upon the relative phase of each fibre and so precise control over the phase of each fibre channel is essential. Determining the required phase compensations from the focal intensity profile alone (as measured via a camera) is extremely challenging with a large number of fibres as the phase information is obfuscated. Whilst iterative methods exist for phase retrieval, in practice, due to phase noise within a fibre laser amplification system, a single step process with computational time on the scale of milliseconds is needed. Here, we show how a neural network can be used to identify the phases of each fibre from the focal intensity profile, in a single step of ~ 10 milliseconds, for a simulated 3-ring hexagonal close packed arrangement, containing 19 separate fibres and subsequently how this enables bespoke beam shaping. In addition, we show that deep learning can be used to determine whether a desired intensity profile is physically possible within the simulation. This, coupled with the demonstrated resilience against simulated experimental noise, indicates a strong potential for the application of deep learning for coherent beam combination.      
### 49.FREGAN : an application of generative adversarial networks in enhancing the frame rate of videos  [ :arrow_down: ](https://arxiv.org/pdf/2111.01105.pdf)
>  A digital video is a collection of individual frames, while streaming the video the scene utilized the time slice for each frame. High refresh rate and high frame rate is the demand of all high technology applications. The action tracking in videos becomes easier and motion becomes smoother in gaming applications due to the high refresh rate. It provides a faster response because of less time in between each frame that is displayed on the screen. FREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been proposed, which predicts future frames of a video sequence based on a sequence of past frames. In this paper, we investigated the GAN model and proposed FREGAN for the enhancement of frame rate in videos. We have utilized Huber loss as a loss function in the proposed FREGAN. It provided excellent results in super-resolution and we have tried to reciprocate that performance in the application of frame rate enhancement. We have validated the effectiveness of the proposed model on the standard datasets (UCF101 and RFree500). The experimental outcomes illustrate that the proposed model has a Peak signal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM) of 0.95.      
### 50.With a Little Help from my Temporal Context: Multimodal Egocentric Action Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.01024.pdf)
>  In egocentric videos, actions occur in quick succession. We capitalise on the action's temporal context and propose a method that learns to attend to surrounding actions in order to improve recognition performance. To incorporate the temporal context, we propose a transformer-based multimodal model that ingests video and audio as input modalities, with an explicit language model providing action sequence context to enhance the predictions. We test our approach on EPIC-KITCHENS and EGTEA datasets reporting state-of-the-art performance. Our ablations showcase the advantage of utilising temporal context as well as incorporating audio input modality and language model to rescore predictions. Code and models at: <a class="link-external link-https" href="https://github.com/ekazakos/MTCN" rel="external noopener nofollow">this https URL</a>.      
### 51.Computing input-output projections of dynamical models with applications to structural identifiability  [ :arrow_down: ](https://arxiv.org/pdf/2111.00991.pdf)
>  Elimination of unknowns in a system of differential equations is often required when analysing (possibly nonlinear) dynamical systems models, where only a subset of variables are observable. One such analysis, identifiability, often relies on computing input-output relations via differential algebraic elimination. Determining identifiability, a natural prerequisite for meaningful parameter estimation, is often prohibitively expensive for medium to large systems due to the computationally expensive task of elimination. <br>We propose an algorithm that computes a description of the set of differential-algebraic relations between the input and output variables of a dynamical system model. The resulting algorithm outperforms general-purpose software for differential elimination on a set of benchmark models from literature. <br>We use the designed elimination algorithm to build a new randomized algorithm for assessing structural identifiability of a parameter in a parametric model. A parameter is said to be identifiable if its value can be uniquely determined from input-output data assuming the absence of noise and sufficiently exciting inputs. Our new algorithm allows the identification of models that could not be tackled before. <br>Our implementation is publicly available as a Julia package at <a class="link-external link-https" href="https://github.com/SciML/StructuralIdentifiability.jl" rel="external noopener nofollow">this https URL</a>.      
### 52.A transfer learning based approach for pronunciation scoring  [ :arrow_down: ](https://arxiv.org/pdf/2111.00976.pdf)
>  Phone-level pronunciation scoring is a challenging task, with performance far from that of human annotators. Standard systems generate a score for each phone in a phrase using models trained for automatic speech recognition (ASR) with native data only. Better performance has been shown when using systems that are trained specifically for the task using non-native data. Yet, such systems face the challenge that datasets labelled for this task are scarce and usually small. In this paper, we present a transfer learning-based approach that leverages a model trained for ASR, adapting it for the task of pronunciation scoring. We analyze the effect of several design choices and compare the performance with a state-of-the-art goodness of pronunciation (GOP) system. Our final system is 20% better than the GOP system on EpaDB, a database for pronunciation scoring research, for a cost function that prioritizes low rates of unnecessary corrections.      
### 53.RefineGAN: Universally Generating Waveform Better than Ground Truth with Highly Accurate Pitch and Intensity Responses  [ :arrow_down: ](https://arxiv.org/pdf/2111.00962.pdf)
>  Most GAN(Generative Adversarial Network)-based approaches towards high-fidelity waveform generation heavily rely on discriminators to improve their performance. However, the over-use of this GAN method introduces much uncertainty into the generation process and often result in mismatches of pitch and intensity, which is fatal when it comes to sensitive using cases such as singing voice synthesis(SVS). To address this problem, we propose RefineGAN, a high-fidelity neural vocoder with faster-than-real-time generation capability, and focused on the robustness, pitch and intensity accuracy, and full-band audio generation. We employed a pitch-guided refine architecture with a multi-scale spectrogram-based loss function to help stabilize the training process and maintain the robustness of the neural vocoder while using the GAN-based training method. Audio generated using this method shows a better performance in subjective tests when compared with the ground-truth audio. This result shows that the fidelity is even improved during the waveform reconstruction by eliminating defects produced by the speaker and the recording procedure. Moreover, a further study shows that models trained on a specified type of data can perform on totally unseen language and unseen speaker identically well. Generated sample pairs are provided on <a class="link-external link-https" href="https://timedomain-tech.github.io/refinegan/" rel="external noopener nofollow">this https URL</a>.      
### 54.Equivariant Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.00899.pdf)
>  In state-of-the-art self-supervised learning (SSL) pre-training produces semantically good representations by encouraging them to be invariant under meaningful transformations prescribed from human knowledge. In fact, the property of invariance is a trivial instance of a broader class called equivariance, which can be intuitively understood as the property that representations transform according to the way the inputs transform. Here, we show that rather than using only invariance, pre-training that encourages non-trivial equivariance to some transformations, while maintaining invariance to other transformations, can be used to improve the semantic quality of representations. Specifically, we extend popular SSL methods to a more general framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL, a simple additional pre-training objective encourages equivariance by predicting the transformations applied to the input. We demonstrate E-SSL's effectiveness empirically on several popular computer vision benchmarks. Furthermore, we demonstrate usefulness of E-SSL for applications beyond computer vision; in particular, we show its utility on regression problems in photonics science. We will release our code.      
### 55.A mathematical model of the vowel space  [ :arrow_down: ](https://arxiv.org/pdf/2111.00868.pdf)
>  The articulatory-acoustic relationship is many-to-one and non linear and this is a great limitation for studying speech production. A simplification is proposed to set a bijection between the vowel space (f1, f2) and the parametric space of different vocal tract models. The generic area function model is based on mixtures of cosines allowing the generation of main vowels with two formulas. Then the mixture function is transformed into a coordination function able to deal with articulatory parameters. This is shown that the coordination function acts similarly with the Fant's model and with the 4-Tube DRM derived from the generic model.      
### 56.MEmoBERT: Pre-training Model with Prompt-based Learning for Multimodal Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.00865.pdf)
>  Multimodal emotion recognition study is hindered by the lack of labelled corpora in terms of scale and diversity, due to the high annotation cost and label ambiguity. In this paper, we propose a pre-training model \textbf{MEmoBERT} for multimodal emotion recognition, which learns multimodal joint representations through self-supervised learning from large-scale unlabeled video data that come in sheer volume. Furthermore, unlike the conventional "pre-train, finetune" paradigm, we propose a prompt-based method that reformulates the downstream emotion classification task as a masked text prediction one, bringing the downstream task closer to the pre-training. Extensive experiments on two benchmark datasets, IEMOCAP and MSP-IMPROV, show that our proposed MEmoBERT significantly enhances emotion recognition performance.      
### 57.Topology identification of autonomous quantum dynamical networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.00812.pdf)
>  Topology identification comprises reconstructing the interaction Hamiltonian of a quantum network by properly processing measurements of its density operator within a fixed time interval. It finds application in several quantum technology contexts, ranging from quantum communication to quantum computing or sensing. In this paper, we provide analytical conditions for the solvability of the topology identification problem of autonomous quantum dynamical networks. The analytical results are then converted in an algorithm for quantum network reconstruction that is able to efficiently determine the topology of large-scale networks and is easily implementable on standard computer facilities. The obtained algorithm is tested on numerical examples based on the quantum walks formalism.      
### 58.Geometric Control for Load Transportation with Quadrotor UAVs by Elastic Cables  [ :arrow_down: ](https://arxiv.org/pdf/2111.00777.pdf)
>  Groups of unmanned aerial vehicles (UAVs) are increasingly utilized in transportation task as the combined strength allows to increase the maximum payload. However, the resulting mechanical coupling of the UAVs impose new challenges in terms of the tracking control. Thus, we design a geometric trajectory tracking controller for the cooperative task of four quadrotor UAVs carrying and transporting a rigid body, which is attached to the quadrotors via inflexible elastic cables. The elasticity of the cables together with techniques of singular perturbation allows a reduction in the model to that of a similar model with inelastic cables. In this reduced model, we design a controller such that the position and attitude of the load exponentially converges to a given desired trajectory. We then show that this result leads to an uniformly converging tracking error for the original elastic model under some assumptions. Furthermore, under the presence of unstructured disturbances on the system, we show that the error is ultimately bounded with an arbitrarily small bound. Finally, a simulation illustrates the theoretical results.      
### 59.A Novel 1D State Space for Efficient Music Rhythmic Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.00704.pdf)
>  Inferring music time structures has a broad range of applications in music production, processing and analysis. Scholars have proposed various methods to analyze different aspects of time structures, including beat, downbeat, tempo and meter. Many of the state-of-the-art methods, however, are computationally expensive. This makes them inapplicable in real-world industrial settings where the scale of the music collections can be millions. This paper proposes a new state space approach for music time structure analysis. The proposed approach collapses the commonly used 2D state spaces into 1D through a jump-back reward strategy. This reduces the state space size drastically. We then utilize the proposed method for casual, joint beat, downbeat, tempo, and meter tracking, and compare it against several previous beat and downbeat tracking methods. The proposed method delivers comparable performance with the state-of-the-art joint casual models with a much smaller state space and a more than 30 times speedup.      
### 60.Safe Learning of Linear Time-Invariant Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.00631.pdf)
>  We consider safety in simultaneous learning and control of discrete-time linear time-invariant systems. We provide rigorous confidence bounds on the learned model of the system based on the number of utilized state measurements. These bounds are used to modify control inputs to the system via an optimization problem with potentially time-varying safety constraints. We prove that the state can only exit the safe set with small probability, provided a feasible solution to the safety-constrained optimization exists. This optimization problem is then reformulated in a more computationally-friendly format by tightening the safety constraints to account for model uncertainty during learning. The tightening decreases as the confidence in the learned model improves. We finally prove that, under persistence of excitation, the tightening becomes negligible as more measurements are gathered.      
### 61.Towards Language Modelling in the Speech Domain Using Sub-word Linguistic Units  [ :arrow_down: ](https://arxiv.org/pdf/2111.00610.pdf)
>  Language models (LMs) for text data have been studied extensively for their usefulness in language generation and other downstream tasks. However, language modelling purely in the speech domain is still a relatively unexplored topic, with traditional speech LMs often depending on auxiliary text LMs for learning distributional aspects of the language. For the English language, these LMs treat words as atomic units, which presents inherent challenges to language modelling in the speech domain. In this paper, we propose a novel LSTM-based generative speech LM that is inspired by the CBOW model and built on linguistic units including syllables and phonemes. This offers better acoustic consistency across utterances in the dataset, as opposed to single melspectrogram frames, or whole words. With a limited dataset, orders of magnitude smaller than that required by contemporary generative models, our model closely approximates babbling speech. We show the effect of training with auxiliary text LMs, multitask learning objectives, and auxiliary articulatory features. Through our experiments, we also highlight some well known, but poorly documented challenges in training generative speech LMs, including the mismatch between the supervised learning objective with which these models are trained such as Mean Squared Error (MSE), and the true objective, which is speech quality. Our experiments provide an early indication that while validation loss and Mel Cepstral Distortion (MCD) are not strongly correlated with generated speech quality, traditional text language modelling metrics like perplexity and next-token-prediction accuracy might be.      
### 62.Laplacian Constrained Precision Matrix Estimation: Existence and High Dimensional Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2111.00590.pdf)
>  This paper considers the problem of estimating high dimensional Laplacian constrained precision matrices by minimizing Stein's loss. We obtain a necessary and sufficient condition for existence of this estimator, that boils down to checking whether a certain data dependent graph is connected. We also prove consistency in the high dimensional setting under the symmetryzed Stein loss. We show that the error rate does not depend on the graph sparsity, or other type of structure, and that Laplacian constraints are sufficient for high dimensional consistency. Our proofs exploit properties of graph Laplacians, and a characterization of the proposed estimator based on effective graph resistances. We validate our theoretical claims with numerical experiments.      
### 63.Classification of fetal compromise during labour: signal processing and feature engineering of the cardiotocograph  [ :arrow_down: ](https://arxiv.org/pdf/2111.00517.pdf)
>  Cardiotocography (CTG) is the main tool used for fetal monitoring during labour. Interpretation of CTG requires dynamic pattern recognition in real time. It is recognised as a difficult task with high inter- and intra-observer disagreement. Machine learning has provided a viable path towards objective and reliable CTG assessment. In this study, novel CTG features are developed based on clinical expertise and system control theory using an autoregressive moving-average (ARMA) model to characterise the response of the fetal heart rate to contractions. The features are evaluated in a machine learning model to assess their efficacy in identifying fetal compromise. ARMA features ranked amongst the top features for detecting fetal compromise. Additionally, including clinical factors in the machine learning model and pruning data based on a signal quality measure improved the performance of the classifier.      
### 64.Fully convolutional Siamese neural networks for buildings damage assessment from satellite images  [ :arrow_down: ](https://arxiv.org/pdf/2111.00508.pdf)
>  Damage assessment after natural disasters is needed to distribute aid and forces to recovery from damage dealt optimally. This process involves acquiring satellite imagery for the region of interest, localization of buildings, and classification of the amount of damage caused by nature or urban factors to buildings. In case of natural disasters, this means processing many square kilometers of the area to judge whether a particular building had suffered from the damaging factors. <br>In this work, we develop a computational approach for an automated comparison of the same region's satellite images before and after the disaster, and classify different levels of damage in buildings. Our solution is based on Siamese neural networks with encoder-decoder architecture. We include an extensive ablation study and compare different encoders, decoders, loss functions, augmentations, and several methods to combine two images. The solution achieved one of the best results in the Computer Vision for Building Damage Assessment competition.      
### 65.Learned Image Compression with Separate Hyperprior Decoders  [ :arrow_down: ](https://arxiv.org/pdf/2111.00485.pdf)
>  Learned image compression techniques have achieved considerable development in recent years. In this paper, we find that the performance bottleneck lies in the use of a single hyperprior decoder, in which case the ternary Gaussian model collapses to a binary one. To solve this, we propose to use three hyperprior decoders to separate the decoding process of the mixed parameters in discrete Gaussian mixture likelihoods, achieving more accurate parameters estimation. Experimental results demonstrate the proposed method optimized by MS-SSIM achieves on average 3.36% BD-rate reduction compared with state-of-the-art approach. The contribution of the proposed method to the coding time and FLOPs is negligible.      
### 66.Analysis of North Indian Classical Ragas Using Tonnetz  [ :arrow_down: ](https://arxiv.org/pdf/2111.00436.pdf)
>  In North Indian Classical music, each raga has been traditionally associated with a performance time, which supposedly maximizes its aesthetic and emotional effects on the listener. The objective of this work was to investigate the structural basis, if any, for the association of ragas with different times of the 24-hour span. The tonnetz framework has been used to analyze the pitch sets of 65 North Indian Classical ragas, and structural similarities have been observed between ragas associated with (1) times of transition between day and night, i.e., dawn and dusk, and (2) times between these transitions. These findings could provide some insight into the scientific basis of the age-old raga-time relation, and their effects on the perception of the listener.      
### 67.Deep Learning in Human Activity Recognition with Wearable Sensors: A Review on Advances  [ :arrow_down: ](https://arxiv.org/pdf/2111.00418.pdf)
>  Mobile and wearable devices have enabled numerous applications, including activity tracking, wellness monitoring, and human-computer interaction, that measure and improve our daily lives. Many of these applications are made possible by leveraging the rich collection of low-power sensors found in many mobile and wearable devices to perform human activity recognition (HAR). Recently, deep learning has greatly pushed the boundaries of HAR on mobile and wearable devices. This paper systematically categorizes and summarizes existing work that introduces deep learning methods for wearables-based HAR and provides a comprehensive analysis of the current advancements, developing trends, and major challenges. We also present cutting-edge frontiers and future directions for deep learning--based HAR.      
### 68.Kernel-Based Identification with Frequency Domain Side-Information  [ :arrow_down: ](https://arxiv.org/pdf/2111.00410.pdf)
>  This paper discusses the problem of system identification when frequency domain side-information is available. Initially, we consider the case where the side-information is provided as the $\mathcal{H}_{\infty}$-norm of the system being bounded by a given scalar. This framework allows considering different forms of frequency domain side-information, such as the dissipativity of the system. We propose a nonparametric identification approach for estimating the impulse response of the system under the given side-information. The estimation problem is formulated as a constrained optimization in a stable reproducing kernel Hilbert space, where suitable constraints are considered for incorporating the desired frequency domain features. The resulting optimization has an infinite-dimensional feasible set with an infinite number of constraints. We show that this problem is a well-defined convex program with a unique solution. We propose a heuristic that tightly approximates this unique solution. The proposed approach is equivalent to solving a finite-dimensional convex quadratically constrained quadratic program. The efficiency of the discussed method is verified by several numerical examples.      
### 69.Speech Emotion Recognition Using Quaternion Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.00404.pdf)
>  Although speech recognition has become a widespread technology, inferring emotion from speech signals still remains a challenge. To address this problem, this paper proposes a quaternion convolutional neural network (QCNN) based speech emotion recognition (SER) model in which Mel-spectrogram features of speech signals are encoded in an RGB quaternion domain. We show that our QCNN based SER model outperforms other real-valued methods in the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS, 8-classes) dataset, achieving, to the best of our knowledge, state-of-the-art results. The QCNN also achieves comparable results with the state-of-the-art methods in the Interactive Emotional Dyadic Motion Capture (IEMOCAP 4-classes) and Berlin EMO-DB (7-classes) datasets. Specifically, the model achieves an accuracy of 77.87\%, 70.46\%, and 88.78\% for the RAVDESS, IEMOCAP, and EMO-DB datasets, respectively. In addition, our results show that the quaternion unit structure is better able to encode internal dependencies to reduce its model size significantly compared to other methods.      
### 70.FANS: Fusing ASR and NLU for on-device SLU  [ :arrow_down: ](https://arxiv.org/pdf/2111.00400.pdf)
>  Spoken language understanding (SLU) systems translate voice input commands to semantics which are encoded as an intent and pairs of slot tags and values. Most current SLU systems deploy a cascade of two neural models where the first one maps the input audio to a transcript (ASR) and the second predicts the intent and slots from the transcript (NLU). In this paper, we introduce FANS, a new end-to-end SLU model that fuses an ASR audio encoder to a multi-task NLU decoder to infer the intent, slot tags, and slot values directly from a given input audio, obviating the need for transcription. FANS consists of a shared audio encoder and three decoders, two of which are seq-to-seq decoders that predict non null slot tags and slot values in parallel and in an auto-regressive manner. FANS neural encoder and decoders architectures are flexible which allows us to leverage different combinations of LSTM, self-attention, and attenders. Our experiments show compared to the state-of-the-art end-to-end SLU models, FANS reduces ICER and IRER errors relatively by 30 % and 7 %, respectively, when tested on an in-house SLU dataset and by 0.86 % and 2 % absolute when tested on a public SLU dataset.      
### 71.A Decentralized Reinforcement Learning Framework for Efficient Passage of Emergency Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2111.00278.pdf)
>  Emergency vehicles (EMVs) play a critical role in a city's response to time-critical events such as medical emergencies and fire outbreaks. The existing approaches to reduce EMV travel time employ route optimization and traffic signal pre-emption without accounting for the coupling between route these two subproblems. As a result, the planned route often becomes suboptimal. In addition, these approaches also do not focus on minimizing disruption to the overall traffic flow. To address these issues, we introduce EMVLight in this paper. This is a decentralized reinforcement learning (RL) framework for simultaneous dynamic routing and traffic signal control. EMVLight extends Dijkstra's algorithm to efficiently update the optimal route for an EMV in real-time as it travels through the traffic network. Consequently, the decentralized RL agents learn network-level cooperative traffic signal phase strategies that reduce EMV travel time and the average travel time of non-EMVs in the network. We have carried out comprehensive experiments with synthetic and real-world maps to demonstrate this benefit. Our results show that EMVLight outperforms benchmark transportation engineering techniques as well as existing RL-based traffic signal control methods.      
### 72.Learning Continuous Representation of Audio for Arbitrary Scale Super Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2111.00195.pdf)
>  Audio super resolution aims to predict the missing high resolution components of the low resolution audio signals. While audio in nature is continuous signal, current approaches treat it as discrete data (i.e., input is defined on discrete time domain), and consider the super resolution over fixed scale factor (i.e., it is required to train a new neural network to change output resolution). To obtain a continuous representation of audio and enable super resolution for arbitrary scale factor, we propose a method of neural implicit representation, coined Local Implicit representation for Super resolution of Arbitrary scale (LISA). Our method locally parameterizes a chunk of audio as a function of continuous time, and represents each chunk with the local latent codes of neighboring chunks so that the function can extrapolate the signal at any time coordinate, i.e., infinite resolution. To learn a continuous representation for audio, we design a self-supervised learning strategy to practice super resolution tasks up to the original resolution by stochastic selection. Our numerical evaluation shows that LISA outperforms the previous fixed-scale methods with a fraction of parameters, but also is capable of arbitrary scale super resolution even beyond the resolution of training data.      
### 73.Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings  [ :arrow_down: ](https://arxiv.org/pdf/2111.00185.pdf)
>  Policy gradient methods have been frequently applied to problems in control and reinforcement learning with great success, yet existing convergence analysis still relies on non-intuitive, impractical and often opaque conditions. In particular, existing rates are achieved in limited settings, under strict smoothness and bounded conditions. In this work, we establish explicit convergence rates of policy gradient methods without relying on these conditions, instead extending the convergence regime to weakly smooth policy classes with $L_2$ integrable gradient. We provide intuitive examples to illustrate the insight behind these new conditions. We also characterize the sufficiency conditions for the ergodicity of near-linear MDPs, which represent an important class of problems. Notably, our analysis also shows that fast convergence rates are achievable for both the standard policy gradient and the natural policy gradient algorithms under these assumptions. Lastly we provide conditions and analysis for optimality of the converged policies.      
### 74.Advanced Algorithms of Collision Free Navigation and Flocking for Autonomous UAVs  [ :arrow_down: ](https://arxiv.org/pdf/2111.00166.pdf)
>  Unmanned aerial vehicles (UAVs) have become very popular for many military and civilian applications including in agriculture, construction, mining, environmental monitoring, etc. A desirable feature for UAVs is the ability to navigate and perform tasks autonomously with least human interaction. This is a very challenging problem due to several factors such as the high complexity of UAV applications, operation in harsh environments, limited payload and onboard computing power and highly nonlinear dynamics. The work presented in this report contributes towards the state-of-the-art in UAV control for safe autonomous navigation and motion coordination of multi-UAV systems. The first part of this report deals with single-UAV systems. The complex problem of three-dimensional (3D) collision-free navigation in unknown/dynamic environments is addressed. To that end, advanced 3D reactive control strategies are developed adopting the sense-and-avoid paradigm to produce quick reactions around obstacles. A special case of navigation in 3D unknown confined environments (i.e. tunnel-like) is also addressed. General 3D kinematic models are considered in the design which makes these methods applicable to different UAV types in addition to underwater vehicles. Moreover, different implementation methods for these strategies with quadrotor-type UAVs are also investigated considering UAV dynamics in the control design. Practical experiments and simulations were carried out to analyze the performance of the developed methods. The second part of this report addresses safe navigation for multi-UAV systems. Distributed motion coordination methods of multi-UAV systems for flocking and 3D area coverage are developed. These methods offer good computational cost for large-scale systems. Simulations were performed to verify the performance of these methods considering systems with different sizes.      
### 75.Pseudo-Labeling for Massively Multilingual Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.00161.pdf)
>  Semi-supervised learning through pseudo-labeling has become a staple of state-of-the-art monolingual speech recognition systems. In this work, we extend pseudo-labeling to massively multilingual speech recognition with 60 languages. We propose a simple pseudo-labeling recipe that works well even with low-resource languages: train a supervised multilingual model, fine-tune it with semi-supervised learning on a target language, generate pseudo-labels for that language, and train a final model using pseudo-labels for all languages, either from scratch or by fine-tuning. Experiments on the labeled Common Voice and unlabeled VoxPopuli datasets show that our recipe can yield a model with better performance for many languages that also transfers well to LibriSpeech.      
### 76.On the Control of Flying Qubits  [ :arrow_down: ](https://arxiv.org/pdf/2111.00143.pdf)
>  The control of flying quantum bits (qubits) carried by traveling quantum fields is crucial for coherent information transmission in quantum networks. In this paper, we develop a general framework for modeling the generation, catching and transformation processes of flying qubits. We introduce the quantum stochastic differential equation (QSDE) to describe the flying-qubit input-output relations actuated by a standing quantum system. Under the continuous time-ordered photon-number basis, the infinite-dimensional QSDE is reduced to a low-dimensional deterministic non-unitary differential equation for the state evolution of the standing system, and the outgoing flying-qubit states can be calculated via randomly occurring quantum jumps. This makes it possible, as demonstrated by examples of flying-qubit generation and transformation, to analyze general cases when the number of excitations is not reserved. The proposed framework lays the foundation for the design of flying-qubit control systems from a control theoretic point of view, within which advanced control techniques can be incorporated for practical applications.      
### 77.Visual Explanations for Convolutional Neural Networks via Latent Traversal of Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.00116.pdf)
>  Lack of explainability in artificial intelligence, specifically deep neural networks, remains a bottleneck for implementing models in practice. Popular techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) provide a coarse map of salient features in an image, which rarely tells the whole story of what a convolutional neural network (CNN) learned. Using COVID-19 chest X-rays, we present a method for interpreting what a CNN has learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework disentangles lung structure from COVID-19 features. Using this GAN, we can visualize the transition of a pair of COVID negative lungs in a chest radiograph to a COVID positive pair by interpolating in the latent space of the GAN, which provides fine-grained visualization of how the CNN responds to varying features within the lungs.      
### 78.Principal Component Pursuit for Pattern Identification in Environmental Mixtures  [ :arrow_down: ](https://arxiv.org/pdf/2111.00104.pdf)
>  Environmental health researchers often aim to identify sources/behaviors that give rise to potentially harmful exposures. We adapted principal component pursuit (PCP)-a robust technique for dimensionality reduction in computer vision and signal processing-to identify patterns in environmental mixtures. PCP decomposes the exposure mixture into a low-rank matrix containing consistent exposure patterns across pollutants and a sparse matrix isolating unique exposure events. We adapted PCP to accommodate non-negative and missing data, and values below a given limit of detection (LOD). We simulated data to represent environmental mixtures of two sizes with increasing proportions &lt;LOD and three noise structures. We compared PCP-LOD to principal component analysis (PCA) to evaluate performance. We next applied PCP-LOD to a mixture of 21 persistent organic pollutants (POPs) measured in 1,000 U.S. adults from the 2001-2002 National Health and Nutrition Examination Survey. We applied singular value decomposition to the estimated low-rank matrix to characterize the patterns. PCP-LOD recovered the true number of patterns through cross-validation for all simulations; based on an a priori specified criterion, PCA recovered the true number of patterns in 32% of simulations. PCP-LOD achieved lower relative predictive error than PCA for all simulated datasets with up to 50% of the data &lt;LOD. When 75% of values were &lt;LOD, PCP-LOD outperformed PCA only when noise was low. In the POP mixture, PCP-LOD identified a rank-three underlying structure and separated 6% of values as unique events. One pattern represented comprehensive exposure to all POPs. The other patterns grouped chemicals based on known structure and toxicity. PCP-LOD serves as a useful tool to express multi-dimensional exposures as consistent patterns that, if found to be related to adverse health, are amenable to targeted interventions.      
### 79.Online Optimization with Feedback Delay and Nonlinear Switching Cost  [ :arrow_down: ](https://arxiv.org/pdf/2111.00095.pdf)
>  We study a variant of online optimization in which the learner receives $k$-round $\textit{delayed feedback}$ about hitting cost and there is a multi-step nonlinear switching cost, i.e., costs depend on multiple previous actions in a nonlinear manner. Our main result shows that a novel Iterative Regularized Online Balanced Descent (iROBD) algorithm has a constant, dimension-free competitive ratio that is $O(L^{2k})$, where $L$ is the Lipschitz constant of the switching cost. Additionally, we provide lower bounds that illustrate the Lipschitz condition is required and the dependencies on $k$ and $L$ are tight. Finally, via reductions, we show that this setting is closely related to online control problems with delay, nonlinear dynamics, and adversarial disturbances, where iROBD directly offers constant-competitive online policies.      
### 80.Stitching Dynamic Movement Primitives and Image-based Visual Servo Control  [ :arrow_down: ](https://arxiv.org/pdf/2111.00088.pdf)
>  Utilizing perception for feedback control in combination with Dynamic Movement Primitive (DMP)-based motion generation for a robot's end-effector control is a useful solution for many robotic manufacturing tasks. For instance, while performing an insertion task when the hole or the recipient part is not visible in the eye-in-hand camera, a learning-based movement primitive method can be used to generate the end-effector path. Once the recipient part is in the field of view (FOV), Image-based Visual Servo (IBVS) can be used to control the motion of the robot. Inspired by such applications, this paper presents a generalized control scheme that switches between motion generation using DMPs and IBVS control. To facilitate the design, a common state space representation for the DMP and the IBVS systems is first established. Stability analysis of the switched system using multiple Lyapunov functions shows that the state trajectories converge to a bound asymptotically. The developed method is validated by two real world experiments using the eye-in-hand configuration on a Baxter research robot.      
### 81.DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation Therapy  [ :arrow_down: ](https://arxiv.org/pdf/2111.00077.pdf)
>  The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet is proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP challenge were utilized, with 200 for training, 40 for validation, and 100 for testing. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord, right parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared error (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume histogram (DVH) based loss functions were investigated. Each model's performance was compared using a 3D dose score, $\bar{S_{D}}$, (mean absolute difference between ground truth and predicted 3D dose distributions) and a DVH score, $\bar{S_{DVH}}$ (mean absolute difference between ground truth and predicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc [Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the MAE plus DVH-based loss function had the best dose score performance of the OpenKBP entries. MAE+DVH model had the lowest prediction error (P&lt;0.0001, Wilcoxon test) on validation and test datasets (validation: $\bar{S_{D}}$=2.3Gy, $\bar{S_{DVH}}$=1.9Gy; test: $\bar{S_{D}}$=2.0Gy, $\bar{S_{DVH}}$=1.6Gy) followed by the MAE model (validation: $\bar{S_{D}}$=3.6Gy, $\bar{S_{DVH}}$=2.4Gy; test: $\bar{S_{D}}$=3.5Gy, $\bar{S_{DVH}}$=2.3Gy). The MSE model had the highest prediction error (validation: $\bar{S_{D}}$=3.7Gy, $\bar{S_{DVH}}$=3.2Gy; test: $\bar{S_{D}}$=3.6Gy, $\bar{S_{DVH}}$=3.0Gy). No significant difference was found among models in terms of Mean [Gy], but the MAE+DVH model significantly outperformed the MAE and MSE models in terms of D0.1cc[Gy], particularly for mandible and parotids on both validation (P&lt;0.01) and test (P&lt;0.0001) datasets. MAE+DVH outperformed (P&lt;0.0001) in terms of D99%, D95%, D1% for targets. MAE+DVH reduced $\bar{S_{D}}$ by ~60% and $\bar{S_{DVH}}$ by ~70%.      
### 82.Robust and efficient change point detection using novel multivariate rank-energy GoF test  [ :arrow_down: ](https://arxiv.org/pdf/2111.00047.pdf)
>  In this paper, we use and further develop upon a recently proposed multivariate, distribution-free Goodness-of-Fit (GoF) test based on the theory of Optimal Transport (OT) called the Rank Energy (RE) [1], for non-parametric and unsupervised Change Point Detection (CPD) in multivariate time series data. We show that directly using RE leads to high sensitivity to very small changes in distributions (causing high false alarms) and it requires large sample complexity and huge computational cost. To alleviate these drawbacks, we propose a new GoF test statistic called as soft-Rank Energy (sRE) that is based on entropy regularized OT and employ it towards CPD. We discuss the advantages of using sRE over RE and demonstrate that the proposed sRE based CPD outperforms all the existing methods in terms of Area Under the Curve (AUC) and F1-score on real and synthetic data sets.      
### 83.Multiple Sclerosis Lesions Identification/Segmentation in Magnetic Resonance Imaging using Ensemble CNN and Uncertainty Classification  [ :arrow_down: ](https://arxiv.org/pdf/2108.11791.pdf)
>  To date, several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging (MRI) have been presented but they are either outperformed by human experts or perform differently from them. This is mainly due to the ambiguity originated by MRI instabilities, peculiar variability of MS and unspecific nature of MRI with respect to MS. Physicians partially manage the uncertainty generated by ambiguity relying on their personal radiological/clinical/anatomical background and experience. We present an automated framework based on three pivotal concepts to better emulate human reasoning: 1. the modelling of uncertainty; 2. the proposal of two, separately trained, CNN, one optimized with respect to lesions themselves and the other to the environment surrounding lesions, respectively repeated for axial, coronal and sagittal directions; 3. the definition of an ensemble classifier to merge the information collected by all CNN. The proposed framework is trained, validated and tested on the 2016 MSSEG benchmark public data set from a single imaging modality, the FLuid-Attenuated Inversion Recovery (FLAIR). The comparison, made with the consensus (the ground-truth) between 7 human raters and with each of the 7 human raters, proves that there is no significant difference between the automated and the human raters. The results of our framework concerning the uncertainty are also reported, even if a comparison with the raters is impossible because they don't recognize this class.      
