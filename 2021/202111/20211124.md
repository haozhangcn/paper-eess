# ArXiv eess --Wed, 24 Nov 2021
### 1.Physics Informed Neural Networks for Control Oriented Thermal Modeling of Buildings  [ :arrow_down: ](https://arxiv.org/pdf/2111.12066.pdf)
>  This paper presents a data-driven modeling approach for developing control-oriented thermal models of buildings. These models are developed with the objective of reducing energy consumption costs while controlling the indoor temperature of the building within required comfort limits. To combine the interpretability of white/gray box physics models and the expressive power of neural networks, we propose a physics informed neural network approach for this modeling task. Along with measured data and building parameters, we encode the neural networks with the underlying physics that governs the thermal behavior of these buildings. Thus, realizing a model that is guided by physics, aids in modeling the temporal evolution of room temperature and power consumption as well as the hidden state, i.e., the temperature of building thermal mass for subsequent time steps. The main research contributions of this work are: (1) we propose two variants of physics informed neural network architectures for the task of control-oriented thermal modeling of buildings, (2) we show that training these architectures is data-efficient, requiring less training data compared to conventional, non-physics informed neural networks, and (3) we show that these architectures achieve more accurate predictions than conventional neural networks for longer prediction horizons. We test the prediction performance of the proposed architectures using simulated and real-word data to demonstrate (2) and (3) and show that the proposed physics informed neural network architectures can be used for this control-oriented modeling problem.      
### 2.Distributed energy control in electric energy systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.12046.pdf)
>  The power interactions of any component in electric energy systems with the rest of the system happen naturally, as governed by the energy conservation principles. However, instabilities may get induced when the dynamics of power produced by local energy conversion and local control do not align with the incoming power dynamics from the rest of the system. To model and control such instabilities, this paper introduces a notion of a common variable shared by components called interaction variable. The same variable captures aggregate system-wide effects and sets reference points for multi-layered distributed output feedback control. It has a physical interpretation of instantaneous power and generalized reactive power. The higher layer design utilizes the interactive energy state-space model to derive intermediate reactive power control, which becomes a control command to the lower layer physical model. This command is implemented using either Feedback Linearizing Control (FBLC) or Sliding Mode Control (SMC), for which sufficient stability conditions are stated. This paper proves that the proposed design is fundamental to aligning dynamic interactions between components for stability and feasibility. Without loss of generality, we utilize a simple RLC circuit with a controllable voltage source for illustrations, which is a simplified representation of any controllable component in microgrids.      
### 3.Model in-cognizant control of residential HVAC units with limited sensing and actuation  [ :arrow_down: ](https://arxiv.org/pdf/2111.12039.pdf)
>  In this paper, we consider the problem of controlling residential heating, ventilation and air conditioning (HVAC) units in response to changes in grid-side electrical power imbalances causing unacceptable frequency. We derive a novel energy-based model that relates the HVAC physics-based dynamics to both real and reactive power balance at the point of interconnection with the grid. Based on this modeling, we propose a composite control comprising of a robust sliding mode controller in tandem with a slower model predictive controller that can achieve near-optimal physical and economic performance. In contrast to several other approaches in the literature, we analyze whether a limited number of HVAC units can meet the stringent performance metrics set by the ARPA-E/NODES program on following the regulation signal, while maintaining consumer comfort. Theoretical and simulation-based evidence is provided to show that the proposed approach to control a single HVAC unit results in a provable response simultaneously satisfying NODES program performance metrics and consumer comfort constraints. The use of this model overcomes fundamental issues concerning limited sensor measurements and model uncertainties.      
### 4.Stability and Sensitivity Analysis of Multi-Vendor, Multi-Terminal HVDC Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.12013.pdf)
>  The stability of multi-vendor, multi-terminal HVDC systems can be analyzed in frequency domain by black-box impedance models using the generalized Nyquist stability criterion. Based on the impedance stability analysis, a multi-level sensitivity analysis approach using frequency-domain sensitivity functions is proposed to identify the root cause of potential instability. Case studies on a four-terminal HVDC system are carried out for stability and sensitivity analysis based on the impedance measurement in PSCAD. The analysis results are finally validated by electromagnetic transient simulations.      
### 5.Reinforcement Learning for Volt-Var Control: A Novel Two-stage Progressive Training Strategy  [ :arrow_down: ](https://arxiv.org/pdf/2111.11987.pdf)
>  This paper develops a reinforcement learning (RL)approach to solve a cooperative, multi-agent Volt-Var Control (VVC) problem for high solar penetration distribution systems. The ingenuity of our RL method lies in a novel two-stage progressive training strategy that can effectively improve training speed and convergence of the machine learning algorithm. In Stage 1(individual training), while holding all the other agents inactive, we separately train each agent to obtain its own optimal VVC actions in the action space: {consume, generate, do-nothing}. In Stage 2 (cooperative training), all agents are trained again coordinatively to share VVC responsibility. Rewards and costs in our RL scheme include (i) a system-level reward (for taking an action), (ii) an agent-level reward (for doing-nothing), and(iii) an agent-level action cost function. This new framework allows rewards to be dynamically allocated to each agent based on their contribution while accounting for the trade-off between control effectiveness and action cost. The proposed methodology is tested and validated in a modified IEEE 123-bus system using realistic PV and load profiles. Simulation results confirm that the proposed approach is robust and computationally efficient; and it achieves desirable volt-var control performance under a wide range of operation conditions.      
### 6.Is Deep Image Prior in Need of a Good Education?  [ :arrow_down: ](https://arxiv.org/pdf/2111.11926.pdf)
>  Deep image prior was recently introduced as an effective prior for image reconstruction. It represents the image to be recovered as the output of a deep convolutional neural network, and learns the network's parameters such that the output fits the corrupted observation. Despite its impressive reconstructive properties, the approach is slow when compared to learned or traditional reconstruction techniques. Our work develops a two-stage learning paradigm to address the computational challenge: (i) we perform a supervised pretraining of the network on a synthetic dataset; (ii) we fine-tune the network's parameters to adapt to the target reconstruction. We showcase that pretraining considerably speeds up the subsequent reconstruction from real-measured micro computed tomography data of biological specimens. The code and additional experimental materials are available at <a class="link-external link-https" href="https://educateddip.github.io/docs.educated_deep_image_prior/" rel="external noopener nofollow">this https URL</a>.      
### 7.Symbol-Based Over-the-Air Digital Predistortion Using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.11923.pdf)
>  We propose an over-the-air digital predistortion optimization algorithm using reinforcement learning. Based on a symbol-based criterion, the algorithm minimizes the errors between downsampled messages at the receiver side. The algorithm does not require any knowledge about the underlying hardware or channel. For a generalized memory polynomial power amplifier and additive white Gaussian noise channel, we show that the proposed algorithm achieves performance improvements in terms of symbol error rate compared with an indirect learning architecture even when the latter is coupled with a full sampling rate ADC in the feedback path. Furthermore, it maintains a satisfactory adjacent channel power ratio.      
### 8.GEVD-based Low-Rank Channel Covariance Matrix Estimation and MMSE Channel Estimation for Uplink Cellular Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.11902.pdf)
>  Uplink channel estimation is a crucial component for the performance of cellular massive MIMO systems. However, when the number of user equipments (UEs) grows, the sharing of the available resources causes interference between UEs in neighboring cells. Minimum mean squared error (MMSE) channel estimators have been proposed to mitigate this interference, but these require estimates of the channel covariance matrices. Therefore, a new channel covariance matrix estimator for low-rank channel covariance matrices is presented in this paper, using a generalized eigenvalue decomposition (GEVD) of two covariance matrices that can be estimated from the available uplink data. The requirements for the systems are minimal and, except for synchronization, there is no need for communication between the different cells and no prior knowledge on the background noise is required. Approximate MMSE estimators are also derived based on the newly proposed channel covariance matrix estimator. The effectiveness of the proposed methods is demonstrated in numerical simulations.      
### 9.Reduced-order observer design for a robotic manipulator  [ :arrow_down: ](https://arxiv.org/pdf/2111.11900.pdf)
>  This paper investigates the design of reduced-order observers for robotic manipulators. Observer stability conditions are obtained based on a Lyapunov analysis and the proposed observer is enhanced with a hybrid scheme that may adjust the gains to cope with possible unbounded velocities of the robot joints. Thanks to such hybrid strategy, the observer works accurately both for robots driven by open-loop controllers and by output feedback controllers. Numerical simulations illustrate the efficacy of the reduced-order observer in several scenarios, including a comparison with the performances of a classical full-order observer.      
### 10.Extending the Unmixing methods to Multispectral Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.11893.pdf)
>  In the past few decades, there has been intensive research concerning the Unmixing of hyperspectral images. Some methods such as NMF, VCA, and N-FINDR have become standards since they show robustness in dealing with the unmixing of hyperspectral images. However, the research concerning the unmixing of multispectral images is relatively scarce. Thus, we extend some unmixing methods to the multispectral images. In this paper, we have created two simulated multispectral datasets from two hyperspectral datasets whose ground truths are given. Then we apply the unmixing methods (VCA, NMF, N-FINDR) to these two datasets. By comparing and analyzing the results, we have been able to demonstrate some interesting results for the utilization of VCA, NMF, and N-FINDR with multispectral datasets. Besides, this also demonstrates the possibilities in extending these unmixing methods to the field of multispectral imaging.      
### 11.Dataset of Spatial Room Impulse Responses in a Variable Acoustics Room for Six Degrees-of-Freedom Rendering and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.11882.pdf)
>  Room acoustics measurements are used in many areas of audio research, from physical acoustics modelling and speech enhancement to virtual reality applications. This paper documents the technical specifications and choices made in the measurement of a dataset of spatial room impulse responses (SRIRs) in a variable acoustics room. Two spherical microphone arrays are used: the mh Acoustics Eigenmike em32 and the Zylia ZM-1, capable of up to fourth- and third-order Ambisonic capture, respectively. The dataset consists of three source and seven receiver positions, repeated with five configurations of the room's acoustics with varying levels of reverberation. Possible applications of the dataset include six degrees-of-freedom (6DoF) analysis and rendering, SRIR interpolation methods, and spatial dereverberation techniques.      
### 12.Functional Model of Residential Consumption Elasticity under Dynamic Tariffs  [ :arrow_down: ](https://arxiv.org/pdf/2111.11875.pdf)
>  One of the major barriers for the retailers is to understand the consumption elasticity they can expect from their contracted demand response (DR) clients. The current trend of DR products provided by retailers are not consumer-specific, which poses additional barriers for the active engagement of consumers in these programs. The elasticity of consumers demand behavior varies from individual to individual. The utility will benefit from knowing more accurately how changes in its prices will modify the consumption pattern of its clients. This work proposes a functional model for the consumption elasticity of the DR contracted consumers. The model aims to determine the load adjustment the DR consumers can provide to the retailers or utilities for different price levels. The proposed model uses a Bayesian probabilistic approach to identify the actual load adjustment an individual contracted client can provide for different price levels it can experience. The developed framework provides the retailers or utilities with a tool to obtain crucial information on how an individual consumer will respond to different price levels. This approach is able to quantify the likelihood with which the consumer reacts to a DR signal and identify the actual load adjustment an individual contracted DR client provides for different price levels they can experience. This information can be used to maximize the control and reliability of the services the retailer or utility can offer to the System Operators.      
### 13.Deformable Image Registration with Deep Network Priors: a Study on Longitudinal PET Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.11873.pdf)
>  Longitudinal image registration is challenging and has not yet benefited from major performance improvements thanks to deep-learning. Inspired by Deep Image Prior, this paper introduces a different use of deep architectures as regularizers to tackle the image registration question. We propose a subject-specific deformable registration method called MIRRBA, relying on a deep pyramidal architecture to be the prior parametric model constraining the deformation field. Diverging from the supervised learning paradigm, MIRRBA does not require a learning database, but only the pair of images to be registered to optimize the network's parameters and provide a deformation field. We demonstrate the regularizing power of deep architectures and present new elements to understand the role of the architecture in deep learning methods for registration. Hence, to study the impact of the network parameters, we ran our method with different architectural configurations on a private dataset of 110 metastatic breast cancer full-body PET images with manual segmentations of the brain, bladder and metastatic lesions. We compared it against conventional iterative registration approaches and supervised deep learning-based models. Global and local registration accuracies were evaluated using the detection rate and the Dice score respectively, while registration realism was evaluated using the Jacobian's determinant. Moreover, we computed the ability of the different methods to shrink vanishing lesions with the disappearing rate. MIRRBA significantly improves the organ and lesion Dice scores of supervised models. Regarding the disappearing rate, MIRRBA more than doubles the best performing conventional approach SyNCC score. Our work therefore proposes an alternative way to bridge the performance gap between conventional and deep learning-based methods and demonstrates the regularizing power of deep architectures.      
### 14.Multi-agent Bayesian Deep Reinforcement Learning for Microgrid Energy Management under Communication Failures  [ :arrow_down: ](https://arxiv.org/pdf/2111.11868.pdf)
>  Microgrids (MGs) are important players for the future transactive energy systems where a number of intelligent Internet of Things (IoT) devices interact for energy management in the smart grid. Although there have been many works on MG energy management, most studies assume a perfect communication environment, where communication failures are not considered. In this paper, we consider the MG as a multi-agent environment with IoT devices in which AI agents exchange information with their peers for collaboration. However, the collaboration information may be lost due to communication failures or packet loss. Such events may affect the operation of the whole MG. To this end, we propose a multi-agent Bayesian deep reinforcement learning (BA-DRL) method for MG energy management under communication failures. We first define a multi-agent partially observable Markov decision process (MA-POMDP) to describe agents under communication failures, in which each agent can update its beliefs on the actions of its peers. Then, we apply a double deep Q-learning (DDQN) architecture for Q-value estimation in BA-DRL, and propose a belief-based correlated equilibrium for the joint-action selection of multi-agent BA-DRL. Finally, the simulation results show that BA-DRL is robust to both power supply uncertainty and communication failure uncertainty. BA-DRL has 4.1% and 10.3% higher reward than Nash Deep Q-learning (Nash-DQN) and alternating direction method of multipliers (ADMM) respectively under 1% communication failure probability.      
### 15.Cost Optimization of Water Distribution Networks: Model Refinement Is Better Than Problem-Specific Solving Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2111.11865.pdf)
>  Existing techniques for the cost optimization of water distribution networks either employ meta-heuristics, or try to develop problem-specific optimization techniques. Instead, we exploit recent advances in generic NLP solvers and explore a rich set of model refinement techniques. The networks that we study contain a single source and multiple demand nodes with residual pressure constraints. Indeterminism of flow values and flow direction in the network leads to non-linearity in these constraints making the optimization problem non-convex. While the physical network is cyclic, flow through the network is necessarily acyclic and thus enforces an acyclic orientation. We devise different strategies of finding acyclic orientations and explore the benefit of enforcing such orientations explicitly as a constraint. Finally, we propose a parallel link formulation that models flow in each link as two separate flows with opposing directions. This allows us to tackle numerical difficulties in optimization when flow in a link is near zero. We find that all our proposed formulations give results at par with least cost solutions obtained in the literature on benchmark networks. We also introduce a suite of large test networks since existing benchmark networks are small in size, and find that the parallel link approach outperforms all other approaches on these bigger networks, resulting in a more tractable technique of cost optimization.      
### 16.Flight Control System Design for Autonomous Aerial Surveys of Volcanoes  [ :arrow_down: ](https://arxiv.org/pdf/2111.11861.pdf)
>  The controller for a quadrotor working in severe environment is developed in this study. Here, the severe environment indicates the temperature-varying air near the volcano. The controller overcomes the intensively changing temperature above the crater of the volcano which biases the nominal dynamics (25 Celcius). The target Volcano is picked as Satsuma-iojima located in a tiny insular South to the mainland of Japan. The temperature distribution is contributed from previous research by Geological Survey of Japan. To guarantee that the control signal is under the input saturation, a path planning method is developed. Picking the eigenvalue for a system with a moving reference is a novel topic; the method to develop a controller with specific requirement is created for the first time. This method might be referred as a standard way for designers/engineers in developing controller with a moving target/reference in further study. In controlling part, a state feedback controller is designed to stabilize the height of the quadrotor. The eigenvalue of the feedback controller is picked based on the method developed in Chapter Path Planning. And a PID controller is designed to control the attitude. The result of these are verified in a simulator written in MATLAB. At last, a Kalman filter is applied in height control to combine the measurement noise from IMU and laser scanner and the system noise caused by the changing temperature. Another reason for developing a Kalman filter is that IMU readout provides with acceleration. While the velocity is not achieved by sensor directly. The result of height control with a Kalman filter is verified in MATLAB Simulink.      
### 17.SpeechMoE2: Mixture-of-Experts Model with Improved Routing  [ :arrow_down: ](https://arxiv.org/pdf/2111.11831.pdf)
>  Mixture-of-experts based acoustic models with dynamic routing mechanisms have proved promising results for speech recognition. The design principle of router architecture is important for the large model capacity and high computational efficiency. Our previous work SpeechMoE only uses local grapheme embedding to help routers to make route decisions. To further improve speech recognition performance against varying domains and accents, we propose a new router architecture which integrates additional global domain and accent embedding into router input to promote adaptability. Experimental results show that the proposed SpeechMoE2 can achieve lower character error rate (CER) with comparable parameters than SpeechMoE on both multi-domain and multi-accent task. Primarily, the proposed method provides up to 1.6% - 4.8% relative CER improvement for the multidomain task and 1.9% - 17.7% relative CER improvement for the multi-accent task respectively. Besides, increasing the number of experts also achieves consistent performance improvement and keeps the computational cost constant.      
### 18.Techno-economic analysis of Power-to-Gas plants in a gas and electricity distribution network system with high renewable energy penetration  [ :arrow_down: ](https://arxiv.org/pdf/2111.11790.pdf)
>  Distributed generation, based on the exploitation of Renewable Energy Sources (RES), has increased in the last few decades to limit anthropogenic carbon dioxide emissions, and this trend will increase in the future. However, RES generation is not dispatchable, and an increasing share of RES may lead to inefficiencies and even problems for the electricity network. Flexible resources are needed to handle RES generation in order to support the delicate electricity generation and demand balance. Energy conversion technologies (P2X, Power to X) allow the flexibility of energy systems to be increased. These technologies make a connection between different energy sectors (e.g., electricity and gas) possible, and thus create new synergies within an overall multi energy system. This paper analyzes how the P2G technology can be used at the distribution network level (both gas and electricity) to optimize the use of RES. In fact, in order to coordinate P2X resources, it is necessary to take into account the whole multi energy scenario, and not just the electrical side: it therefore becomes fundamental to recognize the pros and cons that Balancing Service Providers (BSPs), composed of a number of P2G plants (representing the Balancing Responsible Providers, BRPs), may have when offering services to an electricity network. Moreover, the convenience of the decarbonization of the gas grid has been evaluated through the calculation of the levelized cost of Synthetic Natural Gas (LCSNG) for cost scenarios for the years 2030 and 2050, considering different assumptions about the cost of the surplus utilization of RES. The results show that LCSNG may vary from 47 to 319 EURO/MWh, according to the different configurations, i.e., only in the best case scenario is the SNG cost comparable with the cost of natural gas, and hence does the P2G technology result to be profitable      
### 19.Robust Time-Varying Parameters Estimation Based on I-DREM Procedure  [ :arrow_down: ](https://arxiv.org/pdf/2111.11716.pdf)
>  We consider a class of systems with time-varying parameters, which are written as linear regressions with bounded disturbances. The task is to estimate such parameters under the condition that the regressor is finitely exciting (FE). Considering such a problem statement, a new robust method is proposed to identify the time-varying parameters with bounded error, which could be reduced to the limit by the adjustment of such method parameters. For this purpose, the function of the system unknown parameters, which depends on time, is expanded into a Taylor series in order to turn the considered problem into the identification of the regression with piecewise-constant parameters. This results in the increase of the dimensionality of the problem to be solved. Then, the I-DREM procedure with exponential forgetting, resetting, and normalization of the regressor, which has been proposed earlier by the authors, is applied to the obtained regression. This allows one, in contrast to the known solutions, to get the dimensionality of the problem back to the initial one and provide the required exponential convergence of the parameter error to a bounded set with adjustable bound under the condition that the regressor is FE. In addition, this method guarantees that the parameter error is bounded beyond the regressor excitation interval. The above properties are proved analytically and shown via numerical simulations.      
### 20.IF equation: a feature extractor for high-concentration time-frequency representation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11689.pdf)
>  High-concentration time-frequency (TF) representation provides a valuable tool for characterizing multi-component non-stationary signals. In our previous work, we proposed using an instantaneous frequency (IF) equation to sharpen the TF distribution and its effectiveness has been verified in experiments. In this paper, we systematically discuss why the IF equation-based TF analysis methods work and how to use the IF equation to improve the TF sharpness. By theory analysis, many popular TF post-processing methods, such as the synchroextracting transform, the multi-synchrosqueezing transform, and the time extracting transform, fall into the IF equation-based category. A comparison of the IF equation-based method with the popular synchrosqueezing transform is made. Numerical examples of the theoretical derivations are presented to illustrate the performance of the proposed IF equation-based TF analysis method.      
### 21.An Optimal Weighting Function for the Savitzky-Golay Filter  [ :arrow_down: ](https://arxiv.org/pdf/2111.11667.pdf)
>  The Savitzky-Golay FIR digital filter is based on a least-squares polynomial fit to a hypothetical sample of equally spaced data. This gives the filter the ability to preserve moments of features like peaks in the input. Descriptions of the filter typically consider the case where equal weights are implicitly applied to the residuals of the fit. In a largely overlooked paper Turton showed that weighting the residuals with a triangular function significantly improves the frequency response of the filter in the stopband. The Savitzky-Golay filter is commonly referred to as a smoothing filter. This paper uses a particular measure of smoothness to show that a quadratic residual weighting function optimizes the smoothness of the filter output for a given sample size and degree of the fitting polynomial. This weighting function can provide substantially better smoothness than that with a constant weighting function.      
### 22.RadFusion: Benchmarking Performance and Fairness for Multimodal Pulmonary Embolism Detection from CT and EHR  [ :arrow_down: ](https://arxiv.org/pdf/2111.11665.pdf)
>  Despite the routine use of electronic health record (EHR) data by radiologists to contextualize clinical history and inform image interpretation, the majority of deep learning architectures for medical imaging are unimodal, i.e., they only learn features from pixel-level information. Recent research revealing how race can be recovered from pixel data alone highlights the potential for serious biases in models which fail to account for demographics and other key patient attributes. Yet the lack of imaging datasets which capture clinical context, inclusive of demographics and longitudinal medical history, has left multimodal medical imaging underexplored. To better assess these challenges, we present RadFusion, a multimodal, benchmark dataset of 1794 patients with corresponding EHR data and high-resolution computed tomography (CT) scans labeled for pulmonary embolism. We evaluate several representative multimodal fusion models and benchmark their fairness properties across protected subgroups, e.g., gender, race/ethnicity, age. Our results suggest that integrating imaging and EHR data can improve classification performance and robustness without introducing large disparities in the true positive rate between population groups.      
### 23.The RETA Benchmark for Retinal Vascular Tree Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.11658.pdf)
>  Topological and geometrical analysis of retinal blood vessel is a cost-effective way for early detection of many common diseases. Meanwhile, automated vessel segmentation and vascular tree analysis are still lacking in terms of generalization capability. In this work, we construct a novel benchmark RETA with 81 labeled vessel masks aiming to facilitate retinal vessel analysis. A semi-automated coarse-to-fine workflow is proposed to annotating vessel pixels. During dataset construction, we strived to control inter-annotator variability and intra-annotator variability by performing multi-stage annotation and label disambiguation on self-developed dedicated software. In addition to binary vessel masks, we obtained vessel annotations containing artery/vein masks, vascular skeletons, bifurcations, trees and abnormalities during vessel labelling. Both subjective and objective quality validation of labeled vessel masks have demonstrated significant improved quality over other publicly datasets. The annotation software is also made publicly available for vessel annotation visualization. Users could develop vessel segmentation algorithms or evaluate vessel segmentation performance with our dataset. Moreover, our dataset might be a good research source for cross-modality tubular structure segmentation.      
### 24.Effect of noise suppression losses on speech distortion and ASR performance  [ :arrow_down: ](https://arxiv.org/pdf/2111.11606.pdf)
>  Deep learning based speech enhancement has made rapid development towards improving quality, while models are becoming more compact and usable for real-time on-the-edge inference. However, the speech quality scales directly with the model size, and small models are often still unable to achieve sufficient quality. Furthermore, the introduced speech distortion and artifacts greatly harm speech quality and intelligibility, and often significantly degrade automatic speech recognition (ASR) rates. In this work, we shed light on the success of the spectral complex compressed mean squared error (MSE) loss, and how its magnitude and phase-aware terms are related to the speech distortion vs. noise reduction trade off. We further investigate integrating pre-trained reference-less predictors for mean opinion score (MOS) and word error rate (WER), and pre-trained embeddings on ASR and sound event detection. Our analyses reveal that none of the pre-trained networks added significant performance over the strong spectral loss.      
### 25.Unsupervised COVID-19 Lesion Segmentation in CT Using Cycle Consistent Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2111.11602.pdf)
>  COVID-19 has become a global pandemic and is still posing a severe health risk to the public. Accurate and efficient segmentation of pneumonia lesions in CT scans is vital for treatment decision-making. We proposed a novel unsupervised approach using cycle consistent generative adversarial network (cycle-GAN) which automates and accelerates the process of lesion delineation. The workflow includes lung volume segmentation, "synthetic" healthy lung generation, infected and healthy image subtraction, and binary lesion mask creation. The lung volume volume was firstly delineated using a pre-trained U-net and worked as the input for the later network. The cycle-GAN was developed to generate synthetic "healthy" lung CT images from infected lung images. After that, the pneumonia lesions are extracted by subtracting the synthetic "healthy" lung CT images from the "infected" lung CT images. A median filter and K-means clustering were then applied to contour the lesions. The auto segmentation approach was validated on two public datasets (Coronacases and Radiopedia). The Dice coefficients reached 0.748 and 0.730, respectively, for the Coronacases and Radiopedia datasets. Meanwhile, the precision and sensitivity for lesion segmentationdetection are 0.813 and 0.735 for the Coronacases dataset, and 0.773 and 0.726 for the Radiopedia dataset. The performance is comparable to existing supervised segmentation networks and outperforms previous unsupervised ones. The proposed unsupervised segmentation method achieved high accuracy and efficiency in automatic COVID-19 lesion delineation. The segmentation result can serve as a baseline for further manual modification and a quality assurance tool for lesion diagnosis. Furthermore, due to its unsupervised nature, the result is not influenced by physicians' experience which otherwise is crucial for supervised methods.      
### 26.Strategic Competition of Electric Vehicle Charging Stations in a Regulated Retail Electricity Market  [ :arrow_down: ](https://arxiv.org/pdf/2111.11592.pdf)
>  The increasing trend of transportation electrification presents investors the opportunity to provide charging services to Electric Vehicle (EV) owners via the energy purchased from the wholesale electricity market. This will benefit EV owners with the availability of competitive rates compared to the regulated utility time-of-use (TOU) rates. The fundamental questions addressed in this paper are 1) will EV owners benefit from the additional choice of Electric Vehicle Charging Stations (EVCSs) compared to home charging? 2) is there any profitable market opportunity for charging stations while the retail electricity market is regulated? To this end, the strategic bidding problem for EVCSs which purchase electricity from the Day-Ahead Electricity Market (DAM) and sell it to EV owners is presented. The strategic bidding problem is constrained by the market-clearing problem within the DAM as well as EVs' charging cost minimization problem. A bi-level optimization problem formulation and a solution method are presented to address this work's research questions. The effectiveness of the proposed structure in gaining profit for EVCSs is illustrated, and it is shown that EV owners also save on their charging cost with the presence of EVCSs as a choice.      
### 27.Universal Swarm Computing by Nanorobots  [ :arrow_down: ](https://arxiv.org/pdf/2111.11503.pdf)
>  Realization of universal computing units for nanorobots is highly promising in creating new and wide arrays of applications, particularly in the realm of distributed computation. However, such realization is also a challenging problem due to the physical limitations of nanometer-sized designs such as in computation, sensory and perception as well as actuation. This paper proposes a theoretical foundation for solving this problem based on a novel notion of distributed swarm computing by basis agents (BAs). The proposed BA is an abstract model for nanorobots that can compute a very simple basis function called B-function. It is mathematically shown here that a swarm of BAs has the universal function approximation property and can accurately approximate functions. It is then analytically demonstrated that a swarm of BAs can be easily reprogrammed to compute desired functions simply by adjusting the concentrations of BAs in the environment. We further propose a specific structure for BAs which enable them to perform distributed computing such as in the aqueous environment of living tissues and nanomedicine. The hardware complexity of this structure aims to remain low to be more reasonably realizable by today technology. Finally, the performance of the proposed approach is illustrated by a simulation example.      
### 28.Robust Control of Nanoscale Drug Delivery System in Atherosclerosis: A Mathematical Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.11499.pdf)
>  This paper proposes a mathematical approach for robust control of a nanoscale drug delivery system in treatment of atherosclerosis. First, a new nonlinear lumped model is introduced for mass transport in the arterial wall, and its accuracy is evaluated in comparison with the original distributed-parameter model. Then, based on the notion of sliding-mode control, an abstract model is designed for a smart drug delivery nanoparticle. In contrast to the competing strategies on nanorobotics, the proposed nanoparticles carry simpler hardware to penetrate the interior arterial wall and become more technologically feasible. Finally, from this lumped model and the nonlinear control theory, the overall system's stability is mathematically proven in the presence of uncertainty. Simulation results on a well-known model, and comparisons with earlier benchmark approaches, reveals that even when the LDL concentration in the lumen is high, the proposed nanoscale drug delivery system successfully reduces the drug consumption levels by as much as 16% and the LDL level in the Endothelium, Intima, Internal Elastic Layer (IEL) and Media layers of an unhealthy arterial wall by as much as 14.6%, 50.5%, 51.8%, and 64.4%, respectively.      
### 29.Drone flight data reveal energy and greenhouse gas emissions savings for small package delivery  [ :arrow_down: ](https://arxiv.org/pdf/2111.11463.pdf)
>  The adoption of Uncrewed Aerial Vehicles (UAVs) for last-mile deliveries will affect the energy productivity of package delivery and require new methods to understand the associated energy consumption and greenhouse gas (GHG) emissions. Here we combine empirical testing of 187 quadcopter flights with first principles analysis to develop a usable energy model for drone package delivery. We develop a machine-learning algorithm to assess energy use across three different flight regimes: takeoff, cruise, and landing. Our model shows that, in the US, a small electric quadcopter drone with a payload of 1 kg would consume approximately 0.05 MJ/km and result in 41 g of CO$_{2}$e per package. The energy per package delivered by drones (0.19 MJ/package) can be up to 96\% lower than conventional transportation modes. Our open model and generalizable coefficients can assist stakeholders in understanding and improving the energy use of drone package delivery.      
### 30.Predicting Osteoarthritis Progression in Radiographs via Unsupervised Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.11439.pdf)
>  Osteoarthritis (OA) is the most common joint disorder affecting substantial proportions of the global population, primarily the elderly. Despite its individual and socioeconomic burden, the onset and progression of OA can still not be reliably predicted. Aiming to fill this diagnostic gap, we introduce an unsupervised learning scheme based on generative models to predict the future development of OA based on knee joint radiographs. Using longitudinal data from osteoarthritis studies, we explore the latent temporal trajectory to predict a patient's future radiographs up to the eight-year follow-up visit. Our model predicts the risk of progression towards OA and surpasses its supervised counterpart whose input was provided by seven experienced radiologists. With the support of the model, sensitivity, specificity, positive predictive value, and negative predictive value increased significantly from 42.1% to 51.6%, from 72.3% to 88.6%, from 28.4% to 57.6%, and from 83.9% to 88.4%, respectively, while without such support, radiologists performed only slightly better than random guessing. Our predictive model improves predictions on OA onset and progression, despite requiring no human annotation in the training phase.      
### 31.Semantic-Aware Collaborative Deep Reinforcement Learning Over Wireless Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.12064.pdf)
>  Collaborative deep reinforcement learning (CDRL) algorithms in which multiple agents can coordinate over a wireless network is a promising approach to enable future intelligent and autonomous systems that rely on real-time decision-making in complex dynamic environments. Nonetheless, in practical scenarios, CDRL faces many challenges due to the heterogeneity of agents and their learning tasks, different environments, time constraints of the learning, and resource limitations of wireless networks. To address these challenges, in this paper, a novel semantic-aware CDRL method is proposed to enable a group of heterogeneous untrained agents with semantically-linked DRL tasks to collaborate efficiently across a resource-constrained wireless cellular network. To this end, a new heterogeneous federated DRL (HFDRL) algorithm is proposed to select the best subset of semantically relevant DRL agents for collaboration. The proposed approach then jointly optimizes the training loss and wireless bandwidth allocation for the cooperating selected agents in order to train each agent within the time limit of its real-time task. Simulation results show the superior performance of the proposed algorithm compared to state-of-the-art baselines.      
### 32.Forget-SVGD: Particle-Based Bayesian Federated Unlearning  [ :arrow_down: ](https://arxiv.org/pdf/2111.12056.pdf)
>  Variational particle-based Bayesian learning methods have the advantage of not being limited by the bias affecting more conventional parametric techniques. This paper proposes to leverage the flexibility of non-parametric Bayesian approximate inference to develop a novel Bayesian federated unlearning method, referred to as Forget-Stein Variational Gradient Descent (Forget-SVGD). Forget-SVGD builds on SVGD - a particle-based approximate Bayesian inference scheme using gradient-based deterministic updates - and on its distributed (federated) extension known as Distributed SVGD (DSVGD). Upon the completion of federated learning, as one or more participating agents request for their data to be "forgotten", Forget-SVGD carries out local SVGD updates at the agents whose data need to be "unlearned", which are interleaved with communication rounds with a parameter server. The proposed method is validated via performance comparisons with non-parametric schemes that train from scratch by excluding data to be forgotten, as well as with existing parametric Bayesian unlearning methods.      
### 33.Romanian Speech Recognition Experiments from the ROBIN Project  [ :arrow_down: ](https://arxiv.org/pdf/2111.12028.pdf)
>  One of the fundamental functionalities for accepting a socially assistive robot is its communication capabilities with other agents in the environment. In the context of the ROBIN project, situational dialogue through voice interaction with a robot was investigated. This paper presents different speech recognition experiments with deep neural networks focusing on producing fast (under 100ms latency from the network itself), while still reliable models. Even though one of the key desired characteristics is low latency, the final deep neural network model achieves state of the art results for recognizing Romanian language, obtaining a 9.91% word error rate (WER), when combined with a language model, thus improving over the previous results while offering at the same time an improved runtime performance. Additionally, we explore two modules for correcting the ASR output (hyphen and capitalization restoration and unknown words correction), targeting the ROBIN project's goals (dialogue in closed micro-worlds). We design a modular architecture based on APIs allowing an integration engine (either in the robot or external) to chain together the available modules as needed. Finally, we test the proposed design by integrating it in the RELATE platform and making the ASR service available to web users by either uploading a file or recording new speech.      
### 34.Scalable Learning for Optimal Load Shedding Under Power Grid Emergency Operations  [ :arrow_down: ](https://arxiv.org/pdf/2111.11980.pdf)
>  Effective and timely responses to unexpected contingencies are crucial for enhancing the resilience of power grids. Given the fast, complex process of cascading propagation, corrective actions such as optimal load shedding (OLS) are difficult to attain in large-scale networks due to the computation complexity and communication latency issues. This work puts forth an innovative learning-for-OLS approach by constructing the optimal decision rules of load shedding under a variety of potential contingency scenarios through offline neural network (NN) training. Notably, the proposed NN-based OLS decisions are fully decentralized, enabling individual load centers to quickly react to the specific contingency using readily available local measurements. Numerical studies on the IEEE 14-bus system have demonstrated the effectiveness of our scalable OLS design for real-time responses to severe grid emergency events.      
### 35.Application of Gaussian Processes to online approximation of compressor maps for load-sharing in a compressor station  [ :arrow_down: ](https://arxiv.org/pdf/2111.11890.pdf)
>  Devising optimal operating strategies for a compressor station relies on the knowledge of compressor characteristics. As the compressor characteristics change with time and use, it is necessary to provide accurate models of the characteristics that can be used in optimization of the operating strategy. This paper proposes a new algorithm for online learning of the characteristics of the compressors using Gaussian Processes. The performance of the new approximation is shown in a case study with three compressors. The case study shows that Gaussian Processes accurately capture the characteristics of compressors even if no knowledge about the characteristics is initially available. The results show that the flexible nature of Gaussian Processes allows them to adapt to the data online making them amenable for use in real-time optimization problems.      
### 36.Longitudinal Speech Biomarkers for Automated Alzheimer's Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.11859.pdf)
>  We introduce a novel audio processing architecture, the Open Voice Brain Model (OVBM), improving detection accuracy for Alzheimer's (AD) longitudinal discrimination from spontaneous speech. We also outline the OVBM design methodology leading us to such architecture, which in general can incorporate multimodal biomarkers and target simultaneously several diseases and other AI tasks. Key in our methodology is the use of multiple biomarkers complementing each other, and when two of them uniquely identify different subjects in a target disease we say they are orthogonal. We illustrate the methodology by introducing 16 biomarkers, three of which are orthogonal, demonstrating simultaneous above state-of-the-art discrimination for apparently unrelated diseases such as AD and COVID-19. Inspired by research conducted at the MIT Center for Brain Minds and Machines, OVBM combines biomarker implementations of the four modules of intelligence: The brain OS chunks and overlaps audio samples and aggregates biomarker features from the sensory stream and cognitive core creating a multi-modal graph neural network of symbolic compositional models for the target task. We apply it to AD, achieving above state-of-the-art accuracy of 93.8% on raw audio, while extracting a subject saliency map that longitudinally tracks relative disease progression using multiple biomarkers, 16 in the reported AD task. The ultimate aim is to help medical practice by detecting onset and treatment impact so that intervention options can be longitudinally tested. Using the OBVM design methodology, we introduce a novel lung and respiratory tract biomarker created using 200,000+ cough samples to pre-train a model discriminating cough cultural origin. This cough dataset sets a new benchmark as the largest audio health dataset with 30,000+ subjects participating in April 2020, demonstrating for the first-time cough cultural bias.      
### 37.U-shape Transformer for Underwater Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2111.11843.pdf)
>  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image enhancement (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted enhancement. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.      
### 38.Reliable Deep Learning based Localization with CSI Fingerprints and Multiple Base Stations  [ :arrow_down: ](https://arxiv.org/pdf/2111.11839.pdf)
>  Deep learning (DL) methods have been recently proposed for user equipment (UE) localization in wireless communication networks, based on the channel state information (CSI) between a UE and each base station (BS) in the uplink. With the CSI from the available BSs, UE localization can be performed in different ways. One the one hand, a single neural network (NN) can be trained for the UE localization by considering the CSI from all the available BSs as one overall fingerprint of the user's location. On the other hand, the CSI at each BS can be used to obtain an estimate of the UE's position with a separate NN at each BS, and then the position estimates of all BSs are combined to obtain an overall estimate of the UE position. In this work, we show that UE localization with the latter approach can achieve a higher positioning accuracy. We propose to consider the uncertainty in the UE localization at each BS, such that overall UE's position is determined by combining the position estimates of the different BSs based on the uncertainty at each BS. With this approach, a more reliable position estimate can be obtained in case of variations in the channel.      
### 39.RIS-Assisted Receive Quadrature Space-Shift Keying: A New Paradigm and Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.11813.pdf)
>  Reconfigurable intelligent surfaces (RISs) represent a promising candidate for sixth-generation (6G) wireless networks, as the RIS technology provides a new solution to control the propagation channel in order to improve the efficiency of a wireless link through enhancing the received signal power. In this paper, we propose RIS-assisted receive quadrature space-shift keying (RIS-RQSSK), which enhances the spectral efficiency of an RIS-based index modulation (IM) system by using the real and imaginary dimensions independently for the purpose of IM. Therefore, the error rate performance of the system is improved as all RIS elements reflect the incident transmit signal toward both selected receive antennas. At the receiver, a low-complexity but effective greedy detector (GD) can be employed which determines the maximum energy per dimension at the receive antennas. A max-min optimization problem is defined to maximize the received signal-to-noise ratio (SNR) components at both selected receive antennas; an analytical solution is provided based on Lagrange duality. In particular, the multi-variable optimization problem is shown to reduce to the solution of a single-variable equation, which results in a very simple design procedure. In addition, we investigate the average bit error probability (ABEP) of the proposed RIS-RQSSK system and derive a closed-form approximate upper bound on the ABEP. We also provide extensive numerical simulations to validate our derivations. Numerical results show that the proposed RIS-RQSSK scheme substantially outperforms recent prominent benchmark schemes. This enhancement considerably increases with an increasing number of receive antennas.      
### 40.Introduction to Presentation Attack Detection in Face Biometrics and Recent Advances  [ :arrow_down: ](https://arxiv.org/pdf/2111.11794.pdf)
>  The main scope of this chapter is to serve as an introduction to face presentation attack detection, including key resources and advances in the field in the last few years. The next pages present the different presentation attacks that a face recognition system can confront, in which an attacker presents to the sensor, mainly a camera, a Presentation Attack Instrument (PAI), that is generally a photograph, a video, or a mask, to try to impersonate a genuine user. First, we make an introduction of the current status of face recognition, its level of deployment, and its challenges. In addition, we present the vulnerabilities and the possible attacks that a face recognition system may be exposed to, showing that way the high importance of presentation attack detection methods. We review different types of presentation attack methods, from simpler to more complex ones, and in which cases they could be effective. Then, we summarize the most popular presentation attack detection methods to deal with these attacks. Finally, we introduce public datasets used by the research community for exploring vulnerabilities of face biometrics to presentation attacks and developing effective countermeasures against known PAIs.      
### 41.End-to-End Optimized Arrhythmia Detection Pipeline using Machine Learning for Ultra-Edge Devices  [ :arrow_down: ](https://arxiv.org/pdf/2111.11789.pdf)
>  Atrial fibrillation (AF) is the most prevalent cardiac arrhythmia worldwide, with 2% of the population affected. It is associated with an increased risk of strokes, heart failure and other heart-related complications. Monitoring at-risk individuals and detecting asymptomatic AF could result in considerable public health benefits, as individuals with asymptomatic AF could take preventive measures with lifestyle changes. With increasing affordability to wearables, personalized health care is becoming more accessible. These personalized healthcare solutions require accurate classification of bio-signals while being computationally inexpensive. By making inferences on-device, we avoid issues inherent to cloud-based systems such as latency and network connection dependency. We propose an efficient pipeline for real-time Atrial Fibrillation Detection with high accuracy that can be deployed in ultra-edge devices. The feature engineering employed in this research catered to optimizing the resource-efficient classifier used in the proposed pipeline, which was able to outperform the best performing standard ML model by $10^5\times$ in terms of memory footprint with a mere trade-off of 2% classification accuracy. We also obtain higher accuracy of approximately 6% while consuming 403$\times$ lesser memory and being 5.2$\times$ faster compared to the previous state-of-the-art (SoA) embedded implementation.      
### 42.Upsampling layers for music source separation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11773.pdf)
>  Upsampling artifacts are caused by problematic upsampling layers and due to spectral replicas that emerge while upsampling. Also, depending on the used upsampling layer, such artifacts can either be tonal artifacts (additive high-frequency noise) or filtering artifacts (substractive, attenuating some bands). In this work we investigate the practical implications of having upsampling artifacts in the resulting audio, by studying how different artifacts interact and assessing their impact on the models' performance. To that end, we benchmark a large set of upsampling layers for music source separation: different transposed and subpixel convolution setups, different interpolation upsamplers (including two novel layers based on stretch and sinc interpolation), and different wavelet-based upsamplers (including a novel learnable wavelet layer). Our results show that filtering artifacts, associated with interpolation upsamplers, are perceptually preferrable, even if they tend to achieve worse objective scores.      
### 43.Guided-TTS:Text-to-Speech with Untranscribed Speech  [ :arrow_down: ](https://arxiv.org/pdf/2111.11755.pdf)
>  Most neural text-to-speech (TTS) models require &lt;speech, transcript&gt; paired data from the desired speaker for high-quality speech synthesis, which limits the usage of large amounts of untranscribed data for training. In this work, we present Guided-TTS, a high-quality TTS model that learns to generate speech from untranscribed speech data. Guided-TTS combines an unconditional diffusion probabilistic model with a separately trained phoneme classifier for text-to-speech. By modeling the unconditional distribution for speech, our model can utilize the untranscribed data for training. For text-to-speech synthesis, we guide the generative process of the unconditional DDPM via phoneme classification to produce mel-spectrograms from the conditional distribution given transcript. We show that Guided-TTS achieves comparable performance with the existing methods without any transcript for LJSpeech. Our results further show that a single speaker-dependent phoneme classifier trained on multispeaker large-scale data can guide unconditional DDPMs for various speakers to perform TTS.      
### 44.ADTOF: A large dataset of non-synthetic music for automatic drum transcription  [ :arrow_down: ](https://arxiv.org/pdf/2111.11737.pdf)
>  The state-of-the-art methods for drum transcription in the presence of melodic instruments (DTM) are machine learning models trained in a supervised manner, which means that they rely on labeled datasets. The problem is that the available public datasets are limited either in size or in realism, and are thus suboptimal for training purposes. Indeed, the best results are currently obtained via a rather convoluted multi-step training process that involves both real and synthetic datasets. To address this issue, starting from the observation that the communities of rhythm games players provide a large amount of annotated data, we curated a new dataset of crowdsourced drum transcriptions. This dataset contains real-world music, is manually annotated, and is about two orders of magnitude larger than any other non-synthetic dataset, making it a prime candidate for training purposes. However, due to crowdsourcing, the initial annotations contain mistakes. We discuss how the quality of the dataset can be improved by automatically correcting different types of mistakes. When used to train a popular DTM model, the dataset yields a performance that matches that of the state-of-the-art for DTM, thus demonstrating the quality of the annotations.      
### 45.IR Motion Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2111.11734.pdf)
>  Camera gimbal systems are important in various air or water borne systems for applications such as navigation, target tracking, security and surveillance. A higher steering rate (rotation angle per second) of gimbal is preferable for real-time applications since a given field-of-view (FOV) can be revisited within a short period of time. However, due to relative motion between the gimbal and scene during the exposure time, the captured video frames can suffer from motion blur. Since most of the post-capture applications require blurfree images, motion deblurring in real-time is an important need. Even though there exist blind deblurring methods which aim to retrieve latent images from blurry inputs, they are constrained by very high-dimensional optimization thus incurring large execution times. On the other hand, deep learning methods for motion deblurring, though fast, do not generalize satisfactorily to different domains (e.g., air, water, etc). In this work, we address the problem of real-time motion deblurring in infrared (IR) images captured by a gimbal-based system. We reveal how a priori knowledge of the blur-kernel can be used in conjunction with non-blind deblurring methods to achieve real-time performance. Importantly, our mathematical model can be leveraged to create large-scale datasets with realistic gimbal motion blur. Such datasets which are a rarity can be a valuable asset for contemporary deep learning methods. We show that, in comparison to the state-of-the-art techniques in deblurring, our method is better suited for practical gimbal-based imaging systems.      
### 46.A Contextual Latent Space Model: Subsequence Modulation in Melodic Sequence  [ :arrow_down: ](https://arxiv.org/pdf/2111.11703.pdf)
>  Some generative models for sequences such as music and text allow us to edit only subsequences, given surrounding context sequences, which plays an important part in steering generation interactively. However, editing subsequences mainly involves randomly resampling subsequences from a possible generation space. We propose a contextual latent space model (CLSM) in order for users to be able to explore subsequence generation with a sense of direction in the generation space, e.g., interpolation, as well as exploring variations -- semantically similar possible subsequences. A context-informed prior and decoder constitute the generative model of CLSM, and a context position-informed encoder is the inference model. In experiments, we use a monophonic symbolic music dataset, demonstrating that our contextual latent space is smoother in interpolation than baselines, and the quality of generated samples is superior to baseline models. The generation examples are available online.      
### 47.Optimum Noise Mechanism for Differentially Private Queries in Discrete Finite Sets  [ :arrow_down: ](https://arxiv.org/pdf/2111.11661.pdf)
>  In this paper, we provide an optimal additive noise mechanism for database queries with discrete answers on a finite support. The noise provides the minimum error rate for a given $(\epsilon,\delta)$ pair. Popular schemes apply random additive noise with infinite support and then clamp the resulting query response to the desired range. Clamping, unfortunately, compromises the privacy guarantees. Using modulo addition, rather than clamping, we show that, for any $(\epsilon,\delta)$ pair, the optimum additive noise distribution can be obtained by solving a mixed integer linear program (MILP). Having introduced our optimal noise design formulation, we derive closed form solutions for the optimal noise probability mass function (PMF) and the probability of error for two special cases. In our performance studies, we show that the proposed optimal mechanism outperforms state of the art for a given probability of error and for any budget $\epsilon &gt;0$.      
### 48.Aerial Intelligent Reflecting Surface Enabled Terahertz Covert Communications in Beyond-5G Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2111.11650.pdf)
>  Unmanned aerial vehicles (UAVs) are envisioned to be extensively employed for assisting wireless communications in Internet of Things (IoT) applications. On the other hand, terahertz (THz) enabled intelligent reflecting surface (IRS) is expected to be one of the core enabling technologies for forthcoming beyond-5G wireless communications that promise a broad range of data-demand applications. In this paper, we propose a UAV-mounted IRS (UIRS) communication system over THz bands for confidential data dissemination from an access point (AP) towards multiple ground user equipments (UEs) in IoT networks. Specifically, the AP intends to send data to the scheduled UE, while unscheduled UEs may pose potential adversaries. To protect information messages and the privacy of the scheduled UE, we aim to devise an energy-efficient multi-UAV covert communication scheme, where the UIRS is for reliable data transmissions, and an extra UAV is utilized as a cooperative jammer generating artificial noise (AN) to degrade unscheduled UEs detection. We then formulate a novel minimum average energy efficiency (mAEE) optimization problem, targetting to improve the covert throughput and reduce UAVs' propulsion energy consumption subject to the covertness requirement, which is determined analytically. Since the optimization problem is non-convex, we tackle it via the block successive convex approximation (BSCA) approach to iteratively solve a sequence of approximated convex sub-problems, designing the binary user scheduling, AP's power allocation, maximum AN jamming power, IRS beamforming, and both UAVs' trajectory planning. Finally, we present a low-complex overall algorithm for system performance enhancement with complexity and convergence analysis. Numerical results are provided to verify our analysis and demonstrate significant outperformance of our design over other existing benchmark schemes.      
### 49.Music Classification: Beyond Supervised Learning, Towards Real-world Applications  [ :arrow_down: ](https://arxiv.org/pdf/2111.11636.pdf)
>  Music classification is a music information retrieval (MIR) task to classify music items to labels such as genre, mood, and instruments. It is also closely related to other concepts such as music similarity and musical preference. In this tutorial, we put our focus on two directions - the recent training schemes beyond supervised learning and the successful application of music classification models. <br>The target audience for this web book is researchers and practitioners who are interested in state-of-the-art music classification research and building real-world applications. We assume the audience is familiar with the basic machine learning concepts. <br>In this book, we present three lectures as follows: 1. Music classification overview: Task definition, applications, existing approaches, datasets, 2. Beyond supervised learning: Semi- and self-supervised learning for music classification, 3. Towards real-world applications: Less-discussed, yet important research issues in practice.      
### 50.Δ-MILP: Deep Space Network Scheduling via Mixed-Integer Linear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2111.11628.pdf)
>  This paper introduces $\Delta$-MILP, a powerful variant of the mixed-integer linear programming (MILP) optimization framework to solve NASA's Deep Space Network (DSN) scheduling problem. This work is an extension of our original MILP framework (DOI:<a class="link-https link-external" data-doi="10.1109/ACCESS.2021.3064928" href="https://arxiv.org/ct?url=https%3A%2F%2Fdx.doi.org%2F10.1109%2FACCESS.2021.3064928&amp;v=19b27600" rel="external noopener nofollow">10.1109/ACCESS.2021.3064928</a>) and inherits many of its constructions and strengths, including the base MILP formulation for DSN scheduling. To provide more feasible schedules with respect to the DSN requirements, $\Delta$-MILP incorporates new sets of constraints including 1) splitting larger tracks into shorter segments and 2) preventing overlapping between tracks on different antennas. Additionally, $\Delta$-MILP leverages a heuristic to balance mission satisfaction and allows to prioritize certain missions in special scenarios including emergencies and landings. Numerical validations demonstrate that $\Delta$-MILP now satisfies 100% of the requested constraints and provides fair schedules amongst missions with respect to the state-of-the-art for the most oversubscribed weeks of the years 2016 and 2018.      
### 51.State Estimation of the Stefan PDE: A Tutorial on Design and Applications to Polar Ice and Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2111.11617.pdf)
>  The Stefan PDE system is a representative model for thermal phase change phenomena, such as melting and solidification, arising in numerous science and engineering processes. The mathematical description is given by a Partial Differential Equation (PDE) of the temperature distribution defined on a spatial interval with a moving boundary, where the boundary represents the liquid-solid interface and its dynamics are governed by an Ordinary Differential Equation (ODE). The PDE-ODE coupling at the boundary is nonlinear and creates a significant challenge for state estimation with provable convergence and robustness. This tutorial article presents a state estimation method based on PDE backstepping for the Stefan system, using measurements only at the moving boundary. PDE backstepping observer design generates an observer gain by employing a Volterra transformation of the observer error state into a desirable target system, solving a Goursat-form PDE for the transformation's kernel, and performing a Lyapunov analysis of the target observer error system. The observer is applied to models of problems motivated by climate change and the need for renewable energy storage: a model of polar ice dynamics and a model of charging and discharging in lithium-ion batteries. The numerical results for polar ice demonstrate a robust performance of the designed estimator with respect to the unmodeled salinity effect in sea ice. The results for an electrochemical PDE model of a lithium-ion battery with a phase transition material show the elimination of more than 15 \% error in State-of-Charge estimate within 5 minutes even in the presence of sensor noise.      
### 52.Active IRS Aided WPCNs: A New Paradigm Towards Higher Efficiency and Wider Coverage  [ :arrow_down: ](https://arxiv.org/pdf/2111.11600.pdf)
>  This paper considers an active intelligent reflecting surface (IRS)-aided wireless powered communication network (WPCN), where devices first harvest energy and then transmit information to a hybrid access point (HAP). Different from the existing works on passive IRS-aided WPCNs, this is the first work that introduces the active IRS in WPCNs. To guarantee the fairness, the problem is formulated as an amplifying power-limited weighted sum throughput (WST) maximization problem, which is solved by successive convex approximation technique and fractional programming alternatively. To balance the performance and complexity tradeoff, three beamforming setups are considered at the active IRS, namely user-adaptive IRS beamforming, uplink-adaptive IRS beamforming, and static IRS beamforming. Numerical results demonstrate the significant superiority of employing active IRS in WPCNs and the benefits of dynamic IRS beamforming. Specifically, it is found that compared to the passive IRS, active IRS not only improves the WST greatly, but also is more energy-efficient and can significantly extend the transmission coverage. Moreover, different from the symmetric deployment strategy of passive IRS, it is more preferable to deploy the active IRS near the devices.      
### 53.Generative Adversarial Networks for Astronomical Images Generation  [ :arrow_down: ](https://arxiv.org/pdf/2111.11578.pdf)
>  Space exploration has always been a source of inspiration for humankind, and thanks to modern telescopes, it is now possible to observe celestial bodies far away from us. With a growing number of real and imaginary images of space available on the web and exploiting modern deep Learning architectures such as Generative Adversarial Networks, it is now possible to generate new representations of space. In this research, using a Lightweight GAN, a dataset of images obtained from the web, and the Galaxy Zoo Dataset, we have generated thousands of new images of celestial bodies, galaxies, and finally, by combining them, a wide view of the universe. The code for reproducing our results is publicly available at <a class="link-external link-https" href="https://github.com/davide-coccomini/GAN-Universe" rel="external noopener nofollow">this https URL</a>, and the generated images can be explored at <a class="link-external link-https" href="https://davide-coccomini.github.io/GAN-Universe/" rel="external noopener nofollow">this https URL</a>.      
### 54.Camera Measurement of Physiological Vital Signs  [ :arrow_down: ](https://arxiv.org/pdf/2111.11547.pdf)
>  The need for remote tools for healthcare monitoring has never been more apparent. Camera measurement of vital signs leverages imaging devices to compute physiological changes by analyzing images of the human body. Building on advances in optics, machine learning, computer vision and medicine these techniques have progressed significantly since the invention of digital cameras. This paper presents a comprehensive survey of camera measurement of physiological vital signs, describing they vital signs that can be measured and the computational techniques for doing so. I cover both clinical and non-clinical applications and the challenges that need to be overcome for these applications to advance from proofs-of-concept. Finally, I describe the current resources (datasets and code) available to the research community and provide a comprehensive webpage (<a class="link-external link-https" href="https://cameravitals.github.io/" rel="external noopener nofollow">this https URL</a>) with links to these resource and a categorized list of all the papers referenced in this article.      
### 55.Graph Neural Networks with Parallel Neighborhood Aggregations for Graph Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.11482.pdf)
>  We focus on graph classification using a graph neural network (GNN) model that precomputes the node features using a bank of neighborhood aggregation graph operators arranged in parallel. These GNN models have a natural advantage of reduced training and inference time due to the precomputations but are also fundamentally different from popular GNN variants that update node features through a sequential neighborhood aggregation procedure during training. We provide theoretical conditions under which a generic GNN model with parallel neighborhood aggregations (PA-GNNs, in short) are provably as powerful as the well-known Weisfeiler-Lehman (WL) graph isomorphism test in discriminating non-isomorphic graphs. Although PA-GNN models do not have an apparent relationship with the WL test, we show that the graph embeddings obtained from these two methods are injectively related. We then propose a specialized PA-GNN model, called SPIN, which obeys the developed conditions. We demonstrate via numerical experiments that the developed model achieves state-of-the-art performance on many diverse real-world datasets while maintaining the discriminative power of the WL test and the computational advantage of preprocessing graphs before the training process.      
### 56.Scheduling the NASA Deep Space Network with Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.05167.pdf)
>  With three complexes spread evenly across the Earth, NASA's Deep Space Network (DSN) is the primary means of communications as well as a significant scientific instrument for dozens of active missions around the world. A rapidly rising number of spacecraft and increasingly complex scientific instruments with higher bandwidth requirements have resulted in demand that exceeds the network's capacity across its 12 antennae. The existing DSN scheduling process operates on a rolling weekly basis and is time-consuming; for a given week, generation of the final baseline schedule of spacecraft tracking passes takes roughly 5 months from the initial requirements submission deadline, with several weeks of peer-to-peer negotiations in between. This paper proposes a deep reinforcement learning (RL) approach to generate candidate DSN schedules from mission requests and spacecraft ephemeris data with demonstrated capability to address real-world operational constraints. A deep RL agent is developed that takes mission requests for a given week as input, and interacts with a DSN scheduling environment to allocate tracks such that its reward signal is maximized. A comparison is made between an agent trained using Proximal Policy Optimization and its random, untrained counterpart. The results represent a proof-of-concept that, given a well-shaped reward signal, a deep RL agent can learn the complex heuristics used by experts to schedule the DSN. A trained agent can potentially be used to generate candidate schedules to bootstrap the scheduling process and thus reduce the turnaround cycle for DSN scheduling.      
