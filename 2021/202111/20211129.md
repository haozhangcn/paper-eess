# ArXiv eess --Mon, 29 Nov 2021
### 1.On a Stochastic Fundamental Lemma and Its Use for Data-Driven MPC  [ :arrow_down: ](https://arxiv.org/pdf/2111.13636.pdf)
>  Data-driven Model Predictive Control (MPC) based on the fundamental lemma by Willems et al. has shown promising results for deterministic LTI systems subject to measurement noise. However, besides measurement noise, stochastic disturbances might also directly affect the dynamics. In this paper, we extend deterministic data-driven MPC towards stochastic systems. Leveraging Polynomial Chaos Expansions (PCE), we propose a novel variant of the fundamental lemma for stochastic LTI systems. This extension allows to predict future distributions of the behaviors for stochastic LTI systems based on the knowledge of previously recorded behavior realizations and based on the knowledge of the noise distribution. Finally, we propose a framework for data-driven stochastic MPC which is applicable to a large class of noise distributions with finite variance. Numerical examples illustrate the efficacy of the proposed scheme.      
### 2.Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements  [ :arrow_down: ](https://arxiv.org/pdf/2111.13630.pdf)
>  Even though many semantic segmentation methods exist that are able to perform well on many medical datasets, often, they are not designed for direct use in clinical practice. The two main concerns are generalization to unseen data with a different visual appearance, e.g., images acquired using a different scanner, and efficiency in terms of computation time and required Graphics Processing Unit (GPU) memory. In this work, we employ a multi-organ segmentation model based on the SpatialConfiguration-Net (SCN), which integrates prior knowledge of the spatial configuration among the labelled organs to resolve spurious responses in the network outputs. Furthermore, we modified the architecture of the segmentation model to reduce its memory footprint as much as possible without drastically impacting the quality of the predictions. Lastly, we implemented a minimal inference script for which we optimized both, execution time and required GPU memory.      
### 3.Hidden Markov Modeling over Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2111.13626.pdf)
>  This work proposes a multi-agent filtering algorithm over graphs for finite-state hidden Markov models (HMMs), which can be used for sequential state estimation or for tracking opinion formation over dynamic social networks. We show that the difference from the optimal centralized Bayesian solution is asymptotically bounded for geometrically ergodic transition models. Experiments illustrate the theoretical findings and in particular, demonstrate the superior performance of the proposed algorithm compared to a state-of-the-art social learning algorithm.      
### 4.Fusion of Sensor Measurements and Target-Provided Information in Multitarget Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2111.13589.pdf)
>  Tracking multiple time-varying states based on heterogeneous observations is a key problem in many applications. Here, we develop a statistical model and algorithm for tracking an unknown number of targets based on the probabilistic fusion of observations from two classes of data sources. The first class, referred to as target-independent perception systems (TIPSs), consists of sensors that periodically produce noisy measurements of targets without requiring target cooperation. The second class, referred to as target-dependent reporting systems (TDRSs), relies on cooperative targets that report noisy measurements of their state and their identity. We present a joint TIPS-TDRS observation model that accounts for observation-origin uncertainty, missed detections, false alarms, and asynchronicity. We then establish a factor graph that represents this observation model along with a state evolution model including target identities. Finally, by executing the sum-product algorithm on that factor graph, we obtain a scalable multitarget tracking algorithm with inherent TIPS-TDRS fusion. The performance of the proposed algorithm is evaluated using simulated data as well as real data from a maritime surveillance experiment.      
### 5.Teaching Undergraduate Students to Think Like Real-World Systems Engineers: A Technology-Based Hybrid Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.13559.pdf)
>  A hybrid teaching approach that relied on combining Project Based Learning with Team Based Learning was trialled in an engineering module during the past five years. Our motivation was to expose students to real-world authentic engineering problems and to steer them away from the classical 'banking' approach, with a view to developing their systems engineering skills via deeper and more collaborative learning. Our third year module was called Team Design and Project Skills and was concerned with 320 students dividing themselves in teams to develop a smart electronic system. We reveal module design details and discuss the effectiveness of our teaching approach via analysis of student grades during the past five years, as well as data from surveys that were completed by 68 students. 64% of surveyed students agreed that the module helped broaden their perspective in electronic systems design. Moreover, 84% recognised that this module was a valuable component in their degree programme. Adopting this approach in an engineering curriculum enabled students to integrate knowledge in areas that included control systems, image processing, embedded systems, sensors, as well as team working, decision making, trouble shooting and project planning.      
### 6.On Recurrent Neural Networks for learning-based control: recent results and ideas for future developments  [ :arrow_down: ](https://arxiv.org/pdf/2111.13557.pdf)
>  This paper aims to discuss and analyze the potentialities of Recurrent Neural Networks (RNN) in control design applications. The main families of RNN are considered, namely Neural Nonlinear AutoRegressive eXogenous, (NNARX), Echo State Networks (ESN), Long Short Term Memory (LSTM), and Gated Recurrent Units (GRU). The goal is twofold. Firstly, to survey recent results concerning the training of RNN that enjoy Input-to-State Stability (ISS) and Incremental Input-to-State Stability ({\delta}ISS) guarantees. Secondly, to discuss the issues that still hinder the widespread use of RNN for control, namely their robustness, verifiability, and interpretability. The former properties are related to the so-called generalization capabilities of the networks, i.e. their consistency with the underlying real plants, even in presence of unseen or perturbed input trajectories. The latter is instead related to the possibility of providing a clear formal connection between the RNN model and the plant. In this context, we illustrate how ISS and {\delta}ISS represent a significant step towards the robustness and verifiability of the RNN models, while the requirement of interpretability paves the way to the use of physics-based networks. The design of model predictive controllers with RNN as plant's model is also briefly discussed. Lastly, some of the main topics of the paper are illustrated on a simulated chemical system.      
### 7.Joint transmit and reflective beamforming for IRS-assisted integrated sensing and communication  [ :arrow_down: ](https://arxiv.org/pdf/2111.13511.pdf)
>  This letter studies an intelligent reflecting surface (IRS)-assisted integrated sensing and communication (ISAC) system, in which one IRS is deployed to not only assist the wireless communication from a multi-antenna base station (BS) to a single-antenna communication user (CU), but also create virtual line-of-sight (LoS) links for sensing targets at areas with LoS links blocked. We consider that the BS transmits combined information and sensing signals for ISAC. Under this setup, we jointly optimize the transmit information and sensing beamforming at the BS and the reflective beamforming at the IRS, to maximize the IRS's minimum beampattern gain towards the desired sensing angles, subject to the minimum signal-to-noise ratio (SNR) requirement at the CU and the maximum transmit power constraint at the BS. Although the formulated SNR-constrained beampattern gain maximization problem is non-convex and difficult to solve, we present an efficient algorithm to obtain a high-quality solution using alternating optimization and semi-definite relaxation (SDR). Numerical results show that the proposed algorithm achieves improved sensing performance while ensuring the communication requirement.      
### 8.Short-time Fourier transform based on stimulated Brillouin scattering  [ :arrow_down: ](https://arxiv.org/pdf/2111.13438.pdf)
>  In this paper, all-optical short-time Fourier transform (STFT) based on stimulated Brillouin scattering (SBS) is proposed and further used for real-time time-frequency analysis of different radio frequency (RF) signals. In the proposed all-optical STFT system, SBS not only provides a band-pass filter for implementing the window function in conjunction with a periodic frequency-sweep optical signal but also obtains the frequency domain information in different time windows through the generated waveform via frequency-to-time mapping (FTTM). A periodic frequency-sweep optical signal is generated and then modulated at a Mach-Zehnder modulator by the electrical signal under test (SUT). During different sweep periods, the fixed Brillouin gain functions as a bandpass filter to select a specific range of the spectrum, which is equivalent to applying a sliding window function to the corresponding section of the temporal signal with the help of the sweep optical signal. At the same time, after the optical signal is selectively amplified by the SBS gain and converted back to the electrical domain, SBS also implements the real-time FTTM, which can be utilized to obtain the frequency domain information corresponding to different time windows through the generated waveforms via the FTTM. The frequency domain information corresponding to different time windows is formed and spliced to analyze the time-frequency relationship of the SUT in real-time. An experiment is performed. STFTs of a variety of RF signals are carried out in a 12-GHz bandwidth limited only by the equipment, and the dynamic frequency resolution is better than 60 MHz.      
### 9.Learning source-aware representations of music in a discrete latent space  [ :arrow_down: ](https://arxiv.org/pdf/2111.13321.pdf)
>  In recent years, neural network based methods have been proposed as a method that cangenerate representations from music, but they are not human readable and hardly analyzable oreditable by a human. To address this issue, we propose a novel method to learn source-awarelatent representations of music through Vector-Quantized Variational Auto-Encoder(VQ-VAE).We train our VQ-VAE to encode an input mixture into a tensor of integers in a discrete latentspace, and design them to have a decomposed structure which allows humans to manipulatethe latent vector in a source-aware manner. This paper also shows that we can generate basslines by estimating latent vectors in a discrete space.      
### 10.Instrumented shoulder functional assessment using inertial measurement units for frozen shoulder  [ :arrow_down: ](https://arxiv.org/pdf/2111.13312.pdf)
>  Frozen shoulder (FS) is a shoulder condition that leads to pain and loss of shoulder range of motion. FS patients have difficulties in independently performing daily activities. Inertial measurement units (IMUs) have been developed to objectively measure upper limb range of motion (ROM) and shoulder function. In this work, we propose an IMU-based shoulder functional task assessment with kinematic parameters (e.g., smoothness, power, speed, and duration) in FS patients and analyze the functional performance on complete shoulder tasks and subtasks. Twenty FS patients and twenty healthy subjects were recruited in this study. Five shoulder functional tasks are performed by participants, such as washing hair (WH), washing upper back (WUB), washing lower back (WLB), placing an object on a high shelf (POH), and removing an object from back pocket (ROP). The results demonstrate that the used smoothness features can reflect the differences of movement fluency between FS patients and healthy controls (p &lt; 0.05 and effect size &gt; 0.8). Moreover, features of subtasks provided subtle information related to clinical conditions that have not been revealed in features of a complete task, especially the defined subtask 1 and 2 of each task.      
### 11.A Volumetric Transformer for Accurate 3D Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.13300.pdf)
>  This paper presents a Transformer architecture for volumetric medical image segmentation. Designing a computationally efficient Transformer architecture for volumetric segmentation is a challenging task. It requires keeping a complex balance in encoding local and global spatial cues, and preserving information along all axes of the volumetric data. The proposed volumetric Transformer has a U-shaped encoder-decoder design that processes the input voxels in their entirety. Our encoder has two consecutive self-attention layers to simultaneously encode local and global cues, and our decoder has novel parallel shifted window based self and cross attention blocks to capture fine details for boundary refinement by subsuming Fourier position encoding. Our proposed design choices result in a computationally efficient architecture, which demonstrates promising results on Brain Tumor Segmentation (BraTS) 2021, and Medical Segmentation Decathlon (Pancreas and Liver) datasets for tumor segmentation. We further show that the representations learned by our model transfer better across-datasets and are robust against data corruptions. \href{<a class="link-external link-https" href="https://github.com/himashi92/VT-UNet" rel="external noopener nofollow">this https URL</a>}{Our code implementation is publicly available}.      
### 12.Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2111.13299.pdf)
>  Liver cancer is one of the most common malignant diseases in the world. Segmentation and labeling of liver tumors and blood vessels in CT images can provide convenience for doctors in liver tumor diagnosis and surgical intervention. In the past decades, automatic CT segmentation methods based on deep learning have received widespread attention in the medical field. Many state-of-the-art segmentation algorithms appeared during this period. Yet, most of the existing segmentation methods only care about the local feature context and have a perception defect in the global relevance of medical images, which significantly affects the segmentation effect of liver tumors and blood vessels. We introduce a multi-scale feature context fusion network called TransFusionNet based on Transformer and SEBottleNet. This network can accurately detect and identify the details of the region of interest of the liver vessel, meanwhile it can improve the recognition of morphologic margins of liver tumors by exploiting the global information of CT images. Experiments show that TransFusionNet is better than the state-of-the-art method on both the public dataset LITS and 3Dircadb and our clinical dataset. Finally, we propose an automatic 3D reconstruction algorithm based on the trained model. The algorithm can complete the reconstruction quickly and accurately in 1 second.      
### 13.Model Reduction of Linear Dynamical Systems via Balancing for Bayesian Inference  [ :arrow_down: ](https://arxiv.org/pdf/2111.13246.pdf)
>  We consider the Bayesian approach to the linear Gaussian inference problem of inferring the initial condition of a linear dynamical system from noisy output measurements taken after the initial time. In practical applications, the large dimension of the dynamical system state poses a computational obstacle to computing the exact posterior distribution. Model reduction offers a variety of computational tools that seek to reduce this computational burden. In particular, balanced truncation is a system-theoretic approach to model reduction which obtains an efficient reduced-dimension dynamical system by projecting the system operators onto state directions which trade off the reachability and observability of state directions as expressed through the associated Gramians. We introduce Gramian definitions relevant to the inference setting and propose a balanced truncation approach based on these inference Gramians that yield a reduced dynamical system that can be used to cheaply approximate the posterior mean and covariance. Our definitions exploit natural connections between (i) the reachability Gramian and the prior covariance and (ii) the observability Gramian and the Fisher information. The resulting reduced model then inherits stability properties and error bounds from system theoretic considerations, and in some settings yields an optimal posterior covariance approximation. Numerical demonstrations on two benchmark problems in model reduction show that our method can yield near-optimal posterior covariance approximations with order-of-magnitude state dimension reduction.      
### 14.Evaluation of Interpretability for Deep Learning algorithms in EEG Emotion Recognition: A case study in Autism  [ :arrow_down: ](https://arxiv.org/pdf/2111.13208.pdf)
>  Current models on Explainable Artificial Intelligence (XAI) have shown an evident and quantified lack of reliability for measuring feature-relevance when statistically entangled features are proposed for training deep classifiers. There has been an increase in the application of Deep Learning in clinical trials to predict early diagnosis of neuro-developmental disorders, such as Autism Spectrum Disorder (ASD). However, the inclusion of more reliable saliency-maps to obtain more trustworthy and interpretable metrics using neural activity features is still insufficiently mature for practical applications in diagnostics or clinical trials. Moreover, in ASD research the inclusion of deep classifiers that use neural measures to predict viewed facial emotions is relatively unexplored. Therefore, in this study we propose the evaluation of a Convolutional Neural Network (CNN) for electroencephalography (EEG)-based facial emotion recognition decoding complemented with a novel RemOve-And-Retrain (ROAR) methodology to recover highly relevant features used in the classifier. Specifically, we compare well-known relevance maps such as Layer-Wise Relevance Propagation (LRP), PatternNet, Pattern Attribution, and Smooth-Grad Squared. This study is the first to consolidate a more transparent feature-relevance calculation for a successful EEG-based facial emotion recognition using a within-subject-trained CNN in typically-developed and ASD individuals.      
### 15.A Novel Framework for Image-to-image Translation and Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2111.13105.pdf)
>  Data-driven paradigms using machine learning are becoming ubiquitous in image processing and communications. In particular, image-to-image (I2I) translation is a generic and widely used approach to image processing problems, such as image synthesis, style transfer, and image restoration. At the same time, neural image compression has emerged as a data-driven alternative to traditional coding approaches in visual communications. In this paper, we study the combination of these two paradigms into a joint I2I compression and translation framework, focusing on multi-domain image synthesis. We first propose distributed I2I translation by integrating quantization and entropy coding into an I2I translation framework (i.e. I2Icodec). In practice, the image compression functionality (i.e. autoencoding) is also desirable, requiring to deploy alongside I2Icodec a regular image codec. Thus, we further propose a unified framework that allows both translation and autoencoding capabilities in a single codec. Adaptive residual blocks conditioned on the translation/compression mode provide flexible adaptation to the desired functionality. The experiments show promising results in both I2I translation and image compression using a single model.      
### 16.DeepJSCC-Q: Channel Input Constrained Deep Joint Source-Channel Coding  [ :arrow_down: ](https://arxiv.org/pdf/2111.13042.pdf)
>  Recent works have shown that the task of wireless transmission of images can be learned with the use of machine learning techniques. Very promising results in end-to-end image quality, superior to popular digital schemes that utilize source and channel coding separation, have been demonstrated through the training of an autoencoder, with a non-trainable channel layer in the middle. However, these methods assume that any complex value can be transmitted over the channel, which can prevent the application of the algorithm in scenarios where the hardware or protocol can only admit certain sets of channel inputs, such as the use of a digital constellation. Herein, we propose DeepJSCC-Q, an end-to-end optimized joint source-channel coding scheme for wireless image transmission, which is able to operate with a fixed channel input alphabet. We show that DeepJSCC-Q can achieve similar performance to models that use continuous-valued channel input. Importantly, it preserves the graceful degradation of image quality observed in prior work when channel conditions worsen, making DeepJSCC-Q much more attractive for deployment in practical systems.      
### 17.DeepWiVe: Deep-Learning-Aided Wireless Video Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2111.13034.pdf)
>  We present DeepWiVe, the first-ever end-to-end joint source-channel coding (JSCC) video transmission scheme that leverages the power of deep neural networks (DNNs) to directly map video signals to channel symbols, combining video compression, channel coding, and modulation steps into a single neural transform. Our DNN decoder predicts residuals without distortion feedback, which improves video quality by accounting for occlusion/disocclusion and camera movements. We simultaneously train different bandwidth allocation networks for the frames to allow variable bandwidth transmission. Then, we train a bandwidth allocation network using reinforcement learning (RL) that optimizes the allocation of limited available channel bandwidth among video frames to maximize overall visual quality. Our results show that DeepWiVe can overcome the cliff-effect, which is prevalent in conventional separation-based digital communication schemes, and achieve graceful degradation with the mismatch between the estimated and actual channel qualities. DeepWiVe outperforms H.264 video compression followed by low-density parity check (LDPC) codes in all channel conditions by up to 0.0462 on average in terms of the multi-scale structural similarity index measure (MS-SSIM), while beating H.265 + LDPC by up to 0.0058 on average. We also illustrate the importance of optimizing bandwidth allocation in JSCC video transmission by showing that our optimal bandwidth allocation policy is superior to the naÃ¯ve uniform allocation. We believe this is an important step towards fulfilling the potential of an end-to-end optimized JSCC wireless video transmission system that is superior to the current separation-based designs.      
### 18.Intermittent Sampling in Repetitive Control: Exploiting Time-Varying Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2111.13008.pdf)
>  The performance increase up to the sensor resolution in repetitive control (RC) invalidates the standard assumption in RC that data is available at equidistant time instances, e.g., in systems with package loss or when exploiting timestamped data from optical encoders. The aim of this paper is to develop an intermittent sampling RC framework for non-equidistant measurements. Sufficient stability conditions are derived that can be verified using non-parametric frequency response function data. This results in a frequency domain design procedure to explicitly address uncertainty. The RC framework is validated on an industrial printbelt setup for which exact non-equidistant measurement data is available.      
### 19.Non Parametric Data Augmentations Improve Deep-Learning based Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2111.12991.pdf)
>  Automatic brain tumor segmentation from Magnetic Resonance Imaging (MRI) data plays an important role in assessing tumor response to therapy and personalized treatment stratification.Manual segmentation is tedious and subjective.Deep-learning-based algorithms for brain tumor segmentation have the potential to provide objective and fast tumor segmentation.However, the training of such algorithms requires large datasets which are not always available. Data augmentation techniques may reduce the need for large datasets.However current approaches are mostly parametric and may result in suboptimal performance.We introduce two non-parametric methods of data augmentation for brain tumor segmentation: the mixed structure regularization (MSR) and shuffle pixels noise (SPN).We evaluated the added value of the MSR and SPN augmentation on the brain tumor segmentation (BraTS) 2018 challenge dataset with the encoder-decoder nnU-Net architecture as the segmentation algorithm.Both MSR and SPN improve the nnU-Net segmentation accuracy compared to parametric Gaussian noise augmentation.Mean dice score increased from 80% to 82% and p-values=0.0022, 0.0028 when comparing MSR to non-parametric augmentation for the tumor core and whole tumor experiments respectively.The proposed MSR and SPN augmentations have the potential to improve neural-networks performance in other tasks as well.      
### 20.Hidden Order of Boolean Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.12988.pdf)
>  It is a common belief that the order of a Boolean network is mainly determined by its attractors, including fixed points and cycles. Using semi-tensor product (STP) of matrices and the algebraic state-space representation (ASSR) of Boolean networks, this paper reveals that in addition to this explicit order, there is certain implicit or hidden order, which is determined by the fixed points and limit cycles of their dual networks. The structure and certain properties of dual networks are investigated. Instead of a trajectory, which describes the evolution of a state, hidden order provides a global picture to describe the evolution of the overall network. It is our conjecture that the order of networks is mainly determined by the dual attractors via their corresponding hidden orders. The previously obtained results about Boolean networks are further extended to the k-valued case.      
### 21.A Preliminary Study on the Role of Energy Storage and Load Rationing in Mitigating the Impact of the 2021 Texas Power Outage  [ :arrow_down: ](https://arxiv.org/pdf/2111.12908.pdf)
>  In February 2021, an unprecedented winter storm swept across the U.S., severely affecting the Texas power grid, leading to more than 4.5 million customers' electricity service interruption. This paper assesses the load shedding experienced by customers under realistic scenarios in the actual power grid. It also conducts a preliminary study on using energy storage and load rationing to mitigate rotating blackout's adverse impact on the grid. It is estimated that utility-scale battery storage systems with a total installed capacity of 920 GWh would be required to fully offset the load shedding during the Texas power outage if energy storage were the only technical option. Our simulation result suggests that implementing 20 percent load rationing on the system could potentially reduce this estimated energy storage capacity by 85 percent. This estimate is obtained using the predicted capacity and demand profile from February 15 to February 18, 2021. Recognizing the fact that it would be very challenging to practically deploy energy storage of this size, approaches to provide more granular demand reduction are studied as a means of leveraging the energy storage to maximize the survivability of consumers. Preliminary case study suggests the potential of combining load rationing and proper sizing of energy storage would potentially provide much reliability improvement for the grid under such extreme weather conditions.      
### 22.Morphological feature visualization of Alzheimer's disease via Multidirectional Perception GAN  [ :arrow_down: ](https://arxiv.org/pdf/2111.12886.pdf)
>  The diagnosis of early stages of Alzheimer's disease (AD) is essential for timely treatment to slow further deterioration. Visualizing the morphological features for the early stages of AD is of great clinical value. In this work, a novel Multidirectional Perception Generative Adversarial Network (MP-GAN) is proposed to visualize the morphological features indicating the severity of AD for patients of different stages. Specifically, by introducing a novel multidirectional mapping mechanism into the model, the proposed MP-GAN can capture the salient global features efficiently. Thus, by utilizing the class-discriminative map from the generator, the proposed model can clearly delineate the subtle lesions via MR image transformations between the source domain and the pre-defined target domain. Besides, by integrating the adversarial loss, classification loss, cycle consistency loss and \emph{L}1 penalty, a single generator in MP-GAN can learn the class-discriminative maps for multiple-classes. Extensive experimental results on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that MP-GAN achieves superior performance compared with the existing methods. The lesions visualized by MP-GAN are also consistent with what clinicians observe.      
### 23.Coded Illumination for Improved Lensless Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.12862.pdf)
>  Mask-based lensless cameras can be flat, thin and light-weight, which makes them suitable for novel designs of computational imaging systems with large surface areas and arbitrary shapes. Despite recent progress in lensless cameras, the quality of images recovered from the lensless cameras is often poor due to the ill-conditioning of the underlying measurement system. In this paper, we propose to use coded illumination to improve the quality of images reconstructed with lensless cameras. In our imaging model, the scene/object is illuminated by multiple coded illumination patterns as the lensless camera records sensor measurements. We designed and tested a number of illumination patterns and observed that shifting dots (and related orthogonal) patterns provide the best overall performance. We propose a fast and low-complexity recovery algorithm that exploits the separability and block-diagonal structure in our system. We present simulation results and hardware experiment results to demonstrate that our proposed method can significantly improve the reconstruction quality.      
### 24.On-Board Federated Learning for Dense LEO Constellations  [ :arrow_down: ](https://arxiv.org/pdf/2111.12769.pdf)
>  Mega-constellations of small-size Low Earth Orbit (LEO) satellites are currently planned and deployed by various private and public entities. While global connectivity is the main rationale, these constellations also offer the potential to gather immense amounts of data, e.g., for Earth observation. Power and bandwidth constraints together with motives like privacy, limiting delay, or resiliency make it desirable to process this data directly within the constellation. We consider the implementation of on-board federated learning (FL) orchestrated by an out-of-constellation parameter server (PS) and propose a novel communication scheme tailored to support FL. It leverages intra-orbit inter-satellite links, the predictability of satellite movements and partial aggregating to massively reduce the training time and communication costs. In particular, for a constellation with 40 satellites equally distributed among five low Earth orbits and the PS in medium Earth orbit, we observe a 29x speed-up in the training process time and a 8x traffic reduction at the PS over the baseline.      
### 25.Finite Horizon Worst-Case Analysis of Linear Time-Varying Systems Applied to Launch Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2111.12748.pdf)
>  This paper presents an approach to compute the worst-case gain of the interconnection of a finite time horizon linear time-variant system and a perturbation. The input/output behavior of the uncertainty is described by integral quadratic constraints (IQCs). A condition for the worst-case gain of such an interconnection can be formulated using dissipation theory as a parameterized Riccati differential equation, which depends on the chosen IQC multiplier. A nonlinear optimization problem is formulated to minimize the upper bound of the worst-case gain over a set of admissible IQC multipliers. This problem can be efficiently solved with a custom-tailored logarithm scaled, adaptive differential evolution algorithm. It provides a fast alternative to similar approaches based on solving semidefinite programs. The algorithm is applied to the worst-case aerodynamic load analysis for an expendable launch vehicle (ELV). The worst-case load of the uncertain ELV is calculated under wind turbulence during the atmospheric ascend and compared to results from nonlinear simulation.      
### 26.NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images  [ :arrow_down: ](https://arxiv.org/pdf/2111.13679.pdf)
>  Neural Radiance Fields (NeRF) is a technique for high quality novel view synthesis from a collection of posed input images. Like most view synthesis methods, NeRF uses tonemapped low dynamic range (LDR) as input; these images have been processed by a lossy camera pipeline that smooths detail, clips highlights, and distorts the simple noise distribution of raw sensor data. We modify NeRF to instead train directly on linear raw images, preserving the scene's full dynamic range. By rendering raw output images from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks. In addition to changing the camera viewpoint, we can manipulate focus, exposure, and tonemapping after the fact. Although a single raw image appears significantly more noisy than a postprocessed one, we show that NeRF is highly robust to the zero-mean distribution of raw noise. When optimized over many noisy raw inputs (25-200), NeRF produces a scene representation so accurate that its rendered novel views outperform dedicated single and multi-image deep raw denoisers run on the same wide baseline input images. As a result, our method, which we call RawNeRF, can reconstruct scenes from extremely noisy images captured in near-darkness.      
### 27.Non-Convex Recovery from Phaseless Low-Resolution Blind Deconvolution Measurements using Noisy Masked Patterns  [ :arrow_down: ](https://arxiv.org/pdf/2111.13670.pdf)
>  This paper addresses recovery of a kernel $\boldsymbol{h}\in \mathbb{C}^{n}$ and a signal $\boldsymbol{x}\in \mathbb{C}^{n}$ from the low-resolution phaseless measurements of their noisy circular convolution $\boldsymbol{y} = \left \rvert \boldsymbol{F}_{lo}( \boldsymbol{x}\circledast \boldsymbol{h}) \right \rvert^{2} + \boldsymbol{\eta}$, where $\boldsymbol{F}_{lo}\in \mathbb{C}^{m\times n}$ stands for a partial discrete Fourier transform ($m&lt;n$), $\boldsymbol{\eta}$ models the noise, and $\lvert \cdot \rvert$ is the element-wise absolute value function. This problem is severely ill-posed because both the kernal and signal are unknown and, in addition, the measurements are phaseless, leading to many $x$-$h$ pairs that correspond to the measurements. Therefore, to guarantee a stable recovery of $\boldsymbol{x}$ and $\boldsymbol{h}$ from $\boldsymbol{y}$, we assume that the kernel $\boldsymbol{h}$ and the signal $\boldsymbol{x}$ lie in known subspaces of dimensions $k$ and $s$, respectively, such that $m\gg k+s$. We solve this problem by proposing a \textit{bli}nd deconvolution algorithm for \textit{pha}seless \textit{su}per-resolution to minimize a non-convex least-squares objective function. The method first estimates a low-resolution version of both signals through a spectral algorithm, which are then refined based upon a sequence of stochastic gradient iterations. We show that our BliPhaSu algorithm converges linearly to a pair of true signals on expectation under a proper initialization that is based on spectral method. Numerical results from experimental data demonstrate perfect recovery of both $h$ and $s$ using our method.      
### 28.Joint Wireless and Computing Resources Allocation in Multi-Cell MEC  [ :arrow_down: ](https://arxiv.org/pdf/2111.13608.pdf)
>  This paper addresses join wireless and computing resource allocation in mobile edge computing (MEC) systems with several access points and with the possibility that users connect to many access points, and utilize the computation capability of many servers at the same time. The problem of sum transmission energy minimization under response time constraints is considered. It is proved, that the optimization problem is non-convex. The complexity of optimization of a part of the system parameters is investigated, and based on these results an Iterative Resource Allocation procedure is proposed, that converges to a local optimum. The performance of the joint resource allocation is evaluated by comparing it to lower and upper bounds defined by less or more flexible multi-cell MEC architectures. The results show that the free selection of the access point is crucial for good system performance.      
### 29.Semi-supervised t-SNE for Millimeter-wave Wireless Localization  [ :arrow_down: ](https://arxiv.org/pdf/2111.13573.pdf)
>  We consider the mobile localization problem in future millimeter-wave wireless networks with distributed Base Stations (BSs) based on multi-antenna channel state information (CSI). For this problem, we propose a Semi-supervised tdistributed Stochastic Neighbor Embedding (St-SNE) algorithm to directly embed the high-dimensional CSI samples into the 2D geographical map. We evaluate the performance of St-SNE in a simulated urban outdoor millimeter-wave radio access network. Our results show that St-SNE achieves a mean localization error of 6.8 m with only 5% of labeled CSI samples in a 200*200 m^2 area with a ray-tracing channel model. St-SNE does not require accurate synchronization among multiple BSs, and is promising for future large-scale millimeter-wave localization.      
### 30.Double Intelligent Reflecting Surface-assisted Multi-User MIMO mmWave Systems with Hybrid Precoding  [ :arrow_down: ](https://arxiv.org/pdf/2111.13518.pdf)
>  This work investigates the effect of double intelligent reflecting surface (IRS) in improving the spectrum efficient of multi-user multiple-input multiple-output (MIMO) network operating in the millimeter wave (mmWave) band. Specifically, we aim to solve a weighted sum rate maximization problem by jointly optimizing the digital precoding at the transmitter and the analog phase shifters at the IRS, subject to the minimum achievable rate constraint. To facilitate the design of an efficient solution, we first reformulate the original problem into a tractable one by exploiting the majorization-minimization (MM) method. Then, a block coordinate descent (BCD) method is proposed to obtain a suboptimal solution, where the precoding matrices and the phase shifters are alternately optimized. Specifically, the digital precoding matrix design problem is solved by the quadratically constrained quadratic programming (QCQP), while the analog phase shift optimization is solved by the Riemannian manifold optimization (RMO). The convergence and computational complexity are analyzed. Finally, simulation results are provided to verify the performance of the proposed design, as well as the effectiveness of double-IRS in improving the spectral efficiency.      
### 31.When Creators Meet the Metaverse: A Survey on Computational Arts  [ :arrow_down: ](https://arxiv.org/pdf/2111.13486.pdf)
>  The metaverse, enormous virtual-physical cyberspace, has brought unprecedented opportunities for artists to blend every corner of our physical surroundings with digital creativity. This article conducts a comprehensive survey on computational arts, in which seven critical topics are relevant to the metaverse, describing novel artworks in blended virtual-physical realities. The topics first cover the building elements for the metaverse, e.g., virtual scenes and characters, auditory, textual elements. Next, several remarkable types of novel creations in the expanded horizons of metaverse cyberspace have been reflected, such as immersive arts, robotic arts, and other user-centric approaches fuelling contemporary creative outputs. Finally, we propose several research agendas: democratising computational arts, digital privacy, and safety for metaverse artists, ownership recognition for digital artworks, technological challenges, and so on. The survey also serves as introductory material for artists and metaverse technologists to begin creations in the realm of surrealistic cyberspace.      
### 32.Morphology Decoder: A Machine Learning Guided 3D Vision Quantifying Heterogenous Rock Permeability for Planetary Surveillance and Robotic Functions  [ :arrow_down: ](https://arxiv.org/pdf/2111.13460.pdf)
>  Permeability has a dominant influence on the flow properties of a natural fluid. Lattice Boltzmann simulator determines permeability from the nano and micropore network. The simulator holds millions of flow dynamics calculations with its accumulated errors and high consumption of computing power. To efficiently and consistently predict permeability, we propose a morphology decoder, a parallel and serial flow reconstruction of machine learning segmented heterogeneous Cretaceous texture from 3D micro computerized tomography and nuclear magnetic resonance images. For 3D vision, we introduce controllable-measurable-volume as new supervised segmentation, in which a unique set of voxel intensity corresponds to grain and pore throat sizes. The morphology decoder demarks and aggregates the morphologies boundaries in a novel way to produce permeability. Morphology decoder method consists of five novel processes, which describes in this paper, these novel processes are: (1) Geometrical 3D Permeability, (2) Machine Learning guided 3D Properties Recognition of Rock Morphology, (3) 3D Image Properties Integration Model for Permeability, (4) MRI Permeability Imager, and (5) Morphology Decoder (the process that integrates the other four novel processes).      
### 33.Semi-Supervised Music Tagging Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2111.13457.pdf)
>  We present Music Tagging Transformer that is trained with a semi-supervised approach. The proposed model captures local acoustic characteristics in shallow convolutional layers, then temporally summarizes the sequence of the extracted features using stacked self-attention layers. Through a careful model assessment, we first show that the proposed architecture outperforms the previous state-of-the-art music tagging models that are based on convolutional neural networks under a supervised scheme. <br>The Music Tagging Transformer is further improved by noisy student training, a semi-supervised approach that leverages both labeled and unlabeled data combined with data augmentation. To our best knowledge, this is the first attempt to utilize the entire audio of the million song dataset.      
### 34.Minimum jointly structural input and output selection for strongly connected networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.13449.pdf)
>  In this paper, given a linear time-invariant strongly connected network, we study the problem of determining the minimum number of state variables that need to be simultaneously actuated and measured to ensure structural controllability and observability, respectively. This problem is fundamental in the design of multi-agent systems, where there are economic constraints in the decision of which agents to equip with a more costly on-board system that will allow the agent to have both actuation and sensing capabilities. Despite the combinatorial nature of this problem, we present a solution that couples the design of both structural controllability and structural observability counterparts to address it with polynomial-time complexity.      
### 35.RIS-aided D2D Communication Design for URLLC Packet Delivery  [ :arrow_down: ](https://arxiv.org/pdf/2111.13421.pdf)
>  In this paper, we consider a smart factory scenario where a set of actuators receive critical control signals from an access point (AP) with reliability and low latency requirements. We investigate jointly active beamforming at the AP and passive phase shifting at the reconfigurable intelligent surface (RIS) for successfully delivering the control signals from the AP to the actuators within a required time duration. The transmission follows a two-stage design. In the first stage, each actuator can both receive the direct signal from AP and the reflected signal from the RIS. In the second stage, the actuators with successful reception in the first stage, relay the message through the D2D network to the actuators with failed receptions. We formulate a non-convex optimization problem where we first obtain an equivalent but more tractable form by addressing the problem with discrete indicator functions. Then, Frobenius inner product based equality is applied for decoupling the optimization variables. Further, we adopt a penalty-based approach to resolve the rank-one constraints. Finally, we deal with the $\ell_0$-norm by $\ell_1$-norm approximation and add an extra term $\ell_1-\ell_2$ for sparsity. Numerical results reveal that the proposed two-stage RIS-aided D2D communication protocol is effective for enabling reliable communication with latency requirements.      
### 36.Optimizing Packet Reception Rates for Low Duty-Cycle BLE Relay Nodes  [ :arrow_down: ](https://arxiv.org/pdf/2111.13414.pdf)
>  In order to achieve the full potential of the Internet-of-Things, connectivity between devices should be ubiquitous and efficient. Wireless mesh networks are a critical component to achieve this ubiquitous connectivity for a wide range of services, and are composed of terminal devices (i.e., nodes), such as sensors of various types, and wall powered gateway devices, which provide further internet connectivity (e..g, via WiFi). When considering large indoor areas, such as hospitals or industrial scenarios, the mesh must cover a large area, which introduces concerns regarding range and the number of gateways needed and respective wall cabling infrastructure. Solutions for mesh networks implemented over different wireless protocols exist, like the recent Bluetooth Low Energy (BLE) 5.1. Besides range concerns, choosing which nodes forward data through the mesh has a large impact on performance and power consumption. We address the area coverage issue via a battery powered BLE relay device of our own design, which acts as a range extender by forwarding packets from end nodes to gateways. We present the relay's design and experimentally determine the packet forwarding efficiency for several scenarios and configurations. In the best case, up to 35% of the packets transmitted by 11 nodes can be forwarded to a gateway by a single relay under continuous operation. A battery lifetime of 1 year can be achieved with a relay duty cycle of 20%.      
### 37.Deep Learning for Reaction-Diffusion Glioma Growth Modelling: Towards a Fully Personalised Model?  [ :arrow_down: ](https://arxiv.org/pdf/2111.13404.pdf)
>  Reaction-diffusion models have been proposed for decades to capture the growth of gliomas, the most common primary brain tumours. However, severe limitations regarding the estimation of the initial conditions and parameter values of such models have restrained their clinical use as a personalised tool. In this work, we investigate the ability of deep convolutional neural networks (DCNNs) to address the pitfalls commonly encountered in the field. Based on 1,200 synthetic tumours grown over real brain geometries derived from magnetic resonance (MR) data of 6 healthy subjects, we demonstrate the ability of DCNNs to reconstruct a whole tumour cell density distribution from only two imaging contours at a single time point. With an additional imaging contour extracted at a prior time point, we also demonstrate the ability of DCNNs to accurately estimate the individual diffusivity and proliferation parameters of the model. From this knowledge, the spatio-temporal evolution of the tumour cell density distribution at later time points can ultimately be precisely captured using the model. We finally show the applicability of our approach to MR data of a real glioblastoma patient. This approach may open the perspective of a clinical application of reaction-diffusion growth models for tumour prognosis and treatment planning.      
### 38.Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey  [ :arrow_down: ](https://arxiv.org/pdf/2111.13282.pdf)
>  This is a tutorial and survey paper on Generative Adversarial Network (GAN), adversarial autoencoders, and their variants. We start with explaining adversarial learning and the vanilla GAN. Then, we explain the conditional GAN and DCGAN. The mode collapse problem is introduced and various methods, including minibatch GAN, unrolled GAN, BourGAN, mixture GAN, D2GAN, and Wasserstein GAN, are introduced for resolving this problem. Then, maximum likelihood estimation in GAN are explained along with f-GAN, adversarial variational Bayes, and Bayesian GAN. Then, we cover feature matching in GAN, InfoGAN, GRAN, LSGAN, energy-based GAN, CatGAN, MMD GAN, LapGAN, progressive GAN, triple GAN, LAG, GMAN, AdaGAN, CoGAN, inverse GAN, BiGAN, ALI, SAGAN, Few-shot GAN, SinGAN, and interpolation and evaluation of GAN. Then, we introduce some applications of GAN such as image-to-image translation (including PatchGAN, CycleGAN, DeepFaceDrawing, simulated GAN, interactive GAN), text-to-image translation (including StackGAN), and mixing image characteristics (including FineGAN and MixNMatch). Finally, we explain the autoencoders based on adversarial learning including adversarial autoencoder, PixelGAN, and implicit autoencoder.      
### 39.Unscented Kalman Filter for Long-Distance Vessel Tracking in Geodetic Coordinates  [ :arrow_down: ](https://arxiv.org/pdf/2111.13254.pdf)
>  This paper describes a novel tracking filter, designed primarily for use in collision avoidance systems on autonomous surface vehicles (ASVs). The proposed methodology leverages real-time kinematic information broadcast via the Automatic Information System (AIS) messaging protocol, in order to estimate the position, speed, and heading of nearby cooperative targets. The state of each target is recursively estimated in geodetic coordinates using an unscented Kalman filter (UKF) with kinematic equations derived from the spherical law of cosines. This improves upon previous approaches, many of which employ the extended Kalman filter (EKF), and thus require the specification of a local planar coordinate frame, in order to describe the state kinematics in an easily differentiable form. The proposed geodetic UKF obviates the need for this local plane. This feature is particularly advantageous for long-range ASVs, which must otherwise periodically redefine a new local plane to curtail linearization error. In real-world operations, this recurring redefinition can introduce error and complicate mission planning. It is shown through both simulation and field testing that the proposed geodetic UKF performs as well as, or better than, the traditional plane-Cartesian EKF, both in terms of estimation error and stability.      
### 40.Country-wide Retrieval of Forest Structure From Optical and SAR Satellite Imagery With Bayesian Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.13154.pdf)
>  Monitoring and managing Earth's forests in an informed manner is an important requirement for addressing challenges like biodiversity loss and climate change. While traditional in situ or aerial campaigns for forest assessments provide accurate data for analysis at regional level, scaling them to entire countries and beyond with high temporal resolution is hardly possible. In this work, we propose a Bayesian deep learning approach to densely estimate forest structure variables at country-scale with 10-meter resolution, using freely available satellite imagery as input. Our method jointly transforms Sentinel-2 optical images and Sentinel-1 synthetic aperture radar images into maps of five different forest structure variables: 95th height percentile, mean height, density, Gini coefficient, and fractional cover. We train and test our model on reference data from 41 airborne laser scanning missions across Norway and demonstrate that it is able to generalize to unseen test regions, achieving normalized mean absolute errors between 11% and 15%, depending on the variable. Our work is also the first to propose a Bayesian deep learning approach so as to predict forest structure variables with well-calibrated uncertainty estimates. These increase the trustworthiness of the model and its suitability for downstream tasks that require reliable confidence estimates, such as informed decision making. We present an extensive set of experiments to validate the accuracy of the predicted maps as well as the quality of the predicted uncertainties. To demonstrate scalability, we provide Norway-wide maps for the five forest structure variables.      
### 41.Few-Shot Real Image Restoration via Distortion-Relation Guided Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.13078.pdf)
>  Collecting large clean-distorted training image pairs in real world is non-trivial, which seriously limits the practical applications of these supervised learning based image restoration (IR) methods. Previous works attempt to address this problem by leveraging unsupervised learning technologies to alleviate the dependency for paired training samples. However, these methods typically suffer from unsatisfactory textures synthesis due to the lack of clean image supervision. Compared with purely unsupervised solution, the under-explored scheme with Few-Shot clean images (FS-IR) is more feasible to tackle this challenging real Image Restoration task. In this paper, we are the first to investigate the few-shot real image restoration and propose a Distortion-Relation guided Transfer Learning (termed as DRTL) framework. DRTL assigns a knowledge graph to capture the distortion relation between auxiliary tasks (i.e., synthetic distortions) and target tasks (i.e., real distortions with few images), and then adopt a gradient weighting strategy to guide the knowledge transfer from auxiliary task to target task. In this way, DRTL could quickly learn the most relevant knowledge from the prior distortions for target distortion. We instantiate DRTL integrated with pre-training and meta-learning pipelines as an embodiment to realize a distortion-relation aware FS-IR. Extensive experiments on multiple benchmarks demonstrate the effectiveness of DRTL on few-shot real image restoration.      
### 42.Hybrid Jammer Mitigation for All-Digital mmWave Massive MU-MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2111.13055.pdf)
>  Low-resolution analog-to-digital converters (ADCs) simplify the design of millimeter-wave (mmWave) massive multi-user multiple-input multiple-output (MU-MIMO) basestations, but increase vulnerability to jamming attacks. As a remedy, we propose HERMIT (short for Hybrid jammER MITigation), a method that combines a hardware-friendly adaptive analog transform with a corresponding digital equalizer: The analog transform removes most of the jammer's energy prior to data conversion; the digital equalizer suppresses jammer residues while detecting the legitimate transmit data. We provide theoretical results that establish the optimal analog transform as a function of the user equipments' and the jammer's channels. Using simulations with mmWave channel models, we demonstrate the superiority of HERMIT compared both to purely digital jammer mitigation as well as to a recent hybrid method that mitigates jammer interference with a nonadaptive analog transform.      
### 43.A-Muze-Net: Music Generation by Composing the Harmony based on the Generated Melody  [ :arrow_down: ](https://arxiv.org/pdf/2111.12986.pdf)
>  We present a method for the generation of Midi files of piano music. The method models the right and left hands using two networks, where the left hand is conditioned on the right hand. This way, the melody is generated before the harmony. The Midi is represented in a way that is invariant to the musical scale, and the melody is represented, for the purpose of conditioning the harmony, by the content of each bar, viewed as a chord. Finally, notes are added randomly, based on this chord representation, in order to enrich the generated audio. Our experiments show a significant improvement over the state of the art for training on such datasets, and demonstrate the contribution of each of the novel components.      
### 44.Investigation of domain gap problem in several deep-learning-based CT metal artefact reduction methods  [ :arrow_down: ](https://arxiv.org/pdf/2111.12983.pdf)
>  Metal artefacts in CT images may disrupt image quality and interfere with diagnosis. Recently many deep-learning-based CT metal artefact reduction (MAR) methods have been proposed. Current deep MAR methods may be troubled with domain gap problem, where methods trained on simulated data cannot perform well on practical data. In this work, we experimentally investigate two image-domain supervised methods, two dual-domain supervised methods and two image-domain unsupervised methods on a dental dataset and a torso dataset, to explore whether domain gap problem exists or is overcome. We find that I-DL-MAR and DudoNet are effective for practical data of the torso dataset, indicating the domain gap problem is solved. However, none of the investigated methods perform satisfactorily on practical data of the dental dataset. Based on the experimental results, we further analyze the causes of domain gap problem for each method and dataset, which may be beneficial for improving existing methods or designing new ones. The findings suggest that the domain gap problem in deep MAR methods remains to be addressed.      
### 45.CDNet is all you need: Cascade DCN based underwater object detection RCNN  [ :arrow_down: ](https://arxiv.org/pdf/2111.12982.pdf)
>  Object detection is a very important basic research direction in the field of computer vision and a basic method for other advanced tasks in the field of computer vision. It has been widely used in practical applications such as object tracking, video behavior recognition and underwater robotics vision. The Cascade-RCNN and Deformable Convolution Network are both classical and excellent object detection algorithms. In this report, we evaluate our Cascade-DCN based method on underwater optical image and acoustics image datasets with different engineering tricks and augumentation.      
### 46.Data-driven distributionally robust iterative risk-constrained model predictive control  [ :arrow_down: ](https://arxiv.org/pdf/2111.12977.pdf)
>  This paper considers a risk-constrained infinite-horizon optimal control problem and proposes to solve it in an iterative manner. Each iteration of the algorithm generates a trajectory from the starting point to the target equilibrium state by implementing a distributionally robust risk-constrained model predictive control (MPC) scheme. At each iteration, a set of safe states (that satisfy the risk-constraint with high probability) and a certain number of independent and identically distributed samples of the uncertainty governing the risk constraint are available. These states and samples are accumulated in previous iterations. The safe states are used as terminal constraint in the MPC scheme and samples are used to construct a set of distributions, termed ambiguity set, such that it contains the underlying distribution of the uncertainty with high probability. The risk-constraint in each iteration is required to hold for all distributions in the ambiguity set. We establish that the trajectories generated by our iterative procedure are feasible, safe, and converge asymptotically to the equilibrium. Simulation example illustrates our results for the case of finding a risk-constrained path for a mobile robot in the presence of an uncertain obstacle.      
### 47.Learn Zero-Constraint-Violation Policy in Model-Free Constrained Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.12953.pdf)
>  In the trial-and-error mechanism of reinforcement learning (RL), a notorious contradiction arises when we expect to learn a safe policy: how to learn a safe policy without enough data and prior model about the dangerous region? Existing methods mostly use the posterior penalty for dangerous actions, which means that the agent is not penalized until experiencing danger. This fact causes that the agent cannot learn a zero-violation policy even after convergence. Otherwise, it would not receive any penalty and lose the knowledge about danger. In this paper, we propose the safe set actor-critic (SSAC) algorithm, which confines the policy update using safety-oriented energy functions, or the safety indexes. The safety index is designed to increase rapidly for potentially dangerous actions, which allows us to locate the safe set on the action space, or the control safe set. Therefore, we can identify the dangerous actions prior to taking them, and further obtain a zero constraint-violation policy after convergence.We claim that we can learn the energy function in a model-free manner similar to learning a value function. By using the energy function transition as the constraint objective, we formulate a constrained RL problem. We prove that our Lagrangian-based solutions make sure that the learned policy will converge to the constrained optimum under some assumptions. The proposed algorithm is evaluated on both the complex simulation environments and a hardware-in-loop (HIL) experiment with a real controller from the autonomous vehicle. Experimental results suggest that the converged policy in all environments achieves zero constraint violation and comparable performance with model-based baselines.      
### 48.ContourletNet: A Generalized Rain Removal Architecture Using Multi-Direction Hierarchical Representation  [ :arrow_down: ](https://arxiv.org/pdf/2111.12925.pdf)
>  Images acquired from rainy scenes usually suffer from bad visibility which may damage the performance of computer vision applications. The rainy scenarios can be categorized into two classes: moderate rain and heavy rain scenes. Moderate rain scene mainly consists of rain streaks while heavy rain scene contains both rain streaks and the veiling effect (similar to haze). Although existing methods have achieved excellent performance on these two cases individually, it still lacks a general architecture to address both heavy rain and moderate rain scenarios effectively. In this paper, we construct a hierarchical multi-direction representation network by using the contourlet transform (CT) to address both moderate rain and heavy rain scenarios. The CT divides the image into the multi-direction subbands (MS) and the semantic subband (SS). First, the rain streak information is retrieved to the MS based on the multi-orientation property of the CT. Second, a hierarchical architecture is proposed to reconstruct the background information including damaged semantic information and the veiling effect in the SS. Last, the multi-level subband discriminator with the feedback error map is proposed. By this module, all subbands can be well optimized. This is the first architecture that can address both of the two scenarios effectively. The code is available in <a class="link-external link-https" href="https://github.com/cctakaet/ContourletNet-BMVC2021" rel="external noopener nofollow">this https URL</a>.      
### 49.Robustness against Adversarial Attacks in Neural Networks using Incremental Dissipativity  [ :arrow_down: ](https://arxiv.org/pdf/2111.12906.pdf)
>  Adversarial examples can easily degrade the classification performance in neural networks. Empirical methods for promoting robustness to such examples have been proposed, but often lack both analytical insights and formal guarantees. Recently, some robustness certificates have appeared in the literature based on system theoretic notions. This work proposes an incremental dissipativity-based robustness certificate for neural networks in the form of a linear matrix inequality for each layer. We also propose an equivalent spectral norm bound for this certificate which is scalable to neural networks with multiple layers. We demonstrate the improved performance against adversarial attacks on a feed-forward neural network trained on MNIST and an Alexnet trained using CIFAR-10.      
### 50.V2C: Visual Voice Cloning  [ :arrow_down: ](https://arxiv.org/pdf/2111.12890.pdf)
>  Existing Voice Cloning (VC) tasks aim to convert a paragraph text to a speech with desired voice specified by a reference audio. This has significantly boosted the development of artificial speech applications. However, there also exist many scenarios that cannot be well reflected by these VC tasks, such as movie dubbing, which requires the speech to be with emotions consistent with the movie plots. To fill this gap, in this work we propose a new task named Visual Voice Cloning (V2C), which seeks to convert a paragraph of text to a speech with both desired voice specified by a reference audio and desired emotion specified by a reference video. To facilitate research in this field, we construct a dataset, V2C-Animation, and propose a strong baseline based on existing state-of-the-art (SoTA) VC techniques. Our dataset contains 10,217 animated movie clips covering a large variety of genres (e.g., Comedy, Fantasy) and emotions (e.g., happy, sad). We further design a set of evaluation metrics, named MCD-DTW-SL, which help evaluate the similarity between ground-truth speeches and the synthesised ones. Extensive experimental results show that even SoTA VC methods cannot generate satisfying speeches for our V2C task. We hope the proposed new task together with the constructed dataset and evaluation metric will facilitate the research in the field of voice cloning and the broader vision-and-language community.      
### 51.A novel time delay estimation algorithm of acoustic pyrometry for furnace  [ :arrow_down: ](https://arxiv.org/pdf/2111.12884.pdf)
>  Acoustic pyrometry is a non-contact measurement technology for monitoring furnace combustion reaction, diagnosing energy loss due to incomplete combustion and ensuring safe production. The accuracy of time of flight (TOF) estimation of an acoustic pyrometry directly affects the authenticity of furnace temperature measurement. In this paper presented is a novel TOF (i.e. time delay) estimation algorithm based on digital lock-in filtering (DLF) algorithm. In this research, the time-frequency relationship between the first harmonic of the acoustic signal and the moment of characteristic frequency applied is established through the digital lock-in and low-pass filtering techniques. The accurate estimation of TOF is obtained by extracting and comparing the temporal relationship of the characteristic frequency occurrence between received and source acoustic signals. The computational error analysis indicates that the accuracy of the proposed algorithm is better than that of the classical generalized cross-correlation (GCC) algorithm, and the computational effort is significantly reduced to half of that the GCC can offer. It can be confirmed that with this method, the temperature measurement in furnaces can be improved in terms of computational effort and accuracy, which are vital parameters in furnace combustion control. It provides a new idea of time delay estimation with the utilization of acoustic pyrometry for furnace.      
### 52.Graph recovery from graph wave equation  [ :arrow_down: ](https://arxiv.org/pdf/2111.12874.pdf)
>  We propose a method by which to recover an underlying graph from a set of multivariate wave signals that is discretely sampled from a solution of the graph wave equation. Herein, the graph wave equation is defined with the graph Laplacian, and its solution is explicitly given as a mode expansion of the Laplacian eigenvalues and eigenfunctions. For graph recovery, our idea is to extract modes corresponding to the square root of the eigenvalues from the discrete wave signals using the DMD method, and then to reconstruct the graph (Laplacian) from the eigenfunctions obtained as amplitudes of the modes. Moreover, in order to estimate modes more precisely, we modify the DMD method under an assumption that only stationary modes exist, because graph wave functions always satisfy this assumption. In conclusion, we demonstrate the proposed method on the wave signals over a path graph. Since our graph recovery procedure can be applied to non-wave signals, we also check its performance on human joint sensor time-series data.      
### 53.Polyphonic Sound Event Detection Using Capsule Neural Network on Multi-Type-Multi-Scale Time-Frequency Representation  [ :arrow_down: ](https://arxiv.org/pdf/2111.12869.pdf)
>  The challenges of polyphonic sound event detection (PSED) stem from the detection of multiple overlapping events in a time series. Recent efforts exploit Deep Neural Networks (DNNs) on Time-Frequency Representations (TFRs) of audio clips as model inputs to mitigate such issues. However, existing solutions often rely on a single type of TFR, which causes under-utilization of input features. To this end, we propose a novel PSED framework, which incorporates Multi-Type-Multi-Scale TFRs. Our key insight is that: TFRs, which are of different types or in different scales, can reveal acoustics patterns in a complementary manner, so that the overlapped events can be best extracted by combining different TFRs. Moreover, our framework design applies a novel approach, to adaptively fuse different models and TFRs symbiotically. Hence, the overall performance can be significantly improved. We quantitatively examine the benefits of our framework by using Capsule Neural Networks, a state-of-the-art approach for PSED. The experimental results show that our method achieves a reduction of 7\% in error rate compared with the state-of-the-art solutions on the TUT-SED 2016 dataset.      
### 54.Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements  [ :arrow_down: ](https://arxiv.org/pdf/2111.12855.pdf)
>  Deep networks provide state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. However, most existing networks are trained with clean signals which are often hard or impossible to obtain. Equivariant imaging (EI) is a recent self-supervised learning framework that exploits the group invariance present in signal distributions to learn a reconstruction function from partial measurement data alone. While EI results are impressive, its performance degrades with increasing noise. In this paper, we propose a Robust Equivariant Imaging (REI) framework which can learn to image from noisy partial measurements alone. The proposed method uses Stein's Unbiased Risk Estimator (SURE) to obtain a fully unsupervised training loss that is robust to noise. We show that REI leads to considerable performance gains on linear and nonlinear inverse problems, thereby paving the way for robust unsupervised imaging with deep networks. Code will be available at: <a class="link-external link-https" href="https://github.com/edongdongchen/REI" rel="external noopener nofollow">this https URL</a>.      
### 55.Extending the Relative Seriality Formalism for Interpretable Deep Learning of Normal Tissue Complication Probability Models  [ :arrow_down: ](https://arxiv.org/pdf/2111.12854.pdf)
>  We formally demonstrate that the relative seriality model of Kallman, et al. maps exactly onto a simple type of convolutional neural network. This approach leads to a natural interpretation of feedforward connections in the convolutional layer and stacked intermediate pooling layers in terms of bystander effects and hierarchical tissue organization, respectively. These results serve as proof-of-principle for radiobiologically interpretable deep learning of normal tissue complication probability using large-scale imaging and dosimetry datasets.      
### 56.Asymptotic Average Mutual Information Over Finite Input Mixture Gamma Distributed Channels  [ :arrow_down: ](https://arxiv.org/pdf/2111.12822.pdf)
>  This letter establishes a unified analytical framework to study the asymptotic average mutual information (AMI) of mixture gamma (MG) distributed fading channels driven by finite input signals in the high signal-to-noise ratio (SNR) regime. It is found that the AMI converges to some constant as the average SNR increases and its rate of convergence (ROC) is determined by the coding gain and diversity order. Moreover, the derived results are used to investigate the asymptotic optimal power allocation policy of a bank of parallel fading channels having finite inputs. It is suggested that in the high SNR region, the sub-channel with a lower coding gain or diversity order should be allocated with more power. Finally, numerical results are provided to collaborate the theoretical analyses.      
### 57.MMSE Bound for MIMO Channel  [ :arrow_down: ](https://arxiv.org/pdf/2111.12819.pdf)
>  Detailed derivations of two bounds of the minimum mean-square error (MMSE) of complex-valued multiple-input multiple-output (MIMO) systems are proposed for performance evaluation. Particularly, the lower bound is derived based on a genie-aided MMSE estimator, whereas the upper bound is derived based on a maximum-likelihood (ML) estimator. Using the famous relationship between the mutual information (MI) and MMSE, two bounds for the MI are also derived, based on which we discuss the asymptotic behaviours of the average MI in the high-signal-to-noise ratio (SNR) regime. Theoretical analyses suggest that the average MI will converge its maximum as the SNR increases and the diversity order is the same as receive antenna number.      
### 58.Algorithm and Hardware Co-design for Reconfigurable CNN Accelerator  [ :arrow_down: ](https://arxiv.org/pdf/2111.12787.pdf)
>  Recent advances in algorithm-hardware co-design for deep neural networks (DNNs) have demonstrated their potential in automatically designing neural architectures and hardware designs. Nevertheless, it is still a challenging optimization problem due to the expensive training cost and the time-consuming hardware implementation, which makes the exploration on the vast design space of neural architecture and hardware design intractable. In this paper, we demonstrate that our proposed approach is capable of locating designs on the Pareto frontier. This capability is enabled by a novel three-phase co-design framework, with the following new features: (a) decoupling DNN training from the design space exploration of hardware architecture and neural architecture, (b) providing a hardware-friendly neural architecture space by considering hardware characteristics in constructing the search cells, (c) adopting Gaussian process to predict accuracy, latency and power consumption to avoid time-consuming synthesis and place-and-route processes. In comparison with the manually-designed ResNet101, InceptionV2 and MobileNetV2, we can achieve up to 5% higher accuracy with up to 3x speed up on the ImageNet dataset. Compared with other state-of-the-art co-design frameworks, our found network and hardware configuration can achieve 2% ~ 6% higher accuracy, 2x ~ 26x smaller latency and 8.5x higher energy efficiency.      
### 59.Semi-Supervised Audio Classification with Partially Labeled Data  [ :arrow_down: ](https://arxiv.org/pdf/2111.12761.pdf)
>  Audio classification has seen great progress with the increasing availability of large-scale datasets. These large datasets, however, are often only partially labeled as collecting full annotations is a tedious and expensive process. This paper presents two semi-supervised methods capable of learning with missing labels and evaluates them on two publicly available, partially labeled datasets. The first method relies on label enhancement by a two-stage teacher-student learning process, while the second method utilizes the mean teacher semi-supervised learning algorithm. Our results demonstrate the impact of improperly handling missing labels and compare the benefits of using different strategies leveraging data with few labels. Methods capable of learning with partially labeled data have the potential to improve models for audio classification by utilizing even larger amounts of data without the need for complete annotations.      
### 60.Lensless multicore-fiber microendoscope for real-time tailored light field generation with phase encoder neural network (CoreNet)  [ :arrow_down: ](https://arxiv.org/pdf/2111.12758.pdf)
>  The generation of tailored light with multi-core fiber (MCF) lensless microendoscopes is widely used in biomedicine. However, the computer-generated holograms (CGHs) used for such applications are typically generated by iterative algorithms, which demand high computation effort, limiting advanced applications like in vivo optogenetic stimulation and fiber-optic cell manipulation. The random and discrete distribution of the fiber cores induces strong spatial aliasing to the CGHs, hence, an approach that can rapidly generate tailored CGHs for MCFs is highly demanded. We demonstrate a novel phase encoder deep neural network (CoreNet), which can generate accurate tailored CGHs for MCFs at a near video-rate. Simulations show that CoreNet can speed up the computation time by two magnitudes and increase the fidelity of the generated light field compared to the conventional CGH techniques. For the first time, real-time generated tailored CGHs are on-the-fly loaded to the phase-only SLM for dynamic light fields generation through the MCF microendoscope in experiments. This paves the avenue for real-time cell rotation and several further applications that require real-time high-fidelity light delivery in biomedicine.      
### 61.Diagnosis of sickle cell anemia using AutoML on UV-Vis absorbance spectroscopy data  [ :arrow_down: ](https://arxiv.org/pdf/2111.12711.pdf)
>  Sickle cell anemia is a genetic disorder that is widespread in many regions of the world. Early diagnosis through screening and preventive treatments are known to reduce mortality in the case of sickle cell disease (SCD). In addition, the screening of individuals with the largely asymptomatic condition of sickle cell trait (SCT) is necessary to curtail the genetic propagation of the disease. However, the cost and complexity of conventional diagnostic methods limit the feasibility of early diagnosis of SCD and SCT in resource-limited areas worldwide. Recently, our group developed a low-cost UV-Vis absorbance spectroscopy based diagnostic test for SCD and SCT. Here, we propose an AutoML based approach to classify the raw spectra data obtained from the developed UV-Vis spectroscopy technique with high accuracy. The proposed approach can detect the presence of sickle hemoglobin with 100% sensitivity and 93.84% specificity. This study demonstrates the potential utility of the machine learning-based absorbance spectroscopy test for deployment in mass screening programs in resource-limited settings.      
