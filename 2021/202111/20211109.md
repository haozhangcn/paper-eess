# ArXiv eess --Tue, 9 Nov 2021
### 1.Data-driven Set-based Estimation of Polynomial Systems with Application to SIR Epidemics  [ :arrow_down: ](https://arxiv.org/pdf/2111.04704.pdf)
>  This paper proposes a data-driven set-based estimation algorithm for a class of nonlinear systems with polynomial nonlinearities. Using the system's input-output data, the proposed method computes in real-time a set that guarantees the inclusion of the system's state. Although the system is assumed to be polynomial type, the exact polynomial functions and their coefficients need not be known. To this end, the estimator relies on offline and online phases. The offline phase utilizes past input-output data to estimate a set of possible coefficients of the polynomial system. Then, using this estimated set of coefficients and the side information about the system, the online phase provides a set estimate of the state. Finally, the proposed methodology is evaluated through its application on SIR (Susceptible, Infected, Recovered) epidemic model.      
### 2.Automated pharyngeal phase detection and bolus localization in videofluoroscopic swallowing study: Killing two birds with one stone?  [ :arrow_down: ](https://arxiv.org/pdf/2111.04699.pdf)
>  The videofluoroscopic swallowing study (VFSS) is a gold-standard imaging technique for assessing swallowing, but analysis and rating of VFSS recordings is time consuming and requires specialized training and expertise. Researchers have demonstrated that it is possible to automatically detect the pharyngeal phase of swallowing and to localize the bolus in VFSS recordings via computer vision approaches, fostering the development of novel techniques for automatic VFSS analysis. However, training of algorithms to perform these tasks requires large amounts of annotated data that are seldom available. We demonstrate that the challenges of pharyngeal phase detection and bolus localization can be solved together using a single approach. We propose a deep-learning framework that jointly tackles pharyngeal phase detection and bolus localization in a weakly-supervised manner, requiring only the initial and final frames of the pharyngeal phase as ground truth annotations for the training. Our approach stems from the observation that bolus presence in the pharynx is the most prominent visual feature upon which to infer whether individual VFSS frames belong to the pharyngeal phase. We conducted extensive experiments with multiple convolutional neural networks (CNNs) on a dataset of 1245 VFSS clips from 59 healthy subjects. We demonstrated that the pharyngeal phase can be detected with an F1-score higher than 0.9. Moreover, by processing the class activation maps of the CNNs, we were able to localize the bolus with promising results, obtaining correlations with ground truth trajectories higher than 0.9, without any manual annotations of bolus location used for training purposes. Once validated on a larger sample of participants with swallowing disorders, our framework will pave the way for the development of intelligent tools for VFSS analysis to support clinicians in swallowing assessment.      
### 3.A Comparison of Model-Free and Model Predictive Control for Price Responsive Water Heaters  [ :arrow_down: ](https://arxiv.org/pdf/2111.04689.pdf)
>  We present a careful comparison of two model-free control algorithms, Evolution Strategies (ES) and Proximal Policy Optimization (PPO), with receding horizon model predictive control (MPC) for operating simulated, price responsive water heaters. Four MPC variants are considered: a one-shot controller with perfect forecasting yielding optimal control; a limited-horizon controller with perfect forecasting; a mean forecasting-based controller; and a two-stage stochastic programming controller using historical scenarios. In all cases, the MPC model for water temperature and electricity price are exact; only water demand is uncertain. For comparison, both ES and PPO learn neural network-based policies by directly interacting with the simulated environment under the same scenarios used by MPC. All methods are then evaluated on a separate one-week continuation of the demand time series. We demonstrate that optimal control for this problem is challenging, requiring more than 8-hour lookahead for MPC with perfect forecasting to attain the minimum cost. Despite this challenge, both ES and PPO learn good general purpose policies that outperform mean forecast and two-stage stochastic MPC controllers in terms of average cost and are more than two orders of magnitude faster at computing actions. We show that ES in particular can leverage parallelism to learn a policy in under 90 seconds using 1150 CPU cores.      
### 4.Minimum-lap-time Control Strategies for All-wheel Drive Electric Race Cars via Convex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2111.04650.pdf)
>  This paper presents a convex optimization framework to compute the minimum-lap-time control strategies of all-wheel drive (AWD) battery electric race cars, accounting for the grip limitations of the individual tyres. Specifically, we first derive the equations of motion (EOM) of the race car and simplify them to a convex form. Second, we leverage convex models of the electric motors (EMs) and battery, and frame the time-optimal final-drives design and EMs control problem in space domain. The resulting optimization problem is fully convex and can be efficiently solved with global optimality guarantees using second-order conic programming algorithms. Finally, we validate our modeling assumptions via the original non-convex EOM, and showcase our framework on the Formula Student Netherlands endurance race track. Thereby, we compare a torque vectoring with a fixed power split configuration, showing that via torque vectoring we can make a better use of the individual tyre grip, and significantly improve the achievable lap time by more than 6%. Finally, we present a design study investigating the respective impact of the front and rear EM size on lap time, revealing that the rear motor sizing is predominant due to the higher vertical rear tyre load caused by the center of pressure position and rearwards load transfer under acceleration.      
### 5.Privacy-Preserving Distributed Average Consensus in Finite Time using Random Gossip  [ :arrow_down: ](https://arxiv.org/pdf/2111.04642.pdf)
>  In this paper, we develop and analyze a gossip-based average consensus algorithm that enables all of the components of a distributed system, each with some initial value, to reach (approximate) average consensus on their initial values after executing a finite number of iterations, and without having to reveal the specific value they contribute to the average calculation. We consider a fully-connected (undirected) network in which each pair of components (nodes) can be randomly selected to perform pairwise standard gossip averaging of their values, and propose an enhancement that can be followed by each node that does not want to reveal its initial value to other (curious) nodes. We assume that curious nodes try to identify the initial values of other nodes but do not interfere in the computation in any other way; however, as a worst-case assumption, curious nodes are allowed to collaborate arbitrarily and are assumed to know the privacy-preserving strategy (but not the actual parameters chosen by the nodes that want to preserve their privacy). We characterize precisely conditions on the information exchange that guarantee privacy-preservation for a specific node. The protocol also provides a criterion that allows the nodes to determine, in a distributed manner (while running the enhanced gossip protocol), when to terminate their operation because approximate average consensus has been reached, i.e., all nodes have obtained values that are within a small distance from the exact average of their initial values.      
### 6.The complex-valued correlation coefficient accounts for binaural detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.04637.pdf)
>  Binaural hearing is one of the principal mechanisms enabling the localization of sound sources in space. In addition, binaural hearing also significantly improves the ability to detect signals in noise. Humans can detect interaurally anti-phasic tones in masking noise at sound levels 15 dB below the detection threshold of the equivalent in-phase tones. Intermediate thresholds result from detecting tones in noise with an interaural time difference (ITD). The ITD dependence has been most accurately accounted for by models using an internal delay-line mechanism. The delay lines, or an equivalent mechanism, however, have not been found in mammals. Alternative coding principles that do not include delay lines can explain many aspects of sound localization but have failed to account for some of the available data on binaural detection. By employing the complex-valued correlation coefficient, we show that a minimum assumption model can explain the outcome of a wide range of binaural detection experiments. The proposed mechanism requires fewer degrees of freedom when compared to delay-line models while arguably improving compatibility with mammalian physiology. The study also shows that the 2-dimensional acoustic feature space of complex correlation coefficients is at the same time a perceptually uniform space for binaural detection.      
### 7.Safe Control of Arbitrary Nonlinear Systems using Dynamic Extension  [ :arrow_down: ](https://arxiv.org/pdf/2111.04615.pdf)
>  Safe control for control-affine systems has been extensively studied. However, due to the complexity of system dynamics, it is challenging and time-consuming to apply these methods directly to non-control-affine systems, which cover a large group of dynamic systems, such as UAVs and systems with data-driven Neural Network Dynamic Models (NNDMs). Although all dynamic systems can be written in control-affine forms through dynamic extension, it remains unclear how to optimally design a computationally efficient algorithm to safely control the extended system. This paper addresses this challenge by proposing an optimal approach to synthesize safe control for the extended system under the framework of energy-function-based safe control. The proposed method first extends the energy function and then performs hyperparameter optimization to maximize performance while guaranteeing safety. It has been theoretically proved that our method guarantees safety (forward invariance of the safe set) and performance (bounded tracking error and smoother trajectories). It has been numerically validated that the proposed method is computationally efficient for non-control-affine systems.      
### 8.Learning Filterbanks for End-to-End Acoustic Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2111.04614.pdf)
>  Recent work on monaural source separation has shown that performance can be increased by using fully learned filterbanks with short windows. On the other hand it is widely known that, for conventional beamforming techniques, performance increases with long analysis windows. This applies also to most hybrid neural beamforming methods which rely on a deep neural network (DNN) to estimate the spatial covariance matrices. In this work we try to bridge the gap between these two worlds and explore fully end-to-end hybrid neural beamforming in which, instead of using the Short-Time-Fourier Transform, also the analysis and synthesis filterbanks are learnt jointly with the DNN. In detail, we explore two different types of learned filterbanks: fully learned and analytic. We perform a detailed analysis using the recent Clarity Challenge data and show that by using learnt filterbanks is possible to surpass oracle-mask based beamforming for short windows.      
### 9.A GN-model closed-form formula supporting ultra-low fiber loss and short fiber spans  [ :arrow_down: ](https://arxiv.org/pdf/2111.04584.pdf)
>  We report on a fully closed-form approximation of the GN model for Nyquist WDM systems that extends the range of applicability of previously available formulas to values of fiber loss and span loss that were not previously covered. In particular, so far, a closed-form formula was available for zero loss, and another for span loss of at least about 7 dB. The new formula is accurate over any fiber loss and any span loss value. The interest for this new formula is varied, ranging from hollow-core fibers to improving modeling of standard systems that present lumped loss along installed spans (such as splices or connectors).      
### 10.Dual Band GNSS Antenna Phase Center Characterization for Automotive Applications  [ :arrow_down: ](https://arxiv.org/pdf/2111.04569.pdf)
>  In this paper, a low-cost small size dual-band ceramic GNSS patch antenna is presented from design to real sample. A further study of this patch antenna illustrates the absolute phase center variation measured in an indoor range to achieve a received signal phase error correction. In addition, this low-cost antenna solution is investigated when integrated into a standard multi-band automotive antenna product. This product is evaluated both on its own in an indoor range and on a typical vehicle roof at an outdoor range. By using this evaluation file to estimate the receiver position could achieve phase motion error-free result.      
### 11.Simultaneous estimation of wall and object parameters in TWR using deep neural network  [ :arrow_down: ](https://arxiv.org/pdf/2111.04568.pdf)
>  This paper presents a deep learning model for simultaneously estimating target and wall parameters in Through-the-Wall Radar. In this work, we consider two modes: single-target and two-targets. In both cases, we consider the permittivity and thickness for the wall, as well as the two-dimensional coordinates of the target's center and permittivity. This means that in the case of a single target, we estimate five values, whereas, in the case of two targets, we estimate eight values simultaneously, each of which represents the mentioned parameters. We discovered that when using deep neural networks to solve the target locating problem, giving the model more parameters of the problem increases the location accuracy. As a result, we included two wall parameters in the problem and discovered that the accuracy of target locating improves while the wall parameters are estimated. We were able to estimate the parameters of wall permittivity and thickness, as well as two-dimensional coordinates and permittivity of targets in single-target and two-target modes with 99\% accuracy by using a deep neural network model.      
### 12.Compact Heterogeneous Integration for Next Generation High Frequency Scalable Array with Miniaturized and Efficient Power Delivery Network  [ :arrow_down: ](https://arxiv.org/pdf/2111.04567.pdf)
>  Next generation communication and sensing require enabling technologies for miniaturized and efficient heterogeneous systems while integrating technologies ranging from silicon to compound semiconductors and from photonic chips to micro-sensors. To this end, high frequency and mm-wave (MMW) lossy parasitics and delay between modules need to be significantly reduced to minimize area, loss and thermal heating of inter-chip wiring and power delivery networks. In this work, we propose novel approaches to achieve an efficient wideband MMW array integrations. The proposed techniques are built upon the following: 1) fixed antenna package buildup for every element with differential excitation on two half sides of array to reduce the fabrication cost and the IC-to-antenna routing loss; 2) miniaturized aperture coupled local oscillator (LO) and intermediate frequency (IF) power delivery feed distribution to minimize the packaging stacked layers and their loss. The proposed 16-element antenna array is integrated which 4 dies in 2x2 configurations implemented in a 90-nm SiGe BiCMOS process using compact Weaver image-selection architecture (WISA). The proposed miniaturized and efficient architecture from circuit and chip level to package level results in 1.5 GHz modulation bandwidth for 64 QAM (9 Gb/s) and 2 GHz for 16 QAM with only +-2 dB EVM variation over the 20% FBW (71-86 GHz). The system produces 30-dBm EIRP with enhanced efficiency of 25% EIRP/PDC over the bandwidth      
### 13.RF-Net: a Unified Meta-learning Framework for RF-enabled One-shot Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.04566.pdf)
>  Radio-Frequency (RF) based device-free Human Activity Recognition (HAR) rises as a promising solution for many applications. However, device-free (or contactless) sensing is often more sensitive to environment changes than device-based (or wearable) sensing. Also, RF datasets strictly require on-line labeling during collection, starkly different from image and text data collections where human interpretations can be leveraged to perform off-line labeling. Therefore, existing solutions to RF-HAR entail a laborious data collection process for adapting to new environments. To this end, we propose RF-Net as a meta-learning based approach to one-shot RF-HAR; it reduces the labeling efforts for environment adaptation to the minimum level. In particular, we first examine three representative RF sensing techniques and two major meta-learning approaches. The results motivate us to innovate in two designs: i) a dual-path base HAR network, where both time and frequency domains are dedicated to learning powerful RF features including spatial and attention-based temporal ones, and ii) a metric-based meta-learning framework to enhance the fast adaption capability of the base network, including an RF-specific metric module along with a residual classification module. We conduct extensive experiments based on all three RF sensing techniques in multiple real-world indoor environments; all results strongly demonstrate the efficacy of RF-Net compared with state-of-the-art baselines.      
### 14.Calibration of Polarimetric Radar Data using the Sylvester Equation in a Pauli Basis  [ :arrow_down: ](https://arxiv.org/pdf/2111.04565.pdf)
>  In this paper we develop a new approach to the calibration of polarimetric radar data based on two key ideas. The first is the use of in-scene trihedral corner reflectors not only for radiometric and geometric calibration but also to completely remove any receiver distortion components. Secondly, we then show that the remaining transmitter distortion acts as a similarity transformation of the true scattering matrix. This leads us to employ a change of base to the Pauli matrix components. We show that in this basis calibration and the effects of Faraday rotation become much simplified and for example by using reciprocity alone we can then solve for copolar channel imbalance. Finally by using an uncalibrated symmetric point target of opportunity we can estimate cross-talks and hence fully solve the calibration problem without the need for using clutter averaging or symmetry assumptions in the covariance matrix as used in many other algorithms.      
### 15.Human Activity Recognition using Attribute-Based Neural Networks and Context Information  [ :arrow_down: ](https://arxiv.org/pdf/2111.04564.pdf)
>  We consider human activity recognition (HAR) from wearable sensor data in manual-work processes, like warehouse order-picking. Such structured domains can often be partitioned into distinct process steps, e.g., packaging or transporting. Each process step can have a different prior distribution over activity classes, e.g., standing or walking, and different system dynamics. Here, we show how such context information can be integrated systematically into a deep neural network-based HAR system. Specifically, we propose a hybrid architecture that combines a deep neural network-that estimates high-level movement descriptors, attributes, from the raw-sensor data-and a shallow classifier, which predicts activity classes from the estimated attributes and (optional) context information, like the currently executed process step. We empirically show that our proposed architecture increases HAR performance, compared to state-of-the-art methods. Additionally, we show that HAR performance can be further increased when information about process steps is incorporated, even when that information is only partially correct.      
### 16.Decentralized Coordinated State Estimation in Integrated Transmission and Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.04555.pdf)
>  Current transmission and distribution system states are mostly unobservable to each other, and state estimation is separately conducted in the two systems owing to the differences in network structures and analytical models. The large-scale integration of transmission and active distribution systems calls for an effective solution to global state estimation. Unlike existing independent state estimation methods on both levels of these systems, we propose a decentralized coordinated transmission and distribution system state estimation (C-TDSE) method. This method enables accurate monitoring of the integrated systems with a global reference in a decentralized manner and reconciles the mismatches of voltages and powers on the boundaries of the systems. The comparative analysis on the integrated transmission and distribution systems points to improved estimation results relative to the independent state estimation methods.      
### 17.Triple-level Model Inferred Collaborative Network Architecture for Video Deraining  [ :arrow_down: ](https://arxiv.org/pdf/2111.04459.pdf)
>  Video deraining is an important issue for outdoor vision systems and has been investigated extensively. However, designing optimal architectures by the aggregating model formation and data distribution is a challenging task for video deraining. In this paper, we develop a model-guided triple-level optimization framework to deduce network architecture with cooperating optimization and auto-searching mechanism, named Triple-level Model Inferred Cooperating Searching (TMICS), for dealing with various video rain circumstances. In particular, to mitigate the problem that existing methods cannot cover various rain streaks distribution, we first design a hyper-parameter optimization model about task variable and hyper-parameter. Based on the proposed optimization model, we design a collaborative structure for video deraining. This structure includes Dominant Network Architecture (DNA) and Companionate Network Architecture (CNA) that is cooperated by introducing an Attention-based Averaging Scheme (AAS). To better explore inter-frame information from videos, we introduce a macroscopic structure searching scheme that searches from Optical Flow Module (OFM) and Temporal Grouping Module (TGM) to help restore latent frame. In addition, we apply the differentiable neural architecture searching from a compact candidate set of task-specific operations to discover desirable rain streaks removal architectures automatically. Extensive experiments on various datasets demonstrate that our model shows significant improvements in fidelity and temporal consistency over the state-of-the-art works. Source code is available at <a class="link-external link-https" href="https://github.com/vis-opt-group/TMICS" rel="external noopener nofollow">this https URL</a>.      
### 18.RawBoost: A Raw Data Boosting and Augmentation Method applied to Automatic Speaker Verification Anti-Spoofing  [ :arrow_down: ](https://arxiv.org/pdf/2111.04433.pdf)
>  This paper introduces RawBoost, a data boosting and augmentation method for the design of more reliable spoofing detection solutions which operate directly upon raw waveform inputs. While RawBoost requires no additional data sources, e.g. noise recordings or impulse responses and is data, application and model agnostic, it is designed for telephony scenarios. Based upon the combination of linear and non-linear convolutive noise, impulsive signal-dependent additive noise and stationary signal-independent additive noise, RawBoost models nuisance variability stemming from, e.g., encoding, transmission, microphones and amplifiers, and both linear and non-linear distortion. Experiments performed using the ASVspoof 2021 logical access database show that RawBoost improves the performance of a state-of-the-art raw end-to-end baseline system by 27% relative and is only outperformed by solutions that either depend on external data or that require additional intervention at the model level.      
### 19.Robust dynamic self-triggered control for nonlinear systems using hybrid Lyapunov functions  [ :arrow_down: ](https://arxiv.org/pdf/2111.04347.pdf)
>  Self-triggered control (STC) is a resource efficient approach to determine sampling instants for Networked Control Systems. At each sampling instant, an STC mechanism determines not only the control inputs but also the next sampling instant. In this article, an STC framework for perturbed nonlinear systems is proposed. In the framework, a dynamic variable is used in addition to current state information to determine the next sampling instant, rendering the STC mechanism dynamic. Using dynamic variables has proven to be powerful for increasing sampling intervals for the closely related concept of event-triggered control, but has so far not been exploited for STC. Two variants of the dynamic STC framework are presented. The first variant can be used without further knowledge on the disturbance and leads to guarantees on input-to-state stability. The second variant exploits a known disturbance bound to determine sampling instants and guarantees asymptotic stability of a set containing the origin. In both cases, hybrid Lyapunov function techniques are used to derive the respective stability guarantees. Different choices for the dynamics of the dynamic variable, that lead to different particular STC mechanisms, are presented for both variants of the framework. The resulting dynamic STC mechanisms are illustrated with two numerical examples to emphasize their benefits in comparison to existing static STC approaches.      
### 20.Inter-channel Conv-TasNet for multichannel speech enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2111.04312.pdf)
>  Speech enhancement in multichannel settings has been realized by utilizing the spatial information embedded in multiple microphone signals. Moreover, deep neural networks (DNNs) have been recently advanced in this field; however, studies on the efficient multichannel network structure fully exploiting spatial information and inter-channel relationships is still in its early stages. In this study, we propose an end-to-end time-domain speech enhancement network that can facilitate the use of inter-channel relationships at individual layers of a DNN. The proposed technique is based on a fully convolutional time-domain audio separation network (Conv-TasNet), originally developed for speech separation tasks. We extend Conv-TasNet into several forms that can handle multichannel input signals and learn inter-channel relationships. To this end, we modify the encoder-mask-decoder structures of the network to be compatible with 3-D tensors defined over spatial channels, features, and time dimensions. In particular, we conduct extensive parameter analyses on the convolution structure and propose independent assignment of the depthwise and 1$\times$1 convolution layers to the feature and spatial dimensions, respectively. We demonstrate that the enriched inter-channel information from the proposed network plays a significant role in suppressing noisy signals impinging from various directions. The proposed inter-channel Conv-TasNet outperforms the state-of-the-art multichannel variants of neural networks, even with one-tenth of their parameter size. The performance of the proposed model is evaluated using the CHiME-3 dataset, which exhibits a remarkable improvement in SDR, PESQ, and STOI.      
### 21.State Drift and Gait Plan in Feedback Linearization Control of A Tilt Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2111.04307.pdf)
>  To stabilize a conventional quadrotor, simplified equivalent vehicles (e.g., autonomous car) are developed to test the designed controller [1]. Based on that, various controllers based on feedback linearization have been developed [2,3]. With the recently developed concept of tilt-rotor [4], there lacks the simplified/equivalent model, however. Indeed, the tilt structure is relatively unusual in vehicles. In this research, we put forward a unique fictional vehicle with tilt structure, which is to help evaluate the property of the tilt-structure-aimed controllers. One phenomenon (state drift) in controlling an over-actuated tilt structure by feedback linearization is presented subsequently. State drift can be easily neglected and is not paid attention to in the current researches in tilt-rotor controllers design so far. We report this phenomenon with providing a potential approach to avoid this behavior.      
### 22.Dense Representative Tooth Landmark/axis Detection Network on 3D Model  [ :arrow_down: ](https://arxiv.org/pdf/2111.04212.pdf)
>  Artificial intelligence (AI) technology is increasingly used for digital orthodontics, but one of the challenges is to automatically and accurately detect tooth landmarks and axes. This is partly because of sophisticated geometric definitions of them, and partly due to large variations among individual tooth and across different types of tooth. As such, we propose a deep learning approach with a labeled dataset by professional dentists to the tooth landmark/axis detection on tooth model that are crucial for orthodontic treatments. Our method can extract not only tooth landmarks in the form of point (e.g. cusps), but also axes that measure the tooth angulation and inclination. The proposed network takes as input a 3D tooth model and predicts various types of the tooth landmarks and axes. Specifically, we encode the landmarks and axes as dense fields defined on the surface of the tooth model. This design choice and a set of added components make the proposed network more suitable for extracting sparse landmarks from a given 3D tooth model. Extensive evaluation of the proposed method was conducted on a set of dental models prepared by experienced dentists. Results show that our method can produce tooth landmarks with high accuracy. Our method was examined and justified via comparison with the state-of-the-art methods as well as the ablation studies.      
### 23.Quantitative Resilience of Generalized Integrators  [ :arrow_down: ](https://arxiv.org/pdf/2111.04163.pdf)
>  To design critical systems engineers must be able to prove that their system can continue with its mission even after losing control authority over some of its actuators. Such a malfunction results in actuators producing possibly undesirable inputs over which the controller has real-time readings but no control. By definition, a system is resilient if it can still reach a target after a partial loss of control authority. However, after such a malfunction, a resilient system might be significantly slower to reach a target compared to its initial capabilities. To quantify this loss of performance we introduce the notion of quantitative resilience as the maximal ratio of the minimal times required to reach any target for the initial and malfunctioning systems. Naive computation of quantitative resilience directly from the definition is a complex task as it requires solving four nested, possibly nonlinear, optimization problems. The main technical contribution of this work is to provide an efficient method to compute quantitative resilience of control systems with multiple integrators and nonsymmetric input sets. Relying on control theory and on two novel geometric results we reduce the computation of quantitative resilience to a linear optimization problem. We illustrate our method on two numerical examples: a trajectory controller for low-thrust spacecrafts and a UAV with eight propellers.      
### 24.Data-Efficient Deep Reinforcement Learning for Attitude Control of Fixed-Wing UAVs: Field Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2111.04153.pdf)
>  Attitude control of fixed-wing unmanned aerial vehicles (UAVs)is a difficult control problem in part due to uncertain nonlinear dynamics, actuator constraints, and coupled longitudinal and lateral motions. Current state-of-the-art autopilots are based on linear control and are thus limited in their effectiveness and performance. Deep reinforcement learning (DRL) is a machine learning method to automatically discover optimal control laws through interaction with the controlled system, that can handle complex nonlinear dynamics. We show in this paper that DRL can successfully learn to perform attitude control of a fixed-wing UAV operating directly on the original nonlinear dynamics, requiring as little as three minutes of flight data. We initially train our model in a simulation environment and then deploy the learned controller on the UAV in flight tests, demonstrating comparable performance to the state-of-the-art ArduPlaneproportional-integral-derivative (PID) attitude controller with no further online learning required. To better understand the operation of the learned controller we present an analysis of its behaviour, including a comparison to the existing well-tuned PID controller.      
### 25.Optimization of the Model Predictive Control Meta-Parameters Through Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.04146.pdf)
>  Model predictive control (MPC) is increasingly being considered for control of fast systems and embedded applications. However, the MPC has some significant challenges for such systems. Its high computational complexity results in high power consumption from the control algorithm, which could account for a significant share of the energy resources in battery-powered embedded systems. The MPC parameters must be tuned, which is largely a trial-and-error process that affects the control performance, the robustness and the computational complexity of the controller to a high degree. In this paper, we propose a novel framework in which any parameter of the control algorithm can be jointly tuned using reinforcement learning(RL), with the goal of simultaneously optimizing the control performance and the power usage of the control algorithm. We propose the novel idea of optimizing the meta-parameters of MPCwith RL, i.e. parameters affecting the structure of the MPCproblem as opposed to the solution to a given problem. Our control algorithm is based on an event-triggered MPC where we learn when the MPC should be re-computed, and a dual mode MPC and linear state feedback control law applied in between MPC computations. We formulate a novel mixture-distribution policy and show that with joint optimization we achieve improvements that do not present themselves when optimizing the same parameters in isolation. We demonstrate our framework on the inverted pendulum control task, reducing the total computation time of the control system by 36% while also improving the control performance by 18.4% over the best-performing MPC baseline.      
### 26.Learning-based Remote Radio Head Selection and Localization in Distributed Antenna System  [ :arrow_down: ](https://arxiv.org/pdf/2111.04106.pdf)
>  In this work, we consider estimating user positions in a spatially distributed antenna system (DAS) from the uplink channel state information (CSI). However, with the increased number of remote radio heads (RRHs), collecting CSI at a central unit (CU) can significantly increase the fronthaul overhead and computational complexity of the CU. This problem can be mitigated by selecting a subset of RRHs. Thus, we present a deep learning-based approach to select a subset of RRHs for wireless localization. We employ an RRH selection layer that is jointly trained with the rest of the network and learn the model parameters as well as the set of selected RRHs. We show that the selection strategy comes at a relatively small cost of localization performance. Nonetheless, by comparison to a trivial approach based on the maximization of the channel gain, we show that the proposed method leads to significant performance gains in a propagation environment dominated by non-line-of-sight.      
### 27.Acquisition-invariant brain MRI segmentation with informative uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2111.04094.pdf)
>  Combining multi-site data can strengthen and uncover trends, but is a task that is marred by the influence of site-specific covariates that can bias the data and therefore any downstream analyses. Post-hoc multi-site correction methods exist but have strong assumptions that often do not hold in real-world scenarios. Algorithms should be designed in a way that can account for site-specific effects, such as those that arise from sequence parameter choices, and in instances where generalisation fails, should be able to identify such a failure by means of explicit uncertainty modelling. This body of work showcases such an algorithm, that can become robust to the physics of acquisition in the context of segmentation tasks, while simultaneously modelling uncertainty. We demonstrate that our method not only generalises to complete holdout datasets, preserving segmentation quality, but does so while also accounting for site-specific sequence choices, which also allows it to perform as a harmonisation tool.      
### 28.Texture-enhanced Light Field Super-resolution with Spatio-Angular Decomposition Kernels  [ :arrow_down: ](https://arxiv.org/pdf/2111.04069.pdf)
>  Despite the recent progress in light field super-resolution (LFSR) achieved by convolutional neural networks, the correlation information of light field (LF) images has not been sufficiently studied and exploited due to the complexity of 4D LF data. To cope with such high-dimensional LF data, most of the existing LFSR methods resorted to decomposing it into lower dimensions and subsequently performing optimization on the decomposed sub-spaces. However, these methods are inherently limited as they neglected the characteristics of the decomposition operations and only utilized a limited set of LF sub-spaces ending up failing to comprehensively extract spatio-angular features and leading to a performance bottleneck. To overcome these limitations, in this paper, we thoroughly discover the potentials of LF decomposition and propose a novel concept of decomposition kernels. In particular, we systematically unify the decomposition operations of various sub-spaces into a series of such decomposition kernels, which are incorporated into our proposed Decomposition Kernel Network (DKNet) for comprehensive spatio-angular feature extraction. The proposed DKNet is experimentally verified to achieve substantial improvements by 1.35 dB, 0.83 dB, and 1.80 dB PSNR in 2x, 3x and 4x LFSR scales, respectively, when compared with the state-of-the-art methods. To further improve DKNet in producing more visually pleasing LFSR results, based on the VGG network, we propose a LFVGG loss to guide the Texture-Enhanced DKNet (TE-DKNet) to generate rich authentic textures and enhance LF images' visual quality significantly. We also propose an indirect evaluation metric by taking advantage of LF material recognition to objectively assess the perceptual enhancement brought by the LFVGG loss.      
### 29.LiMuSE: Lightweight Multi-modal Speaker Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2111.04063.pdf)
>  The past several years have witnessed significant progress in modeling the Cocktail Party Problem in terms of speech separation and speaker extraction. In recent years, multi-modal cues, including spatial information, facial expression and voiceprint, are introduced to speaker extraction task to serve as complementary information to each other to achieve better performance. However, the front-end model, for speaker extraction, become large and hard to deploy on a resource-constrained device. In this paper, we address the aforementioned problem with novel model architectures and model compression techniques, and propose a lightweight multi-modal framework for speaker extraction (dubbed LiMuSE), which adopts group communication (GC) to split multi-modal high-dimension features into groups of low-dimension features with smaller width which could be run in parallel, and further uses an ultra-low bit quantization strategy to achieve lower model size. The experiments on the GRID dataset show that incorporating GC into the multi-modal framework achieves on par or better performance with 24.86 times fewer parameters, and applying the quantization strategy to the GC-equipped model further obtains about 9 times compression ratio while maintaining a comparable performance compared with baselines. Our code will be available at <a class="link-external link-https" href="https://github.com/aispeech-lab/LiMuSE" rel="external noopener nofollow">this https URL</a>.      
### 30.A matrix theoretic characterization of the strongly reachable subspace  [ :arrow_down: ](https://arxiv.org/pdf/2111.04059.pdf)
>  In this paper, we provide novel characterizations of the weakly unobservable and the strongly reachable subspaces corresponding to a given state-space system. These characterizations provide closed-form representations for the said subspaces. In this process, we establish that the strongly reachable subspace is intimately related to the space of admissible impulsive inputs. We also show how to calculate the dimensions of these subspaces from the transfer matrix of the system.      
### 31.Multi-Fake Evolutionary Generative Adversarial Networks for Imbalance Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.04019.pdf)
>  This paper presents a novel multi-fake evolutionary generative adversarial network(MFEGAN) for handling imbalance hyperspectral image classification. It is an end-to-end approach in which different generative objective losses are considered in the generator network to improve the classification performance of the discriminator network. Thus, the same discriminator network has been used as a standard classifier by embedding the classifier network on top of the discriminating function. The effectiveness of the proposed method has been validated through two hyperspectral spatial-spectral data sets. The same generative and discriminator architectures have been utilized with two different GAN objectives for a fair performance comparison with the proposed method. It is observed from the experimental validations that the proposed method outperforms the state-of-the-art methods with better classification performance.      
### 32.The Three-Dimensional Structural Configuration of the Central Retinal Vessel Trunk and Branches as a Glaucoma Biomarker  [ :arrow_down: ](https://arxiv.org/pdf/2111.03997.pdf)
>  Purpose: To assess whether the three-dimensional (3D) structural configuration of the central retinal vessel trunk and its branches (CRVT&amp;B) could be used as a diagnostic marker for glaucoma. Method: We trained a deep learning network to automatically segment the CRVT&amp;B from the B-scans of the optical coherence tomography (OCT) volume of the optic nerve head (ONH). Subsequently, two different approaches were used for glaucoma diagnosis using the structural configuration of the CRVT&amp;B as extracted from the OCT volumes. In the first approach, we aimed to provide a diagnosis using only 3D CNN and the 3D structure of the CRVT&amp;B. For the second approach, we projected the 3D structure of the CRVT&amp;B orthographically onto three planes to obtain 2D images, and then a 2D CNN was used for diagnosis. The segmentation accuracy was evaluated using the Dice coefficient, whereas the diagnostic accuracy was assessed using the area under the receiver operating characteristic curves (AUC). The diagnostic performance of the CRVT&amp;B was also compared with that of retinal nerve fiber layer (RNFL) thickness. Results: Our segmentation network was able to efficiently segment retinal blood vessels from OCT scans. On a test set, we achieved a Dice coefficient of 0.81\pm0.07. The 3D and 2D diagnostic networks were able to differentiate glaucoma from non-glaucoma subjects with accuracies of 82.7% and 83.3%, respectively. The corresponding AUCs for CRVT&amp;B were 0.89 and 0.90, higher than those obtained with RNFL thickness alone. Conclusions: Our work demonstrated that the diagnostic power of the CRVT&amp;B is superior to that of a gold-standard glaucoma parameter, i.e., RNFL thickness. Our work also suggested that the major retinal blood vessels form a skeleton -- the configuration of which may be representative of major ONH structural changes as typically observed with the development and progression of glaucoma.      
### 33.Maximizing Unambiguous Velocity Range in Phase-contrast MRI with Multipoint Encoding  [ :arrow_down: ](https://arxiv.org/pdf/2111.03990.pdf)
>  In phase-contrast magnetic resonance imaging (PC-MRI), the velocity of spins at a voxel is encoded in the image phase. The strength of the velocity encoding gradient offers a trade-off between the velocity-to-noise ratio (VNR) and the extent of phase aliasing. Phase differences provide invariance to an unknown background phase. Existing literature proposes processing a reduced set of phase difference equations, simplifying the phase unwrapping problem at the expense of VNR or unaliased range of velocities, or both. Here, we demonstrate that the fullest unambiguous range of velocities is a parallelepiped, which can be accessed by jointly processing all phase differences. The joint processing also minimizes the velocity-to-noise ratio. The simple understanding of the unambiguous parallelepiped provides the potential for analyzing new multi-point acquisitions for an enhanced range of unaliased velocities; two examples are given.      
### 34.Planning for net zero by 2050, what HVAC system interventions will today's code minimum commercial buildings require?  [ :arrow_down: ](https://arxiv.org/pdf/2111.03899.pdf)
>  Heating, Ventilation and Air conditioning (HVAC) systems account for approximately 40% of the total energy used by buildings in the USA. To reduce this consumption States enforce minimum energy codes that currently range from strict (ASHRAE 90.1-2016) to relaxed (ASHRAE 90.1-2007) with some states following no particular standard. To reach as close as possible to net zero carbon and energy, each statewide energy code requires different levels of interventions for each code minimum building. This paper presents a collection of potential HVAC retrofits to transition each State's current code minimum buildings towards the goal of net zero to achieve a carbon free future by 2050. The study shall use a large array of code minimum criteria and climate zones covering the 48 contiguous United States to determine the most successful interventions at reducing the energy use of buildings meeting today's energy codes. Office use type has been selected for the study as they account for 18% of total buildings and close to 19% of the total commercial floorspace. A number of interventions will be applied to this use type that will vary based on current code and climate zone; however, a common theme will be electrification through the use of heat pump technology. Each intervention will be scored based on energy and carbon savings, along with level of difficulty and cost. The study not only provides a comprehensive transition guideline toward the net zero energy and carbon but also predicts the future project opportunities.      
### 35.Demystifying Deep Learning Models for Retinal OCT Disease Classification using Explainable AI  [ :arrow_down: ](https://arxiv.org/pdf/2111.03890.pdf)
>  In the world of medical diagnostics, the adoption of various deep learning techniques is quite common as well as effective, and its statement is equally true when it comes to implementing it into the retina Optical Coherence Tomography (OCT) sector, but (i)These techniques have the black box characteristics that prevent the medical professionals to completely trust the results generated from them (ii)Lack of precision of these methods restricts their implementation in clinical and complex cases (iii)The existing works and models on the OCT classification are substantially large and complicated and they require a considerable amount of memory and computational power, reducing the quality of classifiers in real-time applications. To meet these problems, in this paper a self-developed CNN model has been proposed which is comparatively smaller and simpler along with the use of Lime that introduces Explainable AI to the study and helps to increase the interpretability of the model. This addition will be an asset to the medical experts for getting major and detailed information and will help them in making final decisions and will also reduce the opacity and vulnerability of the conventional deep learning models.      
### 36.Trajectory PHD Filter with Unknown Detection Profile and Clutter Rate  [ :arrow_down: ](https://arxiv.org/pdf/2111.03871.pdf)
>  In this paper, we derive the robust TPHD (R-TPHD) filter, which can adaptively learn the unknown detection profile history and clutter rate. The R-TPHD filter is derived by obtaining the best Poisson posterior density approximation over trajectories on hybrid and augmented state space by minimizing the Kullback-Leibler divergence (KLD). Because of the huge computational burden and the short-term stability of the detection profile, we also propose the R-TPHD filter with unknown detection profile only at current time as an approximation. The Beta-Gaussian mixture model is proposed for the implementation, which is referred to as the BG-R-TPHD filter and we also propose a L-scan approximation for the BG-R-TPHD filter, which possesses lower computational burden.      
### 37.AI-based Radio Resource Management and Trajectory Design for PD-NOMA Communication in IRS-UAV Assisted Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.03869.pdf)
>  In this paper, we consider that the unmanned aerial vehicles (UAVs) with attached intelligent reflecting surfaces (IRSs) play the role of flying reflectors that reflect the signal of users to the destination, and utilize the power-domain non-orthogonal multiple access (PD-NOMA) scheme in the uplink. We investigate the benefits of the UAV-IRS on the internet of things (IoT) networks that improve the freshness of collected data of the IoT devices via optimizing power, sub-carrier, and trajectory variables, as well as, the phase shift matrix elements. We consider minimizing the average age-of-information (AAoI) of users subject to the maximum transmit power limitations, PD-NOMA-related restriction, and the constraints related to UAV's movement. The optimization problem consists of discrete and continuous variables. Hence, we divide the resource allocation problem into two sub-problems and use two different reinforcement learning (RL) based algorithms to solve them, namely the double deep Qnetwork (DDQN) and a proximal policy optimization (PPO). Our numerical results illustrate the performance gains that can be achieved for IRS enabled UAV communication systems. Moreover, we compare our deep RL (DRL) based algorithm with matching algorithm and random trajectory, showing the combination of DDQN and PPO algorithm proposed in this paper performs 10% and 15% better than matching algorithm and random-trajectory algorithm, respectively.      
### 38.Multi-target Joint Tracking and Classification Using the Trajectory PHD Filter  [ :arrow_down: ](https://arxiv.org/pdf/2111.03868.pdf)
>  To account for joint tracking and classification (JTC) of multiple targets from observation sets in presence of detection uncertainty, noise and clutter, this paper develops a new trajectory probability hypothesis density (TPHD) filter, which is referred to as the JTC-TPHD filter. The JTC-TPHD filter classifies different targets based on their motion models and each target is assigned with multiple class hypotheses. By using this strategy, we can not only obtain the category information of the targets, but also a more accurate trajectory estimation than the traditional TPHD filter. The JTC-TPHD filter is derived by finding the best Poisson posterior approximation over trajectories on an augmented state space using the Kullback-Leibler divergence (KLD) minimization. The Gaussian mixture is adopted for the implementation, which is referred to as the GM-JTC-TPHD filter. The L-scan approximation is also presented for the GM-JTC-TPHD filter, which possesses lower computational burden. Simulation results show that the GM-JTC-TPHD filter can classify targets correctly and obtain accurate trajectory estimation.      
### 39.Trajectory PHD and CPHD Filters with Unknown Detection Profile  [ :arrow_down: ](https://arxiv.org/pdf/2111.03863.pdf)
>  Compared to the probability hypothesis density (PHD) and cardinalized PHD (CPHD) filters, the trajectory PHD (TPHD) and trajectory CPHD (TCPHD) filters are for sets of trajectories, and thus are able to produce trajectory estimates with better estimation performance. In this paper, we develop the TPHD and TCPHD filters which can adaptively learn the history of the unknown target detection probability, and therefore they can perform more robustly in scenarios where targets are with unknown and time-varying detection probabilities. These filters are referred to as the unknown TPHD (U-TPHD) and unknown TCPHD (U-TCPHD) <a class="link-external link-http" href="http://filters.By" rel="external noopener nofollow">this http URL</a> minimizing the Kullback-Leibler divergence (KLD), the U-TPHD and U-TCPHD filters can obtain, respectively, the best Poisson and independent identically distributed (IID) density approximations over the augmented sets of trajectories. For computational efficiency, we also propose the U-TPHD and U-TCPHD filters that only consider the unknown detection profile at the current time. Specifically, the Beta-Gaussian mixture method is adopted for the implementation of proposed filters, which are referred to as the BG-U-TPHD and BG-U-TCPHD filters. The L-scan approximations of these filters with much lower computational burden are also presented. Finally, various simulation results demonstrate that the BG-U-TPHD and BG-U-TCPHD filters can achieve robust tracking performance to adapt to unknown detection profile. Besides, it also shows that usually a small value of the L-scan approximation can achieve almost full efficiency of both filters but with a much lower computational costs.      
### 40.A new baseline for retinal vessel segmentation: Numerical identification and correction of methodological inconsistencies affecting 100+ papers  [ :arrow_down: ](https://arxiv.org/pdf/2111.03853.pdf)
>  In the last 15 years, the segmentation of vessels in retinal images has become an intensively researched problem in medical imaging, with hundreds of algorithms published. One of the de facto benchmarking data sets of vessel segmentation techniques is the DRIVE data set. Since DRIVE contains a predefined split of training and test images, the published performance results of the various segmentation techniques should provide a reliable ranking of the algorithms. Including more than 100 papers in the study, we performed a detailed numerical analysis of the coherence of the published performance scores. We found inconsistencies in the reported scores related to the use of the field of view (FoV), which has a significant impact on the performance scores. We attempted to eliminate the biases using numerical techniques to provide a more realistic picture of the state of the art. Based on the results, we have formulated several findings, most notably: despite the well-defined test set of DRIVE, most rankings in published papers are based on non-comparable figures; in contrast to the near-perfect accuracy scores reported in the literature, the highest accuracy score achieved to date is 0.9582 in the FoV region, which is 1% higher than that of human annotators. The methods we have developed for identifying and eliminating the evaluation biases can be easily applied to other domains where similar problems may arise.      
### 41.Multimodal PET/CT Tumour Segmentation and Prediction of Progression-Free Survival using a Full-Scale UNet with Attention  [ :arrow_down: ](https://arxiv.org/pdf/2111.03848.pdf)
>  Segmentation of head and neck (H\&amp;N) tumours and prediction of patient outcome are crucial for patient's disease diagnosis and treatment monitoring. Current developments of robust deep learning models are hindered by the lack of large multi-centre, multi-modal data with quality annotations. The MICCAI 2021 HEad and neCK TumOR (HECKTOR) segmentation and outcome prediction challenge creates a platform for comparing segmentation methods of the primary gross target volume on fluoro-deoxyglucose (FDG)-PET and Computed Tomography images and prediction of progression-free survival in H\&amp;N oropharyngeal cancer.For the segmentation task, we proposed a new network based on an encoder-decoder architecture with full inter- and intra-skip connections to take advantage of low-level and high-level semantics at full scales. Additionally, we used Conditional Random Fields as a post-processing step to refine the predicted segmentation maps. We trained multiple neural networks for tumor volume segmentation, and these segmentations were ensembled achieving an average Dice Similarity Coefficient of 0.75 in cross-validation, and 0.76 on the challenge testing data set. For prediction of patient progression free survival task, we propose a Cox proportional hazard regression combining clinical, radiomic, and deep learning features. Our survival prediction model achieved a concordance index of 0.82 in cross-validation, and 0.62 on the challenge testing data set.      
### 42.Deep Noise Suppression Maximizing Non-Differentiable PESQ Mediated by a Non-Intrusive PESQNet  [ :arrow_down: ](https://arxiv.org/pdf/2111.03847.pdf)
>  Speech enhancement employing deep neural networks (DNNs) for denoising are called deep noise suppression (DNS). During training, DNS methods are typically trained with mean squared error (MSE) type loss functions, which do not guarantee good perceptual quality. Perceptual evaluation of speech quality (PESQ) is a widely used metric for evaluating speech quality. However, the original PESQ algorithm is non-differentiable, and therefore cannot directly be used as optimization criterion for gradient-based learning. In this work, we propose an end-to-end non-intrusive PESQNet DNN to estimate the PESQ scores of the enhanced speech signal. Thus, by providing a reference-free perceptual loss, it serves as a mediator towards the DNS training, allowing to maximize the PESQ score of the enhanced speech signal. We illustrate the potential of our proposed PESQNet-mediated training on the basis of an already strong baseline DNS. As further novelty, we propose to train the DNS and the PESQNet alternatingly to keep the PESQNet up-to-date and perform well specifically for the DNS under training. Our proposed method is compared to the same DNS trained with MSE-based loss for joint denoising and dereverberation, and the Interspeech 2021 DNS Challenge baseline. Detailed analysis shows that the PESQNet mediation can further increase the DNS performance by about 0.1 PESQ points on synthetic test data and by 0.03 DNSMOS points on real test data, compared to training with the MSE-based loss. Our proposed method also outperforms the Challenge baseline by 0.2 PESQ points on synthetic test data and 0.1 DNSMOS points on real test data.      
### 43.Class Token and Knowledge Distillation for Multi-head Self-Attention Speaker Verification Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.03842.pdf)
>  This paper explores three novel approaches to improve the performance of speaker verification (SV) systems based on deep neural networks (DNN) using Multi-head Self-Attention (MSA) mechanisms and memory layers. Firstly, we propose the use of a learnable vector called Class token to replace the average global pooling mechanism to extract the embeddings. Unlike global average pooling, our proposal takes into account the temporal structure of the input what is relevant for the text-dependent SV task. The class token is concatenated to the input before the first MSA layer, and its state at the output is used to predict the classes. To gain additional robustness, we introduce two approaches. First, we have developed a Bayesian estimation of the class token. Second, we have added a distilled representation token for training a teacher-student pair of networks using the Knowledge Distillation (KD) philosophy, which is combined with the class token. This distillation token is trained to mimic the predictions from the teacher network, while the class token replicates the true label. All the strategies have been tested on the RSR2015-Part II and DeepMine-Part 1 databases for text-dependent SV, providing competitive results compared to the same architecture using the average pooling mechanism to extract average embeddings.      
### 44.Design, Modelling, and Simulation analysis of a Single Axis MEMS-based Capacitive Accelerometer  [ :arrow_down: ](https://arxiv.org/pdf/2111.03816.pdf)
>  This paper presents the design, simulation, and analytical modeling of the single proposed axis MEMSbased capacitive accelerometer. Analytical modeling has been done for frequency and displacement sensitivity. The performance of the accelerometer was tested for both static and dynamic conditions, and the corresponding static capacitance value was calculated and was found to be C0=0.730455pF, a response time of 95.17{\mu}s, and settling time of 7.261ms and the displacement sensitivity Sd= 3.5362* m/g. It was observed that the sensitivity of the accelerometer depends on its design parameters like beam length, overlap area of comb, sensing mass, and the number of interdigital fingers. A novel capacitive accelerometer has been designed for an operating frequency of 2.1kHz The accelerometer was designed using COMSOL Multiphysics and analyzed using the MATLAB simulator tool. The single proposed axis MEMS-based capacitive accelerometer is suitable for automobile applications such as airbag deployment and navigation.      
### 45.Order-Guided Disentangled Representation Learning for Ulcerative Colitis Classification with Limited Labels  [ :arrow_down: ](https://arxiv.org/pdf/2111.03815.pdf)
>  Ulcerative colitis (UC) classification, which is an important task for endoscopic diagnosis, involves two main difficulties. First, endoscopic images with the annotation about UC (positive or negative) are usually limited. Second, they show a large variability in their appearance due to the location in the colon. Especially, the second difficulty prevents us from using existing semi-supervised learning techniques, which are the common remedy for the first difficulty. In this paper, we propose a practical semi-supervised learning method for UC classification by newly exploiting two additional features, the location in a colon (e.g., left colon) and image capturing order, both of which are often attached to individual images in endoscopic image sequences. The proposed method can extract the essential information of UC classification efficiently by a disentanglement process with those features. Experimental results demonstrate that the proposed method outperforms several existing semi-supervised learning methods in the classification task, even with a small number of annotated images.      
### 46.Compensation of Reactive Power in Grid-Connected Solar PV Array System Using STATCOM and Fixed Capacitor Bank  [ :arrow_down: ](https://arxiv.org/pdf/2111.03814.pdf)
>  In this article, we propose reactive compensation for the PV integrated grid system using a STATCOM and a fixed capacitor bank. This paper presents a design calculation for a PV integrated grid system with a fixed capacitor and STATCOM. The proposed system is simulated and tested using the MATLAB Simulink software package. The suggested system has been evaluated under a variety of operating circumstances, including changing solar PV array irradiance and changing reactive load power. Detailed simulation and comparisons between the fixed capacitor and STATCOM represented.      
### 47.Artifact- and content-specific quality assessment for MRI with image rulers  [ :arrow_down: ](https://arxiv.org/pdf/2111.03780.pdf)
>  In clinical practice MR images are often first seen by radiologists long after the scan. If image quality is inadequate either patients have to return for an additional scan, or a suboptimal interpretation is rendered. An automatic image quality assessment (IQA) would enable real-time remediation. Existing IQA works for MRI give only a general quality score, agnostic to the cause of and solution to low-quality scans. Furthermore, radiologists' image quality requirements vary with the scan type and diagnostic task. Therefore, the same score may have different implications for different scans. We propose a framework with multi-task CNN model trained with calibrated labels and inferenced with image rulers. Labels calibrated by human inputs follow a well-defined and efficient labeling task. Image rulers address varying quality standards and provide a concrete way of interpreting raw scores from the CNN. The model supports assessments of two of the most common artifacts in MRI: noise and motion. It achieves accuracies of around 90%, 6% better than the best previous method examined, and 3% better than human experts on noise assessment. Our experiments show that label calibration, image rulers, and multi-task training improve the model's performance and generalizability.      
### 48.OTFS-Based Joint Communication and Sensing for Future Industrial IoT  [ :arrow_down: ](https://arxiv.org/pdf/2111.03768.pdf)
>  Effective wireless communications are increasingly important in maintaining the successful closed-loop operation of mission-critical industrial Internet-of-Things (IIoT) applications. To meet the ever-increasing demands on better wireless communications for IIoT, we propose an orthogonal time-frequency space (OTFS) waveform-based joint communication and radio sensing (JCAS) scheme -- an energy-efficient solution for not only reliable communications but also high-accuracy sensing. OTFS has been demonstrated to have higher reliability and energy efficiency than the currently popular IIoT communication waveforms. JCAS has also been highly recommended for IIoT, since it saves cost, power and spectrum compared to having two separate radio frequency systems. Performing JCAS based on OTFS, however, can be hindered by a lack of effective OTFS sensing. This paper is dedicated to filling this technology gap. We first design a series of echo pre-processing methods that successfully remove the impact of communication data symbols in the time-frequency domain, where major challenges, like inter-carrier and inter-symbol interference and noise amplification, are addressed. Then, we provide a comprehensive analysis of the signal-to-interference-plus-noise ratio (SINR) for sensing and optimize a key parameter of the proposed method to maximize the SINR. Extensive simulations show that the proposed sensing method approaches the maximum likelihood estimator with respect to the estimation accuracy of target parameters and manifests applicability to wide ranges of key system parameters. Notably, the complexity of the proposed method is only dominated by a two-dimensional Fourier transform.      
### 49.RAIL: Robust Acoustic Indoor Localization for Drones  [ :arrow_down: ](https://arxiv.org/pdf/2111.03764.pdf)
>  Navigating in environments where the GPS signal is unavailable, weak, purposefully blocked, or spoofed has become crucial for a wide range of applications. A prime example is autonomous navigation for drones in indoor environments: to fly fully or partially autonomously, drones demand accurate and frequent updates of their locations. This paper proposes a Robust Acoustic Indoor Localization (RAIL) scheme for drones designed explicitly for GPS-denied environments. Instead of depending on GPS, RAIL leverages ultrasonic acoustic signals to achieve precise localization using a novel hybrid Frequency Hopping Code Division Multiple Access (FH-CDMA) technique. Contrary to previous approaches, RAIL is able to both overcome the multi-path fading effect and provide precise signal separation in the receiver. Comprehensive simulations and experiments using a prototype implementation demonstrate that RAIL provides high-accuracy three-dimensional localization with an average error of less than $1.5$~cm.      
### 50.Securing your Airspace: Detection of Drones Trespassing Protected Areas  [ :arrow_down: ](https://arxiv.org/pdf/2111.03760.pdf)
>  There has been a rapid growth in the deployment of Unmanned Aerial Vehicles (UAVs) in various applications ranging from vital safety-of-life such as surveillance and reconnaissance at nuclear power plants to entertainment and hobby applications. While popular, drones can pose serious security threats that can be unintentional or intentional. Thus, there is an urgent need for real-time accurate detection and classification of drones. In this article, we perform a survey of drone detection approaches presenting their advantages and limitations. We analyze detection techniques that employ radars, acoustic and optical sensors, and emitted radio frequency (RF) signals. We compare their performance, accuracy, and cost, concluding that combining multiple sensing modalities might be the path forward.      
### 51.Explaining neural network predictions of material strength  [ :arrow_down: ](https://arxiv.org/pdf/2111.03729.pdf)
>  We recently developed a deep learning method that can determine the critical peak stress of a material by looking at scanning electron microscope (SEM) images of the material's crystals. However, it has been somewhat unclear what kind of image features the network is keying off of when it makes its prediction. It is common in computer vision to employ an explainable AI saliency map to tell one what parts of an image are important to the network's decision. One can usually deduce the important features by looking at these salient locations. However, SEM images of crystals are more abstract to the human observer than natural image photographs. As a result, it is not easy to tell what features are important at the locations which are most salient. To solve this, we developed a method that helps us map features from important locations in SEM images to non-abstract textures that are easier to interpret.      
### 52.Spatiotemporal Impact of Hurricanes on a Power Grid  [ :arrow_down: ](https://arxiv.org/pdf/2111.03711.pdf)
>  Almost 90% of the major power outages in the US are caused due to hurricanes. Due to the highly uncertain nature of hurricanes in both spatial and temporal dimensions, it is essential to quantify the effect of such hurricanes on a power grid. In this paper, we provide a Monte-Carlo-based framework in which several hurricane scenarios and their impact on a power grid are analyzed in spatiotemporal dimensions. The hurricane simulations are performed using samples from previously occurred hurricanes in the US whereas probabilistic assessment of the transmission lines is performed through line fragility model. Finally, a loss metric based on the amount of load disconnected due to hurricanes traveling inland is calculated for each time step. The simulation is performed on ACTIVSg2000: 2000-bus synthetic Texas grid while mapping the transmission lines of the test case on the geographical footprint of Texas. The simulation results show that the loss increases significantly for a few time steps when the wind field of a hurricane is intense and almost saturates when the intensity of the hurricane decays while traversing further. The proposed analysis can provide some insights for proactive planning strategies on improving the resilience of the power grid.      
### 53.Damage Estimation and Localization from Sparse Aerial Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2111.03708.pdf)
>  Aerial images provide important situational awareness for responding to natural disasters such as hurricanes. They are well-suited for providing information for damage estimation and localization (DEL); i.e., characterizing the type and spatial extent of damage following a disaster. Despite recent advances in sensing and unmanned aerial systems technology, much of post-disaster aerial imagery is still taken by handheld DSLR cameras from small, manned, fixed-wing aircraft. However, these handheld cameras lack IMU information, and images are taken opportunistically post-event by operators. As such, DEL from such imagery is still a highly manual and time-consuming process. We propose an approach to both detect damage in aerial images and localize it in world coordinates, with specific focus on detecting and localizing flooding. The approach is based on using structure from motion to relate image coordinates to world coordinates via a projective transformation, using class activation mapping to detect the extent of damage in an image, and applying the projective transformation to localize damage in world coordinates. We evaluate the performance of our approach on post-event data from the 2016 Louisiana floods, and find that our approach achieves a precision of 88%. Given this high precision using limited data, we argue that this approach is currently viable for fast and effective DEL from handheld aerial imagery for disaster response.      
### 54.First steps on Gamification of Lung Fluid Cells Annotations in the Flower Domain  [ :arrow_down: ](https://arxiv.org/pdf/2111.03663.pdf)
>  Annotating data, especially in the medical domain, requires expert knowledge and a lot of effort. This limits the amount and/or usefulness of available medical data sets for experimentation. Therefore, developing strategies to increase the number of annotations while lowering the needed domain knowledge is of interest. A possible strategy is the use of gamification, that is i.e. transforming the annotation task into a game. We propose an approach to gamify the task of annotating lung fluid cells from pathological whole slide images. As this domain is unknown to non-expert annotators, we transform images of cells detected with a RetinaNet architecture to the domain of flower images. This domain transfer is performed with a CycleGAN architecture for different cell types. In this more assessable domain, non-expert annotators can be (t)asked to annotate different kinds of flowers in a playful setting. In order to provide a proof of concept, this work shows that the domain transfer is possible by evaluating an image classification network trained on real cell images and tested on the cell images generated by the CycleGAN network. The classification network reaches an accuracy of 97.48% and 95.16% on the original lung fluid cells and transformed lung fluid cells, respectively. With this study, we lay the foundation for future research on gamification using CycleGANs.      
### 55.OMD: Orthogonal Malware Detection Using Audio, Image, and Static Features  [ :arrow_down: ](https://arxiv.org/pdf/2111.04710.pdf)
>  With the growing number of malware and cyber attacks, there is a need for "orthogonal" cyber defense approaches, which are complementary to existing methods by detecting unique malware samples that are not predicted by other methods. In this paper, we propose a novel and orthogonal malware detection (OMD) approach to identify malware using a combination of audio descriptors, image similarity descriptors and other static/statistical features. First, we show how audio descriptors are effective in classifying malware families when the malware binaries are represented as audio signals. Then, we show that the predictions made on the audio descriptors are orthogonal to the predictions made on image similarity descriptors and other static features. Further, we develop a framework for error analysis and a metric to quantify how orthogonal a new feature set (or type) is with respect to other feature sets. This allows us to add new features and detection methods to our overall framework. Experimental results on malware datasets show that our approach provides a robust framework for orthogonal malware detection.      
### 56.HAPSSA: Holistic Approach to PDF Malware Detection Using Signal and Statistical Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.04703.pdf)
>  Malicious PDF documents present a serious threat to various security organizations that require modern threat intelligence platforms to effectively analyze and characterize the identity and behavior of PDF malware. State-of-the-art approaches use machine learning (ML) to learn features that characterize PDF malware. However, ML models are often susceptible to evasion attacks, in which an adversary obfuscates the malware code to avoid being detected by an Antivirus. In this paper, we derive a simple yet effective holistic approach to PDF malware detection that leverages signal and statistical analysis of malware binaries. This includes combining orthogonal feature space models from various static and dynamic malware detection methods to enable generalized robustness when faced with code obfuscations. Using a dataset of nearly 30,000 PDF files containing both malware and benign samples, we show that our holistic approach maintains a high detection rate (99.92%) of PDF malware and even detects new malicious files created by simple methods that remove the obfuscation conducted by malware authors to hide their malware, which are undetected by most antiviruses.      
### 57.Computationally efficient full-waveform inversion of the brain using frequency-adaptive grids and lossy compression  [ :arrow_down: ](https://arxiv.org/pdf/2111.04700.pdf)
>  A tomographic technique called full-waveform inversion has recently shown promise as a fast, affordable, and safe modality to image the brain using ultrasound. However, its high computational cost and memory footprint currently limit its clinical applicability. Here, we address these challenges through a frequency-adaptive discretisation of the imaging domain and lossy compression techniques. Because full-waveform inversion relies on the adjoint-state method, every iteration involves solving the wave equation over a discretised spatiotemporal grid and storing the numerical solution to calculate gradient updates. The computational cost depends on the grid size, which is controlled by the maximum frequency being modelled. Since the propagated frequency typically varies during the reconstruction, we reduce reconstruction time and memory use by allowing the grid size to change throughout the inversion. Moreover, we combine this approach with multiple lossy compression techniques that exploit the sparsity of the wavefield to further reduce its memory footprint. We explore applying these techniques in the spatial, wavelet, and wave atom domains. Numerical experiments using a human-head model show that our methods lead to a 30% reduction in reconstruction time and up to three orders of magnitude less memory, while negligibly affecting the accuracy of the reconstructions.      
### 58.Reinforcement Learning for Mixed Autonomy Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2111.04686.pdf)
>  We propose a model-free reinforcement learning method for controlling mixed autonomy traffic in simulated traffic networks with through-traffic-only two-way and four-way intersections. Our method utilizes multi-agent policy decomposition which allows decentralized control based on local observations for an arbitrary number of controlled vehicles. We demonstrate that, even without reward shaping, reinforcement learning learns to coordinate the vehicles to exhibit traffic signal-like behaviors, achieving near-optimal throughput with 33-50% controlled vehicles. With the help of multi-task learning and transfer learning, we show that this behavior generalizes across inflow rates and size of the traffic network. Our code, models, and videos of results are available at <a class="link-external link-https" href="https://github.com/ZhongxiaYan/mixed_autonomy_intersections" rel="external noopener nofollow">this https URL</a>.      
### 59.Joint Optimization of Uplink Power and Computational Resources in Mobile Edge Computing-Enabled Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2111.04678.pdf)
>  The coupling of cell-free massive MIMO (CF-mMIMO) with Mobile Edge Computing (MEC) is investigated in this paper. A MEC-enabled CF-mMIMO architecture implementing a distributed user-centric approach both from the radio and the computational resource allocation perspective is proposed. An optimization problem for the joint allocation of uplink powers and remote computational resources is formulated, aimed at minimizing the total uplink power consumption under power budget and latency constraints, while simultaneously maximizing the minimum SE throughout the network. In order to efficiently solve such a challenging non-convex problem, an iterative algorithm based on sequential convex programming is proposed, along with two approaches to priory assess the problem feasibility. Finally, a detailed performance comparison between the proposed MEC-enabled CF-mMIMO architecture and its cellular counterpart is provided. Numerical results reveal the effectiveness of the proposed joint optimization problem, and the natural suitability of CF-mMIMO in supporting computation-offloading applications with benefits over users' transmit power and energy consumption, the offloading latency experienced, and the total amount of allocated remote computational resources.      
### 60.On the Stochastic Stability of Deep Markov Models  [ :arrow_down: ](https://arxiv.org/pdf/2111.04601.pdf)
>  Deep Markov models (DMM) are generative models that are scalable and expressive generalization of Markov models for representation, learning, and inference problems. However, the fundamental stochastic stability guarantees of such models have not been thoroughly investigated. In this paper, we provide sufficient conditions of DMM's stochastic stability as defined in the context of dynamical systems and propose a stability analysis method based on the contraction of probabilistic maps modeled by deep neural networks. We make connections between the spectral properties of neural network's weights and different types of used activation functions on the stability and overall dynamic behavior of DMMs with Gaussian distributions. Based on the theory, we propose a few practical methods for designing constrained DMMs with guaranteed stability. We empirically substantiate our theoretical results via intuitive numerical experiments using the proposed stability constraints.      
### 61.Frequency-Dependent $F$-Number Increases the Contrast and the Spatial Resolution in Fast Pulse-Echo Ultrasound Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.04593.pdf)
>  Fixed $F$-numbers reduce grating lobe artifacts in fast pulse-echo ultrasound imaging. Such $F$-numbers result in dynamic receive subapertures whose widths vary with the focal position. These subapertures, however, ignore useful low-frequency components in the excluded radio frequency (RF) signals and, thus, reduce the lateral resolution. Here, we propose a frequency-dependent $F$-number to simultaneously suppress grating lobe artifacts and maintain the lateral resolution. This $F$-number, at high frequencies, reduces the receive subaperture to remove spatially undersampled components of the RF signals and suppress grating lobes. The $F$-number, at low frequencies, enlarges the receive subaperture to use the components of all RF signals and maintain the lateral resolution. Experiments validated the proposed $F$-number and demonstrated improvements in the contrast and the widths of wire targets of up to 3.2 % and 12.8 %, respectively.      
### 62.CoCo Games: Graphical Game-Theoretic Swarm Control for Communication-Aware Coverage  [ :arrow_down: ](https://arxiv.org/pdf/2111.04576.pdf)
>  We present a novel approach to maximize the communication-aware coverage for robots operating over large-scale geographical regions of interest (ROIs). Our approach complements the underlying network topology in neighborhood selection and control, rendering it highly robust in dynamic environments. We formulate the coverage as a multi-stage, cooperative graphical game and employ Variational Inference (VI) to reach the equilibrium. We experimentally validate our approach in an mobile ad-hoc wireless network scenario using Unmanned Aerial Vehicles (UAV) and User Equipment (UE) robots. We show that it can cater to ROIs defined by stationary and moving User Equipment (UE) robots under realistic network conditions.      
### 63.Terahertz Wireless Channels: A Holistic Survey on Measurement, Modeling, and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2111.04522.pdf)
>  Terahertz (THz) communications are envisioned as a key technology for sixth generation (6G) wireless systems. The study of underlying THz wireless propagation channels provides the foundations for the development of reliable THz communication systems and their applications. This article provides a comprehensive overview of the study of THz wireless channels. First, the three most popular THz channel measurement methodologies, namely, frequency-domain channel measurement based on a vector network analyzer (VNA), time-domain channel measurement based on sliding correlation, and time-domain channel measurement based on THz pulses from time-domain spectroscopy (THz-TDS), are introduced and compared. Current channel measurement systems and measurement campaigns are reviewed. Then, existing channel modeling methodologies are categorized into deterministic, stochastic, and hybrid approaches. State-of-the-art THz channel models are analyzed, and the channel simulators that are based on them are introduced. Next, an in-depth review of channel characteristics in the THz band is presented. Finally, open problems and future research directions for research studies on THz wireless channels for 6G are elaborated.      
### 64.SEOFP-NET: Compression and Acceleration of Deep Neural Networks for Speech Enhancement Using Sign-Exponent-Only Floating-Points  [ :arrow_down: ](https://arxiv.org/pdf/2111.04436.pdf)
>  Numerous compression and acceleration strategies have achieved outstanding results on classification tasks in various fields, such as computer vision and speech signal processing. Nevertheless, the same strategies have yielded ungratified performance on regression tasks because the nature between these and classification tasks differs. In this paper, a novel sign-exponent-only floating-point network (SEOFP-NET) technique is proposed to compress the model size and accelerate the inference time for speech enhancement, a regression task of speech signal processing. The proposed method compressed the sizes of deep neural network (DNN)-based speech enhancement models by quantizing the fraction bits of single-precision floating-point parameters during training. Before inference implementation, all parameters in the trained SEOFP-NET model are slightly adjusted to accelerate the inference time by replacing the floating-point multiplier with an integer-adder. For generalization, the SEOFP-NET technique is introduced to different speech enhancement tasks in speech signal processing with different model architectures under various corpora. The experimental results indicate that the size of SEOFP-NET models can be significantly compressed by up to 81.249% without noticeably downgrading their speech enhancement performance, and the inference time can be accelerated to 1.212x compared with the baseline models. The results also verify that the proposed SEOFP-NET can cooperate with other efficiency strategies to achieve a synergy effect for model compression. In addition, the just noticeable difference (JND) was applied to the user study experiment to statistically analyze the effect of speech enhancement on listening. The results indicate that the listeners cannot facilely differentiate between the enhanced speech signals processed by the baseline model and the proposed SEOFP-NET.      
### 65.A Survey of Human Activity Recognition in Smart Homes Based on IoT Sensors Algorithms: Taxonomies, Challenges, and Opportunities with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.04418.pdf)
>  Recent advances in Internet of Things (IoT) technologies and the reduction in the cost of sensors have encouraged the development of smart environments, such as smart homes. Smart homes can offer home assistance services to improve the quality of life, autonomy and health of their residents, especially for the elderly and dependent. To provide such services, a smart home must be able to understand the daily activities of its residents. Techniques for recognizing human activity in smart homes are advancing daily. But new challenges are emerging every day. In this paper, we present recent algorithms, works, challenges and taxonomy of the field of human activity recognition in a smart home through ambient sensors. Moreover, since activity recognition in smart homes is a young field, we raise specific problems, missing and needed contributions. But also propose directions, research opportunities and solutions to accelerate advances in this field.      
### 66.Characterizing the adversarial vulnerability of speech self-supervised learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.04330.pdf)
>  A leaderboard named Speech processing Universal PERformance Benchmark (SUPERB), which aims at benchmarking the performance of a shared self-supervised learning (SSL) speech model across various downstream speech tasks with minimal modification of architectures and small amount of data, has fueled the research for speech representation learning. The SUPERB demonstrates speech SSL upstream models improve the performance of various downstream tasks through just minimal adaptation. As the paradigm of the self-supervised learning upstream model followed by downstream tasks arouses more attention in the speech community, characterizing the adversarial robustness of such paradigm is of high priority. In this paper, we make the first attempt to investigate the adversarial vulnerability of such paradigm under the attacks from both zero-knowledge adversaries and limited-knowledge adversaries. The experimental results illustrate that the paradigm proposed by SUPERB is seriously vulnerable to limited-knowledge adversaries, and the attacks generated by zero-knowledge adversaries are with transferability. The XAB test verifies the imperceptibility of crafted adversarial attacks.      
### 67.Spirometry-based airways disease simulation and recognition using Machine Learning approaches  [ :arrow_down: ](https://arxiv.org/pdf/2111.04315.pdf)
>  The purpose of this study is to provide means to physicians for automated and fast recognition of airways diseases. In this work, we mainly focus on measures that can be easily recorded using a spirometer. The signals used in this framework are simulated using the linear bi-compartment model of the lungs. This allows us to simulate ventilation under the hypothesis of ventilation at rest (tidal breathing). By changing the resistive and elastic parameters, data samples are realized simulating healthy, fibrosis and asthma breathing. On this synthetic data, different machine learning models are tested and their performance is assessed. All but the Naive bias classifier show accuracy of at least 99%. This represents a proof of concept that Machine Learning can accurately differentiate diseases based on manufactured spirometry data. This paves the way for further developments on the topic, notably testing the model on real data.      
### 68.Assessing learned features of Deep Learning applied to EEG  [ :arrow_down: ](https://arxiv.org/pdf/2111.04309.pdf)
>  Convolutional Neural Networks (CNNs) have achieved impressive performance on many computer vision related tasks, such as object detection, image recognition, image retrieval, etc. These achievements benefit from the CNNs' outstanding capability to learn discriminative features with deep layers of neuron structures and iterative training process. This has inspired the EEG research community to adopt CNN in performing EEG classification tasks. However, CNNs learned features are not immediately interpretable, causing a lack of understanding of the CNNs' internal working mechanism. To improve CNN interpretability, CNN visualization methods are applied to translate the internal features into visually perceptible patterns for qualitative analysis of CNN layers. Many CNN visualization methods have been proposed in the Computer Vision literature to interpret the CNN network structure, operation, and semantic concept, yet applications to EEG data analysis have been limited. In this work we use 3 different methods to extract EEG-relevant features from a CNN trained on raw EEG data: optimal samples for each classification category, activation maximization, and reverse convolution. We applied these methods to a high-performing Deep Learning model with state-of-the-art performance for an EEG sex classification task, and show that the model features a difference in the theta frequency band. We show that visualization of a CNN model can reveal interesting EEG results. Using these tools, EEG researchers using Deep Learning can better identify the learned EEG features, possibly identifying new class relevant biomarkers.      
### 69.Retrieving Speaker Information from Personalized Acoustic Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2111.04194.pdf)
>  The widespread of powerful personal devices capable of collecting voice of their users has opened the opportunity to build speaker adapted speech recognition system (ASR) or to participate to collaborative learning of ASR. In both cases, personalized acoustic models (AM), i.e. fine-tuned AM with specific speaker data, can be built. A question that naturally arises is whether the dissemination of personalized acoustic models can leak personal information. In this paper, we show that it is possible to retrieve the gender of the speaker, but also his identity, by just exploiting the weight matrix changes of a neural acoustic model locally adapted to this speaker. Incidentally we observe phenomena that may be useful towards explainability of deep neural networks in the context of speech processing. Gender can be identified almost surely using only the first layers and speaker verification performs well when using middle-up layers. Our experimental study on the TED-LIUM 3 dataset with HMM/TDNN models shows an accuracy of 95% for gender detection, and an Equal Error Rate of 9.07% for a speaker verification task by only exploiting the weights from personalized models that could be exchanged instead of user data.      
### 70.CoughTrigger: Earbuds IMU Based Cough Detection Activator Using An Energy-efficient Sensitivity-prioritized Time Series Classifier  [ :arrow_down: ](https://arxiv.org/pdf/2111.04185.pdf)
>  Persistent coughs are a major symptom of respiratory-related diseases. Increasing research attention has been paid to detecting coughs using wearables, especially during the COVID-19 pandemic. Among all types of sensors utilized, microphone is most widely used to detect coughs. However, the intense power consumption needed to process audio signals hinders continuous audio-based cough detection on battery-limited commercial wearable products, such as earbuds. We present CoughTrigger, which utilizes a lower-power sensor, an inertial measurement unit (IMU), in earbuds as a cough detection activator to trigger a higher-power sensor for audio processing and classification. It is able to run all-the-time as a standby service with minimal battery consumption and trigger the audio-based cough detection when a candidate cough is detected from IMU. Besides, the use of IMU brings the benefit of improved specificity of cough detection. Experiments are conducted on 45 subjects and our IMU-based model achieved 0.77 AUC score under leave one subject out evaluation. We also validated its effectiveness on free-living data and through on-device implementation.      
### 71.A Survey of Wireless Networks for Future Aerial COMmunications (FACOM)  [ :arrow_down: ](https://arxiv.org/pdf/2111.04175.pdf)
>  Electrification turned over a new leaf in aviation by introducing new types of aerial vehicles along with new means of transportation. Addressing a plethora of use cases, drones are gaining attention and increasingly appear in the sky. Emerging concepts of flying taxi enable passengers to be transported over several tens of kilometers. Therefore, unmanned traffic management systems are under development to cope with the complexity of future airspace, thereby resulting in unprecedented communication needs. Moreover, the increase in the number of commercial airplanes pushes the limits of voice-oriented communications, and future options such as single-pilot operations demand robust connectivity. In this survey, we provide a comprehensive review and vision for enabling the connectivity applications of aerial vehicles utilizing current and future communication technologies. We begin by categorizing the connectivity use cases per aerial vehicle and analyzing their connectivity requirements. By reviewing more than 500 related studies, we aim for a comprehensive approach to cover wireless communication technologies, and provide an overview of recent findings from the literature toward the possibilities and challenges of employing the wireless communication standards. After analyzing the network architectures, we list the open-source testbed platforms to facilitate future investigations. This study helped us observe that while numerous works focused on cellular technologies for aerial platforms, a single wireless technology is not sufficient to meet the stringent connectivity demands of the aerial use cases. We identified the need of further investigations on multi-technology network architectures to enable robust connectivity in the sky. Future works should consider suitable technology combinations to develop unified aerial networks that can meet the diverse quality of service demands.      
### 72.PID Controller Optimization for Low-cost Line Follower Robots  [ :arrow_down: ](https://arxiv.org/pdf/2111.04149.pdf)
>  In this paper, modification of the classical PID controller and development of open-loop control mechanisms to improve stability and robustness of a differential wheeled robot are discussed. To deploy the algorithm, a test platform has been constructed using low-cost and off-the-shelf components including a microcontroller, reflectance sensor, and motor driver. This paper describes the heuristic approach used in the identification of the system specifications as well as the optimization of the controller. The PID controller is analyzed in detail and the effect of each term is explained in the context of stability. Lastly, the challenges encountered during the development of controller and robot are discussed. Code is available at: <a class="link-external link-https" href="https://github.com/sametoguten/STM32-Line-Follower-with-PID" rel="external noopener nofollow">this https URL</a>.      
### 73.Ballistic Multibody Estimator for 2D Open Kinematic Chain  [ :arrow_down: ](https://arxiv.org/pdf/2111.04118.pdf)
>  Applications of free-flying robots range from entertainment purposes to aerospace applications. The control algorithm for such systems requires accurate estimation of their states based on sensor feedback. The objective of this paper is to design and verify a lightweight state estimation algorithm for a free-flying open kinematic chain that estimates the state of its center-of-mass and its posture. Instead of utilizing a nonlinear dynamics model, this research proposes a cascade structure of two Kalman filters (KF), which relies on the information from the ballistic motion of free-falling multibody systems together with feedback from an inertial measurement unit (IMU) and encoders. Multiple algorithms are verified in the simulation that mimics real-world circumstances with Simulink. Several uncertain physical parameters are varied, and the result shows that the proposed estimator outperforms EKF and UKF in terms of tracking performance and computational time.      
### 74.Theme Transformer: Symbolic Music Generation with Theme-Conditioned Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2111.04093.pdf)
>  Attention-based Transformer models have been increasingly employed for automatic music generation. To condition the generation process of such a model with a user-specified sequence, a popular approach is to take that conditioning sequence as a priming sequence and ask a Transformer decoder to generate a continuation. However, this prompt-based conditioning cannot guarantee that the conditioning sequence would develop or even simply repeat itself in the generated continuation. In this paper, we propose an alternative conditioning approach, called theme-based conditioning, that explicitly trains the Transformer to treat the conditioning sequence as a thematic material that has to manifest itself multiple times in its generation result. This is achieved with two main technical contributions. First, we propose a deep learning-based approach that uses contrastive representation learning and clustering to automatically retrieve thematic materials from music pieces in the training data. Second, we propose a novel gated parallel attention module to be used in a sequence-to-sequence (seq2seq) encoder/decoder architecture to more effectively account for a given conditioning thematic material in the generation process of the Transformer decoder. We report on objective and subjective evaluations of variants of the proposed Theme Transformer and the conventional prompt-based baseline, showing that our best model can generate, to some extent, polyphonic pop piano music with repetition and plausible variations of a given condition.      
### 75.Learn-Morph-Infer: a new way of solving the inverse problem for brain tumor modeling  [ :arrow_down: ](https://arxiv.org/pdf/2111.04090.pdf)
>  Current treatment planning of patients diagnosed with brain tumor could significantly benefit by accessing the spatial distribution of tumor cell concentration. Existing diagnostic modalities, such as magnetic-resonance imaging (MRI), contrast sufficiently well areas of high cell density. However, they do not portray areas of low concentration, which can often serve as a source for the secondary appearance of the tumor after treatment. Numerical simulations of tumor growth could complement imaging information by providing estimates of full spatial distributions of tumor cells. Over recent years a corpus of literature on medical image-based tumor modeling was published. It includes different mathematical formalisms describing the forward tumor growth model. Alongside, various parametric inference schemes were developed to perform an efficient tumor model personalization, i.e. solving the inverse problem. However, the unifying drawback of all existing approaches is the time complexity of the model personalization that prohibits a potential integration of the modeling into clinical settings. In this work, we introduce a methodology for inferring patient-specific spatial distribution of brain tumor from T1Gd and FLAIR MRI medical scans. Coined as \textit{Learn-Morph-Infer} the method achieves real-time performance in the order of minutes on widely available hardware and the compute time is stable across tumor models of different complexity, such as reaction-diffusion and reaction-advection-diffusion models. We believe the proposed inverse solution approach not only bridges the way for clinical translation of brain tumor personalization but can also be adopted to other scientific and engineering domains.      
### 76.GSG: A Granary Soft Gripper with Mechanical Force Sensing via 3-Dimensional Snap-Through Structure  [ :arrow_down: ](https://arxiv.org/pdf/2111.04046.pdf)
>  Grasping is an essential capability for most robots in practical applications. Soft robotic grippers are considered as a critical part of robotic grasping and have attracted considerable attention in terms of the advantages of the high compliance and robustness to variance in object geometry; however, they are still limited by the corresponding sensing capabilities and actuation mechanisms. We propose a novel soft gripper that looks like a granary with a compliant snap-through bistable mechanism fabricated by integrated mold technology, achieving sensing and actuation purely mechanically. In particular, the snap-through bistable structure in the proposed gripper allows us to reduce the complexity of the mechanism, control, sensing designs since the grasping and sensing behaviors are completely passive. The grasping behaviors are automatically motivated once the trigger position of the gripper touches an object and applies sufficient force. To grasp objects with various profiles, the proposed granary soft gripper (GSG) is designed to be capable of enveloping, pinching and caging grasps. The gripper consists of a chamber palm, a palm cap and three fingers. First, the design of the gripper is analyzed. Then, after the theoretical model is constructed, finite element (FE) simulations are conducted to verify the built model. Finally, a series of grasping experiments is carried out to assess the snap-through behavior of the proposed gripper on grasping and sensing. The experimental results illustrate that the proposed gripper can manipulate a variety of soft and rigid objects and remain stable even though it undertakes external disturbances.      
### 77.Meta-TTS: Meta-Learning for Few-Shot Speaker Adaptive Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2111.04040.pdf)
>  Personalizing a speech synthesis system is a highly desired application, where the system can generate speech with the user's voice with rare enrolled recordings. There are two main approaches to build such a system in recent works: speaker adaptation and speaker encoding. On the one hand, speaker adaptation methods fine-tune a trained multi-speaker text-to-speech (TTS) model with few enrolled samples. However, they require at least thousands of fine-tuning steps for high-quality adaptation, making it hard to apply on devices. On the other hand, speaker encoding methods encode enrollment utterances into a speaker embedding. The trained TTS model can synthesize the user's speech conditioned on the corresponding speaker embedding. Nevertheless, the speaker encoder suffers from the generalization gap between the seen and unseen speakers. <br>In this paper, we propose applying a meta-learning algorithm to the speaker adaptation method. More specifically, we use Model Agnostic Meta-Learning (MAML) as the training algorithm of a multi-speaker TTS model, which aims to find a great meta-initialization to adapt the model to any few-shot speaker adaptation tasks quickly. Therefore, we can also adapt the meta-trained TTS model to unseen speakers efficiently. Our experiments compare the proposed method (Meta-TTS) with two baselines: a speaker adaptation method baseline and a speaker encoding method baseline. The evaluation results show that Meta-TTS can synthesize high speaker-similarity speech from few enrollment samples with fewer adaptation steps than the speaker adaptation baseline and outperforms the speaker encoding baseline under the same training scheme. When the speaker encoder of the baseline is pre-trained with extra 8371 speakers of data, Meta-TTS can still outperform the baseline on LibriTTS dataset and achieve comparable results on VCTK dataset.      
### 78.Style Transfer with Target Feature Palette and Attention Coloring  [ :arrow_down: ](https://arxiv.org/pdf/2111.04028.pdf)
>  Style transfer has attracted a lot of attentions, as it can change a given image into one with splendid artistic styles while preserving the image structure. However, conventional approaches easily lose image details and tend to produce unpleasant artifacts during style transfer. In this paper, to solve these problems, a novel artistic stylization method with target feature palettes is proposed, which can transfer key features accurately. Specifically, our method contains two modules, namely feature palette composition (FPC) and attention coloring (AC) modules. The FPC module captures representative features based on K-means clustering and produces a feature target palette. The following AC module calculates attention maps between content and style images, and transfers colors and patterns based on the attention map and the target palette. These modules enable the proposed stylization to focus on key features and generate plausibly transferred images. Thus, the contributions of the proposed method are to propose a novel deep learning-based style transfer method and present target feature palette and attention coloring modules, and provide in-depth analysis and insight on the proposed method via exhaustive ablation study. Qualitative and quantitative results show that our stylized images exhibit state-of-the-art performance, with strength in preserving core structures and details of the content image.      
### 79.SL-CycleGAN: Blind Motion Deblurring in Cycles using Sparse Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.04026.pdf)
>  In this paper, we introduce an end-to-end generative adversarial network (GAN) based on sparse learning for single image blind motion deblurring, which we called SL-CycleGAN. For the first time in blind motion deblurring, we propose a sparse ResNet-block as a combination of sparse convolution layers and a trainable spatial pooler k-winner based on HTM (Hierarchical Temporal Memory) to replace non-linearity such as ReLU in the ResNet-block of SL-CycleGAN generators. Furthermore, unlike many state-of-the-art GAN-based motion deblurring methods that treat motion deblurring as a linear end-to-end process, we take our inspiration from the domain-to-domain translation ability of CycleGAN, and we show that image deblurring can be cycle-consistent while achieving the best qualitative results. Finally, we perform extensive experiments on popular image benchmarks both qualitatively and quantitatively and achieve the record-breaking PSNR of 38.087 dB on GoPro dataset, which is 5.377 dB better than the most recent deblurring method.      
### 80.CubeLearn: End-to-end Learning for Human Motion Recognition from Raw mmWave Radar Signals  [ :arrow_down: ](https://arxiv.org/pdf/2111.03976.pdf)
>  mmWave FMCW radar has attracted huge amount of research interest for human-centered applications in recent years, such as human gesture/activity recognition. Most existing pipelines are built upon conventional Discrete Fourier Transform (DFT) pre-processing and deep neural network classifier hybrid methods, with a majority of previous works focusing on designing the downstream classifier to improve overall accuracy. In this work, we take a step back and look at the pre-processing module. To avoid the drawbacks of conventional DFT pre-processing, we propose a learnable pre-processing module, named CubeLearn, to directly extract features from raw radar signal and build an end-to-end deep neural network for mmWave FMCW radar motion recognition applications. Extensive experiments show that our CubeLearn module consistently improves the classification accuracies of different pipelines, especially benefiting those previously weaker models. We provide ablation studies on initialization methods and structure of the proposed module, as well as an evaluation of the running time on PC and edge devices. This work also serves as a comparison of different approaches towards data cube slicing. Through our task agnostic design, we propose a first step towards a generic end-to-end solution for radar recognition problems.      
### 81.Towards noise robust trigger-word detection with contrastive learning pre-task for fast on-boarding of new trigger-words  [ :arrow_down: ](https://arxiv.org/pdf/2111.03971.pdf)
>  Trigger-word detection plays an important role as the entry point of user's communication with voice assistants. But supporting a particular word as a trigger-word involves huge amount of data collection, augmentation and labelling for that word. This makes supporting new trigger-words a tedious and time consuming process. To combat this, we explore the use of contrastive learning as a pre-training task that helps the detection model to generalize to different words and noise conditions. We explore supervised contrastive techniques and also propose a self-supervised technique using chunked words from long sentence audios. We show that the contrastive pre-training techniques have comparable results to a traditional classification pre-training on new trigger words with less data availability.      
### 82.Feedback Control of Millimeter Scale Pivot Walkers Using Magnetic Actuation  [ :arrow_down: ](https://arxiv.org/pdf/2111.03934.pdf)
>  An external magnetic field can be used to remotely control small-scaled robots, making them promising candidates for diverse biomedical and engineering applications. We showed that our magnetically actuated millirobot is highly agile and can perform a variety of locomotive tasks such as pivot walking and tumbling in a horizontal plane. Here, we focus on controlling the locomotion outcomes of this millirobot in the pivot walking mode. A mathematical model of the system is developed and the kinematic model is derived. The role of the sweep and tilt angles in the robot's motion is also investigated. We propose two controllers to regulate the gait of the pivot walker. The first one is a proportional-geometric controller, which determines the correct pivot point that the millirobot should use. Then, it regulates the angular velocity proportionally based on the error between the center of the millirobot and the reference trajectory. The second controller is based on a gradient descent optimization technique, which expresses the control action as an optimization problem. These control algorithms enable the millirobot to generate a stable gait while tracking the desired trajectory. We conduct a set of different experiments and simulation runs to establish the effectiveness of proposed controllers for different sweep and tilt angles in terms of the tracking error. The two controllers exhibit an appropriate performance, but it is observed that gradient descent based controller yields faster convergence time, smaller tracking error, and fewer number of steps. Finally, we perform an extensive experimentally parametric analysis on the effect of the sweep angle, tilt angle, and step time on the tracking error. As we expect, the optimization-based controller outperforms the geometric based controller.      
### 83.Swarm Control of Magnetically Actuated Millirobots  [ :arrow_down: ](https://arxiv.org/pdf/2111.03931.pdf)
>  Small-size robots offer access to spaces that are inaccessible to larger ones. This type of access is crucial in applications such as drug delivery, environmental detection, and collection of small samples. However, there are some tasks that are not possible to perform using only one robot including assembly and manufacturing at small scales, manipulation of micro- and nano- objects, and robot-based structuring of small-scale materials. The solution to this problem is to use a group of robots as a system. Thus, we focus on tasks that can be achieved using a group of small-scale robots. These robots are typically externally actuated due to their size limitation. Yet, one faces the challenge of controlling a group of robots using a single global input. We propose a control algorithm to position individual members of a swarm in predefined positions. A single control input applies to the system and moves all robots in the same direction. We also add another control modality by using different length robots. An electromagnetic coil system applied external force and steered the millirobots. This millirobot can move in various modes of motion such as pivot walking and tumbling. We propose two new designs of these millirobots. In the first design, the magnets are placed at the center of body to reduce the magnetic attraction force. In the second design, the millirobots are of identical length with two extra legs acting as the pivot points. This way we vary pivot separation in design to take advantage of variable speed in pivot walking mode while keeping the speed constant in tumbling mode. This paper presents a general algorithm for positional control of n millirobots with different lengths to move them from given initial positions to final desired ones. This method is based on choosing a leader that is fully controllable. Simulations and hardware experiments validate these results.      
### 84.Space-Time Block Coded Spatial Modulation for Indoor Visible Light Communications  [ :arrow_down: ](https://arxiv.org/pdf/2111.03928.pdf)
>  Visible light communication (VLC) has been recognized as a promising technology for handling the continuously increasing quality of service and connectivity requirements in modern wireless communications, particularly in indoor scenarios. In this context, the present work considers the integration of two distinct modulation schemes, namely spatial modulation (SM) with space time block codes (STBCs), aiming at improving the overall VLC system reliability. Based on this and in order to further enhance the achievable transmission data rate, we integrate quasi-orthogonal STBC (QOSTBC) with SM, since relaxing the orthogonality condition of OSTBC ultimately provides a higher coding rate. Then, we generalize the developed results to any number of active light-emitting diodes (LEDs) and any M-ary pulse amplitude modulation size. Furthermore, we derive a tight and tractable upper bound for the corresponding bit error rate (BER) by considering a simple two-step decoding procedure to detect the indices of the transmitting LEDs and then decode the signal domain symbols. Notably, the obtained results demonstrate that QOSTBC with SM enhances the achievable BER compared to SM with repetition coding (RC-SM). Finally, we compare STBC-SM with both multiple active SM (MASM) and RC-SM in terms of the achievable BER and overall data rate, which further justifies the usefulness of the proposed scheme.      
### 85.Robust Deep Reinforcement Learning for Quadcopter Control  [ :arrow_down: ](https://arxiv.org/pdf/2111.03915.pdf)
>  Deep reinforcement learning (RL) has made it possible to solve complex robotics problems using neural networks as function approximators. However, the policies trained on stationary environments suffer in terms of generalization when transferred from one environment to another. In this work, we use Robust Markov Decision Processes (RMDP) to train the drone control policy, which combines ideas from Robust Control and RL. It opts for pessimistic optimization to handle potential gaps between policy transfer from one environment to another. The trained control policy is tested on the task of quadcopter positional control. RL agents were trained in a MuJoCo simulator. During testing, different environment parameters (unseen during the training) were used to validate the robustness of the trained policy for transfer from one environment to another. The robust policy outperformed the standard agents in these environments, suggesting that the added robustness increases generality and can adapt to non-stationary environments. <br>Codes: <a class="link-external link-https" href="https://github.com/adipandas/gym_multirotor" rel="external noopener nofollow">this https URL</a>      
### 86.Digital Audio Processing Tools for Music Corpus Studies  [ :arrow_down: ](https://arxiv.org/pdf/2111.03895.pdf)
>  Digital audio processing tools offer music researchers the opportunity to examine both non-notated music and music as performance. This chapter summarises the types of information that can be extracted from audio as well as currently available audio tools for music corpus studies. The survey of extraction methods includes both a primer on signal processing and background theory on audio feature extraction. The survey of audio tools focuses on widely used tools, including both those with a graphical user interface, namely Audacity and Sonic Visualiser, and code-based tools written in the C/C++, Java, MATLAB, and Python computer programming languages.      
### 87.Resource Allocation in STAR-RIS-Aided Networks: OMA and NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2111.03883.pdf)
>  Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is a promising technology to achieve full-space coverage. This paper investigates the resource allocation problem in a STAR-RIS-assisted multi-carrier communication network. To maximize the system sum-rate, a joint optimization problem for orthogonal multiple access (OMA) is first formulated, which is a mixed-integer non-linear programming problem. To solve this challenging problem, we first propose a channel assignment scheme utilizing matching theory and then invoke the alternating optimization-based method to optimize the resource allocation policy and beamforming vectors iteratively. Furthermore, the sum-rate maximization problem for non-orthogonal multiple access (NOMA) is investigated. To efficiently solve it, we first propose a location-based matching algorithm to determine the sub-channel assignment, where a transmitted user and a reflected user are grouped on a sub-channel. Then, a three-step approach is proposed, where the decoding orders, beamforming-coefficient vectors, and power allocation are optimized by employing semidefinite programming, convex upper bound approximation, and geometry programming, respectively. Numerical results unveil that: 1) For OMA, a general design that includes same-side user-pairing for channel assignment is preferable, while for NOMA, the proposed transmission-and-reflection scheme can achieve near-optimal performance. 2) The STAR-RIS-aided NOMA network significantly outperforms the networks employing conventional RISs and OMA.      
### 88.Learning equilibria with personalized incentives in a class of nonmonotone games  [ :arrow_down: ](https://arxiv.org/pdf/2111.03854.pdf)
>  We consider quadratic, nonmonotone generalized Nash equilibrium problems with symmetric interactions among the agents, which are known to be potential. As may happen in practical cases, we envision a scenario in which an explicit expression of the underlying potential function is not available, and we design a two-layer Nash equilibrium seeking algorithm. In the proposed scheme, a coordinator iteratively integrates the noisy agents' feedback to learn the pseudo-gradients of the agents, and then design personalized incentives for them. On their side, the agents receive those personalized incentives, compute a solution to an extended game, and then return feedback measures to the coordinator. We show that our algorithm returns an equilibrium in case the coordinator is endowed with standard learning policies, and corroborate our results on a numerical instance of a hypomonotone game.      
### 89.Multi-modal land cover mapping of remote sensing images using pyramid attention and gated fusion networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.03845.pdf)
>  Multi-modality data is becoming readily available in remote sensing (RS) and can provide complementary information about the Earth's surface. Effective fusion of multi-modal information is thus important for various applications in RS, but also very challenging due to large domain differences, noise, and redundancies. There is a lack of effective and scalable fusion techniques for bridging multiple modality encoders and fully exploiting complementary information. To this end, we propose a new multi-modality network (MultiModNet) for land cover mapping of multi-modal remote sensing data based on a novel pyramid attention fusion (PAF) module and a gated fusion unit (GFU). The PAF module is designed to efficiently obtain rich fine-grained contextual representations from each modality with a built-in cross-level and cross-view attention fusion mechanism, and the GFU module utilizes a novel gating mechanism for early merging of features, thereby diminishing hidden redundancies and noise. This enables supplementary modalities to effectively extract the most valuable and complementary information for late feature fusion. Extensive experiments on two representative RS benchmark datasets demonstrate the effectiveness, robustness, and superiority of the MultiModNet for multi-modal land cover classification.      
### 90.SIG-VC: A Speaker Information Guided Zero-shot Voice Conversion System for Both Human Beings and Machines  [ :arrow_down: ](https://arxiv.org/pdf/2111.03811.pdf)
>  Nowadays, as more and more systems achieve good performance in traditional voice conversion (VC) tasks, people's attention gradually turns to VC tasks under extreme conditions. In this paper, we propose a novel method for zero-shot voice conversion. We aim to obtain intermediate representations for speaker-content disentanglement of speech to better remove speaker information and get pure content information. Accordingly, our proposed framework contains a module that removes the speaker information from the acoustic feature of the source speaker. Moreover, speaker information control is added to our system to maintain the voice cloning performance. The proposed system is evaluated by subjective and objective metrics. Results show that our proposed system significantly reduces the trade-off problem in zero-shot voice conversion, while it also manages to have high spoofing power to the speaker verification system.      
### 91.Robust data analysis and imaging with computational ghost imaging  [ :arrow_down: ](https://arxiv.org/pdf/2111.03790.pdf)
>  Nowadays the world has entered into the digital age, in which the data analysis and visualization have become more and more important. In analogy to imaging the real object, we demonstrate that the computational ghost imaging can image the digital data to show their characteristics, such as periodicity. Furthermore, our experimental results show that the use of optical imaging methods to analyse data exhibits unique advantages, especially in anti-interference. The data analysis with computational ghost imaging can be well performed against strong noise, random amplitude and phase changes in the binarized signals. Such robust data data analysis and imaging has an important application prospect in big data analysis, meteorology, astronomy, economics and many other fields.      
### 92.Privacy attacks for automatic speech recognition acoustic models in a federated learning framework  [ :arrow_down: ](https://arxiv.org/pdf/2111.03777.pdf)
>  This paper investigates methods to effectively retrieve speaker information from the personalized speaker adapted neural network acoustic models (AMs) in automatic speech recognition (ASR). This problem is especially important in the context of federated learning of ASR acoustic models where a global model is learnt on the server based on the updates received from multiple clients. We propose an approach to analyze information in neural network AMs based on a neural network footprint on the so-called Indicator dataset. Using this method, we develop two attack models that aim to infer speaker identity from the updated personalized models without access to the actual users' speech data. Experiments on the TED-LIUM 3 corpus demonstrate that the proposed approaches are very effective and can provide equal error rate (EER) of 1-2%.      
### 93.CloudRCA: A Root Cause Analysis Framework for Cloud Computing Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2111.03753.pdf)
>  As business of Alibaba expands across the world among various industries, higher standards are imposed on the service quality and reliability of big data cloud computing platforms which constitute the infrastructure of Alibaba Cloud. However, root cause analysis in these platforms is non-trivial due to the complicated system architecture. In this paper, we propose a root cause analysis framework called CloudRCA which makes use of heterogeneous multi-source data including Key Performance Indicators (KPIs), logs, as well as topology, and extracts important features via state-of-the-art anomaly detection and log analysis techniques. The engineered features are then utilized in a Knowledge-informed Hierarchical Bayesian Network (KHBN) model to infer root causes with high accuracy and efficiency. Ablation study and comprehensive experimental comparisons demonstrate that, compared to existing frameworks, CloudRCA 1) consistently outperforms existing approaches in f1-score across different cloud systems; 2) can handle novel types of root causes thanks to the hierarchical structure of KHBN; 3) performs more robustly with respect to algorithmic configurations; and 4) scales more favorably in the data and feature sizes. Experiments also show that a cross-platform transfer learning mechanism can be adopted to further improve the accuracy by more than 10\%. CloudRCA has been integrated into the diagnosis system of Alibaba Cloud and employed in three typical cloud computing platforms including MaxCompute, Realtime Compute and Hologres. It saves Site Reliability Engineers (SREs) more than $20\%$ in the time spent on resolving failures in the past twelve months and improves service reliability significantly.      
### 94.Frugal Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.03731.pdf)
>  Machine learning, already at the core of increasingly many systems and applications, is set to become even more ubiquitous with the rapid rise of wearable devices and the Internet of Things. In most machine learning applications, the main focus is on the quality of the results achieved (e.g., prediction accuracy), and hence vast amounts of data are being collected, requiring significant computational resources to build models. In many scenarios, however, it is infeasible or impractical to set up large centralized data repositories. In personal health, for instance, privacy issues may inhibit the sharing of detailed personal data. In such cases, machine learning should ideally be performed on wearable devices themselves, which raises major computational limitations such as the battery capacity of smartwatches. This paper thus investigates frugal learning, aimed to build the most accurate possible models using the least amount of resources. A wide range of learning algorithms is examined through a frugal lens, analyzing their accuracy/runtime performance on a wide range of data sets. The most promising algorithms are thereafter assessed in a real-world scenario by implementing them in a smartwatch and letting them learn activity recognition models on the watch itself.      
### 95.A space of goals: the cognitive geometry of informationally bounded agents  [ :arrow_down: ](https://arxiv.org/pdf/2111.03699.pdf)
>  Traditionally, Euclidean geometry is treated by scientists as a priori and objective. However, when we take the position of an agent, the problem of selecting a best route should also factor in the abilities of the agent, its embodiment and particularly its cognitive effort. In this paper we consider geometry in terms of travel between states within a world by incorporating information processing costs with the appropriate spatial distances. This induces a geometry that increasingly differs from the original geometry of the given world, as information costs become increasingly important. We visualize this \textit{"cognitive geometry"} by projecting it onto 2- and 3-dimensional spaces showing distinct distortions reflecting the emergence of epistemic and information-saving strategies as well as pivot states. The analogies between traditional cost-based geometries and those induced by additional informational costs invite a generalization of the traditional notion of geodesics as cheapest routes towards the notion of \textit{infodesics}. Crucially, the concept of infodesics approximates the usual geometric property that, travelling from a start to a goal along a geodesic, not only the goal, but all intermediate points are equally visited at optimal cost from the start.      
### 96.Disaster mapping from satellites: damage detection with crowdsourced point labels  [ :arrow_down: ](https://arxiv.org/pdf/2111.03693.pdf)
>  High-resolution satellite imagery available immediately after disaster events is crucial for response planning as it facilitates broad situational awareness of critical infrastructure status such as building damage, flooding, and obstructions to access routes. Damage mapping at this scale would require hundreds of expert person-hours. However, a combination of crowdsourcing and recent advances in deep learning reduces the effort needed to just a few hours in real time. Asking volunteers to place point marks, as opposed to shapes of actual damaged areas, significantly decreases the required analysis time for response during the disaster. However, different volunteers may be inconsistent in their marking. This work presents methods for aggregating potentially inconsistent damage marks to train a neural network damage detector.      
### 97.High Voltage Generation by Fiber-Coupled Pulsed Laser for a Simple Receiver Circuit Structure  [ :arrow_down: ](https://arxiv.org/pdf/2111.03680.pdf)
>  Almost all high-voltage dc generation for low-power applications is done by either electrostatic machines or voltage multipliers. Electrostatic machines use mechanically moving parts to transfer charge and energy from the low-voltage side to the high-voltage side. Voltage multipliers use capacitive and inductive networks to achieve the same purpose of energy transfer. Considering the pros and cons inherent in those mechanical, capacitive, and inductive energy transfer, a new means of energy transfer may provide a superior design of a high voltage dc generator. Here we investigate the design of high voltage generators based on optical power transfer. Optical power delivered via fiber-optic cable allows extensive input-to-output dc insulation and spatial separation. These characteristics lead to advantages with respect to ease of insulation, ease of electromagnetic shielding, and scalability. We experimentally validate the idea by building and testing a 5.5 kV dc generator module solely powered by a 20 kHz pulsed laser, and cascading three of those modules to obtain 14.7 kV dc output voltage. We then discuss possible improvements to the circuit design to make it useful for real-world applications. Finally, we demonstrate an optically powered electroadhesion gripper to show the practicality of the proposed high voltage generator.      
### 98.Oracle Teacher: Towards Better Knowledge Distillation  [ :arrow_down: ](https://arxiv.org/pdf/2111.03664.pdf)
>  Knowledge distillation (KD), best known as an effective method for model compression, aims at transferring the knowledge of a bigger network (teacher) to a much smaller network (student). Conventional KD methods usually employ the teacher model trained in a supervised manner, where output labels are treated only as targets. Extending this supervised scheme further, we introduce a new type of teacher model for KD, namely Oracle Teacher, that utilizes the embeddings of both the source inputs and the output labels to extract a more accurate knowledge to be transferred to the student. The proposed model follows the encoder-decoder attention structure of the Transformer network, which allows the model to attend to related information from the output labels. Extensive experiments are conducted on three different sequence learning tasks: speech recognition, scene text recognition, and machine translation. From the experimental results, we empirically show that the proposed model improves the students across these tasks while achieving a considerable speed-up in the teacher model's training time.      
