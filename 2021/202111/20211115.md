# ArXiv eess --Mon, 15 Nov 2021
### 1.Rigid Motion Invariant Statistical Shape Modeling based on Discrete Fundamental Forms  [ :arrow_down: ](https://arxiv.org/pdf/2111.06850.pdf)
>  We present a novel approach for nonlinear statistical shape modeling that is invariant under Euclidean motion and thus alignment-free. By analyzing metric distortion and curvature of shapes as elements of Lie groups in a consistent Riemannian setting, we construct a framework that reliably handles large deformations. Due to the explicit character of Lie group operations, our non-Euclidean method is very efficient allowing for fast and numerically robust processing. This facilitates Riemannian analysis of large shape populations accessible through longitudinal and multi-site imaging studies providing increased statistical power. Additionally, as planar configurations form a submanifold in shape space, our representation allows for effective estimation of quasi-isometric surfaces flattenings. We evaluate the performance of our model w.r.t. shape-based classification of hippocampus and femur malformations due to Alzheimer's disease and osteoarthritis, respectively. In particular, we outperform state-of-the-art classifiers based on geometric deep learning as well as statistical shape modeling especially in presence of sparse training data. We evaluate the performance of our model w.r.t. shape-based classification of pathological malformations of the human knee and show that it outperforms the standard Euclidean as well as a recent nonlinear approach especially in presence of sparse training data. To provide insight into the model's ability of capturing biological shape variability, we carry out an analysis of specificity and generalization ability.      
### 2.Impact of Strategic Electric Vehicles Driving Behavior on the Grid  [ :arrow_down: ](https://arxiv.org/pdf/2111.06823.pdf)
>  In the context of transport electrification, a model coupling Electric Vehicles (EV) driving and charging decisions is considered. While a Traffic Assignment Problem (TAP) is considered for the driving part, the charging operation is done with an exact load flow on a simple distribution network. This setting allows assessing precisely the coupled impact of driving and charging decisions. In particular, to schedule the charging need coming from the driving part, different charging strategies are defined and compared according to a cost metric based on the load flow computation. In view of this metric, the proposed non-load flow based strategies can perform similarly to a load flow based one, and with significantly reduced computation time and data need. Numerical simulations show how a transportation toll can influence the charging results.      
### 3.Matryoshka and Disjoint Cluster Synchronization of Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.06715.pdf)
>  The main motivation for this paper is to present a definition of network synchronizability for the case of cluster synchronization, similar to the definition introduced by Barahona and Pecora for the case of complete synchronization. We find this problem to be substantially more complex than the original one. We distinguish between the cases that the master stability function is negative in either a bounded or an unbounded range of its argument. For CS, each cluster may be stable independent of the others, which indicates that the range of a given parameter that synchronizes the cluster may be different for different clusters (isolated CS.) For each pair of clusters, we distinguish between three different cases: Matryoshka Cluster Synchronization (when the range of stability for one cluster is included in that of the other cluster), Partially Disjoint Cluster Synchronization (when the ranges of stability partially overlap), and Complete Disjoint Cluster Synchronization (when the ranges of stability do not overlap.) Among these cases, only the case of Matryoshka synchronization had been previously reported. However, a study of several real networks from the literature shows that Partially Disjoint Cluster Synchronization is prevalent in these networks.      
### 4.Transformer-based Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2111.06707.pdf)
>  A Transformer-based Image Compression (TIC) approach is developed which reuses the canonical variational autoencoder (VAE) architecture with paired main and hyper encoder-decoders. Both main and hyper encoders are comprised of a sequence of neural transformation units (NTUs) to analyse and aggregate important information for more compact representation of input image, while the decoders mirror the encoder-side operations to generate pixel-domain image reconstruction from the compressed bitstream. Each NTU is consist of a Swin Transformer Block (STB) and a convolutional layer (Conv) to best embed both long-range and short-range information; In the meantime, a casual attention module (CAM) is devised for adaptive context modeling of latent features to utilize both hyper and autoregressive priors. The TIC rivals with state-of-the-art approaches including deep convolutional neural networks (CNNs) based learnt image coding (LIC) methods and handcrafted rules-based intra profile of recently-approved Versatile Video Coding (VVC) standard, and requires much less model parameters, e.g., up to 45% reduction to leading-performance LIC.      
### 5.A Bayesian Nash equilibrium-based moving target defense against stealthy sensor attacks  [ :arrow_down: ](https://arxiv.org/pdf/2111.06682.pdf)
>  We present a moving target defense strategy to reduce the impact of stealthy sensor attacks on feedback systems. The defender periodically and randomly switches between thresholds from a discrete set to increase the uncertainty for the attacker and make stealthy attacks detectable. However, the defender does not know the exact goal of the attacker but only the prior of the possible attacker goals. Here, we model one period with a constant threshold as a Bayesian game and use the Bayesian Nash equilibrium to find the distribution for the choice of the threshold in that period, which takes the defender's uncertainty about the attacker into account. To obtain the equilibrium distribution, the defender minimizes its cost consisting of the cost for false alarms and the cost induced by the attack. We present a necessary and sufficient condition for the existence of a moving target defense and formulate a linear program to determine the moving target defense. Furthermore, we present a closed-form solution for the special case when the defender knows the attacker's goals. The results are numerically evaluated on a four-tank process.      
### 6.HLT-NUS SUBMISSION FOR 2020 NIST Conversational Telephone Speech SRE  [ :arrow_down: ](https://arxiv.org/pdf/2111.06671.pdf)
>  This work provides a brief description of Human Language Technology (HLT) Laboratory, National University of Singapore (NUS) system submission for 2020 NIST conversational telephone speech (CTS) speaker recognition evaluation (SRE). The challenge focuses on evaluation under CTS data containing multilingual speech. The systems developed at HLT-NUS consider time-delay neural network (TDNN) x-vector and ECAPA-TDNN systems. We also perform domain adaption of probabilistic linear discriminant analysis (PLDA) model and adaptive s-norm on our systems. The score level fusion of TDNN x-vector and ECAPA-TDNN systems is carried out, which improves the final system performance of our submission to 2020 NIST CTS SRE.      
### 7.Photonics-based de-chirping and leakage cancellation for frequency-modulated continuous-wave radar system  [ :arrow_down: ](https://arxiv.org/pdf/2111.06622.pdf)
>  A photonics-based leakage cancellation and echo signal de-chirping approach for frequency-modulated continuous-wave radar systems is proposed based on a dual-drive Mach-Zehnder modulator (DD-MZM), with its performance evaluated by the radar measurement and imaging. The de-chirp reference signal and the leakage cancellation reference signal are combined and applied to the upper arm of the DD-MZM, while the received signal including the leakage signal and echo signals is applied to the lower arm of the DD-MZM. When the amplitudes and delays of the leakage cancellation reference signal and the leakage signal are precisely matched and the DD-MZM is biased at the minimum transmission point, the leakage signal is canceled in the optical domain. The de-chirped signals are obtained after the leakage-free optical signal is detected in a photodetector. An experiment is performed. The cancellation depth of the de-chirped leakage signal is around 23 dB when the center frequency and bandwidth of the linearly frequency-modulated signal are 11.5 and 2 GHz. The leakage cancellation scheme is used in a radar system. When the leakage cancellation is not employed, the leakage signal will seriously affect the imaging results and distance measurement accuracy of the radar system. When the leakage cancellation is applied, the imaging results of multiple targets can be clearly distinguished, and the error of the distance measurement results is significantly reduced to 10 cm.      
### 8.Ramp metering: modeling, simulations and control issues  [ :arrow_down: ](https://arxiv.org/pdf/2111.06610.pdf)
>  The aim of ramp metering is to improve the highway traffic conditions by an appropriate regulation of the inflow from the on-ramps to the highway mainstream. Our presentation rests on several improvements: 1) Our simulation techniques do not need contrarily to other approaches any heuristic fundamental law. 2) There is no need of crucial time-varying quantities, like the critical density, which is most difficult to estimate correctly online. 3) Our feedback loop, which is stemming from model-free control, is easy to implement and shows an excellent robustness with respect to model mismatch. Several computer experiments are displayed and discussed.      
### 9.AC-VC: Non-parallel Low Latency Phonetic Posteriorgrams Based Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2111.06601.pdf)
>  This paper presents AC-VC (Almost Causal Voice Conversion), a phonetic posteriorgrams based voice conversion system that can perform any-to-many voice conversion while having only 57.5 ms future look-ahead. The complete system is composed of three neural networks trained separately with non-parallel data. While most of the current voice conversion systems focus primarily on quality irrespective of algorithmic latency, this work elaborates on designing a method using a minimal amount of future context thus allowing a future real-time implementation. According to a subjective listening test organized in this work, the proposed AC-VC system achieves parity with the non-causal ASR-TTS baseline of the Voice Conversion Challenge 2020 in naturalness with a MOS of 3.5. In contrast, the results indicate that missing future context impacts speaker similarity. Obtained similarity percentage of 65% is lower than the similarity of current best voice conversion systems.      
### 10.Towards 6G Internet of Things: Recent Advances, Use Cases, and Open Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2111.06596.pdf)
>  Smart services based on the Internet of Everything (IoE) are gaining considerable popularity due to the ever-increasing demands of wireless networks. This demands the appraisal of the wireless networks with enhanced properties as next-generation communication systems. Although 5G networks show great potential to support numerous IoE based services, it is not adequate to meet the complete requirements of the new smart applications. Therefore, there is an increased demand for envisioning the 6G wireless communication systems to overcome the major limitations in the existing 5G networks. Moreover, incorporating artificial intelligence in 6G will provide solutions for very complex problems relevant to network optimization. Furthermore, to add further value to the future 6G networks, researchers are investigating new technologies, such as THz and quantum communications. The requirements of future 6G wireless communications demand to support massive data-driven applications and the increasing number of users. This paper presents recent advances in the 6G wireless networks, including the evolution from 1G to 5G communications, the research trends for 6G, enabling technologies, and state-of-the-art 6G projects.      
### 11.Digital-assisted photonic analog wideband multipath self-interference cancellation  [ :arrow_down: ](https://arxiv.org/pdf/2111.06594.pdf)
>  A digital-assisted photonic analog wideband radio-frequency multipath self-interference cancellation (SIC) and frequency downconversion method based on a dual-drive Mach-Zehnder modulator and the recursive least square (RLS) algorithm is proposed and demonstrated for in-band full-duplex systems. Besides the reference for the direct-path self-interference (SI) signal, the RLS algorithm is used to construct another reference for the residual SI signal from the direct path and the SI signals from the reflection paths. The proposed method can solve the performance limitation in the previously reported SIC methods of constructing the multipath SI signal using a single reference caused by the limited dynamic range of the digital-to-analog converter when the direct-path SI signal is much stronger than the sub-weak reflection-path SI signals. An experiment is performed. When the carrier frequency of the multipath SI signal is 10 GHz and the direct-path SI signal is much stronger than the sub-weak multipath SI signal, the cancellation depths of about 26.7 and 26.1 dB are realized with SI baud rates of 0.5 and 1 Gbaud. When the direct-path SI signal and sub-weak multipath SI signal own closer power, the corresponding cancellation depths are 24.7 and 20.8 dB, respectively.      
### 12.Data-Driven Pole Placement in LMI Regions with Robustness Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2111.06590.pdf)
>  This paper proposes a robust learning methodology to place the closed-loop poles in desired convex regions in the complex plane. We considered the system state and input matrices to be unknown and can only use the measurements of the system trajectories. The closed-loop pole placement problem in the linear matrix inequality (LMI) regions is considered a classic robust control problem; however, that requires knowledge about the state and input matrices of the linear system. We bring in ideas from the behavioral system theory and persistency of excitation condition-based fundamental lemma to develop a data-driven counterpart that satisfies multiple closed-loop robustness specifications, such as $\mathcal{D}$-stability and mixed $H_2/H_{\infty}$ performance specifications. Our formulations lead to data-driven semi-definite programs (SDPs) that are coupled with sufficient theoretical guarantees. We validate the theoretical results with numerical simulations on a third-order dynamic system.      
### 13.A new technique for compression of data sets  [ :arrow_down: ](https://arxiv.org/pdf/2111.06572.pdf)
>  Data compression techniques are characterized by four key performance indices which are (i) associated accuracy, (ii) compression ratio, (iii) computational work, and (iv) degree of freedom. The method of data compression developed in this paper allows us to substantially improve all the four issues above. The proposed transform $F$ is presented in the form of a sum with $p-1$ terms, $F_1,..., F_{p-1}$, where each term is a particular sub-transform presented by a first degree polynomial. For $j=1,\ldots,p-1$, each sub-transform $F_{j}$ is determined from interpolation-like conditions. This device provides the transform flexibility to incorporate variation of observed data and leads to performance improvement. The transform $F$ has two degrees of freedom, the number of sub-transforms and associated compression ratio associated with each sub-transform $F_{j}$.      
### 14.Diffuse arrays that autocorrelate and project as delta-like points  [ :arrow_down: ](https://arxiv.org/pdf/2111.06568.pdf)
>  Diffuse two-dimensional integer-valued arrays are demonstrated that have delta-like aperiodic autocorrelation and, simultaneously, the array sums form delta-like projections along several directions. The delta-projected views show a single sharp spike at the central ray. When such arrays are embedded in larger blocks of two-dimensional data, their location can be fixed precisely via the fast and simple intersection of the back-projected central rays along two or more directions. This mechanism complements localization of the same array from its delta-like autocorrelation, which, although more robust, is slower and more complex to compute.      
### 15.An analysis of voltage source inverter switches fault classification using short time Fourier transform  [ :arrow_down: ](https://arxiv.org/pdf/2111.06566.pdf)
>  The dependability of power electronics systems, such as three-phase inverters, is critical in a variety of applications. Different types of failures that occur in an inverter circuit might affect system operation and raise the entire cost of the manufacturing process. As a result, detecting and identifying inverter problems for such devices is critical in industry. This study presents the short-time Fourier transform (STFT) for fault classification and identification in three-phase type, voltage source inverter (VSI) switches. Time-frequency representation (TFR) represents the signal analysis of STFT, which includes total harmonic distortion, instantaneous RMS current, RMS fundamental current, total non harmonic distortion, total waveform distortion and average current. The features of the faults are used with a rule-based classifier based on the signal parameters to categorise and detect the switch faults. The suggested method's performance is evaluated using 60 signals containing short and open circuit faults with varying characteristics for each switch in VSI. The classification results demonstrate the proposed technique is good to be implemented for VSI switches faults classification, with an accuracy classification rate of 98.3%.      
### 16.Disentangling Physical Parameters for Anomalous Sound Detection Under Domain Shifts  [ :arrow_down: ](https://arxiv.org/pdf/2111.06539.pdf)
>  To develop a sound-monitoring system for machines, a method for detecting anomalous sound under domain shifts is proposed. A domain shift occurs when a machine's physical parameters change. Because a domain shift changes the distribution of normal sound data, conventional unsupervised anomaly detection methods can output false positives. To solve this problem, the proposed method constrains some latent variables of a normalizing flows (NF) model to represent physical parameters, which enables disentanglement of the factors of domain shifts and learning of a latent space that is invariant with respect to these domain shifts. Anomaly scores calculated from this domain-shift-invariant latent space are unaffected by such shifts, which reduces false positives and improves the detection performance. Experiments were conducted with sound data from a slide rail under different operation velocities. The results show that the proposed method disentangled the velocity to obtain a latent space that was invariant with respect to domain shifts, which improved the AUC by 13.2% for Glow with a single block and 2.6% for Glow with multiple blocks.      
### 17.A Time-Series Scale Mixture Model of EEG with a Hidden Markov Structure for Epileptic Seizure Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.06526.pdf)
>  In this paper, we propose a time-series stochastic model based on a scale mixture distribution with Markov transitions to detect epileptic seizures in electroencephalography (EEG). In the proposed model, an EEG signal at each time point is assumed to be a random variable following a Gaussian distribution. The covariance matrix of the Gaussian distribution is weighted with a latent scale parameter, which is also a random variable, resulting in the stochastic fluctuations of covariances. By introducing a latent state variable with a Markov chain in the background of this stochastic relationship, time-series changes in the distribution of latent scale parameters can be represented according to the state of epileptic seizures. In an experiment, we evaluated the performance of the proposed model for seizure detection using EEGs with multiple frequency bands decomposed from a clinical dataset. The results demonstrated that the proposed model can detect seizures with high sensitivity and outperformed several baselines.      
### 18.Unique Bispectrum Inversion for Signals with Finite Spectral/Temporal Support  [ :arrow_down: ](https://arxiv.org/pdf/2111.06479.pdf)
>  Retrieving a signal from the Fourier transform of its third-order statistics or bispectrum arises in a wide range of signal processing problems. Conventional methods do not provide a unique inversion of bispectrum. In this paper, we present a an approach that uniquely recovers signals with finite spectral support (band-limited signals) from at least $3B$ measurements of its bispectrum function (BF), where $B$ is the signal's bandwidth. Our approach also extends to time-limited signals. We propose a two-step trust region algorithm that minimizes a non-convex objective function. First, we approximate the signal by a spectral algorithm. Then, we refine the attained initialization based upon a sequence of gradient iterations. Numerical experiments suggest that our proposed algorithm is able to estimate band/time-limited signals from its BF for both complete and undersampled observations.      
### 19.MultiSV: Dataset for Far-Field Multi-Channel Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2111.06458.pdf)
>  Motivated by unconsolidated data situation and the lack of a standard benchmark in the field, we complement our previous efforts and present a comprehensive corpus designed for training and evaluating text-independent multi-channel speaker verification systems. It can be readily used also for experiments with dereverberation, denoising, and speech enhancement. We tackled the ever-present problem of the lack of multi-channel training data by utilizing data simulation on top of clean parts of the Voxceleb dataset. The development and evaluation trials are based on a retransmitted Voices Obscured in Complex Environmental Settings (VOiCES) corpus, which we modified to provide multi-channel trials. We publish full recipes that create the dataset from public sources as the MultiSV corpus, and we provide results with two of our multi-channel speaker verification systems with neural network-based beamforming based either on predicting ideal binary masks or the more recent Conv-TasNet.      
### 20.Multiple Hypothesis Hypergraph Tracking for Posture Identification in Embryonic Caenorhabditis elegans  [ :arrow_down: ](https://arxiv.org/pdf/2111.06425.pdf)
>  Current methods in multiple object tracking (MOT) rely on independent object trajectories undergoing predictable motion to effectively track large numbers of objects. Adversarial conditions such as volatile object motion and imperfect detections create a challenging tracking landscape in which established methods may yield inadequate results. Multiple hypothesis hypergraph tracking (MHHT) is developed to perform MOT among interdependent objects amid noisy detections. The method extends traditional multiple hypothesis tracking (MHT) via hypergraphs to model correlated object motion, allowing for robust tracking in challenging scenarios. MHHT is applied to perform seam cell tracking during late-stage embryogenesis in embryonic C. elegans.      
### 21.Stacked U-Nets with Self-Assisted Priors Towards Robust Correction of Rigid Motion Artifact in Brain MRI  [ :arrow_down: ](https://arxiv.org/pdf/2111.06401.pdf)
>  In this paper, we develop an efficient retrospective deep learning method called stacked U-Nets with self-assisted priors to address the problem of rigid motion artifacts in MRI. The proposed work exploits the usage of additional knowledge priors from the corrupted images themselves without the need for additional contrast data. The proposed network learns missed structural details through sharing auxiliary information from the contiguous slices of the same distorted subject. We further design a refinement stacked U-Nets that facilitates preserving of the image spatial details and hence improves the pixel-to-pixel dependency. To perform network training, simulation of MRI motion artifacts is inevitable. We present an intensive analysis using various types of image priors: the proposed self-assisted priors and priors from other image contrast of the same subject. The experimental analysis proves the effectiveness and feasibility of our self-assisted priors since it does not require any further data scans.      
### 22.Fast T2w/FLAIR MRI Acquisition by Optimal Sampling of Information Complementary to Pre-acquired T1w MRI  [ :arrow_down: ](https://arxiv.org/pdf/2111.06400.pdf)
>  Recent studies on T1-assisted MRI reconstruction for under-sampled images of other modalities have demonstrated the potential of further accelerating MRI acquisition of other modalities. Most of the state-of-the-art approaches have achieved improvement through the development of network architectures for fixed under-sampling patterns, without fully exploiting the complementary information between modalities. Although existing under-sampling pattern learning algorithms can be simply modified to allow the fully-sampled T1-weighted MR image to assist the pattern learning, no significant improvement on the reconstruction task can be achieved. To this end, we propose an iterative framework to optimize the under-sampling pattern for MRI acquisition of another modality that can complement the fully-sampled T1-weighted MR image at different under-sampling factors, while jointly optimizing the T1-assisted MRI reconstruction model. Specifically, our proposed method exploits the difference of latent information between the two modalities for determining the sampling patterns that can maximize the assistance power of T1-weighted MR image in improving the MRI reconstruction. We have demonstrated superior performance of our learned under-sampling patterns on a public dataset, compared to commonly used under-sampling patterns and state-of-the-art methods that can jointly optimize both the reconstruction network and the under-sampling pattern, up to 8-fold under-sampling factor.      
### 23.Selective Synthetic Augmentation with HistoGAN for Improved Histopathology Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2111.06399.pdf)
>  Histopathological analysis is the present gold standard for precancerous lesion diagnosis. The goal of automated histopathological classification from digital images requires supervised training, which requires a large number of expert annotations that can be expensive and time-consuming to collect. Meanwhile, accurate classification of image patches cropped from whole-slide images is essential for standard sliding window based histopathology slide classification methods. To mitigate these issues, we propose a carefully designed conditional GAN model, namely HistoGAN, for synthesizing realistic histopathology image patches conditioned on class labels. We also investigate a novel synthetic augmentation framework that selectively adds new synthetic image patches generated by our proposed HistoGAN, rather than expanding directly the training set with synthetic images. By selecting synthetic images based on the confidence of their assigned labels and their feature similarity to real labeled images, our framework provides quality assurance to synthetic augmentation. Our models are evaluated on two datasets: a cervical histopathology image dataset with limited annotations, and another dataset of lymph node histopathology images with metastatic cancer. Here, we show that leveraging HistoGAN generated images with selective augmentation results in significant and consistent improvements of classification performance (6.7% and 2.8% higher accuracy, respectively) for cervical histopathology and metastatic cancer datasets.      
### 24.A Multi-attribute Controllable Generative Model for Histopathology Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2111.06398.pdf)
>  Generative models have been applied in the medical imaging domain for various image recognition and synthesis tasks. However, a more controllable and interpretable image synthesis model is still lacking yet necessary for important applications such as assisting in medical training. In this work, we leverage the efficient self-attention and contrastive learning modules and build upon state-of-the-art generative adversarial networks (GANs) to achieve an attribute-aware image synthesis model, termed AttributeGAN, which can generate high-quality histopathology images based on multi-attribute inputs. In comparison to existing single-attribute conditional generative models, our proposed model better reflects input attributes and enables smoother interpolation among attribute values. We conduct experiments on a histopathology dataset containing stained H&amp;E images of urothelial carcinoma and demonstrate the effectiveness of our proposed model via comprehensive quantitative and qualitative comparisons with state-of-the-art models as well as different variants of our model. Code is available at <a class="link-external link-https" href="https://github.com/karenyyy/MICCAI2021AttributeGAN" rel="external noopener nofollow">this https URL</a>.      
### 25.Guided Sampling-based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2111.06885.pdf)
>  The diagnostic performance of most of the deep learning models is greatly affected by the selection of model architecture and their hyperparameters. The main challenges in model selection methodologies are the design of architecture optimizer and model evaluation strategy. In this paper, we have proposed a novel framework of evolutionary deep neural network which uses policy gradient to guide the evolution of DNN architecture towards maximum diagnostic accuracy. We have formulated a policy gradient-based controller which generates an action to sample the new model architecture at every generation. The best fitness obtained is used as a reward to update the policy parameters. Also, the best model obtained is transferred to the next generation for quick model evaluation in the NSGA-II evolutionary framework. Thus, the algorithm gets the benefits of fast non-dominated sorting as well as quick model evaluation. The effectiveness of the proposed framework has been validated on three datasets: the Air Compressor dataset, Case Western Reserve University dataset, and Paderborn university dataset.      
### 26.Deciphering Speech: a Zero-Resource Approach to Cross-Lingual Transfer in ASR  [ :arrow_down: ](https://arxiv.org/pdf/2111.06799.pdf)
>  We present a method for cross-lingual training an ASR system using absolutely no transcribed training data from the target language, and with no phonetic knowledge of the language in question. Our approach uses a novel application of a decipherment algorithm, which operates given only unpaired speech and text data from the target language. We apply this decipherment to phone sequences generated by a universal phone recogniser trained on out-of-language speech corpora, which we follow with flat-start semi-supervised training to obtain an acoustic model for the new language. To the best of our knowledge, this is the first practical approach to zero-resource cross-lingual ASR which does not rely on any hand-crafted phonetic information. We carry out experiments on read speech from the GlobalPhone corpus, and show that it is possible to learn a decipherment model on just 20 minutes of data from the target language. When used to generate pseudo-labels for semi-supervised training, we obtain WERs that range from 25% to just 5% absolute worse than the equivalent fully supervised models trained on the same data.      
### 27.Q-Learning for MDPs with General Spaces: Convergence and Near Optimality via Quantization under Weak Continuity  [ :arrow_down: ](https://arxiv.org/pdf/2111.06781.pdf)
>  Reinforcement learning algorithms often require finiteness of state and action spaces in Markov decision processes (MDPs) and various efforts have been made in the literature towards the applicability of such algorithms for continuous state and action spaces. In this paper, we show that under very mild regularity conditions (in particular, involving only weak continuity of the transition kernel of an MDP), Q-learning for standard Borel MDPs via quantization of states and actions converge to a limit, and furthermore this limit satisfies an optimality equation which leads to near optimality with either explicit performance bounds or which are guaranteed to be asymptotically optimal. Our approach builds on (i) viewing quantization as a measurement kernel and thus a quantized MDP as a POMDP, (ii) utilizing near optimality and convergence results of Q-learning for POMDPs, and (iii) finally, near-optimality of finite state model approximations for MDPs with weakly continuous kernels which we show to correspond to the fixed point of the constructed POMDP. Thus, our paper presents a very general convergence and approximation result for the applicability of Q-learning for continuous MDPs.      
### 28.Resilient Consensus-based Multi-agent Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.06776.pdf)
>  Adversarial attacks during training can strongly influence the performance of multi-agent reinforcement learning algorithms. It is, thus, highly desirable to augment existing algorithms such that the impact of adversarial attacks on cooperative networks is eliminated, or at least bounded. In this work, we consider a fully decentralized network, where each agent receives a local reward and observes the global state and action. We propose a resilient consensus-based actor-critic algorithm, whereby each agent estimates the team-average reward and value function, and communicates the associated parameter vectors to its immediate neighbors. We show that in the presence of Byzantine agents, whose estimation and communication strategies are completely arbitrary, the estimates of the cooperative agents converge to a bounded consensus value with probability one, provided that there are at most $H$ Byzantine agents in the neighborhood of each cooperative agent and the network is $(2H+1)$-robust. Furthermore, we prove that the policy of the cooperative agents converges with probability one to a bounded neighborhood around a local maximizer of their team-average objective function under the assumption that the policies of the adversarial agents asymptotically become stationary.      
### 29.The Time-Freezing Reformulation for Numerical Optimal Control of Complementarity Lagrangian Systems with State Jumps  [ :arrow_down: ](https://arxiv.org/pdf/2111.06759.pdf)
>  This paper introduces a novel reformulation and numerical methods for optimal control of complementarity Lagrangian systems with state jumps. The solutions of the reformulated system have jump discontinuities in the first time derivative instead of the trajectory itself, which is easier to handle theoretically and numerically. We cover not only the easier case of elastic impacts, but also the difficult case, when after the state jump the system evolves on the boundary of the dynamic's feasible set. In nonsmooth mechanics this corresponds to inelastic impacts. The main idea of the time-freezing reformulation is to introduce a clock state and an auxiliary dynamic system whose trajectory endpoints satisfy the state jump law. When the auxiliary system is active, the clock state is not evolving, hence by taking only the parts of the trajectory when the clock state was active, we can recover the original solution. %Formally, we transform Dynamic Complementarity Systems (DCS) with relative degree two into Piecewise Smooth Systems (PSS). For computational convenience, the resulting PSS can be transformed into an DCS with relative degree one, whose solution does not have state jumps. We detail how to recover the solution of the original system, show how to select appropriate auxiliary dynamics and give practical numerical methods to handle discontinuous ODEs with nonunique sliding motions. Moreover, we introduce a novel auxiliary ODE for time-freezing for elastic impacts and overcome some drawbacks of [22]. The theoretical findings are illustrated on the nontrivial numerical optimal control example of a hopping one-legged robot.      
### 30.Monte Carlo dropout increases model repeatability  [ :arrow_down: ](https://arxiv.org/pdf/2111.06754.pdf)
>  The integration of artificial intelligence into clinical workflows requires reliable and robust models. Among the main features of robustness is repeatability. Much attention is given to classification performance without assessing the model repeatability, leading to the development of models that turn out to be unusable in practice. In this work, we evaluate the repeatability of four model types on images from the same patient that were acquired during the same visit. We study the performance of binary, multi-class, ordinal, and regression models on three medical image analysis tasks: cervical cancer screening, breast density estimation, and retinopathy of prematurity classification. Moreover, we assess the impact of sampling Monte Carlo dropout predictions at test time on classification performance and repeatability. Leveraging Monte Carlo predictions significantly increased repeatability for all tasks on the binary, multi-class, and ordinal models leading to an average reduction of the 95% limits of agreement by 17% points.      
### 31.Robust Analytics for Video-Based Gait Biometrics  [ :arrow_down: ](https://arxiv.org/pdf/2111.06670.pdf)
>  Gait analysis is the study of the systematic methods that assess and quantify animal locomotion. Gait finds a unique importance among the many state-of-the-art biometric systems since it does not require the subject's cooperation to the extent required by other modalities. Hence by nature, it is an unobtrusive biometric. <br>This thesis discusses both hard and soft biometric characteristics of gait. It shows how to identify gender based on gait alone through the Posed-Based Voting scheme. It then describes improving gait recognition accuracy using Genetic Template Segmentation. Members of a wide population can be authenticated using Multiperson Signature Mapping. Finally, the mapping can be improved in a smaller population using Bayesian Thresholding. All methods proposed in this thesis have outperformed their existing state of the art with adequate experimentation and results.      
### 32.Fully Automatic Page Turning on Real Scores  [ :arrow_down: ](https://arxiv.org/pdf/2111.06643.pdf)
>  We present a prototype of an automatic page turning system that works directly on real scores, i.e., sheet images, without any symbolic representation. Our system is based on a multi-modal neural network architecture that observes a complete sheet image page as input, listens to an incoming musical performance, and predicts the corresponding position in the image. Using the position estimation of our system, we use a simple heuristic to trigger a page turning event once a certain location within the sheet image is reached. As a proof of concept we further combine our system with an actual machine that will physically turn the page on command.      
### 33.On Effective Secrecy Throughput of Underlay Spectrum Sharing $α$-$μ$/ Málaga Hybrid Model under Interference-and-Transmit Power Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2111.06574.pdf)
>  The underlay cognitive radio-based hybrid radio frequency / free-space optical (RF / FSO) systems have been emerged as a promising technology due to its ability to eliminate spectrum scarcity and spectrum under-utilization problems. Consequently, this work analyzes the physical layer security aspects of a cognitive RF / FSO hybrid network that includes a primary user, a secondary source, a secondary receiver, and an eavesdropper where the secret communication takes place between two legitimate secondary peers over the RF and FSO links simultaneously, and the eavesdropper can overhear the RF link only. In particular, the maximum transmit power limitation at the secondary user as well as the permissible interference power restriction at the primary user are also taken into consideration. All the RF links are modeled with $\alpha$-$\mu$ fading whereas the FSO link undergoes Málaga (M) turbulence with link blockage and pointing error impairments. At the receiver, the selection combining diversity technique is utilized to select the signal with the best electrical signal-to-ratio (SNR). Moreover, the closed-form expressions for the secrecy outage probability, probability of strictly positive secrecy capacity, and effective secrecy throughput are derived to analyze the secrecy performance. Besides, the impacts of fading, primary-secondary interference, detection techniques, link blockage probability, atmospheric turbulence, and pointing error are examined. Finally, Monte-Carlo simulations are performed to corroborate the derived expressions.      
### 34.Queue Length Violation Probability of Joint Channel and Buffer Aware Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2111.06569.pdf)
>  Queue length violation probability, i.e., the tail distribution of the queue length, is a widely used statistical quality-of-service (QoS) metric in wireless communications. Many previous works conducted tail distribution analysis on the control policies with the assumption that the condition of the large deviations theory (LDT) is satisfied. LDT indicates that the tail distribution of the queue length has a linear-decay-rate exponent. However, there are many control policies which do not meet that assumption, while the optimal control policy may be included in these policies. In this paper, we put our focus on the analysis of the tail distribution of the queue length from the perspective of cross-layer design in wireless link transmission. Specifically, we divide the wireless link transmission systems into three scenarios according to the decay rate of the queue-length tail distribution with the finite average power consumption. A heuristic policy is conceived to prove that the arbitrary-decay-rate tail distribution with the finite average power consumption exists in Rayleigh fading channels. Based on this heuristic policy, we generalize the analysis to Nakagami-m fading channels. Numerical results with approximation validate our analysis.      
### 35.A Robust Deep Learning-Based Beamforming Design for RIS-assisted Multiuser MISO Communications with Practical Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2111.06555.pdf)
>  Reconfigurable intelligent surface (RIS) has become a promising technology to improve wireless communication in recent years. It steers the incident signals to create a favorable propagation environment by controlling the reconfigurable passive elements with less hardware cost and lower power consumption. In this paper, we consider a RIS-aided multiuser multiple-input single-output downlink communication system. We aim to maximize the weighted sum-rate of all users by joint optimizing the active beamforming at the access point and the passive beamforming vector of the RIS elements. Unlike most existing works, we consider the more practical situation with the discrete phase shifts and imperfect channel state information (CSI). Specifically, for the situation that the discrete phase shifts and perfect CSI are considered, we first develop a deep quantization neural network (DQNN) to simultaneously design the active and passive beamforming while most reported works design them alternatively. Then, we propose an improved structure (I-DQNN) based on DQNN to simplify the parameters decision process when the control bits of each RIS element are greater than 1 bit. Finally, we extend the two proposed DQNN-based algorithms to the case that the discrete phase shifts and imperfect CSI are considered simultaneously. Our simulation results show that the two DQNN-based algorithms have better performance than traditional algorithms in the perfect CSI case, and are also more robust in the imperfect CSI case.      
### 36.Competitive epidemic networks with multiple survival-of-the-fittest outcomes  [ :arrow_down: ](https://arxiv.org/pdf/2111.06538.pdf)
>  We use a deterministic model to study two competing viruses spreading over a two-layer network in the Susceptible--Infected--Susceptible (SIS) framework, and address the central problem of identifying the winning virus in a "survival-of-the-fittest" battle. Existing sufficient conditions ensure that the same virus always wins regardless of initial states. For networks with an arbitrary but finite number of nodes, we present a necessary and sufficient condition that guarantees local exponential stability of the two equilibria corresponding to each virus winning the battle. Thus, either of the viruses can win, depending on the initial states. We then prove that for almost any network layer of one virus, there exists a network layer for the other virus such that the resulting two-layer network satisfies the aforementioned condition. To operationalize our findings, a four-step procedure is developed to reliably and consistently design one of the network layers, when given the other layer. Numerical case studies illustrate the theoretical result and its practical consequences.      
### 37.Nonlinear Tensor Ring Network  [ :arrow_down: ](https://arxiv.org/pdf/2111.06532.pdf)
>  The state-of-the-art deep neural networks (DNNs) have been widely applied for various real-world applications, and achieved significant performance for cognitive problems. However, the increment of DNNs' width and depth in architecture results in a huge amount of parameters to challenge the storage and memory cost, limiting to the usage of DNNs on resource-constrained platforms, such as portable devices. By converting redundant models into compact ones, compression technique appears to be a practical solution to reducing the storage and memory consumption. In this paper, we develop a nonlinear tensor ring network (NTRN) in which both fullyconnected and convolutional layers are compressed via tensor ring decomposition. Furthermore, to mitigate the accuracy loss caused by compression, a nonlinear activation function is embedded into the tensor contraction and convolution operations inside the compressed layer. Experimental results demonstrate the effectiveness and superiority of the proposed NTRN for image classification using two basic neural networks, LeNet-5 and VGG-11 on three datasets, viz. MNIST, Fashion MNIST and Cifar-10.      
### 38.Domain Generalization on Efficient Acoustic Scene Classification using Residual Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2111.06531.pdf)
>  It is a practical research topic how to deal with multi-device audio inputs by a single acoustic scene classification system with efficient design. In this work, we propose Residual Normalization, a novel feature normalization method that uses frequency-wise normalization % instance normalization with a shortcut path to discard unnecessary device-specific information without losing useful information for classification. Moreover, we introduce an efficient architecture, BC-ResNet-ASC, a modified version of the baseline architecture with a limited receptive field. BC-ResNet-ASC outperforms the baseline architecture even though it contains the small number of parameters. Through three model compression schemes: pruning, quantization, and knowledge distillation, we can reduce model complexity further while mitigating the performance degradation. The proposed system achieves an average test accuracy of 76.3% in TAU Urban Acoustic Scenes 2020 Mobile, development dataset with 315k parameters, and average test accuracy of 75.3% after compression to 61.0KB of non-zero parameters. The proposed method won the 1st place in DCASE 2021 challenge, TASK1A.      
### 39.Scalable Operator Allocation for Multi-Robot Assistance: A Restless Bandit Approach  [ :arrow_down: ](https://arxiv.org/pdf/2111.06437.pdf)
>  In this paper, we consider the problem of allocating human operators in a system with multiple semi-autonomous robots. Each robot is required to perform an independent sequence of tasks, subjected to a chance of failing and getting stuck in a fault state at every task. If and when required, a human operator can assist or teleoperate a robot. Conventional MDP techniques used to solve such problems face scalability issues due to exponential growth of state and action spaces with the number of robots and operators. In this paper we derive conditions under which the operator allocation problem is indexable, enabling the use of the Whittle index heuristic. The conditions can be easily checked to verify indexability, and we show that they hold for a wide range of problems of interest. Our key insight is to leverage the structure of the value function of individual robots, resulting in conditions that can be verified separately for each state of each robot. We apply these conditions to two types of transitions commonly seen in remote robot supervision systems. Through numerical simulations, we demonstrate the efficacy of Whittle index policy as a near-optimal and scalable approach that outperforms existing scalable methods.      
### 40.A Robust Mean-field Game of Boltzmann-Vlasov-like Traffic Flow  [ :arrow_down: ](https://arxiv.org/pdf/2111.06426.pdf)
>  Historically, traffic modelling approaches have taken either a particle-like (microscopic) approach, or a gas-like (meso- or macroscopic) approach. Until recently with the introduction of mean-field games to the controls community, there has not been a rigorous framework to facilitate passage between controls for the microscopic models and the macroscopic models. We begin this work with a particle-based model of autonomous vehicles subject to drag and unknown disturbances, noise, and a speed limit in addition to the control. <br>We formulate a robust stochastic differential game on the particles. We pass formally to the infinite-particle limit to obtain a robust mean-field game PDE system. We solve the mean-field game PDE system numerically and discuss the results. In particular, we obtain an optimal control which increases the bulk velocity of the traffic flow while reducing congestion.      
