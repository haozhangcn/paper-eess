# ArXiv eess --Fri, 5 Nov 2021
### 1.Access Delay Constrained Activity Detection in Massive Random Access  [ :arrow_down: ](https://arxiv.org/pdf/2111.03051.pdf)
>  In 5G and future generation wireless systems, massive IoT networks with bursty traffic are expected to co-exist with cellular systems to serve several latency-critical applications. Thus, it is important for the access points to identify the active devices promptly with minimal resource consumption to enable massive machine-type communication without disrupting the conventional traffic. In this paper, a frequency-multiplexed strategy based on group testing is proposed for activity detection which can take into account the constraints on network latency while minimizing the overall resource utilization. The core idea is that during each time-slot of active device discovery, multiple subcarriers in frequency domain can be used to launch group tests in parallel to reduce delay. Our proposed scheme is functional in the asymptotic and non-asymptotic regime of the total number of devices $(n)$ and the number of concurrently active devices $(k)$. We prove that, asymptotically, when the number of available time-slots scale as $\Omega\big(\log (\frac{n}{k})\big)$, the frequency-multiplexed group testing strategy requires $O\big(k\log (\frac{n}{k})\big)$ time-frequency resources which is order-optimal and results in an $O(k)$ reduction in the number of time-slots with respect to the optimal strategy of fully-adaptive generalized binary splitting. Furthermore, we establish that the frequency-multiplexed GT strategy shows significant tolerance to estimation errors in $k$. Comparison with 3GPP standardized random access protocol for NB-IoT indicates the superiority of our proposed strategy in terms of access delay and overall resource utilization.      
### 2.Barrier States Embedded Iterative Dynamic Game for Robust and Safe Trajectory Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2111.02979.pdf)
>  Considering uncertainties and disturbances is an important, yet challenging, step in successful decision making. The problem becomes more challenging in safety-constrained environments. In this paper, we propose a robust and safe trajectory optimization algorithm through solving a constrained min-max optimal control problem. The proposed method leverages a game theoretic differential dynamic programming approach with barrier states to handle parametric and non-parametric uncertainties in safety-critical control systems. Barrier states are embedded into the differential game's dynamics and cost to portray the constrained environment in a higher dimensional state space and certify the safety of the optimized trajectory. Moreover, we propose to perform line-search in a Stackleberg (leader-follower) game fashion which is shown to increase robustness of our controller. The proposed algorithm is evaluated on a velocity-constrained inverted pendulum model that has a 50% error in the model's parameters to show its efficacy in such a comprehensible system. The algorithm is subsequently implemented on a quadrotor in a windy environment in which sinusoidal wind turbulences applied in all directions.      
### 3.Game-based decision algorithm for socially compatible automated driving: a case study of unsignalized intersection driving  [ :arrow_down: ](https://arxiv.org/pdf/2111.02977.pdf)
>  Smooth and harmonic interacting with other vehicles is one of the ultimate goals of driving automation. However, recent reports of demonstrative deployments of automated vehicles (AVs) indicate that AVs are still difficult to meet the expectation of other interacting drivers, which leads to several AV accidents involving human-driven vehicles (HVs). This is most likely due to the lack of understanding about the dynamic interaction process, especially about the human drivers. By investigating the causes of 4,300 video clips of traffic accidents, it is found that the limited dynamic visual field of drivers is one leading factor in inter-vehicle interaction accidents, especially for those involving trucks. Taking the interaction with a human-driven truck at an unsignalized intersection as an example scenario, a game-theoretic decision algorithm considering social compatibility is proposed. Starting from a probabilistic model for the visual field characteristics of truck drivers, social fitness and reciprocal altruism in decision are incorporated in the game payoff design. Results of human-in-the-loop experiments show that the proposed socially compatible algorithm can effectively improve both safety and time efficiency, and make AV decision more in line with the expectation of interacting human drivers. It can be viewed as a promising solution to handling the interactive issues between automated and human-driven vehicles.      
### 4.idSTLPy: A Python Toolbox for Active Perception and Control  [ :arrow_down: ](https://arxiv.org/pdf/2111.02943.pdf)
>  This paper describes a Python toolbox for active perception and control synthesis of probabilistic signal temporal logic (PrSTL) formulas of switched linear systems with additive Gaussian disturbances and measurement noises. We implement a counterexample-guided synthesis strategy that combines Bounded Model Checking, linear programming, and sampling-based motion planning techniques. We illustrate our approach and the toolbox throughout the paper with a motion planning example for a vehicle with noisy localization. The code is available at \url{<a class="link-external link-https" href="https://codeocean.com/capsule/0013534/tree" rel="external noopener nofollow">this https URL</a>}.      
### 5.Efficient approximation of Jacobian matrices involving a non-uniform fast Fourier transform (NUFFT)  [ :arrow_down: ](https://arxiv.org/pdf/2111.02912.pdf)
>  There is growing interest in learning k-space sampling patterns for MRI using optimization approaches. For non-Cartesian sampling patterns, reconstruction methods typically involve non-uniform FFT (NUFFT) operations. A typical NUFFT method contains frequency domain interpolation using Kaiser-Bessel kernel values that are retrieved by nearest neighbor look-up in a finely tabulated kernel. That look-up operation is not differentiable with respect to the sampling pattern, complicating auto-differentiation routines for backpropagation (stochastic gradient descent) for sampling pattern optimization. This paper describes an efficient and accurate approach for computing approximate gradients with respect to the sampling pattern for learning k-space sampling. Various numerical experiments validate the accuracy of the proposed approximation. We also showcase the trajectories optimized for different iterative reconstruction algorithms, including smooth convex regularized reconstruction and compressed sensing-based reconstruction.      
### 6.A unified concurrent-composition method to state/event inference and concealment in discrete-event systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02824.pdf)
>  A unified verification method based on a concurrent-composition structure is proposed to verify state/event-inference-based properties (e.g., strong detectability, diagnosability, and predictability) and state-concealment-based properties (e.g., opacity) of discrete-event systems modeled by labeled finite-state automata. Hence, inference-based properties and concealment-based properties have been unified into one unified mathematical framework.      
### 7.Monetarization of the Feasible Operation Region based on a Cost-Optimal Flexibility Disaggregation  [ :arrow_down: ](https://arxiv.org/pdf/2111.02810.pdf)
>  Hierarchical multi-(voltage-)level grid control strategies are an appropriate design concept for the coordination of future TSO/DSO- and DSO/DSO-interactions. Hierarchical approaches are based on the aggregation of decentralized ancillary service potentials, represented by converter-coupled, communicable active and reactive power flexibility providing units (FPU) (e.g. wind turbines) at vertical system interfaces. The resulting PQ-polygon made available by the DSO for a potential request of ancillary service flexibilities by the TSO is called feasible operation region (FOR). A monetarization of the FOR is necessary for the implementation as operational degree of freedom within higher-level grid control. This paper presents an approach for the monetarization of the FOR in the context of a hierarchical multi-level flexibility market by a cost structure using metadata from population based optimization methods. Multiple FPU flexibility polygons at a single bus are aggregated for a reduction of the search space dimensions. The main contribution of the proposed method is the cost-optimal disaggregation of a flexibility demand to the single FPUs within the aggregated FPU by a mixed integer linear program (MILP). Therefore, a local flexibility market considering bids for the active and reactive power flexibilities by the FPUs stakeholders is assumed. The approach is applied within a case-study of the CigrÃ© medium voltage system.      
### 8.A Two-Stage Stochastic Programming Model for Blood Supply Chain Management, Considering Facility Disruption and Service Level  [ :arrow_down: ](https://arxiv.org/pdf/2111.02808.pdf)
>  In this paper, a blood supply chain network, where the occurrence of disruption might interrupt the flow of Red Blood Cells, is dealt with. In principle, the probability of disruption is not the only property confiding the network, but unprecedented fluctuations in supplies and demands also contribute to the network shortages and outdated blood units. Although the consideration of parameter uncertainties is of paramount importance in the real-world circumstances for a decision-maker, she or he would be willing to monitor the network in a properly broader perspective. Therefore, one of the eminent key performance indicators known as service level turned our attention. To tackle uncertainties in the mentioned network - comprising of the four conventional levels containing donors, blood collection facilities, blood banks, and hospitals - we present a two-stage stochastic programming model. Consequently, a toy-example is randomly generated to validate the proposed model. Furthermore, numerical analysis led us to a comprehensive service level analysis. Finally, potential pathways for future research are suggested.      
### 9.A Fiber Measurement System with Approximate Deconvolution Based on the Analysis of Fault Clusters in Linearized Bregman Iterations  [ :arrow_down: ](https://arxiv.org/pdf/2111.02798.pdf)
>  Automatic detection of faults in optical fibers is an active area of research that plays a significant role in the design of reliable and stable optical networks. A fiber measurement system that combines automated data acquisition and processing represents a disruptive impact in the management of optical fiber networks with fast and reliable event detection. It has been shown in the literature that the linearized Bregman iterations (LBI) algorithm and variations can be successfully used for processing and accurately identifying faults in a fiber profile. One of the factors that impact the performance of these algorithms is the degradation of spatial resolution, which is mainly caused by the appearance of fault clusters due to a reduced number of iterations. In this paper, a method is proposed based on an approximate deconvolution approach for increasing the spatial resolution, possible after a thorough analysis of fault clusters that appear in the algorithm's output. The effect of such approximate deconvolution is shown to extend beyond the improvement of spatial resolution, allowing for better performances to be reached at shorter processing times. An efficient hardware architecture that implements the approximate deconvolution, compatible with the hardware structure recently presented for the LBI algorithm, is also proposed and discussed.      
### 10.Radio Sensing with Large Intelligent Surface for 6G  [ :arrow_down: ](https://arxiv.org/pdf/2111.02783.pdf)
>  This paper leverages the potential of Large Intelligent Surface (LIS) for radio sensing in 6G wireless networks. Major research has been undergone about its communication capabilities but it can be exploited as a formidable tool for radio sensing. By taking advantage of arbitrary communication signals occurring in the scenario, we apply a Matched Filtering (MF) processing to the output signal from the LIS to obtain a radio map that describes the physical presence of passive devices (scatterers, humans) which act as virtual sources due to the communication signal reflections. We then assess the usage of machine learning (k-means clustering), image processing and computer vision (template matching and component labeling) to extract meaningful information from these radio maps. As an exemplary use case, we evaluate this method for both active and passive user detection in an indoor setting. The results show that the presented method has high application potential as we are able to detect around 98% of humans passively and 100% active users by just using communication signals of commodity devices even in quite unfavorable Signal-to-Noise Ratio (SNR) conditions.      
### 11.The role of MRI physics in brain segmentation CNNs: achieving acquisition invariance and instructive uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2111.02771.pdf)
>  Being able to adequately process and combine data arising from different sites is crucial in neuroimaging, but is difficult, owing to site, sequence and acquisition-parameter dependent biases. It is important therefore to design algorithms that are not only robust to images of differing contrasts, but also be able to generalise well to unseen ones, with a quantifiable measure of uncertainty. In this paper we demonstrate the efficacy of a physics-informed, uncertainty-aware, segmentation network that employs augmentation-time MR simulations and homogeneous batch feature stratification to achieve acquisition invariance. We show that the proposed approach also accurately extrapolates to out-of-distribution sequence samples, providing well calibrated volumetric bounds on these. We demonstrate a significant improvement in terms of coefficients of variation, backed by uncertainty based volumetric validation.      
### 12.Towards dynamic multi-modal phenotyping using chest radiographs and physiological data  [ :arrow_down: ](https://arxiv.org/pdf/2111.02710.pdf)
>  The healthcare domain is characterized by heterogeneous data modalities, such as imaging and physiological data. In practice, the variety of medical data assists clinicians in decision-making. However, most of the current state-of-the-art deep learning models solely rely upon carefully curated data of a single modality. In this paper, we propose a dynamic training approach to learn modality-specific data representations and to integrate auxiliary features, instead of solely relying on a single modality. Our preliminary experiments results for a patient phenotyping task using physiological data in MIMIC-IV &amp; chest radiographs in the MIMIC- CXR dataset show that our proposed approach achieves the highest area under the receiver operating characteristic curve (AUROC) (0.764 AUROC) compared to the performance of the benchmark method in previous work, which only used physiological data (0.740 AUROC). For a set of five recurring or chronic diseases with periodic acute episodes, including cardiac dysrhythmia, conduction disorders, and congestive heart failure, the AUROC improves from 0.747 to 0.798. This illustrates the benefit of leveraging the chest imaging modality in the phenotyping task and highlights the potential of multi-modal learning in medical applications.      
### 13.Voice Conversion Can Improve ASR in Very Low-Resource Settings  [ :arrow_down: ](https://arxiv.org/pdf/2111.02674.pdf)
>  Voice conversion (VC) has been proposed to improve speech recognition systems in low-resource languages by using it to augment limited training data. But until recently, practical issues such as compute speed have limited the use of VC for this purpose. Moreover, it is still unclear whether a VC model trained on one well-resourced language can be applied to speech from another low-resource language for the purpose of data augmentation. In this work we assess whether a VC system can be used cross-lingually to improve low-resource speech recognition. Concretely, we combine several recent techniques to design and train a practical VC system in English, and then use this system to augment data for training a speech recognition model in several low-resource languages. We find that when using a sensible amount of augmented data, speech recognition performance is improved in all four low-resource languages considered.      
### 14.Physics Assisted Deep Learning for Indoor Imaging using Phaseless Wi-Fi Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2111.02667.pdf)
>  A physics assisted deep learning framework to perform accurate indoor imaging using phaseless Wi-Fi measurements is proposed. It is able to image objects that are large (compared to wavelength) and have high permittivity values, that existing radio frequency (RF) inverse scattering techniques find very challenging, making it suitable for indoor RF imaging. The technique utilizes a Rytov based inverse scattering model with a deep learning framework. The inverse scattering model is based on an extended Rytov approximation (xRA) that pre-reconstructs the RF measurements. Under strong scattering conditions, this pre-reconstruction is related to the actual permittivity profile by a non-linear function, which is learned by a modified U-Net model to obtain the permittivity profile of the object. Thus, our proposed approach not only reconstructs the shape of objects, but also estimates their permittivity values accurately. We demonstrate its imaging performance using simulations as well as experimental results in an actual indoor environment using 2.4 GHz Wi-Fi phaseless measurements. For incident wavelength $\lambda_0$, the proposed framework can reconstruct objects with relative permittivity as high as 77 and electrical size as large as $40 \lambda$, where $\lambda =\lambda_0/\sqrt{77}$. This is in contrast to existing phaseless imaging techniques which cannot reconstruct permittivity values beyond 3 or 4. Thus, our proposed method is the first inverse scattering-based deep learning framework which can image large scatterers with high permittivity and achieve accurate indoor RF imaging using phaseless Wi-Fi measurements.      
### 15.Supporting GNSS Baseband Using Smartphone IMU and Ultra-Tight Integration  [ :arrow_down: ](https://arxiv.org/pdf/2111.02613.pdf)
>  A great surge of the global navigation satellite system (GNSS) development excavates the potential of promoting pomposity in many state-of-art technologies, e.g., autonomous ground vehicles (AGVs). Nevertheless, the GNSS is fragile to the various ground interferences which significantly break down the continuity of the navigation system. Meanwhile, the GNSS-based next-generation navigation devices are being developed to be smaller, more low-cost, and lightweight as forecasted by the commercial market. This work aims to answer the question of whether the smartphone inertial measurement unit (IMU) is sufficient to support the GNSS baseband. Thus, a cascaded ultra-tightly integrated GNSS/inertial navigation system (INS) technique, where the consumer-level smartphone sensors are used, is proposed to improve the baseband performance of GNSS software-defined radios (SDRs). To integrate the GNSS baseband, a Doppler value is predicted based on an integrated extended Kalman filter (EKF) navigator where the pseudo-range-state-based measurements of GNSS and INS are fused, and it is used to assist the numerically controlled oscillator (NCO) algorithms. Then, an ultra-tight integration platform is built with an upgraded GNSS SDR of which baseband processing is integrated with the INS mechanization algorithm. Finally, by comparing with the previous algorithms, both tracking-level and carrier-based positioning performances are assessed in the proposed platform for the smartphone-IMU-aided GNSS baseband via kinematic AGV field tests. The experimental results demonstrate the performance of the tracking ability and the high-precision positioning of the proposed ultra-tight integration algorithms using the smartphone IMU.      
### 16.Meta-learning for RIS-assisted NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02582.pdf)
>  A novel reconfigurable intelligent surfaces (RISs)-based transmission framework is proposed for downlink non-orthogonal multiple access (NOMA) networks. We propose a quality-of-service (QoS)-based clustering scheme to improve the resource efficiency and formulate a sum rate maximization problem by jointly optimizing the phase shift of the RIS and the power allocation at the base station (BS). A model-agnostic meta-learning (MAML)-based learning algorithm is proposed to solve the joint optimization problem with a fast convergence rate and low model complexity. Extensive simulation results demonstrate that the proposed QoS-based NOMA network achieves significantly higher transmission throughput compared to the conventional orthogonal multiple access (OMA) network. It can also be observed that substantial throughput gain can be achieved by integrating RISs in NOMA and OMA networks. Moreover, simulation results of the proposed QoS-based clustering method demonstrate observable throughput gain against the conventional channel condition-based schemes.      
### 17.MAUS: A Dataset for Mental Workload Assessmenton N-back Task Using Wearable Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2111.02561.pdf)
>  This paper describes an open-access database focusing on the study of mental workload (MW) assessment system for wearable devices. A wristband photoplethysmogram (PPG) was provided as a representative of wearable devices. In addition, a clinical device that can record Electrocardiography (ECG) , galvanic skin response (GSR) and, fingertip PPG was included in the database as a reference. The MW was induced by performing the N-back task with 22 subjects. The participants were asked to answer the Pittsburgh Sleep Quality Index (PSQI) questionnaire at the beginning of the experiment and the NASA Task Load Index (NASA-TLX) questionnaire after each N-back task. The result of data analysis show the potential uses of the recorded modalities and the feasibility of the MW elicitation protocol. Finally the MAUS dataset is now available for academic use (The MAUS dataset is available at IEEE Dataport: <a class="link-external link-https" href="https://ieee-dataport.org/open-access/maus-dataset-mental-workload-assessment-n-back-task-using-wearable-sensor" rel="external noopener nofollow">this https URL</a>). Besides, we also presents a reproducible baseline system as a preliminary benchmark (The code of the baseline system on MAUS dataset is available on Github: <a class="link-external link-https" href="https://github.com/rickwu11/MAUS" rel="external noopener nofollow">this https URL</a>\_dataset\_baseline\_system), which testing accuracy are 71.6 %, 66.7 %, and 59.9 % in ECG, fingertip PPG, wristband PPG, respectively.      
### 18.VORTEX: Physics-Driven Data Augmentations for Consistency Training for Robust Accelerated MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2111.02549.pdf)
>  Deep neural networks have enabled improved image quality and fast inference times for various inverse problems, including accelerated magnetic resonance imaging (MRI) reconstruction. However, such models require large amounts of fully-sampled ground truth data, which are difficult to curate and are sensitive to distribution drifts. In this work, we propose applying physics-driven data augmentations for consistency training that leverage our domain knowledge of the forward MRI data acquisition process and MRI physics for improved data efficiency and robustness to clinically-relevant distribution drifts. Our approach, termed VORTEX (1) demonstrates strong improvements over supervised baselines with and without augmentation in robustness to signal-to-noise ratio change and motion corruption in data-limited regimes; (2) considerably outperforms state-of-the-art data augmentation techniques that are purely image-based on both in-distribution and out-of-distribution data; and (3) enables composing heterogeneous image-based and physics-driven augmentations.      
### 19.Resampling and super-resolution of hexagonally sampled images using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02520.pdf)
>  Super-resolution (SR) aims to increase the resolution of imagery. Applications include security, medical imaging, and object recognition. We propose a deep learning-based SR system that takes a hexagonally sampled low-resolution image as an input and generates a rectangularly sampled SR image as an output. For training and testing, we use a realistic observation model that includes optical degradation from diffraction and sensor degradation from detector integration. Our SR approach first uses non-uniform interpolation to partially upsample the observed hexagonal imagery and convert it to a rectangular grid. We then leverage a state-of-the-art convolutional neural network (CNN) architecture designed for SR known as Residual Channel Attention Network (RCAN). In particular, we use RCAN to further upsample and restore the imagery to produce the final SR image estimate. We demonstrate that this system is superior to applying RCAN directly to rectangularly sampled LR imagery with equivalent sample density. The theoretical advantages of hexagonal sampling are well known. However, to the best of our knowledge, the practical benefit of hexagonal sampling in light of modern processing techniques such as RCAN SR is heretofore untested. Our SR system demonstrates a notable advantage of hexagonally sampled imagery when employing a modified RCAN for hexagonal SR.      
### 20.Clustering-based Multicast Scheme for UAV Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02509.pdf)
>  When an unmanned aerial vehicle (UAV) network is utilized as an aerial small base station (BS), like a relay deployed far away from macro BSs, existing multicast methods based on acknowledgement (ACK) feedback and retransmissions may encounter severe delay and signaling overhead due to hostile wireless environments caused by a long-distance propagation and numerous UAVs. In this paper, a novel multicast scheme is designed for UAV networks serving as an aerial small BS, where a UAV experiencing a packet loss will request the packet from other UAVs in the same cluster rather than relying on retransmissions of BSs. The technical details of the introduced multicast scheme are designed with the carrier sense multiple access with collision avoidance (CSMA/CA) protocol for practicability and without loss of generality. Then, the Poisson cluster process is employed to model UAV networks to capture their dynamic network topology, based on which distance distributions are derived using tools of stochastic geometry for analytical tractability. Additionally, critical performance indicators of the designed multicast scheme are analyzed. Through extensive simulation studies, the superiority of the designed multicast scheme is demonstrated and the system design insight related to the proper number of clusters is revealed.      
### 21.Real-Time Simulation of Level 1, Level 2, and Level 3 Electric Vehicle Charging Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02506.pdf)
>  A charging system is required to convert ac electricity from the grid to dc electricity to charge an electric vehicle (EV) battery. According to the Society of Automatic Engineers (SAE) standard, EV chargers can be divided into three levels based on power rating: Level 1, Level 2, and Level 3. This paper investigates the circuit topologies and control principles of EV charging systems at each level. Three high-fidelity testbeds of EV charging systems for a 10 kWh battery are designed and implemented in real-time digital simulator RT-Lab. The testbeds include modeling details such as switching of semiconductors. Twenty-five minutes real-time simulation is conducted for each testbed. Detailed dynamic performance of the circuits and the controls at every stage are presented to demonstrate the charging process. All three level EV charging systems employ high-frequency transformer embedded dual active bridge (DAB) dc/dc converter to regulate battery side dc voltage and current. Hence, average model-based linear system analysis is given to configure the parameters of the phase shift control adopted by the DAB dc/dc converter. In addition, power factor control (PFC) that is employed for Level 1 and Level 2 single-phase ac charging systems, three-phase voltage source converter control that is employed for Level 3 three-phase ac charging systems, are all analyzed. The three testbeds, with their detailed circuit parameters and control parameters presented, can be used as reference testbeds for EV grid integration research.      
### 22.Channel modeling for in-body optical wireless communications  [ :arrow_down: ](https://arxiv.org/pdf/2111.02495.pdf)
>  Next generation in-to-out-of body biomedical applications have adopted optical wireless communications (OWCs). However, by delving into the published literature, a gap is recognised in modeling the in-to-out-of channel, since most published contributions neglect the particularities of different type of tissues. Towards this direction, in this paper we present a novel pathloss and scattering models for in-to-out-of OWC links. Specifically, we derive extract analytical expressions that accurately describe the absorption of the five main tissues' constituents, namely fat, water, melanin, oxygenated and de-oxygenated blood. Moreover, we formulate a model for the calculation of the absorption coefficient of any generic biological tissue. Next, by incorporating the impact of scattering in the aforementioned model we formulate the complete pathloss model. The developed theoretical framework is verified by means of comparisons between the estimated pathloss and experimental measurements from independent research works. Finally, we illustrate the accuracy of the theoretical framework in estimating the optical properties of any generic tissue based on its constitution. The extracted channel model is capable of boosting the design of optimized communication protocols for a plethora of biomedical applications.      
### 23.Roadmap on Signal Processing for Next Generation Measurement Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02493.pdf)
>  Signal processing is a fundamental component of almost any sensor-enabled system, with a wide range of applications across different scientific disciplines. Time series data, images, and video sequences comprise representative forms of signals that can be enhanced and analysed for information extraction and quantification. The recent advances in artificial intelligence and machine learning are shifting the research attention towards intelligent, data-driven, signal processing. This roadmap presents a critical overview of the state-of-the-art methods and applications aiming to highlight future challenges and research opportunities towards next generation measurement systems. It covers a broad spectrum of topics ranging from basic to industrial research, organized in concise thematic sections that reflect the trends and the impacts of current and future developments per research field. Furthermore, it offers guidance to researchers and funding agencies in identifying new prospects.      
### 24.Automatic ultrasound vessel segmentation with deep spatiotemporal context learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02461.pdf)
>  Accurate, real-time segmentation of vessel structures in ultrasound image sequences can aid in the measurement of lumen diameters and assessment of vascular diseases. This, however, remains a challenging task, particularly for extremely small vessels that are difficult to visualize. We propose to leverage the rich spatiotemporal context available in ultrasound to improve segmentation of small-scale lower-extremity arterial vasculature. We describe efficient deep learning methods that incorporate temporal, spatial, and feature-aware contextual embeddings at multiple resolution scales while jointly utilizing information from B-mode and Color Doppler signals. Evaluating on femoral and tibial artery scans performed on healthy subjects by an expert ultrasonographer, and comparing to consensus expert ground-truth annotations of inner lumen boundaries, we demonstrate real-time segmentation using the context-aware models and show that they significantly outperform comparable baseline approaches.      
### 25.Smart sensors network for accurate indirect heat accounting in apartment buildings  [ :arrow_down: ](https://arxiv.org/pdf/2111.02459.pdf)
>  A new method for accurate indirect heat accounting in apartment buildings has been recently developed by the Centre Suisse d'Electronique et de Microtechnique (CSEM). It is based on a data driven approach aimed to the smart networking of any type of indirect heat allocation devices, which can provide, for each heat delivery point of an apartment building, measurements or estimations of the temperature difference between the heat transfer fluid and the indoor environment. The analysis of the data gathered from the devices installed on the heating bodies, together with the measurements of the overall building heat consumption provided by direct heat metering, allows the evaluation of the characteristic thermal model parameters of heating bodies at actual installation and working conditions. Thus overcoming the negative impact on accuracy of conventional indirect heat accounting due to off-design operation, in which these measurement systems normally operate. The method has been tested on conventional heat cost allocators (HCA), and on innovative smart radiator thermostatic valves developed by CSEM. The evaluations were carried out at the centralized heating system mock-up of the Istituto Nazionale di Ricerca Metrologica (INRIM), and also in a real building in Neuchatel, Switzerland. The method has proven to be an effective tool to improve the accuracy of indirect heat metering systems; compared to conventional HCA systems, the error on the individual heating bill is reduced by 20% to 50%.      
### 26.Breast Cancer Classification Using: Pixel Interpolation  [ :arrow_down: ](https://arxiv.org/pdf/2111.02409.pdf)
>  Image Processing represents the backbone research area within engineering and computer science specialization. It is promptly growing technologies today, and its applications founded in various aspects of biomedical fields especially in cancer disease. Breast cancer is considered the fatal one of all cancer types according to recent statistics all over the world. It is the most commonly cancer in women and the second reason of cancer death between females. About 23% of the total cancer cases in both developing and developed countries. In this work, an interpolation process was used to classify the breast cancer into main types, benign and malignant. This scheme dependent on the morphologic spectrum of mammographic masses. Malignant tumors had irregular shape percent higher than the benign tumors. By this way the boundary of the tumor will be interpolated by additional pixels to make the boundary smoothen as possible, these needed pixels is proportional with irregularity shape of the tumor, so that the increasing in interpolated pixels meaning the tumor goes toward the malignant case. The proposed system is implemented using MATLAB programming and tested over several images taken from the Mammogram Image Analysis Society (MIAS) image database. The MIAS offers a regular classification for mammographic studies. The system works faster so that any radiologist can take a clear decision about the appearance of calcifications by visual inspection.      
### 27.Partial supervision for the FeTA challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2111.02408.pdf)
>  This paper describes our method for our participation in the FeTA challenge2021 (team name: TRABIT). The performance of convolutional neural networks for medical image segmentation is thought to correlate positively with the number of training data. The FeTA challenge does not restrict participants to using only the provided training data but also allows for using other publicly available sources. Yet, open access fetal brain data remains limited. An advantageous strategy could thus be to expand the training data to cover broader perinatal brain imaging sources. Perinatal brain MRIs, other than the FeTA challenge data, that are currently publicly available, span normal and pathological fetal atlases as well as neonatal scans. However, perinatal brain MRIs segmented in different datasets typically come with different annotation protocols. This makes it challenging to combine those datasets to train a deep neural network. We recently proposed a family of loss functions, the label-set loss functions, for partially supervised learning. Label-set loss functions allow to train deep neural networks with partially segmented images, i.e. segmentations in which some classes may be grouped into super-classes. We propose to use label-set loss functions to improve the segmentation performance of a state-of-the-art deep learning pipeline for multi-class fetal brain segmentation by merging several publicly available datasets. To promote generalisability, our approach does not introduce any additional hyper-parameters tuning.      
### 28.WORD: Revisiting Organs Segmentation in the Whole Abdominal Region  [ :arrow_down: ](https://arxiv.org/pdf/2111.02403.pdf)
>  Whole abdominal organs segmentation plays an important role in abdomen lesion diagnosis, radiotherapy planning, and follow-up. However, delineating all abdominal organs by oncologists manually is time-consuming and very expensive. Recently, deep learning-based medical image segmentation has shown the potential to reduce manual delineation efforts, but it still requires a large-scale fine annotated dataset for training. Although many efforts in this task, there are still few large image datasets covering the whole abdomen region with accurate and detailed annotations for the whole abdominal organ segmentation. In this work, we establish a large-scale \textit{W}hole abdominal \textit{OR}gans \textit{D}ataset (\textit{WORD}) for algorithms research and clinical applications development. This dataset contains 150 abdominal CT volumes (30495 slices) and each volume has 16 organs with fine pixel-level annotations and scribble-based sparse annotation, which may be the largest dataset with whole abdominal organs annotation. Several state-of-the-art segmentation methods are evaluated on this dataset. And, we also invited clinical oncologists to revise the model predictions to measure the gap between the deep learning method and real oncologists. We further introduce and evaluate a new scribble-based weakly supervised segmentation on this dataset. The work provided a new benchmark for the abdominal multi-organ segmentation task and these experiments can serve as the baseline for future research and clinical application development. The codebase and dataset will be released at: <a class="link-external link-https" href="https://github.com/HiLab-git/WORD" rel="external noopener nofollow">this https URL</a>      
### 29.Skin Cancer Classification using Inception Network and Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02402.pdf)
>  Medical data classification is typically a challenging task due to imbalance between classes. In this paper, we propose an approach to classify dermatoscopic images from HAM10000 (Human Against Machine with 10000 training images) dataset, consisting of seven imbalanced types of skin lesions, with good precision and low resources requirements. Classification is done by using a pretrained convolutional neural network. We evaluate the accuracy and performance of the proposal and illustrate possible extensions.      
### 30.Polarization-Based Reconfigurable Tags for Robust Ambient Backscatter Communications  [ :arrow_down: ](https://arxiv.org/pdf/2111.02401.pdf)
>  Ambient backscatter communication is an emerging and promising low-energy technology for the Internet of Things. In such a system, a tag sends a binary message to a reader by backscattering a radio frequency signal generated by an ambient source. The tag can operate without battery and without generating additional radio waves. However, the tag-to-reader link suffers from the source-to-reader interference. In this paper, we propose a polarization-based reconfigurable antenna in order to improve the robustness of the tag-to-reader link against the source-to-reader direct interference. More precisely, we compare different types of tags' antennas, different tags' encoding schemes, and different detectors at the reader. By using analysis, numerical simulations, and experiments, we show that a polarization-based reconfigurable tag with four polarization directions significantly outperforms a non-reconfigurable tag, and provides almost the same performance as an ideal reconfigurable tag with a large number of reconfigurable polarization patterns.      
### 31.Transparency of Deep Neural Networks for Medical Image Analysis: A Review of Interpretability Methods  [ :arrow_down: ](https://arxiv.org/pdf/2111.02398.pdf)
>  Artificial Intelligence has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. In order to conform to the principles of trustworthy AI, it is essential that the AI system be transparent, robust, fair and ensure accountability. Current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision making process. Therefore, there is a need to ensure interpretability of deep neural networks before they can be incorporated in the routine clinical workflow. In this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. Furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. Finally we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis.      
### 32.Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.03062.pdf)
>  Dexterous manipulation of arbitrary objects, a fundamental daily task for humans, has been a grand challenge for autonomous robotic systems. Although data-driven approaches using reinforcement learning can develop specialist policies that discover behaviors to control a single object, they often exhibit poor generalization to unseen ones. In this work, we show that policies learned by existing reinforcement learning algorithms can in fact be generalist when combined with multi-task learning and a well-chosen object representation. We show that a single generalist policy can perform in-hand manipulation of over 100 geometrically-diverse real-world objects and generalize to new objects with unseen shape or size. Interestingly, we find that multi-task learning with object point cloud representations not only generalizes better but even outperforms the single-object specialist policies on both training as well as held-out test objects. Video results at <a class="link-external link-https" href="https://huangwl18.github.io/geometry-dex" rel="external noopener nofollow">this https URL</a>      
### 33.MT3: Multi-Task Multitrack Music Transcription  [ :arrow_down: ](https://arxiv.org/pdf/2111.03017.pdf)
>  Automatic Music Transcription (AMT), inferring musical notes from raw audio, is a challenging task at the core of music understanding. Unlike Automatic Speech Recognition (ASR), which typically focuses on the words of a single speaker, AMT often requires transcribing multiple instruments simultaneously, all while preserving fine-scale pitch and timing information. Further, many AMT datasets are "low-resource", as even expert musicians find music transcription difficult and time-consuming. Thus, prior work has focused on task-specific architectures, tailored to the individual instruments of each task. In this work, motivated by the promising results of sequence-to-sequence transfer learning for low-resource Natural Language Processing (NLP), we demonstrate that a general-purpose Transformer model can perform multi-task AMT, jointly transcribing arbitrary combinations of musical instruments across several transcription datasets. We show this unified training framework achieves high-quality transcription results across a range of datasets, dramatically improving performance for low-resource instruments (such as guitar), while preserving strong performance for abundant instruments (such as piano). Finally, by expanding the scope of AMT, we expose the need for more consistent evaluation metrics and better dataset alignment, and provide a strong baseline for this new direction of multi-task AMT.      
### 34.Computation of Input Disturbance Sets for Constrained Output Reachability  [ :arrow_down: ](https://arxiv.org/pdf/2111.03009.pdf)
>  Linear models with additive unknown-but-bounded input disturbances are extensively used to model uncertainty in robust control systems design. Typically, the disturbance set is either assumed to be known a priori or estimated from data through set-membership identification. However, the problem of computing a suitable input disturbance set in case the set of possible output values is assigned a priori has received relatively little attention. This problem arises in many contexts, such as in supervisory control, actuator design, decentralized control, and others. In this paper, we propose a method to compute input disturbance sets (and the corresponding set of states) such that the resulting set of outputs matches as closely as possible a given set of outputs, while additionally satisfying strict (inner or outer) inclusion constraints. We formulate the problem as an optimization problem by relying on the concept of robust invariance. The effectiveness of the approach is demonstrated in numerical examples that illustrate how to solve safe reference set and input-constraint set computation problems.      
### 35.A Quantization QoE Evaluation Approach in6DoF Point Cloud Video Streaming  [ :arrow_down: ](https://arxiv.org/pdf/2111.02985.pdf)
>  Point cloud video has been widely used by augmented reality (AR) and virtual reality (VR) applications as it allows users to have an immersive experience of six degrees of freedom (6DoFs). Yet there is still a lack of research on quality of experience (QoE) model of point cloud video streaming, which cannot provide optimization metric for streaming systems. Besides, position and color information contained in each pixel of point cloud video, and viewport distance effect caused by 6DoFs viewing procedure make the traditional objective quality evaluation metric cannot be directly used in point cloud video streaming system. In this paper we first analyze the subjective and objective factors related to QoE model. Then an experimental system to simulate point cloud video streaming is setup and detailed subjective quality evaluation experiments are carried out. Based on collected mean opinion score (MOS) data, we propose a QoE model for point cloud video streaming. We also verify the model by actual subjective scoring, and the results show that the proposed QoE model can accurately reflect users' visual perception. We also make the experimental database public to promote the QoE research of point cloud video streaming.      
### 36.OpenFWI: Benchmark Seismic Datasets for Machine Learning-Based Full Waveform Inversion  [ :arrow_down: ](https://arxiv.org/pdf/2111.02926.pdf)
>  We present OpenFWI, a collection of large-scale open-source benchmark datasets for seismic full waveform inversion (FWI). OpenFWI is the first-of-its-kind in the geoscience and machine learning community to facilitate diversified, rigorous, and reproducible research on machine learning-based FWI. OpenFWI includes datasets of multiple scales, encompasses diverse domains, and covers various levels of model complexity. Along with the dataset, we also perform an empirical study on each dataset with a fully-convolutional deep learning model. OpenFWI has been meticulously maintained and will be regularly updated with new data and experimental results. We appreciate the inputs from the community to help us further improve OpenFWI. At the current version, we publish seven datasets in OpenFWI, of which one is specified for 3D FWI and the rest are for 2D scenarios. All datasets and related information can be accessed through our website at <a class="link-external link-https" href="https://openfwi.github.io/" rel="external noopener nofollow">this https URL</a>.      
### 37.Map-Assisted Power Allocation and Constellation Design for mmWave WDM with OAM in Short-Range LOS Environment  [ :arrow_down: ](https://arxiv.org/pdf/2111.02921.pdf)
>  Consider a system that integrates positioning and single-user millimeter wave (mmWave) communication, where the communication part adopts wavelength division multiplexing (WDM) and orbital angular momentum (OAM). This paper addresses the power allocation and high dimensional constellation design in short-range line-of-sight (LOS) environment, where the communication links are relatively stable. We propose a map-assisted method to replace online estimation, feedback and computation with the look-up table searching. We explore the possibility of using a few patterns in the maps, and investigate the performance loss of using the optimal solution of one position for other positions. For power allocation, we first characterize the performance loss outside the OAM beam regions, where we only use plane waves, and figure out that the loss is always small. However, in OAM beam regions, the performance loss has similar characteristics only at some specific positions. Combining with numerical results, we illustrate that a few patterns can be adopted for all receiver locations in the map. We also investigate the high dimensional constellation design and prove that the positions where the channel matrices are sufficiently close to be proportional can employ a fixed constellation. Then, we figure out that the constellation design for all receiver locations can be represented by a few constellation sets.      
### 38.Stochasticity Invariance Control in Pr$_{1-x}$Ca$_x$MnO$_3$ RRAM to enable Large-Scale Stochastic Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02885.pdf)
>  Emerging non-volatile memories have been proposed for a wide range of applications from easing the von-Neumann bottleneck to neuromorphic applications. Specifically, scalable RRAMs based on Pr$_{1-x}$Ca$_x$MnO$_3$ (PCMO) exhibit analog switching have been demonstrated as an integrating neuron, an analog synapse, and a voltage-controlled oscillator. More recently, the inherent stochasticity of memristors has been proposed for efficient hardware implementations of Boltzmann Machines. However, as the problem size scales, the number of neurons increase and controlling the stochastic distribution tightly over many iterations is necessary. This requires parametric control over stochasticity. Here, we characterize the stochastic Set in PCMO RRAMs. We identify that the Set time distribution depends on the internal state of the device (i.e., resistance) in addition to external input (i.e., voltage pulse). This requires the confluence of contradictory properties like stochastic switching as well as deterministic state control in the same device. Unlike, "stochastic-everywhere" filamentary memristors, in PCMO RRAMs, we leverage the (i) stochastic Set in negative polarity and (ii) deterministic analog Reset in positive polarity to demonstrate 100x reduced Set time distribution drift. The impact on Boltzmann Machines' performance is analyzed and as opposed to the "fixed external input stochasticity", the "state-monitored stochasticity" can solve problems 20x larger in size. State monitoring also tunes out the device-to-device variability effect on distributions providing 10x better performance. In addition to the physical insights, this study establishes the use of experimental stochasticity in PCMO RRAMs in stochastic recurrent neural networks reliably over many iterations.      
### 39.WaveFake: A Data Set to Facilitate Audio Deepfake Detection  [ :arrow_down: ](https://arxiv.org/pdf/2111.02813.pdf)
>  Deep generative modeling has the potential to cause significant harm to society. Recognizing this threat, a magnitude of research into detecting so-called "Deepfakes" has emerged. This research most often focuses on the image domain, while studies exploring generated audio signals have, so-far, been neglected. In this paper we make three key contributions to narrow this gap. First, we provide researchers with an introduction to common signal processing techniques used for analyzing audio signals. Second, we present a novel data set, for which we collected nine sample sets from five different network architectures, spanning two languages. Finally, we supply practitioners with two baseline models, adopted from the signal processing community, to facilitate further research in this area.      
### 40.A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2111.02735.pdf)
>  Self-supervised speech representations such as wav2vec 2.0 and HuBERT are making revolutionary progress in Automatic Speech Recognition (ASR). However, self-supervised models have not been totally proved to produce better performance on tasks other than ASR. In this work, we explore partial fine-tuning and entire fine-tuning on wav2vec 2.0 and HuBERT pre-trained models for three non-ASR speech tasks : Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding. We also compare pre-trained models with/without ASR fine-tuning. With simple down-stream frameworks, the best scores reach 79.58% weighted accuracy for Speech Emotion Recognition on IEMOCAP, 2.36% equal error rate for Speaker Verification on VoxCeleb1, 87.51% accuracy for Intent Classification and 75.32% F1 for Slot Filling on SLURP, thus setting a new state-of-the-art for these three benchmarks, proving that fine-tuned wav2vec 2.0 and HuBERT models can better learn prosodic, voice-print and semantic representations.      
### 41.A semi-automatic ultrasound image analysis system for the grading diagnosis of COVID-19 pneumonia  [ :arrow_down: ](https://arxiv.org/pdf/2111.02676.pdf)
>  This paper proposes a semi-automatic system based on quantitative characterization of the specific image patterns in lung ultrasound (LUS) images, in order to assess the lung conditions of patients with COVID-19 pneumonia, as well as to differentiate between the severe / and no-severe cases. Specifically, four parameters are extracted from each LUS image, namely the thickness (TPL) and roughness (RPL) of the pleural line, and the accumulated with (AWBL) and acoustic coefficient (ACBL) of B lines. 27 patients are enrolled in this study, which are grouped into 13 moderate patients, 7 severe patients and 7 critical patients. Furthermore, the severe and critical patients are regarded as the severe cases, and the moderate patients are regarded as the non-severe cases. Biomarkers among different groups are compared. Each single biomarker and a classifier with all the biomarkers as input are utilized for the binary diagnosis of severe case and non-severe case, respectively. The classifier achieves the best classification performance among all the compared methods (area under the receiver operating characteristics curve = 0.93, sensitivity = 0.93, specificity = 0.85). The proposed image analysis system could be potentially applied to the grading and prognosis evaluation of patients with COVID-19 pneumonia.      
### 42.Recurrent Neural Network Training with Convex Loss and Regularization Functions by Extended Kalman Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2111.02673.pdf)
>  We investigate the use of extended Kalman filtering to train recurrent neural networks for data-driven nonlinear, possibly adaptive, model-based control design. We show that the approach can be applied to rather arbitrary convex loss functions and regularization terms on the network parameters. We show that the learning method outperforms stochastic gradient descent in a nonlinear system identification benchmark and in training a linear system with binary outputs. We also explore the use of the algorithm in data-driven nonlinear model predictive control and its relation with disturbance models for offset-free tracking.      
### 43.Speech recognition for air traffic control via feature learning and end-to-end training  [ :arrow_down: ](https://arxiv.org/pdf/2111.02654.pdf)
>  In this work, we propose a new automatic speech recognition (ASR) system based on feature learning and an end-to-end training procedure for air traffic control (ATC) systems. The proposed model integrates the feature learning block, recurrent neural network (RNN), and connectionist temporal classification loss to build an end-to-end ASR model. Facing the complex environments of ATC speech, instead of the handcrafted features, a learning block is designed to extract informative features from raw waveforms for acoustic modeling. Both the SincNet and 1D convolution blocks are applied to process the raw waveforms, whose outputs are concatenated to the RNN layers for the temporal modeling. Thanks to the ability to learn representations from raw waveforms, the proposed model can be optimized in a complete end-to-end manner, i.e., from waveform to text. Finally, the multilingual issue in the ATC domain is also considered to achieve the ASR task by constructing a combined vocabulary of Chinese characters and English letters. The proposed approach is validated on a multilingual real-world corpus (ATCSpeech), and the experimental results demonstrate that the proposed approach outperforms other baselines, achieving a 6.9\% character error rate.      
### 44.Temporal Fusion Based Mutli-scale Semantic Segmentation for Detecting Concealed Baggage Threats  [ :arrow_down: ](https://arxiv.org/pdf/2111.02651.pdf)
>  Detection of illegal and threatening items in baggage is one of the utmost security concern nowadays. Even for experienced security personnel, manual detection is a time-consuming and stressful task. Many academics have created automated frameworks for detecting suspicious and contraband data from X-ray scans of luggage. However, to our knowledge, no framework exists that utilizes temporal baggage X-ray imagery to effectively screen highly concealed and occluded objects which are barely visible even to the naked eye. To address this, we present a novel temporal fusion driven multi-scale residual fashioned encoder-decoder that takes series of consecutive scans as input and fuses them to generate distinct feature representations of the suspicious and non-suspicious baggage content, leading towards a more accurate extraction of the contraband data. The proposed methodology has been thoroughly tested using the publicly accessible GDXray dataset, which is the only dataset containing temporally linked grayscale X-ray scans showcasing extremely concealed contraband data. The proposed framework outperforms its competitors on the GDXray dataset on various metrics.      
### 45.Global Controllability for General Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02645.pdf)
>  This note studies the global controllability of a general nonlinear system by extending it to affine one. The state space of the obtained affine system admits a nature foliation, each leaf of which is diffeomorphic to the state space of the original system. Through this foliation, the global controllability of these two kinds of systems are closely related and we prove that they are indeed equivalent. The result is then extended to the case with bounded inputs to make it practically more useful. To demonstrate the power of our approach, several examples are presented.      
### 46.A Concentration Bound for LSPE($Î»$)  [ :arrow_down: ](https://arxiv.org/pdf/2111.02644.pdf)
>  The popular LSPE($\lambda$) algorithm for policy evaluation is revisited to derive a concentration bound that gives high probability performance guarantees from some time on.      
### 47.The Age of Information of Short-Packet Communications: Joint or Distributed Encoding?  [ :arrow_down: ](https://arxiv.org/pdf/2111.02638.pdf)
>  In this paper, we analyze the impact of different encoding schemes on the age of information (AoI) performance in a point-to-point system, where a source generates packets based on the status updates collected from multiple sensors and transmits the packets to a destination. In this system, we consider two encoding schemes, namely, the joint encoding scheme and the distributed encoding scheme. In the joint encoding scheme, the status updates from all the sensors are jointly encoded into a packet for transmission. In the distributed encoding scheme, the status update from each sensor is encoded individually and the sensors' packets are transmitted following the round robin policy. To ensure the freshness of packets, the zero-wait policy is adopted in both schemes, where a new packet is immediately generated once the source finishes the transmission of the current packet. We derive closed-form expressions for the average AoI achieved by these two encoding schemes and compare their performances. Simulation results show that the distributed encoding scheme is more appropriate for systems with a relatively large number of sensors, compared with the joint encoding scheme.      
### 48.Energy-Efficient Online Data Sensing and Processing in Wireless Powered Edge Computing Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02593.pdf)
>  This paper focuses on developing energy-efficient online data processing strategy of wireless powered MEC systems under stochastic fading channels. In particular, we consider a hybrid access point (HAP) transmitting RF energy to and processing the sensing data offloaded from multiple WDs. Under an average power constraint of the HAP, we aim to maximize the long-term average data sensing rate of the WDs while maintaining task data queue stability. We formulate the problem as a multi-stage stochastic optimization to control the energy transfer and task data processing in sequential time slots. Without the knowledge of future channel fading, it is very challenging to determine the sequential control actions that are tightly coupled by the battery and data buffer dynamics. To solve the problem, we propose an online algorithm named LEESE that applies the perturbed Lyapunov optimization technique to decompose the multi-stage stochastic problem into per-slot deterministic optimization problems. We show that each per-slot problem can be equivalently transformed into a convex optimization problem. To facilitate online implementation in large-scale MEC systems, instead of solving the per-slot problem with off-the-shelf convex algorithms, we propose a block coordinate descent (BCD)-based method that produces close-to-optimal solution in less than 0.04\% of the computation delay. Simulation results demonstrate that the proposed LEESE algorithm can provide 21.9\% higher data sensing rate than the representative benchmark methods considered, while incurring sub-millisecond computation delay suitable for real-time control under fading channel.      
### 49.Building Damage Mapping with Self-PositiveUnlabeled Learning  [ :arrow_down: ](https://arxiv.org/pdf/2111.02586.pdf)
>  Humanitarian organizations must have fast and reliable data to respond to disasters. Deep learning approaches are difficult to implement in real-world disasters because it might be challenging to collect ground truth data of the damage situation (training data) soon after the event. The implementation of recent self-paced positive-unlabeled learning (PU) is demonstrated in this work by successfully applying to building damage assessment with very limited labeled data and a large amount of unlabeled data. Self-PU learning is compared with the supervised baselines and traditional PU learning using different datasets collected from the 2011 Tohoku earthquake, the 2018 Palu tsunami, and the 2018 Hurricane Michael. By utilizing only a portion of labeled damaged samples, we show how models trained with self-PU techniques may achieve comparable performance as supervised learning.      
### 50.InQSS: a speech intelligibility assessment model using a multi-task learning network  [ :arrow_down: ](https://arxiv.org/pdf/2111.02585.pdf)
>  Speech intelligibility assessment models are essential tools for researchers to evaluate and improve speech processing models. In this study, we propose InQSS, a speech intelligibility assessment model that uses both spectrogram and scattering coefficients as input features. In addition, InQSS uses a multi-task learning network in which quality scores can guide the training of the speech intelligibility assessment. The resulting model can predict not only the intelligibility scores but also the quality scores of a speech. The experimental results confirm that the scattering coefficients and quality scores are informative for intelligibility. Moreover, we released TMHINT-QI, which is a Chinese speech dataset that records the quality and intelligibility scores of clean, noisy, and enhanced speech.      
### 51.Real-time Wireless Transmitter Authorization: Adapting to Dynamic Authorized Sets with Information Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2111.02584.pdf)
>  As the Internet of Things (IoT) continues to grow, ensuring the security of systems that rely on wireless IoT devices has become critically important. Deep learning-based passive physical layer transmitter authorization systems have been introduced recently for this purpose, as they accommodate the limited computational and power budget of such devices. These systems have been shown to offer excellent outlier detection accuracies when trained and tested on a fixed authorized transmitter set. However in a real-life deployment, a need may arise for transmitters to be added and removed as the authorized set of transmitters changes. In such cases, the system could experience long down-times, as retraining the underlying deep learning model is often a time-consuming process. In this paper, we draw inspiration from information retrieval to address this problem: by utilizing feature vectors as RF fingerprints, we first demonstrate that training could be simplified to indexing those feature vectors into a database using locality sensitive hashing (LSH). Then we show that approximate nearest neighbor search could be performed on the database to perform transmitter authorization that matches the accuracy of deep learning models, while allowing for more than 100x faster retraining. Furthermore, dimensionality reduction techniques are used on the feature vectors to show that the authorization latency of our technique could be reduced to approach that of traditional deep learning-based systems.      
### 52.Optimal Discrete Constellation Inputs for Aggregated LiFi-WiFi Networks  [ :arrow_down: ](https://arxiv.org/pdf/2111.02581.pdf)
>  In this paper, we investigate the performance of a practical aggregated LiFi-WiFi system with the discrete constellation inputs from a practical view. We derive the achievable rate expressions of the aggregated LiFi-WiFi system for the first time. Then, we study the rate maximization problem via optimizing the constellation distribution and power allocation jointly. Specifically, a multilevel mercy-filling power allocation scheme is proposed by exploiting the relationship between the mutual information and minimum mean-squared error (MMSE) of discrete inputs. Meanwhile, an inexact gradient descent method is proposed for obtaining the optimal probability distributions. To strike a balance between the computational complexity and the transmission performance, we further develop a framework that maximizes the lower bound of the achievable rate where the optimal power allocation can be obtained in closed forms and the constellation distributions problem can be solved efficiently by Frank-Wolfe method. Extensive numerical results show that the optimized strategies are able to provide significant gains over the state-of-the-art schemes in terms of the achievable rate.      
### 53.Performance Analysis under IRS-User Association for Distributed IRSs Assisted MISO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2111.02531.pdf)
>  Distributed intelligent reflecting surfaces (IRSs) deployed in multi-user wireless communication systems promise improved system performance. However, the signal-to-interference-plus-noise ratio (SINR) analysis and IRSs optimization in such a system become challenging, due to the large number of involved parameters. The system optimization can be simplified if users are associated with IRSs, which in turn focus on serving the associated users. We provide a practical theoretical framework for the average SINR analysis of a distributed IRSs-assisted multi-user MISO system, where IRSs are optimized to serve their associated users. In particular, we derive the average SINR expression under maximum ratio transmission (MRT) precoding at the BS and optimized reflect beamforming configurations at the IRSs. A successive refinement (SR) method is then outlined to optimize the IRS-user association parameters for the formulated max-min SINR problem which motivates user-fairness. Simulations validate the average SINR analysis while confirming the superiority of a distributed IRSs system over a centralized IRS system as well as the gains with optimized IRS-user association as compared to random association.      
### 54.Energy Efficiency of Uplink Cell-Free Massive MIMO With Transmit Power Control in Measured Propagation Channel  [ :arrow_down: ](https://arxiv.org/pdf/2111.02514.pdf)
>  Cell-free massive MIMO (CF-mMIMO) provides wireless connectivity for a large number of user equipments (UEs) using access points (APs) distributed across a wide area with high spectral efficiency (SE). The energy efficiency (EE) of the uplink is determined by (i) the transmit power control (TPC) algorithms, (ii) the numbers, configurations, and locations of the APs and the UEs, and (iii) the propagation channels between the APs and the UEs. This paper investigates all three aspects, based on extensive (~30,000 possible AP locations and 128 possible UE locations) channel measurement data at 3.5 GHz. We compare three different TPC algorithms, namely maximization of transmit power (max-power), maximization of minimum SE (max-min SE), and maximization of minimum EE (max-min EE) while guaranteeing a target SE. We also compare various antenna arrangements including fully-distributed and semi-distributed systems, where APs can be located on a regular grid or randomly, and the UEs can be placed in clusters or far apart. Overall, we show that the max-min EE TPC is highly effective in improving the uplink EE, especially when no UE within a set of served UEs is in a bad channel condition and when the BS antennas are fully-distributed.      
### 55.Deep AUC Maximization for Medical Image Classification: Challenges and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2111.02400.pdf)
>  In this extended abstract, we will present and discuss opportunities and challenges brought about by a new deep learning method by AUC maximization (aka \underline{\bf D}eep \underline{\bf A}UC \underline{\bf M}aximization or {\bf DAM}) for medical image classification. Since AUC (aka area under ROC curve) is a standard performance measure for medical image classification, hence directly optimizing AUC could achieve a better performance for learning a deep neural network than minimizing a traditional loss function (e.g., cross-entropy loss). Recently, there emerges a trend of using deep AUC maximization for large-scale medical image classification. In this paper, we will discuss these recent results by highlighting (i) the advancements brought by stochastic non-convex optimization algorithms for DAM; (ii) the promising results on various medical image classification problems. Then, we will discuss challenges and opportunities of DAM for medical image classification from three perspectives, feature learning, large-scale optimization, and learning trustworthy AI models.      
### 56.Cluster Synchronization of Coupled Systems with Nonidentical Linear Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/1502.07481.pdf)
>  This paper considers the cluster synchronization problem of generic linear dynamical systems whose system models are distinct in different clusters. These nonidentical linear models render control design and coupling conditions highly correlated if static couplings are used for all individual systems. In this paper, a dynamic coupling structure, which incorporates a global weighting factor and a vanishing auxiliary control variable, is proposed for each agent and is shown to be a feasible solution. Lower bounds on the global and local weighting factors are derived under the condition that every interaction subgraph associated with each cluster admits a directed spanning tree. The spanning tree requirement is further shown to be a necessary condition when the clusters connect acyclically with each other. Simulations for two applications, cluster heading alignment of nonidentical ships and cluster phase synchronization of nonidentical harmonic oscillators, illustrate essential parts of the derived theoretical results.      
