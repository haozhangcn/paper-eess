# ArXiv eess --Mon, 9 Aug 2021
### 1.A Model-Agnostic Method for PMU Data Recovery Using Optimal Singular Value Thresholding  [ :arrow_down: ](https://arxiv.org/pdf/2108.03220.pdf)
>  This paper presents a fast model-agnostic method for recovering noisy Phasor Measurement Unit (PMU) datastreams with missing entries. The measurements are first transformed into a Page matrix, and the original signals are reconstructed using low-rank matrix estimation based on optimal singular value thresholding. Two variations of the recovery algorithm are shown- a) an offline block-processing method for imputing past measurements, and b) an online method for predicting future measurements. Information within a PMU channel (temporal correlation) as well as from different PMUchannels in a network (spatial correlation) are utilized to recover degraded data. The proposed method is fast and needs no explicit knowledge of the underlying system model or measurement noise distribution. The performance of the recovery algorithms is illustrated using simulated measurements from the IEEE 39-bus test system as well as real measurements from an anonymized U.S. electric utility. Extensive numeric tests show that the original signals can be accurately recovered in the presence of additive noise, consecutive data drop as well as simultaneous data erasure across multiple PMU channels.      
### 2.A Generalized Space-Frequency Index Modulation Scheme for Downlink MIMO Transmissions with Improved Diversity  [ :arrow_down: ](https://arxiv.org/pdf/2108.03205.pdf)
>  Multidimensional Index Modulations (IM) are a novel alternative to conventional modulations which can bring considerable benefits for future wireless networks. Within this scope, in this paper we present a new scheme, named as Precoding-aided Transmitter side Generalized Space-Frequency Index Modulation (PT-GSFIM), where part of the information bits select the active antennas and subcarriers which then carry amplitude and phase modulated symbols. The proposed scheme is designed for multiuser multiple-input multiple-output (MU-MIMO) scenarios and incorporates a precoder which removes multiuser interference (MUI) at the receivers. Furthermore, the proposed PT-GSFIM also integrates signal space diversity (SSD) techniques for tackling the typical poor performance of uncoded orthogonal frequency division multiplexing (OFDM) based schemes. By combining complex rotation matrices (CRM) and subcarrier-level interleaving, PT-GSFIM can exploit the inherent diversity in frequency selective channels and improve the performance without additional power or bandwidth. To support reliable detection of the multidimensional PT-GSFIM we also propose three different detection algorithms which can provide different tradeoffs between performance and complexity. Simulation results shows that proposed PT-GSFIM scheme, can provide significant gains over conventional MU-MIMO and GSM schemes.      
### 3.Dynamic Control for Random Access in Deadline-Constrained Broadcasting  [ :arrow_down: ](https://arxiv.org/pdf/2108.03176.pdf)
>  This paper considers random access in deadline-constrained broadcasting with frame-synchronized traffic. To enhance the maximum achievable timely delivery ratio (TDR), we define a dynamic control scheme that allows each active node to determine the transmission probability with certainty based on the current delivery urgency and the knowledge of current contention intensity. For an idealized environment where the contention intensity is completely known, we develop an analytical framework based on the theory of Markov Decision Process (MDP), which leads to an optimal scheme by applying backward induction. For a realistic environment where the contention intensity is incompletely known, we develop a framework using Partially Observable Markov Decision Process (POMDP), which can in theory be solved. We show that for both environments, there exists an optimal scheme that is optimal over all types of policies. To overcome the infeasibility in obtaining an optimal or near-optimal scheme from the POMDP framework, we investigate the behaviors of the optimal scheme for two extreme cases in the MDP framework, and leverage intuition gained from these behaviors to propose a heuristic scheme for the realistic environment with TDR close to the maximum achievable TDR in the idealized environment. In addition, we propose an approximation on the knowledge of contention intensity to further simplify this heuristic scheme. Numerical results with respect to a wide range of configurations are provided to validate our study.      
### 4.Incremental learning of LSTM framework for sensor fusion in attitude estimation  [ :arrow_down: ](https://arxiv.org/pdf/2108.03173.pdf)
>  This paper presents a novel method for attitude estimation of an object in 3D space by incremental learning of the Long-Short Term Memory (LSTM) network. Gyroscope, accelerometer, and magnetometer are few widely used sensors in attitude estimation applications. Traditionally, multi-sensor fusion methods such as the Extended Kalman Filter and Complementary Filter are employed to fuse the measurements from these sensors. However, these methods exhibit limitations in accounting for the uncertainty, unpredictability, and dynamic nature of the motion in real-world situations. In this paper, the inertial sensors data are fed to the LSTM network which are then updated incrementally to incorporate the dynamic changes in motion occurring in the run time. The robustness and efficiency of the proposed framework is demonstrated on the dataset collected from a commercially available inertial measurement unit. The proposed framework offers a significant improvement in the results compared to the traditional method, even in the case of a highly dynamic environment. The LSTM framework-based attitude estimation approach can be deployed on a standard AI-supported processing module for real-time applications.      
### 5.A General Regularized Distributed Solution for System State Estimation from Relative Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2108.03172.pdf)
>  Resting on the graph-based representation of multi-agent architectures, this work presents a novel general regularized distributed solution for state estimation in networked systems. Adopting a multivariate least-squares approach, the designed solution exploits the set of the available inter-agent relative measurements and resorts on the introduction of some regularization parameters, whose selection is shown to affect the estimation procedure convergence performance. As confirmed by the numerical results, this new general framework allows both the extension of the regularization approach investigated in literature and the convergence rate optimization of the distributed estimation in correspondence to any (undirected) graph modeling the given multi-agent system.      
### 6.Respiratory Rate Estimation Based on WiFi Frame Capture  [ :arrow_down: ](https://arxiv.org/pdf/2108.03170.pdf)
>  This paper presents a method that estimates the respiratory rate based on the frame capturing of wireless local area networks. The method uses beamforming feedback matrices (BFMs) contained in the captured frames, which is a rotation matrix of channel state information (CSI). BFMs are transmitted unencrypted and easily obtained using frame capturing, requiring no specific firmware or WiFi chipsets, unlike the methods that use CSI. Such properties of BFMs allow us to apply frame capturing to various sensing tasks, e.g., vital sensing. In the proposed method, principal component analysis is applied to BFMs to isolate the effect of the chest movement of the subject, and then, discrete Fourier transform is performed to extract respiratory rates in a frequency domain. Experimental evaluation results confirm that the frame-capture-based respiratory rate estimation can achieve estimation error lower than 3.2 breaths/minute.      
### 7.Responding to Illegal Activities Along the Canadian Coastlines Using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.03169.pdf)
>  This article elaborates on how machine learning (ML) can leverage the solution of a contemporary problem related to the security of maritime domains. The worldwide ``Illegal, Unreported, and Unregulated'' (IUU) fishing incidents have led to serious environmental and economic consequences which involve drastic changes in our ecosystems in addition to financial losses caused by the depletion of natural resources. The Fisheries and Aquatic Department (FAD) of the United Nation's Food and Agriculture Organization (FAO) issued a report which indicated that the annual losses due to IUU fishing reached $25 Billion. This imposes negative impacts on the future-biodiversity of the marine ecosystem and domestic Gross National Product (GNP). Hence, robust interception mechanisms are increasingly needed for detecting and pursuing the unrelenting illegal fishing incidents in maritime territories. This article addresses the problem of coordinating the motion of a fleet of marine vessels (pursuers) to catch an IUU vessel while still in local waters. The problem is formulated as a pursuer-evader problem that is tackled within an ML framework. One or more pursuers, such as law enforcement vessels, intercept an evader (i.e., the illegal fishing ship) using an online reinforcement learning mechanism that is based on a value iteration process. It employs real-time navigation measurements of the evader ship as well as those of the pursuing vessels and returns back model-free interception strategies.      
### 8.Pattern Recognition in Vital Signs Using Spectrograms  [ :arrow_down: ](https://arxiv.org/pdf/2108.03168.pdf)
>  Spectrograms visualize the frequency components of a given signal which may be an audio signal or even a time-series signal. Audio signals have higher sampling rate and high variability of frequency with time. Spectrograms can capture such variations well. But, vital signs which are time-series signals have less sampling frequency and low-frequency variability due to which, spectrograms fail to express variations and patterns. In this paper, we propose a novel solution to introduce frequency variability using frequency modulation on vital signs. Then we apply spectrograms on frequency modulated signals to capture the patterns. The proposed approach has been evaluated on 4 different medical datasets across both prediction and classification tasks. Significant results are found showing the efficacy of the approach for vital sign signals. The results from the proposed approach are promising with an accuracy of 91.55% and 91.67% in prediction and classification tasks respectively.      
### 9.Generalized Tensor Summation Compressive Sensing Network (GTSNET): An Easy to Learn Compressive Sensing Operation  [ :arrow_down: ](https://arxiv.org/pdf/2108.03167.pdf)
>  In CS literature, the efforts can be divided into two groups: finding a measurement matrix that preserves the compressed information at the maximum level, and finding a reconstruction algorithm for the compressed information. In the traditional CS setup, the measurement matrices are selected as random matrices, and optimization-based iterative solutions are used to recover the signals. However, when we handle large signals, using random matrices become cumbersome especially when it comes to iterative optimization-based solutions. Even though recent deep learning-based solutions boost the reconstruction accuracy performance while speeding up the recovery, still jointly learning the whole measurement matrix is a difficult process. In this work, we introduce a separable multi-linear learning of the CS matrix by representing it as the summation of arbitrary number of tensors. For a special case where the CS operation is set as a single tensor multiplication, the model is reduced to the learning-based separable CS; while a dense CS matrix can be approximated and learned as the summation of multiple tensors. Both cases can be used in CS of two or multi-dimensional signals e.g., images, multi-spectral images, videos, etc. Structural CS matrices can also be easily approximated and learned in our multi-linear separable learning setup with structural tensor sum representation. Hence, our learnable generalized tensor summation CS operation encapsulates most CS setups including separable CS, non-separable CS (traditional vector-matrix multiplication), structural CS, and CS of the multi-dimensional signals. For both gray-scale and RGB images, the proposed scheme surpasses most state-of-the-art solutions, especially in lower measurement rates. Although the performance gain remains limited from tensor to the sum of tensor representation for gray-scale images, it becomes significant in the RGB case.      
### 10.Feature Augmented Hybrid CNN for Stress Recognition Using Wrist-based Photoplethysmography Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2108.03166.pdf)
>  Stress is a physiological state that hampers mental health and has serious consequences to physical health. Moreover, the COVID-19 pandemic has increased stress levels among people across the globe. Therefore, continuous monitoring and detection of stress are necessary. The recent advances in wearable devices have allowed the monitoring of several physiological signals related to stress. Among them, wrist-worn wearable devices like smartwatches are most popular due to their convenient usage. And the photoplethysmography (PPG) sensor is the most prevalent sensor in almost all consumer-grade wrist-worn smartwatches. Therefore, this paper focuses on using a wrist-based PPG sensor that collects Blood Volume Pulse (BVP) signals to detect stress which may be applicable for consumer-grade wristwatches. Moreover, state-of-the-art works have used either classical machine learning algorithms to detect stress using hand-crafted features or have used deep learning algorithms like Convolutional Neural Network (CNN) which automatically extracts features. This paper proposes a novel hybrid CNN (H-CNN) classifier that uses both the hand-crafted features and the automatically extracted features by CNN to detect stress using the BVP signal. Evaluation on the benchmark WESAD dataset shows that, for 3-class classification (Baseline vs. Stress vs. Amusement), our proposed H-CNN outperforms traditional classifiers and normal CNN by 5% and 7% accuracy, and 10% and 7% macro F1 score, respectively. Also for 2-class classification (Stress vs. Non-stress), our proposed H-CNN outperforms traditional classifiers and normal CNN by 3% and ~5% accuracy, and ~3% and ~7% macro F1 score, respectively.      
### 11.RadioMic: Sound Sensing via mmWave Signals  [ :arrow_down: ](https://arxiv.org/pdf/2108.03164.pdf)
>  Voice interfaces has become an integral part of our lives, with the proliferation of smart devices. Today, IoT devices mainly rely on microphones to sense sound. Microphones, however, have fundamental limitations, such as weak source separation, limited range in the presence of acoustic insulation, and being prone to multiple side-channel attacks. In this paper, we propose RadioMic, a radio-based sound sensing system to mitigate these issues and enrich sound applications. RadioMic constructs sound based on tiny vibrations on active sources (e.g., a speaker or human throat) or object surfaces (e.g., paper bag), and can work through walls, even a soundproof one. To convert the extremely weak sound vibration in the radio signals into sound signals, RadioMic introduces radio acoustics, and presents training-free approaches for robust sound detection and high-fidelity sound recovery. It then exploits a neural network to further enhance the recovered sound by expanding the recoverable frequencies and reducing the noises. RadioMic translates massive online audios to synthesized data to train the network, and thus minimizes the need of RF data. We thoroughly evaluate RadioMic under different scenarios using a commodity mmWave radar. The results show RadioMic outperforms the state-of-the-art systems significantly. We believe RadioMic provides new horizons for sound sensing and inspires attractive sensing capabilities of mmWave sensing devices      
### 12.RockGPT: Reconstructing three-dimensional digital rocks from single two-dimensional slice from the perspective of video generation  [ :arrow_down: ](https://arxiv.org/pdf/2108.03132.pdf)
>  Random reconstruction of three-dimensional (3D) digital rocks from two-dimensional (2D) slices is crucial for elucidating the microstructure of rocks and its effects on pore-scale flow in terms of numerical modeling, since massive samples are usually required to handle intrinsic uncertainties. Despite remarkable advances achieved by traditional process-based methods, statistical approaches and recently famous deep learning-based models, few works have focused on producing several kinds of rocks with one trained model and allowing the reconstructed samples to satisfy certain given properties, such as porosity. To fill this gap, we propose a new framework, named RockGPT, which is composed of VQ-VAE and conditional GPT, to synthesize 3D samples based on a single 2D slice from the perspective of video generation. The VQ-VAE is utilized to compress high-dimensional input video, i.e., the sequence of continuous rock slices, to discrete latent codes and reconstruct them. In order to obtain diverse reconstructions, the discrete latent codes are modeled using conditional GPT in an autoregressive manner, while incorporating conditional information from a given slice, rock type, and porosity. We conduct two experiments on five kinds of rocks, and the results demonstrate that RockGPT can produce different kinds of rocks with the same model, and the reconstructed samples can successfully meet certain specified porosities. In a broader sense, through leveraging the proposed conditioning scheme, RockGPT constitutes an effective way to build a general model to produce multiple kinds of rocks simultaneously that also satisfy user-defined properties.      
### 13.COVID-Net US: A Tailored, Highly Efficient, Self-Attention Deep Convolutional Neural Network Design for Detection of COVID-19 Patient Cases from Point-of-care Ultrasound Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2108.03131.pdf)
>  The Coronavirus Disease 2019 (COVID-19) pandemic has impacted many aspects of life globally, and a critical factor in mitigating its effects is screening individuals for infections, thereby allowing for both proper treatment for those individuals as well as action to be taken to prevent further spread of the virus. Point-of-care ultrasound (POCUS) imaging has been proposed as a screening tool as it is a much cheaper and easier to apply imaging modality than others that are traditionally used for pulmonary examinations, namely chest x-ray and computed tomography. Given the scarcity of expert radiologists for interpreting POCUS examinations in many highly affected regions around the world, low-cost deep learning-driven clinical decision support solutions can have a large impact during the on-going pandemic. Motivated by this, we introduce COVID-Net US, a highly efficient, self-attention deep convolutional neural network design tailored for COVID-19 screening from lung POCUS images. Experimental results show that the proposed COVID-Net US can achieve an AUC of over 0.98 while achieving 353X lower architectural complexity, 62X lower computational complexity, and 14.3X faster inference times on a Raspberry Pi. Clinical validation was also conducted, where select cases were reviewed and reported on by a practicing clinician (20 years of clinical practice) specializing in intensive care (ICU) and 15 years of expertise in POCUS interpretation. To advocate affordable healthcare and artificial intelligence for resource-constrained environments, we have made COVID-Net US open source and publicly available as part of the COVID-Net open source initiative.      
### 14.Complex-valued Spatial Autoencoders for Multichannel Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2108.03130.pdf)
>  In this contribution, we present a novel online approach to multichannel speech enhancement. The proposed method estimates the enhanced signal through a filter-and-sum framework. More specifically, complex-valued masks are estimated by a deep complex-valued neural network, termed the complex-valued spatial autoencoder. The proposed network is capable of exploiting as well as manipulating both the phase and the amplitude of the microphone signals. As shown by the experimental results, the proposed approach is able to exploit both spatial and spectral characteristics of the desired source signal resulting in a physically plausible spatial selectivity and superior speech quality compared to other baseline methods.      
### 15.Stochastic Deep Model Reference Adaptive Control  [ :arrow_down: ](https://arxiv.org/pdf/2108.03120.pdf)
>  In this paper, we present a Stochastic Deep Neural Network-based Model Reference Adaptive Control. Building on our work "Deep Model Reference Adaptive Control", we extend the controller capability by using Bayesian deep neural networks (DNN) to represent uncertainties and model non-linearities. Stochastic Deep Model Reference Adaptive Control uses a Lyapunov-based method to adapt the output-layer weights of the DNN model in real-time, while a data-driven supervised learning algorithm is used to update the inner-layers parameters. This asynchronous network update ensures boundedness and guaranteed tracking performance with a learning-based real-time feedback controller. A Bayesian approach to DNN learning helped avoid over-fitting the data and provide confidence intervals over the predictions. The controller's stochastic nature also ensured "Induced Persistency of excitation," leading to convergence of the overall system signal.      
### 16.Deep Residual Echo Suppression and Noise Reduction: A Multi-Input FCRN Approach in a Hybrid Speech Enhancement System  [ :arrow_down: ](https://arxiv.org/pdf/2108.03051.pdf)
>  Deep neural network (DNN)-based approaches to acoustic echo cancellation (AEC) and hybrid speech enhancement systems have gained increasing attention recently, introducing significant performance improvements to this research field. Using the fully convolutional recurrent network (FCRN) architecture that is among state of the art topologies for noise reduction, we present a novel deep residual echo suppression and noise reduction with up to four input signals as part of a hybrid speech enhancement system with a linear frequency domain adaptive Kalman filter AEC. In an extensive ablation study, we reveal trade-offs with regard to echo suppression, noise reduction, and near-end speech quality, and provide surprising insights to the choice of the FCRN inputs: In contrast to often seen input combinations for this task, we propose not to use the loudspeaker reference signal, but the enhanced signal after AEC, the microphone signal, and the echo estimate, yielding improvements over previous approaches by more than 0.2 PESQ points.      
### 17.Energy Efficiency Maximization Precoding for Quantized Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.03048.pdf)
>  The use of low-resolution digital-to-analog and analog-to-digital converters (DACs and ADCs) significantly benefits energy efficiency (EE) at the cost of high quantization noise in implementing massive multiple-input multiple-output (MIMO) systems. For maximizing EE in quantized downlink massive MIMO systems, this paper formulates a precoding optimization problem with antenna selection; yet acquiring the optimal joint precoding and antenna selection solution is challenging due to the intricate EE characterization. To resolve this challenge, we decompose the problem into precoding direction and power optimization problems. For precoding direction, we characterize the first-order optimality condition, which entails the effects of quantization distortion and antenna selection. For precoding power, we obtain the optimum solution using a gradient descent algorithm to maximize EE for given precoding direction. We cast the derived condition as a functional eigenvalue problem, wherein finding the principal eigenvector attains the best local optimal point. To this end, we propose generalized power iteration based algorithm. Alternating these two methods, our algorithm identifies a joint solution of the active antenna set and the precoding direction and power. In simulations, the proposed methods provide considerable performance gains. Our results suggest that a few-bit DACs are sufficient for achieving high EE in massive MIMO systems.      
### 18.The Influence of Age and Gender Information on the Diagnosis of Diabetic Retinopathy: Based on Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.03026.pdf)
>  This paper proposes the importance of age and gender information in the diagnosis of diabetic retinopathy. We utilized Deep Residual Neural Networks (ResNet) and Densely Connected Convolutional Networks (DenseNet), which are proven effective on image classification problems and the diagnosis of diabetic retinopathy using the retinal fundus images. We used the ensemble of several classical networks and decentralized the training so that the network was simple and avoided overfitting. To observe whether the age and gender information could help enhance the performance, we added the information before the dense layer and compared the results with the results that did not add age and gender information. We found that the test accuracy of the network with age and gender information was 2.67% higher than that of the network without age and gender information. Meanwhile, compared with gender information, age information had a better help for the results.      
### 19.Rollout event-triggered control: Reconciling event- and time-triggered control  [ :arrow_down: ](https://arxiv.org/pdf/2108.02994.pdf)
>  Event-triggered control (ETC) and time-triggered control (TTC), the classical concepts to determine the transmission instants for networked control systems, each come with drawbacks: It is difficult to tune ETC such that a certain bandwidth is respected, whereas TTC cannot adapt the sampling interval to the current state of the control system. In this article, we provide an overview over rollout ETC, a method aimed at reconciling the advantages of ETC and TTC. We unite two variants of rollout ETC under a common framework and present conditions for convergence and compliance with a predefined bandwidth limit. Furthermore, we demonstrate that rollout ETC satisfies a performance bound and that it allows for a very flexible transmission scheduling similar to classical ETC. The mentioned beneficial properties are illustrated through extensive numerical simulations.      
### 20.Deep Reinforcement Learning for Intelligent Reflecting Surface-assisted D2D Communications  [ :arrow_down: ](https://arxiv.org/pdf/2108.02892.pdf)
>  In this paper, we propose a deep reinforcement learning (DRL) approach for solving the optimisation problem of the network's sum-rate in device-to-device (D2D) communications supported by an intelligent reflecting surface (IRS). The IRS is deployed to mitigate the interference and enhance the signal between the D2D transmitter and the associated D2D receiver. Our objective is to jointly optimise the transmit power at the D2D transmitter and the phase shift matrix at the IRS to maximise the network sum-rate. We formulate a Markov decision process and then propose the proximal policy optimisation for solving the maximisation game. Simulation results show impressive performance in terms of the achievable rate and processing time.      
### 21.RIS-assisted UAV Communications for IoT with Wireless Power Transfer Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.02889.pdf)
>  Many of the devices used in Internet-of-Things (IoT) applications are energy-limited, and thus supplying energy while maintaining seamless connectivity for IoT devices is of considerable importance. In this context, we propose a simultaneous wireless power transfer and information transmission scheme for IoT devices with support from reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicle (UAV) communications. In particular, in a first phase, IoT devices harvest energy from the UAV through wireless power transfer; and then in a second phase, the UAV collects data from the IoT devices through information transmission. To characterise the agility of the UAV, we consider two scenarios: a hovering UAV and a mobile UAV. Aiming at maximizing the total network sum-rate, we jointly optimize the trajectory of the UAV, the energy harvesting scheduling of IoT devices, and the phaseshift matrix of the RIS. We formulate a Markov decision process and propose two deep reinforcement learning algorithms to solve the optimization problem of maximizing the total network sum-rate. Numerical results illustrate the effectiveness of the UAV's flying path optimization and the network's throughput of our proposed techniques compared with other benchmark schemes. Given the strict requirements of the RIS and UAV, the significant improvement in processing time and throughput performance demonstrates that our proposed scheme is well applicable for practical IoT applications.      
### 22.Unsupervised Domain Adaptation in Speech Recognition using Phonetic Features  [ :arrow_down: ](https://arxiv.org/pdf/2108.02850.pdf)
>  Automatic speech recognition is a difficult problem in pattern recognition because several sources of variability exist in the speech input like the channel variations, the input might be clean or noisy, the speakers may have different accent and variations in the gender, etc. As a result, domain adaptation is important in speech recognition where we train the model for a particular source domain and test it on a different target domain. In this paper, we propose a technique to perform unsupervised gender-based domain adaptation in speech recognition using phonetic features. The experiments are performed on the TIMIT dataset and there is a considerable decrease in the phoneme error rate using the proposed approach.      
### 23.Ada-VSR: Adaptive Video Super-Resolution with Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.02832.pdf)
>  Most of the existing works in supervised spatio-temporal video super-resolution (STVSR) heavily rely on a large-scale external dataset consisting of paired low-resolution low-frame rate (LR-LFR)and high-resolution high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these methods make a prior assumption that the low-resolution video is obtained by down-scaling the high-resolution video using a known degradation kernel, which does not hold in practical settings. Another problem with these methods is that they cannot exploit instance-specific internal information of video at testing time. Recently, deep internal learning approaches have gained attention due to their ability to utilize the instance-specific statistics of a video. However, these methods have a large inference time as they require thousands of gradient updates to learn the intrinsic structure of the data. In this work, we presentAdaptiveVideoSuper-Resolution (Ada-VSR) which leverages external, as well as internal, information through meta-transfer learning and internal learning, respectively. Specifically, meta-learning is employed to obtain adaptive parameters, using a large-scale external dataset, that can adapt quickly to the novel condition (degradation model) of the given test video during the internal learning task, thereby exploiting external and internal information of a video for super-resolution. The model trained using our approach can quickly adapt to a specific video condition with only a few gradient updates, which reduces the inference time significantly. Extensive experiments on standard datasets demonstrate that our method performs favorably against various state-of-the-art approaches.      
### 24.Applying the Information Bottleneck Principle to Prosodic Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.02821.pdf)
>  This paper describes a novel design of a neural network-based speech generation model for learning prosodic representation.The problem of representation learning is formulated according to the information bottleneck (IB) principle. A modified VQ-VAE quantized layer is incorporated in the speech generation model to control the IB capacity and adjust the balance between reconstruction power and disentangle capability of the learned representation. The proposed model is able to learn word-level prosodic representations from speech data. With an optimized IB capacity, the learned representations not only are adequate to reconstruct the original speech but also can be used to transfer the prosody onto different textual content. Extensive results of the objective and subjective evaluation are presented to demonstrate the effect of IB capacity control, the effectiveness, and potential usage of the learned prosodic representation in controllable neural speech generation.      
### 25.Configuring Antenna System to Enhance the Downlink Performance of High Velocity Users in 5G MU-MIMO Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.02804.pdf)
>  An exponential increase in the data rate demand prompted several technical innovations. Multi User Multiple Input Multiple Output (MU-MIMO) is one of the most promising schemes. This has been evolved into Massive MIMO technology in 5G to further stretch the network throughput. Massive MIMO tackles the rising data rate with the increase in the number of antenna. This comes at the price of a higher energy consumption. Moreover the high velocity users in MU-MIMO scheme experiences a frequent unpredictable change in the channel condition that degrade its downlink performance. Therefore a proper number of antenna selection is of paramount importance. This issue has been addressed using machine learning techniques and Channel State Information (CSI) but only for static users. In this study we propose to introduce antenna diversity in spatial multiplexing MU-MIMO transmission scheme by operating more number of reception antenna compare to the number of transmission antenna. The diversity improves the downlink performance of high velocity users. In general our results can be interpreted for large scale antenna systems like Massive MIMO. The proposed method can be easily implemented in the existing network architectures with minimal complexity. Also it has the potential for solving real-life problems like call drops and low data rate to be experienced by cellular users traveling through high-speed transportation systems like Dhaka MRT project      
### 26.Differentiable Moving Horizon Estimation for Robust Flight Control  [ :arrow_down: ](https://arxiv.org/pdf/2108.03212.pdf)
>  Estimating and reacting to external disturbances is of fundamental importance for robust control of quadrotors. Existing estimators typically require significant tuning or training with a large amount of data, including the ground truth, to achieve satisfactory performance. This paper proposes a data-efficient differentiable moving horizon estimation (DMHE) algorithm that can automatically tune the MHE parameters online and also adapt to different scenarios. We achieve this by deriving the analytical gradient of the estimated trajectory from MHE with respect to the tuning parameters, enabling end-to-end learning for auto-tuning. Most interestingly, we show that the gradient can be calculated efficiently from a Kalman filter in a recursive form. Moreover, we develop a model-based policy gradient algorithm to learn the parameters directly from the trajectory tracking errors without the need for the ground truth. The proposed DMHE can be further embedded as a layer with other neural networks for joint optimization. Finally, we demonstrate the effectiveness of the proposed method via both simulation and experiments on quadrotors, where challenging scenarios such as sudden payload change and flying in downwash are examined.      
### 27.Beam-Slicing for Jammer Mitigation in mmWave Massive MU-MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2108.03202.pdf)
>  Millimeter-wave (mmWave) massive multi-user multiple-input multiple-output (MU-MIMO) technology promises unprecedentedly high data rates for next-generation wireless systems. To be practically viable, mmWave massive MU-MIMO basestations (BS) must (i) rely on low-resolution data-conversion and (ii) be robust to jammer interference. This paper considers the problem of mitigating the impact of a permanently transmitting jammer during uplink transmission to a BS equipped with low-resolution analog-to-digital converters (ADCs). To this end, we propose SNIPS, short for Soft-Nulling of Interferers with Partitions in Space. SNIPS combines beam-slicing---a localized, analog spatial transform that focuses the jammer energy onto a subset of all ADCs---together with a soft-nulling data detector that exploits knowledge of which ADCs are contaminated by jammer interference. Our numerical results show that SNIPS is able to successfully serve 65% of the user equipments (UEs) for scenarios in which a conventional antenna-domain soft-nulling data detector is only able to serve 2% of the UEs.      
### 28.Shift-invariant waveform learning on epileptic ECoG  [ :arrow_down: ](https://arxiv.org/pdf/2108.03177.pdf)
>  Seizure detection algorithms must discriminate abnormal neuronal activity associated with a seizure from normal neural activity in a variety of conditions. Our approach is to seek spatiotemporal waveforms with distinct morphology in electrocorticographic (ECoG) recordings of epileptic patients that are indicative of a subsequent seizure (preictal) versus non-seizure segments (interictal). To find these waveforms we apply a shift-invariant k-means algorithm to segments of spatially filtered signals to learn codebooks of prototypical waveforms. The frequency of the cluster labels from the codebooks is then used to train a binary classifier that predicts the class (preictal or interictal) of a test ECoG segment. We use the Matthews correlation coefficient to evaluate the performance of the classifier and the quality of the codebooks. We found that our method finds recurrent non-sinusoidal waveforms that could be used to build interpretable features for seizure prediction and that are also physiologically meaningful.      
### 29.Accurate simulation of operating system updates in neuroimaging using Monte-Carlo arithmetic  [ :arrow_down: ](https://arxiv.org/pdf/2108.03129.pdf)
>  Operating system (OS) updates introduce numerical perturbations that impact the reproducibility of computational pipelines. In neuroimaging, this has important practical implications on the validity of computational results, particularly when obtained in systems such as high-performance computing clusters where the experimenter does not control software updates. We present a framework to reproduce the variability induced by OS updates in controlled conditions. We hypothesize that OS updates impact computational pipelines mainly through numerical perturbations originating in mathematical libraries, which we simulate using Monte-Carlo arithmetic in a framework called "fuzzy libmath" (FL). We applied this methodology to pre-processing pipelines of the Human Connectome Project, a flagship open-data project in neuroimaging. We found that FL-perturbed pipelines accurately reproduce the variability induced by OS updates and that this similarity is only mildly dependent on simulation parameters. Importantly, we also found between-subject differences were preserved in both cases, though the between-run variability was of comparable magnitude for both FL and OS perturbations. We found the numerical precision in the HCP pre-processed images to be relatively low, with less than 8 significant bits among the 24 available, which motivates further investigation of the numerical stability of components in the tested pipeline. Overall, our results establish that FL accurately simulates results variability due to OS updates, and is a practical framework to quantify numerical uncertainty in neuroimaging.      
### 30.Anomaly Search with Multiple Plays under Delay and Switching Costs  [ :arrow_down: ](https://arxiv.org/pdf/2108.03082.pdf)
>  The problem of searching for $L$ anomalous processes among $M$ processes is considered. At each time, the decision maker can observe a subset of $K$ processes (i.e., multiple plays). The measurement drawn when observing a process follows one of two different distributions, depending on whether the process is normal or abnormal. The goal is to design a policy that minimizes the Bayes risk which balances between the sample complexity, detection errors, and the switching cost associated with switching across processes. We develop a policy, dubbed consecutive controlled sensing (CCS), to achieve this goal. On the one hand, by contrast to existing studies on controlled sensing, the CCS policy senses processes consecutively to reduce the switching cost. On the other hand, the policy controls the sensing operation in a closed-loop manner to switch between processes when necessary to guarantee reliable inference. We prove theoretically that CCS is asymptotically optimal in terms of minimizing the Bayes risk as the detection error approaches zero (i.e., the sample complexity increases). Simulation results demonstrate strong performance of CCS in the finite regime as well.      
### 31.Alternative Formulations for the Fluctuating Two-Ray Fading Model  [ :arrow_down: ](https://arxiv.org/pdf/2108.02990.pdf)
>  We present two alternative formulations for the popular fluctuating two-ray (FTR) fading model, which largely simplify its statistical characterization and subsequent use for performance evaluation. The new formulations are based on the observation that the FTR fading distribution can be expressed in terms of a finite continuous mixture of simpler distributions, also popular in the context of wireless channel modeling. In the general case with arbitrary $m$, the FTR fading model is described as an underlying Rician Shadowed (RS) distribution with continuously varying parameter $K$; hence, the chief statistics of the FTR fading model are expressed in terms of a finite-range integral over the equivalent RS statistic. In the special case of integer $m$, the FTR fading model is described in terms of a finite number of underlying squared Nakagami-$m$ distributions; again, the chief statistics of the FTR fading model are expressed in terms of a number of finite-range integrals over the equivalent Nakagami-$m$ statistic. In all instances, previous existing results in the literature for those simpler distributions can be extended to the case of FTR fading. Alternative expressions for the probability density function and cumulative distribution function of the FTR model are obtained, as well as new expressions for some Laplace-domain statistics of interest; these are used to exemplify the practical relevance of this new formulation for performance analysis.      
### 32.User Scheduling for Federated Learning Through Over-the-Air Computation  [ :arrow_down: ](https://arxiv.org/pdf/2108.02891.pdf)
>  A new machine learning (ML) technique termed as federated learning (FL) aims to preserve data at the edge devices and to only exchange ML model parameters in the learning process. FL not only reduces the communication needs but also helps to protect the local privacy. Although FL has these advantages, it can still experience large communication latency when there are massive edge devices connected to the central parameter server (PS) and/or millions of model parameters involved in the learning process. Over-the-air computation (AirComp) is capable of computing while transmitting data by allowing multiple devices to send data simultaneously by using analog modulation. To achieve good performance in FL through AirComp, user scheduling plays a critical role. In this paper, we investigate and compare different user scheduling policies, which are based on various criteria such as wireless channel conditions and the significance of model updates. Receiver beamforming is applied to minimize the mean-square-error (MSE) of the distortion of function aggregation result via AirComp. Simulation results show that scheduling based on the significance of model updates has smaller fluctuations in the training process while scheduling based on channel condition has the advantage on energy efficiency.      
### 33.The most likely evolution of diffusing and vanishing particles: Schrodinger Bridges with unbalanced marginals  [ :arrow_down: ](https://arxiv.org/pdf/2108.02879.pdf)
>  Stochastic flows of an advective-diffusive nature are ubiquitous in physical sciences. Of particular interest is the problem to reconcile observed marginal distributions with a given prior posed by E. Schrodinger in 1932/32 and known as the Schrodinger Bridge Problem (SBP). Due to its fundamental significance, interest in SBP has in recent years enticed a broad spectrum of disciplines. Yet, while the mathematics and applications of SBP have been developing at a considerable pace, accounting for marginals of unequal mass has received scant attention; the problem to interpolate between unbalanced marginals has been approached by introducing source/sink terms in an Adhoc manner. Nevertheless, losses are inherent in many physical processes and, thereby, models that account for lossy transport may also need to be reconciled with observed marginals following Schrodinger's dictum; that is, to adjust the probability of trajectories of particles, including those that do not make it to the terminal observation point, so that the updated law represents the most likely way that particles may have been transported, or vanished, at some intermediate point. Thus, the purpose of this work is to develop such a natural generalization of the SBP for stochastic evolution with losses, whereupon particles are "killed" according to a probabilistic law. Through a suitable embedding, we turn the problem into an SBP for stochastic processes that combine diffusive and jump characteristics. Then, following a large-deviations formalism, given a prior law that allows for losses, we ask for the most probable evolution of particles along with the most likely killing rate as the particles transition between the specified marginals. Our approach differs sharply from previous work involving a Feynman-Kac multiplicative reweighing of the reference measure: The latter, as we argue, is far from Schrodinger's quest.      
### 34.Two Basic Queueing Models of Service Platforms in Digital Sharing Economy  [ :arrow_down: ](https://arxiv.org/pdf/2108.02852.pdf)
>  This paper describes two basic queueing models of service platforms in digital sharing economy by means of two different policies of platform matching information. We show that the two queueing models of service platforms can be expressed as the level-independent quasi birth-and-death (QBD) processes. Using the proposed QBD processes, we provide a detailed analysis for the two queueing models of service platforms, including the system stability, the average stationary numbers of seekers and of idle owners, the expected sojourn time of an arriving seeker, and the expected profits for both the service platform and each owner. Finally, numerical examples are employed to verify our theoretical results, and demonstrate how the performance measures of service platforms are influenced by some key system parameters. We believe that the methodology and results developed in this paper not only can be applied to develop a broad class of queuing models of service platforms, but also will open a series of promising innovative research on performance evaluation, optimal control and queueing-game of service platforms and digital sharing economy.      
