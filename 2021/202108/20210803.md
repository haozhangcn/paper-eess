# ArXiv eess --Tue, 3 Aug 2021
### 1.Open and free EEG datasets for epilepsy diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2108.01030.pdf)
>  The Epilepsies are a common, chronic neurological disorder affecting more than 50 million individuals across the globe. It is characterized by unprovoked, recurring (similar or different type) seizures which are commonly diagnosed through clinical EEGs. Good-quality, open-access and free EEG data can act as a catalyst for on-going state-of-the-art (SOTA) research works for detection, prediction and management of epilepsy and seizures. They can also aid in improving the quality of life (QOL) of these diseased individuals and contribute research in healthcare multimedia, data analytics and Artificial Intelligence (AI) in personalized medicine. This paper presents widely used, available, open and free EEG datasets available for epilepsy and seizure diagnosis. A brief comparison and discussion of open and private datasets has also been done. Such datasets will help in development and evaluation of automatic computer-aided system in healthcare.      
### 2.Accelerated Alternating Minimization for X-ray Tomographic Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2108.01017.pdf)
>  While Computerized Tomography (CT) images can help detect disease such as Covid-19, regular CT machines are large and expensive. Cheaper and more portable machines suffer from errors in geometry acquisition that downgrades CT image quality. The errors in geometry can be represented with parameters in the mathematical model for image reconstruction. To obtain a good image, we formulate a nonlinear least squares problem that simultaneously reconstructs the image and corrects for errors in the geometry parameters. We develop an accelerated alternating minimization scheme to reconstruct the image and geometry parameters.      
### 3.Aircraft turnaround time estimation in early design phases: simulation tools development and application to the case of box-wing architecture  [ :arrow_down: ](https://arxiv.org/pdf/2108.01015.pdf)
>  This work deals with the problem of estimating the turnaround time in the early stages of aircraft design. The turnaround time has a significant impact in terms of marketability and value creation potential of an aircraft and, for this reason, it should be considered as an important driver of fuselage and cabin design decisions. Estimating the turnaround time during the early stages of aircraft design is therefore an essential task. This task becomes even more decisive when designers explore unconventional aircraft architectures or, in general, are still evaluating the fuselage design and its internal layout. In particular, it is of paramount importance to properly estimate the boarding and deboarding times, which contribute for up the 40% to the overall turnaround time. For this purpose, a tool, called SimBaD, has been developed and validated with publicly available data for existing aircraft of different classes. In order to demonstrate SimBaD capability of evaluating the influence of fuselage and cabin features on the turnaround time, its application to an unconventional box-wing aircraft architecture, known as PrandtlPlane, is presented as case study. Finally, considering standard scenarios provided by aircraft manufacturers, a comparison between the turnaround time of the PrandtlPlane and the turnaround time of a conventional competitor aircraft is presented.      
### 4.Control Design of Dynamic Virtual Power Plants: An Adaptive Divide-and-Conquer Approach  [ :arrow_down: ](https://arxiv.org/pdf/2108.00925.pdf)
>  In this paper, we present a novel decentralized and multivariable control approach for dynamic virtual power plants (DVPPs). In particular, we consider a group of heterogeneous distributed energy resources (DERs) which collectively provide desired dynamic ancillary services such as fast frequency and voltage control. Our control approach relies on an adaptive divide-and-conquer strategy: First, we disaggregate the desired frequency and voltage control specifications of the aggregate DVPP via adaptive dynamic participation matrices (ADPMs) to obtain the desired local behavior for each device. Second, we design local linear parameter-varying (LPV) $\mathcal{H}_\infty$ controllers to optimally match this local behaviors. In the process, the control design also incorporates the physical and engineered limits of each DVPP device. Furthermore, our adaptive control design can properly respond to fluctuating device capacities, and thus include weather-driven DERs into the DVPP setup. Finally, we demonstrate the effectiveness of our control strategy in a case study based on the IEEE nine-bus system.      
### 5.Analyzing Speaker Information in Self-Supervised Models to Improve Zero-Resource Speech Processing  [ :arrow_down: ](https://arxiv.org/pdf/2108.00917.pdf)
>  Contrastive predictive coding (CPC) aims to learn representations of speech by distinguishing future observations from a set of negative examples. Previous work has shown that linear classifiers trained on CPC features can accurately predict speaker and phone labels. However, it is unclear how the features actually capture speaker and phonetic information, and whether it is possible to normalize out the irrelevant details (depending on the downstream task). In this paper, we first show that the per-utterance mean of CPC features captures speaker information to a large extent. Concretely, we find that comparing means performs well on a speaker verification task. Next, probing experiments show that standardizing the features effectively removes speaker information. Based on this observation, we propose a speaker normalization step to improve acoustic unit discovery using K-means clustering of CPC features. Finally, we show that a language model trained on the resulting units achieves some of the best results in the ZeroSpeech2021~Challenge.      
### 6.2-D Directed Formation Control Based on Bipolar Coordinates  [ :arrow_down: ](https://arxiv.org/pdf/2108.00916.pdf)
>  This work proposes a novel 2-D formation control scheme for acyclic triangulated directed graphs (a class of minimally acyclic persistent graphs) based on bipolar coordinates with (almost) global convergence to the desired shape. Prescribed performance control is employed to devise a decentralized control law that avoids singularities and introduces robustness against external disturbances while ensuring predefined transient and steady-state performance for the closed-loop system. Furthermore, it is shown that the proposed formation control scheme can handle formation maneuvering, scaling, and orientation specifications simultaneously. Additionally, the proposed control law is implementable in the agents' arbitrarily oriented local coordinate frames using only low-cost onboard vision sensors, which are favorable for practical applications. Finally, various simulation studies clarify and verify the proposed approach.      
### 7.Robust Acoustic Scene Classification in the Presence of Active Foreground Speech  [ :arrow_down: ](https://arxiv.org/pdf/2108.00912.pdf)
>  We present an iVector based Acoustic Scene Classification (ASC) system suited for real life settings where active foreground speech can be present. In the proposed system, each recording is represented by a fixed-length iVector that models the recording's important properties. A regularized Gaussian backend classifier with class-specific covariance models is used to extract the relevant acoustic scene information from these iVectors. To alleviate the large performance degradation when a foreground speaker dominates the captured signal, we investigate the use of the iVector framework on Mel-Frequency Cepstral Coefficients (MFCCs) that are derived from an estimate of the noise power spectral density. This noise-floor can be extracted in a statistical manner for single channel recordings. We show that the use of noise-floor features is complementary to multi-condition training in which foreground speech is added to training signal to reduce the mismatch between training and testing conditions. Experimental results on the DCASE 2016 Task 1 dataset show that the noise-floor based features and multi-condition training realize significant classification accuracy gains of up to more than 25 percentage points (absolute) in the most adverse conditions. These promising results can further facilitate the integration of ASC in resource-constrained devices such as hearables.      
### 8.Multi-phase Liver Tumor Segmentation with Spatial Aggregation and Uncertain Region Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2108.00911.pdf)
>  Multi-phase computed tomography (CT) images provide crucial complementary information for accurate liver tumor segmentation (LiTS). State-of-the-art multi-phase LiTS methods usually fused cross-phase features through phase-weighted summation or channel-attention based concatenation. However, these methods ignored the spatial (pixel-wise) relationships between different phases, hence leading to insufficient feature integration. In addition, the performance of existing methods remains subject to the uncertainty in segmentation, which is particularly acute in tumor boundary regions. In this work, we propose a novel LiTS method to adequately aggregate multi-phase information and refine uncertain region segmentation. To this end, we introduce a spatial aggregation module (SAM), which encourages per-pixel interactions between different phases, to make full use of cross-phase information. Moreover, we devise an uncertain region inpainting module (URIM) to refine uncertain pixels using neighboring discriminative features. Experiments on an in-house multi-phase CT dataset of focal liver lesions (MPCT-FLLs) demonstrate that our method achieves promising liver tumor segmentation and outperforms state-of-the-arts.      
### 9.Adversarial Data Augmentation for Disordered Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.00899.pdf)
>  Automatic recognition of disordered speech remains a highly challenging task to date. The underlying neuro-motor conditions, often compounded with co-occurring physical disabilities, lead to the difficulty in collecting large quantities of impaired speech required for ASR system development. To this end, data augmentation techniques play a vital role in current disordered speech recognition systems. In contrast to existing data augmentation techniques only modifying the speaking rate or overall shape of spectral contour, fine-grained spectro-temporal differences between disordered and normal speech are modelled using deep convolutional generative adversarial networks (DCGAN) during data augmentation to modify normal speech spectra into those closer to disordered speech. Experiments conducted on the UASpeech corpus suggest the proposed adversarial data augmentation approach consistently outperformed the baseline augmentation methods using tempo or speed perturbation on a state-of-the-art hybrid DNN system. An overall word error rate (WER) reduction up to 3.05\% (9.7\% relative) was obtained over the baseline system using no data augmentation. The final learning hidden unit contribution (LHUC) speaker adapted system using the best adversarial augmentation approach gives an overall WER of 25.89% on the UASpeech test set of 16 dysarthric speakers.      
### 10.A SPA-based Manifold Learning Framework for Motor Imagery EEG Data Classification  [ :arrow_down: ](https://arxiv.org/pdf/2108.00865.pdf)
>  The electroencephalography (EEG) signal is a non-stationary, stochastic, and highly non-linear bioelectric signal for which achieving high classification accuracy is challenging, especially when the number of subjects is limited. As frequently used solution, classifiers based on multilayer neural networks has to be implemented without large training data sets and careful tuning. This paper proposes a manifold learning framework to classify two types of EEG data from motor imagery (MI) tasks by discovering lower dimensional geometric structures. For feature extraction, it is implemented by Common Spatial Pattern (CSP) from the preprocessed EEG signals. In the neighborhoods of the features for classification, the local approximation to the support of the data is obtained, and then the features are assigned to the classes with the closest support. A spherical approximation (SPA) classifier is created using spherelets for local approximation, and the extracted features are classified with this manifold-based method. The SPA classifier achieves high accuracy in the 2008 BCI competition data, and the analysis shows that this method can significantly improve the decoding accuracy of MI tasks and exhibit strong robustness for small sample datasets. It would be simple and efficient to tune the two-parameters classifier for the online brain-computer interface(BCI)system.      
### 11.Spatio-temporal estimation of wind speed and wind power using machine learning: predictions, uncertainty and technical potential  [ :arrow_down: ](https://arxiv.org/pdf/2108.00859.pdf)
>  The growth of wind generation capacities in the past decades has shown that wind energy can contribute to the energy transition in many parts of the world. Being highly variable and complex to model, the quantification of the spatio-temporal variation of wind power and the related uncertainty is highly relevant for energy planners. Machine Learning has become a popular tool to perform wind-speed and power predictions. However, the existing approaches have several limitations. These include (i) insufficient consideration of spatio-temporal correlations in wind-speed data, (ii) a lack of existing methodologies to quantify the uncertainty of wind speed prediction and its propagation to the wind-power estimation, and (iii) a focus on less than hourly frequencies. To overcome these limitations, we introduce a framework to reconstruct a spatio-temporal field on a regular grid from irregularly distributed wind-speed measurements. After decomposing data into temporally referenced basis functions and their corresponding spatially distributed coefficients, the latter are spatially modelled using Extreme Learning Machines. Estimates of both model and prediction uncertainties, and of their propagation after the transformation of wind speed into wind power, are then provided without any assumptions on distribution patterns of the data. The methodology is applied to the study of hourly wind power potential on a grid of $250\times 250$ m$^2$ for turbines of 100 meters hub height in Switzerland, generating the first dataset of its type for the country. The potential wind power generation is combined with the available area for wind turbine installations to yield an estimate of the technical potential for wind power in Switzerland. The wind power estimate presented here represents an important input for planners to support the design of future energy systems with increased wind power generation.      
### 12.Projective Skip-Connections for Segmentation Along a Subset of Dimensions in Retinal OCT  [ :arrow_down: ](https://arxiv.org/pdf/2108.00831.pdf)
>  In medical imaging, there are clinically relevant segmentation tasks where the output mask is a projection to a subset of input image dimensions. In this work, we propose a novel convolutional neural network architecture that can effectively learn to produce a lower-dimensional segmentation mask than the input image. The network restores encoded representation only in a subset of input spatial dimensions and keeps the representation unchanged in the others. The newly proposed projective skip-connections allow linking the encoder and decoder in a UNet-like structure. We evaluated the proposed method on two clinically relevant tasks in retinal Optical Coherence Tomography (OCT): geographic atrophy and retinal blood vessel segmentation. The proposed method outperformed the current state-of-the-art approaches on all the OCT datasets used, consisting of 3D volumes and corresponding 2D en-face masks. The proposed architecture fills the methodological gap between image classification and ND image segmentation.      
### 13.Objective crystallographic symmetry classifications of noisy and noise-free 2D periodic patterns with strong Fedorov type pseudosymmetries  [ :arrow_down: ](https://arxiv.org/pdf/2108.00829.pdf)
>  Statistically sound crystallographic symmetry classifications are obtained with information theory based methods in the presence of approximately Gaussian distributed noise. A set of three synthetic images with very strong Fedorov type pseudosymmetries and varying amounts of noise serve as examples. The correct distinctions between genuine symmetries and their Fedorov type pseudosymmetry counterparts failed only for the noisiest image of the series where an inconsistent combination of plane symmetry group and projected Laue class was obtained. Contrary to traditional crystallographic symmetry classifications with an image processing program such as CRISP, the classification process does not need to be supervised by a human being. This enables crystallographic symmetry classification of digital images that are more or less periodic in two dimensions (2D) as recorded with sufficient spatial resolution from a wide range of samples with different types of scanning probe microscopes. Alternatives to the employed objective classification methods as proposed by members of the computational symmetry community and machine learning proponents are briefly discussed in an appendix and are found to be wanting because they ignore Fedorov type pseudosymmetries completely. The information theory based methods are more accurate than visual classifications at first sight by most human experts.      
### 14.Cross-Modal Knowledge Transfer via Inter-Modal Translation and Alignment for Affect Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.00809.pdf)
>  Multi-modal affect recognition models leverage complementary information in different modalities to outperform their uni-modal counterparts. However, due to the unavailability of modality-specific sensors or data, multi-modal models may not be always employable. For this reason, we aim to improve the performance of uni-modal affect recognition models by transferring knowledge from a better-performing (or stronger) modality to a weaker modality during training. Our proposed multi-modal training framework for cross-modal knowledge transfer relies on two main steps. First, an encoder-classifier model creates task-specific representations for the stronger modality. Then, cross-modal translation generates multi-modal intermediate representations, which are also aligned in the latent space with the stronger modality representations. To exploit the contextual information in temporal sequential affect data, we use Bi-GRU and transformer encoder. We validate our approach on two multi-modal affect datasets, namely CMU-MOSI for binary sentiment classification and RECOLA for dimensional emotion regression. The results show that the proposed approach consistently improves the uni-modal test-time performance of the weaker modalities.      
### 15.Coalitional Control for Self-Organizing Agents  [ :arrow_down: ](https://arxiv.org/pdf/2108.00802.pdf)
>  Coalitional control is concerned with the management of multi-agent systems where cooperation cannot be taken for granted (due to, e.g., market competition, logistics). This paper proposes a model predictive control (MPC) framework aimed at large-scale dynamically-coupled systems whose individual components, possessing a limited model of the system, are controlled independently, pursuing possibly competing objectives. The emergence of cooperating clusters of controllers is contemplated through an autonomous negotiation protocol, based on the characterization as a coalitional game of the benefit derived by a broader feedback and the alignment of the individual objectives. Specific mechanisms for the cooperative benefit redistribution that relax the cognitive requirements of the game are employed to compensate for possible local cost increases due to cooperation. As a result, the structure of the overall MPC feedback can be adapted online to the degree of interaction between different parts of the system, while satisfying the individual interests of the agents. A wide-area control application for the power grid with the objective of minimizing frequency deviations and undesired inter-area power transfers is used as study case.      
### 16.Bite-Weight Estimation Using Commercial Ear Buds  [ :arrow_down: ](https://arxiv.org/pdf/2108.00771.pdf)
>  While automatic tracking and measuring of our physical activity is a well established domain, not only in research but also in commercial products and every-day life-style, automatic measurement of eating behavior is significantly more limited. Despite the abundance of methods and algorithms that are available in bibliography, commercial solutions are mostly limited to digital logging applications for smart-phones. One factor that limits the adoption of such solutions is that they usually require specialized hardware or sensors. Based on this, we evaluate the potential for estimating the weight of consumed food (per bite) based only on the audio signal that is captured by commercial ear buds (Samsung Galaxy Buds). Specifically, we examine a combination of features (both audio and non-audio features) and trainable estimators (linear regression, support vector regression, and neural-network based estimators) and evaluate on an in-house dataset of 8 participants and 4 food types. Results indicate good potential for this approach: our best results yield mean absolute error of less than 1 g for 3 out of 4 food types when training food-specific models, and 2.1 g when training on all food types together, both of which improve over an existing literature approach.      
### 17.Self-Supervised Feature Learning of 1D Convolutional Neural Networks with Contrastive Loss Using In-Ear Microphone Audio for Eating Detection  [ :arrow_down: ](https://arxiv.org/pdf/2108.00769.pdf)
>  The importance of automated and objective monitoring of dietary behavior is becoming increasingly accepted. The advancements in sensor technology along with recent achievements in machine-learning--based signal-processing algorithms have enabled the development of dietary monitoring solutions that yield highly accurate results. A common bottleneck for developing and training machine learning algorithms is obtaining labeled data for training supervised algorithms, and in particular ground truth annotations. Manual ground truth annotation is laborious, cumbersome, can sometimes introduce errors, and is sometimes impossible in free-living data collection. As a result, there is a need to decrease the labeled data required for training. Additionally, unlabeled data, gathered in-the-wild from existing wearables (such as Bluetooth earbuds) can be used to train and fine-tune eating-detection models. In this work, we focus on training a feature extractor for audio signals captured by an in-ear microphone for the task of eating detection in a self-supervised way. We base our approach on the SimCLR method for image classification, proposed by Chen et al. from the domain of computer vision. Results are promising as our self-supervised method achieves similar results to supervised training alternatives, and its overall effectiveness is comparable to current state-of-the-art methods. Code is available at \url{<a class="link-external link-https" href="https://github.com/mug-auth/ssl-chewing" rel="external noopener nofollow">this https URL</a>}.      
### 18.Complexity of the LTI system trajectory boundedness problem  [ :arrow_down: ](https://arxiv.org/pdf/2108.00728.pdf)
>  We study the algorithmic complexity of the problem of deciding whether a Linear Time Invariant dynamical system has bounded trajectories. Despite its ubiquitous and elementary nature in Systems and Control, it turns out that this question is quite intricate, and, to the best of our knowledge, unsolved in the literature. We show that classical tools, such as Gaussian Elimination, the Routh--Hurwitz Criterion, and the Euclidean Algorithm for GCD of polynomials indeed allow for an algorithm that is polynomial in the bit size of the instance. However, all these tools have to be implemented with care, and in a non-standard way, which relies on an advanced analysis.      
### 19.N-Step Nonblocking Supervisory Control of Discrete-Event Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.00721.pdf)
>  In this paper, we propose a new automaton property of N-step nonblockingness for a given positive integer N. This property quantifies the standard nonblocking property by capturing the practical requirement that all tasks be completed within a bounded number of steps. Accordingly, we formulate a new N-step nonblocking supervisory control problem, and characterize its solvability in terms of a new concept of N-step language completability. It is proved that there exists a unique supremal N-step completable sublanguage of a given language, and we develop a generator-based algorithm to compute the supremal sublanguage. Finally, together with the supremal controllable sublanguage, we design an algorithm to compute a maximally permissive supervisory control solution to the new N-step nonblocking supervisory control problem.      
### 20.Cohort Bias Adaptation in Aggregated Datasets for Lesion Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2108.00713.pdf)
>  Many automatic machine learning models developed for focal pathology (e.g. lesions, tumours) detection and segmentation perform well, but do not generalize as well to new patient cohorts, impeding their widespread adoption into real clinical contexts. One strategy to create a more diverse, generalizable training set is to naively pool datasets from different cohorts. Surprisingly, training on this \it{big data} does not necessarily increase, and may even reduce, overall performance and model generalizability, due to the existence of cohort biases that affect label distributions. In this paper, we propose a generalized affine conditioning framework to learn and account for cohort biases across multi-source datasets, which we call Source-Conditioned Instance Normalization (SCIN). Through extensive experimentation on three different, large scale, multi-scanner, multi-centre Multiple Sclerosis (MS) clinical trial MRI datasets, we show that our cohort bias adaptation method (1) improves performance of the network on pooled datasets relative to naively pooling datasets and (2) can quickly adapt to a new cohort by fine-tuning the instance normalization parameters, thus learning the new cohort bias with only 10 labelled samples.      
### 21.Local Diversity and Ultra-Reliable Antenna Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2108.00712.pdf)
>  Ultra-reliable low-latency communication enables new use cases for mobile radio networks. The ultra-reliability (UR) regime covers outage probabilities between $10^{-9}$ and $10^{-5}$, obtained under stringent latency requirements. Characterisation of the UR-relevant statistics is difficult due to the rare nature of outage events, but diversity defines the asymptotic behaviour of the small-scale fading distributions' lower tail. The UR-relevant regime in large-scale antenna systems behaves differently from the tail. The generalising local diversity at a certain outage probability shows this difference clearly. For more than four independent antenna elements, the classic diversity overestimates and underestimates the slope of the cumulative density function for weak and strong deterministic channel components, respectively.      
### 22.Zonotope-based Controller Synthesis for LTL Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2108.00704.pdf)
>  This paper studies the controller synthesis problem for Linear Temporal Logic (LTL) specifications using (constrained) zonotope techniques. To begin with, we implement (constrained) zonotope techniques to partition the state space and further to verify whether the LTL specification can be satisfied. Once the LTL specification can be satisfied, the next step is to design a controller to guarantee the satisfaction of the LTL specification for dynamic systems. Based on the verification of the LTL specification, an abstraction-based control design approach is proposed in this paper: a novel abstraction construction is developed first, then finite local abstract controllers are designed to achieve the LTL specification, and finally the designed abstract controllers are combined and refined as the controller for the original system. The proposed control design strategy is illustrated via a numerical example from autonomous robots.      
### 23.Nonlinear Controller Design with Prediction Horizon Time Reduction Applied to Unstable CSTR System  [ :arrow_down: ](https://arxiv.org/pdf/2108.00689.pdf)
>  Ensuring nominal asymptotic stability of the Nonlinear Model Predictive Control controller is not trivial. Stabilizing ingredients such as terminal penalty term and terminal region are crucial in establishing the asymptotic stability. Current work presents alternate approaches namely arbitrary controller based approach and linear quadratic regulator based approach, which provide larger degrees of freedom for enlarging the terminal region as against conservative approaches from the literature. Efficacy of the proposed approaches is demonstrated using benchmark two state continuous stirrer tank reactor system around an unstable operating point. Terminal regions obtained using the arbitrary controller based approach and linear quadratic regulator based approach are approximately 45 and 412 times larger by area measure when compared to the largest terminal region obtained using the approach from the literature. As a result, there is significant reduction in the prediction and control horizon time.      
### 24.Energy-efficient Blood Pressure Monitoring based on Single-site Photoplethysmogram on Wearable Devices  [ :arrow_down: ](https://arxiv.org/pdf/2108.00672.pdf)
>  The paper proposes accurate Blood Pressure Monitoring (BPM) based on a single-site Photoplethysmographic (PPG) sensor and provides an energy-efficient solution on edge cuffless wearable devices. Continuous PPG signal preprocessed and used as input of the Artificial Neural Network (ANN), and outputs systolic BP (SBP), diastolic BP (DBP), and mean arterial BP (MAP) values for each heartbeat. The improvement of the BPM accuracy is obtained by removing outliers in the preprocessing step and the whole-based inputs compared to parameter-based inputs extracted from the PPG signal. Performance obtained is $3.42 \pm 5.42$ mmHg (MAE $\pm$ RMSD) for SBP, $1.92 \pm 3.29$ mmHg for DBP, and $2.21 \pm 3.50$ mmHg for MAP which is competitive compared to other studies. This is the first BPM solution with edge computing artificial intelligence as we have learned so far. Evaluation experiments on real hardware show that the solution takes 42.2 ms, 18.2 KB RAM, and 2.1 mJ average energy per reading.      
### 25.Bespoke Fractal Sampling Patterns for Discrete Fourier Space via the Kaleidoscope Transform  [ :arrow_down: ](https://arxiv.org/pdf/2108.00639.pdf)
>  Sampling strategies are important for sparse imaging methodologies, especially those employing the discrete Fourier transform (DFT). Chaotic sensing is one such methodology that employs deterministic, fractal sampling in conjunction with finite, iterative reconstruction schemes to form an image from limited samples. Using a sampling pattern constructed entirely from periodic lines in DFT space, chaotic sensing was found to outperform traditional compressed sensing for magnetic resonance imaging; however, only one such sampling pattern was presented and the reason for its fractal nature was not proven. Through the introduction of a novel image transform known as the kaleidoscope transform, which formalises and extends upon the concept of downsampling and concatenating an image with itself, this paper: (1) demonstrates a fundamental relationship between multiplication in modular arithmetic and downsampling; (2) provides a rigorous mathematical explanation for the fractal nature of the sampling pattern in the DFT; and (3) leverages this understanding to develop a collection of novel fractal sampling patterns for the 2D DFT with customisable properties. The ability to design tailor-made fractal sampling patterns expands the utility of the DFT in chaotic imaging and may form the basis for a bespoke chaotic sensing methodology, in which the fractal sampling matches the imaging task for improved reconstruction.      
### 26.Quantum Scheduling for Millimeter-Wave Observation Satellite Constellation  [ :arrow_down: ](https://arxiv.org/pdf/2108.00626.pdf)
>  In beyond 5G and 6G network scenarios, the use of satellites has been actively discussed for extending target monitoring areas, even for extreme circumstances, where the monitoring functionalities can be realized due to the usage of millimeter-wave wireless links. This paper designs an efficient scheduling algorithm which minimizes overlapping monitoring areas among observation satellite constellation. In order to achieve this objective, a quantum optimization based algorithm is used because the overlapping can be mathematically modelled via a max-weight independent set (MWIS) problem which is one of well-known NP-hard problems.      
### 27.Data-driven Clustering in Ad-hoc Networks based on Community Detection  [ :arrow_down: ](https://arxiv.org/pdf/2108.00600.pdf)
>  High demands for industrial networks lead to increasingly large sensor networks. However, the complexity of networks and demands for accurate data require better stability and communication quality. Conventional clustering methods for ad-hoc networks are based on topology and connectivity, leading to unstable clustering results and low communication quality. In this paper, we focus on two situations: time-evolving networks, and multi-channel ad-hoc networks. We model ad-hoc networks as graphs and introduce community detection methods to both situations. Particularly, in time-evolving networks, our method utilizes the results of community detection to ensure stability. By using similarity or human-in-the-loop measures, we construct a new weighted graph for final clustering. In multi-channel networks, we perform allocations from the results of multiplex community detection. Experiments on real-world datasets show that our method outperforms baselines in both stability and quality.      
### 28.Synthetic Active Distribution System Generation via Unbalanced Graph Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2108.00599.pdf)
>  Real active distribution networks with associated smart meter (SM) data are critical for power researchers. However, it is practically difficult for researchers to obtain such comprehensive datasets from utilities due to privacy concerns. To bridge this gap, an implicit generative model with Wasserstein GAN objectives, namely unbalanced graph generative adversarial network (UG-GAN), is designed to generate synthetic three-phase unbalanced active distribution system connectivity. The basic idea is to learn the distribution of random walks both over a real-world system and across each phase of line segments, capturing the underlying local properties of an individual real-world distribution network and generating specific synthetic networks accordingly. Then, to create a comprehensive synthetic test case, a network correction and extension process is proposed to obtain time-series nodal demands and standard distribution grid components with realistic parameters, including distributed energy resources (DERs) and capacity banks. A Midwest distribution system with 1-year SM data has been utilized to validate the performance of our method. Case studies with several power applications demonstrate that synthetic active networks generated by the proposed framework can mimic almost all features of real-world networks while avoiding the disclosure of confidential information.      
### 29.Frequency support Scheme based on parametrized power curve for de-loaded Wind Turbine under various wind speed  [ :arrow_down: ](https://arxiv.org/pdf/2108.00589.pdf)
>  With increased wind power penetration in modern power systems, wind plants are required to provide frequency support similar to conventional plants. However, for the existing frequency regulation scheme of wind turbines, the control gains in the auxiliary frequency controller are difficult to set because of the compromise of the frequency regulation performance and the stable operation of wind turbines, especially when the wind speed remains variable. This paper proposes a novel frequency regulation scheme (FRS) for de-loaded wind turbines. Instead of an auxiliary frequency controller, frequency support is provided by modifying the parametrized power versus rotor speed curve, including the inertia power versus rotor speed curve and the droop power versus rotor speed curve. The advantage of the proposed scheme is that it does not contain any control gains and generally adapts to different wind speeds. Further, the proposed scheme can work for the whole section of wind speed without wind speed measurement information. The compared simulation results demonstrate the scheme improves the system frequency response while ensuring the stable operation of doubly-fed induction generators (DFIGs)-based variable-speed wind turbines (VSWTs) under various wind conditions. Furthermore, the scheme prevents rotor speed overdeceleration even when the wind speed decreases during frequency regulation control.      
### 30.High-resolution chirplet transform: from parameters analysis to parameters combination  [ :arrow_down: ](https://arxiv.org/pdf/2108.00572.pdf)
>  The standard chirplet transform (CT) with a chirp-modulated Gaussian window provides a valuable tool for analyzing linear chirp signals. The parameters present in the window determine the performance of CT and play a very important role in high-resolution time-frequency (TF) analysis. In this paper, we first give the window shape analysis of CT and compare it with the extension that employs a rotating Gaussian window by fractional Fourier transform. The given parameters analysis provides certain theoretical guidance for developing high-resolution CT. We then propose a multi-resolution chirplet transform (MrCT) by combining multiple CTs with different parameter combinations. These are combined geometrically to obtain an improved TF resolution by overcoming the limitations of any single representation of the CT. By deriving the combined instantaneous frequency equation, we further develop a high-concentration TF post-processing approach to improve the readability of the MrCT. Numerical experiments on simulated and real signals verify its effectiveness.      
### 31.Fuzzy-based Higher Adaptive Order Sliding Mode Observers  [ :arrow_down: ](https://arxiv.org/pdf/2108.00541.pdf)
>  In this article, I introduce the notion of Fuzzy-based Higher adaptive order sliding mode observers through the example of the super-twisting adaptive order sliding mode observer. I begin by presenting the super-twisting second order sliding mode observer for systems in triangular form. Then I replace the sign functions with fuzzy inference systems in order to eliminate the chattering effect. I then show that this variant of the super-twisting second order sliding mode observer may not converge depending on the input, so I replace the square root with an adaptive power $\gamma$. The efficiency of the proposed method is illustrated by simulations made on MATLAB/Simulink.      
### 32.Green Hydrogen Plant: Optimal control strategies for integrated hydrogen storage and power generation with wind energy  [ :arrow_down: ](https://arxiv.org/pdf/2108.00530.pdf)
>  The intermittent nature of renewable energy resources such as wind and solar causes the energy supply to be less predictable leading to possible mismatches in the power network. To this end, hydrogen production and storage can provide a solution by increasing flexibility within the system. Stored hydrogen can either be converted back to electricity or it can be used as feed-stock for industry, heating for built environment, and as fuel for vehicles. This research examines the optimal strategies for operating integrated energy systems consisting of renewable energy production and hydrogen storage. Using Markov decision process theory, we construct optimal policies for day-to-day decisions on how much energy to store as hydrogen, or buy from or sell to the electricity market, and on how much hydrogen to sell for use as gas. We pay special emphasis to practical settings, such as contractually binding power purchase agreements, varying electricity prices, different distribution channels, green hydrogen offtake agreements, and hydrogen market price uncertainties. Extensive experiments and analysis are performed in the context of Northern Netherlands where Europe's first Hydrogen Valley is being formed. Results show that substantial gains in operational revenues of up to 51\% are possible by introducing hydrogen storage units and competitive hydrogen market-prices. This amounts to a \euro 126,000 increase in revenues per turbine per year for a 4.5 MW wind turbine. Moreover, our results indicate that hydrogen offtake agreements will be crucial in keeping the energy transition on track.      
### 33.Application of Tilt Correlation Statistics to Anisoplanatic Optical Turbulence Modeling and Mitigation  [ :arrow_down: ](https://arxiv.org/pdf/2108.00528.pdf)
>  Atmospheric optical turbulence can be a significant source of image degradation, particularly in long range imaging applications. Many turbulence mitigation algorithms rely on an optical transfer function (OTF) model that includes the Fried parameter. We present anisoplanatic tilt statistics for spherical wave propagation. We transform these into 2D autocorrelation functions that can inform turbulence modeling and mitigation algorithms. Using these, we construct an OTF model that accounts for image registration. We also propose a spectral-ratio Fried parameter estimation algorithm that is robust to camera motion and requires no specialized scene content or sources. We employ the Fried parameter estimation and OTF model for turbulence mitigation. A numerical wave-propagation turbulence simulator is used to generate data to quantitatively validate the proposed methods. Results with real camera data are also presented.      
### 34.A Scalable Federated Multi-agent Architecture for Networked Connected Communication Network  [ :arrow_down: ](https://arxiv.org/pdf/2108.00506.pdf)
>  Scalability is the key roadstone towards the application of cooperative intelligent algorithms in large-scale networks. Reinforcement learning (RL) is known as model-free and high efficient intelligent algorithm for communication problems and proved useful in the communication network. However, when coming to large-scale networks with limited centralization, it is not possible to employ a centralized entity to perform joint real-time decision making for entire network. This introduces the scalability challenges, while multi-agent reinforcement shows the opportunity to cope this challenges and extend the intelligent algorithm to cooperative large-scale network. In this paper, we introduce the federated mean-field multi-agent reinforcement learning structure to capture the problem in large scale multi-agent communication scenarios, where agents share parameters to form consistency. We present the theoretical basis of our architecture and show the influence of federated frequency with an informational multi-agent model. We then exam the performance of our architecture with a coordinated multi-point environment which requires handshakes between neighbour access-points to realise the cooperation gain. Our result shows that the learning structure can effectively solve the cooperation problem in a large scale network with decent scalability. We also show the effectiveness of federated algorithms and highlight the importance of maintaining personality in each access-point.      
### 35.A Track-Before-Detect Algorithm for UWB Radar Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.00501.pdf)
>  Precise localization and tracking of moving non-collaborative persons and objects using a network of ultra-wideband (UWB) radar nodes has been shown to represent a practical and effective approach. In UWB radar sensor networks (RSNs), existence of strong clutter, weak target echoes, and closely spaced targets are obstacles to achieving a satisfactory tracking performance. Using a track-before-detect (TBD) approach, the waveform obtained by each node during a time period are jointly processed. Both spatial information and temporal relationship between measurements are exploited in generating all possible candidate trajectories and only the best trajectories are selected as the outcome. The effectiveness of the developed TBD technique for UWB RSNs is confirmed by numerical simulations and by two experimental results, both carried out with actual UWB signals. In the first experiment, a human target is tracked by a monostatic radar network with an average localization error of 41.9 cm with no false alarm trajectory in a cluttered outdoor environment. In the second experiment, two targets are detected by multistatic radar network with localization errors of 25.4 cm and 19.7 cm, and detection rate of the two targets is 88.75%, and no false alarm trajectory.      
### 36.A Survey on Audio Synthesis and Audio-Visual Multimodal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2108.00443.pdf)
>  With the development of deep learning and artificial intelligence, audio synthesis has a pivotal role in the area of machine learning and shows strong applicability in the industry. Meanwhile, significant efforts have been dedicated by researchers to handle multimodal tasks at present such as audio-visual multimodal processing. In this paper, we conduct a survey on audio synthesis and audio-visual multimodal processing, which helps understand current research and future trends. This review focuses on text to speech(TTS), music generation and some tasks that combine visual and acoustic information. The corresponding technical methods are comprehensively classified and introduced, and their future development trends are prospected. This survey can provide some guidance for researchers who are interested in the areas like audio synthesis and audio-visual multimodal processing.      
### 37.Style Curriculum Learning for Robust Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2108.00402.pdf)
>  The performance of deep segmentation models often degrades due to distribution shifts in image intensities between the training and test data sets. This is particularly pronounced in multi-centre studies involving data acquired using multi-vendor scanners, with variations in acquisition protocols. It is challenging to address this degradation because the shift is often not known \textit{a priori} and hence difficult to model. We propose a novel framework to ensure robust segmentation in the presence of such distribution shifts. Our contribution is three-fold. First, inspired by the spirit of curriculum learning, we design a novel style curriculum to train the segmentation models using an easy-to-hard mode. A style transfer model with style fusion is employed to generate the curriculum samples. Gradually focusing on complex and adversarial style samples can significantly boost the robustness of the models. Second, instead of subjectively defining the curriculum complexity, we adopt an automated gradient manipulation method to control the hard and adversarial sample generation process. Third, we propose the Local Gradient Sign strategy to aggregate the gradient locally and stabilise training during gradient manipulation. The proposed framework can generalise to unknown distribution without using any target data. Extensive experiments on the public M\&amp;Ms Challenge dataset demonstrate that our proposed framework can generalise deep models well to unknown distributions and achieve significant improvements in segmentation accuracy.      
### 38.CNN based Channel Estimation using NOMA for mmWave Massive MIMO System  [ :arrow_down: ](https://arxiv.org/pdf/2108.00367.pdf)
>  Non-Orthogonal Multiple Access (NOMA) schemes are being actively explored to address some of the major challenges in 5th Generation (5G) Wireless communications. Channel estimation is exceptionally challenging in scenarios where NOMA schemes are integrated with millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems. An accurate estimation of the channel is essential in exploiting the benefits of the pairing of the duo-NOMA and mmWave. This paper proposes a convolutional neural network (CNN) based approach to estimate the channel for NOMA based millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems built on a hybrid architecture. Initially, users are grouped into different clusters based on their channel gains and beamforming technique is performed to maximize the signal in the direction of desired cluster. A coarse estimation of the channel is first made from the received signal and this estimate is given as the input to CNN to fine estimate the channel coefficients. Numerical illustrations show that the proposed method outperforms least square (LS) estimate, minimum mean square error (MMSE) estimate and are close to the Cramer-Rao Bound (CRB).      
### 39.UAV Trajectory Planning in Wireless Sensor Networks for Energy Consumption Minimization by Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.00354.pdf)
>  Unmanned aerial vehicles (UAVs) have emerged as a promising candidate solution for data collection of large-scale wireless sensor networks (WSNs). In this paper, we investigate a UAV-aided WSN, where cluster heads (CHs) receive data from their member nodes, and a UAV is dispatched to collect data from CHs along the planned trajectory. We aim to minimize the total energy consumption of the UAV-WSN system in a complete round of data collection. Toward this end, we formulate the energy consumption minimization problem as a constrained combinatorial optimization problem by jointly selecting CHs from nodes within clusters and planning the UAV's visiting order to the selected CHs. The formulated energy consumption minimization problem is NP-hard, and hence, hard to solve optimally. In order to tackle this challenge, we propose a novel deep reinforcement learning (DRL) technique, pointer network-A* (Ptr-A*), which can efficiently learn from experiences the UAV trajectory policy for minimizing the energy consumption. The UAV's start point and the WSN with a set of pre-determined clusters are fed into the Ptr-A*, and the Ptr-A* outputs a group of CHs and the visiting order to these CHs, i.e., the UAV's trajectory. The parameters of the Ptr-A* are trained on small-scale clusters problem instances for faster training by using the actor-critic algorithm in an unsupervised manner. At inference, three search strategies are also proposed to improve the quality of solutions. Simulation results show that the trained models based on 20-clusters and 40-clusters have a good generalization ability to solve the UAV's trajectory planning problem in WSNs with different numbers of clusters, without the need to retrain the models. Furthermore, the results show that our proposed DRL algorithm outperforms two baseline techniques.      
### 40.Practical Adoption of Cloud Computing in Power Systems: Drivers, Challenges, Guidance, and Real-world Use Cases  [ :arrow_down: ](https://arxiv.org/pdf/2108.00303.pdf)
>  Motivated by FERC's recent direction and ever-growing interest in cloud adoption by power utilities, a Task Force was established to assist power system practitioners with secure, reliable and cost-effective adoption of cloud technology to meet various business needs. This paper summarizes the business drivers, challenges, guidance, and best practices for cloud adoption in power systems from the Task Force's perspective, after extensive review and deliberation by its members that include grid operators, utility companies, software vendors and cloud providers. The paper begins by enumerating various business drivers for cloud adoption in the power industry. It follows with the discussion of challenges and risks of migrating power grid utility workloads to cloud. Next for each corresponding challenge or risk, the paper provides appropriate guidance. Importantly, the guidance is directed toward power industry professionals who are considering cloud solutions and are yet hesitant about the practical execution. Finally, to tie all the sections together, the paper documents various real-world use cases of cloud technology in the power system domain, which both the power industry practitioners and software vendors can look forward to design and select their own future cloud solutions. We hope that the information in this paper will serve as useful guidance for the development of NERC guidelines and standards relevant to cloud adoption in the industry.      
### 41.Modeling and Design of IRS-Assisted Multi-Link FSO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.00291.pdf)
>  In this paper, we investigate the modeling and design of intelligent reflecting surface (IRS)-assisted optical communication systems which are deployed to relax the line-of-sight (LOS) requirement in multi-link free space optical (FSO) systems. The FSO laser beams incident on the optical IRSs have a Gaussian power intensity profile and a nonlinear phase profile, whereas the plane waves in radio frequency (RF) systems have a uniform power intensity profile and a linear phase profile. Given these substantial differences, the results available for IRS-assisted RF systems are not applicable to IRS-assisted FSO systems. Therefore, we develop a new analytical channel model for point-to-point IRS-assisted FSO systems based on the Huygens-Fresnel principle. Our analytical model captures the impact of the size, position, and orientation of the IRS as well as its phase shift profile on the end-to-end channel. To allow the sharing of the optical IRS by multiple FSO links, we propose three different protocols, namely the time division (TD), IRS-division (IRSD), and IRS homogenization (IRSH) protocols. The proposed protocols address the specific characteristics of FSO systems including the non-uniformity and possible misalignment of the laser beams. Furthermore, to compare the proposed IRS sharing protocols, we analyze the bit error rate (BER) and the outage probability of IRS-assisted multi-link FSO systems in the presence of inter-link interference. Our simulation results validate the accuracy of the proposed analytical channel model for IRS-assisted FSO systems and confirm that this model is applicable for both large and intermediate IRS-receiver lens distances. Moreover, in the absence of misalignment errors, the IRSD protocol outperforms the other protocols, whereas in the presence of misalignment errors, the IRSH protocol performs significantly better than the IRSD protocol.      
### 42.An Intelligent Energy Management Framework for Hybrid-Electric Propulsion Systems Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.00256.pdf)
>  Hybrid-electric propulsion systems powered by clean energy derived from renewable sources offer a promising approach to decarbonise the world's transportation systems. Effective energy management systems are critical for such systems to achieve optimised operational performance. However, developing an intelligent energy management system for applications such as ships operating in a highly stochastic environment and requiring concurrent control over multiple power sources presents challenges. This article proposes an intelligent energy management framework for hybrid-electric propulsion systems using deep reinforcement learning. In the proposed framework, a Twin-Delayed Deep Deterministic Policy Gradient agent is trained using an extensive volume of historical load profiles to generate a generic energy management strategy. The strategy, i.e. the core of the energy management system, can concurrently control multiple power sources in continuous state and action spaces. The proposed framework is applied to a coastal ferry model with multiple fuel cell clusters and a battery, achieving near-optimal cost performance when applied to novel future voyages.      
### 43.Single-Channel EEG Based Arousal Level Estimation Using Multitaper Spectrum Estimation at Low-Power Wearable Devices  [ :arrow_down: ](https://arxiv.org/pdf/2108.00216.pdf)
>  This paper proposes a novel lightweight method using the multitaper power spectrum to estimate arousal levels at wearable devices. We show that the spectral slope (1/f) of the electrophysiological power spectrum reflects the scale-free neural activity. To evaluate the proposed feature's performance, we used scalp EEG recorded during anesthesia and sleep with technician-scored Hypnogram annotations. It is shown that the proposed methodology discriminates wakefulness from reduced arousal solely based on the neurophysiological brain state with more than 80% accuracy. Therefore, our findings describe a common electrophysiological marker that tracks reduced arousal states, which can be applied to different applications (e.g., emotion detection, driver drowsiness). Evaluation on hardware shows that the proposed methodology can be implemented for devices with a minimum RAM of 512 KB with 55 mJ average energy consumption.      
### 44.Performance assessment and tuning of PID control using TLBO: the single-loop case and PI/P cascade case  [ :arrow_down: ](https://arxiv.org/pdf/2108.00184.pdf)
>  Proportional-integral-derivative (PID) control, the most common control strategy in the industry, always suffers from health problems resulting from external disturbances, improper tuning, etc. Therefore, there have been many studies on control performance assessment (CPA) and optimal tuning. Minimum output variance (MOV) is used as a benchmark for CPA of PID, but it is difficult to be found due to the associated non-convex optimization problem. For the optimal tuning, many different objective functions have been proposed, but few consider the stochastic disturbance rejection. In this paper, a multi-objective function simultaneously considering integral of absolute error (IAE) and MOV is proposed to optimize PID for better disturbance rejection. The non-convex problem and multi-objective problem are solved by teaching-learning-based optimization (TLBO). This stochastic optimization algorithm can guarantee a tighter lower bound for MOV due to the excellent capability of local optima avoidance and needs less calculation time due to the low complexity. Furthermore, CPA and the tuning method are extended to the PI/P cascade case. The results of several numerical examples of CPA problems show that TLBO can generate better MOV than existing methods within one second on most examples. The simulation results of the tuning method applied to two temperature control systems reveal that the weight of the multi-objective function can compromise other performance criteria such as overshoot and settling time to improve the disturbance rejection. It also indicates that the tuning method can be utilized to multi-stage PID control strategy to resolve the contradiction between disturbance rejection and other performance criteria.      
### 45.Understanding the merging behavior patterns and evolutionary mechanism at freeway on-ramps  [ :arrow_down: ](https://arxiv.org/pdf/2108.00178.pdf)
>  Understanding the merging behavior patterns at freeway on-ramps is important for assistanting the decisions of autonomous driving. This study develops a primitive-based framework to identify the driving patterns during merging processes and reveal the evolutionary mechanism at freeway on-ramps in congested traffic flow. The Nonhomogeneous Hidden Markov Model is introduced to decompose the merging processes into primitives containing semantic information. Then, the time-series K-means clustering is utilized to gather these primitives with variable-length time series into interpretable merging behavior patterns. Different from traditional state segmentation methods (e.g. Hidden Markov Model), the model proposed in this study considers the dependence of transition probability on exogenous variables, thereby revealing the influence of covariates on the evolution of driving patterns. This approach is evaluated in the merging area at a freeway on-ramp using the INTERACTION dataset. Results demonstrate that the approach provides an insight about the complicated merging processes. The findings about interpretable merging behavior patterns as well as the evolutionary mechanism can be used to design and improve the merging decision-making for autonomous vehicles.      
### 46.Dynamic Virtual Power Plant: A New Concept for Grid Integration of Renewable Energy Sources  [ :arrow_down: ](https://arxiv.org/pdf/2108.00153.pdf)
>  The notion of Virtual Power Plant (VPP) has been used many times in last years in power systems and for several reasons. As a general trend, the behavior of a classic synchronous generator is to be emulated for a class of conventional grid components like, e.g., renewable generators or/and power electronic units. Most of the times production of these units is of interest, as it is the case for the new AGC scheme of Spain which, from this point of view, looks like a VPP. However, dynamic aspects are of high importance, especially for increasing the actual rate of penetration of Renewable Energy Sources (RES). Indeed, to go above the actual rate of RES penetration, one should deal with full participation of RES to grid services. For that, we propose here a new concept called Dynamic VPP (DVPP) which fully integrates the dynamic aspects at all levels: locally (for each RES generator), globally (for grid ancillary services and interaction with other neighbor elements of the grid) and economically (for internal optimal dispatch and participation to electricity markets). A DVPP is a set of RES along with a set of control and operation procedures. This means methodologies for: choosing the participating RES, optimal and continuous operation as a whole (especially in case of loss of natural resources - e.g., wind, sun - on a part of the DVPP), regulation (in the dynamic sense) to ensure local objectives for each generator, participation to ancillary services of the DVPP as a unit and to diminish negative effects of interaction with neighbor dynamics elements of the power system, integration in both actual power systems scenarios (with mixed classic and power electronics based generation) and future ones with high degree of RES penetration.      
### 47.A Machine-learning Based Initialization for Joint Statistical Iterative Dual-energy CT with Application to Proton Therapy  [ :arrow_down: ](https://arxiv.org/pdf/2108.00109.pdf)
>  Dual-energy CT (DECT) has been widely investigated to generate more informative and more accurate images in the past decades. For example, Dual-Energy Alternating Minimization (DEAM) algorithm achieves sub-percentage uncertainty in estimating proton stopping-power mappings from experimental 3-mm collimated phantom data. However, elapsed time of iterative DECT algorithms is not clinically acceptable, due to their low convergence rate and the tremendous geometry of modern helical CT scanners. A CNN-based initialization method is introduced to reduce the computational time of iterative DECT algorithms. DEAM is used as an example of iterative DECT algorithms in this work. The simulation results show that our method generates denoised images with greatly improved estimation accuracy for adipose, tonsils, and muscle tissue. Also, it reduces elapsed time by approximately 5-fold for DEAM to reach the same objective function value for both simulated and real data.      
### 48.Thermal Image Super-Resolution Using Second-Order Channel Attention with Varying Receptive Fields  [ :arrow_down: ](https://arxiv.org/pdf/2108.00094.pdf)
>  Thermal images model the long-infrared range of the electromagnetic spectrum and provide meaningful information even when there is no visible illumination. Yet, unlike imagery that represents radiation from the visible continuum, infrared images are inherently low-resolution due to hardware constraints. The restoration of thermal images is critical for applications that involve safety, search and rescue, and military operations. In this paper, we introduce a system to efficiently reconstruct thermal images. Specifically, we explore how to effectively attend to contrasting receptive fields (RFs) where increasing the RFs of a network can be computationally expensive. For this purpose, we introduce a deep attention to varying receptive fields network (AVRFN). We supply a gated convolutional layer with higher-order information extracted from disparate RFs, whereby an RF is parameterized by a dilation rate. In this way, the dilation rate can be tuned to use fewer parameters thus increasing the efficacy of AVRFN. Our experimental results show an improvement over the state of the art when compared against competing thermal image super-resolution methods.      
### 49.Interruption flows for reliability evaluation of power distribution networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.00058.pdf)
>  Energy networks should strive for reliability. How can it be assessed, measured, and improved? What are the best trade-offs between investments and their worth? The flow-based framework for the reliability assessment of energy networks proposed in this paper addresses these questions with a focus on power distribution networks. The framework introduces the concept of iflows, or interruption flows, which translate the analytical reliability evaluation into solving a series of node balance equations computable in linear time. The iflows permeate the network, providing relevant information to support linear formulations of reliability optimization problems. Numerical examples showcase the evaluation process obtained through iflows in illustrative distribution networks with distributed generation. A visual representation of the reliability state provides insights into the most critical regions of the network. A case study of the optimal allocation of switches in power distribution systems is described. Computational experiments were conducted using a benchmark of distribution networks, having up to 881 nodes. The results confirm the effectiveness of the approach in terms of providing high-quality information and optimal trade-offs to aid reliability decisions for energy networks.      
### 50.A Multi-Period Water Network Planning for Industrial Parks; Impact of Design Periods on Park's Flexibility  [ :arrow_down: ](https://arxiv.org/pdf/2108.01047.pdf)
>  The central goal of this study is to advance the state-of-the-art in the field of water network management for industrial ecologies. Considering the global water shortage and environmental regulations, the reduction of water consumption has become a necessity within the industrial sector. To find the optimal water management strategies in an eco-industrial park (EIP), a refined superstructure is proposed. An MINLP mathematical model is then developed, based on the superstructure, to synthesize water and wastewater streams within the network, including nearby companies. Surveying two case studies, each studied in two different scenarios, showed that the cost objective functions deteriorates with increase in number of design periods. Results also provide some evidence of a trade-off between water network flexibility and performance, and vice versa.      
### 51.Musical Speech: A Transformer-based Composition Tool  [ :arrow_down: ](https://arxiv.org/pdf/2108.01043.pdf)
>  In this paper, we propose a new compositional tool that will generate a musical outline of speech recorded/provided by the user for use as a musical building block in their compositions. The tool allows any user to use their own speech to generate musical material, while still being able to hear the direct connection between their recorded speech and the resulting music. The tool is built on our proposed pipeline. This pipeline begins with speech-based signal processing, after which some simple musical heuristics are applied, and finally these pre-processed signals are passed through Transformer models trained on new musical tasks. We illustrate the effectiveness of our pipeline -- which does not require a paired dataset for training -- through examples of music created by musicians making use of our tool.      
### 52.Bringing AI pipelines onto cloud-HPC: setting a baseline for accuracy of COVID-19 AI diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2108.01033.pdf)
>  HPC is an enabling platform for AI. The introduction of AI workloads in the HPC applications basket has non-trivial consequences both on the way of designing AI applications and on the way of providing HPC computing. This is the leitmotif of the convergence between HPC and AI. The formalized definition of AI pipelines is one of the milestones of HPC-AI convergence. If well conducted, it allows, on the one hand, to obtain portable and scalable applications. On the other hand, it is crucial for the reproducibility of scientific pipelines. In this work, we advocate the StreamFlow Workflow Management System as a crucial ingredient to define a parametric pipeline, called "CLAIRE COVID-19 Universal Pipeline," which is able to explore the optimization space of methods to classify COVID-19 lung lesions from CT scans, compare them for accuracy, and therefore set a performance baseline. The universal pipeline automatizes the training of many different Deep Neural Networks (DNNs) and many different hyperparameters. It, therefore, requires a massive computing power, which is found in traditional HPC infrastructure thanks to the portability-by-design of pipelines designed with StreamFlow. Using the universal pipeline, we identified a DNN reaching over 90% accuracy in detecting COVID-19 lesions in CT scans.      
### 53.Neuromechanical model-based control of bi-lateral ankle exoskeletons: biological joint torque and electromyogram reduction across walking conditions  [ :arrow_down: ](https://arxiv.org/pdf/2108.00980.pdf)
>  To enable the broad adoption of wearable robotic exoskeletons in medical and industrial settings, it is crucial they can effectively support large repertoires of movements. We propose a new human-machine interface to drive bilateral ankle exoskeletons during a range of 'unseen' walking conditions that were not used for establishing the control interface. The proposed approach uses person-specific neuromechanical models of the human body to estimate biological ankle torques in real-time from electromyograms (EMGS) and joint angles. A low-level controller based on a disturbance observer translates biological torque estimates into exoskeleton commands. We call this 'neuromechanical model-based control' (NMBC). NMBC enabled five individuals to voluntarily control exoskeletons across two walking speeds performed at three ground elevations with no need for predefined torque profiles, nor a prior chosen neuromuscular reflex rules, or state machines as common in literature. Furthermore, a single subject case study was carried out on a dexterous moonwalk task, showing reduction in muscular effort. NMBC enabled reducing biological ankle torques as well as eight ankle muscle EMGs both within (22% for the torque; 13% for the EMG) and between walking conditions (22% for the torque; 13% for the EMG) when compared to non-assisted conditions. Torque and EMG reduction in novel walking conditions indicated the exoskeleton operated symbiotically as an exomuscle controlled by the operator's neuromuscular system. This will open new avenues for systematic adoption of wearable robots in out-of-the-lab medical and occupational settings.      
### 54.An Applied Deep Learning Approach for Estimating Soybean Relative Maturity from UAV Imagery to Aid Plant Breeding Decisions  [ :arrow_down: ](https://arxiv.org/pdf/2108.00952.pdf)
>  For a global breeding organization, identifying the next generation of superior crops is vital for its success. Recognizing new genetic varieties requires years of in-field testing to gather data about the crop's yield, pest resistance, heat resistance, etc. At the conclusion of the growing season, organizations need to determine which varieties will be advanced to the next growing season (or sold to farmers) and which ones will be discarded from the candidate pool. Specifically for soybeans, identifying their relative maturity is a vital piece of information used for advancement decisions. However, this trait needs to be physically observed, and there are resource limitations (time, money, etc.) that bottleneck the data collection process. To combat this, breeding organizations are moving toward advanced image capturing devices. In this paper, we develop a robust and automatic approach for estimating the relative maturity of soybeans using a time series of UAV images. An end-to-end hybrid model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed to extract features and capture the sequential behavior of time series data. The proposed deep learning model was tested on six different environments across the United States. Results suggest the effectiveness of our proposed CNN-LSTM model compared to the local regression method. Furthermore, we demonstrate how this newfound information can be used to aid in plant breeding advancement decisions.      
### 55.Aerial Vehicles Tracking Using Noncoherent Crowdsourced Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.00922.pdf)
>  Air traffic management (ATM) of manned and unmanned aerial vehicles (AVs) relies critically on ubiquitous location tracking. While technologies exist for AVs to broadcast their location periodically and for airports to track and detect AVs, methods to verify the broadcast locations and complement the ATM coverage are urgently needed, addressing anti-spoofing and safe coexistence concerns. In this work, we propose an ATM solution by exploiting noncoherent crowdsourced wireless networks (CWNs) and correcting the inherent clock-synchronization problems present in such non-coordinated sensor networks. While CWNs can provide a great number of measurements for ubiquitous ATM, these are normally obtained from unsynchronized sensors. This article first presents an analysis of the effects of lack of clock synchronization in ATM with CWN and provides solutions based on the presence of few trustworthy sensors in a large non-coordinated network. Secondly, autoregressive-based and long short-term memory (LSTM)-based approaches are investigated to achieve the time synchronization needed for localization of the AVs. Finally, a combination of a multilateration (MLAT) method and a Kalman filter is employed to provide an anti-spoofing tracking solution for AVs. We demonstrate the performance advantages of our framework through a dataset collected by a real-world CWN. Our results show that the proposed framework achieves localization accuracy comparable to that acquired using only GPS-synchronized sensors and outperforms the localization accuracy obtained based on state-of-the-art CWN synchronization methods.      
### 56.Communication-Efficient Federated Learning via Predictive Coding  [ :arrow_down: ](https://arxiv.org/pdf/2108.00918.pdf)
>  Federated learning can enable remote workers to collaboratively train a shared machine learning model while allowing training data to be kept locally. In the use case of wireless mobile devices, the communication overhead is a critical bottleneck due to limited power and bandwidth. Prior work has utilized various data compression tools such as quantization and sparsification to reduce the overhead. In this paper, we propose a predictive coding based communication scheme for federated learning. The scheme has shared prediction functions among all devices and allows each worker to transmit a compressed residual vector derived from the reference. In each communication round, we select the predictor and quantizer based on the rate-distortion cost, and further reduce the redundancy with entropy coding. Extensive simulations reveal that the communication cost can be reduced up to 99% with even better learning performance when compared with other baseline methods.      
### 57.Indexability and Rollout Policy for Multi-State Partially Observable Restless Bandits  [ :arrow_down: ](https://arxiv.org/pdf/2108.00892.pdf)
>  Restless multi-armed bandits with partially observable states has applications in communication systems, age of information and recommendation systems. In this paper, we study multi-state partially observable restless bandit models. We consider three different models based on information observable to decision maker -- 1) no information is observable from actions of a bandit 2) perfect information from bandit is observable only for one action on bandit, there is a fixed restart state, i.e., transition occurs from all other states to that state 3) perfect state information is available to decision maker for both actions on a bandit and there are two restart state for two actions. We develop the structural properties. We also show a threshold type policy and indexability for model 2 and 3. We present Monte Carlo (MC) rollout policy. We use it for whittle index computation in case of model 2. We obtain the concentration bound on value function in terms of horizon length and number of trajectories for MC rollout policy. We derive explicit index formula for model 3. We finally describe Monte Carlo rollout policy for model 1 when it is difficult to show indexability. We demonstrate the numerical examples using myopic policy, Monte Carlo rollout policy and Whittle index policy. We observe that Monte Carlo rollout policy is good competitive policy to myopic.      
### 58.Domain Adaptation for Autoencoder-Based End-to-End Communication Over Wireless Channels  [ :arrow_down: ](https://arxiv.org/pdf/2108.00874.pdf)
>  The problem of domain adaptation conventionally considers the setting where a source domain has plenty of labeled data, and a target domain (with a different data distribution) has plenty of unlabeled data but none or very limited labeled data. In this paper, we address the setting where the target domain has only limited labeled data from a distribution that is expected to change frequently. We first propose a fast and light-weight method for adapting a Gaussian mixture density network (MDN) using only a small set of target domain samples. This method is well-suited for the setting where the distribution of target data changes rapidly (e.g., a wireless channel), making it challenging to collect a large number of samples and retrain. We then apply the proposed MDN adaptation method to the problem of end-of-end learning of a wireless communication autoencoder. A communication autoencoder models the encoder, decoder, and the channel using neural networks, and learns them jointly to minimize the overall decoding error rate. However, the error rate of an autoencoder trained on a particular (source) channel distribution can degrade as the channel distribution changes frequently, not allowing enough time for data collection and retraining of the autoencoder to the target channel distribution. We propose a method for adapting the autoencoder without modifying the encoder and decoder neural networks, and adapting only the MDN model of the channel. The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the decoder samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed methods can quickly adapt the MDN model, and improve or maintain the error rate of the autoencoder under changing channel conditions.      
### 59.U-GAT: Multimodal Graph Attention Network for COVID-19 Outcome Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2108.00860.pdf)
>  During the first wave of COVID-19, hospitals were overwhelmed with the high number of admitted patients. An accurate prediction of the most likely individual disease progression can improve the planning of limited resources and finding the optimal treatment for patients. However, when dealing with a newly emerging disease such as COVID-19, the impact of patient- and disease-specific factors (e.g. body weight or known co-morbidities) on the immediate course of disease is by and large unknown. In the case of COVID-19, the need for intensive care unit (ICU) admission of pneumonia patients is often determined only by acute indicators such as vital signs (e.g. breathing rate, blood oxygen levels), whereas statistical analysis and decision support systems that integrate all of the available data could enable an earlier prognosis. To this end, we propose a holistic graph-based approach combining both imaging and non-imaging information. Specifically, we introduce a multimodal similarity metric to build a population graph for clustering patients and an image-based end-to-end Graph Attention Network to process this graph and predict the COVID-19 patient outcomes: admission to ICU, need for ventilation and mortality. Additionally, the network segments chest CT images as an auxiliary task and extracts image features and radiomics for feature fusion with the available metadata. Results on a dataset collected in Klinikum rechts der Isar in Munich, Germany show that our approach outperforms single modality and non-graph baselines. Moreover, our clustering and graph attention allow for increased understanding of the patient relationships within the population graph and provide insight into the network's decision-making process.      
### 60.Learning to Learn to Demodulate with Uncertainty Quantification via Bayesian Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.00785.pdf)
>  Meta-learning, or learning to learn, offers a principled framework for few-shot learning. It leverages data from multiple related learning tasks to infer an inductive bias that enables fast adaptation on a new task. The application of meta-learning was recently proposed for learning how to demodulate from few pilots. The idea is to use pilots received and stored for offline use from multiple devices in order to meta-learn an adaptation procedure with the aim of speeding up online training on new devices. Standard frequentist learning, which can yield relatively accurate "hard" classification decisions, is known to be poorly calibrated, particularly in the small-data regime. Poor calibration implies that the soft scores output by the demodulator are inaccurate estimates of the true probability of correct demodulation. In this work, we introduce the use of Bayesian meta-learning via variational inference for the purpose of obtaining well-calibrated few-pilot demodulators. In a Bayesian framework, each neural network weight is represented by a distribution, capturing epistemic uncertainty. Bayesian meta-learning optimizes over the prior distribution of the weights. The resulting Bayesian ensembles offer better calibrated soft decisions, at the computational cost of running multiple instances of the neural network for demodulation. Numerical results for single-input single-output Rayleigh fading channels with transmitter's non-linearities are provided that compare symbol error rate and expected calibration error for both frequentist and Bayesian meta-learning, illustrating how the latter is both more accurate and better-calibrated.      
### 61.Analysing digital in-memory computing for advanced finFET node  [ :arrow_down: ](https://arxiv.org/pdf/2108.00778.pdf)
>  Digital In-memory computing improves energy efficiency and throughput of a data-intensive process, which incur memory thrashing and, resulting multiple same memory accesses in a von Neumann architecture. Digital in-memory computing involves accessing multiple SRAM cells simultaneously, which may result in a bit flip when not timed critically. Therefore we discuss the transient voltage characteristics of the bitlines during an SRAM compute. To improve the packaging density and also avoid MOSFET down-scaling issues, we use a 7-nm predictive PDK which uses a finFET node. The finFET process has discrete fins and a lower Voltage supply, which makes the design of in-memory compute SRAM difficult. In this paper, we design a 6T SRAM cell in 7-nm finFET node and compare its SNMs with a UMC 28nm node implementation. Further, we design and simulate the rest of the SRAM peripherals, and in-memory computation for an advanced finFET node.      
### 62.Cross-cultural Mood Perception in Pop Songs and its Alignment with Mood Detection Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2108.00768.pdf)
>  Do people from different cultural backgrounds perceive the mood in music the same way? How closely do human ratings across different cultures approximate automatic mood detection algorithms that are often trained on corpora of predominantly Western popular music? Analyzing 166 participants responses from Brazil, South Korea, and the US, we examined the similarity between the ratings of nine categories of perceived moods in music and estimated their alignment with four popular mood detection algorithms. We created a dataset of 360 recent pop songs drawn from major music charts of the countries and constructed semantically identical mood descriptors across English, Korean, and Portuguese languages. Multiple participants from the three countries rated their familiarity, preference, and perceived moods for a given song. Ratings were highly similar within and across cultures for basic mood attributes such as sad, cheerful, and energetic. However, we found significant cross-cultural differences for more complex characteristics such as dreamy and love. To our surprise, the results of mood detection algorithms were uniformly correlated across human ratings from all three countries and did not show a detectable bias towards any particular culture. Our study thus suggests that the mood detection algorithms can be considered as an objective measure at least within the popular music context.      
### 63.Multiplicative updates for symmetric-cone factorizations  [ :arrow_down: ](https://arxiv.org/pdf/2108.00740.pdf)
>  Given a matrix $X\in \mathbb{R}^{m\times n}_+$ with non-negative entries, the cone factorization problem over a cone $\mathcal{K}\subseteq \mathbb{R}^k$ concerns computing $\{ a_1,\ldots, a_{m} \} \subseteq \mathcal{K}$ and $\{ b_1,\ldots, b_{n} \} \subseteq~\mathcal{K}^*$ belonging to its dual so that $X_{ij} = \langle a_i, b_j \rangle$ for all $i\in [m], j\in [n]$. Cone factorizations are fundamental to mathematical optimization as they allow us to express convex bodies as feasible regions of linear conic programs. In this paper, we introduce and analyze the symmetric-cone multiplicative update (SCMU) algorithm for computing cone factorizations when $\mathcal{K}$ is symmetric; i.e., it is self-dual and homogeneous. Symmetric cones are of central interest in mathematical optimization as they provide a common language for studying linear optimization over the nonnegative orthant (linear programs), over the second-order cone (second order cone programs), and over the cone of positive semidefinite matrices (semidefinite programs). The SCMU algorithm is multiplicative in the sense that the iterates are updated by applying a meticulously chosen automorphism of the cone computed using a generalization of the geometric mean to symmetric cones. Using an extension of Lieb's concavity theorem and von Neumann's trace inequality to symmetric cones, we show that the squared loss objective is non-decreasing along the trajectories of the SCMU algorithm. Specialized to the nonnegative orthant, the SCMU algorithm corresponds to the seminal algorithm by Lee and Seung for computing Nonnegative Matrix Factorizations.      
### 64.Angle Estimation for Terahertz Ultra-Massive MIMO-Based Space-to-Air Communications  [ :arrow_down: ](https://arxiv.org/pdf/2108.00675.pdf)
>  This paper investigates terahertz ultra-massive (UM)-MIMO-based angle estimation for space-to-air communications, which can solve the performance degradation problem caused by the dual delay-beam squint effects of terahertz UM-MIMO channels. Specifically, we first design a grouping true-time delay unit module that can significantly mitigate the impact of delay-beam squint effects to establish the space-to-air THz link. Based on the subarray selection scheme, the UM hybrid array can be equivalently considered as a low-dimensional fully-digital array, and then the fine estimates of azimuth/elevation angles at both UAVs and satellite can be separately acquired using the proposed prior-aided iterative angle estimation algorithm. The simulation results that close to Cramr-Rao lower bounds verify the effectiveness of our solution.      
### 65.Few-shot calibration of low-cost air pollution (PM2.5) sensors using meta-learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.00640.pdf)
>  Low-cost particulate matter sensors are transforming air quality monitoring because they have lower costs and greater mobility as compared to reference monitors. Calibration of these low-cost sensors requires training data from co-deployed reference monitors. Machine Learning based calibration gives better performance than conventional techniques, but requires a large amount of training data from the sensor, to be calibrated, co-deployed with a reference monitor. In this work, we propose novel transfer learning methods for quick calibration of sensors with minimal co-deployment with reference monitors. Transfer learning utilizes a large amount of data from other sensors along with a limited amount of data from the target sensor. Our extensive experimentation finds the proposed Model-Agnostic- Meta-Learning (MAML) based transfer learning method to be the most effective over other competitive baselines.      
### 66.Performance Analysis of a Two-Hop Relaying LoRa System  [ :arrow_down: ](https://arxiv.org/pdf/2108.00638.pdf)
>  The conventional LoRa system is not able to sustain long-range communication over fading channels. To resolve the challenging issue, this paper investigates a two-hop opportunistic amplify-and-forward relaying LoRa system. Based on the best relay-selection protocol, the analytical and asymptotic bit error rate (BER), achievable diversity order, coverage probability, and throughput of the proposed system are derived over the Nakagamim fading channel. Simulative and numerical results show that although the proposed system reduces the throughput compared to the conventional LoRa system, it can significantly improve BER and coverage probability. Hence, the proposed system can be considered as a promising platform for low-power, long-range and highly reliable wireless-communication applications.      
### 67.Accurate Signal Recovery in UHF Band Reuse-1 Cellular OFDMA Downlinks  [ :arrow_down: ](https://arxiv.org/pdf/2108.00598.pdf)
>  Accurate signal recovery is challenging for non-co-located transmit antennae deployments due to Inter Tower Interference (ITI) in reuse-1 cellular OFDMA networks. In the sub-1 GHz UHF band where only SISO deployment is possible, interference aware receiver algorithms are essential to mitigate the ITI. In this work, we develop a Joint Modified Least Squares (JmLS) algorithm for channel estimation in the presence of ITI. Firstly, it is shown that the JmLS algorithm achieves the Cramer-Rao lower bound. Next, an approach to managing the possibly distinct carrier frequency offsets of the different co-channel signals of interest is proposed. This improves the quality of the bit-level Joint Log-Likelihood Ratio. Finally, the impact of the choice of pilot sub-carrier information in the block modulated air-interface on the coded block error rate performance is studied. In particular, a comparison is made between (i) frequency orthogonal pilots from the different sectors, vis-a-vis, (ii) a pilot-on-pilot arrangement using pseudo-orthogonal sequences. The study indicates that based on the extent of frequency selectivity and the number of interferers being considered, (ii) is advantageous when the set of ITI pilots incident on a receiver is small when compared to the set of all possible pilots.      
### 68.Resource Management in Edge and Fog Computing using FogBus2 Framework  [ :arrow_down: ](https://arxiv.org/pdf/2108.00591.pdf)
>  Edge/Fog computing is a novel computing paradigm that provides resource-limited Internet of Things (IoT) devices with scalable computing and storage resources. Compared to cloud computing, edge/fog servers have fewer resources, but they can be accessed with higher bandwidth and less communication latency. Thus, integrating edge/fog and cloud infrastructures can support the execution of diverse latency-sensitive and computation-intensive IoT applications. Although some frameworks attempt to provide such integration, there are still several challenges to be addressed, such as dynamic scheduling of different IoT applications, scalability mechanisms, multi-platform support, and supporting different interaction models. FogBus2, as a new python-based framework, offers a lightweight and distributed container-based framework to overcome these challenges. In this chapter, we highlight key features of the FogBus2 framework alongside describing its main components. Besides, we provide a step-by-step guideline to set up an integrated computing environment, containing multiple cloud service providers (Hybrid-cloud) and edge devices, which is a prerequisite for any IoT application scenario. To obtain this, a low-overhead communication network among all computing resources is initiated by the provided scripts and configuration files. Next, we provide instructions and corresponding code snippets to install and run the main framework and its integrated applications. Finally, we demonstrate how to implement and integrate several new IoT applications and custom scheduling and scalability policies with the FogBus2 framework.      
### 69.A Machine-Learning-Based Direction-of-Origin Filter for the Identification of Radio Frequency Interference in the Search for Technosignatures  [ :arrow_down: ](https://arxiv.org/pdf/2108.00559.pdf)
>  Radio frequency interference (RFI) mitigation remains a major challenge in the search for radio technosignatures. Typical mitigation strategies include a direction-of-origin (DoO) filter, where a signal is classified as RFI if it is detected in multiple directions on the sky. These classifications generally rely on estimates of signal properties, such as frequency and frequency drift rate. Convolutional neural networks (CNNs) offer a promising complement to existing filters because they can be trained to analyze dynamic spectra directly, instead of relying on inferred signal properties. In this work, we compiled several data sets consisting of labeled pairs of images of dynamic spectra, and we designed and trained a CNN that can determine whether or not a signal detected in one scan is also present in another scan. This CNN-based DoO filter outperforms both a baseline 2D correlation model as well as existing DoO filters over a range of metrics, with precision and recall values of 99.15% and 97.81%, respectively. We found that the CNN reduces the number of signals requiring visual inspection after the application of traditional DoO filters by a factor of 6-16 in nominal situations.      
### 70.Real-Time ECG Interval Monitoring Using a Fully Disposable Wireless Patch Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2108.00536.pdf)
>  ECG interval monitoring provides key insights into the diagnosis of cardiac diseases. The standard 12-lead ECG is generally used, however, because of the current COVID-19 pandemic there is a strong need for a remote monitoring solution which will reduce exposure of health care providers to coronavirus. This article presents a disposable wireless patch biosensor (VitalPatch) and associated platform functionalities for real-time continuous measurement of clinically relevant ECG intervals including PR interval, QRS duration, QT interval, corrected QT interval by Bazett (QTb), and corrected QT interval by Fridericia (QTf). The performance of the VitalPatch is validated by comparing its automated algorithm interval measurements to the manually annotated global intervals of the 12-lead ECG device in 30 subjects. The accuracy of interval monitoring (in terms of mean timing error calculated by subtracting the VitalPatch measurements from the global intervals) is 2.7+/-15.94 ms, -1.97+/-12.29 ms, -14.6+/-12.97 ms, - 15.33+/-14.11 ms, and -15.08+/-13.69 ms for PR interval, QRS duration, QT interval, QTb, and QTf, respectively. These results demonstrate that the VitalPatch is a viable solution for measuring ECG intervals while taking advantage of its remote monitoring feature during the pandemic.      
### 71.End to End Bangla Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2108.00500.pdf)
>  Text-to-Speech (TTS) system is a system where speech is synthesized from a given text following any particular approach. Concatenative synthesis, Hidden Markov Model (HMM) based synthesis, Deep Learning (DL) based synthesis with multiple building blocks, etc. are the main approaches for implementing a TTS system. Here, we are presenting our deep learning-based end-to-end Bangla speech synthesis system. It has been implemented with minimal human annotation using only 3 major components (Encoder, Decoder, Post-processing net including waveform synthesis). It does not require any frontend preprocessor and Grapheme-to-Phoneme (G2P) converter. Our model has been trained with phonetically balanced 20 hours of single speaker speech data. It has obtained a 3.79 Mean Opinion Score (MOS) on a scale of 5.0 as subjective evaluation and a 0.77 Perceptual Evaluation of Speech Quality(PESQ) score on a scale of [-0.5, 4.5] as objective evaluation. It is outperforming all existing non-commercial state-of-the-art Bangla TTS systems based on naturalness.      
### 72.CERL: A Unified Optimization Framework for Light Enhancement with Realistic Noise  [ :arrow_down: ](https://arxiv.org/pdf/2108.00478.pdf)
>  Low-light images captured in the real world are inevitably corrupted by sensor noise. Such noise is spatially variant and highly dependent on the underlying pixel intensity, deviating from the oversimplified assumptions in conventional denoising. Existing light enhancement methods either overlook the important impact of real-world noise during enhancement, or treat noise removal as a separate pre- or post-processing step. We present Coordinated Enhancement for Real-world Low-light Noisy Images (CERL), that seamlessly integrates light enhancement and noise suppression parts into a unified and physics-grounded optimization framework. For the real low-light noise removal part, we customize a self-supervised denoising model that can easily be adapted without referring to clean ground-truth images. For the light enhancement part, we also improve the design of a state-of-the-art backbone. The two parts are then joint formulated into one principled plug-and-play optimization. Our approach is compared against state-of-the-art low-light enhancement methods both qualitatively and quantitatively. Besides standard benchmarks, we further collect and test on a new realistic low-light mobile photography dataset (RLMP), whose mobile-captured photos display heavier realistic noise than those taken by high-quality cameras. CERL consistently produces the most visually pleasing and artifact-free results across all experiments. Our RLMP dataset and codes are available at: <a class="link-external link-https" href="https://github.com/VITA-Group/CERL" rel="external noopener nofollow">this https URL</a>.      
### 73.A Sequential Supervised Machine Learning Approach for Cyber Attack Detection in a Smart Grid System  [ :arrow_down: ](https://arxiv.org/pdf/2108.00476.pdf)
>  Modern smart grid systems are heavily dependent on Information and Communication Technology, and this dependency makes them prone to cyberattacks. The occurrence of a cyberattack has increased in recent years resulting in substantial damage to power systems. For a reliable and stable operation, cyber protection, control, and detection techniques are becoming essential. Automated detection of cyberattacks with high accuracy is a challenge. To address this, we propose a two-layer hierarchical machine learning model having an accuracy of 95.44 % to improve the detection of cyberattacks. The first layer of the model is used to distinguish between the two modes of operation (normal state or cyberattack). The second layer is used to classify the state into different types of cyberattacks. The layered approach provides an opportunity for the model to focus its training on the targeted task of the layer, resulting in improvement in model accuracy. To validate the effectiveness of the proposed model, we compared its performance against other recent cyber attack detection models proposed in the literature.      
### 74.Self-supervised Learning with Local Attention-Aware Feature  [ :arrow_down: ](https://arxiv.org/pdf/2108.00475.pdf)
>  In this work, we propose a novel methodology for self-supervised learning for generating global and local attention-aware visual features. Our approach is based on training a model to differentiate between specific image transformations of an input sample and the patched images. Utilizing this approach, the proposed method is able to outperform the previous best competitor by 1.03% on the Tiny-ImageNet dataset and by 2.32% on the STL-10 dataset. Furthermore, our approach outperforms the fully-supervised learning method on the STL-10 dataset. Experimental results and visualizations show the capability of successfully learning global and local attention-aware visual representations.      
### 75.Delay Aware Secure Offloading for NOMA-Assisted Mobile Edge Computing in Internet of Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2108.00469.pdf)
>  In this paper, a multi-vehicle multi-task nonorthogonal multiple access (NOMA) assisted mobile edge computing (MEC) system with passive eavesdropping vehicles is investigated. To heighten the performance of edge vehicles, we propose a vehicle grouping pairing method, which utilizes vehicles near the MEC as full-duplex relays to assist edge vehicles. For promoting transmission security, we employ artificial noise to interrupt eavesdropping vehicles. Furthermore, we derive the approximate expression of secrecy outage probability of the system. The combined optimization of vehicle task division, power allocation, and transmit beamforming is formulated to minimize the total delay of task completion of edge vehicles. Then, we design a power allocation and task scheduling algorithm based on genetic algorithm to solve the mixed-integer nonlinear programming problem. Numerical results demonstrate the superiority of our proposed scheme in terms of system security and transmission delay.      
### 76.Hybrid Beamforming and Combining for Millimeter Wave Full Duplex Massive MIMO Interference Channel  [ :arrow_down: ](https://arxiv.org/pdf/2108.00465.pdf)
>  Full-Duplex (FD) communication can revolutionize wireless communications as it avoids using independent channels for bi-directional communications. In this work, we generalize the point-to-point FD communication in millimeter wave (mmWave) band consisting of K-pair of massive MIMO FD nodes operating simultaneously. To enable the coexistence of massive MIMO FD links cost-efficiently, we present novel joint hybrid beamforming (HYBF) and combining scheme for weighted sum-rate (WSR) maximization. The proposed algorithm is based on alternative optimization based on the minorization-maximization method. Moreover, we present a novel SI and massive MIMO interference channel aware power allocation scheme to include the optimal power control. Simulation results show significant performance improvement compared to a traditional bidirectional half-duplex communication system.      
### 77.3D Reactive Control and Frontier-Based Exploration for Unstructured Environments  [ :arrow_down: ](https://arxiv.org/pdf/2108.00380.pdf)
>  The paper proposes a reliable and robust planning solution to the long range robotic navigation problem in extremely cluttered environments. A two-layer planning architecture is proposed that leverages both the environment map and the direct depth sensor information to ensure maximal information gain out of the onboard sensors. A frontier-based pose sampling technique is used with a fast marching cost-to-go calculation to select a goal pose and plan a path to maximize robot exploration rate. An artificial potential function approach, relying on direct depth measurements, enables the robot to follow the path while simultaneously avoiding small scene obstacles that are not captured in the map due to mapping and localization uncertainties. We demonstrate the feasibility and robustness of the proposed approach through field deployments in a structurally complex warehouse using a micro-aerial vehicle (MAV) with all the sensing and computations performed onboard.      
### 78.SurpriseNet: Melody Harmonization Conditioning on User-controlled Surprise Contours  [ :arrow_down: ](https://arxiv.org/pdf/2108.00378.pdf)
>  The surprisingness of a song is an essential and seemingly subjective factor in determining whether the listener likes it. With the help of information theory, it can be described as the transition probability of a music sequence modeled as a Markov chain. In this study, we introduce the concept of deriving entropy variations over time, so that the surprise contour of each chord sequence can be extracted. Based on this, we propose a user-controllable framework that uses a conditional variational autoencoder (CVAE) to harmonize the melody based on the given chord surprise indication. Through explicit conditions, the model can randomly generate various and harmonic chord progressions for a melody, and the Spearman's correlation and p-value significance show that the resulting chord progressions match the given surprise contour quite well. The vanilla CVAE model was evaluated in a basic melody harmonization task (no surprise control) in terms of six objective metrics. The results of experiments on the Hooktheory Lead Sheet Dataset show that our model achieves performance comparable to the state-of-the-art melody harmonization model.      
### 79.Design of Non-Orthogonal Sequences Using a Two-Stage Genetic Algorithm for Grant-Free Massive Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2108.00361.pdf)
>  In massive machine-type communications (mMTC), grant-free access is a key enabler for a massive number of users to be connected to a base station with low signaling overhead and low latency. In this paper, a two-stage genetic algorithm (GA) is proposed to design a new set of user-specific, non-orthogonal, unimodular sequences for uplink grant-free access. The first-stage GA is to find a subsampling index set for a partial unitary matrix that can be approximated to an equiangular tight frame. Then in the second-stage GA, we try to find a sequence to be masked to each column of the partial unitary matrix, in order to reduce the peak-to-average power ratio of the resulting columns for multicarrier transmission. Finally, the masked columns of the matrix are proposed as new non-orthogonal sequences for uplink grant-free access. Simulation results demonstrate that the non-orthogonal sequences designed by our two-stage GA exhibit excellent performance for compressed sensing based joint activity detection and channel estimation in uplink grant-free access. Compared to algebraic design, this GA-based design can present a set of good non-orthogonal sequences of arbitrary length, which provides more flexibility for uplink grant-free access in mMTC.      
### 80.Energy harvesting from anisotropic fluctuations  [ :arrow_down: ](https://arxiv.org/pdf/2108.00334.pdf)
>  We consider a rudimentary model for a heat engine, known as the Brownian gyrator, that consists of an overdamped system with two degrees of freedom in an anisotropic temperature field. Whereas the hallmark of the gyrator is a nonequilibrium steady-state curl-carrying probability current that can generate torque, we explore the coupling of this natural gyrating motion with a periodic actuation potential for the purpose of extracting work. We show that path-lengths traversed in the manifold of thermodynamic states, measured in a suitable Riemannian metric, represent dissipative losses, while area integrals of a work-density quantify work being extracted. Thus, the maximal amount of work that can be extracted relates to an isoperimetric problem, trading off area against length of an encircling path. We derive an isoperimetric inequality that provides a universal bound on the efficiency of all cyclic operating protocols, and a bound on how fast a closed path can be traversed before it becomes impossible to extract positive work. The analysis presented provides guiding principles for building autonomous engines that extract work from anistropic fluctuations.      
### 81.Self Context and Shape Prior for Sensorless Freehand 3D Ultrasound Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2108.00274.pdf)
>  3D ultrasound (US) is widely used for its rich diagnostic information. However, it is criticized for its limited field of view. 3D freehand US reconstruction is promising in addressing the problem by providing broad range and freeform scan. The existing deep learning based methods only focus on the basic cases of skill sequences, and the model relies on the training data heavily. The sequences in real clinical practice are a mix of diverse skills and have complex scanning paths. Besides, deep models should adapt themselves to the testing cases with prior knowledge for better robustness, rather than only fit to the training cases. In this paper, we propose a novel approach to sensorless freehand 3D US reconstruction considering the complex skill sequences. Our contribution is three-fold. First, we advance a novel online learning framework by designing a differentiable reconstruction algorithm. It realizes an end-to-end optimization from section sequences to the reconstructed volume. Second, a self-supervised learning method is developed to explore the context information that reconstructed by the testing data itself, promoting the perception of the model. Third, inspired by the effectiveness of shape prior, we also introduce adversarial training to strengthen the learning of anatomical shape prior in the reconstructed volume. By mining the context and structural cues of the testing data, our online learning methods can drive the model to handle complex skill sequences. Experimental results on developmental dysplasia of the hip US and fetal US datasets show that, our proposed method can outperform the start-of-the-art methods regarding the shift errors and path similarities.      
### 82.Phnomen-Signal-Modell: Formalismus, Graph und Anwendung  [ :arrow_down: ](https://arxiv.org/pdf/2108.00252.pdf)
>  If we consider information as the basis of action, it may be of interest to examine the flow and acquisition of information between the actors in traffic. The central question is, which signals an automaton has to receive, decode or send in road traffic in order to act safely and in a conform manner to valid standards. The phenomenon-signal-model is a method to structure the problem, to analyze and to describe this very signal flow. Explaining the basics, structure and application of this method is the aim of this paper. <br>-- <br>Betrachtet man Information als Grundlage des Handelns, so wird es interessant sein, Fluss und Erfassung von Information zwischen den Akteuren des Verkehrsgeschehens zu untersuchen. Die zentrale Frage ist, welche Signale ein Automat im Straenverkehr empfangen, decodieren oder senden muss, um konform zu geltenden Mastben und sicher zu agieren. Das Phnomen-Signal-Modell ist eine Methode, das Problemfeld zu strukturieren, eben diesen Signalfluss zu analysieren und zu beschreiben. Der vorliegende Aufsatz erklrt Grundlagen, Aufbau und Anwendung dieser Methode.      
### 83.Voice Reconstruction from Silent Speech with a Sequence-to-Sequence Model  [ :arrow_down: ](https://arxiv.org/pdf/2108.00190.pdf)
>  Silent Speech Decoding (SSD) based on Surface electromyography (sEMG) has become a prevalent task in recent years. Though revolutions have been proposed to decode sEMG to audio successfully, some problems still remain. In this paper, we propose an optimized sequence-to-sequence (Seq2Seq) approach to synthesize voice from subvocal sEMG. Both subvocal and vocal sEMG are collected and preprocessed to provide data information. Then, we extract durations from the alignment between subvocal and vocal signals to regulate the subvocal sEMG following audio length. Besides, we use phoneme classification and vocal sEMG reconstruction modules to improve the model performance. Finally, experiments on a Mandarin speaker dataset, which consists of 6.49 hours of data, demonstrate that the proposed model improves the mapping accuracy and voice quality of reconstructed voice.      
### 84.Personalized Stress Monitoring using Wearable Sensors in Everyday Settings  [ :arrow_down: ](https://arxiv.org/pdf/2108.00144.pdf)
>  Since stress contributes to a broad range of mental and physical health problems, the objective assessment of stress is essential for behavioral and physiological studies. Although several studies have evaluated stress levels in controlled settings, objective stress assessment in everyday settings is still largely under-explored due to challenges arising from confounding contextual factors and limited adherence for self-reports. In this paper, we explore the objective prediction of stress levels in everyday settings based on heart rate (HR) and heart rate variability (HRV) captured via low-cost and easy-to-wear photoplethysmography (PPG) sensors that are widely available on newer smart wearable devices. We present a layered system architecture for personalized stress monitoring that supports a tunable collection of data samples for labeling, and present a method for selecting informative samples from the stream of real-time data for labeling. We captured the stress levels of fourteen volunteers through self-reported questionnaires over periods of between 1-3 months, and explored binary stress detection based on HR and HRV using Machine Learning Methods. We observe promising preliminary results given that the dataset is collected in the challenging environments of everyday settings. The binary stress detector is fairly accurate and can detect stressful vs non-stressful samples with a macro-F1 score of up to \%76. Our study lays the groundwork for more sophisticated labeling strategies that generate context-aware, personalized models that will empower health professionals to provide personalized interventions.      
### 85.A Deep Learning Approach to Predict Blood Pressure from PPG Signals  [ :arrow_down: ](https://arxiv.org/pdf/2108.00099.pdf)
>  Blood Pressure (BP) is one of the four primary vital signs indicating the status of the body's vital (life-sustaining) functions. BP is difficult to continuously monitor using a sphygmomanometer (i.e. a blood pressure cuff), especially in everyday-setting. However, other health signals which can be easily and continuously acquired, such as photoplethysmography (PPG), show some similarities with the Aortic Pressure waveform. Based on these similarities, in recent years several methods were proposed to predict BP from the PPG signal. Building on these results, we propose an advanced personalized data-driven approach that uses a three-layer deep neural network to estimate BP based on PPG signals. Different from previous work, the proposed model analyzes the PPG signal in time-domain and automatically extracts the most critical features for this specific application, then uses a variation of recurrent neural networks called Long-Short-Term-Memory (LSTM) to map the extracted features to the BP value associated with that time window. Experimental results on two separate standard hospital datasets, yielded absolute errors mean and absolute error standard deviation for systolic and diastolic BP values outperforming prior works.      
### 86.Computational Complexity of Synchronization under Sparse Regular Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2108.00081.pdf)
>  The constrained synchronization problem (CSP) asks for a synchronizing word of a given input automaton contained in a regular set of constraints. It could be viewed as a special case of synchronization of a discrete event system under supervisory control. Here, we study the computational complexity of this problem for the class of sparse regular constraint languages. We give a new characterization of sparse regular sets, which equal the bounded regular sets, and derive a full classification of the computational complexity of CSP for letter-bounded regular constraint languages, which properly contain the strictly bounded regular languages. Then, we introduce strongly self-synchronizing codes and investigate CSP for bounded languages induced by these codes. With our previous result, we deduce a full classification for these languages as well. In both cases, depending on the constraint language, our problem becomes NP-complete or polynomial time solvable.      
### 87.A Point-to-Distribution Joint Geometry and Color Metric for Point Cloud Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2108.00054.pdf)
>  Point clouds (PCs) are a powerful 3D visual representation paradigm for many emerging application domains, especially virtual and augmented reality, and autonomous vehicles. However, the large amount of PC data required for highly immersive and realistic experiences requires the availability of efficient, lossy PC coding solutions are critical. Recently, two MPEG PC coding standards have been developed to address the relevant application requirements and further developments are expected in the future. In this context, the assessment of PC quality, notably for decoded PCs, is critical and asks for the design of efficient objective PC quality metrics. In this paper, a novel point-to-distribution metric is proposed for PC quality assessment considering both the geometry and texture. This new quality metric exploits the scale-invariance property of the Mahalanobis distance to assess first the geometry and color point-to-distribution distortions, which are after fused to obtain a joint geometry and color quality metric. The proposed quality metric significantly outperforms the best PC quality assessment metrics in the literature.      
### 88.Long-Range Optical Wireless Information and Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2108.00004.pdf)
>  Simultaneous wireless information and power transfer (SWIPT) is a remarkable technology to support data and energy transfer in the era of Internet of Things (IoT). In this paper, we propose a beam-compression resonant beam (BCRB) system for long-range optical wireless information and power transfer based on the telescope-like internal modulator (TIM). Utilizing the TIM, the resonant beam is compressed, making the transmission energy be further concentrated. Thus the over-the-air power loss produced by the beam diverged decreases, which enables the long-range SWIPT capability. We establish the analytical models of the transmission loss, the stability condition, the output power, and the spectral efficiency of the BCRB system, and evaluate the performance on the beam-compression, energy delivery, and data transfer. Numerical analysis illustrates that the exemplary BCRB system can deliver 6 W power and have 14 bit/s/Hz spectral efficiency over 200 m distance. Overall, the BCRB system is a potential scheme for long-range SWIPT in IoT.      
