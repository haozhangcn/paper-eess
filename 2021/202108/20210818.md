# ArXiv eess --Wed, 18 Aug 2021
### 1.Optimal Placement of Public Electric Vehicle Charging Stations Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.07772.pdf)
>  The placement of charging stations in areas with developing charging infrastructure is a critical component of the future success of electric vehicles (EVs). In Albany County in New York, the expected rise in the EV population requires additional charging stations to maintain a sufficient level of efficiency across the charging infrastructure. A novel application of Reinforcement Learning (RL) is able to find optimal locations for new charging stations given the predicted charging demand and current charging locations. The most important factors that influence charging demand prediction include the conterminous traffic density, EV registrations, and proximity to certain types of public buildings. The proposed RL framework can be refined and applied to cities across the world to optimize charging station placement.      
### 2.A New Backbone for Hyperspectral Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2108.07739.pdf)
>  The study of 3D hyperspectral image (HSI) reconstruction refers to the inverse process of snapshot compressive imaging, during which the optical system, e.g., the coded aperture snapshot spectral imaging (CASSI) system, captures the 3D spatial-spectral signal and encodes it to a 2D measurement. While numerous sophisticated neural networks have been elaborated for end-to-end reconstruction, trade-offs still need to be made among performance, efficiency (training and inference time), and feasibility (the ability of restoring high resolution HSI on limited GPU memory). This raises a challenge to design a new baseline to conjointly meet the above requirements. In this paper, we fill in this blank by proposing a Spatial/Spectral Invariant Residual U-Net, namely SSI-ResU-Net. It differentiates with U-Net in three folds--1) scale/spectral-invariant learning, 2) nested residual learning, and 3) computational efficiency. Benefiting from these three modules, the proposed SSI-ResU-Net outperforms the current state-of-the-art method TSA-Net by over 3 dB in PSNR and 0.036 in SSIM while only using 2.82% trainable parameters. To the greatest extent, SSI-ResU-Net achieves competing performance with over 77.3% reduction in terms of floating-point operations (FLOPs), which for the first time, makes high-resolution HSI reconstruction feasible under practical application scenarios. Code and pre-trained models are made available at <a class="link-external link-https" href="https://github.com/Jiamian-Wang/HSI_baseline" rel="external noopener nofollow">this https URL</a>.      
### 3.0.8% Nyquist computational ghost imaging via non-experimental deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.07673.pdf)
>  We present a framework for computational ghost imaging based on deep learning and customized pink noise speckle patterns. The deep neural network in this work, which can learn the sensing model and enhance image reconstruction quality, is trained merely by simulation. To demonstrate the sub-Nyquist level in our work, the conventional computational ghost imaging results, reconstructed imaging results using white noise and pink noise via deep learning are compared under multiple sampling rates at different noise conditions. We show that the proposed scheme can provide high-quality images with a sampling rate of 0.8% even when the object is outside the training dataset, and it is robust to noisy environments. This method is excellent for various applications, particularly those that require a low sampling rate, fast reconstruction efficiency, or experience strong noise interference.      
### 4.Deep MRI Reconstruction with Radial Subsampling  [ :arrow_down: ](https://arxiv.org/pdf/2108.07619.pdf)
>  In spite of its extensive adaptation in almost every medical diagnostic and examinatorial application, Magnetic Resonance Imaging (MRI) is still a slow imaging modality which limits its use for dynamic imaging. In recent years, Parallel Imaging (PI) and Compressed Sensing (CS) have been utilised to accelerate the MRI acquisition. In clinical settings, subsampling the k-space measurements during scanning time using Cartesian trajectories, such as rectilinear sampling, is currently the most conventional CS approach applied which, however, is prone to producing aliased reconstructions. With the advent of the involvement of Deep Learning (DL) in accelerating the MRI, reconstructing faithful images from subsampled data became increasingly promising. Retrospectively applying a subsampling mask onto the k-space data is a way of simulating the accelerated acquisition of k-space data in real clinical setting. In this paper we compare and provide a review for the effect of applying either rectilinear or radial retrospective subsampling on the quality of the reconstructions outputted by trained deep neural networks. With the same choice of hyper-parameters, we train and evaluate two distinct Recurrent Inference Machines (RIMs), one for each type of subsampling. The qualitative and quantitative results of our experiments indicate that the model trained on data with radial subsampling attains higher performance and learns to estimate reconstructions with higher fidelity paving the way for other DL approaches to involve radial subsampling.      
### 5.spectrai: A deep learning framework for spectral data  [ :arrow_down: ](https://arxiv.org/pdf/2108.07595.pdf)
>  Deep learning computer vision techniques have achieved many successes in recent years across numerous imaging domains. However, the application of deep learning to spectral data remains a complex task due to the need for augmentation routines, specific architectures for spectral data, and significant memory requirements. Here we present spectrai, an open-source deep learning framework designed to facilitate the training of neural networks on spectral data and enable comparison between different methods. Spectrai provides numerous built-in spectral data pre-processing and augmentation methods, neural networks for spectral data including spectral (image) denoising, spectral (image) classification, spectral image segmentation, and spectral image super-resolution. Spectrai includes both command line and graphical user interfaces (GUI) designed to guide users through model and hyperparameter decisions for a wide range of applications.      
### 6.Near-field Wireless Power Transfer for 6G Internet-of-Everything Mobile Networks: Opportunities and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2108.07576.pdf)
>  Radiating wireless power transfer (WPT) brings forth the possibility to cost-efficiently charge wireless devices without requiring a wiring infrastructure. As such, it is expected to play a key role in the deployment of limited-battery communicating devices, as part of the 6G enabled Internet-of-Everything (IoE) vision. To date, radiating WPT technologies are mainly studied and designed assuming that the devices are located in the far-field region of the power radiating antenna, resulting in a relatively low energy transfer efficiency. However, with the transition of 6G systems to mmWave frequencies combined with the usage of large-scale antennas, future WPT devices are likely to operate in the radiating near-field (Fresnel) region. In this article, we provide an overview of the opportunities and challenges which arise from radiating near-field WPT. In particular, we discuss about the possibility to realize beam focusing in near-field radiating conditions, and highlight its possible implications for WPT in future {IoE} networks. Besides, we overview some of the design challenges and research directions which arise from this emerging paradigm, including its simultaneous operation with wireless communications, radiating waveform considerations, hardware aspects, and operation with typical antenna architectures.      
### 7.A technique to enable frequency dependent power savings in a level crossing analog-to-digital converter  [ :arrow_down: ](https://arxiv.org/pdf/2108.07566.pdf)
>  The level crossing analog-to-digital converters are meant for the effective conversion of sparse signals by construction. In these converters, the bandwidth-power trade-off requires a re-design of the comparators which takes a lot of time and effort to reach the application optimum point. Inspired by synchronous converters that have a dynamic power component that can be traded with bandwidth with the change of a clock frequency, a technique to allow such trade-off in the level crossing converter was developed. The resulting level crossing ADC has an input signal dependent dynamic power which can reach up to 42\% OFF time during the conversion of sine waves, achieving 45.5% power reduction in the simulated design with TSMC 180nm PDK.      
### 8.A 1V 5-bits Low Power Level Crossing ADC with OFF state in idle time for bio-medical applications in 0.18um CMOS  [ :arrow_down: ](https://arxiv.org/pdf/2108.07564.pdf)
>  The ubiquitous use of sensing and signal processing is increasing exponentially with the advance of the Internet of Everything (IoE). In this context, the design of every time more power efficient sensor nodes is a must. Within these nodes, one of the most power-hungry components are the analog-to-digital converters (ADC). These components are used everywhere to translate real-world analog signals into computer intelligible digital signals. One of the promising architecture for the sensing of physiological signals is the level crossing ADC due to the sparse characteristics of those signals. One of the challenges to improve the power efficiency of this type of ADC lies in the use of continuous comparators to keep track of the input signal within the voltage references. The aim of this work is to investigate the impact of using continuous comparator which can be turned off without incurring error to the conversion of the level crossing ADC. New boundaries will be set for the correct behavior of the level crossing ADC together with the conditions for power saving with the proposed architecture. A 1V 5-bits level crossing ADC was implemented using the TSMC 0.18um process and fabricated for laboratory measurements. The ADC consumes 12.2uW during tracking state and with the proposed technique, the reduction of the average power can go from 4.2% to 45.5% depending on the activity and the type of the input signal.      
### 9.An End-to-End Deep Learning Approach for Epileptic Seizure Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2108.07453.pdf)
>  An accurate seizure prediction system enables early warnings before seizure onset of epileptic patients. It is extremely important for drug-refractory patients. Conventional seizure prediction works usually rely on features extracted from Electroencephalography (EEG) recordings and classification algorithms such as regression or support vector machine (SVM) to locate the short time before seizure onset. However, such methods cannot achieve high-accuracy prediction due to information loss of the hand-crafted features and the limited classification ability of regression and SVM algorithms. We propose an end-to-end deep learning solution using a convolutional neural network (CNN) in this paper. One and two dimensional kernels are adopted in the early- and late-stage convolution and max-pooling layers, respectively. The proposed CNN model is evaluated on Kaggle intracranial and CHB-MIT scalp EEG datasets. Overall sensitivity, false prediction rate, and area under receiver operating characteristic curve reaches 93.5%, 0.063/h, 0.981 and 98.8%, 0.074/h, 0.988 on two datasets respectively. Comparison with state-of-the-art works indicates that the proposed model achieves exceeding prediction performance.      
### 10.A BCS-GDE Algorithm for Multi-objective Optimization of Combined Cooling, Heating and Power Model  [ :arrow_down: ](https://arxiv.org/pdf/2108.07394.pdf)
>  District energy systems can not only reduce energy consumption but also set energy supply dispatching schemes according to demand. In this paper, the combined cooling heating and power economic emission dispatch (CCHPEED) model is established with the objective of economic cost, primary energy consumption, and pollutant emissions, as well as three decision-making strategies, are proposed to meet the demand for energy supply. Besides, a generalized differential evolution with the best compromise solution processing mechanism (BCS-GDE) is proposed to solve the model, also, the best compromise solution processing mechanism is put forward in the algorithm. In the simulation, the resource dispatching is performed according to the different energy demands of hotels, offices, and residential buildings on the whole day. The simulation results show that the model established in this paper can reduce the economic cost, energy consumption, and pollutant emission, in which the maximum reduction rate of economic cost is 72%, the maximum reduction rate of primary energy consumption is 73%, and the maximum reduction rate of pollutant emission is 88%. Concurrently, BCS-GDE also has better convergence and diversity than the classic algorithms.      
### 11.Precision and accuracy of acoustic gunshot location in an urban environment  [ :arrow_down: ](https://arxiv.org/pdf/2108.07377.pdf)
>  The muzzle blast caused by the discharge of a firearm generates a loud, impulsive sound that propagates away from the shooter in all directions. The location of the source can be computed from time-of-arrival measurements of the muzzle blast on multiple acoustic sensors at known locations, a technique known as multilateration. The multilateration problem is considerably simplified by assuming straight-line propagation in a homogeneous medium, a model for which there are multiple published solutions. Live-fire tests of the ShotSpotter gunshot location system in Pittsburgh, PA were analyzed off-line under several algorithms and geometric constraints to evaluate the accuracy of acoustic multilateration in a forensic context. Best results were obtained using the algorithm due to Mathias, Leonari and Galati under a two-dimensional geometric constraint. Multilateration on random subsets of the participating sensor array show that 96% of shots can be located to an accuracy of 15 m or better when six or more sensors participate in the solution.      
### 12.Task-Oriented Multi-User Semantic Communications for Multimodal Data  [ :arrow_down: ](https://arxiv.org/pdf/2108.07357.pdf)
>  Semantic communications focus on the successful transmission of information relevant to the transmission task. In this paper, we investigate multi-users transmission for multimodal data in a task semantic communication system. We take the vision-answering as the semantic transmission task, in which part of the users transmit images and the other users transmit text to inquiry the information about the images. The receiver will provide answers based on the image and text from multiple users in the considered system. To exploit the correlation between the multimodal data from multiple users, we proposed a deep neural network enabled multi-user semantic communication system, named MU-DeepSC, for the visual question answering (VQA) task, in which the answer is highly dependent on the related image and text from the multiple users. Particularly, based on the memory, attention, and composition (MAC) neural network, we jointly design the transceiver and merge the MAC network to capture the features from the correlated multimodal data for serving the transmission task. The MU-DeepSC extracts the semantic information of image and text from different users and then generates the corresponding answers. Simulation results validate the feasibility of the proposed MU-DeepSC, which is more robust to various channel conditions than the traditional communication systems, especially in the low signal-to-noise (SNR) regime.      
### 13.Classification of Common Waveforms Including a Watchdog for Unknown Signals  [ :arrow_down: ](https://arxiv.org/pdf/2108.07339.pdf)
>  In this paper, we examine the use of a deep multi-layer perceptron model architecture to classify received signal samples as coming from one of four common waveforms, Single Carrier (SC), Single-Carrier Frequency Division Multiple Access (SC-FDMA), Orthogonal Frequency Division Multiplexing (OFDM), and Linear Frequency Modulation (LFM), used in communication and radar networks. Synchronization of the signals is not needed as we assume there is an unknown and uncompensated time and frequency offset. An autoencoder with a deep CNN architecture is also examined to create a new fifth classification category of an unknown waveform type. This is accomplished by calculating a minimum and maximum threshold values from the root mean square error (RMSE) of the radar and communication waveforms. The classifier and autoencoder work together to monitor a spectrum area to identify the common waveforms inside the area of operation along with detecting unknown waveforms. Results from testing showed the classifier had 100\% classification rate above 0 dB with accuracy of 83.2\% and 94.7\% at -10 dB and -5 dB, respectively, with signal impairments present. Results for the anomaly detector showed 85.3\% accuracy at 0 dB with 100\% at SNR greater than 0 dB with signal impairments present when using a high-value Fast Fourier Transform (FFT) size. Accurate detection rates decline as additional noise is introduced to the signals, with 78.1\% at -5 dB and 56.5\% at -10 dB. However, these low rates seen can be potentially mitigated by using even higher FFT sizes also shown in our results.      
### 14.Iterative learning control with discrete-time nonlinear nonminimum phase models via stable inversion  [ :arrow_down: ](https://arxiv.org/pdf/2108.07315.pdf)
>  Output reference tracking can be improved by iteratively learning from past data to inform the design of feedforward control inputs for subsequent tracking attempts. This process is called iterative learning control (ILC). This article develops a method to apply ILC to systems with nonlinear discrete-time dynamical models with unstable inverses (i.e. discrete-time nonlinear non-minimum phase models). This class of systems includes piezoactuators, electric power converters, and manipulators with flexible links, which may be found in nanopositioning stages, rolling mills, and robotic arms, respectively. As these devices may be required to execute fine transient reference tracking tasks repetitively in contexts such as manufacturing, they may benefit from ILC. Specifically, this article facilitates ILC of such systems by presenting a new ILC synthesis framework that allows combination of the principles of Newton's root finding algorithm with stable inversion, a technique for generating stable trajectories from unstable models. The new framework, called Invert-Linearize ILC (ILILC), is validated in simulation on a cart-and-pendulum system with model error, process noise, and measurement noise. Where preexisting Newton-based ILC diverges, ILILC with stable inversion converges, and does so in less than one third the number of trials necessary for the convergence of a gradient-descent-based ILC technique used as a benchmark.      
### 15.Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.07789.pdf)
>  Language models (LMs) pre-trained on massive amounts of text, in particular bidirectional encoder representations from Transformers (BERT), generative pre-training (GPT), and GPT-2, have become a key technology for many natural language processing tasks. In this paper, we present results using fine-tuned GPT, GPT-2, and their combination for automatic speech recognition (ASR). Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct product of the output probabilities is no longer a valid language prior probability. A conversion method is proposed to compute the correct language prior probability based on bidirectional LM outputs in a mathematically exact way. Experimental results on the widely used AMI and Switchboard ASR tasks showed that the combination of the fine-tuned GPT and GPT-2 outperformed the combination of three neural LMs with different architectures trained from scratch on the in-domain text by up to a 12% relative word error rate reduction (WERR). Furthermore, the proposed conversion for language prior probabilities enables BERT to receive an extra 3% relative WERR, and the combination of BERT, GPT and GPT-2 results in further improvements.      
### 16.Combining speakers of multiple languages to improve quality of neural voices  [ :arrow_down: ](https://arxiv.org/pdf/2108.07737.pdf)
>  In this work, we explore multiple architectures and training procedures for developing a multi-speaker and multi-lingual neural TTS system with the goals of a) improving the quality when the available data in the target language is limited and b) enabling cross-lingual synthesis. We report results from a large experiment using 30 speakers in 8 different languages across 15 different locales. The system is trained on the same amount of data per speaker. Compared to a single-speaker model, when the suggested system is fine tuned to a speaker, it produces significantly better quality in most of the cases while it only uses less than $40\%$ of the speaker's data used to build the single-speaker model. In cross-lingual synthesis, on average, the generated quality is within $80\%$ of native single-speaker models, in terms of Mean Opinion Score.      
### 17.Passivity-based control for haptic teleoperation of a legged manipulator in presence of time-delays  [ :arrow_down: ](https://arxiv.org/pdf/2108.07658.pdf)
>  When dealing with the haptic teleoperation of multi-limbed mobile manipulators, the problem of mitigating the destabilizing effects arising from the communication link between the haptic device and the remote robot has not been properly addressed. In this work, we propose a passive control architecture to haptically teleoperate a legged mobile manipulator, while remaining stable in the presence of time delays and frequency mismatches in the master and slave controllers. At the master side, a discrete-time energy modulation of the control input is proposed. At the slave side, passivity constraints are included in an optimization-based whole-body controller to satisfy the energy limitations. A hybrid teleoperation scheme allows the human operator to remotely operate the robot's end-effector while in stance mode, and its base velocity in locomotion mode. The resulting control architecture is demonstrated on a quadrupedal robot with an artificial delay added to the network.      
### 18.Wireless Federated Langevin Monte Carlo: Repurposing Channel Noise for Bayesian Sampling and Privacy  [ :arrow_down: ](https://arxiv.org/pdf/2108.07644.pdf)
>  Most works on federated learning (FL) focus on the most common frequentist formulation of learning whereby the goal is minimizing the global empirical loss. Frequentist learning, however, is known to be problematic in the regime of limited data as it fails to quantify epistemic uncertainty in prediction. Bayesian learning provides a principled solution to this problem by shifting the optimization domain to the space of distribution in the model parameters. This paper studies for the first time Bayesian FL in wireless systems by proposing and analyzing a gradient-based Markov Chain Monte Carlo (MCMC) method -- Wireless Federated Langevin Monte Carlo (WFLMC). The key idea of this work is to repurpose channel noise for the double role of seed randomness for MCMC sampling and of privacy-preserving mechanism. To this end, based on the analysis of the Wasserstein distance between sample distribution and global posterior distribution under privacy and power constraints, we introduce a power allocation strategy as the solution of a convex program. The analysis identifies distinct operating regimes in which the performance of the system is power-limited, privacy-limited, or limited by the requirement of MCMC sampling. Both analytical and simulation results demonstrate that, if the channel noise is properly accounted for under suitable conditions, it can be fully repurposed for both MCMC sampling and privacy preservation, obtaining the same performance as in an ideal communication setting that is not subject to privacy constraints.      
### 19.Look Who's Talking: Active Speaker Detection in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2108.07640.pdf)
>  In this work, we present a novel audio-visual dataset for active speaker detection in the wild. A speaker is considered active when his or her face is visible and the voice is audible simultaneously. Although active speaker detection is a crucial pre-processing step for many audio-visual tasks, there is no existing dataset of natural human speech to evaluate the performance of active speaker detection. We therefore curate the Active Speakers in the Wild (ASW) dataset which contains videos and co-occurring speech segments with dense speech activity labels. Videos and timestamps of audible segments are parsed and adopted from VoxConverse, an existing speaker diarisation dataset that consists of videos in the wild. Face tracks are extracted from the videos and active segments are annotated based on the timestamps of VoxConverse in a semi-automatic way. Two reference systems, a self-supervised system and a fully supervised one, are evaluated on the dataset to provide the baseline performances of ASW. Cross-domain evaluation is conducted in order to show the negative effect of dubbed videos in the training data.      
### 20.A rolled-off passivity theorem  [ :arrow_down: ](https://arxiv.org/pdf/2108.07634.pdf)
>  Given two nonlinear systems which only violate passivity when their incremental gains are sufficiently small, we give a condition for their negative feedback interconnection to have finite incremental gain, which generalizes the incremental small gain and incremental passivity theorems. The property may be determined graphically by plotting the Scaled Relative Graphs (SRGs) of the systems, which provides engineering significance to the mathematical result.      
### 21.Two-Timescale Design for Reconfigurable Intelligent Surface-Aided Massive MIMO Systems with Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2108.07622.pdf)
>  This paper investigates the two-timescale transmission design for reconfigurable intelligent surface (RIS)-aided massive multiple-input multiple-output (MIMO) systems, where the beamforming at the base station (BS) is adapted to the rapidly-changing instantaneous channel state information (CSI), while the passive beamforming at the RIS is adapted to the slowly-changing statistical CSI. <br>Specifically, we first propose a linear minimum mean square error (LMMSE) estimator to obtain the aggregated channel from the users to the BS in each channel coherence interval. Based on the estimated channel, we apply the low-complexity maximal ratio combining (MRC) beamforming at the BS, and then derive the ergodic achievable rate in a closed form expression. <br>To draw design insights, we perform a detailed theoretical analysis departing from the derived ergodic achievable rate. If the BS-RIS channel is Rician distributed, we prove that the transmit power can be scaled proportionally to $1/M$, as the number of BS antennas, $M$, grows to infinity while maintaining a non-zero rate. <br>If the BS-RIS channel is Rayleigh distributed, the transmit power can be scaled either proportionally to $1/\sqrt{M}$ as $M$ grows large, or proportionally to $1/N$ as the number of reflecting elements, $N$, grows large, while still maintaining a non-zero rate. <br>By capitalizing on the derived expression of the data rate under the statistical knowledge of the CSI, we maximize the minimum user rate by designing the passive beamforming at the RIS. <br>Numerical results confirm that, even in the presence of imperfect CSI, the integration of an RIS in massive MIMO systems results in promising performance gains. In addition, the obtained results reveal that it is favorable to place the RIS close to the users rather than close to the BS.      
### 22.How Powerful is Graph Convolution for Recommendation?  [ :arrow_down: ](https://arxiv.org/pdf/2108.07567.pdf)
>  Graph convolutional networks (GCNs) have recently enabled a popular class of algorithms for collaborative filtering (CF). Nevertheless, the theoretical underpinnings of their empirical successes remain elusive. In this paper, we endeavor to obtain a better understanding of GCN-based CF methods via the lens of graph signal processing. By identifying the critical role of smoothness, a key concept in graph signal processing, we develop a unified graph convolution-based framework for CF. We prove that many existing CF methods are special cases of this framework, including the neighborhood-based methods, low-rank matrix factorization, linear auto-encoders, and LightGCN, corresponding to different low-pass filters. Based on our framework, we then present a simple and computationally efficient CF baseline, which we shall refer to as Graph Filter based Collaborative Filtering (GF-CF). Given an implicit feedback matrix, GF-CF can be obtained in a closed form instead of expensive training with back-propagation. Experiments will show that GF-CF achieves competitive or better performance against deep learning-based methods on three well-known datasets, notably with a $70\%$ performance gain over LightGCN on the Amazon-book dataset.      
### 23.Revisiting State Augmentation methods for Reinforcement Learning with Stochastic Delays  [ :arrow_down: ](https://arxiv.org/pdf/2108.07555.pdf)
>  Several real-world scenarios, such as remote control and sensing, are comprised of action and observation delays. The presence of delays degrades the performance of reinforcement learning (RL) algorithms, often to such an extent that algorithms fail to learn anything substantial. This paper formally describes the notion of Markov Decision Processes (MDPs) with stochastic delays and shows that delayed MDPs can be transformed into equivalent standard MDPs (without delays) with significantly simplified cost structure. We employ this equivalence to derive a model-free Delay-Resolved RL framework and show that even a simple RL algorithm built upon this framework achieves near-optimal rewards in environments with stochastic delays in actions and observations. The delay-resolved deep Q-network (DRDQN) algorithm is bench-marked on a variety of environments comprising of multi-step and stochastic delays and results in better performance, both in terms of achieving near-optimal rewards and minimizing the computational overhead thereof, with respect to the currently established algorithms.      
### 24.Distributed Expectation Propagation Detection for Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2108.07498.pdf)
>  In cell-free massive MIMO networks, an efficient distributed detection algorithm is of significant importance. In this paper, we propose a distributed expectation propagation (EP) detector for cell-free massive MIMO. The detector is composed of two modules, a nonlinear module at the central processing unit (CPU) and a linear module at the access point (AP). The turbo principle in iterative decoding is utilized to compute and pass the extrinsic information between modules. An analytical framework is then provided to characterize the asymptotic performance of the proposed EP detector with a large number of antennas. Simulation results will show that the proposed method outperforms the distributed detectors in terms of bit-error-rate.      
### 25.Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model  [ :arrow_down: ](https://arxiv.org/pdf/2108.07467.pdf)
>  Abdominal auscultation is a convenient, safe and inexpensive method to assess bowel conditions, which is essential in neonatal care. It helps early detection of neonatal bowel dysfunctions and allows timely intervention. This paper presents a neonatal bowel sound detection method to assist the auscultation. Specifically, a Convolutional Neural Network (CNN) is proposed to classify peristalsis and non-peristalsis sounds. The classification is then optimized using a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is validated on abdominal sounds from 49 newborn infants admitted to our tertiary Neonatal Intensive Care Unit (NICU). The results show that the method can effectively detect bowel sounds with accuracy and area under curve (AUC) score being 89.81% and 83.96% respectively, outperforming 13 baseline methods. Furthermore, the proposed Laplace HSMM refinement strategy is proven capable to enhance other bowel sound detection models. The outcomes of this work have the potential to facilitate future telehealth applications for neonatal care. The source code of our work can be found at: <a class="link-external link-https" href="https://bitbucket.org/chirudeakin/neonatal-bowel-sound-classification/" rel="external noopener nofollow">this https URL</a>      
### 26.Transferring Knowledge with Attention Distillation for Multi-Domain Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07466.pdf)
>  Gradient-based attention modeling has been used widely as a way to visualize and understand convolutional neural networks. However, exploiting these visual explanations during the training of generative adversarial networks (GANs) is an unexplored area in computer vision research. Indeed, we argue that this kind of information can be used to influence GANs training in a positive way. For this reason, in this paper, it is shown how gradient based attentions can be used as knowledge to be conveyed in a teacher-student paradigm for multi-domain image-to-image translation tasks in order to improve the results of the student architecture. Further, it is demonstrated how "pseudo"-attentions can also be employed during training when teacher and student networks are trained on different domains which share some similarities. The approach is validated on multi-domain facial attributes transfer and human expression synthesis showing both qualitative and quantitative results.      
### 27.Diffeomorphic Particle Image Velocimetry  [ :arrow_down: ](https://arxiv.org/pdf/2108.07438.pdf)
>  The existing particle image velocimetry (PIV) do not consider the curvature effect of the non-straight particle trajectory, because it seems to be impossible to obtain the curvature information from a pair of particle images. As a result, the computed vector underestimates the real velocity due to the straight-line approximation, that further causes a systematic error for the PIV instrument. In this work, the particle curved trajectory between two recordings is firstly explained with the streamline segment of a steady flow (diffeomorphic transformation) instead of a single vector, and this idea is termed as diffeomorphic PIV. Specifically, a deformation field is introduced to describe the particle displacement, i.e., we try to find the optimal velocity field, of which the corresponding deformation vector field agrees with the particle displacement. Because the variation of the deformation function can be approximated with the variation of the velocity function, the diffeomorphic PIV can be implemented as iterative PIV. That says, the diffeomorphic PIV warps the images with deformation vector field instead of the velocity, and keeps the rest as same as iterative PIVs. Two diffeomorphic deformation schemes -- forward diffeomorphic deformation interrogation (FDDI) and central diffeomorphic deformation interrogation (CDDI) -- are proposed. Tested on synthetic images, the FDDI achieves significant accuracy improvement across different one-pass displacement estimators (cross-correlation, optical flow, deep learning flow). Besides, the results on three real PIV image pairs demonstrate the non-negligible curvature effect for CDI-based PIV, and our FDDI provides larger velocity estimation (more accurate) in the fast curvy streamline areas. The accuracy improvement of the combination of FDDI and accurate dense estimator means that our diffeomorphic PIV paves a new way for complex flow measurement.      
### 28.DeepEigen: Learning-based Modal Sound Synthesis with Acoustic Transfer Maps  [ :arrow_down: ](https://arxiv.org/pdf/2108.07425.pdf)
>  We present a novel learning-based approach to compute the eigenmodes and acoustic transfer data for the sound synthesis of arbitrary solid objects. Our approach combines two network-based solutions to formulate a complete learning-based 3D modal sound model. This includes a 3D sparse convolution network as the eigendecomposition solver and an encoder-decoder network for the prediction of the Far-Field Acoustic Transfer maps (FFAT Maps). We use our approach to compute the vibration modes (eigenmodes) and FFAT maps for each mode (acoustic data) for arbitrary-shaped objects at interactive rates without any precomputed dataset for any new object. Our experimental results demonstrate the effectiveness and benefits of our approach. We compare its accuracy and efficiency with physically-based sound synthesis methods.      
### 29.DRB-GAN: A Dynamic ResBlock Generative Adversarial Network for Artistic Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2108.07379.pdf)
>  The paper proposes a Dynamic ResBlock Generative Adversarial Network (DRB-GAN) for artistic style transfer. The style code is modeled as the shared parameters for Dynamic ResBlocks connecting both the style encoding network and the style transfer network. In the style encoding network, a style class-aware attention mechanism is used to attend the style feature representation for generating the style codes. In the style transfer network, multiple Dynamic ResBlocks are designed to integrate the style code and the extracted CNN semantic feature and then feed into the spatial window Layer-Instance Normalization (SW-LIN) decoder, which enables high-quality synthetic images with artistic style transfer. Moreover, the style collection conditional discriminator is designed to equip our DRB-GAN model with abilities for both arbitrary style transfer and collection style transfer during the training stage. No matter for arbitrary style transfer or collection style transfer, extensive experiments strongly demonstrate that our proposed DRB-GAN outperforms state-of-the-art methods and exhibits its superior performance in terms of visual quality and efficiency. Our source code is available at \color{magenta}{\url{<a class="link-external link-https" href="https://github.com/xuwenju123/DRB-GAN" rel="external noopener nofollow">this https URL</a>}}.      
### 30.Convolutive Prediction for Monaural Speech Dereverberation and Noisy-Reverberant Speaker Separation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07376.pdf)
>  A promising approach for speech dereverberation is based on supervised learning, where a deep neural network (DNN) is trained to predict the direct sound from noisy-reverberant speech. This data-driven approach is based on leveraging prior knowledge of clean speech patterns and does not explicitly exploit the linear-filter structure in reverberation, i.e., that reverberation results from a linear convolution between a room impulse response (RIR) and a dry source signal. In this work, we propose to exploit this linear-filter structure within a deep learning based monaural speech dereverberation framework. The key idea is to first estimate the direct-path signal of the target speaker using a DNN and then identify signals that are decayed and delayed copies of the estimated direct-path signal, as these can be reliably considered as reverberation. They can be either directly removed for dereverberation, or used as extra features for another DNN to perform better dereverberation. To identify the copies, we estimate the underlying filter (or RIR) by efficiently solving a linear regression problem per frequency in the time-frequency domain. We then modify the proposed algorithm for speaker separation in reverberant and noisy-reverberant conditions. State-of-the-art speech dereverberation and speaker separation results are obtained on the REVERB, SMS-WSJ, and WHAMR! datasets.      
### 31.CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects  [ :arrow_down: ](https://arxiv.org/pdf/2108.07368.pdf)
>  Segmenting medical images accurately and reliably is important for disease diagnosis and treatment. It is a challenging task because of the wide variety of objects' sizes, shapes, and scanning modalities. Recently, many convolutional neural networks (CNN) have been designed for segmentation tasks and achieved great success. Few studies, however, have fully considered the sizes of objects and thus most demonstrate poor performance on segmentation of small objects segmentation. This can have significant impact on early detection of disease. This paper proposes a Context Axial Reserve Attention Network (CaraNet) to improve the segmentation performance on small objects compared with recent state-of-the-art models. We test our CaraNet on brain tumor (BraTS 2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300 and ETIS-LaribPolypDB) segmentation. Our CaraNet not only achieves the top-rank mean Dice segmentation accuracy, but also shows a distinct advantage in segmentation of small medical objects.      
### 32.Density control of interacting agent systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.07342.pdf)
>  We consider the problem of controlling the group behavior of a large number of dynamic systems that are constantly interacting with each other. These systems are assumed to have identical dynamics (e.g., birds flock, robot swarm) and their group behavior can be modeled by a distribution. Thus, this problem can be viewed as an optimal control problem over the space of distributions. We propose a novel algorithm to compute a feedback control strategy so that, when adopted by the agents, the distribution of them would be transformed from an initial one to a target one over a finite time window. Our method is built on optimal transport theory but differs significantly from existing work in this area in that our method models the interactions among agents explicitly. From an algorithmic point of view, our algorithm is based on a generalized version of the proximal gradient descent algorithm and has a convergence guarantee with a sublinear rate. We further extend our framework to account for the scenarios where the agents are from multiple species. In the linear quadratic setting, the solution is characterized by coupled Riccati equations which can be solved in closed-form. Finally, several numerical examples are presented to illustrate our framework.      
### 33.Correlation of Golay-Rudin-Shapiro Sequences  [ :arrow_down: ](https://arxiv.org/pdf/2108.07318.pdf)
>  Sequences with low aperiodic autocorrelation and crosscorrelation are used in communications and remote sensing. Golay and Shapiro independently devised a recursive construction that produces families of complementary pairs of binary sequences. In the simplest case, the construction produces the Rudin-Shapiro sequences, and in general it produces what we call Golay-Rudin-Shapiro sequences. Calculations by Littlewood show that the Rudin-Shapiro sequences have low mean square autocorrelation. A sequence's peak sidelobe level is its largest magnitude of autocorrelation over all nonzero shifts. Høholdt, Jensen, and Justesen showed that there is some undetermined positive constant $A$ such that the peak sidelobe level of a Rudin-Shapiro sequence of length $2^n$ is bounded by $A(1.842626\ldots)^n$, where $1.842626\ldots$ is the positive real root of $X^4-3 X-6$. We show that the peak sidelobe level is bounded by $5(1.658967\ldots)^{n-4}$, where $1.658967\ldots$ is the real root of $X^3+X^2-2 X-4$. Any exponential bound with lower base will fail to be true for almost all $n$, and any bound with the same base but a lower constant prefactor will fail to be true for at least one $n$. We provide a similar bound on the peak crosscorrelation (largest magnitude of crosscorrelation over all shifts) between the sequences in each Rudin-Shapiro pair. The methods that we use generalize to all families of complementary pairs produced by the Golay-Rudin-Shapiro recursion, for which we obtain bounds on the peak sidelobe level and peak crosscorrelation with the same exponential growth rate as we obtain for the original Rudin-Shapiro sequences.      
