# ArXiv eess --Thu, 19 Aug 2021
### 1.Deep Reparametrization of Multi-Frame Super-Resolution and Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2108.08286.pdf)
>  We propose a deep reparametrization of the maximum a posteriori formulation commonly employed in multi-frame image restoration tasks. Our approach is derived by introducing a learned error metric and a latent representation of the target image, which transforms the MAP objective to a deep feature space. The deep reparametrization allows us to directly model the image formation process in the latent space, and to integrate learned image priors into the prediction. Our approach thereby leverages the advantages of deep learning, while also benefiting from the principled multi-frame fusion provided by the classical MAP formulation. We validate our approach through comprehensive experiments on burst denoising and burst super-resolution datasets. Our approach sets a new state-of-the-art for both tasks, demonstrating the generality and effectiveness of the proposed formulation.      
### 2.Modular Sparse Conical Multi-beam Phased Array Design for Air Traffic Control Radar  [ :arrow_down: ](https://arxiv.org/pdf/2108.08240.pdf)
>  The design of a conical phased array antenna for air traffic control (ATC) radar systems is addressed in this work. The array, characterized by a fully digital beam-forming (DBF) architecture, is composed of equal vertical modules consisting of linear sparse arrays able to generate on receive multiple instantaneous beams pointing along different elevation directions. The synthesis problem is cast in the Compressive Sensing (CS) framework to achieve the best trade-off between the antenna complexity (i.e., minimum number of array elements and/or radio frequency components) and radiation performance (i.e., matching of a set of reference patterns). Towards this aim, the positions of the array elements and the set of complex element excitations of each beam are jointly defined through a customized CS-based optimization tool. Representative numerical results, concerned with ideal as well as real antenna models, are reported and discussed to validate the proposed design strategy and point out the features of the deigned modular sparse arrays also in comparison with those obtained from conventional arrays with uniformly spaced elements.      
### 3.Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2108.08202.pdf)
>  Internet video delivery has undergone a tremendous explosion of growth over the past few years. However, the quality of video delivery system greatly depends on the Internet bandwidth. Deep Neural Networks (DNNs) are utilized to improve the quality of video delivery recently. These methods divide a video into chunks, and stream LR video chunks and corresponding content-aware models to the client. The client runs the inference of models to super-resolve the LR chunks. Consequently, a large number of models are streamed in order to deliver a video. In this paper, we first carefully study the relation between models of different chunks, then we tactfully design a joint training framework along with the Content-aware Feature Modulation (CaFM) layer to compress these models for neural video delivery. {\bf With our method, each video chunk only requires less than $1\% $ of original parameters to be streamed, achieving even better SR performance.} We conduct extensive experiments across various SR backbones, video time length, and scaling factors to demonstrate the advantages of our method. Besides, our method can be also viewed as a new approach of video coding. Our primary experiments achieve better video quality compared with the commercial H.264 and H.265 standard under the same storage cost, showing the great potential of the proposed method. Code is available at:\url{<a class="link-external link-https" href="https://github.com/Neural-video-delivery/CaFM-Pytorch-ICCV2021" rel="external noopener nofollow">this https URL</a>}      
### 4.Structure Parameter Optimized Kernel Based Online Prediction with a Generalized Optimization Strategy for Nonstationary Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2108.08180.pdf)
>  In this paper, sparsification techniques aided online prediction algorithms in a reproducing kernel Hilbert space are studied for nonstationary time series. The online prediction algorithms as usual consist of the selection of kernel structure parameters and the kernel weight vector updating. For structure parameters, the kernel dictionary is selected by some sparsification techniques with online selective modeling criteria, and moreover the kernel covariance matrix is intermittently optimized in the light of the covariance matrix adaptation evolution strategy (CMA-ES). Optimizing the real symmetric covariance matrix can not only improve the kernel structure's flexibility by the cross relatedness of the input variables, but also partly alleviate the prediction uncertainty caused by the kernel dictionary selection for nonstationary time series. In order to sufficiently capture the underlying dynamic characteristics in prediction-error time series, a generalized optimization strategy is designed to construct the kernel dictionary sequentially in multiple kernel connection modes. The generalized optimization strategy provides a more self-contained way to construct the entire kernel connections, which enhances the ability to adaptively track the changing dynamic characteristics. Numerical simulations have demonstrated that the proposed approach has superior prediction performance for nonstationary time series.      
### 5.Gastric Cancer Detection from X-ray Images Using Effective Data Augmentation and Hard Boundary Box Training  [ :arrow_down: ](https://arxiv.org/pdf/2108.08158.pdf)
>  X-ray examination is suitable for screening of gastric cancer. Compared to endoscopy, which can only be performed by doctors, X-ray imaging can also be performed by radiographers, and thus, can treat more patients. However, the diagnostic accuracy of gastric radiographs is as low as 85%. To address this problem, highly accurate and quantitative automated diagnosis using machine learning needs to be performed. This paper proposes a diagnostic support method for detecting gastric cancer sites from X-ray images with high accuracy. The two new technical proposal of the method are (1) stochastic functional gastric image augmentation (sfGAIA), and (2) hard boundary box training (HBBT). The former is a probabilistic enhancement of gastric folds in X-ray images based on medical knowledge, whereas the latter is a recursive retraining technique to reduce false positives. We use 4,724 gastric radiographs of 145 patients in clinical practice and evaluate the cancer detection performance of the method in a patient-based five-group cross-validation. The proposed sfGAIA and HBBT significantly enhance the performance of the EfficientDet-D7 network by 5.9% in terms of the F1-score, and our screening method reaches a practical screening capability for gastric cancer (F1: 57.8%, recall: 90.2%, precision: 42.5%).      
### 6.Multi-Target Localization Using Polarization Sensitive Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2108.08151.pdf)
>  In this work we develop clustering techniques for the Bearing Only Target Localization (BOTL) problem. Our scenario has a receiver move along some path, generating bearing estimates on some interval. Multiple emitting targets exist in the environment, and may be physically close with respect to the receiver distance. The first method is iterative and uses only a series of observed bearings to multiple targets to establish clusters. In each iteration, target positions are estimated using a nonlinear least squares solution. The second technique uses additional polarization information, and is shown to be more effective while requiring more information. In addition the second technique is non-iterative and requires far less computation. In this work we presume knowledge of the number of targets. We conclude by providing simulations of our method and show that the proposed approach outperforms previously proposed methods.      
### 7.DRDrV3: Complete Lesion Detection in Fundus Images Using Mask R-CNN, Transfer Learning, and LSTM  [ :arrow_down: ](https://arxiv.org/pdf/2108.08095.pdf)
>  Medical Imaging is one of the growing fields in the world of computer vision. In this study, we aim to address the Diabetic Retinopathy (DR) problem as one of the open challenges in medical imaging. In this research, we propose a new lesion detection architecture, comprising of two sub-modules, which is an optimal solution to detect and find not only the type of lesions caused by DR, their corresponding bounding boxes, and their masks; but also the severity level of the overall case. Aside from traditional accuracy, we also use two popular evaluation criteria to evaluate the outputs of our models, which are intersection over union (IOU) and mean average precision (mAP). We hypothesize that this new solution enables specialists to detect lesions with high confidence and estimate the severity of the damage with high accuracy.      
### 8.Combined neural network-based intra prediction and transform selection  [ :arrow_down: ](https://arxiv.org/pdf/2108.08087.pdf)
>  The interactions between different tools added successively to a block-based video codec are critical to its rate-distortion efficiency. In particular, when deep neural network-based intra prediction modes are inserted into a block-based video codec, as the neural network-based prediction function cannot be easily characterized, the adaptation of the transform selection process to the new modes can hardly be performed manually. That is why this paper presents a combined neural network-based intra prediction and transform selection for a block-based video codec. When putting a single neural network-based intra prediction mode and the learned prediction of the selected LFNST pair index into VTM-8.0, -3.71%, -3.17%, and -3.37% of mean BD-rate reduction in all-intra is obtained.      
### 9.Concurrent Learning Based Dual Control for Exploration and Exploitation in Autonomous Search  [ :arrow_down: ](https://arxiv.org/pdf/2108.08062.pdf)
>  In this paper, a concurrent learning framework is developed for source search in an unknown environment using autonomous platforms equipped with onboard sensors. Distinct from the existing solutions that require significant computational power for Bayesian estimation and path planning, the proposed solution is computationally affordable for onboard processors. A new concept of concurrent learning using multiple parallel estimators is proposed to learn the operational environment and quantify estimation uncertainty. The search agent is empowered with dual capability of exploiting current estimated parameters to track the source and probing the environment to reduce the impacts of uncertainty, namely Concurrent Learning for Exploration and Exploitation (CLEE). In this setting, the control action not only minimises the tracking error between future agent's position and estimated source location, but also the uncertainty of predicted estimation. More importantly, the rigorous proven properties such as the convergence of CLEE algorithm are established under mild assumptions on sensor noises, and the impact of noises on the search performance is examined. Simulation results are provided to validate the effectiveness of the proposed CLEE algorithm. Compared with the information-theoretic approach, CLEE not only guarantees convergence, but produces better search performance and consumes much less computational time.      
### 10.Optimal Scheduling of Integrated Demand Response-Enabled Community Integrated Energy Systems in Uncertain Environments  [ :arrow_down: ](https://arxiv.org/pdf/2108.08055.pdf)
>  The community integrated energy system (CIES) is an essential energy internet carrier that has recently been the focus of much attention. A scheduling model based on chance-constrained programming is proposed for integrated demand response (IDR)-enabled CIES in uncertain environments to minimize the system operating costs, where an IDR program is used to explore the potential interaction ability of electricity-gas-heat flexible loads and electric vehicles. Moreover, power to gas (P2G) and micro-gas turbine (MT), as links of multi-energy carriers, are adopted to strengthen the coupling of different energy subsystems. Sequence operation theory (SOT) and linearization methods are employed to transform the original model into a solvable mixed-integer linear programming model. Simulation results on a practical CIES in North China demonstrate an improvement in the CIES operational economy via the coordination of IDR and renewable uncertainties, with P2G and MT enhancing the system operational flexibility and user comprehensive satisfaction. The CIES operation is able to achieve a trade-off between economy and system reliability by setting a suitable confidence level for the spinning reserve constraints. Besides, the proposed solution method outperforms the Hybrid Intelligent Algorithm in terms of both optimization results and calculation efficiency.      
### 11.Model Predictive Control with Models of Different Granularity and a Non-uniformly Spaced Prediction Horizon  [ :arrow_down: ](https://arxiv.org/pdf/2108.08014.pdf)
>  Horizon length and model accuracy are defining factors when designing a Model Predictive Controller. While long horizons and detailed models have a positive effect on control performance, computational complexity increases. As predictions become less precise over the horizon length, it is worth investigating a combination of different models and varying time step size. Here, we propose a Model Predictive Control scheme that splits the prediction horizon into two segments. A detailed model is used for the short-term prediction horizon and a simplified model with an increased sampling time is employed for the long-term horizon. This approach combines the advantage of a long prediction horizon with a reduction of computational effort due to a simplified model and less decision variables. The presented Model Predictive Control is recursively feasible. A simulation study demonstrates the effectiveness of the proposed method: employing a long prediction horizon with advantages regarding computational complexity.      
### 12.Adaptive Radar Detection in Heterogeneous Clutter-dominated Environments  [ :arrow_down: ](https://arxiv.org/pdf/2108.08011.pdf)
>  In this paper, we propose a new solution for the detection problem of a coherent target in heterogeneous environments. Specifically, we first assume that clutter returns from different range bins share the same covariance structure but different power levels. This model meets the experimental evidence related to non-Gaussian and non-homogeneous scenarios. Then, unlike existing solutions that are based upon estimate and plug methods, we propose an approximation of the generalized likelihood ratio test where the maximizers of the likelihoods are obtained through an alternating estimation procedure. Remarkably, we also prove that such estimation procedure leads to an architecture possessing the constant false alarm rate (CFAR) when a specific initialization is used. The performance analysis, carried out on simulated as well as measured data and in comparison with suitable well-known competitors, highlights that the proposed architecture can overcome the CFAR competitors and exhibits a limited loss with respect to the other non-CFAR detectors.      
### 13.Nonlinear Autoregression with Convergent Dynamics on Novel Computational Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2108.08001.pdf)
>  Nonlinear stochastic modeling is useful for describing complex engineering systems. Meanwhile, neuromorphic (brain-inspired) computing paradigms are developing to tackle tasks that are challenging and resource intensive on digital computers. An emerging scheme is reservoir computing which exploits nonlinear dynamical systems for temporal information processing. This paper introduces reservoir computers with output feedback as stationary and ergodic infinite-order nonlinear autoregressive models. We highlight the versatility of this approach by employing classical and quantum reservoir computers to model synthetic and real data sets, further exploring their potential for control applications.      
### 14.Two Streams and Two Resolution Spectrograms Model for End-to-end Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.07980.pdf)
>  Transformer has shown tremendous progress in Automatic Speech Recognition (ASR), outperforming recurrent neural network-based approaches. Transformer architecture is good at parallelizing data to accelerate as well as capturing content-based global interaction. However, most studies with Transfomer have been utilized only shallow features extracted from the backbone without taking advantage of the deep feature that possesses invariant property. In this paper, we propose a novel framework with two streams that consist of different resolution spectrograms for each steam aiming to capture both shallow and deep features. The feature extraction module consists of a deep network for small resolution spectrogram and a shallow network for large resolution spectrogram. The backbone obtains not only detailed acoustic information for speech-text alignment but also sentence invariant features such as speaker information. Both features are fused with our proposed fusion method and then input into the Transformer encoder-decoder. With our method, the proposed framework shows competitive performance on Mandarin corpus. It outperforms various current state-of-the-art results on the HKUST Mandarian telephone ASR benchmark with a CER of 21.08. To the best of our knowledge, this is the first investigation of incorporating deep features to the backbone.      
### 15.A New Journey from SDRTV to HDRTV  [ :arrow_down: ](https://arxiv.org/pdf/2108.07978.pdf)
>  Nowadays modern displays are capable to render video content with high dynamic range (HDR) and wide color gamut (WCG). However, most available resources are still in standard dynamic range (SDR). Therefore, there is an urgent demand to transform existing SDR-TV contents into their HDR-TV versions. In this paper, we conduct an analysis of SDRTV-to-HDRTV task by modeling the formation of SDRTV/HDRTV content. Base on the analysis, we propose a three-step solution pipeline including adaptive global color mapping, local enhancement and highlight generation. Moreover, the above analysis inspires us to present a lightweight network that utilizes global statistics as guidance to conduct image-adaptive color mapping. In addition, we construct a dataset using HDR videos in HDR10 standard, named HDRTV1K, and select five metrics to evaluate the results of SDRTV-to-HDRTV algorithms. Furthermore, our final results achieve state-of-the-art performance in quantitative comparisons and visual quality. The code and dataset are available at <a class="link-external link-https" href="https://github.com/chxy95/HDRTVNet" rel="external noopener nofollow">this https URL</a>.      
### 16.FDN: Finite Difference Network with Hierachical Convolutional Features for Text-independent Speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2108.07974.pdf)
>  Recently, directly utilize raw waveforms as input is widely explored for the speaker verification system. For example, RawNet [1] and RawNet2 [2] extract feature embeddings from raw waveforms, which largely reduce the front-end computation and achieve state-of-the-art performance. However, they do not consider the speech speed influence which is different from person to person. In this paper, we propose a novel finite-difference network to obtain speaker embeddings. It incorporates speaker speech speed by computing the finite difference between adjacent time speech pieces. Furthermore, we design a hierarchical layer to capture multiscale speech speed features to improve the system accuracy. The speaker embeddings is then input into the GRU to aggregate utterance-level features before the softmax loss. Experiment results on official VoxCeleb1 test data and expanded evaluation on VoxCeleb1-E and VoxCeleb-H protocols show our method outperforms existing state-of-the-art systems. To facilitate further research, code is available at <a class="link-external link-https" href="https://github.com/happyjin/FDN" rel="external noopener nofollow">this https URL</a>      
### 17.Thermal Image Processing via Physics-Inspired Deep Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.07973.pdf)
>  We introduce DeepIR, a new thermal image processing framework that combines physically accurate sensor modeling with deep network-based image representation. Our key enabling observations are that the images captured by thermal sensors can be factored into slowly changing, scene-independent sensor non-uniformities (that can be accurately modeled using physics) and a scene-specific radiance flux (that is well-represented using a deep network-based regularizer). DeepIR requires neither training data nor periodic ground-truth calibration with a known black body target--making it well suited for practical computer vision tasks. We demonstrate the power of going DeepIR by developing new denoising and super-resolution algorithms that exploit multiple images of the scene captured with camera jitter. Simulated and real data experiments demonstrate that DeepIR can perform high-quality non-uniformity correction with as few as three images, achieving a 10dB PSNR improvement over competing approaches.      
### 18.Scalable regret for learning to control network-coupled subsystems with unknown dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2108.07970.pdf)
>  We consider the problem of controlling an unknown linear quadratic Gaussian (LQG) system consisting of multiple subsystems connected over a network. Our goal is to minimize and quantify the regret (i.e. loss in performance) of our strategy with respect to an oracle who knows the system model. Viewing the interconnected subsystems globally and directly using existing LQG learning algorithms for the global system results in a regret that increases super-linearly with the number of subsystems. Instead, we propose a new Thompson sampling based learning algorithm which exploits the structure of the underlying network. We show that the expected regret of the proposed algorithm is bounded by $\tilde{\mathcal{O}} \big( n \sqrt{T} \big)$ where $n$ is the number of subsystems, $T$ is the time horizon and the $\tilde{\mathcal{O}}(\cdot)$ notation hides logarithmic terms in $n$ and $T$. Thus, the regret scales linearly with the number of subsystems. We present numerical experiments to illustrate the salient features of the proposed algorithm.      
### 19.A Novel Formula Calculating the Dynamic State Error and Its Application in UAV Tracking Control Problem  [ :arrow_down: ](https://arxiv.org/pdf/2108.07968.pdf)
>  This paper gives a novel formula (Copenhagen Limit) to calculate/estimate the dynamic state error of a system without a feedforward signal. Copenhagen Limit is in the form of a limit and finds the dynamic error in an analytical solution. It can be used to design the controller in a tracking control problem. A numerical example is displayed to illustrate the accuracy of the Copenhagen Limit. Besides, the controller of a UAV (quadrotor) is designed using the Copenhagen Limit in a trajectory-tracking problem. The result of it is also demonstrated and analyzed.      
### 20.A Simple Framework for 3D Lensless Imaging with Programmable Masks  [ :arrow_down: ](https://arxiv.org/pdf/2108.07966.pdf)
>  Lensless cameras provide a framework to build thin imaging systems by replacing the lens in a conventional camera with an amplitude or phase mask near the sensor. Existing methods for lensless imaging can recover the depth and intensity of the scene, but they require solving computationally-expensive inverse problems. Furthermore, existing methods struggle to recover dense scenes with large depth variations. In this paper, we propose a lensless imaging system that captures a small number of measurements using different patterns on a programmable mask. In this context, we make three contributions. First, we present a fast recovery algorithm to recover textures on a fixed number of depth planes in the scene. Second, we consider the mask design problem, for programmable lensless cameras, and provide a design template for optimizing the mask patterns with the goal of improving depth estimation. Third, we use a refinement network as a post-processing step to identify and remove artifacts in the reconstruction. These modifications are evaluated extensively with experimental results on a lensless camera prototype to showcase the performance benefits of the optimized masks and recovery algorithms over the state of the art.      
### 21.Learning Conditional Knowledge Distillation for Degraded-Reference Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2108.07948.pdf)
>  An important scenario for image quality assessment (IQA) is to evaluate image restoration (IR) algorithms. The state-of-the-art approaches adopt a full-reference paradigm that compares restored images with their corresponding pristine-quality images. However, pristine-quality images are usually unavailable in blind image restoration tasks and real-world scenarios. In this paper, we propose a practical solution named degraded-reference IQA (DR-IQA), which exploits the inputs of IR models, degraded images, as references. Specifically, we extract reference information from degraded images by distilling knowledge from pristine-quality images. The distillation is achieved through learning a reference space, where various degraded images are encouraged to share the same feature statistics with pristine-quality images. And the reference space is optimized to capture deep image priors that are useful for quality assessment. Note that pristine-quality images are only used during training. Our work provides a powerful and differentiable metric for blind IRs, especially for GAN-based methods. Extensive experiments show that our results can even be close to the performance of full-reference settings.      
### 22.Calibration Method of the Monocular Omnidirectional Stereo Camera  [ :arrow_down: ](https://arxiv.org/pdf/2108.07936.pdf)
>  Compact and low-cost devices are needed for autonomous driving to image and measure distances to objects 360-degree around. We have been developing an omnidirectional stereo camera exploiting two hyperbolic mirrors and a single set of a lens and sensor, which makes this camera compact and cost efficient. We establish a new calibration method for this camera considering higher-order radial distortion, detailed tangential distortion, an image sensor tilt, and a lens-mirror offset. Our method reduces the calibration error by 6.0 and 4.3 times for the upper- and lower-view images, respectively. The random error of the distance measurement is 4.9% and the systematic error is 5.7% up to objects 14 meters apart, which is improved almost nine times compared to the conventional method. The remaining distance errors is due to a degraded optical resolution of the prototype, which we plan to make further improvements as future work.      
### 23.Compact Cooperative Adaptive Cruise Control for Energy Saving: Air Drag Modelling and Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07911.pdf)
>  This paper studies the value of communicated motion predictions in the longitudinal control of connected automated vehicles (CAVs). We focus on a safe cooperative adaptive cruise control (CACC) design and analyze the value of vehicle-to-vehicle (V2V) communication in the presence of uncertain front vehicle acceleration. The interest in CACC is motivated by the potential improvement in energy consumption and road throughput. In order to quantify this potential, we characterize experimentally the relationship between inter-vehicular gap, vehicle speed, and (reduction of) energy consumption for a compact plug-in hybrid electric vehicle. The resulting model is leveraged to show efficacy of our control design, which pursues small inter-vehicle gaps between consecutive CAVs and, therefore, improved energy efficiency. Our proposed control design is based on a robust model predictive control framework to systematically account for the system uncertainties. We present a set of thorough simulations aimed at quantifying energy efficiency improvement when vehicle states and predictions exchanged via V2V communication are used in the control law.      
### 24.Experimental Study of Outdoor UAV Localization and Tracking using Passive RF Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2108.07857.pdf)
>  Extensive use of unmanned aerial vehicles (UAVs) is expected to raise privacy and security concerns among individuals and communities. In this context, the detection and localization of UAVs will be critical for maintaining safe and secure airspace in the future. In this work, Keysight N6854A radio frequency (RF) sensors are used to detect and locate a UAV by passively monitoring the signals emitted from the UAV. First, the Keysight sensor detects the UAV by comparing the received RF signature with various other UAVs' RF signatures in the Keysight database using an envelope detection algorithm. Afterward, time difference of arrival (TDoA) based localization is performed by a central controller using the sensor data, and the drone is localized with some error. To mitigate the localization error, implementation of an extended Kalman filter~(EKF) is proposed in this study. The performance of the proposed approach is evaluated on a realistic experimental dataset. EKF requires basic assumptions on the type of motion throughout the trajectory, i.e., the movement of the object is assumed to fit some motion model~(MM) such as constant velocity (CV), constant acceleration (CA), and constant turn (CT). In the experiments, an arbitrary trajectory is followed, therefore it is not feasible to fit the whole trajectory into a single MM. Consequently, the trajectory is segmented into sub-parts and a different MM is assumed in each segment while building the EKF model. Simulation results demonstrate an improvement in error statistics when EKF is used if the MM assumption aligns with the real motion.      
### 25.OncoPetNet: A Deep Learning based AI system for mitotic figure counting on H&amp;E stained whole slide digital images in a large veterinary diagnostic lab setting  [ :arrow_down: ](https://arxiv.org/pdf/2108.07856.pdf)
>  Background: Histopathology is an important modality for the diagnosis and management of many diseases in modern healthcare, and plays a critical role in cancer care. Pathology samples can be large and require multi-site sampling, leading to upwards of 20 slides for a single tumor, and the human-expert tasks of site selection and and quantitative assessment of mitotic figures are time consuming and subjective. Automating these tasks in the setting of a digital pathology service presents significant opportunities to improve workflow efficiency and augment human experts in practice. Approach: Multiple state-of-the-art deep learning techniques for histopathology image classification and mitotic figure detection were used in the development of OncoPetNet. Additionally, model-free approaches were used to increase speed and accuracy. The robust and scalable inference engine leverages Pytorch's performance optimizations as well as specifically developed speed up techniques in inference. Results: The proposed system, demonstrated significantly improved mitotic counting performance for 41 cancer cases across 14 cancer types compared to human expert baselines. In 21.9% of cases use of OncoPetNet led to change in tumor grading compared to human expert evaluation. In deployment, an effective 0.27 min/slide inference was achieved in a high throughput veterinary diagnostic pathology service across 2 centers processing 3,323 digital whole slide images daily. Conclusion: This work represents the first successful automated deployment of deep learning systems for real-time expert-level performance on important histopathology tasks at scale in a high volume clinical practice. The resulting impact outlines important considerations for model development, deployment, clinical decision making, and informs best practices for implementation of deep learning systems in digital histopathology practices.      
### 26.Applying Intelligent Reflector Surfaces for Detecting Respiratory Aerosol Cloud using Terahertz Signals  [ :arrow_down: ](https://arxiv.org/pdf/2108.07834.pdf)
>  The recent COVID-19 pandemic has driven researchers from different spectrum to develop novel solutions that can improve detection and understanding of SARS-CoV-2 virus. In this article we propose the use of Intelligent Reflector Surface (IRS) emitting terahertz signals to detect airborne respiratory aerosol cloud that are secreted from people. Our proposed approach makes use of future IRS infrastructure to extend beyond communication functionality by adding environmental scanning for aerosol clouds. Simulations have also been conducted to analyze the accuracy of aerosol cloud detection based on a signal scanning and path optimization algorithm. Utilizing IRS for detecting respiratory aerosol cloud can lead to new added value of telecommunication infrastructures for sensor monitoring data that can be used for public health.      
### 27.An Algorithmic Safety VEST For Li-ion Batteries During Fast Charging  [ :arrow_down: ](https://arxiv.org/pdf/2108.07833.pdf)
>  Fast charging of lithium-ion batteries is crucial to increase desirability for consumers and hence accelerate the adoption of electric vehicles. A major barrier to shorter charge times is the accelerated aging of the battery at higher charging rates, which can be driven by lithium plating, increased solid electrolyte interphase growth due to elevated temperatures, and particle cracking due to mechanical stress. Lithium plating depends on the overpotential of the negative electrode, and mechanical stress depends on the concentration gradient, both of which cannot be measured directly. Techniques based on physics-based models of the battery and optimal control algorithms have been developed to this end. While these methods show promise in reducing degradation, their optimization algorithms' complexity can limit their implementation. In this paper, we present a method based on the constant current constant voltage (CC-CV) charging scheme, called CC-CV$\eta \sigma$T (VEST). The new approach is simpler to implement and can be used with any model to impose varying levels of constraints on variables pertinent to degradation, such as plating potential and mechanical stress. We demonstrate the new CC-CV$\eta \sigma$T charging using an electrochemical model with mechanical and thermal effects included. Furthermore, we discuss how uncertainties can be accounted for by considering safety margins for the plating and stress constraints.      
### 28.Two parameter Leak Estimation in Non invasive Ventilation  [ :arrow_down: ](https://arxiv.org/pdf/2108.08278.pdf)
>  In this paper we present a method for the estimation of leaks in non-invasive ventilation. Accurate estimation of leaks is a key component of a ventilator, since it determines the ventilator performance in terms of patient-ventilator synchrony and air volume delivery. In particular, in non-invasive ventilation, the patient flow is significantly different from the flow measured at the ventilator outlet. This is mostly due to the vent orifice along the tube that is used for exhalation, but also to the non-intentional leaks that occur elsewhere in the circuit (e.g., at the mask). Such leaks are traditionally quantified via a model with two parameters, but only one of them is continually updated - the other is fixed. The new algorithm allows for breath-by-breath update of both parameters. This was made possible by leveraging a model describing the patient respiratory mechanics.      
### 29.TB-ICT: A Trustworthy Blockchain-Enabled System for Indoor COVID-19 Contact Tracing  [ :arrow_down: ](https://arxiv.org/pdf/2108.08275.pdf)
>  Recently, as a consequence of the COVID-19 pandemic, dependence on Contact Tracing (CT) models has significantly increased to prevent spread of this highly contagious virus and be prepared for the potential future ones. Since the spreading probability of the novel coronavirus in indoor environments is much higher than that of the outdoors, there is an urgent and unmet quest to develop/design efficient, autonomous, trustworthy, and secure indoor CT solutions. Despite such an urgency, this field is still in its infancy. The paper addresses this gap and proposes the Trustworthy Blockchain-enabled system for Indoor Contact Tracing (TB-ICT) framework. The TB-ICT framework is proposed to protect privacy and integrity of the underlying CT data from unauthorized access. More specifically, it is a fully distributed and innovative blockchain platform exploiting the proposed dynamic Proof of Work (dPoW) credit-based consensus algorithm coupled with Randomized Hash Window (W-Hash) and dynamic Proof of Credit (dPoC) mechanisms to differentiate between honest and dishonest nodes. The TB-ICT not only provides a decentralization in data replication but also quantifies the node's behavior based on its underlying credit-based mechanism. For achieving high localization performance, we capitalize on availability of Internet of Things (IoT) indoor localization infrastructures, and develop a data driven localization model based on Bluetooth Low Energy (BLE) sensor measurements. The simulation results show that the proposed TB-ICT prevents the COVID-19 from spreading by implementation of a highly accurate contact tracing model while improving the users' privacy and security.      
### 30.Adaptive Rate NOMA for Cellular IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08235.pdf)
>  Internet-of-Things (IoT) technology is envisioned to enable a variety of real-time applications by interconnecting billions of sensors/devices deployed to observe some random physical processes. These IoT devices rely on low-power wide-area wireless connectivity for transmitting, mostly fixed- but small-size, status updates of their associated random processes. The cellular networks are seen as a natural candidate for providing reliable wireless connectivity to IoT devices. However, the conventional orthogonal multiple access (OMA) to these massive number of devices is expected to degrade the spectral efficiency. As a promising alternative to OMA, the cellular base stations (BSs) can employ non-orthogonal multiple access (NOMA) for the uplink transmissions of mobile users and IoT devices. In particular, the uplink NOMA can be configured such that the mobile user can adapt transmission rate based on its channel condition while the IoT device transmits at a fixed rate. For this setting, we analyze the ergodic capacity of mobile users and the mean local delay of IoT devices using stochastic geometry. Our analysis demonstrates that the above NOMA configuration can provide better ergodic capacity for mobile users compare to OMA when IoT devices' delay constraint is strict. Furthermore, we also show that NOMA can support a larger packet size for IoT devices than OMA under the same delay constraint.      
### 31.Predicting Dynamic Stability of Power Grids using Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08230.pdf)
>  The prediction of dynamical stability of power grids becomes more important and challenging with increasing shares of renewable energy sources due to their decentralized structure, reduced inertia and volatility. We investigate the feasibility of applying graph neural networks (GNN) to predict dynamic stability of synchronisation in complex power grids using the single-node basin stability (SNBS) as a measure. To do so, we generate two synthetic datasets for grids with 20 and 100 nodes respectively and estimate SNBS using Monte-Carlo sampling. Those datasets are used to train and evaluate the performance of eight different GNN-models. All models use the full graph without simplifications as input and predict SNBS in a nodal-regression-setup. We show that SNBS can be predicted in general and the performance significantly changes using different GNN-models. Furthermore, we observe interesting transfer capabilities of our approach: GNN-models trained on smaller grids can directly be applied on larger grids without the need of retraining.      
### 32.Distinguishing Healthy Ageing from Dementia: a Biomechanical Simulation of Brain Atrophy using Deep Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08214.pdf)
>  Biomechanical modeling of tissue deformation can be used to simulate different scenarios of longitudinal brain evolution. In this work,we present a deep learning framework for hyper-elastic strain modelling of brain atrophy, during healthy ageing and in Alzheimer's Disease. The framework directly models the effects of age, disease status, and scan interval to regress regional patterns of atrophy, from which a strain-based model estimates deformations. This model is trained and validated using 3D structural magnetic resonance imaging data from the ADNI cohort. Results show that the framework can estimate realistic deformations, following the known course of Alzheimer's disease, that clearly differentiate between healthy and demented patterns of ageing. This suggests the framework has potential to be incorporated into explainable models of disease, for the exploration of interventions and counterfactual examples.      
### 33.Wideband Channel Estimation for THz Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2108.08173.pdf)
>  Terahertz (THz) communication is considered to be a promising technology for future 6G network. To overcome the severe attenuation and relieve the high power consumption, massive MIMO with hybrid precoding has been widely considered for THz communication. However, accurate wideband channel estimation is challenging in THz massive MIMO systems. The existing wideband channel estimation schemes based on the ideal assumption of common sparse channel support will suffer from a severe performance loss due to the beam split effect. In this paper, we propose a beam split pattern detection based channel estimation scheme to realize reliable wideband channel estimation. Specifically, a comprehensive analysis on the angle-domain sparse structure of the wideband channel is provided by considering the beam split effect. Based on the analysis, we define a series of index sets called as beam split patterns, which are proved to have a one-to-one match to different physical channel directions. Inspired by this one-to-one match, we propose to estimate the physical channel direction by exploiting beam split patterns at first. Then, the sparse channel supports at different subcarriers can be obtained by utilizing a support detection window. This support detection window is generated by expanding the beam split pattern which is determined by the obtained physical channel direction. The above estimation procedure will be repeated path by path until all path components are estimated. The proposed scheme exploits the wideband channel property implied by the beam split effect, which can significantly improve the channel estimation accuracy. Simulation results show that the proposed scheme is able to achieve higher accuracy than existing schemes.      
### 34.Towards Deep and Efficient: A Deep Siamese Self-Attention Fully Efficient Convolutional Network for Change Detection in VHR Images  [ :arrow_down: ](https://arxiv.org/pdf/2108.08157.pdf)
>  Recently, FCNs have attracted widespread attention in the CD field. In pursuit of better CD performance, it has become a tendency to design deeper and more complicated FCNs, which inevitably brings about huge numbers of parameters and an unbearable computational burden. With the goal of designing a quite deep architecture to obtain more precise CD results while simultaneously decreasing parameter numbers to improve efficiency, in this work, we present a very deep and efficient CD network, entitled EffCDNet. In EffCDNet, to reduce the numerous parameters associated with deep architecture, an efficient convolution consisting of depth-wise convolution and group convolution with a channel shuffle mechanism is introduced to replace standard convolutional layers. In terms of the specific network architecture, EffCDNet does not use mainstream UNet-like architecture, but rather adopts the architecture with a very deep encoder and a lightweight decoder. In the very deep encoder, two very deep siamese streams stacked by efficient convolution first extract two highly representative and informative feature maps from input image-pairs. Subsequently, an efficient ASPP module is designed to capture multi-scale change information. In the lightweight decoder, a recurrent criss-cross self-attention (RCCA) module is applied to efficiently utilize non-local similar feature representations to enhance discriminability for each pixel, thus effectively separating the changed and unchanged regions. Moreover, to tackle the optimization problem in confused pixels, two novel loss functions based on information entropy are presented. On two challenging CD datasets, our approach outperforms other SOTA FCN-based methods, with only benchmark-level parameter numbers and quite low computational overhead.      
### 35.Electromagnetic Modeling of Holographic Intelligent Reflecting Surfaces at Terahertz Bands  [ :arrow_down: ](https://arxiv.org/pdf/2108.08104.pdf)
>  Intelligent reflecting surface (IRS)-assisted wireless communication is widely deemed a key technology for 6G systems. The main challenge in deploying an IRS-aided terahertz (THz) link, though, is the severe propagation losses at high frequency bands. Hence, a THz IRS is expected to consist of a massive number of reflecting elements to compensate for those losses. However, as the IRS size grows, the conventional far-field assumption starts becoming invalid and the spherical wavefront of the radiated waves must be taken into account. In this work, we focus on the near-field and analytically determine the IRS response in the Fresnel zone by leveraging electromagnetic theory. Specifically, we derive a novel expression for the path loss and beampattern of a holographic IRS, which is then used to model its discrete counterpart. Our analysis sheds light on the modeling aspects and beamfocusing capabilities of THz IRSs.      
### 36.Dynamic RAT Selection and Transceiver Optimization for Mobile Edge Computing Over Multi-RAT Heterogeneous Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08098.pdf)
>  Mobile edge computing (MEC) integrated with multiple radio access technologies (RATs) is a promising technique for satisfying the growing low-latency computation demand of emerging intelligent internet of things (IoT) applications. Under the distributed MapReduce framework, this paper investigates the joint RAT selection and transceiver design for over-the-air (OTA) aggregation of intermediate values (IVAs) in wireless multiuser MEC systems, while taking into account the energy budget constraint for the local computing and IVA transmission per wireless device (WD). We aim to minimize the weighted sum of the computation mean squared error (MSE) of the aggregated IVA at the RAT receivers, the WDs' IVA transmission cost, and the associated transmission time delay, which is a mixed-integer and non-convex problem. Based on the Lagrange duality method and primal decomposition, we develop a low-complexity algorithm by solving the WDs' RAT selection problem, the WDs' transmit coefficients optimization problem, and the aggregation beamforming problem. Extensive numerical results are provided to demonstrate the effectiveness and merit of our proposed algorithm as compared with other existing schemes.      
### 37.Resource Scheduling in Edge Computing: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2108.08059.pdf)
>  With the proliferation of the Internet of Things (IoT) and the wide penetration of wireless networks, the surging demand for data communications and computing calls for the emerging edge computing paradigm. By moving the services and functions located in the cloud to the proximity of users, edge computing can provide powerful communication, storage, networking, and communication capacity. The resource scheduling in edge computing, which is the key to the success of edge computing systems, has attracted increasing research interests. In this paper, we survey the state-of-the-art research findings to know the research progress in this field. Specifically, we present the architecture of edge computing, under which different collaborative manners for resource scheduling are discussed. Particularly, we introduce a unified model before summarizing the current works on resource scheduling from three research issues, including computation offloading, resource allocation, and resource provisioning. Based on two modes of operation, i.e., centralized and distributed modes, different techniques for resource scheduling are discussed and compared. Also, we summarize the main performance indicators based on the surveyed literature. To shed light on the significance of resource scheduling in real-world scenarios, we discuss several typical application scenarios involved in the research of resource scheduling in edge computing. Finally, we highlight some open research challenges yet to be addressed and outline several open issues as the future research direction.      
### 38.Joint Multiple Intent Detection and Slot Filling via Self-distillation  [ :arrow_down: ](https://arxiv.org/pdf/2108.08042.pdf)
>  Intent detection and slot filling are two main tasks in natural language understanding (NLU) for identifying users' needs from their utterances. These two tasks are highly related and often trained jointly. However, most previous works assume that each utterance only corresponds to one intent, ignoring the fact that a user utterance in many cases could include multiple intents. In this paper, we propose a novel Self-Distillation Joint NLU model (SDJN) for multi-intent NLU. First, we formulate multiple intent detection as a weakly supervised problem and approach with multiple instance learning (MIL). Then, we design an auxiliary loop via self-distillation with three orderly arranged decoders: Initial Slot Decoder, MIL Intent Decoder, and Final Slot Decoder. The output of each decoder will serve as auxiliary information for the next decoder. With the auxiliary knowledge provided by the MIL Intent Decoder, we set Final Slot Decoder as the teacher model that imparts knowledge back to Initial Slot Decoder to complete the loop. The auxiliary loop enables intents and slots to guide mutually in-depth and further boost the overall NLU performance. Experimental results on two public multi-intent datasets indicate that our model achieves strong performance compared to others.      
### 39.Low-Complexity Algorithm for Outage Optimal Resource Allocation in Energy Harvesting-Based UAV Identification Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08016.pdf)
>  We study an unmanned aerial vehicle (UAV) identification network equipped with an energy harvesting (EH) technique. In the network, the UAVs harvest energy through radio frequency (RF) signals transmitted from ground control stations (GCSs) and then transmit their identification information to the ground receiver station (GRS). Specifically, we first derive a closed-form expression of the outage probability to evaluate the network performance. Then we obtain the closed-form expression of the optimal time allocation when the bandwidth is equally allocated to the UAVs. We also propose a fast-converging algorithm for time and the bandwidth allocation, which is necessary for the UAV environment with high mobility, to optimize the outage performance of EH-based UAV identification network. Simulation results show that the proposed algorithm outperforms the conventional bisection algorithm and achieves near-optimal performance.      
### 40.A New Bidirectional Unsupervised Domain Adaptation Segmentation Framework  [ :arrow_down: ](https://arxiv.org/pdf/2108.07979.pdf)
>  Domain shift happens in cross-domain scenarios commonly because of the wide gaps between different domains: when applying a deep learning model well-trained in one domain to another target domain, the model usually performs poorly. To tackle this problem, unsupervised domain adaptation (UDA) techniques are proposed to bridge the gap between different domains, for the purpose of improving model performance without annotation in the target domain. Particularly, UDA has a great value for multimodal medical image analysis, where annotation difficulty is a practical concern. However, most existing UDA methods can only achieve satisfactory improvements in one adaptation direction (e.g., MRI to CT), but often perform poorly in the other (CT to MRI), limiting their practical usage. In this paper, we propose a bidirectional UDA (BiUDA) framework based on disentangled representation learning for equally competent two-way UDA performances. This framework employs a unified domain-aware pattern encoder which not only can adaptively encode images in different domains through a domain controller, but also improve model efficiency by eliminating redundant parameters. Furthermore, to avoid distortion of contents and patterns of input images during the adaptation process, a content-pattern consistency loss is introduced. Additionally, for better UDA segmentation performance, a label consistency strategy is proposed to provide extra supervision by recomposing target-domain-styled images and corresponding source-domain annotations. Comparison experiments and ablation studies conducted on two public datasets demonstrate the superiority of our BiUDA framework to current state-of-the-art UDA methods and the effectiveness of its novel designs. By successfully addressing two-way adaptations, our BiUDA framework offers a flexible solution of UDA techniques to the real-world scenario.      
### 41.Toward Autonomous Reconfigurable Intelligent Surfaces Through Wireless Energy Harvesting  [ :arrow_down: ](https://arxiv.org/pdf/2108.07953.pdf)
>  In this work, we examine the potential of autonomous operation of a reconfigurable intelligent surface (RIS) using wireless energy harvesting from information signals. To this end, we first identify the main RIS power-consuming components and introduce a suitable power-consumption model. Subsequently, we introduce a novel RIS power-splitting architecture that enables simultaneous energy harvesting and beamsteering. Specifically, a subset of the RIS unit cells (UCs) is used for beamsteering while the remaining ones absorb energy. For the subset allocation, we propose policies obtained as solutions to two optimization problems. The first problem aims at maximizing the signal-to-noise ratio (SNR) at the receiver without violating the RIS's energy harvesting demands. Additionally, the objective of the second problem is to maximize the RIS harvested power, while ensuring an acceptable SNR at the receiver. We prove that under particular propagation conditions, some of the proposed policies deliver the optimal solution of the two problems. Furthermore, we report numerical results that reveal the efficiency of the policies with respect to the optimal and very high-complexity brute-force design approach. Finally, through a case study of user tracking, we showcase that the RIS power-consumption demands can be secured by harvesting energy from information signals.      
### 42.Assessing the Integration of Software Agents and Industrial Automation Systems with ISO/IEC 25010  [ :arrow_down: ](https://arxiv.org/pdf/2108.07933.pdf)
>  Agent-technologies have been used for higher-level decision making in addition to carrying out lower-level automation and control functions in industrial systems. Recent research has identified a number of architectural patterns for the use of agents in industrial automation systems but these practices vary in several ways, including how closely agents are coupled with physical systems and their control functions. Such practices may play a pivotal role in the Cyber-Physical System integration and interaction. Hence, there is a clear need for a common set of criteria for assessing available practices and identifying a best-fit practice for a given industrial use case. Unfortunately, no such common criteria exist currently. This work proposes an assessment criteria approach as well as a methodology to enable the use case based selection of a best practice for integrating agents and industrial systems. The software product quality model proposed by the ISO/IEC 25010 family of standards is used as starting point and is put in the industrial automation context. Subsequently, the proposed methodology is applied, and a survey of experts in the domain is carried out, in order to reveal some insights on the key characteristics of the subject matter.      
### 43.Failure of the simultaneous block diagonalization technique applied to complete and cluster synchronization of random networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.07893.pdf)
>  We discuss here the application of the algebraic techniques for the simultaneous block diagonalization (SBD) of matrices to the study of the stability of both complete and cluster synchronization in random (generic) networks. For both problems, we see that the extent of the dimensionality reduction achievable is the same as that produced by application of a trivial transformation.      
### 44.Higher Order Derivative-Based Receiver Pre-processing for Molecular Communications  [ :arrow_down: ](https://arxiv.org/pdf/2108.07830.pdf)
>  While molecular communication via diffusion experiences significant inter-symbol interference (ISI), recent work suggests that ISI can be mitigated via time differentiation pre-processing which achieves pulse narrowing. Herein, the approach is generalized to higher order differentiation. The fundamental trade-off between ISI mitigation and noise amplification is characterized, showing the existence of an optimal derivative order that minimizes the bit error rate (BER). Theoretical analyses of the BER and a signal-to-interference-plus-noise ratio are provided, the derivative order optimization problem is posed and solved for threshold-based detectors. For more complex detectors which exploit a window memory, it is shown that derivative pre-processing can strongly reduce the size of the needed window. Extensive numerical results confirm the accuracy of theoretical derivations, the gains in performance via derivative pre-processing over other methods and the impact of the optimal derivative order. Derivative pre-processing offers a low complexity/high-performance method for reducing ISI at the expense of increased transmission power to reduce noise amplification.      
