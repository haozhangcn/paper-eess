# ArXiv eess --Fri, 20 Aug 2021
### 1.Drift in a Popular Metal Oxide Sensor Dataset Reveals Limitations for Gas Classification Benchmarks  [ :arrow_down: ](https://arxiv.org/pdf/2108.08793.pdf)
>  Metal oxide (MOx) electro-chemical gas sensors are a sensible choice for many applications, due to their tunable sensitivity, their space-efficiency and their low price. Publicly available sensor datasets streamline the development and evaluation of novel algorithm and circuit designs, making them particularly valuable for the Artificial Olfaction / Mobile Robot Olfaction community. In 2013, Vergara et al. published a dataset comprising 16 months of recordings from a large MOx gas sensor array in a wind tunnel, which has since become a standard benchmark in the field. Here we report a previously undetected property of the dataset that limits its suitability for gas classification studies. The analysis of individual measurement timestamps reveals that gases were recorded in temporally clustered batches. The consequential correlation between the sensor response before gas exposure and the time of recording is often sufficient to predict the gas used in a given trial. Even if compensated by zero-offset-subtraction, residual short-term drift contains enough information for gas classification. We have identified a minimally drift-affected subset of the data, which is suitable for gas classification benchmarking after zero-offset-subtraction, although gas classification performance was substantially lower than for the full dataset. We conclude that previous studies conducted with this dataset very likely overestimate the accuracy of gas classification results. For the 17 potentially affected publications, we urge the authors to re-evaluate the results in light of our findings. Our observations emphasize the need to thoroughly document gas sensing datasets, and proper validation before using them for the development of algorithms.      
### 2.MobileCaps: A Lightweight Model for Screening and Severity Analysis of COVID-19 Chest X-Ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2108.08775.pdf)
>  The world is going through a challenging phase due to the disastrous effect caused by the COVID-19 pandemic on the healthcare system and the economy. The rate of spreading, post-COVID-19 symptoms, and the occurrence of new strands of COVID-19 have put the healthcare systems in disruption across the globe. Due to this, the task of accurately screening COVID-19 cases has become of utmost priority. Since the virus infects the respiratory system, Chest X-Ray is an imaging modality that is adopted extensively for the initial screening. We have performed a comprehensive study that uses CXR images to identify COVID-19 cases and realized the necessity of having a more generalizable model. We utilize MobileNetV2 architecture as the feature extractor and integrate it into Capsule Networks to construct a fully automated and lightweight model termed as MobileCaps. MobileCaps is trained and evaluated on the publicly available dataset with the model ensembling and Bayesian optimization strategies to efficiently classify CXR images of patients with COVID-19 from non-COVID-19 pneumonia and healthy cases. The proposed model is further evaluated on two additional RT-PCR confirmed datasets to demonstrate the generalizability. We also introduce MobileCaps-S and leverage it for performing severity assessment of CXR images of COVID-19 based on the Radiographic Assessment of Lung Edema (RALE) scoring technique. Our classification model achieved an overall recall of 91.60, 94.60, 92.20, and a precision of 98.50, 88.21, 92.62 for COVID-19, non-COVID-19 pneumonia, and healthy cases, respectively. Further, the severity assessment model attained an R$^2$ coefficient of 70.51. Owing to the fact that the proposed models have fewer trainable parameters than the state-of-the-art models reported in the literature, we believe our models will go a long way in aiding healthcare systems in the battle against the pandemic.      
### 3.More for Less: Non-Intrusive Speech Quality Assessment with Limited Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2108.08745.pdf)
>  Non-intrusive speech quality assessment is a crucial operation in multimedia applications. The scarcity of annotated data and the lack of a reference signal represent some of the main challenges for designing efficient quality assessment metrics. In this paper, we propose two multi-task models to tackle the problems above. In the first model, we first learn a feature representation with a degradation classifier on a large dataset. Then we perform MOS prediction and degradation classification simultaneously on a small dataset annotated with MOS. In the second approach, the initial stage consists of learning features with a deep clustering-based unsupervised feature representation on the large dataset. Next, we perform MOS prediction and cluster label classification simultaneously on a small dataset. The results show that the deep clustering-based model outperforms the degradation classifier-based model and the 3 baselines (autoencoder features, P.563, and SRMRnorm) on TCD-VoIP. This paper indicates that multi-task learning combined with feature representations from unlabelled data is a promising approach to deal with the lack of large MOS annotated datasets.      
### 4.Neural Predictive Control for the Optimization of Smart Grid Flexibility Schedules  [ :arrow_down: ](https://arxiv.org/pdf/2108.08739.pdf)
>  Model predictive control (MPC) is a method to formulate the optimal scheduling problem for grid flexibilities in a mathematical manner. The resulting time-constrained optimization problem can be re-solved in each optimization time step using classical optimization methods such as Second Order Cone Programming (SOCP) or Interior Point Methods (IPOPT). When applying MPC in a rolling horizon scheme, the impact of uncertainty in forecasts on the optimal schedule is reduced. While MPC methods promise accurate results for time-constrained grid optimization they are inherently limited by the calculation time needed for large and complex power system models. Learning the optimal control behaviour using function approximation offers the possibility to determine near-optimal control actions with short calculation time. A Neural Predictive Control (NPC) scheme is proposed to learn optimal control policies for linear and nonlinear power systems through imitation. It is demonstrated that this procedure can find near-optimal solutions, while reducing the calculation time by an order of magnitude. The learned controllers are validated using a benchmark smart grid.      
### 5.Forced Oscillation Identification and Filtering from Multi-Channel Time-Frequency Representation  [ :arrow_down: ](https://arxiv.org/pdf/2108.08736.pdf)
>  Location of non-stationary forced oscillation (FO) sources can be a challenging task, especially in cases under resonance condition with natural system modes, where the magnitudes of the oscillations could be greater in places far from the source. Therefore, it is of interest to construct a global time-frequency (TF) representation (TFR) of the system, which can capture the oscillatory components present in the system. In this paper we develop a systematic methodology for frequency identification and component filtering of non-stationary power system forced oscillations (FO) based on multi-channel TFR. The frequencies of the oscillatory components are identified on the TF plane by applying a modified ridge estimation algorithm. Then, filtering of the components is carried out on the TF plane applying the anti-transform functions over the individual TFRs around the identified ridges. This step constitutes an initial stage for the application of the Dissipating Energy Flow (DEF) method used to locate FO sources. Besides, we compare three TF approaches: short-time Fourier transform (STFT), STFT-based synchrosqueezing transform (FSST) and second order FSST (FSST2). Simulated signals and signals from real operation are used to show that the proposed method provides a systematic framework for identification and filtering of power systems non-stationary forced oscillations.      
### 6.Sparse Packetized Predictive Control of Disturbed Plants Over Channels with Data Loss  [ :arrow_down: ](https://arxiv.org/pdf/2108.08681.pdf)
>  This paper investigates closed-loop stability of a linear discrete-time plant subject to bounded disturbances when controlled according to packetized predictive control (PPC) policies. In the considered feedback loop, the controller is connected to the actuator via a digital communication channel imposing bounded dropouts. Two PPC strategies are taken into account. In both cases, the control packets are generated by solving sparsity-promoting optimization problems. One is based upon an l2-constrained l0 optimization problem. Such problem is relaxed by an l1-l2 optimization problem in the other sparse PPC setting. We utilize effective solving methods for the latter optimization problems. Moreover, we show that in the presence of plant disturbances, the l2-constrained l0 sparse PPC and unconstrained l1-l2 sparse PPC guarantee practical stability for the system if certain conditions are met. More precisely, in each case, we can derive an upper bound on system state if the design parameters satisfy certain conditions. The bounds we derive are increasing with respect to the disturbance magnitude. We show via simulation that in both cases of proposed sparse PPC strategies, larger disturbances bring about performance degradation with no effect on system practical stability.      
### 7.The Pareto-frontier-based Stiffness of A Controller: Trade-off between Trajectory Plan and Controller Design  [ :arrow_down: ](https://arxiv.org/pdf/2108.08667.pdf)
>  Approaching a set goal for a UAV comprises a trajectory plan and a controller design (control after plan problems). The optimal trajectory (reference) is calculated before being tracked with a proper controller. It is believed that the quadrotor will follow the designed trajectory totally in the trajectory plan process. However, the dynamic state error usually, for a mismatched feed-forward, spoils this assumption, making the unwanted sacrifice in the objective function defined in the trajectory plan process. We base the target problem in this research on a second-order system model which widely exists in the dynamics of vehicles. Specially, the unavoidable dynamic state error is considered in the trajectory plan process, assuming the LQR without the feed-forward is applied in the subsequent control after plan problems. The Copenhagen Limit provides the possibility of estimating the dynamic state error in an analytical solution. The trade-off results are provided in multiobjective Pareto front solutions and the mapped pseudo Pareto fronts. We explore the relationship between the controller and the corresponding pseudo Pareto fronts.      
### 8.Unsupervised Cross-Lingual Speech Emotion Recognition Using Pseudo Multilabel  [ :arrow_down: ](https://arxiv.org/pdf/2108.08663.pdf)
>  Speech Emotion Recognition (SER) in a single language has achieved remarkable results through deep learning approaches in the last decade. However, cross-lingual SER remains a challenge in real-world applications due to a great difference between the source and target domain distributions. To address this issue, we propose an Unsupervised Cross-Lingual Neural Network with Pseudo Multilabel (UCNNPM) that is trained to learn the emotion similarities between source domain features inside an external memory adjusted to identify emotion in cross-lingual databases. UCNNPM introduces a novel approach that leverages external memory to store source domain features and generates pseudo multilabel for each target domain data by computing the similarities between the external memory and the target domain features. We evaluate our approach on multiple different languages of speech emotion databases. Experimental results show our proposed approach significantly improves the weighted accuracy (WA) across multiple low-resource languages on Urdu, Skropus, ShEMO, and EMO-DB corpus.      
### 9.Discrete-time Flatness-based Control of a Gantry Crane  [ :arrow_down: ](https://arxiv.org/pdf/2108.08658.pdf)
>  This article addresses the design of a discrete-time flatness-based tracking control for a gantry crane and demonstrates the practical applicability of the approach by measurement results. The required sampled-data model is derived by an Euler-discretization with a prior state transformation in such a way that the flatness of the continuous-time system is preserved. Like in the continuous-time case, the flatness-based controller design is performed in two steps. First, the sampled-data system is exactly linearized by a discrete-time quasi-static state feedback. Subsequently, a further feedback enforces a stable linear tracking error dynamics. To underline its practical relevance, the performance of the novel discrete-time tracking control is compared to the classical continuous-time approach by measurement results from a laboratory setup. In particular, it turns out that the discrete-time controller is significantly more robust with respect to large sampling times. Moreover, it is shown how the discrete-time approach facilitates the design of optimal reference trajectories, and further measurement results are presented.      
### 10.Wind Turbine Blade Surface Damage Detection based on Aerial Imagery and VGG16-RCNN Framework  [ :arrow_down: ](https://arxiv.org/pdf/2108.08636.pdf)
>  In this manuscript, an image analytics based deep learning framework for wind turbine blade surface damage detection is proposed. Turbine blade(s) which carry approximately one-third of a turbine weight are susceptible to damage and can cause sudden malfunction of a grid-connected wind energy conversion system. The surface damage detection of wind turbine blade requires a large dataset so as to detect a type of damage at an early stage. Turbine blade images are captured via aerial imagery. Upon inspection, it is found that the image dataset was limited and hence image augmentation is applied to improve blade image dataset. The approach is modeled as a multi-class supervised learning problem and deep learning methods like Convolutional neural network (CNN), VGG16-RCNN and AlexNet are tested for determining the potential capability of turbine blade surface damage.      
### 11.A Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2108.08635.pdf)
>  This paper presents a sensor fusion based Global Navigation Satellite System (GNSS) spoofing attack detection framework for autonomous vehicles (AV) that consists of two concurrent strategies: (i) detection of vehicle state using predicted location shift -- i.e., distance traveled between two consecutive timestamps -- and monitoring of vehicle motion state -- i.e., standstill/ in motion; and (ii) detection and classification of turns (i.e., left or right). Data from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering angle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural network model, which is a long short-term memory (LSTM) network for predicting the location shift, i.e., the distance that an AV travels between two consecutive timestamps. This location shift is then compared with the GNSS-based location shift to detect an attack. We have then combined k-Nearest Neighbors (k-NN) and Dynamic Time Warping (DTW) algorithms to detect and classify left and right turns using data from the steering angle sensor. To prove the efficacy of the sensor fusion-based attack detection framework, attack datasets are created for four unique and sophisticated spoofing attacks-turn-by-turn, overshoot, wrong turn, and stop, using the publicly available real-world Honda Research Institute Driving Dataset (HDD). Our analysis reveals that the sensor fusion-based detection framework successfully detects all four types of spoofing attacks within the required computational latency threshold.      
### 12.A Reinforcement Learning Approach for GNSS Spoofing Attack Detection of Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2108.08628.pdf)
>  A resilient and robust positioning, navigation, and timing (PNT) system is a necessity for the navigation of autonomous vehicles (AVs). Global Navigation Satelite System (GNSS) provides satellite-based PNT services. However, a spoofer can temper an authentic GNSS signal and could transmit wrong position information to an AV. Therefore, a GNSS must have the capability of real-time detection and feedback-correction of spoofing attacks related to PNT receivers, whereby it will help the end-user (autonomous vehicle in this case) to navigate safely if it falls into any compromises. This paper aims to develop a deep reinforcement learning (RL)-based turn-by-turn spoofing attack detection using low-cost in-vehicle sensor data. We have utilized Honda Driving Dataset to create attack and non-attack datasets, develop a deep RL model, and evaluate the performance of the RL-based attack detection model. We find that the accuracy of the RL model ranges from 99.99% to 100%, and the recall value is 100%. However, the precision ranges from 93.44% to 100%, and the f1 score ranges from 96.61% to 100%. Overall, the analyses reveal that the RL model is effective in turn-by-turn spoofing attack detection.      
### 13.Reproducible radiomics through automated machine learning validated on twelve clinical applications  [ :arrow_down: ](https://arxiv.org/pdf/2108.08618.pdf)
>  Radiomics uses quantitative medical imaging features to predict clinical outcomes. While many radiomics methods have been described in the literature, these are generally designed for a single application. The aim of this study is to generalize radiomics across applications by proposing a framework to automatically construct and optimize the radiomics workflow per application. To this end, we formulate radiomics as a modular workflow, consisting of several components: image and segmentation preprocessing, feature extraction, feature and sample preprocessing, and machine learning. For each component, a collection of common algorithms is included. To optimize the workflow per application, we employ automated machine learning using a random search and ensembling. We evaluate our method in twelve different clinical applications, resulting in the following area under the curves: 1) liposarcoma (0.83); 2) desmoid-type fibromatosis (0.82); 3) primary liver tumors (0.81); 4) gastrointestinal stromal tumors (0.77); 5) colorectal liver metastases (0.68); 6) melanoma metastases (0.51); 7) hepatocellular carcinoma (0.75); 8) mesenteric fibrosis (0.81); 9) prostate cancer (0.72); 10) glioma (0.70); 11) Alzheimer's disease (0.87); and 12) head and neck cancer (0.84). Concluding, our method fully automatically constructs and optimizes the radiomics workflow, thereby streamlining the search for radiomics biomarkers in new applications. To facilitate reproducibility and future research, we publicly release six datasets, the software implementation of our framework (open-source), and the code to reproduce this study.      
### 14.Large-scale Offshore Wind Farm Electrical Collector System Planning: A Mixed-Integer Linear Programming Approach  [ :arrow_down: ](https://arxiv.org/pdf/2108.08569.pdf)
>  In this paper, we propose a planning method for large-scale offshore wind farm (OWF) electrical collector system (ECS) based on mixed integer linear programming, in which the sizing and siting of offshore substations and the lines between wind turbines (WTs) are optimized. We found out that the problem is similar to power distribution system planning, where the topological constraints for distribution network expansion planning (DNEP) are applied to guarantee the radiality of ECS topology and accelerate the solving process. Case studies based on an OWF with 63 fixed-locations WTs demonstrate the effectiveness of proposed method, in which the cost of ECS's investment on cables is reduced by 23%, power loss reduced by 44% compared with a conventional design, and the calculation time reduced with the help of the radiality constraint.      
### 15.Learned Video Compression with Residual Prediction and Loop Filter  [ :arrow_down: ](https://arxiv.org/pdf/2108.08551.pdf)
>  In this paper, we propose a learned video codec with a residual prediction network (RP-Net) and a feature-aided loop filter (LF-Net). For the RP-Net, we exploit the residual of previous multiple frames to further eliminate the redundancy of the current frame residual. For the LF-Net, the features from residual decoding network and the motion compensation network are used to aid the reconstruction quality. To reduce the complexity, a light ResNet structure is used as the backbone for both RP-Net and LF-Net. Experimental results illustrate that we can save about 10% BD-rate compared with previous learned video compression frameworks. Moreover, we can achieve faster coding speed due to the ResNet backbone. This project is available at <a class="link-external link-https" href="https://github.com/chaoliu18/RPLVC" rel="external noopener nofollow">this https URL</a>.      
### 16.Packetized Energy Management Controller for Residential Consumers  [ :arrow_down: ](https://arxiv.org/pdf/2108.08535.pdf)
>  In this paper, we investigate the management of energy storage control and load scheduling in scenarios considering a grid-connected photovoltaic (PV) system using packetized energy management. The aim is to reduce an average aggregated system cost through the proposed \textit{packetized energy management controller} considering household energy consumption, procurement price, load scheduling delays, PV self-sufficiency via generated renewable energy and battery degradation. The proposed approach solves the joint optimization problem using established heuristics, namely genetic algorithm (GA), binary particle swarm optimization (BPSO), and differential evolution (DE). Additionally, the performances of heuristic algorithms are also compared in terms of the effectiveness of load scheduling with delay constraints, packetized energy transactions, and battery degradation cost. Case studies have been provided to demonstrate and extensively evaluate the algorithms. The numerical results show that the proposed packetized energy management controller can considerably reduce the aggregated average system cost up to 4.7\%, 5.14\%, and 1.35\% by GA, BPSO, and DE, respectively while meeting the packetized energy demand and scheduling delays requirements.      
### 17.Patch-Based Cervical Cancer Segmentation using Distance from Boundary of Tissue  [ :arrow_down: ](https://arxiv.org/pdf/2108.08508.pdf)
>  Pathological diagnosis is used for examining cancer in detail, and its automation is in demand. To automatically segment each cancer area, a patch-based approach is usually used since a Whole Slide Image (WSI) is huge. However, this approach loses the global information needed to distinguish between classes. In this paper, we utilized the Distance from the Boundary of tissue (DfB), which is global information that can be extracted from the original image. We experimentally applied our method to the three-class classification of cervical cancer, and found that it improved the total performance compared with the conventional method.      
### 18.Blindly Assess Quality of In-the-Wild Videos via Quality-aware Pre-training and Motion Perception  [ :arrow_down: ](https://arxiv.org/pdf/2108.08505.pdf)
>  Perceptual quality assessment of the videos acquired in the wilds is of vital importance for quality assurance of video services. The inaccessibility of reference videos with pristine quality and the complexity of authentic distortions pose great challenges for this kind of blind video quality assessment (BVQA) task. Although model-based transfer learning is an effective and efficient paradigm for the BVQA task, it remains to be a challenge to explore what and how to bridge the domain shifts for better video representation. In this work, we propose to transfer knowledge from image quality assessment (IQA) databases with authentic distortions and large-scale action recognition with rich motion patterns. We rely on both groups of data to learn the feature extractor. We train the proposed model on the target VQA databases using a mixed list-wise ranking loss function. Extensive experiments on six databases demonstrate that our method performs very competitively under both individual database and mixed database training settings. We also verify the rationality of each component of the proposed method and explore a simple manner for further improvement.      
### 19.A relaxed technical assumption for posterior sampling-based reinforcement learning for control of unknown linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.08502.pdf)
>  We revisit the Thompson sampling algorithm to control an unknown linear quadratic (LQ) system recently proposed by Ouyang et al (<a class="link-https" data-arxiv-id="1709.04047" href="https://arxiv.org/abs/1709.04047">arXiv:1709.04047</a>). The regret bound of the algorithm was derived under a technical assumption on the induced norm of the closed loop system. In this technical note, we show that by making a minor modification in the algorithm (in particular, ensuring that an episode does not end too soon), this technical assumption on the induced norm can be replaced by a milder assumption in terms of the spectral radius of the closed loop system. The modified algorithm has the same Bayesian regret of $\tilde{\mathcal{O}}(\sqrt{T})$, where $T$ is the time-horizon and the $\tilde{\mathcal{O}}(\cdot)$ notation hides logarithmic terms in~$T$.      
### 20.Blind Identification of State-Space Models in Physical Coordinates  [ :arrow_down: ](https://arxiv.org/pdf/2108.08498.pdf)
>  Blind identification is popular for modeling a system without the input information, such as in the research areas of structural health monitoring and audio signal processing. Existing blind identification methods have both advantages and disadvantages, in this paper, we briefly outline current methods and propose a novel blind identification method for identifying state-space models in physical coordinates. The idea behind this proposed method is first to regard the collected input data of a state-space model as a part of a periodic signal sequence, and then transform the state-space model with input and output into a model without input by augmenting the state-space model with the input model (which is a periodic signal model), and afterwards use merely the output information to identify a state-space model up to a similarity transformation, and finally derive the state-space model in physical coordinates by using a unique similarity transformation. With the above idea, physical parameters and modal parameters of a state-space system can be obtained. Both numerical and practical examples were used to validate the proposed method. The result showed the effectiveness of the novel blind identification method.      
### 21.Classification of Diabetic Retinopathy Severity in Fundus Images with DenseNet121 and ResNet50  [ :arrow_down: ](https://arxiv.org/pdf/2108.08473.pdf)
>  In this work, deep learning algorithms are used to classify fundus images in terms of diabetic retinopathy severity. Six different combinations of two model architectures, the Dense Convolutional Network-121 and the Residual Neural Network-50 and three image types, RGB, Green, and High Contrast, were tested to find the highest performing combination. We achieved an average validation loss of 0.17 and a max validation accuracy of 85 percent. By testing out multiple combinations, certain combinations of parameters performed better than others, though minimal variance was found overall. Green filtration was shown to perform the poorest, while amplified contrast appeared to have a negligible effect in comparison to RGB analysis. ResNet50 proved to be less of a robust model as opposed to DenseNet121.      
### 22.ChMusic: A Traditional Chinese Music Dataset for Evaluation of Instrument Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.08470.pdf)
>  Musical instruments recognition is a widely used application for music information retrieval. As most of previous musical instruments recognition dataset focus on western musical instruments, it is difficult for researcher to study and evaluate the area of traditional Chinese musical instrument recognition. This paper propose a traditional Chinese music dataset for training model and performance evaluation, named ChMusic. This dataset is free and publicly available, 11 traditional Chinese musical instruments and 55 traditional Chinese music excerpts are recorded in this dataset. Then an evaluation standard is proposed based on ChMusic dataset. With this standard, researchers can compare their results following the same rule, and results from different researchers will become comparable.      
### 23.Medical Image Segmentation using 3D Convolutional Neural Networks: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2108.08467.pdf)
>  Computer-aided medical image analysis plays a significant role in assisting medical practitioners for expert clinical diagnosis and deciding the optimal treatment plan. At present, convolutional neural networks (CNN) are the preferred choice for medical image analysis. In addition, with the rapid advancements in three-dimensional (3D) imaging systems and the availability of excellent hardware and software support to process large volumes of data, 3D deep learning methods are gaining popularity in medical image analysis. Here, we present an extensive review of the recently evolved 3D deep learning methods in medical image segmentation. Furthermore, the research gaps and future directions in 3D medical image segmentation are discussed.      
### 24.$\mathcal{L}_1$ Adaptive Control for Learn-to-Fly  [ :arrow_down: ](https://arxiv.org/pdf/2108.08462.pdf)
>  Learn-to-Fly (L2F) is a new framework that aims to replace the traditional iterative development paradigm for aerial vehicles with a combination of real-time aerodynamic modeling, guidance, and learning control. To ensure safe learning of the vehicle dynamics on the fly, this paper presents an $\mathcal{L}_1$ adaptive control ($\mathcal{L}_1$AC) based scheme, which actively estimates and compensates for the discrepancy between the intermediately learned dynamics and the actual dynamics. First, to incorporate the periodic update of the learned model within the L2F framework, this paper extends the $\mathcal{L}_1$AC architecture to handle a switched reference system subject to unknown time-varying parameters and disturbances. The paper also includes analysis of both transient and steady-state performance of the $\mathcal{L}_1$AC architecture in the presence of non-zero initialization error for the state predictor. Second, the paper presents how the proposed $\mathcal{L}_1$AC scheme is integrated into the L2F framework, including its interaction with the baseline controller and the real-time modeling module. Finally, flight tests on an unmanned aerial vehicle (UAV) validate the efficacy of the proposed control and learning scheme.      
### 25.Identifiability Implies Robust, Globally Exponentially Convergent On-line Parameter Estimation: Application to Model Reference Adaptive Control  [ :arrow_down: ](https://arxiv.org/pdf/2108.08436.pdf)
>  In this paper we propose a new parameter estimator that ensures global exponential convergence of linear regression models requiring only the necessary assumption of identifiability of the regression equation,which we show is equivalent to interval excitation of the regressor vector. Continuous and discrete-time versions of the estimators are given. An extension to--separable and monotonic--non-linear parameterizations is also given. The estimators are shown to be robust to additive measurement noise and--not necessarily slow--parameter variations. Moreover, a version of the continuous-time estimator that rejects sinusoidal disturbances with unknown internal model is given. The estimator is shown to be applicable to the classical model reference adaptive control problem relaxing the conspicuous assumption of known sign of the high-frequency gain. Simulation results that illustrate the performance of the estimator are given.      
### 26.Learning explicit predictive controllers: theory and applications  [ :arrow_down: ](https://arxiv.org/pdf/2108.08412.pdf)
>  In this paper, we deal with data-driven predictive control of linear time-invariant (LTI) systems. Specifically, we show for the first time how explicit predictive laws can be learnt directly from data, without needing to identify the system to control. To this aim, we resort to the Willems' fundamental lemma and we derive the explicit formulas by suitably elaborating the constrained optimization problem under investigation. The resulting optimal controller turns out to be a piecewise affine system coinciding with the solution of the original model-based problem in case of noiseless data. Such an equivalence is proven to hold asymptotically also in presence of measurement noise, thus making the proposed method a computationally efficient (but model-free) alternative to the state of the art predictive controls. The above statements are further supported by numerical simulations on three benchmark examples.      
### 27.Denoising ECG by Adaptive Filter with Empirical Mode Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2108.08376.pdf)
>  Electrocardiogram (ECG) signal is an important physiological signal which contains cardiac information and is the basis to diagnosis cardiac related diseases. In this paper, several innovative and efficient methods based on adaptive filter and empirical mode decomposition (EMD) to denoise ECG signal contaminated by various kinds of noise, including baseline wander (BW), power line interference (PLI), electrode motion artifact (EM) and muscle artifact (MA), are proposed. We first present a novel method based on EMD and adaptive filter for the removal of BW and PLI in ECG signal. We then extend the method to the complex scenario where four most common noises, PLI, BW, EM and MA are present. The proposed Parallel EMD adaptive filter structure yields the best SNR improvement on the MIT-BIH arrhythmia database, corrupted by the four types of noises.      
### 28.Data-driven Modeling for Distribution Grids Under Partial Observability  [ :arrow_down: ](https://arxiv.org/pdf/2108.08350.pdf)
>  Accurately modeling power distribution grids is crucial for designing effective monitoring and decision making algorithms. This paper addresses the partial observability issue of data-driven distribution modeling in order to improve the accuracy of line parameter estimation. Inspired by the sparse changes in residential loads, we advocate to regularize the group sparsity of the unobservable injections in a bi-linear estimation problem. The alternating minimization scheme of guaranteed convergence is proposed to take advantage of convex subproblems with efficient solutions. Numerical results using real-world load data on the single-phase equivalent of the IEEE 123-bus test case have demonstrated the accuracy improvements of the proposed solution over existing work for both parameter estimation and voltage modeling.      
### 29.Permanent Magnet Linear Generator Design for Surface Riding Wave Energy Converters  [ :arrow_down: ](https://arxiv.org/pdf/2108.08346.pdf)
>  This paper describes the detailed analysis for the design of a linear generator developed for a Surface Riding Wave Energy Converter (SR-WEC), which was designed to improve energy capture over a wider range of sea states. The study starts with an analysis of the power take-off (PTO) control strategy to harness the maximum output power from given sea states. Passive, reactive, and discrete PTO control are explored. For the random wave excitation and limited sliding distance of the generator, the discrete strategy provides the highest average power output. The paper discusses the sizing requirement for the linear generator. Based on the force and power rating of the system and the application requirements, a slotless permanent magnet tubular generator is designed for the wave energy converter.      
### 30.Temporal Kernel Consistency for Blind Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2108.08305.pdf)
>  Deep learning-based blind super-resolution (SR) methods have recently achieved unprecedented performance in upscaling frames with unknown degradation. These models are able to accurately estimate the unknown downscaling kernel from a given low-resolution (LR) image in order to leverage the kernel during restoration. Although these approaches have largely been successful, they are predominantly image-based and therefore do not exploit the temporal properties of the kernels across multiple video frames. In this paper, we investigated the temporal properties of the kernels and highlighted its importance in the task of blind video super-resolution. Specifically, we measured the kernel temporal consistency of real-world videos and illustrated how the estimated kernels might change per frame in videos of varying dynamicity of the scene and its objects. With this new insight, we revisited previous popular video SR approaches, and showed that previous assumptions of using a fixed kernel throughout the restoration process can lead to visual artifacts when upscaling real-world videos. In order to counteract this, we tailored existing single-image and video SR techniques to leverage kernel consistency during both kernel estimation and video upscaling processes. Extensive experiments on synthetic and real-world videos show substantial restoration gains quantitatively and qualitatively, achieving the new state-of-the-art in blind video SR and underlining the potential of exploiting kernel temporal consistency.      
### 31.Registration-Guided Deep Learning Image Segmentation for Cone Beam CT-based Online Adaptive Radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2108.08731.pdf)
>  Adaptive radiotherapy (ART), especially online ART, effectively accounts for positioning errors and anatomical changes. One key component of online ART is accurately and efficiently delineating organs at risk (OARs) and targets on online images, such as CBCT, to meet the online demands of plan evaluation and adaptation. Deep learning (DL)-based automatic segmentation has gained great success in segmenting planning CT, but its applications to CBCT yielded inferior results due to the low image quality and limited available contour labels for training. To overcome these obstacles to online CBCT segmentation, we propose a registration-guided DL (RgDL) segmentation framework that integrates image registration algorithms and DL segmentation models. The registration algorithm generates initial contours, which were used as guidance by DL model to obtain accurate final segmentations. We had two implementations the proposed framework--Rig-RgDL (Rig for rigid body) and Def-RgDL (Def for deformable)--with rigid body (RB) registration or deformable image registration (DIR) as the registration algorithm respectively and U-Net as DL model architecture. The two implementations of RgDL framework were trained and evaluated on seven OARs in an institutional clinical Head and Neck (HN) dataset. Compared to the baseline approaches using the registration or the DL alone, RgDL achieved more accurate segmentation, as measured by higher mean Dice similarity coefficients (DSC) and other distance-based metrics. Rig-RgDL achieved a DSC of 84.5% on seven OARs on average, higher than RB or DL alone by 4.5% and 4.7%. The DSC of Def-RgDL is 86.5%, higher than DIR or DL alone by 2.4% and 6.7%. The inference time took by the DL model to generate final segmentations of seven OARs is less than one second in RgDL. The resulting segmentation accuracy and efficiency show the promise of applying RgDL framework for online ART.      
### 32.From Real-Time Optimization Techniques to an Autopilot for Steady-State Processes  [ :arrow_down: ](https://arxiv.org/pdf/2108.08715.pdf)
>  Any industrial system goes along with objectives to be met (e.g. economic performance), disturbances to handle (e.g. market fluctuations, catalyst decay, unexpected variations in uncontrolled flow rates and compositions,...), and uncertainties about its behavior. In response to these, decisions must be taken and instructions be sent to the operators to drive and maintain the plant at satisfactory, yet potentially changing operating conditions. <br>Over the past thirty years many methods have been created and developed to answer these questions. In particular, the field of Real-Time Optimization (RTO) has emerged that, among others, encompasses methods that allow the systematic improvement of the performances of the industrial system, using plant measurements and a potentially inaccurate tool to predict its behaviour, generally in the form of a model. Even though the definition of RTO can differ between authors, inside and outside the process systems engineering community, there is currently no RTO method, which is deemed capable of fully automating the aforementioned decision-making process. This thesis consists of a series of contributions in this direction, which brings RTO closer to being capable of a full plant automation. <br>Keywords: Real-time optimization, Decision-making, Optimization, Reduced-order-model optimization, Autopilot for steady-state processes, Operational research.      
### 33.How to cheat with metrics in single-image HDR reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2108.08713.pdf)
>  Single-image high dynamic range (SI-HDR) reconstruction has recently emerged as a problem well-suited for deep learning methods. Each successive technique demonstrates an improvement over existing methods by reporting higher image quality scores. This paper, however, highlights that such improvements in objective metrics do not necessarily translate to visually superior images. The first problem is the use of disparate evaluation conditions in terms of data and metric parameters, calling for a standardized protocol to make it possible to compare between papers. The second problem, which forms the main focus of this paper, is the inherent difficulty in evaluating SI-HDR reconstructions since certain aspects of the reconstruction problem dominate objective differences, thereby introducing a bias. Here, we reproduce a typical evaluation using existing as well as simulated SI-HDR methods to demonstrate how different aspects of the problem affect objective quality metrics. Surprisingly, we found that methods that do not even reconstruct HDR information can compete with state-of-the-art deep learning methods. We show how such results are not representative of the perceived quality and that SI-HDR reconstruction needs better evaluation protocols.      
### 34.Real-time Image Enhancer via Learnable Spatial-aware 3D Lookup Tables  [ :arrow_down: ](https://arxiv.org/pdf/2108.08697.pdf)
>  Recently, deep learning-based image enhancement algorithms achieved state-of-the-art (SOTA) performance on several publicly available datasets. However, most existing methods fail to meet practical requirements either for visual perception or for computation efficiency, especially for high-resolution images. In this paper, we propose a novel real-time image enhancer via learnable spatial-aware 3-dimentional lookup tables(3D LUTs), which well considers global scenario and local spatial information. Specifically, we introduce a light weight two-head weight predictor that has two outputs. One is a 1D weight vector used for image-level scenario adaptation, the other is a 3D weight map aimed for pixel-wise category fusion. We learn the spatial-aware 3D LUTs and fuse them according to the aforementioned weights in an end-to-end manner. The fused LUT is then used to transform the source image into the target tone in an efficient way. Extensive results show that our model outperforms SOTA image enhancement methods on public datasets both subjectively and objectively, and that our model only takes about 4ms to process a 4K resolution image on one NVIDIA V100 GPU.      
### 35.On Accelerating Distributed Convex Optimizations  [ :arrow_down: ](https://arxiv.org/pdf/2108.08670.pdf)
>  This paper studies a distributed multi-agent convex optimization problem. The system comprises multiple agents in this problem, each with a set of local data points and an associated local cost function. The agents are connected to a server, and there is no inter-agent communication. The agents' goal is to learn a parameter vector that optimizes the aggregate of their local costs without revealing their local data points. In principle, the agents can solve this problem by collaborating with the server using the traditional distributed gradient-descent method. However, when the aggregate cost is ill-conditioned, the gradient-descent method (i) requires a large number of iterations to converge, and (ii) is highly unstable against process noise. We propose an iterative pre-conditioning technique to mitigate the deleterious effects of the cost function's conditioning on the convergence rate of distributed gradient-descent. Unlike the conventional pre-conditioning techniques, the pre-conditioner matrix in our proposed technique updates iteratively to facilitate implementation on the distributed network. In the distributed setting, we provably show that the proposed algorithm converges linearly with an improved rate of convergence than the traditional and adaptive gradient-descent methods. Additionally, for the special case when the minimizer of the aggregate cost is unique, our algorithm converges superlinearly. We demonstrate our algorithm's superior performance compared to prominent distributed algorithms for solving real logistic regression problems and emulating neural network training via a noisy quadratic model, thereby signifying the proposed algorithm's efficiency for distributively solving non-convex optimization. Moreover, we empirically show that the proposed algorithm results in faster training without compromising the generalization performance.      
### 36.Inter-Species Cell Detection: Datasets on pulmonary hemosiderophages in equine, human and feline specimens  [ :arrow_down: ](https://arxiv.org/pdf/2108.08529.pdf)
>  Pulmonary hemorrhage (P-Hem) occurs among multiple species and can have various causes. Cytology of bronchoalveolarlavage fluid (BALF) using a 5-tier scoring system of alveolar macrophages based on their hemosiderin content is considered the most sensitive diagnostic method. We introduce a novel, fully annotated multi-species P-Hem dataset which consists of 74 cytology whole slide images (WSIs) with equine, feline and human samples. To create this high-quality and high-quantity dataset, we developed an annotation pipeline combining human expertise with deep learning and data visualisation techniques. We applied a deep learning-based object detection approach trained on 17 expertly annotated equine WSIs, to the remaining 39 equine, 12 human and 7 feline WSIs. The resulting annotations were semi-automatically screened for errors on multiple types of specialised annotation maps and finally reviewed by a trained pathologists. Our dataset contains a total of 297,383 hemosiderophages classified into five grades. It is one of the largest publicly availableWSIs datasets with respect to the number of annotations, the scanned area and the number of species covered.      
### 37.Quad-cone-rotor: A Novel Tilt Quadrotor with Severe-fault-tolerant Ability  [ :arrow_down: ](https://arxiv.org/pdf/2108.08520.pdf)
>  Conventional quadrotors received great attention in trajectory design and fault-tolerant control in these years. The direction of each thrust is perpendicular to the body because of the geometrics in mechanical design. Comparing with the conventional quadrotor, a novel quadrotor named quad-tilt-rotor brings better freedom in manipulating the thrust vector. Quad-tilt-rotor augments the additional degrees of freedom in the thrust, providing the possibility of violating the normal direction of the thrust in the conventional quadrotor. This provides the ability of greater agility in control. This paper presents a novel design of a quad-tilt-rotor (quad-cone-rotor) whose thrust can be assigned along the edge of a cone shape. Besides the inheriting merits in agile from quad-tilt-rotor, the quad-cone-rotor is expected to take fault-tolerant control in severe dynamic failure (total loss in all thrusts). We simulate the control result in a UAV simulator in SIMULINK, MATLAB.      
### 38.Capacity Optimality of OAMP: Beyond IID Sensing Matrices and Gaussian Signaling  [ :arrow_down: ](https://arxiv.org/pdf/2108.08503.pdf)
>  This paper studies a large unitarily invariant system (LUIS) involving a unitarily invariant sensing matrix, an arbitrary signal distribution, and forward error control (FEC) coding. We develop a universal Gram-Schmidt orthogonalization for orthogonal approximate message passing (OAMP). Numerous area properties are established based on the state evolution and minimum mean squared error (MMSE) property of OAMP in an un-coded LUIS. As a byproduct, we provide an alternative derivation for the constrained capacity of a LUIS. Under the assumption that the state evolution for OAMP is correct for the coded system, the achievable rate of OAMP is analyzed. We prove that OAMP achieves the constrained capacity of the LUIS with an arbitrary signal distribution provided that a matching condition is satisfied. Meanwhile, we elaborate a capacity-achieving coding principle for LUIS, based on which irregular low-density parity-check (LDPC) codes are optimized for binary signaling in the numerical results. We show that OAMP with the optimized codes has significant performance improvement over the un-optimized ones and the well-known Turbo linear MMSE algorithm. For quadrature phase-shift keying (QPSK) modulation, capacity-approaching bit error rate (BER) performances are observed under various channel conditions.      
### 39.Monarch: A Durable Polymorphic Memory For Data Intensive Applications  [ :arrow_down: ](https://arxiv.org/pdf/2108.08497.pdf)
>  3D die stacking has often been proposed to build large-scale DRAM-based caches. Unfortunately, the power and performance overheads of DRAM limit the efficiency of high-bandwidth memories. Also, DRAM is facing serious scalability challenges that make alternative technologies more appealing. This paper examines Monarch, a resistive 3D stacked memory based on a novel reconfigurable crosspoint array called XAM. The XAM array is capable of switching between random access and content-addressable modes, which enables Monarch (i) to better utilize the in-package bandwidth and (ii) to satisfy both the random access memory and associative search requirements of various applications. Moreover, the Monarch controller ensures a given target lifetime for the resistive stack. Our simulation results on a set of parallel memory-intensive applications indicate that Monarch outperforms an ideal DRAM caching by 1.21x on average. For in-memory hash table and string matching workloads, Monarch improves performance up to 12x over the conventional high bandwidth memories.      
### 40.Can a Tesla Turbine be Utilised as a Non-Magnetic Actuator for MRI-Guided Robotic Interventions?  [ :arrow_down: ](https://arxiv.org/pdf/2108.08495.pdf)
>  This paper introduces a new type of nonmagnetic actuator for MRI interventions. Ultrasonic and piezoelectric motors are one the most commonly used actuators in MRI applications. However, most of these actuators are only MRI-safe, which means they cannot be operated while imaging as they cause significant visual artifacts. To cope with this issue, we developed a new pneumatic rotary servo-motor (based on the Tesla turbine) that can be effectively used during continuous MR imaging. We thoroughly tested the performance and magnetic properties of our MRI-compatible actuator with several experiments, both inside and outside an MRI scanner. The reported results confirm the feasibility to use this motor for MRI-guided robotic interventions.      
### 41.Towards a Multispectral RGB-IR-UV-D Vision System -- Seeing the Invisible in 3D  [ :arrow_down: ](https://arxiv.org/pdf/2108.08494.pdf)
>  In this paper, we present the development of a sensing system with the capability to compute multispectral point clouds in real-time. The proposed multi-eye sensor system effectively registers information from the visible, (long-wave) infrared, and ultraviolet spectrum to its depth sensing frame, thus enabling to measure a wider range of surface features that are otherwise hidden to the naked eye. For that, we designed a new cross-calibration apparatus that produces consistent features which can be sensed by each of the cameras, therefore, acting as a multispectral "chessboard". The performance of the sensor is evaluated with two different cases of studies, where we show that the proposed system can detect "hidden" features of a 3D environment.      
### 42.Cost-Efficient RIS-Aided Channel Estimation via Rank-One Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2108.08457.pdf)
>  A reconfigurable intelligent surface (RIS) consists of massive meta elements, which can improve the performance of future wireless communication systems. Existing RIS-aided channel estimation methods try to estimate the cascaded channel directly, incurring high computational and training overhead especially when the number of elements of RIS is extremely large. In this paper, we propose a cost-efficient channel estimation method via rank-one matrix factorization (MF). Specifically, if the RIS is employed near base station (BS), it is found that the RIS- aided channel can be factorized into a product of low-dimensional matrices. To estimate these factorized matrices, we propose alternating minimization and gradient descent approaches to obtain the near optimal solutions. Compared to directly estimating the cascaded channel, the proposed MF method reduces training overhead substantially. Finally, the numerical simulations show the effectiveness of the proposed MF method.      
### 43.Integrating Dialog History into End-to-End Spoken Language Understanding Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.08405.pdf)
>  End-to-end spoken language understanding (SLU) systems that process human-human or human-computer interactions are often context independent and process each turn of a conversation independently. Spoken conversations on the other hand, are very much context dependent, and dialog history contains useful information that can improve the processing of each conversational turn. In this paper, we investigate the importance of dialog history and how it can be effectively integrated into end-to-end SLU systems. While processing a spoken utterance, our proposed RNN transducer (RNN-T) based SLU model has access to its dialog history in the form of decoded transcripts and SLU labels of previous turns. We encode the dialog history as BERT embeddings, and use them as an additional input to the SLU model along with the speech features for the current utterance. We evaluate our approach on a recently released spoken dialog data set, the HarperValleyBank corpus. We observe significant improvements: 8% for dialog action and 30% for caller intent recognition tasks, in comparison to a competitive context independent end-to-end baseline system.      
### 44.Big Data in Astroinformatics -- Compression of Scanned Astronomical Photographic Plates  [ :arrow_down: ](https://arxiv.org/pdf/2108.08399.pdf)
>  Construction of Scanned Astronomical Photographic Plates(SAPPs) databases and SVD image compression algorithm are considered. Some examples of compression with different plates are shown.      
### 45.Quality assessment of image matchers for DSM generation -- a comparative study based on UAV images  [ :arrow_down: ](https://arxiv.org/pdf/2108.08369.pdf)
>  Recently developed automatic dense image matching algorithms are now being implemented for DSM/DTM production, with their pixel-level surface generation capability offering the prospect of partially alleviating the need for manual and semi-automatic stereoscopic measurements. In this paper, five commercial/public software packages for 3D surface generation are evaluated, using 5cm GSD imagery recorded from a UAV. Generated surface models are assessed against point clouds generated from mobile LiDAR and manual stereoscopic measurements. The software packages considered are APS, MICMAC, SURE, Pix4UAV and an SGM implementation from DLR.      
### 46.Adaptive Inverse Mapping: A Model-free Semi-supervised Learning Approach towards Robust Imaging through Dynamic Scattering Media  [ :arrow_down: ](https://arxiv.org/pdf/2108.08364.pdf)
>  Imaging through scattering media is a useful and yet demanding task since it involves solving for an inverse mapping from speckle images to object images. It becomes even more challenging when the scattering medium undergoes dynamic changes. Various approaches have been proposed in recent years. However, to date, none is able to preserve high image quality without either assuming a finite number of sources for dynamic changes, assuming a thin scattering medium, or requiring the access to both ends of the medium. In this paper, we propose an adaptive inverse mapping (AIP) method which is flexible regarding any dynamic change and only requires output speckle images after initialization. We show that the inverse mapping can be corrected through unsupervised learning if the output speckle images are followed closely. We test the AIP method on two numerical simulations, namely, a dynamic scattering system formulated as an evolving transmission matrix and a telescope with a changing random phase mask at a defocus plane. Then we experimentally apply the AIP method on a dynamic fiber-optic imaging system. Increased robustness in imaging is observed in all three cases. With the excellent performance, we see the great potential of the AIP method in imaging through dynamic scattering media.      
### 47.A Non-Stationary Channel Model with Correlated NLoS/LoS States for ELAA-mMIMO  [ :arrow_down: ](https://arxiv.org/pdf/2108.08357.pdf)
>  In this paper, a novel spatially non-stationary channel model is proposed for link-level computer simulations of massive multiple-input multiple-output (mMIMO) with extremely large aperture array (ELAA). The proposed channel model allows a mix of non-line-of-sight (NLoS) and LoS links between a user and service antennas. The NLoS/LoS state of each link is characterized by a binary random variable, which obeys a correlated Bernoulli distribution. The correlation is described in the form of an exponentially decaying window. In addition, the proposed model incorporates shadowing effects which are non-identical for NLoS and LoS states. It is demonstrated, through computer emulation, that the proposed model can capture almost all spatially non-stationary fading behaviors of the ELAA-mMIMO channel. Moreover, it has a low implementational complexity. With the proposed channel model, Monte-Carlo simulations are carried out to evaluate the channel capacity of ELAA-mMIMO. It is shown that the ELAA-mMIMO channel capacity has considerably different stochastic characteristics from the conventional mMIMO due to the presence of channel spatial non-stationarity.      
### 48.Development of a Clinical Chemical Exchange Saturation Transfer MR fingerprinting (CEST-MRF) Pulse Sequence and Reconstruction for Brain Tumor Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2108.08333.pdf)
>  Purpose: To develop a clinical chemical exchange saturation transfer magnetic resonance fingerprinting (CEST-MRF) pulse sequence and reconstruction method. <br>Methods: The CEST-MRF pulse sequence was modified to conform to hardware limits on clinical scanners while keeping scan time $\leqslant$ 2 minutes. The measured data was reconstructed using a deep reconstruction network (DRONE) to yield the water relaxation and chemical exchange parameters. The feasibility of the 6 parameter DRONE reconstruction was tested in simulations in a digital brain phantom. A healthy subject was scanned with the CEST-MRF sequence and a conventional MRF sequence for comparison. The reproducibility was assessed via test-retest experiments and the concordance correlation coefficient (CCC) calculated for white matter (WM) and grey matter (GM). The clinical utility of CEST-MRF was demonstrated in a brain metastasis patient in comparison to standard clinical imaging sequences. The tumor was segmented into edema, solid core and necrotic core regions and the CEST-MRF values compared to the contra-lateral side. <br>Results: The 6 parameter DRONE reconstruction of the digital phantom yielded a mean absolute error of $\leqslant$ 6% for all parameters. The CEST-MRF parameters were in good agreement with those from a conventional MRF sequence and previous studies in the literature. The mean CCC for all 6 parameters was 0.79$\pm$0.02 in WM and 0.63$\pm$0.03 in GM. The CEST-MRF values in nearly all tumor regions were significantly different (p=0.001) from each other and the contra-lateral side. <br>Conclusion: The clinical CEST-MRF sequence provides a method for fast simultaneous quantification of multiple tissue parameters in pathologies.      
### 49.ALBRT: Cellular Composition Prediction in Routine Histology Images  [ :arrow_down: ](https://arxiv.org/pdf/2108.08306.pdf)
>  Cellular composition prediction, i.e., predicting the presence and counts of different types of cells in the tumor microenvironment from a digitized image of a Hematoxylin and Eosin (H\&amp;E) stained tissue section can be used for various tasks in computational pathology such as the analysis of cellular topology and interactions, subtype prediction, survival analysis, etc. In this work, we propose an image-based cellular composition predictor (ALBRT) which can accurately predict the presence and counts of different types of cells in a given image patch. ALBRT, by its contrastive-learning inspired design, learns a compact and rotation-invariant feature representation that is then used for cellular composition prediction of different cell types. It offers significant improvement over existing state-of-the-art approaches for cell classification and counting. The patch-level feature representation learned by ALBRT is transferrable for cellular composition analysis over novel datasets and can also be utilized for downstream prediction tasks in CPath as well. The code and the inference webserver for the proposed method are available at the URL: <a class="link-external link-https" href="https://github.com/engrodawood/ALBRT" rel="external noopener nofollow">this https URL</a>.      
### 50.Global Built-up and Population Maps: Which ones should you use for India?  [ :arrow_down: ](https://arxiv.org/pdf/2108.08304.pdf)
>  Multiple global land cover and population distribution datasets are currently available in the public domain. Given the differences between these datasets and the possibility that their accuracy may vary across countries, it is imperative that users have clear guidance on which datasets are appropriate for specific settings and objectives. Here we assess the accuracy of three global 10m resolution built-up datasets (ESRI, GHSL-BUILT-S2 and WSF) and three population distribution datasets (HRSL 30m, WorldPop 100m, GHS-POP 250m) for India. Among built-up datasets, the GHSL-BUILT-S2 is the most suitable for India for the 2015-2020 time period. To assess accuracy of population distribution datasets we use data from the 2011 Census of India at the level of 37,137 village and town polygons for the state of Bihar in India. Among the global datasets, HRSL has the best results. We also compute error metrics for the IDC-POP layer, a 30m resolution population dataset generated by us at the Indian Institute for Human Settlements. For Bihar, the IDC-POP population map outperforms all three global datasets.      
### 51.Identifying Illicit Drug Dealers on Instagram with Large-scale Multimodal Data Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2108.08301.pdf)
>  Illicit drug trafficking via social media sites such as Instagram has become a severe problem, thus drawing a great deal of attention from law enforcement and public health agencies. How to identify illicit drug dealers from social media data has remained a technical challenge due to the following reasons. On the one hand, the available data are limited because of privacy concerns with crawling social media sites; on the other hand, the diversity of drug dealing patterns makes it difficult to reliably distinguish drug dealers from common drug users. Unlike existing methods that focus on posting-based detection, we propose to tackle the problem of illicit drug dealer identification by constructing a large-scale multimodal dataset named Identifying Drug Dealers on Instagram (IDDIG). Totally nearly 4,000 user accounts, of which over 1,400 are drug dealers, have been collected from Instagram with multiple data sources including post comments, post images, homepage bio, and homepage images. We then design a quadruple-based multimodal fusion method to combine the multiple data sources associated with each user account for drug dealer identification. Experimental results on the constructed IDDIG dataset demonstrate the effectiveness of the proposed method in identifying drug dealers (almost 95% accuracy). Moreover, we have developed a hashtag-based community detection technique for discovering evolving patterns, especially those related to geography and drug types.      
### 52.TFRD: A Benchmark Dataset for Research on Temperature Field Reconstruction of Heat-Source Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.08298.pdf)
>  Heat management plays an important role in engineering. Temperature field reconstruction of heat source systems (TFR-HSS) with limited monitoring tensors, performs an essential role in heat management. However, prior methods with common interpolations usually cannot provide accurate reconstruction. In addition, there exists no public dataset for widely research of reconstruction methods to further boost the field reconstruction in engineering. To overcome this problem, this work construct a specific dataset, namely TFRD, for TFR-HSS task with commonly used methods, including the interpolation methods and the surrogate model based methods, as baselines to advance the research over temperature field reconstruction. First, the TFR-HSS task is mathematically modelled from real-world engineering problem and three types of numerically modellings have been constructed to transform the problem into discrete mapping forms. Besides, this work selects four typical reconstruction problem with different heat source information and boundary conditions and generate the standard samples as training and testing samples for further research. Finally, a comprehensive review of the prior methods for TFR-HSS task as well as recent widely used deep learning methods is given and we provide a performance analysis of typical methods on TFRD, which can be served as the baseline results on this benchmark.      
### 53.An analytic physically motivated model of the mammalian cochlea  [ :arrow_down: ](https://arxiv.org/pdf/2012.15750.pdf)
>  We develop an analytic model of the mammalian cochlea. We use a mixed physical-phenomenological approach by utilizing existing work on the physics of classical box-representations of the cochlea, and behavior of recent data-derived wavenumber estimates. Spatial variation is incorporated through a single independent variable that combines space and frequency. We arrive at closed-form expressions for the organ of Corti velocity, its impedance, the pressure difference across the organ of Corti, and its wavenumber. We perform model tests using real and imaginary parts of chinchilla data from multiple locations and for multiple variables. The model also predicts impedances that are qualitatively consistent with current literature. For implementation, the model can leverage existing efforts for both filter bank and filter cascade models that target improved algorithmic or analog circuit efficiencies. The simplicity of the cochlear model, its small number of model constants, its ability to capture the variation of tuning, its closed-form expressions for physically-interrelated variables, and the form of these expressions that allows for easily determining one variable from another make the model appropriate for analytic and digital auditory filter implementations as discussed here, as well as for extracting macromechanical insights regarding how the cochlea works.      
