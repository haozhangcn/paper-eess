# ArXiv eess --Mon, 2 Aug 2021
### 1.DCT2net: an interpretable shallow CNN for image denoising  [ :arrow_down: ](https://arxiv.org/pdf/2107.14803.pdf)
>  This work tackles the issue of noise removal from images, focusing on the well-known DCT image denoising algorithm. The latter, stemming from signal processing, has been well studied over the years. Though very simple, it is still used in crucial parts of state-of-the-art "traditional" denoising algorithms such as BM3D. Since a few years however, deep convolutional neural networks (CNN) have outperformed their traditional counterparts, making signal processing methods less attractive. In this paper, we demonstrate that a DCT denoiser can be seen as a shallow CNN and thereby its original linear transform can be tuned through gradient descent in a supervised manner, improving considerably its performance. This gives birth to a fully interpretable CNN called DCT2net. To deal with remaining artifacts induced by DCT2net, an original hybrid solution between DCT and DCT2net is proposed combining the best that these two methods can offer; DCT2net is selected to process non-stationary image patches while DCT is optimal for piecewise smooth patches. Experiments on artificially noisy images demonstrate that two-layer DCT2net provides comparable results to BM3D and is as fast as DnCNN algorithm composed of more than a dozen of layers.      
### 2.A Multi-Head Relevance Weighting Framework For Learning Raw Waveform Audio Representations  [ :arrow_down: ](https://arxiv.org/pdf/2107.14793.pdf)
>  In this work, we propose a multi-head relevance weighting framework to learn audio representations from raw waveforms. The audio waveform, split into windows of short duration, are processed with a 1-D convolutional layer of cosine modulated Gaussian filters acting as a learnable filterbank. The key novelty of the proposed framework is the introduction of multi-head relevance on the learnt filterbank representations. Each head of the relevance network is modelled as a separate sub-network. These heads perform representation enhancement by generating weight masks for different parts of the time-frequency representation learnt by the parametric acoustic filterbank layer. The relevance weighted representations are fed to a neural classifier and the whole system is trained jointly for the audio classification objective. Experiments are performed on the DCASE2020 Task 1A challenge as well as the Urban Sound Classification (USC) tasks. In these experiments, the proposed approach yields relative improvements of 10% and 23% respectively for the DCASE2020 and USC datasets over the mel-spectrogram baseline. Also, the analysis of multi-head relevance weights provides insights on the learned representations.      
### 3.A guided edge-aware smoothing-sharpening filter based on patch interpolation model and generalized Gamma distribution  [ :arrow_down: ](https://arxiv.org/pdf/2107.14765.pdf)
>  Smoothing and sharpening are two fundamental image processing operations. The latter is usually related to the former through the unsharp masking algorithm. In this paper, we develop a new type of filter which performs smoothing or sharpening via a tuning parameter. The development of the new filter is based on (1) a new Laplacian-based filter formulation which unifies the smoothing and sharpening operations, (2) a patch interpolation model similar to that used in the guided filter which provides edge-awareness capability, and (3) the generalized Gamma distribution which is used as the prior for parameter estimation. We have conducted detailed studies on the properties of two versions of the proposed filter (self-guidance and external guidance). We have also conducted experiments to demonstrate applications of the proposed filter. In the self-guidance case, we have developed adaptive smoothing and sharpening algorithms based on texture, depth and blurriness information extracted from an image. Applications include enhancing human face images, producing shallow depth of field effects, focus-based image enhancement, and seam carving. In the external guidance case, we have developed new algorithms for combining flash and no-flash images and for enhancing multi-spectral images using a panchromatic image.      
### 4.Deep Learning Framework for Hybrid Analog-Digital Signal Processing in mmWave Massive-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.14704.pdf)
>  Hybrid analog-digital signal processing (HSP) is an enabling technology to harvest the potential of millimeter-wave (mmWave) massive-MIMO communications. In this paper, we present a general deep learning (DL) framework for efficient design and implementation of HSP-based massive-MIMO systems. Exploiting the fact that any complex matrix can be written as a scaled sum of two matrices with unit-modulus entries, a novel analog deep neural network (ADNN) structure is first developed which can be implemented with common radio frequency (RF) components. This structure is then embedded into an extended hybrid analog-digital deep neural network (HDNN) architecture which facilitates the implementation of mmWave massive-MIMO systems while improving their performance. In particular, the proposed HDNN architecture enables HSP-based massive-MIMO transceivers to approximate any desired transmitter and receiver mapping with arbitrary precision. To demonstrate the capabilities of the proposed DL framework, we present a new HDNN-based beamformer design that can achieve the same performance as fully-digital beamforming, with reduced number of RF chains. Finally, simulation results are presented confirming the superiority of the proposed HDNN design over existing hybrid beamforming schemes.      
### 5.Deadbeat observer based switched linear system identification  [ :arrow_down: ](https://arxiv.org/pdf/2107.14571.pdf)
>  In this paper, we present a methodology to identify discrete-time state-space switched linear systems (SLSs) from input-output measurements. Continuous-state is not assumed to be measured. The key step is a deadbeat observer based transformation to a switched auto-regressive with exogenous input (SARX) model. <br>This transformation reduces the state-space identification problem to a SARX model estimation problem. Overfitting issues are tackled. The switch and parameter identifiability and the persistence of excitation conditions on the inputs are discussed in detail. The discrete-states are identified in the observer domain by solving a non-convex sparse optimization problem. A clustering algorithm reveals the discrete-states under mild assumptions on the system structure and the dwell times. The switching sequence is estimated from the input-output data by the multi-variable output error state space (MOESP) algorithm and a variant modified from it. A convex relaxation of the sparse optimization problem yields the block basis pursuit denoising (BBPDN) algorithm. Theoretical findings are supported by means of a detailed numerical example. In this example, the proposed methodology is also compared to another identification scheme in hybrid systems literature.      
### 6.Towards a Sustainable Power Grid: Stochastic Hierarchical Planning for High Renewable Integration  [ :arrow_down: ](https://arxiv.org/pdf/2107.14558.pdf)
>  Driven by ambitious renewable portfolio standards, large-scale inclusion of variable energy resources (such as wind and solar) are expected to introduce unprecedented levels of uncertainty into power system operations. The current practice of operations planning with deterministic optimization models may be ill-suited for a future with abundant uncertainty. To overcome the potential reliability and economic challenges, we present a stochastic hierarchical planning (SHP) framework. This framework captures operations at day-ahead, short-term and hour-ahead timescales, along with the interactions between the stochastic processes and decisions. In contrast to earlier studies where stochastic optimization of individual problems (e.g., unit commitment, economic dispatch) have been studied, this paper studies an integrated framework of \emph{planning under uncertainty}, where stochastic optimization models are stitched together in a hierarchical setting which parallels the deterministic hierarchical planning approach that is widely adopted in the power industry. Our experiments, based on the NREL-118 dataset, reveal that under high renewable penetration, significant operational improvements can be expected by transitioning to the SHP paradigm. In particular, the computational results show that significant improvements can be achieved in several metrics, including system reliability, environmental sustainability, and system economics, solely by making a strategic choice to adopt the new SHP paradigm.      
### 7.Topological Similarity Index and Loss Function for Blood Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.14531.pdf)
>  Blood vessel segmentation is one of the most studied topics in computer vision, due to its relevance in daily clinical practice. Despite the evolution the field has been facing, especially after the dawn of deep learning, important challenges are still not solved. One of them concerns the consistency of the topological properties of the vascular trees, given that the best performing methodologies do not directly penalize mistakes such as broken segments and end up producing predictions with disconnected trees. This is particularly relevant in graph-like structures, such as blood vessel trees, given that it puts at risk the characterization steps that follow the segmentation task. In this paper, we propose a similarity index which captures the topological consistency of the predicted segmentations having as reference the ground truth. We also design a novel loss function based on the morphological closing operator and show how it allows to learn deep neural network models which produce more topologically coherent masks. Our experiments target well known retinal benchmarks and a coronary angiogram database.      
### 8.Model-based Synthetic Data-driven Learning (MOST-DL): Application in Single-shot T2 Mapping with Severe Head Motion Using Overlapping-echo Acquisition  [ :arrow_down: ](https://arxiv.org/pdf/2107.14521.pdf)
>  Data-driven learning algorithm has been successfully applied to facilitate reconstruction of medical imaging. However, real-world data needed for supervised learning are typically unavailable or insufficient, especially in the field of magnetic resonance imaging (MRI). Synthetic training samples have provided a potential solution for such problem, while the challenge brought by various non-ideal situations were usually encountered especially under complex experimental conditions. In this study, a general framework, Model-based Synthetic Data-driven Learning (MOST-DL), was proposed to generate paring data for network training to achieve robust T2 mapping using overlapping-echo acquisition under severe head motion accompanied with inhomogeneous RF field. We decomposed this challenging task into parallel reconstruction and motion correction according to a forward model. The neural network was first trained in pure synthetic dataset and then evaluated with in vivo human brain. Experiments showed that MOST-DL method significantly reduces ghosting and motion artifacts in T2 maps in the presence of random and continuous subject movement. We believe that the proposed approach may open a door for solving similar problems with other MRI acquisition methods and can be extended to other areas of medical imaging.      
### 9.On-Line Audio-to-Lyrics Alignment Based on a Reference Performance  [ :arrow_down: ](https://arxiv.org/pdf/2107.14496.pdf)
>  Audio-to-lyrics alignment has become an increasingly active research task in MIR, supported by the emergence of several open-source datasets of audio recordings with word-level lyrics annotations. However, there are still a number of open problems, such as a lack of robustness in the face of severe duration mismatches between audio and lyrics representation; a certain degree of language-specificity caused by acoustic differences across languages; and the fact that most successful methods in the field are not suited to work in real-time. Real-time lyrics alignment (tracking) would have many useful applications, such as fully automated subtitle display in live concerts and opera. In this work, we describe the first real-time-capable audio-to-lyrics alignment pipeline that is able to robustly track the lyrics of different languages, without additional language information. The proposed model predicts, for each audio frame, a probability vector over (European) phoneme classes, using a very small temporal context, and aligns this vector with a phoneme posteriogram matrix computed beforehand from another recording of the same work, which serves as a reference and a proxy to the written-out lyrics. We evaluate our system's tracking accuracy on the challenging genre of classical opera. Finally, robustness to out-of-training languages is demonstrated in an experiment on Jingju (Beijing opera).      
### 10.Graph-PIT: Generalized permutation invariant training for continuous separation of arbitrary numbers of speakers  [ :arrow_down: ](https://arxiv.org/pdf/2107.14446.pdf)
>  Automatic transcription of meetings requires handling of overlapped speech, which calls for continuous speech separation (CSS) systems. The uPIT criterion was proposed for utterance-level separation with neural networks and introduces the constraint that the total number of speakers must not exceed the number of output channels. When processing meeting-like data in a segment-wise manner, i.e., by separating overlapping segments independently and stitching adjacent segments to continuous output streams, this constraint has to be fulfilled for any segment. In this contribution, we show that this constraint can be significantly relaxed. We propose a novel graph-based PIT criterion, which casts the assignment of utterances to output channels in a graph coloring problem. It only requires that the number of concurrently active speakers must not exceed the number of output channels. As a consequence, the system can process an arbitrary number of speakers and arbitrarily long segments and thus can handle more diverse scenarios. Further, the stitching algorithm for obtaining a consistent output order in neighboring segments is of less importance and can even be eliminated completely, not the least reducing the computational effort. Experiments on meeting-style WSJ data show improvements in recognition performance over using the uPIT criterion.      
### 11.Speeding Up Permutation Invariant Training for Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2107.14445.pdf)
>  Permutation invariant training (PIT) is a widely used training criterion for neural network-based source separation, used for both utterance-level separation with utterance-level PIT (uPIT) and separation of long recordings with the recently proposed Graph-PIT. When implemented naively, both suffer from an exponential complexity in the number of utterances to separate, rendering them unusable for large numbers of speakers or long realistic recordings. We present a decomposition of the PIT criterion into the computation of a matrix and a strictly monotonously increasing function so that the permutation or assignment problem can be solved efficiently with several search algorithms. The Hungarian algorithm can be used for uPIT and we introduce various algorithms for the Graph-PIT assignment problem to reduce the complexity to be polynomial in the number of utterances.      
### 12.Single image deep defocus estimation and its applications  [ :arrow_down: ](https://arxiv.org/pdf/2107.14443.pdf)
>  The depth information is useful in many image processing applications. However, since taking a picture is a process of projection of a 3D scene onto a 2D imaging sensor, the depth information is embedded in the image. Extracting the depth information from the image is a challenging task. A guiding principle is that the level of blurriness due to defocus is related to the distance between the object and the focal plane. Based on this principle and the widely used assumption that Gaussian blur is a good model for defocus blur, we formulate the problem of estimating the spatially varying defocus blurriness as a Gaussian blur classification problem. We solved the problem by training a deep neural network to classify image patches into one of the 20 levels of blurriness. We have created a dataset of more than 500000 image patches of size 32x32 which are used to train and test several well-known network models. We find that MobileNetV2 is suitable for this application due to its low memory requirement and high accuracy. The trained model is used to determine the patch blurriness which is then refined by applying an iterative weighted guided filter. The result is a defocus map that carries the information of the degree of blurriness for each pixel. We compare the proposed method with state-of-the-art techniques and we demonstrate its successful applications in adaptive image enhancement, defocus magnification, and multi-focus image fusion.      
### 13.USC: An Open-Source Uzbek Speech Corpus and Initial Speech Recognition Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2107.14419.pdf)
>  We present a freely available speech corpus for the Uzbek language and report preliminary automatic speech recognition (ASR) results using both the deep neural network hidden Markov model (DNN-HMM) and end-to-end (E2E) architectures. The Uzbek speech corpus (USC) comprises 958 different speakers with a total of 105 hours of transcribed audio recordings. To the best of our knowledge, this is the first open-source Uzbek speech corpus dedicated to the ASR task. To ensure high quality, the USC has been manually checked by native speakers. We first describe the design and development procedures of the USC, and then explain the conducted ASR experiments in detail. The experimental results demonstrate promising results for the applicability of the USC for ASR. Specifically, 18.1% and 17.4% word error rates were achieved on the validation and test sets, respectively. To enable experiment reproducibility, we share the USC dataset, pre-trained models, and training recipes in our GitHub repository.      
### 14.Optimal Variable Speed Limit Control Strategy on Freeway Segments under Fog Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2107.14406.pdf)
>  Fog is a critical external factor that threatens traffic safety on freeways. Variable speed limit (VSL) control can effectively harmonize vehicle speed and improve safety. However, most existing weather-related VSL controllers are limited to adapt to the dynamic traffic environment. This study developed optimal VSL control strategy under fog conditions with fully consideration of factors that affect traffic safety risks. The crash risk under fog conditions was estimated using a crash risk prediction model based on Bayesian logistic regression. The traffic flow with VSL control was simulated by a modified cell transmission model (MCTM). The optimal factors of VSL control were obtained by solving an optimization problem that coordinated safety and mobility with the help of the genetic algorithm. An example of I-405 in California, USA was designed to simulate and evaluate the effects of the proposed VSL control strategy. The optimal VSL control factors under fog conditions were compared with sunny conditions, and different placements of VSL signs were evaluated. Results showed that the optimal VSL control strategy under fog conditions changed the speed limit more cautiously. The VSL control under fog conditions in this study effectively reduced crash risks without significantly increasing travel time, which is up to 37.15% reduction of risks and only 0.48% increase of total travel time. The proposed VSL control strategy is expected to be of great use in the development of VSL systems to enhance freeway safety under fog conditions.      
### 15.Fine-Grained Classroom Activity Detection from Audio with Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.14369.pdf)
>  Instructors are increasingly incorporating student-centered learning techniques in their classrooms to improve learning outcomes. In addition to lecture, these class sessions involve forms of individual and group work, and greater rates of student-instructor interaction. Quantifying classroom activity is a key element of accelerating the evaluation and refinement of innovative teaching practices, but manual annotation does not scale. In this manuscript, we present advances to the young application area of automatic classroom activity detection from audio. Using a university classroom corpus with nine activity labels (e.g., "lecture," "group work," "student question"), we propose and evaluate deep fully connected, convolutional, and recurrent neural network architectures, comparing the performance of mel-filterbank, OpenSmile, and self-supervised acoustic features. We compare 9-way classification performance with 5-way and 4-way simplifications of the task and assess two types of generalization: (1) new class sessions from previously seen instructors, and (2) previously unseen instructors. We obtain strong results on the new fine-grained task and state-of-the-art on the 4-way task: our best model obtains frame-level error rates of 6.2%, 7.7% and 28.0% when generalizing to unseen instructors for the 4-way, 5-way, and 9-way classification tasks, respectively (relative reductions of 35.4%, 48.3% and 21.6% over a strong baseline). When estimating the aggregate time spent on classroom activities, our average root mean squared error is 1.64 minutes per class session, a 54.9% relative reduction over the baseline.      
### 16.Deep Quantized Representation for Enhanced Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2107.14368.pdf)
>  While machine learning approaches have shown remarkable performance in biomedical image analysis, most of these methods rely on high-quality and accurate imaging data. However, collecting such data requires intensive and careful manual effort. One of the major challenges in imaging the Shoot Apical Meristem (SAM) of Arabidopsis thaliana, is that the deeper slices in the z-stack suffer from different perpetual quality-related problems like poor contrast and blurring. These quality-related issues often lead to the disposal of the painstakingly collected data with little to no control on quality while collecting the data. Therefore, it becomes necessary to employ and design techniques that can enhance the images to make them more suitable for further analysis. In this paper, we propose a data-driven Deep Quantized Latent Representation (DQLR) methodology for high-quality image reconstruction in the Shoot Apical Meristem (SAM) of Arabidopsis thaliana. Our proposed framework utilizes multiple consecutive slices in the z-stack to learn a low dimensional latent space, quantize it and subsequently perform reconstruction using the quantized representation to obtain sharper images. Experiments on a publicly available dataset validate our methodology showing promising results.      
### 17.New trends in indoor positioning based on WiFi and machine learning: A systematic review  [ :arrow_down: ](https://arxiv.org/pdf/2107.14356.pdf)
>  Currently there is no standard indoor positioning system, similar to outdoor GPS. However, WiFi signals have been used in a large number of proposals to achieve the above positioning, many of which use machine learning to do so. But what are the most commonly used techniques in machine learning? What accuracy do they achieve? Where have they been tested? This article presents a systematic review of works between 2019 and 2021 that use WiFi as the signal for positioning and machine learning models to estimate indoor position. 64 papers have been identified as relevant, which have been systematically analyzed for a better understanding of the current situation in different aspects. The results show that indoor positioning based on WiFi trends use neural network-based models, evaluated in empirical experiments. Despite this, many works still conduct an assessment in small areas, which can influence the goodness of the results presented.      
### 18.LPV Delay-Dependent Sampled-Data Output-Feedback Control of Fueling in Spark Ignition Engines  [ :arrow_down: ](https://arxiv.org/pdf/2107.14321.pdf)
>  We propose a delay-dependent sampled-data output-feedback LPV control technique to address the air-fuel ratio (AFR) regulation problem in spark ignition (SI) engines. AFR control and advanced fueling strategies are essential for maximizing fuel economy while minimizing harmful exhaust emissions. The fuel path of the SI engine, as well as the three-way catalyst (TWC) simplified dynamics, have been captured by a continuous-time linear parameter-varying (LPV) system with varying time delay, where the system dynamics rely on the engine speed, defined as the system's scheduling parameter. The interconnection of the continuous-time plant and a digital controller through analog-to-digital and digital-to-analog converter devices forms a hybrid closed-loop configuration. Therefore, in order to benefit from continuous-time control synthesis tools, the input-delay method has been employed to transform the hybrid closed-loop system into the continuous-time domain with system inherent time delay and an additional delay imposed by the mapping approach. The designed sampled-data gain scheduled output-feedback controller seeks to establish the closed-loop asymptotic stability and a prescribed level of performance for the LPV system with an arbitrarily varying time delay and varying sampling time, where the synthesis results are provided in a convex linear matrix inequality (LMI) constraint setting. Finally, several closed-loop simulation scenarios are conducted, and comparisons are provided to demonstrate the proposed methodology's performance in achieving precise reference AFR tracking and disturbance attenuation.      
### 19.Distributed Identification of Contracting and/or Monotone Network Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2107.14309.pdf)
>  This paper proposes methods for identification of large-scale networked systems with guarantees that the resulting model will be contracting -- a strong form of nonlinear stability -- and/or monotone, i.e. order relations between states are preserved. The main challenges that we address are: simultaneously searching for model parameters and a certificate of stability, and scalability to networks with hundreds or thousands of nodes. We propose a model set that admits convex constraints for stability and monotonicity, and has a separable structure that allows distributed identification via the alternating directions method of multipliers (ADMM). The performance and scalability of the approach is illustrated on a variety of linear and non-linear case studies, including a nonlinear traffic network with a 200-dimensional state space.      
### 20.Automatic Multi-Stain Registration of Whole Slide Images in Histopathology  [ :arrow_down: ](https://arxiv.org/pdf/2107.14292.pdf)
>  Joint analysis of multiple biomarker images and tissue morphology is important for disease diagnosis, treatment planning and drug development. It requires cross-staining comparison among Whole Slide Images (WSIs) of immuno-histochemical and hematoxylin and eosin (H&amp;E) microscopic slides. However, automatic, and fast cross-staining alignment of enormous gigapixel WSIs at single-cell precision is challenging. In addition to morphological deformations introduced during slide preparation, there are large variations in cell appearance and tissue morphology across different staining. In this paper, we propose a two-step automatic feature-based cross-staining WSI alignment to assist localization of even tiny metastatic foci in the assessment of lymph node. Image pairs were aligned allowing for translation, rotation, and scaling. The registration was performed automatically by first detecting landmarks in both images, using the scale-invariant image transform (SIFT), followed by the fast sample consensus (FSC) protocol for finding point correspondences and finally aligned the images. The Registration results were evaluated using both visual and quantitative criteria using the Jaccard index. The average Jaccard similarity index of the results produced by the proposed system is 0.942 when compared with the manual registration.      
### 21.Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs  [ :arrow_down: ](https://arxiv.org/pdf/2107.14795.pdf)
>  The recently-proposed Perceiver model obtains good results on several domains (images, audio, multimodal, point clouds) while scaling linearly in compute and memory with the input size. While the Perceiver supports many kinds of inputs, it can only produce very simple outputs such as class scores. Perceiver IO overcomes this limitation without sacrificing the original's appealing properties by learning to flexibly query the model's latent space to produce outputs of arbitrary size and semantics. Perceiver IO still decouples model depth from data size and still scales linearly with data size, but now with respect to both input and output sizes. The full Perceiver IO model achieves strong results on tasks with highly structured output spaces, such as natural language and visual understanding, StarCraft II, and multi-task and multi-modal domains. As highlights, Perceiver IO matches a Transformer-based BERT baseline on the GLUE language benchmark without the need for input tokenization and achieves state-of-the-art performance on Sintel optical flow estimation.      
### 22.Decentralized Power Allocation for MIMO-NOMA Vehicular Edge Computing Based on Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.14772.pdf)
>  Vehicular edge computing (VEC) is envisioned as a promising approach to process the explosive computation tasks of vehicular user (VU). In the VEC system, each VU allocates power to process partial tasks through offloading and the remaining tasks through local execution. During the offloading, each VU adopts the multi-input multi-out and non-orthogonal multiple access (MIMO-NOMA) channel to improve the channel spectrum efficiency and capacity. However, the channel condition is uncertain due to the channel interference among VUs caused by the MIMO-NOMA channel and the time-varying path-loss caused by the mobility of each VU. In addition, the task arrival of each VU is stochastic in the real world. The stochastic task arrival and uncertain channel condition affect greatly on the power consumption and latency of tasks for each VU. It is critical to design an optimal power allocation scheme considering the stochastic task arrival and channel variation to optimize the long-term reward including the power consumption and latency in the MIMO-NOMA VEC. Different from the traditional centralized deep reinforcement learning (DRL)-based scheme, this paper constructs a decentralized DRL framework to formulate the power allocation optimization problem, where the local observations are selected as the state. The deep deterministic policy gradient (DDPG) algorithm is adopted to learn the optimal power allocation scheme based on the decentralized DRL framework. Simulation results demonstrate that our proposed power allocation scheme outperforms the existing schemes.      
### 23.Feasibility Analysis of Fifth-generation (5G) Mobile Networks for Transmission of Medical Imaging Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.14661.pdf)
>  Next to higher data rates and lower latency, the upcoming fifth-generation mobile network standard will introduce a new service ecosystem. Concepts such as multi-access edge computing or network slicing will enable tailoring service level requirements to specific use-cases. In medical imaging, researchers and clinicians are currently working towards higher portability of scanners. This includes i) small scanners to be wheeled inside the hospital to the bedside and ii) conventional scanners provided via trucks to remote areas. Both use-cases introduce the need for mobile networks adhering to high safety standards and providing high data rates. These requirements could be met by fifth-generation mobile networks. In this work, we analyze the feasibility of transferring medical imaging data using the current state of development of fifth-generation mobile networks (3GPP Release 15). We demonstrate the potential of reaching 100 Mbit/s upload rates using already available consumer-grade hardware. Furthermore, we show an effective average data throughput of 50 Mbit/s when transferring medical images using out-of-the-box open-source software based on the Digital Imaging and Communications in Medicine (DICOM) standard. During transmissions, we sample the radio frequency bands to analyse the characteristics of the mobile radio network. Additionally, we discuss the potential of new features such as network slicing that will be introduced in forthcoming releases.      
### 24.Task 1A DCASE 2021: Acoustic Scene Classification with mismatch-devices using squeeze-excitation technique and low-complexity constraint  [ :arrow_down: ](https://arxiv.org/pdf/2107.14658.pdf)
>  Acoustic scene classification (ASC) is one of the most popular problems in the field of machine listening. The objective of this problem is to classify an audio clip into one of the predefined scenes using only the audio data. This problem has considerably progressed over the years in the different editions of DCASE. It usually has several subtasks that allow to tackle this problem with different approaches. The subtask presented in this report corresponds to a ASC problem that is constrained by the complexity of the model as well as having audio recorded from different devices, known as mismatch devices (real and simulated). The work presented in this report follows the research line carried out by the team in previous years. Specifically, a system based on two steps is proposed: a two-dimensional representation of the audio using the Gamamtone filter bank and a convolutional neural network using squeeze-excitation techniques. The presented system outperforms the baseline by about 17 percentage points.      
### 25.DadaGP: A Dataset of Tokenized GuitarPro Songs for Sequence Models  [ :arrow_down: ](https://arxiv.org/pdf/2107.14653.pdf)
>  Originating in the Renaissance and burgeoning in the digital era, tablatures are a commonly used music notation system which provides explicit representations of instrument fingerings rather than pitches. GuitarPro has established itself as a widely used tablature format and software enabling musicians to edit and share songs for musical practice, learning, and composition. In this work, we present DadaGP, a new symbolic music dataset comprising 26,181 song scores in the GuitarPro format covering 739 musical genres, along with an accompanying tokenized format well-suited for generative sequence models such as the Transformer. The tokenized format is inspired by event-based MIDI encodings, often used in symbolic music generation models. The dataset is released with an encoder/decoder which converts GuitarPro files to tokens and back. We present results of a use case in which DadaGP is used to train a Transformer-based model to generate new songs in GuitarPro format. We discuss other relevant use cases for the dataset (guitar-bass transcription, music style transfer and artist/genre classification) as well as ethical implications. DadaGP opens up the possibility to train GuitarPro score generators, fine-tune models on custom data, create new styles of music, AI-powered songwriting apps, and human-AI improvisation.      
### 26.Practical Attacks on Voice Spoofing Countermeasures  [ :arrow_down: ](https://arxiv.org/pdf/2107.14642.pdf)
>  Voice authentication has become an integral part in security-critical operations, such as bank transactions and call center conversations. The vulnerability of automatic speaker verification systems (ASVs) to spoofing attacks instigated the development of countermeasures (CMs), whose task is to tell apart bonafide and spoofed speech. Together, ASVs and CMs form today's voice authentication platforms, advertised as an impregnable access control mechanism. We develop the first practical attack on CMs, and show how a malicious actor may efficiently craft audio samples to bypass voice authentication in its strictest form. Previous works have primarily focused on non-proactive attacks or adversarial strategies against ASVs that do not produce speech in the victim's voice. The repercussions of our attacks are far more severe, as the samples we generate sound like the victim, eliminating any chance of plausible deniability. Moreover, the few existing adversarial attacks against CMs mistakenly optimize spoofed speech in the feature space and do not take into account the existence of ASVs, resulting in inferior synthetic audio that fails in realistic settings. We eliminate these obstacles through our key technical contribution: a novel joint loss function that enables mounting advanced adversarial attacks against combined ASV/CM deployments directly in the time domain. Our adversarials achieve concerning black-box success rates against state-of-the-art authentication platforms (up to 93.57\%). Finally, we perform the first targeted, over-telephony-network attack on CMs, bypassing several challenges and enabling various potential threats, given the increased use of voice biometrics in call centers. Our results call into question the security of modern voice authentication systems in light of the real threat of attackers bypassing these measures to gain access to users' most valuable resources.      
### 27.An iterative coordinate descent algorithm to compute sparse low-rank approximations  [ :arrow_down: ](https://arxiv.org/pdf/2107.14608.pdf)
>  In this paper, we describe a new algorithm to build a few sparse principal components from a given data matrix. Our approach does not explicitly create the covariance matrix of the data and can be viewed as an extension of the Kogbetliantz algorithm to build an approximate singular value decomposition for a few principal components. We show the performance of the proposed algorithm to recover sparse principal components on various datasets from the literature and perform dimensionality reduction for classification applications.      
### 28.SmartHand: Towards Embedded Smart Hands for Prosthetic and Robotic Applications  [ :arrow_down: ](https://arxiv.org/pdf/2107.14598.pdf)
>  The sophisticated sense of touch of the human hand significantly contributes to our ability to safely, efficiently, and dexterously manipulate arbitrary objects in our environment. Robotic and prosthetic devices lack refined, tactile feedback from their end-effectors, leading to counterintuitive and complex control strategies. To address this lack, tactile sensors have been designed and developed, but they often offer an insufficient spatial and temporal resolution. This paper focuses on overcoming these issues by designing a smart embedded system, called SmartHand, enabling the acquisition and real-time processing of high-resolution tactile information from a hand-shaped multi-sensor array for prosthetic and robotic applications. We acquire a new tactile dataset consisting of 340,000 frames while interacting with 16 everyday objects and the empty hand, i.e., a total of 17 classes. The design of the embedded system minimizes response latency in classification, by deploying a small yet accurate convolutional neural network on a high-performance ARM Cortex-M7 microcontroller. Compared to related work, our model requires one order of magnitude less memory and 15.6x fewer computations while achieving similar inter-session accuracy and up to 98.86% and 99.83% top-1 and top-3 cross-validation accuracy, respectively. Experimental results show a total power consumption of 505mW and a latency of only 100ms.      
### 29.Dark soliton detection using persistent homology  [ :arrow_down: ](https://arxiv.org/pdf/2107.14594.pdf)
>  Classifying experimental image data often requires manual identification of qualitative features, which is difficult to automate. Existing automated approaches based on deep convolutional neural networks can achieve accuracy comparable to human classifiers, but require extensive training data and computational resources. Here we show that the emerging framework of topological data analysis can be used to rapidly and reliably identify qualitative features in image data, enabling their classification using easily-interpretable linear models. Specifically, we consider the task of identifying dark solitons using a freely-available dataset of 6257 labelled Bose-Einstein condensate (BEC) density images. We use point summaries of the images' topological features -- their persistent entropy and lifetime $p$-norms -- to train logistic regression models. The models attain performance comparable to neural networks using a fraction of the training data, classifying images 30 times faster.      
### 30.TASK3 DCASE2021 Challenge: Sound event localization and detection using squeeze-excitation residual CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2107.14561.pdf)
>  Sound event localisation and detection (SELD) is a problem in the field of automatic listening that aims at the temporal detection and localisation (direction of arrival estimation) of sound events within an audio clip, usually of long duration. Due to the amount of data present in the datasets related to this problem, solutions based on deep learning have positioned themselves at the top of the state of the art. Most solutions are based on 2D representations of the audio (different spectrograms) that are processed by a convolutional-recurrent network. The motivation of this submission is to study the squeeze-excitation technique in the convolutional part of the network and how it improves the performance of the system. This study is based on the one carried out by the same team last year. This year, it has been decided to study how this technique improves each of the datasets (last year only the MIC dataset was studied). This modification shows an improvement in the performance of the system compared to the baseline using MIC dataset.      
### 31.Evaluating the COVID-19 Identification ResNet (CIdeR) on the INTERSPEECH COVID-19 from Audio Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2107.14549.pdf)
>  We report on cross-running the recent COVID-19 Identification ResNet (CIdeR) on the two Interspeech 2021 COVID-19 diagnosis from cough and speech audio challenges: ComParE and DiCOVA. CIdeR is an end-to-end deep learning neural network originally designed to classify whether an individual is COVID-positive or COVID-negative based on coughing and breathing audio recordings from a published crowdsourced dataset. In the current study, we demonstrate the potential of CIdeR at binary COVID-19 diagnosis from both the COVID-19 Cough and Speech Sub-Challenges of INTERSPEECH 2021, ComParE and DiCOVA. CIdeR achieves significant improvements over several baselines.      
### 32.Artist Similarity with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.14541.pdf)
>  Artist similarity plays an important role in organizing, understanding, and subsequently, facilitating discovery in large collections of music. In this paper, we present a hybrid approach to computing similarity between artists using graph neural networks trained with triplet loss. The novelty of using a graph neural network architecture is to combine the topology of a graph of artist connections with content features to embed artists into a vector space that encodes similarity. To evaluate the proposed method, we compile the new OLGA dataset, which contains artist similarities from AllMusic, together with content features from AcousticBrainz. With 17,673 artists, this is the largest academic artist similarity dataset that includes content-based features to date. Moreover, we also showcase the scalability of our approach by experimenting with a much larger proprietary dataset. Results show the superiority of the proposed approach over current state-of-the-art methods for music similarity. Finally, we hope that the OLGA dataset will facilitate research on data-driven models for artist similarity.      
### 33.Collaboration in the Sky: A Distributed Framework for Task Offloading and Resource Allocation in Multi-Access Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2107.14502.pdf)
>  Recently, unmanned aerial vehicles (UAVs) assisted multi-access edge computing (MEC) systems emerged as a promising solution for providing computation services to mobile users outside of terrestrial infrastructure coverage. As each UAV operates independently, however, it is challenging to meet the computation demands of the mobile users due to the limited computing capacity at the UAV's MEC server as well as the UAV's energy constraint. Therefore, collaboration among UAVs is needed. In this paper, a collaborative multi-UAV-assisted MEC system integrated with a MEC-enabled terrestrial base station (BS) is proposed. Then, the problem of minimizing the total latency experienced by the mobile users in the proposed system is studied by optimizing the offloading decision as well as the allocation of communication and computing resources while satisfying the energy constraints of both mobile users and UAVs. The proposed problem is shown to be a non-convex, mixed-integer nonlinear problem (MINLP) that is intractable. Therefore, the formulated problem is decomposed into three subproblems: i) users tasks offloading decision problem, ii) communication resource allocation problem and iii) UAV-assisted MEC decision problem. Then, the Lagrangian relaxation and alternating direction method of multipliers (ADMM) methods are applied to solve the decomposed problems, alternatively. Simulation results show that the proposed approach reduces the average latency by up to 40.7\% and 4.3\% compared to the greedy and exhaustive search methods.      
### 34.Feasibility of GNSS-free Localization: A TDoA-based Approach Using LoRaWAN  [ :arrow_down: ](https://arxiv.org/pdf/2107.14494.pdf)
>  LoRaWAN has garnered tremendous attention owing to the low power consumption of end nodes, long range, high resistance to multipath, low cost, and use of license-free sub-GHz bands. Consequently, LoRaWAN is gradually replacing Wi-Fi and Bluetooth in sundry IoT applications including utility metering, smart cities, and localization. Localization, in particular, has already witnessed a surge of alternatives to Global Navigation Satellite System (GNSS), based on Wi-Fi, Bluetooth, Ultra Wide Band, 5G, etc. in indoor and low power domains due to the poor indoor coverage and high power consumption of GNSS. With the need for localization only shooting up with dense IoT deployments, LoRaWAN is seen as a promising solution in this context. Indeed, many attempts employing various techniques such as Time of Arrival (ToA), Time Difference of Arrival (TDoA), and Received Signal Strength Index (RSSI) have been made to achieve localization using LoRaWAN. However, a significant drawback in this scenario is the lack of extensive data on path loss and signal propagation modeling, particularly in Indian cityscapes. Another demerit is the use of GNSS at some stage primarily for time synchronization of gateways. In this work, we attempt to nullify these two disadvantages of LoRaWAN based localization. The first part of this work presents experimental data of LoRaWAN transmissions inside a typical city building to study signal propagation and path loss. The latter part proposes a standalone GNSS-free localization approach using LoRaWAN that is achieved by applying a collaborative, TDoA-based methodology. An additional stationary node is introduced into the network to allow the synchronization of gateways without GNSS. Finally, the distribution of localization error in a triangle of gateways and the effect of timing resolution, time-on-air, and duty cycle constraints on it are investigated.      
### 35.Quotients of probabilistic Boolean networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.14466.pdf)
>  A probabilistic Boolean network (PBN) is a discrete-time system composed of a collection of Boolean networks between which the PBN switches in a stochastic manner. This paper focuses on the study of quotients of PBNs. Given a PBN and an equivalence relation on its state set, we consider a probabilistic transition system that is generated by the PBN; the resulting quotient transition system then automatically captures the quotient behavior of this PBN. We therefore describe a method for obtaining a probabilistic Boolean system that generates the transitions of the quotient transition system. Applications of this quotient description are discussed, and it is shown that for PBNs, controller synthesis can be performed easily by first controlling a quotient system and then lifting the control law back to the original network. A biological example is given to show the usefulness of the developed results.      
### 36.High-Efficiency Resonant Beam Charging and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2107.14458.pdf)
>  Simultaneous wireless information and power transfer (SWIPT) has been envisioned as an enabling technology for future 6G by providing high-efficiency power transfer and high-rate data transmissions concurrently. In this paper, we propose a resonant beam charging and communication (RBCC) system utilizing the telescope internal modulator (TIM) and the semiconductor gain medium. TIM can concentrate the diverged beam into a small-size gain module, thus the propagation loss is reduced and the transmission efficiency is enhanced. Since the semiconductor gain medium has better energy absorption capacity compared with the traditional solid-state one, the overall energy conversion efficiency can be improved. We establish an analytical model of this RBCC system for SWIPT and evaluate its stability, output energy, and spectral efficiency. Numerical analysis shows that the proposed RBCC system can realize stable SWIPT over 10 meters, whose energy conversion efficiency is increased by 14 times compared with the traditional system using the solid-state gain medium without TIM, and the spectrum efficiency can be above 15 bit/s/Hz.      
### 37.Synth-by-Reg (SbR): Contrastive learning for synthesis-based registration of paired images  [ :arrow_down: ](https://arxiv.org/pdf/2107.14449.pdf)
>  Nonlinear inter-modality registration is often challenging due to the lack of objective functions that are good proxies for alignment. Here we propose a synthesis-by-registration method to convert this problem into an easier intra-modality task. We introduce a registration loss for weakly supervised image translation between domains that does not require perfectly aligned training data. This loss capitalises on a registration U-Net with frozen weights, to drive a synthesis CNN towards the desired translation. We complement this loss with a structure preserving constraint based on contrastive learning, which prevents blurring and content shifts due to overfitting. We apply this method to the registration of histological sections to MRI slices, a key step in 3D histology reconstruction. Results on two different public datasets show improvements over registration based on mutual information (13% reduction in landmark error) and synthesis-based algorithms such as CycleGAN (11% reduction), and are comparable to a registration CNN with label supervision.      
### 38.ARCSnake: Reconfigurable Snake-Like Robot with Archimedean Screw Propulsion for Multi-Domain Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2107.14427.pdf)
>  Exploring and navigating in extreme environments, such as caves, oceans, and planetary bodies, are often too hazardous for humans, and as such, robots are possible surrogates. These robots are met with significant locomotion challenges that require traversing a wide range of surface roughnesses and topologies. Previous locomotion strategies, involving wheels or ambulatory motion, such as snake platforms, have success on specific surfaces but fail in others which could be detrimental in exploration and navigation missions. In this paper, we present a novel approach that combines snake-like robots with an Archimedean screw locomotion mechanism to provide multiple, effective mobility strategies in a large range of environments, including those that are difficult to traverse for wheeled and ambulatory robots. This work develops a robotic system called ARCSnake to demonstrate this locomotion principle and tested it in a variety of different terrains and environments in order to prove its controllable, multi-domain, navigation capabilities. These tests show a wide breadth of scenarios that ARCSnake can handle, hence demonstrating its ability to traverse through extreme terrains.      
### 39.Lunaport: Math, Mechanics &amp; Transport  [ :arrow_down: ](https://arxiv.org/pdf/2107.14423.pdf)
>  Issues for transport facilities on the lunar surface related to science, engineering, architecture, and human-factors are discussed. Logistic decisions made in the next decade may be crucial to financial success. In addition to outlining some of the problems and their relations with math and computation, the paper provides useful resources for decision-makers, scientists, and engineers.      
### 40.Towards the Unification and Data-Driven Synthesis of Autonomous Vehicle Safety Concepts  [ :arrow_down: ](https://arxiv.org/pdf/2107.14412.pdf)
>  As safety-critical autonomous vehicles (AVs) will soon become pervasive in our society, a number of safety concepts for trusted AV deployment have been recently proposed throughout industry and academia. Yet, agreeing upon an "appropriate" safety concept is still an elusive task. In this paper, we advocate for the use of Hamilton Jacobi (HJ) reachability as a unifying mathematical framework for comparing existing safety concepts, and propose ways to expand its modeling premises in a data-driven fashion. Specifically, we show that (i) existing predominant safety concepts can be embedded in the HJ reachability framework, thereby enabling a common language for comparing and contrasting modeling assumptions, and (ii) HJ reachability can serve as an inductive bias to effectively reason, in a data-driven context, about two critical, yet often overlooked aspects of safety: responsibility and context-dependency.      
### 41.Towards Efficient Large-Scale Network Slicing: An LP Rounding-and-Refinement Approach  [ :arrow_down: ](https://arxiv.org/pdf/2107.14404.pdf)
>  In this paper, we propose an efficient algorithm for the network slicing problem which attempts to map multiple customized virtual network requests (also called services) to a common shared network infrastructure and allocate network resources to meet diverse service requirements. The problem has been formulated as a mixed integer linear programming (MILP) formulation in the literature. By exploiting the special structure of the network slicing problem, we first propose a novel linear programming (LP) relaxation of the MILP formulation. We show that compared with a natural LP relaxation of the MILP formulation, the novel LP relaxation is much more compact in terms of smaller numbers of variables and constraints, and much stronger in terms of providing a better LP bound, which makes it particularly suitable to be embedded in an LP based algorithm. Then we design an efficient two-stage LP rounding-and-refinement algorithm based on this novel LP relaxation. In the first stage, the proposed algorithm uses an iterative LP rounding procedure to place the virtual network functions of all services into cloud nodes while taking traffic routing of all services into consideration; in the second stage, the proposed algorithm uses an iterative LP refinement procedure to obtain a solution for traffic routing of all services with their end-to-end delay constraints being satisfied. Compared with the existing algorithms which either have an exponential complexity or return a low-quality solution, our proposed algorithm achieves a better trade-off between the solution quality and the computational complexity. In particular, the worst-case complexity of our proposed algorithm is polynomial, which makes it suitable for solving large-scale problems. Numerical results demonstrate the effectiveness and efficiency of our proposed algorithm.      
### 42.Optimal Bidding of Energy Storage: A Surrogate Method with Combined Spatial-Temporal Entropy  [ :arrow_down: ](https://arxiv.org/pdf/2107.14403.pdf)
>  Energy storage is expected to play an increasingly important role in mitigating variations that come along with the growing penetration of renewable energy. In this paper, we study the optimal bidding of an energy storage unit in a semi-centralized market. The energy storage unit offers its available storage capacity and maximum charging/ discharging rate to the operator; then the operator clears the real-time market by minimizing the total cost. The energy storage unit is paid/ charged at locational marginal price (LMP). The problem casts down to a bilevel optimization problem with a mixed-integer lower-level. An improved surrogate-based method with the combined spatial-temporal entropy term is developed to solve this problem. Numerical examples demonstrate the scalability, efficiency, and accuracy of the proposed method.      
### 43.On the interpretation of linear Riemannian tangent space model parameters in M/EEG  [ :arrow_down: ](https://arxiv.org/pdf/2107.14398.pdf)
>  Riemannian tangent space methods offer state-of-the-art performance in magnetoencephalography (MEG) and electroencephalography (EEG) based applications such as brain-computer interfaces and biomarker development. One limitation, particularly relevant for biomarker development, is limited model interpretability compared to established component-based methods. Here, we propose a method to transform the parameters of linear tangent space models into interpretable patterns. Using typical assumptions, we show that this approach identifies the true patterns of latent sources, encoding a target signal. In simulations and two real MEG and EEG datasets, we demonstrate the validity of the proposed approach and investigate its behavior when the model assumptions are violated. Our results confirm that Riemannian tangent space methods are robust to differences in the source patterns across observations. We found that this robustness property also transfers to the associated patterns.      
### 44.Combined Radar and Communications with Phase-Modulated Frequency Permutations  [ :arrow_down: ](https://arxiv.org/pdf/2107.14396.pdf)
>  This paper focuses on the combined radar and communications problem and conducts a thorough analytical investigation on the effect of phase and frequency change on the communication and sensing functionality. First, we consider the classical stepped frequency radar waveform and modulate data using M-ary phase shift keying (MPSK). Two important analytical tools in radar waveform design, namely the ambiguity function (AF) and the Fisher information matrix (FIM) are derived, based on which, we make the important conclusion that MPSK modulation has a negligible effect on radar local accuracy. Next, we extend the analysis to incorporate frequency permutations and propose a new signalling scheme in which the mapping between incoming data and waveforms is performed based on an efficient combinatorial transform called the Lehmer code. We also provide an efficient communications receiver based on the Hungarian algorithm. From the communications perspective, we consider the optimal maximum likelihood (ML) detector and derive the union bound and nearest neighbour approximation on the block error probability. From the radar sensing perspective, we discuss the broader structure of the waveform based on the AF derivation and quantify the radar local accuracy based on the FIM.      
### 45.Random vector functional link neural network based ensemble deep learning for short-term load forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2107.14385.pdf)
>  Electricity load forecasting is crucial for the power systems' planning and maintenance. However, its un-stationary and non-linear characteristics impose significant difficulties in anticipating future demand. This paper proposes a novel ensemble deep Random Vector Functional Link (edRVFL) network for electricity load forecasting. The weights of hidden layers are randomly initialized and kept fixed during the training process. The hidden layers are stacked to enforce deep representation learning. Then, the model generates the forecasts by ensembling the outputs of each layer. Moreover, we also propose to augment the random enhancement features by empirical wavelet transformation (EWT). The raw load data is decomposed by EWT in a walk-forward fashion, not introducing future data leakage problems in the decomposition process. Finally, all the sub-series generated by the EWT, including raw data, are fed into the edRVFL for forecasting purposes. The proposed model is evaluated on twenty publicly available time series from the Australian Energy Market Operator of the year 2020. The simulation results demonstrate the proposed model's superior performance over eleven forecasting methods in three error metrics and statistical tests on electricity load forecasting tasks.      
### 46.OpenSync: An opensource platform for synchronizing multiple measures in neuroscience experiments  [ :arrow_down: ](https://arxiv.org/pdf/2107.14367.pdf)
>  Background: The human mind is multimodal. Yet most behavioral studies rely on century-old measures such as task accuracy and latency. To create a better understanding of human behavior and brain functionality, we should introduce other measures and analyze behavior from various aspects. However, it is technically complex and costly to design and implement the experiments that record multiple measures. To address this issue, a platform that allows synchronizing multiple measures from human behavior is needed. Method: This paper introduces an opensource platform named OpenSync, which can be used to synchronize multiple measures in neuroscience experiments. This platform helps to automatically integrate, synchronize and record physiological measures (e.g., electroencephalogram (EEG), galvanic skin response (GSR), eye-tracking, body motion, etc.), user input response (e.g., from mouse, keyboard, joystick, etc.), and task-related information (stimulus markers). In this paper, we explain the structure and details of OpenSync, provide two case studies in PsychoPy and Unity. Comparison with existing tools: Unlike proprietary systems (e.g., iMotions), OpenSync is free and it can be used inside any opensource experiment design software (e.g., PsychoPy, OpenSesame, Unity, etc., <a class="link-external link-https" href="https://pypi.org/project/OpenSync/" rel="external noopener nofollow">this https URL</a> and <a class="link-external link-https" href="https://github.com/moeinrazavi/OpenSync_Unity" rel="external noopener nofollow">this https URL</a>). Results: Our experimental results show that the OpenSync platform is able to synchronize multiple measures with microsecond resolution.      
### 47.Secure Swarm UAV-assisted Communications with Cooperative Friendly Jamming  [ :arrow_down: ](https://arxiv.org/pdf/2107.14270.pdf)
>  This article proposes a cooperative friendly jamming framework for swarm unmanned aerial vehicle (UAV)-assisted amplify-and-forward (AF) relaying networks with wireless energy harvesting. Due to the limited energy of the UAVs, we develop a collaborative time-switching relaying protocol which allows the UAVs to collaborate to harvest wireless energy, relay information, and jam the eavesdropper. To evaluate the secrecy rate, we derive the secrecy outage probability (SOP) for two popular detection techniques at the eavesdropper, i.e., selection combining and maximum-ratio combining. Monte Carlo simulations are then used to validate the theoretical SOP derivation and to show the effectiveness of the proposed framework in terms of SOP as compared with the conventional amplify-and-forward relaying system. Using the derived SOP, one can obtain engineering insights to optimize the energy harvesting time and the number of UAVs in the swarm to achieve a given secrecy protection level. The analytical SOP derived in this work can also be helpful in future UAV secure-communications optimizations (e.g., trajectory, locations of UAVs). As an example, we present a case study to find the optimal corridor to locate the swarm so as to minimize the system SOP.      
