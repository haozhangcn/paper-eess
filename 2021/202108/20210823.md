# ArXiv eess --Mon, 23 Aug 2021
### 1.The Effect of Dust and Sand on the 5G Terrestrial Links  [ :arrow_down: ](https://arxiv.org/pdf/2108.09226.pdf)
>  Wireless connections are a communication channel used to support different applications in our life such as microwave connections, mobile cellular networks, and intelligent transportation systems. The wireless communication channels are affected by different weather factors such as rain, snow, fog, dust, and sand. This effect is more evident in the high frequencies of the millimeter-wave (mm-wave) band. Recently, the 5G opened the door to support different applications with high speed and good quality. A recent study investigates the effect of rain and snow on the 5G communication channel to reduce the challenge of using high millimeter-wave frequencies. This research investigates the impact of dust and sand on the communication channel of 5G mini links using Mie scattering model to estimate the propagating wave's attenuation by computing the free space loss of a dusty region. Also, the cross-polarization of the propagating wave with dust and sand is taken into account at different distances of the propagating length. Two kinds of mini links, ML-6363, and ML-6352, are considered to demonstrate the effect of dust and sand in these specific operating frequency bands. The 73.5 GHz (V-band) and (21.5GHz (K-band) are the ML-6352 and ML-6363 radio frequency, respectively. Also, signal depolarization is another important radio frequency transmission parameter that is considered heroin. The numerical and simulation results show that the 5G ML-6352 is more effect by dust and sand than ML6363. The 5G toolbox is used to build the communication system and simulate the effect of the dust and sand on the different frequency bands.      
### 2.Investigation of the Assessment of Infant Vocalizations by Laypersons  [ :arrow_down: ](https://arxiv.org/pdf/2108.09205.pdf)
>  The goal of this investigation was the assessment of acoustic infant vocalizations by laypersons. More specifically, the goal was to identify (1) the set of most salient classes for infant vocalizations, (2) their relationship to each other and to affective ratings, and (3) proposals for classification schemes based on these labels and relationships. The assessment behavior of laypersons has not yet been investigated, as current infant vocalization classification schemes have been aimed at professional and scientific applications. The study methodology was based on the Nijmegen protocol, in which participants rated vocalization recordings regarding acoustic class labels, and continuous affective scales valence, tense arousal and energetic arousal. We determined consensus stimuli ratings as well as stimuli similarities based on participant ratings. Our main findings are: (1) we identified 9 salient labels, (2) valence has the overall greatest association to label ratings, (3) there is a strong association between label and valence ratings in the negative valence space, but low association for neutral labels, and (4) stimuli separability is highest when grouping labels into 3 - 5 classes. We finally propose two classification schemes based on these findings.      
### 3.Graph Signal Processing over a Probability Space of Shift Operators  [ :arrow_down: ](https://arxiv.org/pdf/2108.09192.pdf)
>  Graph signal processing (GSP) uses a shift operator to define a Fourier basis for the set of graph signals. The shift operator is often chosen to capture the graph topology. However, in many applications, the graph topology maybe unknown a priori, its structure uncertain, or generated randomly from a predefined set for each observation. Each graph topology gives rise to a different shift operator. In this paper, we develop a GSP framework over a probability space of shift operators. We develop the corresponding notions of Fourier transform, convolution, and band-pass filters in this framework, which subsumes traditional GSP theory as the special case where the probability space consists of a single shift operator. We show that a convolution filter under this framework is the expectation of random convolution filters in traditional GSP, while the notion of bandlimitedness requires additional wriggle room from being simply a fixed point of a band-pass filter. We develop a mechanism that facilitates mapping from one space of shift operators to another, which allows our framework to be applied to a rich set of scenarios. Numerical results on both synthetic and real datasets verify the superiority of performing GSP over a probability space of shift operators versus restricting to a single shift operator.      
### 4.Device-Free Sensing in OFDM Cellular Network  [ :arrow_down: ](https://arxiv.org/pdf/2108.09177.pdf)
>  This paper considers device-free sensing in an orthogonal frequency division multiplexing (OFDM) cellular network to enable integrated sensing and communication (ISAC). A novel two-phase sensing framework is proposed to localize the passive targets that cannot transmit/receive reference signals to/from the base stations (BSs), where the ranges of the targets are estimated based on their reflected OFDM signals to the BSs in Phase I, and the location of each target is estimated based on its values of distance to the BSs in Phase II. Specifically, in Phase I, we design a model-free range estimation approach by leveraging the OFDM channel estimation technique for determining the delay values of all the BS-target-BS paths, which does not rely on any BS-target channel model. In Phase II, we reveal that ghost targets may be falsely detected in some cases as all the targets reflect the same signals to the BSs, which thus do not know how to match each estimated range with the right target. Interestingly, we show that the above issue is not a fundamental limitation for device-free sensing: under the ideal case of perfect range estimation in Phase I, the probability for ghost targets to exist is proved to be negligible when the targets are randomly located. Moreover, under the practical case of imperfect range estimation, we propose an efficient algorithm for joint range matching and target localization. Numerical results show that our proposed framework can achieve very high accuracy in the localization of passive targets, which increases with the system bandwidth.      
### 5.Abnormal Road Surface Detection Using Wheel Sensor Data  [ :arrow_down: ](https://arxiv.org/pdf/2108.09162.pdf)
>  In this manuscript we demonstrate that accurate road abnormality detection based on signals from a 3D force measuring sensor implanted into the tires of a vehicle is possible. We discuss approximating the sensor's output using adaptive Hermite-functions [4] and present an experiment that shows the connection between abnormal road conditions and the level of noise in the residual signal. Finally, we experiment with different classification schemes and conclude that a model-based neural network architecture (VP-NET [7]) outperforms the other candidates in both accuracy and simplicity for surface abnormality detection tasks.      
### 6.Uncertainties and output feedback in rollout event-triggered control  [ :arrow_down: ](https://arxiv.org/pdf/2108.09125.pdf)
>  The fact that event-triggered control (ETC) often exhibits an improved performance-communication tradeoff over time-triggered control renders it especially useful for Networked Control Systems (NCSs). However, it has proven difficult to characterize the traffic produced by ETC a priori, making it hard to adequately dimension the communication system. Rollout ETC addresses this issue by using a triggering and control law that is implicitly defined by the solution to a receding-horizon optimal control problem (OCP), instead of an explicit one as in classical ETC. This allows to directly incorporate predefined constraints on the transmission traffic as well as on states and inputs. In this article, we examine the practically relevant case when output instead of state measurements are available for feedback, and measurements as well as the plant are subject to uncertainties. To address these challenges, we adapt methods from robust tube-based model predictive control and propose three different strategies to implement an error feedback in an NCSs setup, the applicability of which depends on the capabilities of the actuator. We establish recursive feasibility of the OCP, satisfaction of state and input constraints despite the uncertainties, and convergence. Finally, we illustrate our results in a numerical example.      
### 7.Sparse Signal Processing for Massive Connectivity via Mixed-Integer Programming  [ :arrow_down: ](https://arxiv.org/pdf/2108.09116.pdf)
>  Massive connectivity is a critical challenge of Internet of Things (IoT) networks. In this paper, we consider the grant-free uplink transmission of an IoT network with a multi-antenna base station (BS) and a large number of single-antenna IoT devices. Due to the sporadic nature of IoT devices, we formulate the joint activity detection and channel estimation (JADCE) problem as a group-sparse matrix estimation problem. Although many algorithms have been proposed to solve the JADCE problem, most of them are developed based on compressive sensing technique, yielding suboptimal solutions. In this paper, we first develop an efficient weighted $l_1$-norm minimization algorithm to better approximate the group sparsity than the existing mixed $l_1/l_2$-norm minimization. Although an enhanced estimation performance in terms of the mean squared error (MSE) can be achieved, the weighted $l_1$-norm minimization algorithm is still a convex relaxation of the original group-sparse matrix estimation problem, yielding a suboptimal solution. To this end, we further reformulate the JADCE problem as a mixed integer programming (MIP) problem, which can be solved by using the branch-and-bound method. As a result, we are able to obtain an optimal solution of the JADCE problem, which can be adopted as an upper bound to evaluate the effectiveness of the existing algorithms. Moreover, we also derive the minimum pilot sequence length required to fully recover the estimated matrix in the noiseless scenario. Simulation results show the performance gains of the proposed optimal algorithm over the proposed weighted $l_1$-norm algorithm and the conventional mixed $l_1/l_2$-norm algorithm. Results also show that the proposed algorithms require a short pilot sequence than the conventional algorithm to achieve the same estimation performance.      
### 8.Self-supervised learning for joint SAR and multispectral land cover classification  [ :arrow_down: ](https://arxiv.org/pdf/2108.09075.pdf)
>  Self-supervised learning techniques are gaining popularity due to their capability of building models that are effective, even when scarce amounts of labeled data are available. In this paper, we present a framework and specific tasks for self-supervised training of multichannel models, such as the fusion of multispectral and synthetic aperture radar images. We show that the proposed self-supervised approach is highly effective at learning features that correlate with the labels for land cover classification. This is enabled by an explicit design of pretraining tasks which promotes bridging the gaps between sensing modalities and exploiting the spectral characteristics of the input. When limited labels are available, using the proposed self-supervised pretraining and supervised finetuning for land cover classification with SAR and multispectral data outperforms conventional approaches such as purely supervised learning, initialization from training on Imagenet and recent self-supervised approaches for computer vision tasks.      
### 9.Multi-Agent Deep Deterministic Policy Gradient Algorithm for Peer-to-Peer Energy Trading Considering Distribution Network Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2108.09053.pdf)
>  In this paper, we investigate an energy cost minimization problem for prosumers participating in peer-to-peer energy trading. Due to (i) uncertainties caused by renewable energy generation and consumption, (ii) difficulties in developing an accurate and efficient energy trading model, and (iii) the need to satisfy distribution network constraints, it is challenging for prosumers to obtain optimal energy trading decisions that minimize their individual energy costs. To address the challenge, we first formulate the above problem as a Markov decision process and propose a multi-agent deep deterministic policy gradient algorithm to learn optimal energy trading decisions. To satisfy the distribution network constraints, we propose distribution network tariffs which we incorporate in the algorithm as incentives to incentivize energy trading decisions that help to satisfy the constraints and penalize the decisions that violate them. The proposed algorithm is model-free and allows the agents to learn the optimal energy trading decisions without having prior information about other agents in the network. Simulation results based on real-world datasets show the effectiveness and robustness of the proposed algorithm.      
### 10.Latency-Constrained Highly-Reliable mmWave Communication via Multi-point Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2108.09021.pdf)
>  The sensitivity of millimeter-wave (mmWave) radio channel to blockage is a fundamental challenge in achieving low-latency and ultra-reliable connectivity. In this paper, we explore the viability of using coordinated multi-point (CoMP) transmission for a delay bounded and reliable mmWave communication. We propose a novel blockage-aware algorithm for the sum-power minimization problem under the user-specific latency requirements in a dynamic mobile access network. We use the Lyapunov optimization framework, and provide a dynamic control algorithm, which efficiently transforms a time-average stochastic problem into a sequence of deterministic subproblems. A robust beamformer design is then proposed by exploiting the queue backlogs and channel information, that efficiently allocates the required radio and cooperation resources, and proactively leverages the multi-antenna spatial diversity according to the instantaneous needs of the users. Further, to adapt to the uncertainties of the mmWave channel, we consider a pessimistic estimate of the rates over link blockage combinations and an adaptive selection of the CoMP serving set from the available remote radio units (RRUs). Moreover, after the relaxation of coupled and non-convex constraints via the Fractional Program (FP) techniques, a low-complexity closed-form iterative algorithm is provided by solving a system of Karush-Kuhn-Tucker (KKT) optimality conditions. The simulation results manifest that, in the presence of random blockages, the proposed methods outperform the baseline scenarios and provide power-efficient, high-reliable, and low-latency mmWave communication.      
### 11.Cascaded Channel Estimation for Intelligent Reflecting Surface Assisted Multiuser MISO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.09002.pdf)
>  This paper investigates the uplink cascaded channel estimation for intelligent-reflecting-surface (IRS)-assisted multi-user multiple-input-single-output systems. We focus on a sub-6 GHz scenario where the channel propagation is not sparse and the number of IRS elements can be larger than the number of BS antennas. A novel channel estimation protocol without the need of on-off amplitude control to avoid the reflection power loss is proposed. In addition, the pilot overhead is substantially reduced by exploiting the common-link structure to decompose the cascaded channel coefficients by the multiplication of the common-link variables and the user-specific variables. However, these two types of variables are highly coupled, which makes them difficult to estimate. To address this issue, we formulate an optimization-based joint channel estimation problem, which only utilizes the covariance of the cascaded channel. Then, we design a low-complexity alternating optimization algorithm with efficient initialization for the non-convex optimization problem, which achieves a local optimum solution. To further enhance the estimation accuracy, we propose a new formulation to optimize the training phase shifting configuration for the proposed protocol, and then solve it using the successive convex approximation algorithm. Comprehensive simulations verify that the proposed algorithm has supreme performance compared to various state-of-the-art baseline schemes.      
### 12.Impact of Aviation Electrification on Airports: Flight Scheduling and Charging  [ :arrow_down: ](https://arxiv.org/pdf/2108.08963.pdf)
>  Electrification can help to reduce the carbon footprint of aviation. The transition away from jet fuel-powered conventional airplane towards battery-powered electrified aircraft will impose extra charging requirements on airports. In this paper, we first quantify the increase in energy demands at several airports across the United States (US), when commercial airline carriers partially deploy hybrid electric aircraft (HEA). We then illustrate that smart charging and minor modifications to flight schedules can substantially reduce peak power demands, and in turn the needs for grid infrastructure upgrade. Motivated by our data analysis, we then formulate an optimization problem for slot allocation that incorporates HEA charging considerations. This problem jointly decides flight schedules and charging profiles to manage airport congestion and peak power demands. We illustrate the efficacy of our formulation through a case study on the John F. Kennedy International Airport.      
### 13.Sparse Array Capon Beamformer Design Availing Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.08962.pdf)
>  The paper considers sparse array design for receive beamforming achieving maximum signal-to-interference plus noise ratio (MaxSINR). We develop a design approach based on supervised neural network where class labels are generated using an efficient sparse beamformer spectral analysis (SBSA) approach. SBSA uses explicit information of the unknown narrowband interference environment for training the network and bears close performance to training using enumerations, i.e., exhaustive search which is computationally prohibitive for large arrays. The employed DNN effectively approximates the unknown mapping from the input received data spatial correlations to the output of sparse configuration with effective interference mitigation capability. The problem is posed as a multi-label classification problem where the selected antenna locations achieving MaxSINR are indicated by the output layer of DNN. In addition to evaluating the performance of the DNN in terms of the classification accuracy, we evaluate the performance in terms of the the ability of the classified sparse array to mitigate interference and maximize signal power. It is shown that even in the case of miss-classification, where at least one sensor location doesn't match the optimal locations, the DNN effectively learns the sub-optimal sparse configuration which has desirable SINR characteristics. This shows the ability of the DNN to learn the proposed optimization algorithms, hence paving the way for efficient real-time implementation.      
### 14.Blind Modulo Analog-to-Digital Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2108.08937.pdf)
>  In a growing number of applications, there is a need to digitize signals whose spectral characteristics are challenging for traditional Analog-to-Digital Converters (ADCs). Examples, among others, include systems where the ADC must acquire at once a very wide but sparsely and dynamically occupied bandwidth supporting diverse services, as well as systems where the signal of interest is subject to strong narrowband co-channel interference. In such scenarios, the resolution requirements can be prohibitively high. As an alternative, the recently proposed modulo-ADC architecture can in principle require dramatically fewer bits in the conversation to obtain the target fidelity, but requires that information about the spectrum be known and explicitly taken into account by the analog and digital processing in the converter, which is frequently impractical. To address this limitation, we develop a blind version of the architecture that requires no such knowledge in the converter, without sacrificing performance. In particular, it features an automatic modulo-level adjustment and a fully adaptive modulo unwrapping mechanism, allowing it to asymptotically match the characteristics of the unknown input signal. In addition to detailed analysis, simulations demonstrate the attractive performance characteristics in representative settings.      
### 15.Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search  [ :arrow_down: ](https://arxiv.org/pdf/2108.08910.pdf)
>  Though recent years have witnessed remarkable progress in single image super-resolution (SISR) tasks with the prosperous development of deep neural networks (DNNs), the deep learning methods are confronted with the computation and memory consumption issues in practice, especially for resource-limited platforms such as mobile devices. To overcome the challenge and facilitate the real-time deployment of SISR tasks on mobile, we combine neural architecture search with pruning search and propose an automatic search framework that derives sparse super-resolution (SR) models with high image quality while satisfying the real-time inference requirement. To decrease the search cost, we leverage the weight sharing strategy by introducing a supernet and decouple the search problem into three stages, including supernet construction, compiler-aware architecture and pruning search, and compiler-aware pruning ratio search. With the proposed framework, we are the first to achieve real-time SR inference (with only tens of milliseconds per frame) for implementing 720p resolution with competitive image quality (in terms of PSNR and SSIM) on mobile platforms (Samsung Galaxy S20).      
### 16.Real-time Transient Simulation and Studies of Offshore Wind Turbines  [ :arrow_down: ](https://arxiv.org/pdf/2108.08900.pdf)
>  This paper presents developed real-time simulation models for offshore wind turbine generators in compliance with industry standards. The critical control functions such as negative sequence injection, sequence current limit, voltage ride through, and power curtailments are designed to meet the industry requirements for future electromagnetic transient (EMT) testing and controls of offshore wind farms. Average-value and switching detailed models are developed in the Opal-RT real-time simulator. Real-time capabilities of these models are compared to show the effectiveness of the average-value model in terms of accuracy and computation efficiency. Studies of balanced and unbalanced faults illustrate the ability of the proposed turbine models to inject active and reactive currents during fault events. The models are validated against the second-generation generic wind turbine model proposed by Western Electricity Coordinating Council (WECC). Validation results reveal that the proposed models are aligned with the WECC generic model. In addition, the models provide an extended capability in mitigating the active power oscillation during unbalanced fault conditions.      
### 17.Segmentation of Lungs COVID Infected Regions by Attention Mechanism and Synthetic Data  [ :arrow_down: ](https://arxiv.org/pdf/2108.08895.pdf)
>  Coronavirus has caused hundreds of thousands of deaths. Fatalities could decrease if every patient could get suitable treatment by the healthcare system. Machine learning, especially computer vision methods based on deep learning, can help healthcare professionals diagnose and treat COVID-19 infected cases more efficiently. Hence, infected patients can get better service from the healthcare system and decrease the number of deaths caused by the coronavirus. This research proposes a method for segmenting infected lung regions in a CT image. For this purpose, a convolutional neural network with an attention mechanism is used to detect infected areas with complex patterns. Attention blocks improve the segmentation accuracy by focusing on informative parts of the image. Furthermore, a generative adversarial network generates synthetic images for data augmentation and expansion of small available datasets. Experimental results show the superiority of the proposed method compared to some existing procedures.      
### 18.Zoom, Enhance! Measuring Surveillance GAN Up-sampling  [ :arrow_down: ](https://arxiv.org/pdf/2108.09285.pdf)
>  Deep Neural Networks have been very successfully used for many computer vision and pattern recognition applications. While Convolutional Neural Networks(CNNs) have shown the path to state of art image classifications, Generative Adversarial Networks or GANs have provided state of art capabilities in image generation. In this paper we extend the applications of CNNs and GANs to experiment with up-sampling techniques in the domains of security and surveillance. Through this work we evaluate, compare and contrast the state of art techniques in both CNN and GAN based image and video up-sampling in the surveillance domain. As a result of this study we also provide experimental evidence to establish DISTS as a stronger Image Quality Assessment(IQA) metric for comparing GAN Based Image Up-sampling in the surveillance domain.      
### 19.Using Uncertainty in Deep Learning Reconstruction for Cone-Beam CT of the Brain  [ :arrow_down: ](https://arxiv.org/pdf/2108.09229.pdf)
>  Contrast resolution beyond the limits of conventional cone-beam CT (CBCT) systems is essential to high-quality imaging of the brain. We present a deep learning reconstruction method (dubbed DL-Recon) that integrates physically principled reconstruction models with DL-based image synthesis based on the statistical uncertainty in the synthesis image. A synthesis network was developed to generate a synthesized CBCT image (DL-Synthesis) from an uncorrected filtered back-projection (FBP) image. To improve generalizability (including accurate representation of lesions not seen in training), voxel-wise epistemic uncertainty of DL-Synthesis was computed using a Bayesian inference technique (Monte-Carlo dropout). In regions of high uncertainty, the DL-Recon method incorporates information from a physics-based reconstruction model and artifact-corrected projection data. Two forms of the DL-Recon method are proposed: (i) image-domain fusion of DL-Synthesis and FBP (DL-FBP) weighted by DL uncertainty; and (ii) a model-based iterative image reconstruction (MBIR) optimization using DL-Synthesis to compute a spatially varying regularization term based on DL uncertainty (DL-MBIR). The error in DL-Synthesis images was correlated with the uncertainty in the synthesis estimate. Compared to FBP and PWLS, the DL-Recon methods (both DL-FBP and DL-MBIR) showed ~50% reduction in noise (at matched spatial resolution) and ~40-70% improvement in image uniformity. Conventional DL-Synthesis alone exhibited ~10-60% under-estimation of lesion contrast and ~5-40% reduction in lesion segmentation accuracy (Dice coefficient) in simulated and real brain lesions, suggesting a lack of reliability / generalizability for structures unseen in the training data. DL-FBP and DL-MBIR improved the accuracy of reconstruction by directly incorporating information from the measurements in regions of high uncertainty.      
### 20.Parsing Birdsong with Deep Audio Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2108.09203.pdf)
>  Monitoring of bird populations has played a vital role in conservation efforts and in understanding biodiversity loss. The automation of this process has been facilitated by both sensing technologies, such as passive acoustic monitoring, and accompanying analytical tools, such as deep learning. However, machine learning models frequently have difficulty generalizing to examples not encountered in the training data. In our work, we present a semi-supervised approach to identify characteristic calls and environmental noise. We utilize several methods to learn a latent representation of audio samples, including a convolutional autoencoder and two pre-trained networks, and group the resulting embeddings for a domain expert to identify cluster labels. We show that our approach can improve classification precision and provide insight into the latent structure of environmental acoustic datasets.      
### 21.Straggler-Robust Distributed Optimization in Parameter-Server Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.09173.pdf)
>  Optimization in distributed networks plays a central role in almost all distributed machine learning problems. In principle, the use of distributed task allocation has reduced the computational time, allowing better response rates and higher data reliability. However, for these computational algorithms to run effectively in complex distributed systems, the algorithms ought to compensate for communication asynchrony, network node failures and delays known as stragglers. These issues can change the effective connection topology of the network, which may vary over time, thus hindering the optimization process. In this paper, we propose a new distributed unconstrained optimization algorithm for minimizing a convex function which is adaptable to a parameter server network. In particular, the network worker nodes solve their local optimization problems, allowing the computation of their local coded gradients, which will be sent to different server nodes. Then within this parameter server platform each server node aggregates its communicated local gradients, allowing convergence to the desired optimizer. This algorithm is robust to network s worker node failures, disconnection, or delaying nodes known as stragglers. One way to overcome the straggler problem is to allow coding over the network. We further extend this coding framework to enhance the convergence of the proposed algorithm under such varying network topologies. By using coding and utilizing evaluations of gradients of uniformly bounded delay we further enhance the proposed algorithm performance. Finally, we implement the proposed scheme in MATLAB and provide comparative results demonstrating the effectiveness of the proposed framework      
### 22.Convolutional Neural Network (CNN) vs Visual Transformer (ViT) for Digital Holography  [ :arrow_down: ](https://arxiv.org/pdf/2108.09147.pdf)
>  In Digital Holography (DH), it is crucial to extract the object distance from a hologram in order to reconstruct its amplitude and phase. This step is called auto-focusing and it is conventionally solved by first reconstructing a stack of images and then by sharpening each reconstructed image using a focus metric such as entropy or variance. The distance corresponding to the sharpest image is considered the focal position. This approach, while effective, is computationally demanding and time-consuming. In this paper, the determination of the distance is performed by Deep Learning (DL). Two deep learning (DL) architectures are compared: Convolutional Neural Network (CNN)and Visual transformer (ViT). ViT and CNN are used to cope with the problem of auto-focusing as a classification problem. Compared to a first attempt [11] in which the distance between two consecutive classes was 100{\mu}m, our proposal allows us to drastically reduce this distance to 1{\mu}m. Moreover, ViT reaches similar accuracy and is more robust than CNN.      
### 23.deep unfolding for non-negative matrix factorization with application to mutational signature analysis  [ :arrow_down: ](https://arxiv.org/pdf/2108.09138.pdf)
>  Non-negative matrix factorization (NMF) is a fundamental matrix decomposition technique that is used primarily for dimensionality reduction and is increasing in popularity in the biological domain. Although finding a unique NMF is generally not possible, there are various iterative algorithms for NMF optimization that converge to locally optimal solutions. Such techniques can also serve as a starting point for deep learning methods that unroll the algorithmic iterations into layers of a deep network. Here we develop unfolded deep networks for NMF and several regularized variants in both a supervised and an unsupervised setting. We apply our method to various mutation data sets to reconstruct their underlying mutational signatures and their exposures. We demonstrate the increased accuracy of our approach over standard formulations in analyzing simulated and real mutation data.      
### 24.Semantic Communication with Adaptive Universal Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2108.09119.pdf)
>  With the development of deep learning (DL), natural language processing (NLP) makes it possible for us to analyze and understand a large amount of language texts. Accordingly, we can achieve a semantic communication in terms of joint semantic source and channel coding over a noisy channel with the help of NLP. However, the existing method to realize this goal is to use a fixed transformer of NLP while ignoring the difference of semantic information contained in each sentence. To solve this problem, we propose a new semantic communication system based on Universal Transformer. Compared with the traditional transformer, an adaptive circulation mechanism is introduced in the Universal Transformer. Through the introduction of the circulation mechanism, the new semantic communication system can be more flexible to transmit sentences with different semantic information, and achieve better end-to-end performance under various channel conditions.      
### 25.Path Planning With Naive-Valley-Path Obstacle Avoidance and Global Map-Free  [ :arrow_down: ](https://arxiv.org/pdf/2108.09117.pdf)
>  In this paper, we present a complete Path Planning approach divided into two main categories: Global Path Planning (GPP) and Local Path Planning (LPP). Unlike most other works, the GPP layer, instead of complex and heavy maps, uses road and intersections graphs obtained directly from internet applications like OpenStreetMaps (OSM). This map-free GPP frees us from the common area-size restrictions. In the LPP layer, we use a novel Naive-Valley-Path method (NVP) to generate a local path avoiding obstacles in the road in an extremely-low execution time period. This approach exploits the concept of valley areas around local minima, i.e., the ones always away from obstacles. We demonstrate the robustness of the system in our research platform BLUE, driving autonomously across the University of Alicante Scientific Park for more than 20 km in a 12.33 ha area. Our vehicle avoids different static persistent and non-persistent obstacles in the road and even dynamic ones, such as vehicles and pedestrians. Code is available at <a class="link-external link-https" href="https://github.com/AUROVA-LAB/lib_planning" rel="external noopener nofollow">this https URL</a>.      
### 26.Mobility-Aware Cluster Federated Learning in Hierarchical Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.09103.pdf)
>  Implementing federated learning (FL) algorithms in wireless networks has garnered a wide range of attention. However, few works have considered the impact of user mobility on the learning performance. To fill this research gap, firstly, we develop a theoretical model to characterize the hierarchical federated learning (HFL) algorithm in wireless networks where the mobile users may roam across multiple edge access points, leading to incompletion of inconsistent FL training. Secondly, we provide the convergence analysis of HFL with user mobility. Our analysis proves that the learning performance of HFL deteriorates drastically with highly-mobile users. And this decline in the learning performance will be exacerbated with small number of participants and large data distribution divergences among local data of users. To circumvent these issues, we propose a mobility-aware cluster federated learning (MACFL) algorithm by redesigning the access mechanism, local update rule and model aggregation scheme. Finally, we provide experiments to evaluate the learning performance of HFL and our MACFL. The results show that our MACFL can enhance the learning performance, especially for three different cases, namely, the case of users with non-independent and identical distribution data, the case of users with high mobility, and the cases with a small number of users.      
### 27.AdvDrop: Adversarial Attack to DNNs by Dropping Information  [ :arrow_down: ](https://arxiv.org/pdf/2108.09034.pdf)
>  Human can easily recognize visual objects with lost information: even losing most details with only contour reserved, e.g. cartoon. However, in terms of visual perception of Deep Neural Networks (DNNs), the ability for recognizing abstract objects (visual objects with lost information) is still a challenge. In this work, we investigate this issue from an adversarial viewpoint: will the performance of DNNs decrease even for the images only losing a little information? Towards this end, we propose a novel adversarial attack, named \textit{AdvDrop}, which crafts adversarial examples by dropping existing information of images. Previously, most adversarial attacks add extra disturbing information on clean images explicitly. Opposite to previous works, our proposed work explores the adversarial robustness of DNN models in a novel perspective by dropping imperceptible details to craft adversarial examples. We demonstrate the effectiveness of \textit{AdvDrop} by extensive experiments, and show that this new type of adversarial examples is more difficult to be defended by current defense systems.      
### 28.Application of Adversarial Examples to Physical ECG Signals  [ :arrow_down: ](https://arxiv.org/pdf/2108.08972.pdf)
>  This work aims to assess the reality and feasibility of the adversarial attack against cardiac diagnosis system powered by machine learning algorithms. To this end, we introduce adversarial beats, which are adversarial perturbations tailored specifically against electrocardiograms (ECGs) beat-by-beat classification system. We first formulate an algorithm to generate adversarial examples for the ECG classification neural network model, and study its attack success rate. Next, to evaluate its feasibility in a physical environment, we mount a hardware attack by designing a malicious signal generator which injects adversarial beats into ECG sensor readings. To the best of our knowledge, our work is the first in evaluating the proficiency of adversarial examples for ECGs in a physical setup. Our real-world experiments demonstrate that adversarial beats successfully manipulated the diagnosis results 3-5 times out of 40 attempts throughout the course of 2 minutes. Finally, we discuss the overall feasibility and impact of the attack, by clearly defining motives and constraints of expected attackers along with our experimental results.      
### 29.The Importance of Autonomous Driving Using 5G Technology  [ :arrow_down: ](https://arxiv.org/pdf/2108.08966.pdf)
>  The three keys to autonomous driving are sensors, data integration, and 100% safety decisions. In the past, due to the high latency and low reliability of the network, many decisions had to be made locally in the vehicle. This puts high demands on the vehicle itself, which results in the dilatory commercialization of automatic driving. With the advent of 5G, these situations will be greatly improved. In this paper, we present the improvements that 5G technology brings to autonomous vehicles especially in terms of latency and reliability amongst the multitude of other factors. The paper analyzes the specific areas where 5G can improve for autonomous vehicles and Intelligent Transport Systems in general (ITS) and looks forward to the application of 5G technology in the future.      
### 30.Mitigating Greenhouse Gas Emissions Through Generative Adversarial Networks Based Wildfire Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2108.08952.pdf)
>  Over the past decade, the number of wildfire has increased significantly around the world, especially in the State of California. The high-level concentration of greenhouse gas (GHG) emitted by wildfires aggravates global warming that further increases the risk of more fires. Therefore, an accurate prediction of wildfire occurrence greatly helps in preventing large-scale and long-lasting wildfires and reducing the consequent GHG emissions. Various methods have been explored for wildfire risk prediction. However, the complex correlations among a lot of natural and human factors and wildfire ignition make the prediction task very challenging. In this paper, we develop a deep learning based data augmentation approach for wildfire risk prediction. We build a dataset consisting of diverse features responsible for fire ignition and utilize a conditional tabular generative adversarial network to explore the underlying patterns between the target value of risk levels and all involved features. For fair and comprehensive comparisons, we compare our proposed scheme with five other baseline methods where the former outperformed most of them. To corroborate the robustness, we have also tested the performance of our method with another dataset that also resulted in better efficiency. By adopting the proposed method, we can take preventive strategies of wildfire mitigation to reduce global GHG emissions.      
### 31.Challenges and Solutions for Utilizing Earth Observations in the "Big Data" era  [ :arrow_down: ](https://arxiv.org/pdf/2108.08886.pdf)
>  The ever-growing need of data preservation and their systematic analysis contributing to sustainable development of the society spurred in the past decade,numerous Big Data projects and initiatives are focusing on the Earth Observation (EO). The number of Big Data EO applications has grown extremely worldwide almost simultaneously with other scientific and technological areas of the human knowledge due to the revolutionary technological progress in the space and information technology sciences. The substantial contribution to this development are the space programs of the renowned space agencies, such as NASA, ESA,Roskosmos, JAXA, DLR, INPE, ISRO, CNES etc. A snap-shot of the current Big Data sets from available satellite missions covering the Bulgarian territory is also presented. This short overview of the geoscience Big Data collection with a focus on EO will emphasize to the multiple Vs of EO in order to provide a snapshot on the current state-of-the-art in EO data preservation and manipulation. Main modern approaches for compressing, clustering and modelling EO in the geoinformation science for Big Data analysis, interpretation and visualization for a variety of applications are outlined. Special attention is paid to the contemporary EO data modelling and visualization systems.      
