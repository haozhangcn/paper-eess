# ArXiv eess --Tue, 17 Aug 2021
### 1.Active fault tolerant control for twin wind turbine subject to asymmetric fault  [ :arrow_down: ](https://arxiv.org/pdf/2108.07238.pdf)
>  This paper addresses the problem of control of a twin wind turbine which is subject to an electrical fault affecting only one stator phase of one turbine. An active fault tolerant control is proposed. The performance and robustness of the proposed control, comparing to a passive fault tolerant one developed in the literature, are shown through numerical simulations.      
### 2.Continuous-Time Spatiotemporal Calibration of a Rolling Shutter Camera---IMU System  [ :arrow_down: ](https://arxiv.org/pdf/2108.07200.pdf)
>  The rolling shutter (RS) mechanism is widely used by consumer-grade cameras, which are essential parts in smartphones and autonomous vehicles. The RS effect leads to image distortion upon relative motion between a camera and the scene. This effect needs to be considered in video stabilization, structure from motion, and vision-aided odometry, for which recent studies have improved earlier global shutter (GS) methods by accounting for the RS effect. However, it is still unclear how the RS affects spatiotemporal calibration of the camera in a sensor assembly, which is crucial to good performance in aforementioned applications. <br>This work takes the camera-IMU system as an example and looks into the RS effect on its spatiotemporal calibration. To this end, we develop a calibration method for a RS-camera-IMU system with continuous-time B-splines by using a calibration target. Unlike in calibrating GS cameras, every observation of a landmark on the target has a unique camera pose fitted by continuous-time B-splines. With simulated data generated from four sets of public calibration data, we show that RS can noticeably affect the extrinsic parameters, causing errors about 1$^\circ$ in orientation and 2 $cm$ in translation with a RS setting as in common smartphone cameras. With real data collected by two industrial camera-IMU systems, we find that considering the RS effect gives more accurate and consistent spatiotemporal calibration. Moreover, our method also accurately calibrates the inter-line delay of the RS. The code for simulation and calibration is publicly available.      
### 3.Integrated Sensing and Communications: Towards Dual-functional Wireless Networks for 6G and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2108.07165.pdf)
>  As the standardization of 5G is being solidified, researchers are speculating what 6G will be. Integrating sensing functionality is emerging as a key feature of the 6G Radio Access Network (RAN), allowing to exploit the dense cell infrastructure of 5G for constructing a perceptive network. In this paper, we provide a comprehensive overview on the background, range of key applications and state-of-the-art approaches of Integrated Sensing and Communications (ISAC). We commence by discussing the interplay between sensing and communications (S&amp;C) from a historical point of view, and then consider multiple facets of ISAC and its performance gains. By introducing both ongoing and potential use cases, we shed light on industrial progress and standardization activities related to ISAC. We analyze a number of performance tradeoffs between S&amp;C, spanning from information theoretical limits, tradeoffs in physical layer performance, to the tradeoff in cross-layer designs. Next, we discuss signal processing aspects of ISAC, namely ISAC waveform design and receive signal processing. As a step further, we provide our vision on the deeper integration between S&amp;C within the framework of perceptive networks, where the two functionalities are expected to mutually assist each other, i.e., communication-assisted sensing and sensing-assisted communications. Finally, we summarize the paper by identifying the potential integration between ISAC and other emerging communication technologies, and their positive impact on the future of wireless networks.      
### 4.On-the-Fly, Sample-Tailored Optimisation of NMR Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2108.07121.pdf)
>  NMR experiments, indispensable to chemists in many areas of research, are often run with generic, unoptimised experimental parameters. This approach makes robust and automated acquisition on different samples and instruments extremely challenging. Here, we introduce NMR-POISE (Parameter Optimisation by Iterative Spectral Evaluation), the first demonstration of on-the-fly, sample-tailored, and fully automated optimisation of a wide range of NMR experiments. We illustrate how POISE maximises spectral sensitivity and quality with a diverse set of 1D and 2D examples, ranging from HSQC and NOESY experiments to ultrafast and pure shift techniques. Our Python implementation of POISE has an interface integrated into Bruker's TopSpin software, one of the most widely used platforms for NMR acquisition and automation, allowing NMR optimisations to be run without direct user supervision. We predict that POISE will find widespread usage in academia and industry, where sample-specific and automated experiment optimisation is mandatory.      
### 5.Cost-effective vibration analysis through data-backed pipeline optimisation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07017.pdf)
>  Vibration analysis is an active area of research, aimed, among other targets, at an accurate classification of machinery failure modes. This often leads to complex and convoluted signal processing pipeline designs, which are computationally demanding and cannot be deployed in the Edge devices. In the current work, we address this issue by proposing a data-driven methodology that allows optimising and justifying the complexity of the signal processing pipelines. Additionally, aiming to make IoT vibration analysis systems more cost- and computationally effective, on the example of MAFAULDA vibration dataset, we assess the changes in the failure classification performance at low sampling rates as well as short observation time windows. We find out that a decrease of the sampling rate from 50 kHz to 1 kHz leads to a statistically significant classification performance drop. A statistically significant decrease is also observed for the 0.1 second time windows compared to the 5-second ones. However, the effect sizes are small to medium, suggesting that in certain settings lower sampling rates and shorter observation windows can be used. The proposed optimisation approach, as well as statistically supported findings of the study, allow a more efficient design of IoT vibration analysis systems, both in terms of complexity and costs, bringing us one step closer to the IoT/Edge-based vibration analysis.      
### 6.Real-time Transmission of Geometrically-shaped Signals using a Software-defined GPU-based Optical Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2108.07004.pdf)
>  A software-defined optical receiver is implemented on an off-the-shelf commercial graphics processing unit (GPU). The receiver provides real-time signal processing functionality to process 1 GBaud minimum phase (MP) 4-, 8-, 16-, 32-, 64-, 128-ary quadrature amplitude modulation (QAM) as well as geometrically shaped (GS) 8- and 128-QAM signals using Kramers-Kronig (KK) coherent detection. Experimental validation of this receiver over a 91 km field-deployed optical fiber link between two Tokyo locations is shown with detailed optical signal-to-noise ratio (OSNR) investigations. A net data rate of 5 Gbps using 64-QAM is demonstrated.      
### 7.Real-time 10,000 km Straight-line Transmission using a Software-defined GPU-Based Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2108.07001.pdf)
>  Real-time 10,000 km transmission over a straight-line link is achieved using a software-defined multi-modulation format receiver implemented on a commercial off-the-shelf general-purpose graphics processing unit (GPU). Minimum phase 1 GBaud 4-ary quadrature amplitude modulation (QAM) signals are transmitted over 10,000 km and successfully received after detection with a Kramers-Kronig (KK) coherent receiver. 8-, 16-, 32-, and 64-QAM are successfully transmitted over 7600, 5600, 3600, and 1600 km, respectively.      
### 8.UWB Radar for through Foliage Imaging using Cyclic Prefix-based OFDM  [ :arrow_down: ](https://arxiv.org/pdf/2108.06969.pdf)
>  This paper proposes the use of sufficient cyclic prefix (CP) OFDM synthetic aperture radar (SAR) for foliage penetration (FOPEN). The foliage introduces phase and amplitude fluctuation which cause the sidelobes to increase and affects the final image of the obscured targets. The wideband CP-based OFDM SAR inherently eliminates the sidelobes that arise from the interference between targets on the same range line. The integrated sidelobe level ratio (ISLR) of the CP-based OFDM signal along the range direction is lower than that of the random noise signal by 2 dB for foliage penetration application, while the peak sidelobe level ratio (PSLR) are almost the same of both of the two signals.      
### 9.Language-Independent Approach for Automatic Computation of Vowel Articulation Features in Dysarthric Speech Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2108.06943.pdf)
>  Imprecise vowel articulation can be observed in people with Parkinson's disease (PD). Acoustic features measuring vowel articulation have been demonstrated to be effective indicators of PD in its assessment. Standard clinical vowel articulation features of vowel working space area (VSA), vowel articulation index (VAI) and formants centralization ratio (FCR), are derived the first two formants of the three corner vowels /a/, /i/ and /u/. Conventionally, manual annotation of the corner vowels from speech data is required before measuring vowel articulation. This process is time-consuming. The present work aims to reduce human effort in clinical analysis of PD speech by proposing an automatic pipeline for vowel articulation assessment. The method is based on automatic corner vowel detection using a language universal phoneme recognizer, followed by statistical analysis of the formant data. The approach removes the restrictions of prior knowledge of speaking content and the language in question. Experimental results on a Finnish PD speech corpus demonstrate the efficacy and reliability of the proposed automatic method in deriving VAI, VSA, FCR and F2i/F2u (the second formant ratio for vowels /i/ and /u/). The automatically computed parameters are shown to be highly correlated with features computed with manual annotations of corner vowels. In addition, automatically and manually computed vowel articulation features have comparable correlations with experts' ratings on speech intelligibility, voice impairment and overall severity of communication disorder. Language-independence of the proposed approach is further validated on a Spanish PD database, PC-GITA, as well as on TORGO corpus of English dysarthric speech.      
### 10.Equivalence of Linear Complementarity Problems: Theory and Application to Nonsmooth Bifurcations  [ :arrow_down: ](https://arxiv.org/pdf/2108.06917.pdf)
>  Linear complementarity problems provide a powerful framework to model nonsmooth phenomena in a variety of real-world applications. In dynamical control systems, they appear coupled to a linear input-output system in the form of linear complementarity systems. Mimicking the program that led to the foundation of bifurcation theory in smooth maps, we introduce a novel notion of equivalence between linear complementarity problems that sets the basis for a theory of bifurcations in a large class of nonsmooth maps, including, but not restricted to, steadystate bifurcations in linear complementarity systems. Our definition exploits the rich geometry of linear complementarity problems and leads to constructive algebraic conditions for identifying and classifying the nonsmooth singularities associated with nonsmooth bifurcations. We thoroughly illustrate our theory on an extended applied example, the design of bistability in an electrical network, and a more theoretical one, the identification and classification of all possible equivalence classes in two-dimensional linear complementarity problems.      
### 11.GC-TTS: Few-shot Speaker Adaptation with Geometric Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2108.06890.pdf)
>  Few-shot speaker adaptation is a specific Text-to-Speech (TTS) system that aims to reproduce a novel speaker's voice with a few training data. While numerous attempts have been made to the few-shot speaker adaptation system, there is still a gap in terms of speaker similarity to the target speaker depending on the amount of data. To bridge the gap, we propose GC-TTS which achieves high-quality speaker adaptation with significantly improved speaker similarity. Specifically, we leverage two geometric constraints to learn discriminative speaker representations. Here, a TTS model is pre-trained for base speakers with a sufficient amount of data, and then fine-tuned for novel speakers on a few minutes of data with two geometric constraints. Two geometric constraints enable the model to extract discriminative speaker embeddings from limited data, which leads to the synthesis of intelligible speech. We discuss and verify the effectiveness of GC-TTS by comparing it with popular and essential methods. The experimental results demonstrate that GC-TTS generates high-quality speech from only a few minutes of training data, outperforming standard techniques in terms of speaker similarity to the target speaker.      
### 12.Seirios: Leveraging Multiple Channels for LoRaWAN Indoor and Outdoor Localization  [ :arrow_down: ](https://arxiv.org/pdf/2108.06884.pdf)
>  Localization is important for a large number of Internet of Things (IoT) endpoint devices connected by LoRaWAN. Due to the bandwidth limitations of LoRaWAN, existing localization methods without specialized hardware (e.g., GPS) produce poor performance. To increase the localization accuracy, we propose a super-resolution localization method, called Seirios, which features a novel algorithm to synchronize multiple non-overlapped communication channels by exploiting the unique features of the radio physical layer to increase the overall bandwidth. By exploiting both the original and the conjugate of the physical layer, Seirios can resolve the direct path from multiple reflectors in both indoor and outdoor environments. We design a Seirios prototype and evaluate its performance in an outdoor area of 100 m $\times$ 60 m, and an indoor area of 25 m $\times$ 15 m, which shows that Seirios can achieve a median error of 4.4 m outdoors (80% samples &lt; 6.4 m), and 2.4 m indoors (80% samples &lt; 6.1 m), respectively. The results show that Seirios produces 42% less localization error than the baseline approach. Our evaluation also shows that, different to previous studies in Wi-Fi localization systems that have wider bandwidth, time-of-fight (ToF) estimation is less effective for LoRaWAN localization systems with narrowband radio signals.      
### 13.Receding Horizon Iterative Learning Control for Continuously Operated Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.06866.pdf)
>  This paper presents an iterative learning control (ILC) scheme for continuously operated repetitive systems for which no initial condition reset exists. To accomplish this, we develop a lifted system representation that accounts for the effect of the initial conditions on dynamics and projects the dynamics over multiple future iterations. Additionally, we develop an economic cost function and update law that considers the performance over multiple iterations in the future, thus allowing for the prediction horizon to be larger than just the next iteration. Convergence of the iteration varying initial condition and applied input are proven and demonstrated using a simulated servo-positioning system test case.      
### 14.Rate-Splitting Multiple Access for Downlink MIMO: A Generalized Power Iteration Approach  [ :arrow_down: ](https://arxiv.org/pdf/2108.06844.pdf)
>  Rate-splitting multiple access (RSMA) is a general multiple access scheme for downlink multi-antenna systems embracing both classical spatial division multiple access and more recent non-orthogonal multiple access. Finding a linear precoding strategy that maximizes the sum spectral efficiency of RSMA is a challenging yet significant problem. In this paper, we put forth a novel precoder design framework that jointly finds the linear precoders for the common and private messages for RSMA. Our approach is first to approximate the non-smooth minimum function part in the sum spectral efficiency of RSMA using a LogSumExp technique. Then, we reformulate the sum spectral efficiency maximization problem as a form of the log-sum of Rayleigh quotients to convert it into a tractable non-convex optimization problem. By interpreting the first-order optimality condition of the reformulated problem as an eigenvector-dependent nonlinear eigenvalue problem, we reveal that a leading eigenvector is a local optimal solution. To find the leading eigenvector, we propose a computationally efficient algorithm inspired by a power iteration method. Simulation results show that the proposed RSMA transmission strategy provides significant improvement in the sum spectral efficiency compared to the state-of-the-art RSMA transmission methods, while requiring considerably less computational complexity.      
### 15.CVaR-based Safety Analysis for the Infinite Time Setting  [ :arrow_down: ](https://arxiv.org/pdf/2108.06776.pdf)
>  We develop a risk-averse safety analysis method for stochastic systems on discrete infinite time horizons. Our method quantifies the notion of risk for a control system in terms of the severity of a harmful random outcome in a fraction of worst cases, whereas classical methods quantify risk in terms of probabilities. The theoretical arguments are based on the analysis of a value iteration algorithm on an augmented state space. We provide conditions to guarantee the existence of an optimal policy on this space. We illustrate the method numerically using an example from the domain of stormwater management.      
### 16.Optimal Scheduling of Isolated Microgrids Using Automated Reinforcement Learning-based Multi-period Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2108.06764.pdf)
>  In order to reduce the negative impact of the uncertainty of load and renewable energies outputs on microgrid operation, an optimal scheduling model is proposed for isolated microgrids by using automated reinforcement learning-based multi-period forecasting of renewable power generations and loads. Firstly, a prioritized experience replay automated reinforcement learning (PER-AutoRL) is designed to simplify the deployment of deep reinforcement learning (DRL)-based forecasting model in a customized manner, the single-step multi-period forecasting method based on PER-AutoRL is proposed for the first time to address the error accumulation issue suffered by existing multi-step forecasting methods, then the prediction values obtained by the proposed forecasting method are revised via the error distribution to improve the prediction accuracy; secondly, a scheduling model considering demand response is constructed to minimize the total microgrid operating costs, where the revised forecasting values are used as the dispatch basis, and a spinning reserve chance constraint is set according to the error distribution; finally, by transforming the original scheduling model into a readily solvable mixed integer linear programming via the sequence operation theory (SOT), the transformed model is solved by using CPLEX solver. The simulation results show that compared with the traditional scheduling model without forecasting, this approach manages to significantly reduce the system operating costs by improving the prediction accuracy.      
### 17.A Two-Layer Near-Optimal Strategy for Substation Constraint Management via Home Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2108.06735.pdf)
>  Within electrical distribution networks, substation constraints management requires that aggregated power demand from residential users is kept within suitable bounds. Efficiency of substation constraints management can be measured as the reduction of constraints violations w.r.t. unmanaged demand. Home batteries hold the promise of enabling efficient and user-oblivious substation constraints management. Centralized control of home batteries would achieve optimal efficiency. However, it is hardly acceptable by users, since service providers (e.g., utilities or aggregators) would directly control batteries at user premises. Unfortunately, devising efficient hierarchical control strategies, thus overcoming the above problem, is far from easy. <br>We present a novel two-layer control strategy for home batteries that avoids direct control of home devices by the service provider and at the same time yields near-optimal substation constraints management efficiency. Our simulation results on field data from 62 households in Denmark show that the substation constraints management efficiency achieved with our approach is at least 82% of the one obtained with a theoretical optimal centralized strategy.      
### 18.Reception strategies for sky-ground uplink non-orthogonal multiple access  [ :arrow_down: ](https://arxiv.org/pdf/2108.06713.pdf)
>  Integration of unmanned aerial vehicles (UAVs) into fifth generation (5G) and beyond 5G (B5G) cellular networks is an intriguing problem that has recently tackled a lot of interest in both academia and industry. An effective solution is represented by cellular-connected UAVs, where traditional terrestrial users coexist with flying UAVs acting as additional aerial users, which access the 5G/B5G cellular network infrastructure from the sky. In this scenario, we study the challenging application in which an UAV acting as aerial user (AU) and a static (i.e., fixed) terrestrial user (TU) are paired to simultaneously transmit their uplink signals to a ground base station (BS) in the same time-frequency resource blocks. In such a case, due to the highly dynamic nature of the UAV, the signal transmitted by the AU experiences both time dispersion due to multipath propagation effects and frequency dispersion caused by Doppler shifts. On the other hand, for a static ground network, frequency dispersion of the signal transmitted by TU is negligible and only multipath effects have to be taken into account. To decode the superposed signals at the BS by using finite-length data record, we propose a novel sky-ground (SG) nonorthogonal multiple access (NOMA) receiving structure that additionally exploits the different circularity/noncircularity and almost-cyclostationarity properties of the AU and TU by means of improved channel estimation and time-varying successive interference cancellation. Numerical results demonstrate the usefulness of the proposed SG uplink NOMA reception scheme in future 5G/B5G networks.      
### 19.Closed-Form Hybrid Beamforming Solution for Spectral Efficiency Upper Bound Maximization in mmWave MIMO-OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.06691.pdf)
>  Hybrid beamforming is considered a key enabler to realize millimeter wave (mmWave) multiple-input multiple-output (MIMO) communications due to its capability of considerably reducing the number of costly and power-hungry radio frequency chains in the transceiver. However, in mmWave MIMO orthogonal frequency-division multiplexing (MIMO-OFDM) systems, hybrid beamforming design is challenging because the analog precoder and combiner are required to be shared across the whole employed bandwidth. In this paper, we propose closed-form solutions to the problem of designing the analog precoder/combiner in a mmWave MIMO-OFDM system by maximizing the upper bound of the spectral efficiency. The closed-form solutions facilitate the design of analog beamformers while guaranteeing state-of-art performance. Numerical results show that the proposed algorithm attains a slightly improved performance with much lower computational complexity compared to the considered benchmarks.      
### 20.Nonlinear Controllability Assessment of Aerial Manipulator Systems using Lagrangian Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2108.06644.pdf)
>  This paper analyzes the nonlinear Small-Time Local Controllability (STLC) of a class of underatuated aerial manipulator robots. We apply methods of Lagrangian reduction to obtain their lowest dimensional equations of motion (EOM). The symmetry-breaking potential energy terms are resolved using advected parameters, allowing full $SE(3)$ reduction at the cost of additional advection equations. The reduced EOM highlights the shifting center of gravity due to manipulation and is readily in control-affine form, simplifying the nonlinear controllability analysis. Using Sussmann's sufficient condition, we conclude that the aerial manipulator robots are STLC near equilibrium condition, requiring Lie bracket motions up to degree three.      
### 21.Analysing and Modelling of Discretionary Lane Change Duration Considering Driver Heterogeneity  [ :arrow_down: ](https://arxiv.org/pdf/2108.06640.pdf)
>  This paper aims to investigate the characteristics of durations of discretionary lane changes (LCs) on freeways based on an enriched dataset containing LC vehicle trajectories of 2905 passenger cars and 433 heavy vehicles. A comprehensive analysis of LC duration is conducted and four stochastic LC duration models are built according to vehicle types and LC directions. It is found that the LC duration varies across different vehicle types and LC directions. The modelling results show that different variables have different effects on LC duration for different vehicle types and LC directions. Fixed-parameter, latent class, and random parameter accelerated hazard time (AFT) models were built considering driver heterogeneity. Results show that heavy vehicle drivers show more heterogeneity. Different variables were found for different vehicle types and LC directions. The results of this study can be beneficial to understand the mechanism of LC process and the influence of LC on traffic flow.      
### 22.Relaxation Based Modeling of GMD Induced Cascading Failures in PowerModelsGMD.jl  [ :arrow_down: ](https://arxiv.org/pdf/2108.06585.pdf)
>  A major risk of geomagnetic disturbances (GMDs) is cascading failure of electrical grids. The modeling of GMD events and cascading outages in power systems is difficult, both independently and jointly, because of the many different mechanisms and physics involved. This paper introduces a relaxation based modeling of GMD-induced cascading failures:~the dc approximation-based DCSIMSEP solver was adapted to simulate cascading as a result of GMDs, the full set of ac power flow equations were relaxed to guarantee optimality, and the reactive power losses were modeled while keeping the problem convex. The developed algorithm was implemented in PowerModelsGMD.jl - an open-source software specifically designed to model and analyze geomagnetic hazards - and demonstrated to work on the RTS-GMLC-GIC-EAST synthetic test network.      
### 23.A 3D Non-Stationary Geometry-Based Stochastic Model for Industrial Automation Wireless Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.06551.pdf)
>  Industrial automation is one of the key application scenarios of the fifth (5G) wireless communication network. The high requirements of industrial communication systems for latency and reliability lead to the need for industrial channel models to support massive multiple-input multipleoutput (MIMO) and millimeter wave communication. In addition, due to the complex environment, huge communication equipment, and numerous metal scatterers, industrial channels have special rich dense multipath components (DMCs). Considering these characteristics, a novel three dimensional (3D) non-stationary geometry-based stochastic model (GBSM) for industrial automation wireless channel is proposed in this paper. Channel characteristics including the transfer function, time-varying space-time-frequency correlation function (STFCF), and root mean square (RMS) delay spread, model parameters including delay scaling factor and power decay factor are studied and analyzed. Besides, according to the indoor factory scenario classification of the 3rd Generation Partnership Project (3GPP) TR 38.901, two sub-scenarios considering the clutter density are simulated. Simulated cumulative distribution functions (CDFs) of RMS delay spread show a good consistency with the measurement data.      
### 24.A Novel 3D Non-Stationary GBSM for 6G THz Ultra-Massive MIMO Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.06542.pdf)
>  Terahertz (THz) communication is now being considered as one of possible technologies for the sixth generation (6G) wireless communication systems. In this paper, a novel three-dimensional (3D) space-time-frequency non-stationary theoretical channel model is first proposed for 6G THz wireless communication systems employing ultra-massive multiple-input multiple-output (MIMO) technologies with long traveling paths. Considering frequency-dependent diffuse scattering, which is a special property of THz channels different from millimeter wave (mmWave) channels, the relative angles and delays of rays within one cluster will evolve in the frequency domain. Then, a corresponding simulation model is proposed with discrete angles calculated using the method of equal area (MEA). The statistical properties of the proposed theoretical and simulation models are derived and compared, showing good agreements. The accuracy and flexibility of the proposed simulation model are demonstrated by comparing the simulation results of the relative angle spread and root mean square (RMS) delay spread with corresponding measurements.      
### 25.A 2D Non-Stationary Channel Model for Underwater Acoustic Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2108.06513.pdf)
>  Underwater acoustic (UWA) communication plays a key role in the process of exploring and studying the ocean. In this paper, a modified non-stationary wideband channel model for UWA communication in shallow water scenarios is proposed. In this geometry-based stochastic model (GBSM), multiple motion effects, time-varying angles, distances, clusters' locations with the channel geometry, and the ultra-wideband property are considered, which makes the proposed model more realistic and capable of supporting long time/distance simulations. Some key statistical properties are investigated, including temporal autocorrelation function (ACF), power delay profile (PDP), average delay, and root mean square (RMS) delay spread. The impacts of multiple motion factors on temporal ACFs are analyzed. Simulation results show that the proposed model can mimic the non-stationarity of UWA channels. Finally, the proposed model is validated with measurement data.      
### 26.Multi-Frequency Wireless Channel Measurements and Characteristics Analysis in Indoor Corridor Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2108.06511.pdf)
>  In this paper, we conduct wireless channel measurements in indoor corridor scenarios at 2.4, 5 and 6 GHz bands with bandwidth of 320 MHz. The measurement results of channel characteristics at different frequency bands such as average power delay profile (APDP), path loss (PL), delay spread (DS), and Ricean K factor (KF) are presented and analyzed. It is found that the PL exponent (PLE) and PL offset \beta in the floating-intercept (FI) model tend to increase with the increase of frequency. The DS and KF values of the three frequency bands in line of sight (LOS) scenario are basically the same. These results are significant for the design of communication systems.      
### 27.4-D Epanechnikov Mixture Regression in Light Field Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2108.06464.pdf)
>  With the emergence of light field imaging in recent years, the compression of its elementary image array (EIA) has become a significant problem. Our coding framework includes modeling and reconstruction. For the modeling, the covariance-matrix form of the 4-D Epanechnikov kernel (4-D EK) and its correlated statistics were deduced to obtain the 4-D Epanechnikov mixture models (4-D EMMs). A 4-D Epanechnikov mixture regression (4-D EMR) was proposed based on this 4-D EK, and a 4-D adaptive model selection (4-D AMLS) algorithm was designed to realize the optimal modeling for a pseudo video sequence (PVS) of the extracted key-EIA. A linear function based reconstruction (LFBR) was proposed based on the correlation between adjacent elementary images (EIs). The decoded images realized a clear outline reconstruction and superior coding efficiency compared to high-efficiency video coding (HEVC) and JPEG 2000 below approximately 0.05 bpp. This work realized an unprecedented theoretical application by (1) proposing the 4-D Epanechnikov kernel theory, (2) exploiting the 4-D Epanechnikov mixture regression and its application in the modeling of the pseudo video sequence of light field images, (3) using 4-D adaptive model selection for the optimal number of models, and (4) employing a linear function-based reconstruction according to the content similarity.      
### 28.High-dimensional Assisted Generative Model for Color Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2108.06460.pdf)
>  This work presents an unsupervised deep learning scheme that exploiting high-dimensional assisted score-based generative model for color image restoration tasks. Considering that the sample number and internal dimension in score-based generative model have key influence on estimating the gradients of data distribution, two different high-dimensional ways are proposed: The channel-copy transformation increases the sample number and the pixel-scale transformation decreases feasible space dimension. Subsequently, a set of high-dimensional tensors represented by these transformations are used to train the network through denoising score matching. Then, sampling is performed by annealing Langevin dynamics and alternative data-consistency update. Furthermore, to alleviate the difficulty of learning high-dimensional representation, a progressive strategy is proposed to leverage the performance. The proposed unsupervised learning and iterative restoration algo-rithm, which involves a pre-trained generative network to obtain prior, has transparent and clear interpretation compared to other data-driven approaches. Experimental results on demosaicking and inpainting conveyed the remarkable performance and diversity of our proposed method.      
### 29.HoloSketch: Wireless Semantic Segmentation by Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2108.06456.pdf)
>  Semantic segmentation is a process of partitioning an image into multiple segments for recognizing humans and objects, which can be widely applied in scenarios such as healthcare and safety monitoring. To avoid privacy violation, using RF signals instead of an image for human and object recognition has gained increasing attention. However, human and object recognition by using RF signals is usually a passive signal collection and analysis process without changing the radio environment, and the recognition accuracy is restricted significantly by unwanted multi-path fading, and/or the limited number of independent channels between RF transceivers in uncontrollable radio environments. This paper introduces HoloSketch, a novel RF-sensing system that performs semantic recognition and segmentation for humans and objects by making the radio environment reconfigurable. A reconfigurable intelligent surface~(RIS) is incorporated into HoloSketch and diversifies the information carried by RF signals. Using compressive sensing techniques, HoloSketch reconstructs a point cloud consisting of the reflection coefficients of humans and objects at different spatial points, and recognizes the semantic meaning of the points by using symmetric multilayer perceptron groups. Our evaluation results show that HoloSketch is capable of generating favorable radio environments and extracting exact point clouds, and labeling the semantic meaning of the points with an average error rate of less than 1% in an indoor space.      
### 30.Waveform Design and Performance Analysis for Full-Duplex Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2108.06449.pdf)
>  Integrated sensing and communication (ISAC) is a promising technology to fully utilize the precious spectrum and hardware in wireless systems, which has attracted significant attentions recently. This paper studies ISAC for the important and challenging monostatic setup, where one single ISAC node wishes to simultaneously sense a radar target while communicating with a communication receiver. Different from most existing schemes that rely on either radar-centric half-duplex (HD) pulsed transmission with information embedding that suffers from extremely low communication rate, or communication-centric waveform that suffers from degraded sensing performance, we propose a novel full-duplex (FD) ISAC scheme that utilizes the waiting time of conventional pulsed radars to transmit dedicated communication signals. Compared to radar-centric pulsed waveform with information embedding, the proposed design can drastically increase the communication rate, and also mitigate the sensing eclipsing and near-target blind range issues, as long as the self-interference (SI) is effectively suppressed. On the other hand, compared to communication-centric ISAC waveform, the proposed design has better auto-correlation property as it preserves the classic radar waveform for sensing. Performance analysis is developed by taking into account the residual SI, in terms of the probability of detection and ambiguity function for sensing, as well as the spectrum efficiency for communication. Numerical results are provided to show the significant performance gain of our proposed design over benchmark schemes.      
### 31.Hybrid Gaussian Process Modeling Applied to Economic Stochastic Model Predictive Control of Batch Processes  [ :arrow_down: ](https://arxiv.org/pdf/2108.06430.pdf)
>  Nonlinear model predictive control (NMPC) is an efficient approach for the control of nonlinear multivariable dynamic systems with constraints, which however requires an accurate plant model. Plant models can often be determined from first principles, parts of the model are however difficult to derive using physical laws alone. In this paper a hybrid Gaussian process (GP) first principles modeling scheme is proposed to overcome this issue, which exploits GPs to model the parts of the dynamic system that are difficult to describe using first principles. GPs not only give accurate predictions, but also quantify the residual uncertainty of this model. It is vital to account for this uncertainty in the control algorithm, to prevent constraint violations and performance deterioration. Monte Carlo samples of the GPs are generated offline to tighten constraints of the NMPC to ensure joint probabilistic constraint satisfaction online. Advantages of our method include fast online evaluation times, possibility to account for online learning alleviating conservativeness, and exploiting the flexibility of GPs and the data efficiency of first principle models. The algorithm is verified on a case study involving a challenging semi-batch bioreactor.      
### 32.Multihop RIS-Assisted FSO-RF System Over Double Generalized Gamma Fading  [ :arrow_down: ](https://arxiv.org/pdf/2108.07236.pdf)
>  Reconfigurable intelligent surface (RIS) is a promising technology to avoid signal blockage by creating virtual line-of-sight (LOS) connectivity for free-space optical (FSO) and radio frequency (RF) wireless systems. This paper considers a mixed FSO-RF system by employing multiple RISs in both the links for multihop transmissions to extend the communication range. We develop probability density function (PDF) and cumulative density function (CDF) of the signal-to-noise ratio (SNR) for the cascaded channels by considering double generalized gamma (dGG) turbulence with pointing errors for the FSO link and the dGG distribution to model the signal fading for the RF. We derive exact closed-form expressions of the outage probability, average bit-error-rate (BER), and ergodic capacity using the decode-and-forward (DF) relaying for the mixed system. We also present asymptotic analysis on the performance in the high SNR regime depicting the impact of channel parameters on the diversity order of the system. We use computer simulations to demonstrate the effect of system and channel parameters on the RIS-aided multihop transmissions.      
### 33.Convolutive Prediction for Reverberant Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07194.pdf)
>  We investigate the effectiveness of convolutive prediction, a novel formulation of linear prediction for speech dereverberation, for speaker separation in reverberant conditions. The key idea is to first use a deep neural network (DNN) to estimate the direct-path signal of each speaker, and then identify delayed and decayed copies of the estimated direct-path signal. Such copies are likely due to reverberation, and can be directly removed for dereverberation or used as extra features for another DNN to perform better dereverberation and separation. To identify such copies, we solve a linear regression problem per frequency efficiently in the time-frequency (T-F) domain to estimate the underlying room impulse response (RIR). In the multi-channel extension, we perform minimum variance distortionless response (MVDR) beamforming on the outputs of convolutive prediction. The beamforming and dereverberation results are used as extra features for a second DNN to perform better separation and dereverberation. State-of-the-art results are obtained on the SMS-WSJ corpus.      
### 34.NIST SRE CTS Superset: A large-scale dataset for telephony speaker recognition  [ :arrow_down: ](https://arxiv.org/pdf/2108.07118.pdf)
>  This document provides a brief description of the National Institute of Standards and Technology (NIST) speaker recognition evaluation (SRE) conversational telephone speech (CTS) Superset. The CTS Superset has been created in an attempt to provide the research community with a large-scale dataset along with uniform metadata that can be used to effectively train and develop telephony (narrowband) speaker recognition systems. It contains a large number of telephony speech segments from more than 6800 speakers with speech durations distributed uniformly in the [10s, 60s] range. The segments have been extracted from the source corpora used to compile prior SRE datasets (SRE1996-2012), including the Greybeard corpus as well as the Switchboard and Mixer series collected by the Linguistic Data Consortium (LDC). In addition to the brief description, we also report speaker recognition results on the NIST 2020 CTS Speaker Recognition Challenge, obtained using a system trained with the CTS Superset. The results will serve as a reference baseline for the challenge.      
### 35.COL0RME: Super-resolution microscopy based on sparse blinking fluorophore localization and intensity estimation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07095.pdf)
>  To overcome the physical barriers caused by light diffraction, super-resolution techniques are often applied in fluorescent microscopy. State-of-the-art approaches require specific and often demanding acquisition conditions to achieve adequate levels of both spatial and temporal resolution. Analyzing the stochastic fluctuations of the fluorescent molecules provides a solution to the aforementioned limitations, as sufficiently high spatio-temporal resolution for live-cell imaging can be achieved by using common microscopes and conventional fluorescent dyes. Based on this idea, we present COL0RME, a method for COvariance-based $\ell_0$ super-Resolution Microscopy with intensity Estimation, which achieves good spatio-temporal resolution by solving a sparse optimization problem in the covariance domain, and discuss automatic parameter selection strategies. The method is composed of two steps: the former where both the emitters' independence and the sparse distribution of the fluorescent molecules are exploited to provide an accurate localization; the latter where real intensity values are estimated given the computed support. The paper is furnished with several numerical results both on synthetic and real fluorescent microscopy images and several comparisons with state-of-the art approaches are provided. Our results show that COL0RME outperforms competing methods exploiting analogously temporal fluctuations; in particular, it achieves better localization, reduces background artifacts and avoids fine parameter tuning.      
### 36.Sum-Rate Maximization for Multi-Reconfigurable Intelligent Surface-Assisted Device-to-Device Communications  [ :arrow_down: ](https://arxiv.org/pdf/2108.07091.pdf)
>  This paper proposes to deploy multiple reconfigurable intelligent surfaces (RISs) in device-to-device (D2D)-underlaid cellular systems. The uplink sum-rate of the system is maximized by jointly optimizing the transmit powers of the users, the pairing of the cellular users (CUs) and D2D links, the receive beamforming of the base station (BS), and the configuration of the RISs, subject to the power limits and quality-of-service (QoS) of the users. To address the non-convexity of this problem, we develop a new block coordinate descent (BCD) framework which decouples the D2D-CU pairing, power allocation and receive beamforming, from the configuration of the RISs. Specifically, we derive closed-form expressions for the power allocation and receive beamforming under any D2D-CU pairing, which facilitates interpreting the D2D-CU pairing as a bipartite graph matching solved using the Hungarian algorithm. We transform the configuration of the RISs into a quadratically constrained quadratic program (QCQP) with multiple quadratic constraints. A low-complexity algorithm, named Riemannian manifold-based alternating direction method of multipliers (RM-ADMM), is developed to decompose the QCQP into simpler QCQPs with a single constraint each, and solve them efficiently in a decentralized manner. Simulations show that the proposed algorithm can significantly improve the sum-rate of the D2D-underlaid system with a reduced complexity, as compared to its alternative based on semidefinite relaxation (SDR).      
### 37.Robust Beamforming Design for Rate Splitting Multiple Access-Aided MISO Visible Light Communications  [ :arrow_down: ](https://arxiv.org/pdf/2108.07014.pdf)
>  This paper addresses robust beamforming design for rate splitting multiple access (RSMA)-aided multiple-input single-output (MISO) visible light communication (VLC) networks. In particular, since the channel capacity of VLC is yet unknown, we derive the first theoretical bound of channel capacity of RSMA-aided VLC networks, i.e., achievable rates with closed-form expressions. For the perfect channel state information (CSI) scenario, we investigate the beamforming design to minimize the transmitted power of RSMA-aided VLC networks under the quality of service (QoS) constraint of each user and the optical power constraints, and propose a constrained-convex-concave programming (CCCP)-based beamforming design algorithm to obtain high-quality beamformers. Moreover, for the imperfect CSI scenario, we propose a robust CCCP-based beamforming design scheme for RSMA-aided VLC networks by exploiting semidefinite relaxation (SDR) technique and S-lemma. Numerical results show that the proposed RSMA schemes offer a significant spectral efficiency gain over the existing space-division multiple access (SDMA) scheme and non-orthogonal multiple access (NOMA) scheme.      
### 38.Flying Guide Dog: Walkable Path Discovery for the Visually Impaired Utilizing Drones and Transformer-based Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2108.07007.pdf)
>  Lacking the ability to sense ambient environments effectively, blind and visually impaired people (BVIP) face difficulty in walking outdoors, especially in urban areas. Therefore, tools for assisting BVIP are of great importance. In this paper, we propose a novel "flying guide dog" prototype for BVIP assistance using drone and street view semantic segmentation. Based on the walkable areas extracted from the segmentation prediction, the drone can adjust its movement automatically and thus lead the user to walk along the walkable path. By recognizing the color of pedestrian traffic lights, our prototype can help the user to cross a street safely. Furthermore, we introduce a new dataset named Pedestrian and Vehicle Traffic Lights (PVTL), which is dedicated to traffic light recognition. The result of our user study in real-world scenarios shows that our prototype is effective and easy to use, providing new insight into BVIP assistance.      
### 39.Optimal Actor-Critic Policy with Optimized Training Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2108.06911.pdf)
>  Actor-critic (AC) algorithms are known for their efficacy and high performance in solving reinforcement learning problems, but they also suffer from low sampling efficiency. An AC based policy optimization process is iterative and needs to frequently access the agent-environment system to evaluate and update the policy by rolling out the policy, collecting rewards and states (i.e. samples), and learning from them. It ultimately requires a huge number of samples to learn an optimal policy. To improve sampling efficiency, we propose a strategy to optimize the training dataset that contains significantly less samples collected from the AC process. The dataset optimization is made of a best episode only operation, a policy parameter-fitness model, and a genetic algorithm module. The optimal policy network trained by the optimized training dataset exhibits superior performance compared to many contemporary AC algorithms in controlling autonomous dynamical systems. Evaluation on standard benchmarks show that the method improves sampling efficiency, ensures faster convergence to optima, and is more data-efficient than its counterparts.      
### 40.Partisan Confidence Model for Group Polarization  [ :arrow_down: ](https://arxiv.org/pdf/2108.06879.pdf)
>  Models of opinion dynamics play a major role in various disciplines, including economics, political science, psychology, and social science, as they provide a framework for analysis and intervention. In spite of the numerous mathematical models of social learning proposed in the literature, only a few models have focused on or allow for the possibility of popular extreme beliefs' formation in a population. This paper closes this gap by introducing the Partisan Confidence (PC) model inspired by the foundations of the well-established socio-psychological theory of groupthink. The model hints at the existence of a tipping point, passing which the opinions of the individuals within a so-called "social bubble" are exaggerated towards an extreme position, no matter how the general population is united or divided. The results are also justified through numerical experiments, which provide new insights into the evolution of opinions and the groupthink phenomenon.      
### 41.Bayesian Parameter Estimations for Grey System Models in Online Traffic Speed Predictions  [ :arrow_down: ](https://arxiv.org/pdf/2108.06839.pdf)
>  This paper presents Bayesian parameter estimation for first order Grey system models' parameters (or sometimes referred to as hyperparameters). There are different forms of first-order Grey System Models. These include $GM(1,1)$, $GM(1,1| \cos(\omega t)$, $GM(1,1| \sin(\omega t)$, and $GM(1,1| \cos(\omega t), \sin(\omega t)$. The whitenization equation of these models is a first-order linear differential equation of the form \[ \frac{dx}{dt} + a x = f(t) \] where $a$ is a parameter and $f(t) = b$ in $GM(1,1|)$ , $f(t) = b_1\cos(\omega t) + b_2$ in $GM(1,1| cos(\omega t)$, $f(t) = b_1\sin(\omega t)+b_2$ in $GM(1,1| \sin(\omega t)$, $f(t) = b_1\sin(\omega t) + b_2\cos(\omega t) + b_3$ in $GM(1,1| \cos(\omega t), \sin(\omega t)$, $f(t) = b x^2$ in Grey Verhulst model (GVM), <br>and where $b, b_1, b_2$, and $b_3$ are parameters. The results from Bayesian estimations are compared to the least square estimated models with fixed $\omega$. We found that using rolling Bayesian estimations for GM parameters can allow us to estimate the parameters in all possible forms. Based on the data used for the comparison, the numerical results showed that models with Bayesian parameter estimations are up to 45\% more accurate in mean squared errors.      
### 42.Two Eyes Are Better Than One: Exploiting Binocular Correlation for Diabetic Retinopathy Severity Grading  [ :arrow_down: ](https://arxiv.org/pdf/2108.06763.pdf)
>  Diabetic retinopathy (DR) is one of the most common eye conditions among diabetic patients. However, vision loss occurs primarily in the late stages of DR, and the symptoms of visual impairment, ranging from mild to severe, can vary greatly, adding to the burden of diagnosis and treatment in clinical practice. Deep learning methods based on retinal images have achieved remarkable success in automatic DR grading, but most of them neglect that the presence of diabetes usually affects both eyes, and ophthalmologists usually compare both eyes concurrently for DR diagnosis, leaving correlations between left and right eyes unexploited. In this study, simulating the diagnostic process, we propose a two-stream binocular network to capture the subtle correlations between left and right eyes, in which, paired images of eyes are fed into two identical subnetworks separately during training. We design a contrastive grading loss to learn binocular correlation for five-class DR detection, which maximizes inter-class dissimilarity while minimizing the intra-class difference. Experimental results on the EyePACS dataset show the superiority of the proposed binocular model, outperforming monocular methods by a large margin.      
### 43.Multi-Slice Dense-Sparse Learning for Efficient Liver and Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2108.06761.pdf)
>  Accurate automatic liver and tumor segmentation plays a vital role in treatment planning and disease monitoring. Recently, deep convolutional neural network (DCNNs) has obtained tremendous success in 2D and 3D medical image segmentation. However, 2D DCNNs cannot fully leverage the inter-slice information, while 3D DCNNs are computationally expensive and memory intensive. To address these issues, we first propose a novel dense-sparse training flow from a data perspective, in which, densely adjacent slices and sparsely adjacent slices are extracted as inputs for regularizing DCNNs, thereby improving the model performance. Moreover, we design a 2.5D light-weight nnU-Net from a network perspective, in which, depthwise separable convolutions are adopted to improve the efficiency. Extensive experiments on the LiTS dataset have demonstrated the superiority of the proposed method.      
### 44.Time Delay Estimation of Traffic Congestion Propagation based on Transfer Entropy  [ :arrow_down: ](https://arxiv.org/pdf/2108.06717.pdf)
>  Considering how congestion will propagate in the near future, understanding traffic congestion propagation has become crucial in GPS navigation systems for providing users with a more accurate estimated time of arrival (ETA). However, providing the exact ETA during congestion is a challenge owing to the complex propagation process between roads and high uncertainty regarding the future behavior of the process. Recent studies have focused on finding frequent congestion propagation patterns and determining the propagation probabilities. By contrast, this study proposes a novel time delay estimation method for traffic congestion propagation between roads using lag-specific transfer entropy (TE). Nonlinear normalization with a sliding window is used to effectively reveal the causal relationship between the source and target time series in calculating the TE. Moreover, Markov bootstrap techniques were adopted to quantify the uncertainty in the time delay estimator. To the best of our knowledge, the time delay estimation method presented in this article is the first to determine the time delay between roads for any congestion propagation pattern. The proposed method was validated using simulated data as well as real user trajectory data obtained from a major GPS navigation system applied in South Korea.      
### 45.Reference Service Model for Federated Identity Management  [ :arrow_down: ](https://arxiv.org/pdf/2108.06701.pdf)
>  With the pandemic of COVID-19, people around the world increasingly work from home. Each natural person typically has several digital identities with different associated information. During the last years, various identity and access management approaches have gained attraction, helping for example to access other organization's services within trust boundaries. The resulting heterogeneity creates a high complexity to differentiate between these approaches and scenarios as participating entity; combining them is even harder. Last but not least, various actors have a different understanding or perspective of the terms, like 'service', in this context. Our paper describes a reference service with standard components in generic federated identity management. This is utilized with modern Enterprise Architecture using the framework ArchiMate. The proposed universal federated identity management service model (FIMSM) is applied to describe various federated identity management scenarios in a generic service-oriented way. The presented reference design is approved in multiple aspects and is easily applicable in numerous scenarios.      
### 46.Windowed Decoding for Delayed Bit-Interleaved Coded Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2108.06697.pdf)
>  Delayed bit-interleaved coded modulation (DBICM) generalizes bit-interleaved coded modulation (BICM) by modulating differently delayed sub-blocks of codewords onto the same signals. DBICM improves transmission reliability over BICM due to its capability of detecting undelayed sub-blocks with the extrinsic information of the decoded delayed sub-blocks. In this work, we propose a novel windowed decoding algorithm for DBICM, which uses the extrinsic information of both the decoded delayed and undelayed sub-blocks, to improve the detection on all sub-blocks. Numerical results show that the proposed windowed decoding significantly outperforms the original decoding.      
### 47.Automated Enterprise Architecture Model Mining  [ :arrow_down: ](https://arxiv.org/pdf/2108.06696.pdf)
>  Metadata are like the steam engine of the 21st century, driving businesses and offer multiple enhancements. Nevertheless, many companies are unaware that these data can be used efficiently to improve their own operation. This is where the Enterprise Architecture Framework comes in. It empowers an organisation to get a clear view of their business, application, technical and physical layer. This modelling approach is an established method for organizations to take a deeper look into their structure and processes. The development of such models requires a great deal of effort, is carried out manually by interviewing stakeholders and requires continuous maintenance. Our new approach enables the automated mining of Enterprise Architecture models. The system uses common technologies to collect the metadata based on network traffic, log files and other information in an organisation. Based on this, the new approach generates EA models with the desired views points. Furthermore, a rule and knowledge-based reasoning is used to obtain a holistic overview. This offers a strategic decision support from business structure over process design up to planning the appropriate support technology. Therefore, it forms the base for organisations to act in an agile way. The modelling can be performed in different modelling languages, including ArchiMate and the Nato Architecture Framework (NAF). The designed approach is already evaluated on a small company with multiple services and an infrastructure with several nodes.      
### 48.On the Semidefinite Duality of Finite-Horizon LQG Problem  [ :arrow_down: ](https://arxiv.org/pdf/2108.06687.pdf)
>  In this paper, our goal is to study fundamental foundations of linear quadratic Gaussian (LQG) control problems for stochastic linear time-invariant systems via Lagrangian duality of semidefinite programming (SDP) problems. In particular, we derive an SDP formulation of the finite-horizon LQG problem, and its Lagrangian duality. Moreover, we prove that Riccati equation for LQG can be derived the KKT optimality condition of the corresponding SDP problem. Besides, the proposed primal problem efficiently decouples the system matrices and the gain matrix. This allows us to develop new convex relaxations of non-convex structured control design problems such as the decentralized control problem. We expect that this work would provide new insights on the LQG problem and may potentially facilitate developments of new formulations of various optimal control problems. Numerical examples are given to demonstrate the effectiveness of the proposed methods.      
### 49.Joint Dynamic Passive Beamforming and Resource Allocation for IRS-Aided Full-Duplex WPCN  [ :arrow_down: ](https://arxiv.org/pdf/2108.06660.pdf)
>  This paper studies intelligent reflecting surface (IRS)-aided full-duplex (FD) wireless-powered communication network (WPCN), where a hybrid access point (HAP) broadcasts energy signals to multiple devices for their energy harvesting in the downlink (DL) and meanwhile receives information signals in the uplink (UL) with the help of IRS. Particularly, we propose three types of IRS beamforming configurations to strike a balance between the system performance and signaling overhead as well as implementation complexity. We first propose the fully dynamic IRS beamforming, where the IRS phase-shift vectors vary with each time slot for both DL wireless energy transfer (WET) and UL wireless information transmission (WIT). To further reduce signaling overhead and implementation complexity, we then study two special cases, namely, partially dynamic IRS beamforming and static IRS beamforming. For the former case, two different phase-shift vectors can be exploited for the DL WET and the UL WIT, respectively, whereas for the latter case, the same phase-shift vector needs to be applied for both DL and UL transmissions. We aim to maximize the system throughput by jointly optimizing the time allocation, HAP transmit power, and IRS phase shifts for the above three cases. Two efficient algorithms based on alternating optimization and penalty-based algorithms are respectively proposed for both perfect self-interference cancellation (SIC) case and imperfect SIC case by applying successive convex approximation and difference-of-convex optimization techniques. Simulation results demonstrate the benefits of IRS for enhancing the performance of FD-WPCN, and also show that the IRS-aided FD-WPCN is able to achieve significantly performance gain compared to its counterpart with half-duplex when the self-interference (SI) is properly suppressed.      
### 50.Force-feedback based Whole-body Stabilizer for Position-Controlled Humanoid Robots  [ :arrow_down: ](https://arxiv.org/pdf/2108.06652.pdf)
>  This paper studies stabilizer design for position-controlled humanoid robots. Stabilizers are an essential part for position-controlled humanoids, whose primary objective is to adjust the control input sent to the robot to assist the tracking controller to better follow the planned reference trajectory. To achieve this goal, this paper develops a novel force-feedback based whole-body stabilizer that fully exploits the six-dimensional force measurement information and the whole-body dynamics to improve tracking performance. Relying on rigorous analysis of whole-body dynamics of position-controlled humanoids under unknown contact, the developed stabilizer leverages quadratic-programming based technique that allows cooperative consideration of both the center-of-mass tracking and contact force tracking. The effectiveness of the proposed stabilizer is demonstrated on the UBTECH Walker robot in the MuJoCo simulator. Simulation validations show a significant improvement in various scenarios as compared to commonly adopted stabilizers based on the zero-moment-point feedback and the linear inverted pendulum model.      
### 51.LayerPipe: Accelerating Deep Neural Network Training by Intra-Layer and Inter-Layer Gradient Pipelining and Multiprocessor Scheduling  [ :arrow_down: ](https://arxiv.org/pdf/2108.06629.pdf)
>  The time required for training the neural networks increases with size, complexity, and depth. Training model parameters by backpropagation inherently creates feedback loops. These loops hinder efficient pipelining and scheduling of the tasks within the layer and between consecutive layers. Prior approaches, such as PipeDream, have exploited the use of delayed gradient to achieve inter-layer pipelining. However, these approaches treat the entire backpropagation as a single task; this leads to an increase in computation time and processor underutilization. This paper presents novel optimization approaches where the gradient computations with respect to the weights and the activation functions are considered independently; therefore, these can be computed in parallel. This is referred to as intra-layer optimization. Additionally, the gradient computation with respect to the activation function is further divided into two parts and distributed to two consecutive layers. This leads to balanced scheduling where the computation time of each layer is the same. This is referred to as inter-layer optimization. The proposed system, referred to as LayerPipe, reduces the number of clock cycles required for training while maximizing processor utilization with minimal inter-processor communication overhead. LayerPipe achieves an average speedup of 25% and upwards of 80% with 7 to 9 processors with less communication overhead when compared to PipeDream.      
### 52.Reducing Line-of-block Artifacts in Cardiac Activation Maps Estimated Using ECG Imaging: A Comparison of Source Models and Estimation Methods  [ :arrow_down: ](https://arxiv.org/pdf/2108.06602.pdf)
>  Objective: To investigate cardiac activation maps estimated using electrocardiographic imaging and to find methods reducing line-of-block (LoB) artifacts, while preserving real LoBs. Methods: Body surface potentials were computed for 137 simulated ventricular excitations. Subsequently, the inverse problem was solved to obtain extracellular potentials (EP) and transmembrane voltages (TMV). From these, activation times (AT) were estimated using four methods and compared to the ground truth. This process was evaluated with two cardiac mesh resolutions. Factors contributing to LoB artifacts were identified by analyzing the impact of spatial and temporal smoothing on the morphology of source signals. Results: AT estimation using a spatiotemporal derivative performed better than using a temporal derivative. Compared to deflection-based AT estimation, correlation-based methods were less prone to LoB artifacts but performed worse in identifying real LoBs. Temporal smoothing could eliminate artifacts for TMVs but not for EPs, which could be linked to their temporal morphology. TMVs led to more accurate ATs on the septum than EPs. Mesh resolution had a negligible effect on inverse reconstructions, but small distances were important for cross-correlation-based estimation of AT delays. Conclusion: LoB artifacts are mainly caused by the inherent spatial smoothing effect of the inverse reconstruction. Among the configurations evaluated, only deflection-based AT estimation in combination with TMVs and strong temporal smoothing can prevent LoB artifacts, while preserving real LoBs. Significance: Regions of slow conduction are of considerable clinical interest and LoB artifacts observed in non-invasive ATs can lead to misinterpretations. We addressed this problem by identifying factors causing such artifacts and methods to reduce them.      
### 53.Constrained Iterative LQG for Real-Time Chance-ConstrainedGaussian Belief Space Planning  [ :arrow_down: ](https://arxiv.org/pdf/2108.06533.pdf)
>  Motion planning under uncertainty is of significant importance for safety-critical systems such as autonomous vehicles. Such systems have to satisfy necessary constraints (e.g., collision avoidance) with potential uncertainties coming from either disturbed system dynamics or noisy sensor measurements. However, existing motion planning methods cannot efficiently find the robust optimal solutions under general nonlinear and non-convex settings. In this paper, we formulate such problem as chance-constrained Gaussian belief space planning and propose the constrained iterative Linear Quadratic Gaussian (CILQG) algorithm as a real-time solution. In this algorithm, we iteratively calculate a Gaussian approximation of the belief and transform the chance-constraints. We evaluate the effectiveness of our method in simulations of autonomous driving planning tasks with static and dynamic obstacles. Results show that CILQG can handle uncertainties more appropriately and has faster computation time than baseline methods.      
### 54.Investigating Bias In Automatic Toxic Comment Detection: An Empirical Study  [ :arrow_down: ](https://arxiv.org/pdf/2108.06487.pdf)
>  With surge in online platforms, there has been an upsurge in the user engagement on these platforms via comments and reactions. A large portion of such textual comments are abusive, rude and offensive to the audience. With machine learning systems in-place to check such comments coming onto platform, biases present in the training data gets passed onto the classifier leading to discrimination against a set of classes, religion and gender. In this work, we evaluate different classifiers and feature to estimate the bias in these classifiers along with their performance on downstream task of toxicity classification. Results show that improvement in performance of automatic toxic comment detection models is positively correlated to mitigating biases in these models. In our work, LSTM with attention mechanism proved to be a better modelling strategy than a CNN model. Further analysis shows that fasttext embeddings is marginally preferable than glove embeddings on training models for toxicity comment detection. Deeper analysis reveals the findings that such automatic models are particularly biased to specific identity groups even though the model has a high AUC score. Finally, in effort to mitigate bias in toxicity detection models, a multi-task setup trained with auxiliary task of toxicity sub-types proved to be useful leading to upto 0.26% (6% relative) gain in AUC scores.      
### 55.A New Entity Extraction Method Based on Machine Reading Comprehension  [ :arrow_down: ](https://arxiv.org/pdf/2108.06444.pdf)
>  Entity extraction is a key technology for obtaining information from massive texts in natural language processing. The further interaction between them does not meet the standards of human reading comprehension, thus limiting the understanding of the model, and also the omission or misjudgment of the answer (ie the target entity) due to the reasoning question. An effective MRC-based entity extraction model-MRC-I2DP, which uses the proposed gated attention-attracting mechanism to adjust the restoration of each part of the text pair, creating problems and thinking for multi-level interactive attention calculations to increase the target entity It also uses the proposed 2D probability coding module, TALU function and mask mechanism to strengthen the detection of all possible targets of the target, thereby improving the probability and accuracy of prediction. Experiments have proved that MRC-I2DP represents an overall state-of-the-art model in 7 from the scientific and public domains, achieving a performance improvement of 2.1% ~ 10.4% compared to the model model in F1.      
### 56.Minimizing maximum lateness in bi-level projects by tropical optimization  [ :arrow_down: ](https://arxiv.org/pdf/2108.06425.pdf)
>  We are considering a bi-level optimal scheduling problem, which involves two similar projects with the same starting times for workers and the same deadlines for tasks. It is required that the starting times for workers and deadlines for tasks should be optimal for the lower-level project and, under this condition, also for the upper-level project. Optimality is measured with respect to the maximal lateness (or maximal delay) of tasks, which has to be minimized. We represent this problem as a problem of tropical pseudoquadratic optimization and show how the existing methods of tropical optimization and tropical linear algebra yield a full and explicit solution for this problem.      
### 57.Cross-modal Spectrum Transformation Network For Acoustic Scene classification  [ :arrow_down: ](https://arxiv.org/pdf/2108.06401.pdf)
>  Convolutional neural networks (CNNs) with log-mel spectrum features have shown promising results for acoustic scene classification tasks. However, the performance of these CNN based classifiers is still lacking as they do not generalise well for unknown environments. To address this issue, we introduce an acoustic spectrum transformation network where traditional log-mel spectrums are transformed into imagined visual features (IVF). The imagined visual features are learned by exploiting the relationship between audio and visual features present in video recordings. An auto-encoder is used to encode images as visual features and a transformation network learns how to generate imagined visual features from log-mel. Our model is trained on a large dataset of Youtube videos. We test our proposed method on the scene classification task of DCASE and ESC-50, where our method outperforms other spectrum features, especially for unseen environments.      
### 58.DensePASS: Dense Panoramic Semantic Segmentation via Unsupervised Domain Adaptation with Attention-Augmented Context Exchange  [ :arrow_down: ](https://arxiv.org/pdf/2108.06383.pdf)
>  Intelligent vehicles clearly benefit from the expanded Field of View (FoV) of the 360-degree sensors, but the vast majority of available semantic segmentation training images are captured with pinhole cameras. In this work, we look at this problem through the lens of domain adaptation and bring panoramic semantic segmentation to a setting, where labelled training data originates from a different distribution of conventional pinhole camera images. First, we formalize the task of unsupervised domain adaptation for panoramic semantic segmentation, where a network trained on labelled examples from the source domain of pinhole camera data is deployed in a different target domain of panoramic images, for which no labels are available. To validate this idea, we collect and publicly release DensePASS - a novel densely annotated dataset for panoramic segmentation under cross-domain conditions, specifically built to study the Pinhole-to-Panoramic transfer and accompanied with pinhole camera training examples obtained from Cityscapes. DensePASS covers both, labelled- and unlabelled 360-degree images, with the labelled data comprising 19 classes which explicitly fit the categories available in the source domain (i.e. pinhole) data. To meet the challenge of domain shift, we leverage the current progress of attention-based mechanisms and build a generic framework for cross-domain panoramic semantic segmentation based on different variants of attention-augmented domain adaptation modules. Our framework facilitates information exchange at local- and global levels when learning the domain correspondences and improves the domain adaptation performance of two standard segmentation networks by 6.05% and 11.26% in Mean IoU.      
