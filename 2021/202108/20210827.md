# ArXiv eess --Fri, 27 Aug 2021
### 1.Cluster-based Characterization and Modeling for UAV Air-to-Ground Time-Varying Channels  [ :arrow_down: ](https://arxiv.org/pdf/2108.11902.pdf)
>  With the deep integration between the unmanned aerial vehicle (UAV) and wireless communication, UAV-based air-to-ground (AG) propagation channels need more detailed descriptions and accurate models. In this paper, we aim to perform cluster-based characterization and modeling for AG channels. To our best knowledge, this is the first study that concentrates on the clustering and tracking of multipath components (MPCs) for time-varying AG channels. Based on measurement data at 6.5 GHz with 500 MHz of bandwidth, we first estimate potential MPCs utilizing the space-alternating generalized expectation-maximization (SAGE) algorithm. Then, we cluster the extracted MPCs considering their static and dynamic characteristics by employing K-Power-Means (KPM) algorithm under multipath component distance (MCD) measure. For characterizing time-variant clusters, we exploit a clustering-based tracking (CBT) method, which efficiently quantifies the survival lengths of clusters. Ultimately, we establish a cluster-based channel model, and validations illustrate the accuracy of the proposed model. This work not only promotes a better understanding of AG propagation channels but also provides a general cluster-based AG channel model with certain extensibility.      
### 2.FPGA-based Implementation of a New Data Frame Correction System for Merging Units  [ :arrow_down: ](https://arxiv.org/pdf/2108.11886.pdf)
>  With today's increasing demand for digital devices in Substation Automation Systems (SAS) based on the IEC61850 standard, the measured data error due to the synchronization problem should be considered as a significant problem in digitalized SAS. Although time tagging and mathematical methods have been proposed to alleviate this problem, they require a massive amount of calculations and elaborations. To develop a solution for both problems of the data error and the massive computation, in this paper, we propose a data frame correction (DFC) system with a new method of data shift computation as a data correction method implemented as a hardware accelerator on FPGA. Compared to the state-of-the-art DFC systems, the results show that the proposed DFC system can achieve data correction with up to 99.6% fewer hardware resources utilization and fulfills 9x calculation speed while maintaining IEC61850 required accuracy in 2.1ms.      
### 3.A Deep Learning Loss Function based on Auditory Power Compression for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2108.11877.pdf)
>  Deep learning technology has been widely applied to speech enhancement. While testing the effectiveness of various network structures, researchers are also exploring the improvement of the loss function used in network training. Although the existing methods have considered the auditory characteristics of speech or the reasonable expression of signal-to-noise ratio, the correlation with the auditory evaluation score and the applicability of the calculation for gradient optimization still need to be improved. In this paper, a signal-to-noise ratio loss function based on auditory power compression is proposed. The experimental results show that the overall correlation between the proposed function and the indexes of objective speech intelligibility, which is better than other loss functions. For the same speech enhancement model, the training effect of this method is also better than other comparison methods.      
### 4.Data-driven modeling and control of large-scale dynamical systems in the Loewner framework  [ :arrow_down: ](https://arxiv.org/pdf/2108.11870.pdf)
>  In this contribution, we discuss the modeling and model reduction framework known as the Loewner framework. This is a data-driven approach, applicable to large-scale systems, which was originally developed for applications to linear time-invariant systems. In recent years, this method has been extended to a number of additional more complex scenarios, including linear parametric or nonlinear dynamical systems. We will provide here an overview of the latter two, together with time-domain extensions. Additionally, the application of the Loewner framework is illustrated by a collection of practical test cases. Firstly, for data-driven complexity reduction of the underlying model, and secondly, for dealing with control applications of complex systems (in particular, with feedback controller design).      
### 5.Geometric Stochastic Filter with Guaranteed Performance for Autonomous Navigation based on IMU and Feature Sensor Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2108.11866.pdf)
>  This paper concerns the estimation problem of attitude, position, and linear velocity of a rigid-body autonomously navigating with six degrees of freedom (6 DoF). The navigation dynamics are highly nonlinear and are modeled on the matrix Lie group of the extended Special Euclidean Group $\mathbb{SE}_{2}(3)$. A computationally cheap geometric nonlinear stochastic navigation filter is proposed on $\mathbb{SE}_{2}(3)$ with guaranteed transient and steady-state performance. The proposed filter operates based on a fusion of sensor measurements collected by a low-cost inertial measurement unit (IMU) and features (obtained by a vision unit). The closed loop error signals are guaranteed to be almost semi-globally uniformly ultimately bounded in the mean square from almost any initial condition. The equivalent quaternion representation is included in the Appendix. The filter is proposed in continuous form, and its discrete form is tested on a real-world dataset of measurements collected by a quadrotor navigating in three dimensional (3D) space. Keywords: Localization, navigation, position and orientation estimation, stochastic systems, GPS-denied navigation observer, navigation estimator, vision-aided inertial navigation systems (VA-INSs), stochastic differential equation, Gaussian noise, sensor fusion.      
### 6.Passenger Congestion Alleviation in Large Hub Airport Ground Access System Based on Queueing Theory  [ :arrow_down: ](https://arxiv.org/pdf/2108.11836.pdf)
>  Passenger queue congestion in the airport public transport system would cause poor travel experience and unexpected time cost. To solve this problem, we propose a hybrid congestion alleviation strategy based on transport capacity adjustment and passenger guidance in this paper. Firstly, we develop queueing models for three common ground access modes of airports, taxi, bus and subway. Then, we develop the method of successive weighted averages (MSWA) in the queueing system to optimize the passenger share rates among different airport ground access modes based on minimum queueing time. Finally, we present the complete hybrid passenger congestion alleviation strategy consists of adjusting the taxi arrival rate and bus service rate, and generating a guidance on passenger access mode choices, which can alleviate the passenger queue congestion in practical application based on obtained optimal passenger share rates. In the numerical experiments, we set two groups of parameters under the normal situation and the COVID-19 epidemic situation. The numerical results show that our strategy can alleviate the queue congestion and improve the evacuation efficiency effectively in both two backgrounds.      
### 7.Comparison of Clustering Methods for Extraction of Uncorrelated Sparse Sources from Data Mixtures  [ :arrow_down: ](https://arxiv.org/pdf/2108.11776.pdf)
>  There is an extensive set of methods to determine sparse sources from mixtures where the mixing coefficients are unknown. Each method involves plotting N sets of mixed data against each other in N-dimensional space. In the approach adopted in this paper, N dimensional normalised vectors are produced by joining data points that are adjacent in time. A novel clustering approach is adopted: the two vectors, not necessarily adjacent in time, which are closest to each other are identified and one of these vectors is taken as the principal direction corresponding to one of the sources. It is shown, using a deflation approach, that it is possible to estimate individual sources to within a multiplicative constant. This novel method is compared with two related methods and the standard FastICA algorithm. This new method has comparable performances to three other methods when applied to examples of purely sparse, semi-sparse and non-sparse sources and also when applied to fetal ECG data.      
### 8.System Identification and Controller Design for Hydraulic Actuator  [ :arrow_down: ](https://arxiv.org/pdf/2108.11756.pdf)
>  System Identification of Hydraulic Actuators is critical for analyzing their performance and designing a suitable Control System. Hydraulic actuators are extensively used in many applications, ranging from flight simulators, robotics, orthopaedic surgery, material testing, construction and many other industrial types of machinery. In the aviation industry, hydraulic actuators are currently being used in full flight simulators used for controlling the position and orientation of the motion platform. Every actuator has its own characteristics, therefore, the choice of excitation signals for System Identification must take into account the dynamics of the actuator under consideration. This work proposes the selection of excitation signals based on bandwidth of the hydraulic actuator. Validation of the proposed selection is done by performing system identification, obtaining a mathematical model and comparing it with a nonlinear hydraulic actuator model designed in Simscape. After validation, a nonlinear PID control has been tuned on the identified model and tested on the nonlinear model. Extensive simulations have been run and results show accurate mathematical modelling, as well as precise control has been achieved through the proposed methodology.      
### 9.Segmentation of Shoulder Muscle MRI Using a New Region and Edge based Deep Auto-Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2108.11720.pdf)
>  Automatic segmentation of shoulder muscle MRI is challenging due to the high variation in muscle size, shape, texture, and spatial position of tears. Manual segmentation of tear and muscle portion is hard, time-consuming, and subjective to pathological expertise. This work proposes a new Region and Edge-based Deep Auto-Encoder (RE-DAE) for shoulder muscle MRI segmentation. The proposed RE-DAE harmoniously employs average and max-pooling operation in the encoder and decoder blocks of the Convolutional Neural Network (CNN). Region-based segmentation incorporated in the Deep Auto-Encoder (DAE) encourages the network to extract smooth and homogenous regions. In contrast, edge-based segmentation tries to learn the boundary and anatomical information. These two concepts, systematically combined in a DAE, generate a discriminative and sparse hybrid feature space (exploiting both region homogeneity and boundaries). Moreover, the concept of static attention is exploited in the proposed RE-DAE that helps in effectively learning the tear region. The performances of the proposed MRI segmentation based DAE architectures have been tested using a 3D MRI shoulder muscle dataset using the hold-out cross-validation technique. The MRI data has been collected from the Korea University Anam Hospital, Seoul, South Korea. Experimental comparisons have been conducted by employing innovative custom-made and existing pre-trained CNN architectures both using transfer learning and fine-tuning. Objective evaluation on the muscle datasets using the proposed SA-RE-DAE showed a dice similarity of 85.58% and 87.07%, an accuracy of 81.57% and 95.58% for tear and muscle regions, respectively. The high visual quality and the objective result suggest that the proposed SA-RE-DAE is able to correctly segment tear and muscle regions in shoulder muscle MRI for better clinical decisions.      
### 10.PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2108.11695.pdf)
>  3D to 2D retinal vessel segmentation is a challenging problem in Optical Coherence Tomography Angiography (OCTA) images. Accurate retinal vessel segmentation is important for the diagnosis and prevention of ophthalmic diseases. However, making full use of the 3D data of OCTA volumes is a vital factor for obtaining satisfactory segmentation results. In this paper, we propose a Progressive Attention-Enhanced Network (PAENet) based on attention mechanisms to extract rich feature representation. Specifically, the framework consists of two main parts, the three-dimensional feature learning path and the two-dimensional segmentation path. In the three-dimensional feature learning path, we design a novel Adaptive Pooling Module (APM) and propose a new Quadruple Attention Module (QAM). The APM captures dependencies along the projection direction of volumes and learns a series of pooling coefficients for feature fusion, which efficiently reduces feature dimension. In addition, the QAM reweights the features by capturing four-group cross-dimension dependencies, which makes maximum use of 4D feature tensors. In the two-dimensional segmentation path, to acquire more detailed information, we propose a Feature Fusion Module (FFM) to inject 3D information into the 2D path. Meanwhile, we adopt the Polarized Self-Attention (PSA) block to model the semantic interdependencies in spatial and channel dimensions respectively. Experimentally, our extensive experiments on the OCTA-500 dataset show that our proposed algorithm achieves state-of-the-art performance compared with previous methods.      
### 11.Neural Mode Decomposition based on Fourier neural network and frequency clustering  [ :arrow_down: ](https://arxiv.org/pdf/2108.11675.pdf)
>  Since Huang proposed the Empirical Mode Decomposition (EMD) in 1998, mode decomposition has been widely studied, but EMD and relative developed algorithms are still generally lack of adaptability and mathematical theory. This paper propose a new mode decomposition algorithm called Neural Mode Decomposition (NMD) based on Fourier neural network (FNN) and frequency clustering. Firstly, a FNN is constructed to decompose and learn the information of each amplitude modulation frequency component and non-periodic component in the raw data. Secondly, the frequency components obtained by the FNN are clustered into multiple Intrinsic Mode Functions (IMF) with separated spectrum based on the energy of each frequency component learned by FNN. Practical decomposition results on a series of artificial and real data show that NMD algorithm can effectively implement mode decomposition, better reflect the characteristics of raw data than EMD, and has higher adaptability than Variational Mode Decomposition (VMD).      
### 12.Robust AC Transmission Expansion Planning with Load and Renewable Generation Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2108.11662.pdf)
>  With the integration of Renewable Energy Sources (RESs), the power network must be robust to handle the system's uncertain scenarios. DC Transmission Expansion Planning (TEP) plans are generally not feasible for the AC network. A first bi-level Robust Optimization (RO) solution approach for AC TEP with injection uncertainties in loads and RESs generations is proposed in this paper. It utilizes a well-known convex relaxation and is solved by Benders Decomposition (BD), where the master determines the robust AC TEP plan. A novel dual slave model is developed for the second level of BD, which circumvents the issues in using the Conic Duality Theory (CDT), and aids in the worst-case realization of uncertainties using a novel set of constraints. The developed dual slave is not a mixed-integer problem and is solved using the Primal-Dual Interior Point Method (PDIPM). The proposed work also uses additional linear constraints to reduce BD's computational burden and direct the master towards optimality. Monte-Carlo Simulation (MCS) based verification, via actual nonlinear and non-convex AC Optimal Power Flow (OPF), proves 100% robustness of the TEP plans for all scenarios.      
### 13.Cross-domain Single-channel Speech Enhancement Model with Bi-projection Fusion Module for Noise-robust ASR  [ :arrow_down: ](https://arxiv.org/pdf/2108.11598.pdf)
>  In recent decades, many studies have suggested that phase information is crucial for speech enhancement (SE), and time-domain single-channel speech enhancement techniques have shown promise in noise suppression and robust automatic speech recognition (ASR). This paper presents a continuation of the above lines of research and explores two effective SE methods that consider phase information in time domain and frequency domain of speech signals, respectively. Going one step further, we put forward a novel cross-domain speech enhancement model and a bi-projection fusion (BPF) mechanism for noise-robust ASR. To evaluate the effectiveness of our proposed method, we conduct an extensive set of experiments on the publicly-available Aishell-1 Mandarin benchmark speech corpus. The evaluation results confirm the superiority of our proposed method in relation to a few current top-of-the-line time-domain and frequency-domain SE methods in both enhancement and ASR evaluation metrics for the test set of scenarios contaminated with seen and unseen noise, respectively.      
### 14.A Quantitative Approach To The Temporal Dependency in Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2108.11586.pdf)
>  Motion compensated prediction is central to the efficiency of video compression. Its predictive coding scheme propagates the quantization distortion through the prediction chain and creates a temporal dependency. Prior research typically models the distortion propagation based on the similarity between original pixels under the assumption of high resolution quantization. Its efficacy in the low to medium bit-rate range, where the quantization step size is largely comparable to the magnitude of the residual signals, is questionable. This work proposes a quantitative approach to estimating the temporal dependency. It evaluates the rate and distortion for each coding block using the original and the reconstructed motion compensation reference blocks, respectively. Their difference effectively measures how the quantization error in the reference block impacts the coding efficiency of the current block. A recursive update process is formulated to track such dependency through a group of pictures. The proposed scheme quantifies the temporal dependency more accurately across a wide range of operating bit-rates, which translates into considerable coding performance gains over the existing contenders as demonstrated in the experiments.      
### 15.NeighCNN: A CNN based SAR Speckle Reduction using Feature preserving Loss Function  [ :arrow_down: ](https://arxiv.org/pdf/2108.11573.pdf)
>  Coherent imaging systems like synthetic aperture radar are susceptible to multiplicative noise that makes applications like automatic target recognition challenging. In this paper, NeighCNN, a deep learning-based speckle reduction algorithm that handles multiplicative noise with relatively simple convolutional neural network architecture, is proposed. We have designed a loss function which is an unique combination of weighted sum of Euclidean, neighbourhood, and perceptual loss for training the deep network. Euclidean and neighbourhood losses take pixel-level information into account, whereas perceptual loss considers high-level semantic features between two images. Various synthetic, as well as real SAR images, are used for testing the NeighCNN architecture, and the results verify the noise removal and edge preservation abilities of the proposed architecture. Performance metrics like peak-signal-to-noise ratio, structural similarity index, and universal image quality index are used for evaluating the efficiency of the proposed architecture on synthetic images.      
### 16.Secure Control of Networked Control Systems Using Dynamic Watermarking  [ :arrow_down: ](https://arxiv.org/pdf/2108.11572.pdf)
>  We here investigate secure control of networked control systems developing a new dynamic watermarking (DW) scheme. Firstly, the weaknesses of the conventional DW scheme are revealed, and the tradeoff between the effectiveness of false data injection attack (FDIA) detection and system performance loss is analysed. Secondly, we propose a new DW scheme, and its attack detection capability is interrogated using the additive distortion power of a closed-loop system. Furthermore, the FDIA detection effectiveness of the closed-loop system is analysed using auto/cross covariance of the signals, where the positive correlation between the FDIA detection effectiveness and the watermarking intensity is measured. Thirdly, the tolerance capacity of FDIA against the closed-loop system is investigated, and theoretical analysis shows that the system performance can be recovered from FDIA using our new DW scheme. Finally, experimental results from a networked inverted pendulum system demonstrate the validity of our proposed scheme.      
### 17.Targeted False Data Injection Attacks Against AC State Estimation Without Network Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2108.11558.pdf)
>  State estimation is a data processing algorithm for converting redundant meter measurements and other information into an estimate of the state of a power system. Relying heavily on meter measurements, state estimation has proven to be vulnerable to cyber attacks. In this paper, a novel targeted false data injection attack (FDIA) model against AC state estimation is proposed. Leveraging on the intrinsic load dynamics in ambient conditions and important properties of the Ornstein-Uhlenbeck process, we, from the viewpoint of intruders, design an algorithm to extract power network parameters purely from PMU data, which are further used to construct the FDIA vector. Requiring no network parameters and relying only on limited phasor measurement unit (PMU) data, the proposed FDIA model can target specific states and launch large deviation attacks. Sufficient conditions for the proposed FDIA model are also developed. Various attack vectors and attacking regions are studied in the IEEE 39-bus system, showing that the proposed FDIA method can successfully bypass the bad data detection and launch targeted large deviation attacks with very high probabilities.      
### 18.Learning-based Predictive Beamforming for Integrated Sensing and Communication in Vehicular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2108.11540.pdf)
>  This paper investigates the integrated sensing and communication (ISAC) in vehicle-to-infrastructure (V2I) networks. To realize ISAC, an effective beamforming design is essential which however, highly depends on the availability of accurate channel tracking requiring large training overhead and computational complexity. Motivated by this, we adopt a deep learning (DL) approach to implicitly learn the features of historical channels and directly predict the beamforming matrix to be adopted for the next time slot to maximize the average achievable sum-rate of an ISAC system. The proposed method can bypass the need of explicit channel tracking process and reduce the signaling overhead significantly. To this end, a general sum-rate maximization problem with Cramer-Rao lower bounds (CRLBs)-based sensing constraints is first formulated for the considered ISAC system. Then, by exploiting the penalty method, a versatile unsupervised DL-based predictive beamforming design framework is developed to address the formulated design problem. As a realization of the developed framework, a historical channels-based convolutional long short-term memory (LSTM) network (HCL-Net) is devised for predictive beamforming in the ISAC-based V2I network. Specifically, the convolution and LSTM modules are successively adopted in the proposed HCL-Net to exploit the spatial and temporal dependencies of communication channels to further improve the learning performance. Finally, simulation results show that the proposed predictive method not only guarantees the required sensing performance, but also achieves a satisfactory sum-rate that can approach the upper bound obtained by the genie-aided scheme with the perfect instantaneous channel state information.      
### 19.Generalized Real-World Super-Resolution through Adversarial Robustness  [ :arrow_down: ](https://arxiv.org/pdf/2108.11505.pdf)
>  Real-world Super-Resolution (SR) has been traditionally tackled by first learning a specific degradation model that resembles the noise and corruption artifacts in low-resolution imagery. Thus, current methods lack generalization and lose their accuracy when tested on unseen types of corruption. In contrast to the traditional proposal, we present Robust Super-Resolution (RSR), a method that leverages the generalization capability of adversarial attacks to tackle real-world SR. Our novel framework poses a paradigm shift in the development of real-world SR methods. Instead of learning a dataset-specific degradation, we employ adversarial attacks to create difficult examples that target the model's weaknesses. Afterward, we use these adversarial examples during training to improve our model's capacity to process noisy inputs. We perform extensive experimentation on synthetic and real-world images and empirically demonstrate that our RSR method generalizes well across datasets without re-training for specific noise priors. By using a single robust model, we outperform state-of-the-art specialized methods on real-world benchmarks.      
### 20.Model Predictive Control approach to adaptive messaging intervention for physical activity  [ :arrow_down: ](https://arxiv.org/pdf/2108.11499.pdf)
>  In this work, we have developed a framework for synthesizing data driven controllers for a class of uncertain switched systems arising in an application to physical activity interventions. In particular, we present an application of probabilistic model predictive control to design an efficient, tractable, and adaptive intervention using behavioral data sets i.e. physical activity behavior. The models of physical activity for each individual are provided for the design of controllers that maximize the probability of achieving a desired physical activity goal subject to intervention specifications. We have tailored the mixed-integer programming-based approach for evaluating the Model Predictive Control decision at each time step.      
### 21.With One Voice: Composing a Travel Voice Assistant from Re-purposed Models  [ :arrow_down: ](https://arxiv.org/pdf/2108.11463.pdf)
>  Voice assistants provide users a new way of interacting with digital products, allowing them to retrieve information and complete tasks with an increased sense of control and flexibility. Such products are comprised of several machine learning models, like Speech-to-Text transcription, Named Entity Recognition and Resolution, and Text Classification. Building a voice assistant from scratch takes the prolonged efforts of several teams constructing numerous models and orchestrating between components. Alternatives such as using third-party vendors or re-purposing existing models may be considered to shorten time-to-market and development costs. However, each option has its benefits and drawbacks. We present key insights from building a voice search assistant for <a class="link-external link-http" href="http://Booking.com" rel="external noopener nofollow">this http URL</a> search and recommendation system. Our paper compares the achieved performance and development efforts in dedicated tailor-made solutions against existing re-purposed models. We share and discuss our data-driven decisions about implementation trade-offs and their estimated outcomes in hindsight, showing that a fully functional machine learning product can be built from existing models.      
### 22.Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts  [ :arrow_down: ](https://arxiv.org/pdf/2108.11926.pdf)
>  Thanks to their ability to learn flexible data-driven losses, Generative Adversarial Networks (GANs) are an integral part of many semi- and weakly-supervised methods for medical image segmentation. GANs jointly optimise a generator and an adversarial discriminator on a set of training data. After training has completed, the discriminator is usually discarded and only the generator is used for inference. But should we discard discriminators? In this work, we argue that training stable discriminators produces expressive loss functions that we can re-use at inference to detect and correct segmentation mistakes. First, we identify key challenges and suggest possible solutions to make discriminators re-usable at inference. Then, we show that we can combine discriminators with image reconstruction costs (via decoders) to further improve the model. Our method is simple and improves the test-time performance of pre-trained GANs. Moreover, we show that it is compatible with standard post-processing techniques and it has potentials to be used for Online Continual Learning. With our work, we open new research avenues for re-using adversarial discriminators at inference.      
### 23.Green Internet of Vehicles (IoV) in the 6G Era: Toward Sustainable Vehicular Communications and Networking  [ :arrow_down: ](https://arxiv.org/pdf/2108.11879.pdf)
>  As one of the most promising applications in future Internet of Things, Internet of Vehicles (IoV) has been acknowledged as a fundamental technology for developing the Intelligent Transportation Systems in smart cities. With the emergence of the sixth generation (6G) communications technologies, massive network infrastructures will be densely deployed and the number of network nodes will increase exponentially, leading to extremely high energy consumption. There has been an upsurge of interest to develop the green IoV towards sustainable vehicular communication and networking in the 6G era. In this paper, we present the main considerations for green IoV from five different scenarios, including the communication, computation, traffic, Electric Vehicles (EVs), and energy harvesting management. The literatures relevant to each of the scenarios are compared from the perspective of energy optimization (e.g., with respect to resource allocation, workload scheduling, routing design, traffic control, charging management, energy harvesting and sharing, etc.) and the related factors affecting energy efficiency (e.g., resource limitation, channel state, network topology, traffic condition, etc.). In addition, we introduce the potential challenges and the emerging technologies in 6G for developing green IoV systems. Finally, we discuss the research trends in designing energy-efficient IoV systems.      
### 24.Attention-based Neural Load Forecasting: A Dynamic Feature Selection Approach  [ :arrow_down: ](https://arxiv.org/pdf/2108.11763.pdf)
>  Encoder-decoder-based recurrent neural network (RNN) has made significant progress in sequence-to-sequence learning tasks such as machine translation and conversational models. Recent works have shown the advantage of this type of network in dealing with various time series forecasting tasks. The present paper focuses on the problem of multi-horizon short-term load forecasting, which plays a key role in the power system's planning and operation. Leveraging the encoder-decoder RNN, we develop an attention model to select the relevant features and similar temporal information adaptively. First, input features are assigned with different weights by a feature selection attention layer, while the updated historical features are encoded by a bi-directional long short-term memory (BiLSTM) layer. Then, a decoder with hierarchical temporal attention enables a similar day selection, which re-evaluates the importance of historical information at each time step. Numerical results tested on the dataset of the global energy forecasting competition 2014 show that our proposed model significantly outperforms some existing forecasting schemes.      
### 25.Determining the origin of impulsive noise events using paired wireless sound sensors  [ :arrow_down: ](https://arxiv.org/pdf/2108.11758.pdf)
>  This work investigates how to identify the source of impulsive noise events using a pair of wireless noise sensors. One sensor is placed at a known noise source, and another sensor is placed at the noise receiver. Machine learning models receive data from the two sensors and estimate whether a given noise event originates from the known noise source or another source. To avoid privacy issues, the approach uses on-edge preprocessing that converts the sound into privacy compatible spectrograms. The system was evaluated at a shooting range and explosives training facility, using data collected during noise emission testing. The combination of convolutional neural networks with cross-correlation achieved the best results. We created multiple alternative models using different spectrogram representations. The best model detected 70.8\% of the impulsive noise events and correctly predicted 90.3\% of the noise events in the optimal trade-off between recall and precision.      
### 26.Fast Accurate Defect Detection in Wafer Fabrication  [ :arrow_down: ](https://arxiv.org/pdf/2108.11757.pdf)
>  A generic fast method for object classification is proposed. In addition, a method for dimensional reduction is presented. The presented algorithms have been applied to real-world data from chip fabrication successfully to the task of predicting defect states of tens of thousands of chips of several products based on measurements or even just part of measurements. Unlike typical neural networks with a large number of weights to optimize over, the presented algorithm tries optimizing only over a very small number of variables in order to increase chances to find a global optimum. Our approach is interesting in that it is fast, led to good to very good performance with real-world wafer data, allows for short implementations and computes values which have a clear meaning easy to explain.      
### 27.Deep learning based dictionary learning and tomographic image reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2108.11730.pdf)
>  This work presents an approach for image reconstruction in clinical low-dose tomography that combines principles from sparse signal processing with ideas from deep learning. First, we describe sparse signal representation in terms of dictionaries from a statistical perspective and interpret dictionary learning as a process of aligning distribution that arises from a generative model with empirical distribution of true signals. As a result we can see that sparse coding with learned dictionaries resembles a specific variational autoencoder, where the decoder is a linear function and the encoder is a sparse coding algorithm. Next, we show that dictionary learning can also benefit from computational advancements introduced in the context of deep learning, such as parallelism and as stochastic optimization. Finally, we show that regularization by dictionaries achieves competitive performance in computed tomography (CT) reconstruction comparing to state-of-the-art model based and data driven approaches.      
### 28.Revenue Maximization through Cell Switching and Spectrum Leasing in 5G HetNets  [ :arrow_down: ](https://arxiv.org/pdf/2108.11697.pdf)
>  One of the ways of achieving improved capacity in mobile cellular networks is via network densification. Even though densification increases the capacity of the network, it also leads to increased energy consumption which can be curbed by dynamically switching off some base stations (BSs) during periods of low traffic. However, dynamic cell switching has the challenge of spectrum under-utilizationas the spectrum originally occupied by the BSs that are turned off remains dormant. This dormant spectrum can be leased by the primary network (PN) operators, who hold the license, to the secondary network (SN) operators who cannot afford to purchase the spectrum license. Thus enabling the PN to gain additional revenue from spectrum leasing as well as from electricity cost savings due to reduced energy consumption. Therefore, in this work, we propose a cell switching and spectrum leasing framework based on simulated annealing (SA) algorithm to maximize the revenue of the PN while respecting the quality-of-service constraints. The performance evaluation reveals that the proposed method is very close to optimal exhaustive search method with a significant reduction in the computation complexity.      
### 29.Independent dimensional phase transition on a two-dimensional Kuramoto model with matrix coupling  [ :arrow_down: ](https://arxiv.org/pdf/2108.11652.pdf)
>  The high-dimensional generalization of the one-dimensional Kuramoto paradigm has been an essential step in bringing about a more faithful depiction of the dynamics of real-world systems. Despite the multi-dimensional nature of the oscillators in these generalized models, the interacting schemes so far have been dominated by a scalar factor unanimously between any pair of oscillators that leads eventually to synchronization on all dimensions. As a natural extension of the scalar coupling befitting for the one-dimensional case, we take a tentative step in studying numerically and theoretically the coupling mechanism of $2\times2$ real matrices on two-dimensional Kuramoto oscillators. One of the features stemmed from this new mechanism is that the matrix coupling enables the two dimensions of the oscillators to separate their transitions to either synchronization or desynchronization which has not been seen in other high-dimensional generalizations. Under various matrix configurations, the synchronization and desynchronization of the two dimensions combine into four qualitatively distinct modes of position and motion of the system. We demonstrate that as one matrix is morphed into another in a specific manner, the system mode also switches correspondingly either through continuous or explosive transitions of the order parameters, thus mimicking a range of behaviors in information science and biology.      
### 30.Self-Attention for Audio Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2108.11637.pdf)
>  Convolutions operate only locally, thus failing to model global interactions. Self-attention is, however, able to learn representations that capture long-range dependencies in sequences. We propose a network architecture for audio super-resolution that combines convolution and self-attention. Attention-based Feature-Wise Linear Modulation (AFiLM) uses self-attention mechanism instead of recurrent neural networks to modulate the activations of the convolutional model. Extensive experiments show that our model outperforms existing approaches on standard benchmarks. Moreover, it allows for more parallelization resulting in significantly faster training.      
### 31.Web Image Context Extraction with Graph Neural Networks and Sentence Embeddings on the DOM tree  [ :arrow_down: ](https://arxiv.org/pdf/2108.11629.pdf)
>  Web Image Context Extraction (WICE) consists in obtaining the textual information describing an image using the content of the surrounding webpage. A common preprocessing step before performing WICE is to render the content of the webpage. When done at a large scale (e.g., for search engine indexation), it may become very computationally costly (up to several seconds per page). To avoid this cost, we introduce a novel WICE approach that combines Graph Neural Networks (GNNs) and Natural Language Processing models. Our method relies on a graph model containing both node types and text as features. The model is fed through several blocks of GNNs to extract the textual context. Since no labeled WICE dataset with ground truth exists, we train and evaluate the GNNs on a proxy task that consists in finding the semantically closest text to the image caption. We then interpret importance weights to find the most relevant text nodes and define them as the image context. Thanks to GNNs, our model is able to encode both structural and semantic information from the webpage. We show that our approach gives promising results to help address the large-scale WICE problem using only HTML data.      
### 32.Towards Robust Mispronunciation Detection and Diagnosis for L2 English Learners with Accent-Modulating Methods  [ :arrow_down: ](https://arxiv.org/pdf/2108.11627.pdf)
>  With the acceleration of globalization, more and more people are willing or required to learn second languages (L2). One of the major remaining challenges facing current mispronunciation and diagnosis (MDD) models for use in computer-assisted pronunciation training (CAPT) is to handle speech from L2 learners with a diverse set of accents. In this paper, we set out to mitigate the adverse effects of accent variety in building an L2 English MDD system with end-to-end (E2E) neural models. To this end, we first propose an effective modeling framework that infuses accent features into an E2E MDD model, thereby making the model more accent-aware. Going a step further, we design and present disparate accent-aware modules to perform accent-aware modulation of acoustic features in a fine-grained manner, so as to enhance the discriminating capability of the resulting MDD model. Extensive sets of experiments conducted on the L2-ARCTIC benchmark dataset show the merits of our MDD model, in comparison to some existing E2E-based strong baselines and the celebrated pronunciation scoring based method.      
### 33.Model-based Chance-Constrained Reinforcement Learning via Separated Proportional-Integral Lagrangian  [ :arrow_down: ](https://arxiv.org/pdf/2108.11623.pdf)
>  Safety is essential for reinforcement learning (RL) applied in the real world. Adding chance constraints (or probabilistic constraints) is a suitable way to enhance RL safety under uncertainty. Existing chance-constrained RL methods like the penalty methods and the Lagrangian methods either exhibit periodic oscillations or learn an over-conservative or unsafe policy. In this paper, we address these shortcomings by proposing a separated proportional-integral Lagrangian (SPIL) algorithm. We first review the constrained policy optimization process from a feedback control perspective, which regards the penalty weight as the control input and the safe probability as the control output. Based on this, the penalty method is formulated as a proportional controller, and the Lagrangian method is formulated as an integral controller. We then unify them and present a proportional-integral Lagrangian method to get both their merits, with an integral separation technique to limit the integral value in a reasonable range. To accelerate training, the gradient of safe probability is computed in a model-based manner. We demonstrate our method can reduce the oscillations and conservatism of RL policy in a car-following simulation. To prove its practicality, we also apply our method to a real-world mobile robot navigation task, where our robot successfully avoids a moving obstacle with highly uncertain or even aggressive behaviors.      
### 34.Identification of the Resting Position Based on EGG, ECG, Respiration Rate and SpO2 Using Stacked Ensemble Learning  [ :arrow_down: ](https://arxiv.org/pdf/2108.11604.pdf)
>  Rest is essential for a high-level physiological and psychological performance. It is also necessary for the muscles to repair, rebuild, and strengthen. There is a significant correlation between the quality of rest and the resting posture. Therefore, identification of the resting position is of paramount importance to maintain a healthy life. Resting postures can be classified into four basic categories: Lying on the back (supine), facing of the left / right sides and free-fall position. The later position is already considered to be an unhealthy posture by researchers equivocally and hence can be eliminated. In this paper, we analyzed the other three states of resting position based on the data collected from the physiological parameters: Electrogastrogram (EGG), Electrocardiogram (ECG), Respiration Rate, Heart Rate, and Oxygen Saturation (SpO2). Based on these parameters, the resting position is classified using a hybrid stacked ensemble machine learning model designed using the Decision tree, Random Forest, and Xgboost algorithms. Our study demonstrates a 100% accurate prediction of the resting position using the hybrid model. The proposed method of identifying the resting position based on physiological parameters has the potential to be integrated into wearable devices. This is a low cost, highly accurate and autonomous technique to monitor the body posture while maintaining the user privacy by eliminating the use of RGB camera conventionally used to conduct the polysomnography (sleep Monitoring) or resting position studies.      
### 35.Bilateral Denoising Diffusion Models  [ :arrow_down: ](https://arxiv.org/pdf/2108.11514.pdf)
>  Denoising diffusion probabilistic models (DDPMs) have emerged as competitive generative models yet brought challenges to efficient sampling. In this paper, we propose novel bilateral denoising diffusion models (BDDMs), which take significantly fewer steps to generate high-quality samples. From a bilateral modeling objective, BDDMs parameterize the forward and reverse processes with a score network and a scheduling network, respectively. We show that a new lower bound tighter than the standard evidence lower bound can be derived as a surrogate objective for training the two networks. In particular, BDDMs are efficient, simple-to-train, and capable of further improving any pre-trained DDPM by optimizing the inference noise schedules. Our experiments demonstrated that BDDMs can generate high-fidelity samples with as few as 3 sampling steps and produce comparable or even higher quality samples than DDPMs using 1000 steps with only 16 sampling steps (a 62x speedup).      
### 36.Integrated Speech and Gesture Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2108.11436.pdf)
>  Text-to-speech and co-speech gesture synthesis have until now been treated as separate areas by two different research communities, and applications merely stack the two technologies using a simple system-level pipeline. This can lead to modeling inefficiencies and may introduce inconsistencies that limit the achievable naturalness. We propose to instead synthesize the two modalities in a single model, a new problem we call integrated speech and gesture synthesis (ISG). We also propose a set of models modified from state-of-the-art neural speech-synthesis engines to achieve this goal. We evaluate the models in three carefully-designed user studies, two of which evaluate the synthesized speech and gesture in isolation, plus a combined study that evaluates the models like they will be used in real-world applications -- speech and gesture presented together. The results show that participants rate one of the proposed integrated synthesis models as being as good as the state-of-the-art pipeline system we compare against, in all three tests. The model is able to achieve this with faster synthesis time and greatly reduced parameter count compared to the pipeline system, illustrating some of the potential benefits of treating speech and gesture synthesis together as a single, unified problem. Videos and code are available on our project page at <a class="link-external link-https" href="https://swatsw.github.io/isg_icmi21/" rel="external noopener nofollow">this https URL</a>      
