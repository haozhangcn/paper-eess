# ArXiv eess --Tue, 19 Jan 2021
### 1.A tool for user friendly, cloud based, whole slide image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.07222.pdf)
>  Convolutional neural networks, the state of the art for image segmentation, have been successfully applied to histology images by many computational researchers. However, the translatability of this technology to clinicians and biological researchers is limited due to the complex and undeveloped user interface of the code, as well as the extensive computer setup required. As an extension of our previous work (<a class="link-https" data-arxiv-id="1812.07509" href="https://arxiv.org/abs/1812.07509">arXiv:1812.07509</a>), we have developed a tool for segmentation of whole slide images (WSIs) with an easy to use graphical user interface. Our tool runs a state-of-the-art convolutional neural network for segmentation of WSIs in the cloud. Our plugin is built on the open source tool HistomicsTK by Kitware Inc. (Clifton Park, NY), which provides remote data management and viewing abilities for WSI datasets. The ability to access this tool over the internet will facilitate widespread use by computational non-experts. Users can easily upload slides to a server where our plugin is installed and perform human in the loop segmentation analysis remotely. This tool is open source, and has the ability to be adapted to segment of any pathological structure. For a proof of concept, we have trained it to segment glomeruli from renal tissue images, achieving an F-score &gt; 0.97 on holdout tissue slides.      
### 2.A New Approach for Automatic Segmentation and Evaluation of Pigmentation Lesion by using Active Contour Model and Speeded Up Robust Features  [ :arrow_down: ](https://arxiv.org/pdf/2101.07195.pdf)
>  Digital image processing techniques have wide applications in different scientific fields including the medicine. By use of image processing algorithms, physicians have been more successful in diagnosis of different diseases and have achieved much better treatment results. In this paper, we propose an automatic method for segmenting the skin lesions and extracting features that are associated to them. At this aim, a combination of Speeded-Up Robust Features (SURF) and Active Contour Model (ACM), is used. In the suggested method, at first region of skin lesion is segmented from the whole skin image, and then some features like the mean, variance, RGB and HSV parameters are extracted from the segmented region. Comparing the segmentation results, by use of Otsu thresholding, our proposed method, shows the superiority of our procedure over the Otsu theresholding method. Segmentation of the skin lesion by the proposed method and Otsu thresholding compared the results with physician's manual method. The proposed method for skin lesion segmentation, which is a combination of SURF and ACM, gives the best result. For empirical evaluation of our method, we have applied it on twenty different skin lesion images. Obtained results confirm the high performance, speed and accuracy of our method.      
### 3.Quantification of Disaggregation Difficulty with Respect to the Number of Meters  [ :arrow_down: ](https://arxiv.org/pdf/2101.07191.pdf)
>  A promising approach toward efficient energy management is non-intrusive load monitoring (NILM), that is to extract the consumption profiles of appliances within a residence by analyzing the aggregated consumption signal. Among efficient NILM methods are event-based algorithms in which events of the aggregated signal are detected and classified in accordance with the appliances causing them. The large number of appliances and the presence of appliances with close consumption values are known to limit the performance of event-based NILM methods. To tackle these challenges, one could enhance the feature space which in turn results in extra hardware costs, installation complexity, and concerns regarding the consumer's comfort and privacy. This has led to the emergence of an alternative approach, namely semi-intrusive load monitoring (SILM), where appliances are partitioned into blocks and the consumption of each block is monitored via separate power meters. <br>While a greater number of meters can result in more accurate disaggregation, it increases the monetary cost of load monitoring, indicating a trade-off that represents an important gap in this field. In this paper, we take a comprehensive approach to close this gap by establishing a so-called notion of "disaggregation difficulty metric (DDM)," which quantifies how difficult it is to monitor the events of any given group of appliances based on both their power values and the consumer's usage behavior. Thus, DDM in essence quantifies how much is expected to be gained in terms of disaggregation accuracy of a generic event-based algorithm by installing meters on the blocks of any partition of the appliances. Experimental results based on the REDD dataset illustrate the practicality of the proposed approach in addressing the aforementioned trade-off.      
### 4.Incorporating Coincidental Water Data into Non-intrusive Load Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2101.07190.pdf)
>  Non-intrusive load monitoring (NILM) as the process of extracting the usage pattern of appliances from the aggregated power signal is among successful approaches aiding residential energy management. In recent years, high volume datasets on power profiles have become available, which has helped make classification methods employed for the NILM purpose more effective and more accurate. However, the presence of multi-mode appliances and appliances with close power values have remained influential in worsening the computational complexity and diminishing the accuracy of these algorithms. To tackle these challenges, we propose an event-based classification process, in the first phase of which the $K$-nearest neighbors method, as a fast classification technique, is employed to extract power signals of appliances with exclusive non-overlapping power values. Then, two deep learning models, which consider the water consumption of some appliances as a novel signature in the network, are utilized to distinguish between appliances with overlapping power values. In addition to power disaggregation, the proposed process as well extracts the water consumption profiles of specific appliances. To illustrate the proposed process and validate its efficiency, seven appliances of the AMPds are considered, with the numerical classification results showing marked improvement with respect to the existing classification-based NILM techniques.      
### 5.Model-Based Reinforcement Learning for Approximate Optimal Control with Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2101.07156.pdf)
>  In this paper we study the problem of synthesizing optimal control policies for uncertain continuous-time nonlinear systems from syntactically co-safe linear temporal logic (scLTL) formulas. We formulate this problem as a sequence of reach-avoid optimal control sub-problems. We show that the resulting hybrid optimal control policy guarantees the satisfaction of a given scLTL formula by constructing a barrier certificate. Since solving each optimal control problem may be computationally intractable, we take a learning-based approach to approximately solve this sequence of optimal control problems online without requiring full knowledge of the system dynamics. Using Lyapunov-based tools, we develop sufficient conditions under which our approximate solution maintains correctness. Finally, we demonstrate the efficacy of the developed method with a numerical example.      
### 6.Graph-based Matched Field Localization for an Underwater Source  [ :arrow_down: ](https://arxiv.org/pdf/2101.07137.pdf)
>  Matched Field Processing (MFP) locates the underwater sources by matching the received data with the replica vectors, which could be regarded as a generalized beamformer. In this paper, the MFP method is combined with a recently developed framework -- Graph Signal Processing (GSP) method. Following the paradigm of GSP, a spatial adjacency matrix is constructed for the arbitrary distributed sensors based on the Green's function, then the source is located by utilizing the graph Fourier transform. The simulation results illustrate that the Graph-based MFP outperforms the the conventional MFP processors -- the Bartlett processor and the Minimum Variance processor -- for its good accuracy and robustness.      
### 7.Sum-Rate Maximization in Distributed Intelligent Reflecting Surfaces-Aided mmWave Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.07073.pdf)
>  In this paper, we focus on the sum-rate optimization in a multi-user millimeter-wave (mmWave) system with distributed intelligent reflecting surfaces (D-IRSs), where a base station (BS) communicates with users via multiple IRSs. The BS transmit beamforming, IRS switch vector, and phase shifts of the IRS are jointly optimized to maximize the sum-rate under minimum user rate, unit-modulus, and transmit power constraints. To solve the resulting non-convex optimization problem, we develop an efficient alternating optimization (AO) algorithm. Specifically, the non-convex problem is converted into three subproblems, which are solved alternatively. The solution to transmit beamforming at the BS and the phase shifts at the IRS are derived by using the successive convex approximation (SCA)-based algorithm, and a greedy algorithm is proposed to design the IRS switch vector. The complexity of the proposed AO algorithm is analyzed theoretically. Numerical results show that the D-IRSs-aided scheme can significantly improve the sum-rate and energy efficiency performance.      
### 8.Iterative Facial Image Inpainting using Cyclic Reverse Generator  [ :arrow_down: ](https://arxiv.org/pdf/2101.07036.pdf)
>  Facial image inpainting is a challenging problem as it requires generating new pixels that include semantic information for masked key components in a face, e.g., eyes and nose. Recently, remarkable methods have been proposed in this field. Most of these approaches use encoder-decoder architectures and have different limitations such as allowing unique results for a given image and a particular mask. Alternatively, some approaches generate promising results using different masks with generator networks. However, these approaches are optimization-based and usually require quite a number of iterations. In this paper, we propose an efficient solution to the facial image painting problem using the Cyclic Reverse Generator (CRG) architecture, which provides an encoder-generator model. We use the encoder to embed a given image to the generator space and incrementally inpaint the masked regions until a plausible image is generated; a discriminator network is utilized to assess the generated images during the iterations. We empirically observed that only a few iterations are sufficient to generate realistic images with the proposed model. After the generation process, for the post processing, we utilize a Unet model that we trained specifically for this task to remedy the artifacts close to the mask boundaries. Our method allows applying sketch-based inpaintings, using variety of mask types, and producing multiple and diverse results. We qualitatively compared our method with the state-of-the-art models and observed that our method can compete with the other models in all mask types; it is particularly better in images where larger masks are utilized.      
### 9.Federated Learning Based Proactive Handover in Millimeter-wave Vehicular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.07032.pdf)
>  Proactive handover can avoid frequent handovers and reduce handover delay, which plays an important role in maintaining the quality of service (QoS) for mobile users in millimeter-wave vehicular networks. To reduce the communication cost of training the learning model for proactive handover, we propose a federated learning (FL) framework. The proposed FL framework can accommodate the limited storage capacity of each user, increase the number of users who participate in the FL, and adapt to the dynamic mobility pattern. Simulation results validate the effectiveness of the proposed FL framework. Compared to reactive handover schemes, the proposed handover scheme can reduce unnecessary handovers and improve the QoS of users simultaneously.      
### 10.Comparing Deep Learning strategies for paired but unregistered multimodal segmentation of the liver in T1 and T2-weighted MRI  [ :arrow_down: ](https://arxiv.org/pdf/2101.06979.pdf)
>  We address the problem of multimodal liver segmentation in paired but unregistered T1 and T2-weighted MR images. We compare several strategies described in the literature, with or without multi-task training, with or without pre-registration. We also compare different loss functions (cross-entropy, Dice loss, and three adversarial losses). All methods achieved comparable performances with the exception of a multi-task setting that performs both segmentations at once, which performed poorly.      
### 11.Uncertainty-Aware Body Composition Analysis with Deep Regression Ensembles on UK Biobank MRI  [ :arrow_down: ](https://arxiv.org/pdf/2101.06963.pdf)
>  Purpose: To enable fast and automated analysis of body composition from UK Biobank MRI with accurate estimates of individual measurement errors. <br>Methods: In an ongoing large-scale imaging study the UK Biobank has acquired MRI of over 40,000 men and women aged 44-82. Phenotypes derived from these images, such as body composition, can reveal new links between genetics, cardiovascular disease, and metabolic conditions. In this retrospective study, neural networks were trained to provide six measurements of body composition from UK Biobank neck-to-knee body MRI. A ResNet50 architecture can automatically predict these values by image-based regression, but may also produce erroneous outliers. Predictive uncertainty, which could identify these failure cases, was therefore modeled with a mean-variance loss and ensembling. Its estimates of individual prediction errors were evaluated in cross-validation on over 8,000 subjects, tested on another 1,000 cases, and finally applied for inference. <br>Results: Relative measurement errors below 5\% were achieved on all but one target, for intra-class correlation coefficients (ICC) above 0.97 both in validation and testing. Both mean-variance loss and ensembling yielded improvements and provided uncertainty estimates that highlighted some of the worst outlier predictions. Combined, they reached the highest quality, but also exhibited a consistent bias towards high uncertainty in heavyweight subjects. <br>Conclusion: Mean-variance regression and ensembling provided complementary benefits for automated body composition measurements from UK Biobank MRI, reaching high speed and accuracy. These values were inferred for the entire cohort, with uncertainty estimates that can approximate the measurement errors and identify some of the worst outliers automatically.      
### 12.Covid-19 classification with deep neural network and belief functions  [ :arrow_down: ](https://arxiv.org/pdf/2101.06958.pdf)
>  Computed tomography (CT) image provides useful information for radiologists to diagnose Covid-19. However, visual analysis of CT scans is time-consuming. Thus, it is necessary to develop algorithms for automatic Covid-19 detection from CT images. In this paper, we propose a belief function-based convolutional neural network with semi-supervised training to detect Covid-19 cases. Our method first extracts deep features, maps them into belief degree maps and makes the final classification decision. Our results are more reliable and explainable than those of traditional deep learning-based classification models. Experimental results show that our approach is able to achieve a good performance with an accuracy of 0.81, an F1 of 0.812 and an AUC of 0.875.      
### 13.Deep Learning based Antenna Selection and CSI Extrapolation in Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06951.pdf)
>  A critical bottleneck of massive multiple-input multiple-output (MIMO) system is the huge training overhead caused by downlink transmission, like channel estimation, downlink beamforming and covariance observation. In this paper, we propose to use the channel state information (CSI) of a small number of antennas to extrapolate the CSI of the other antennas and reduce the training overhead. Specifically, we design a deep neural network that we call an antenna domain extrapolation network (ADEN) that can exploit the correlation function among antennas. We then propose a deep learning (DL) based antenna selection network (ASN) that can select a limited antennas for optimizing the extrapolation, which is conventionally a type of combinatorial optimization and is difficult to solve. We trickly designed a constrained degradation algorithm to generate a differentiable approximation of the discrete antenna selection vector such that the back-propagation of the neural network can be guaranteed. Numerical results show that the proposed ADEN outperforms the traditional fully connected one, and the antenna selection scheme learned by ASN is much better than the trivially used uniform selection.      
### 14.From Small-Gain Theory to Compositional Construction of Barrier Certificates for Large-Scale Stochastic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06916.pdf)
>  This paper is concerned with a compositional approach for the construction of control barrier certificates for large-scale interconnected stochastic systems while synthesizing hybrid controllers against high-level logic properties. Our proposed methodology involves decomposition of interconnected systems into smaller subsystems and leverages the notion of control sub-barrier certificates of subsystems, enabling one to construct control barrier certificates of interconnected systems by employing some $\max$-type small-gain conditions. The main goal is to synthesize hybrid controllers enforcing complex logic properties including the ones represented by the accepting language of deterministic finite automata (DFA), while providing probabilistic guarantees on the satisfaction of given specifications in bounded-time horizons. To do so, we propose a systematic approach to first decompose high-level specifications into simple reachability tasks by utilizing automata corresponding to the complement of specifications. We then construct control sub-barrier certificates and synthesize local controllers for those simpler tasks and combine them to obtain a hybrid controller that ensures satisfaction of the complex specification with some lower-bound on the probability of satisfaction. To compute control sub-barrier certificates and corresponding local controllers, we provide two systematic approaches based on sum-of-squares (SOS) optimization program and counter-example guided inductive synthesis (CEGIS) framework. We finally apply our proposed techniques to two physical case studies.      
### 15.A Novel Registration &amp; Colorization Technique for Thermal to Cross Domain Colorized Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.06910.pdf)
>  Thermal images can be obtained as either grayscale images or pseudo colored images based on the thermal profile of the object being captured. We present a novel registration method that works on images captured via multiple thermal imagers irrespective of make and internal resolution as well as a colorization scheme that can be used to obtain a colorized thermal image which is similar to an optical image, while retaining the information of the thermal profile as a part of the output, thus providing information of both domains jointly. We call this a cross domain colorized image. We also outline a new public thermal-optical paired database that we are presenting as a part of this paper, containing unique data points obtained via multiple thermal imagers. Finally, we compare the results with prior literature, show how our results are different and discuss on some future work that can be explored further in this domain as well.      
### 16.Tiny Transducer: A Highly-efficient Speech Recognition Model on Edge Devices  [ :arrow_down: ](https://arxiv.org/pdf/2101.06856.pdf)
>  This paper proposes an extremely lightweight phone-based transducer model with a tiny decoding graph on edge devices. First, a phone synchronous decoding (PSD) algorithm based on blank label skipping is first used to speed up the transducer decoding process. Then, to decrease the deletion errors introduced by the high blank score, a blank label deweighting approach is proposed. To reduce parameters and computation, deep feedforward sequential memory network (DFSMN) layers are used in the transducer encoder, and a CNN-based stateless predictor is adopted. SVD technology compresses the model further. WFST-based decoding graph takes the context-independent (CI) phone posteriors as input and allows us to flexibly bias user-specific information. Finally, with only 0.9M parameters after SVD, our system could give a relative 9.1% - 20.5% improvement compared with a bigger conventional hybrid system on edge devices.      
### 17.Deep Symmetric Adaptation Network for Cross-modality Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06853.pdf)
>  Unsupervised domain adaptation (UDA) methods have shown their promising performance in the cross-modality medical image segmentation tasks. These typical methods usually utilize a translation network to transform images from the source domain to target domain or train the pixel-level classifier merely using translated source images and original target images. However, when there exists a large domain shift between source and target domains, we argue that this asymmetric structure could not fully eliminate the domain gap. In this paper, we present a novel deep symmetric architecture of UDA for medical image segmentation, which consists of a segmentation sub-network, and two symmetric source and target domain translation sub-networks. To be specific, based on two translation sub-networks, we introduce a bidirectional alignment scheme via a shared encoder and private decoders to simultaneously align features 1) from source to target domain and 2) from target to source domain, which helps effectively mitigate the discrepancy between domains. Furthermore, for the segmentation sub-network, we train a pixel-level classifier using not only original target images and translated source images, but also original source images and translated target images, which helps sufficiently leverage the semantic information from the images with different styles. Extensive experiments demonstrate that our method has remarkable advantages compared to the state-of-the-art methods in both cross-modality Cardiac and BraTS segmentation tasks.      
### 18.Performance Analysis and Codebook Design for mmWave Beamforming System with Beam Squint  [ :arrow_down: ](https://arxiv.org/pdf/2101.06845.pdf)
>  Beamforming technology is widely used in millimeter wave systems to combat path losses, and beamformers are usually selected from a predefined codebook. Unfortunately, traditional codebook design neglects the beam squint effect, and this will cause severe performance degradation when the bandwidth is large. In this letter, we consider that a codebook with fixed size is adopted in the wideband beamforming system. First, based on the rectangular beams with conventional beam coverage, we analyze how beam squint affects system performance and derive the expression of average spectrum efficiency. Next, we formulate optimization problem to design the optimal codebook. Simulation results demonstrate that the proposed codebook spreads beam coverage to cope with beam squint and significantly slows down the performance degradation.      
### 19.Learning to Select for MIMO Radar based on Hybrid Analog-Digital Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2101.06837.pdf)
>  In this paper, we propose an energy-efficient radar beampattern design framework for a Millimeter Wave (mmWave) massive multi-input multi-output (mMIMO) system, equipped with a hybrid analog-digital (HAD) beamforming structure. Aiming to reduce the power consumption and hardware cost of the mMIMO system, we employ a machine learning approach to synthesize the probing beampattern based on a small number of RF chains and antennas. By leveraging a combination of softmax neural networks, the proposed solution is able to achieve a desirable beampattern with high accuracy.      
### 20.Sparse Array Beamformer Design for Active and Passive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2101.06816.pdf)
>  Sparse sensor placement, with various design objectives, has successfully been employed in diverse application areas, particularly for enhanced parameter estimation and receiver performance. The sparse array design criteria are generally categorized into environment-independent and environment-dependent performance metrics. The former are largely benign to the underlying environment and, in principle, seek to maximize the spatial degrees of freedom by extending the coarray aperture. Environment-dependent objectives, on the other hand, consider the operating conditions characterized by emitters and targets in the array field of view, in addition to receiver noise. In this regard, applying such objectives renders the array configuration as well as the array weights time-varying in response to dynamic and changing environment. <br>This work is geared towards designing environment-dependent sparse array beamformer to improve the output signal-to-interference and noise ratio using both narrowband and wideband signal platforms. One key challenge in implementing the data-dependent approaches is the lack of knowledge of exact or estimated values of the data autocorrelation function across the full sparse array aperture. At the core of this work is to address the aforementioned issues by devising innovative solutions using convex optimization and machine learning tools, structured sparsity concepts, low rank matrix completion schemes and fusing the environment-dependent and environment-independent deigns by developing a hybrid approach.      
### 21.Robust Energy-Efficient Resource Management, SIC Ordering, and Beamforming Design for MC MISO-NOMA Enabled 6G  [ :arrow_down: ](https://arxiv.org/pdf/2101.06799.pdf)
>  This paper studies a novel approach for successive interference cancellation (SIC) ordering and beamforming in a multiple antennas non-orthogonal multiple access (NOMA) network with multi-carrier multi-user setup. To this end, we formulate a joint beamforming design, subcarrier allocation, user association, and SIC ordering algorithm to maximize the worst-case energy efficiency (EE). The formulated problem is a non-convex mixed integer non-linear programming (MINLP) which is generally difficult to solve. To handle it, we first adopt the linearizion technique as well as relaxing the integer variables, and then we employ the Dinkelbach algorithm to convert it into a more mathematically tractable form. The adopted non-convex optimization problem is transformed into an equivalent rank-constrained semidefinite programming (SDP) and is solved by SDP relaxation and exploiting sequential fractional programming. Furthermore, to strike a balance between complexity and performance, a low complex approach based on alternative optimization is adopted. Numerical results unveil that the proposed SIC ordering method outperforms the conventional existing works addressed in the literature.      
### 22.IRS-Enabled Beam-Space Channel  [ :arrow_down: ](https://arxiv.org/pdf/2101.06796.pdf)
>  A model for intelligent reflecting surface (IRS)- enabled beam-space channel is proposed in this paper. Instead of treating IRS as a node in the middle and creating an additional burden of estimating two additional channels, the developed model shows that IRS is just part of the channel acting as a controlled scattering cluster reflecting its own multipath components (MPCs). An antenna segmentation method is proposed to fit IRS in the developed far-field model and show the characteristics of its MPCs and how they can be controlled. To maximize the received signal power, a cascaded beamforming scheme is next proposed. In this scheme, the number of transmitter antenna elements that should be activated is derived in terms of IRS angular span and beamforming at the receiver. Simulation results show that even with the possibility of using more elements, using less number of them gives significant improvement for large IRSs at close distances.      
### 23.An embedded multichannel sound acquisition system for drone audition  [ :arrow_down: ](https://arxiv.org/pdf/2101.06795.pdf)
>  Microphone array techniques can improve the acoustic sensing performance on drones, compared to the use of a single microphone. However, multichannel sound acquisition systems are not available in current commercial drone platforms. To encourage the research in drone audition, we present an embedded sound acquisition and recording system with eight microphones and a multichannel sound recorder mounted on a quadcopter. In addition to recording and storing locally the sound from multiple microphones simultaneously, the embedded system can connect wirelessly to a remote terminal to transfer audio files for further processing. This will be the first stage towards creating a fully embedded solution for drone audition. We present experimental results obtained by state-of-the-art drone audition algorithms applied to the sound recorded by the embedded system.      
### 24.Symmetric-Constrained Irregular Structure Inpainting for Brain MRI Registration with Tumor Pathology  [ :arrow_down: ](https://arxiv.org/pdf/2101.06775.pdf)
>  Deformable registration of magnetic resonance images between patients with brain tumors and healthy subjects has been an important tool to specify tumor geometry through location alignment and facilitate pathological analysis. Since tumor region does not match with any ordinary brain tissue, it has been difficult to deformably register a patients brain to a normal one. Many patient images are associated with irregularly distributed lesions, resulting in further distortion of normal tissue structures and complicating registration's similarity measure. In this work, we follow a multi-step context-aware image inpainting framework to generate synthetic tissue intensities in the tumor region. The coarse image-to-image translation is applied to make a rough inference of the missing parts. Then, a feature-level patch-match refinement module is applied to refine the details by modeling the semantic relevance between patch-wise features. A symmetry constraint reflecting a large degree of anatomical symmetry in the brain is further proposed to achieve better structure understanding. Deformable registration is applied between inpainted patient images and normal brains, and the resulting deformation field is eventually used to deform original patient data for the final alignment. The method was applied to the Multimodal Brain Tumor Segmentation (BraTS) 2018 challenge database and compared against three existing inpainting methods. The proposed method yielded results with increased peak signal-to-noise ratio, structural similarity index, inception score, and reduced L1 error, leading to successful patient-to-normal brain image registration.      
### 25.Latent Space Analysis of VAE and Intro-VAE applied to 3-dimensional MR Brain Volumes of Multiple Sclerosis, Leukoencephalopathy, and Healthy Patients  [ :arrow_down: ](https://arxiv.org/pdf/2101.06772.pdf)
>  Multiple Sclerosis (MS) and microvascular leukoencephalopathy are two distinct neurological conditions, the first caused by focal autoimmune inflammation in the central nervous system, the second caused by chronic white matter damage from atherosclerotic microvascular disease. Both conditions lead to signal anomalies on Fluid Attenuated Inversion Recovery (FLAIR) magnetic resonance (MR) images, which can be distinguished by an expert neuroradiologist, but which can look very similar to the untrained eye as well as in the early stage of both diseases. In this paper, we attempt to train a 3-dimensional deep neural network to learn the specific features of both diseases in an unsupervised manner. For this manner, in a first step we train a generative neural network to create artificial MR images of both conditions with approximate explicit density, using a mixed dataset of multiple sclerosis, leukoencephalopathy and healthy patients containing in total 5404 volumes of 3096 patients. In a second step, we distinguish features between the different diseases in the latent space of this network, and use them to classify new data.      
### 26.Frequency-weighted H2-optimal Model Order Reduction via Projection  [ :arrow_down: ](https://arxiv.org/pdf/2101.06745.pdf)
>  In projection-based model order reduction, a reduced-order approximation of the original full-order system is obtained by projecting it onto a reduced subspace that contains its dominant characteristics. The problem of frequency-weighted H2-optimal model order reduction is to construct a local optimum of the squared H2-norm of the weighted error transfer function. In this paper, a projection-based model order reduction algorithm is proposed that constructs reduced-order models that nearly satisfy the first-order optimality conditions for the frequency-weighted H2-optimal model order reduction problem. It is shown that as the order of the reduced model is increased, the deviation in the satisfaction of the optimality conditions decays. Numerical methods to improve the computational efficiency of the proposed algorithm are also discussed. Three numerical examples are presented to demonstrate the efficacy of the proposed algorithm.      
### 27.On the detection and identification of edge disconnections in a multi-agent consensus network  [ :arrow_down: ](https://arxiv.org/pdf/2101.06728.pdf)
>  In this paper we investigate the problem of the sudden disconnection of an edge in a discrete-time multi-agent consensus network. If the graph remains strongly connected, the multi-agent system still achieves consensus, but in general, unless the information exchange between each pair of agents is symmetric, the agents' states converge to a drifted value of the original consensus value. Consequently the edge disconnection can go unnoticed. In this paper the problems of detecting an edge disconnection and of identifying in a finite number of steps the exact edge that got disconnected are investigated. Necessary and sufficient conditions for both problems to be solvable are presented, both in case all the agents' states are available and in case only a subset of the agents' states is measured. Finally, an example of a network of 7 agents is provided, to illustrate some of the theoretical results derived in the paper.      
### 28.Observer Design for Systems of Conservation Laws with Lipschitz Nonlinear Boundary Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2101.06719.pdf)
>  The problem of state estimation for a system of coupled hyperbolic PDEs and ODEs with Lipschitz nonlinearities with boundary measurements is considered. An infinite dimensional observer with a linear boundary injection term is used to solve the state estimation problem. The interconnection of the observer and the system is written in estimation error coordinates and analyzed as an abstract dynamical system. The observer is designed to achieve global exponential stability of estimation error with respect to a suitable norm. Sufficient conditions in the form of matrix inequalities are proposed to design the observer. Numerical simulations support and corroborate the theoretical results.      
### 29.Fourier, Gabor, Morlet or Wigner: Comparison of Time-Frequency Transforms  [ :arrow_down: ](https://arxiv.org/pdf/2101.06707.pdf)
>  In digital signal processing time-frequency transforms are used to analyze time-varying signals with respect to their spectral contents over time. Apart from the commonly used short-time Fourier transform, other methods exist in literature, such as the Wavelet, Stockwell or Wigner-Ville transform. Consequently, engineers working on digital signal processing tasks are often faced with the question which transform is appropriate for a specific application. To address this question, this paper first briefly introduces the different transforms. Then it compares them with respect to the achievable resolution in time and frequency and possible artifacts. Finally, the paper contains a gallery of time-frequency representations of numerous signals from different fields of applications to allow for visual comparison.      
### 30.A General 3D Non-Stationary Wireless Channel Model for 5G and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2101.06610.pdf)
>  In this paper, a novel three-dimensional (3D) non-stationary geometry-based stochastic model (GBSM) for the fifth generation (5G) and beyond 5G (B5G) systems is proposed. The proposed B5G channel model (B5GCM) is designed to capture various channel characteristics in (B)5G systems such as space-time-frequency (STF) non-stationarity, spherical wavefront (SWF), high delay resolution, time-variant velocities and directions of motion of the transmitter, receiver, and scatterers, spatial consistency, etc. By combining different channel properties into a general channel model framework, the proposed B5GCM is able to be applied to multiple frequency bands and multiple scenarios, including massive multiple-input multiple-output (MIMO), vehicle-to-vehicle (V2V), high-speed train (HST), and millimeter wave-terahertz (mmWave-THz) communication scenarios. Key statistics of the proposed B5GCM are obtained and compared with those of standard 5G channel models and corresponding measurement data, showing the generalization and usefulness of the proposed model.      
### 31.A 3D Non-stationary MmWave Channel Model for Vacuum Tube Ultra-High-Speed Train Channels  [ :arrow_down: ](https://arxiv.org/pdf/2101.06609.pdf)
>  As a potential development direction of future transportation, the vacuum tube ultra-high-speed train (UHST) wireless communication systems have newly different channel characteristics from existing high-speed train (HST) scenarios. In this paper, a three-dimensional non-stationary millimeter wave (mmWave) geometry-based stochastic model (GBSM) is proposed to investigate the channel characteristics of UHST channels in vacuum tube scenarios, taking into account the waveguide effect and the impact of tube wall roughness on channel. Then, based on the proposed model, some important time-variant channel statistical properties are studied and compared with those in existing HST and tunnel channels. The results obtained show that the multipath effect in vacuum tube scenarios will be more obvious than tunnel scenarios but less than existing HST scenarios, which will provide some insights for future research on vacuum tube UHST wireless communications.      
### 32.A General 3D Non-Stationary Massive MIMO GBSM for 6G Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06607.pdf)
>  A general three-dimensional (3D) non-stationary massive multiple-input multiple-output (MIMO) geometry-based stochastic model (GBSM) for the sixth generation (6G) communication systems is proposed in the paper. The novelty of the model is that the model is designed to cover a variety of channel characteristics, including space-time-frequency (STF) non-stationarity, spherical wavefront, spatial consistency, channel hardening, etc. Firstly, the introduction of the twin-cluster channel model is given in detail. Secondly, the key statistical properties such as space-time-frequency correlation function (STFCF), space cross-correlation function (CCF), temporal autocorrelation function (ACF), frequency correlation function (FCF), and performance indicators, e.g., singular value spread (SVS), and channel capacity are derived. Finally, the simulation results are given and consistent with some measurements in relevant literatures, which validate that the proposed channel model has a certain value as a reference to model massive MIMO channel characteristics.      
### 33.A Novel Approach for Earthquake Early Warning System Design using Deep Learning Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2101.06517.pdf)
>  Earthquake signals are non-stationary in nature and thus in real-time, it is difficult to identify and classify events based on classical approaches like peak ground displacement, peak ground velocity. Even the popular algorithm of STA/LTA requires extensive research to determine basic thresholding parameters so as to trigger an alarm. Also, many times due to human error or other unavoidable natural factors such as thunder strikes or landslides, the algorithm may end up raising a false alarm. This work focuses on detecting earthquakes by converting seismograph recorded data into corresponding audio signals for better perception and then uses popular Speech Recognition techniques of Filter bank coefficients and Mel Frequency Cepstral Coefficients (MFCC) to extract the features. These features were then used to train a Convolutional Neural Network(CNN) and a Long Short Term Memory(LSTM) network. The proposed method can overcome the above-mentioned problems and help in detecting earthquakes automatically from the waveforms without much human intervention. For the 1000Hz audio data set the CNN model showed a testing accuracy of 91.1% for 0.2-second sample window length while the LSTM model showed 93.99% for the same. A total of 610 sounds consisting of 310 earthquake sounds and 300 non-earthquake sounds were used to train the models. While testing, the total time required for generating the alarm was approximately 2 seconds which included individual times for data collection, processing, and prediction taking into consideration the processing and prediction delays. This shows the effectiveness of the proposed method for Earthquake Early Warning (EEW) applications. Since the input of the method is only the waveform, it is suitable for real-time processing, thus the models can also be used as an onsite EEW system requiring a minimum amount of preparation time and workload.      
### 34.Frequency Dynamics Constrained Sequential Service Restoration in Inverter-Dominated Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2101.06512.pdf)
>  This paper proposes a service restoration model for unbalanced distribution systems and inverter-dominated microgrids (MGs), in which frequency dynamics constraints are developed to optimize the load pick-up during restoration process and guarantee frequency stability. After extreme events, the damaged distribution systems can be sectionalized into several isolated MGs to restore critical loads and tripped distributed generations (DGs) by black-start DGs. However, the high penetration of inverter-based DGs reduce the system inertia, which results in low-inertia issues and large frequency fluctuation during the restoration. To address this challenge, we formulate a sequential service restoration model as a mixed integer linear programming (MILP) problem. The proposed MILP model explicitly incorporates the frequency response into constraints, by interfacing with transient simulations of inverter-dominated MGs. Numerical results on a modified IEEE 123-bus system have validated that the frequency dynamic performance of the proposed service restoration model are indeed improved.      
### 35.Learning Robust Hybrid Control Barrier Functions for Uncertain Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06492.pdf)
>  The need for robust control laws is especially important in safety-critical applications. We propose robust hybrid control barrier functions as a means to synthesize control laws that ensure robust safety. Based on this notion, we formulate an optimization problem for learning robust hybrid control barrier functions from data. We identify sufficient conditions on the data such that feasibility of the optimization problem ensures correctness of the learned robust hybrid control barrier functions. Our techniques allow us to safely expand the region of attraction of a compass gait walker that is subject to model uncertainty.      
### 36.Optimized and autonomous machine learning framework for characterizing pores, particles, grains and grain boundaries in microstructural images  [ :arrow_down: ](https://arxiv.org/pdf/2101.06474.pdf)
>  Additively manufactured metals exhibit heterogeneous microstructure which dictates their material and failure properties. Experimental microstructural characterization techniques generate a large amount of data that requires expensive computationally resources. In this work, an optimized machine learning (ML) framework is proposed to autonomously and efficiently characterize pores, particles, grains and grain boundaries (GBs) from a given microstructure image. First, using a classifier Convolutional Neural Network (CNN), defects such as pores, powder particles, or GBs were recognized from a given microstructure. Depending on the type of defect, two different processes were used. For powder particles or pores, binary segmentations were generated using an optimized Convolutional Encoder-Decoder Network (CEDN). The binary segmentations were used to used obtain particle and pore size and bounding boxes using an object detection ML network (YOLOv5). For GBs, another optimized CEDN was developed to generate RGB segmentation images, which were used to obtain grain size distribution using two regression CNNS. To optimize the RGB CEDN, the Deep Emulator Network SEarch (DENSE) method which employs the Covariance Matrix Adaptation - Evolution Strategy (CMA-ES) was implemented. The optimized RGB segmentation network showed a substantial reduction in training time and GPU usage compared to the unoptimized network, while maintaining high accuracy. Lastly, the proposed framework showed a significant improvement in analysis time when compared to conventional methods.      
### 37.Adversarial cycle-consistent synthesis of cerebral microbleeds for data augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06468.pdf)
>  We propose a novel framework for controllable pathological image synthesis for data augmentation. Inspired by CycleGAN, we perform cycle-consistent image-to-image translation between two domains: healthy and pathological. Guided by a semantic mask, an adversarially trained generator synthesizes pathology on a healthy image in the specified location. We demonstrate our approach on an institutional dataset of cerebral microbleeds in traumatic brain injury patients. We utilize synthetic images generated with our method for data augmentation in cerebral microbleeds detection. Enriching the training dataset with synthetic images exhibits the potential to increase detection performance for cerebral microbleeds in traumatic brain injury patients.      
### 38.MPC-CSAS: Multi-Party Computation for Real-time Privacy-preserving Speed Advisory Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06451.pdf)
>  As a part of Advanced Driver Assistance Systems (ADASs), Consensus-based Speed Advisory Systems (CSAS) have been proposed to recommend a common speed to a group of vehicles for specific application purposes, such as emission control and energy management. With Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I) technologies and advanced control theories in place, state-of-the-art CSAS can be designed to get an optimal speed in a privacy-preserving and decentralized manner. However, the current method only works for specific cost functions of vehicles, and its execution usually involves many algorithm iterations leading long convergence time. Therefore, the state-of-the-art design method is not applicable to a CSAS design which requires real-time decision making. In this paper, we address the problem by introducing MPC-CSAS, a Multi-Party Computation (MPC) based design approach for privacy-preserving CSAS. Our proposed method is simple to implement and applicable to all types of cost functions of vehicles. Moreover, our simulation results show that the proposed MPC-CSAS can achieve very promising system performance in just one algorithm iteration without using extra infrastructure for a typical CSAS.      
### 39.Scale factor point spread function matching: Beyond aliasing in image resampling  [ :arrow_down: ](https://arxiv.org/pdf/2101.06440.pdf)
>  Imaging devices exploit the Nyquist-Shannon sampling theorem to avoid both aliasing and redundant oversampling by design. Conversely, in medical image resampling, images are considered as continuous functions, are warped by a spatial transformation, and are then sampled on a regular grid. In most cases, the spatial warping changes the frequency characteristics of the continuous function and no special care is taken to ensure that the resampling grid respects the conditions of the sampling theorem. This paper shows that this oversight introduces artefacts, including aliasing, that can lead to important bias in clinical applications. One notable exception to this common practice is when multi-resolution pyramids are constructed, with low-pass "anti-aliasing" filters being applied prior to downsampling. In this work, we illustrate why similar caution is needed when resampling images under general spatial transformations and propose a novel method that is more respectful of the sampling theorem, minimising aliasing and loss of information. We introduce the notion of scale factor point spread function (sfPSF) and employ Gaussian kernels to achieve a computationally tractable resampling scheme that can cope with arbitrary non-linear spatial transformations and grid sizes. Experiments demonstrate significant (p&lt;1e-4) technical and clinical implications of the proposed method.      
### 40.Morphological Change Forecasting for Prostate Glands using Feature-based Registration and Kernel Density Extrapolation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06425.pdf)
>  Organ morphology is a key indicator for prostate disease diagnosis and prognosis. For instance, In longitudinal study of prostate cancer patients under active surveillance, the volume, boundary smoothness and their changes are closely monitored on time-series MR image data. In this paper, we describe a new framework for forecasting prostate morphological changes, as the ability to detect such changes earlier than what is currently possible may enable timely treatment or avoiding unnecessary confirmatory biopsies. In this work, an efficient feature-based MR image registration is first developed to align delineated prostate gland capsules to quantify the morphological changes using the inferred dense displacement fields (DDFs). We then propose to use kernel density estimation (KDE) of the probability density of the DDF-represented \textit{future morphology changes}, between current and future time points, before the future data become available. The KDE utilises a novel distance function that takes into account morphology, stage-of-progression and duration-of-change, which are considered factors in such subject-specific forecasting. We validate the proposed approach on image masks unseen to registration network training, without using any data acquired at the future target time points. The experiment results are presented on a longitudinal data set with 331 images from 73 patients, yielding an average Dice score of 0.865 on a holdout set, between the ground-truth and the image masks warped by the KDE-predicted-DDFs.      
### 41.Smart City Enabled by 5G/6G Networks: An Intelligent Hybrid Random Access Scheme  [ :arrow_down: ](https://arxiv.org/pdf/2101.06421.pdf)
>  The Internet of Things (IoT) is the enabler for smart city to achieve the envision of the "Internet of Everything" by intelligently connecting devices without human interventions. The explosive growth of IoT devices makes the amount of business data generated by machine-type communications (MTC) account for a great proportion in all communication services. The fifth-generation (5G) specification for cellular networks defines two types of application scenarios for MTC: One is massive machine type communications (mMTC) requiring massive connections, while the other is ultra-reliable low latency communications (URLLC) requiring high reliability and low latency communications. 6G, as the next generation beyond 5G, will have even stronger scales of mMTC and URLLC. mMTC and URLLC will co-exist in MTC networks for 5G 6G-enabled smart city. To enable massive and reliable LLC access to such heterogeneous MTC networks where mMTC and URLLC co-exist, in this article, we introduce the network architecture of heterogeneous MTC networks, and propose an intelligent hybrid random access scheme for 5G/6G-enabled smart city. Numerical results show that, compared to the benchmark schemes, the proposed scheme significantly improves the successful access probability, and satisfies the diverse quality of services requirements of URLLC and mMTC devices.      
### 42.Mispronunciation Detection in Non-native (L2) English with Uncertainty Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2101.06396.pdf)
>  A common approach to the automatic detection of mispronunciation works by recognizing the phonemes produced by a student and comparing it to the expected pronunciation of a native speaker. This approach makes two simplifying assumptions: a) phonemes can be recognized from speech with high accuracy, b) there is a single correct way for a sentence to be pronounced. These assumptions do not always hold which can result in a significant amount of false mispronunciation alarms. We propose a novel approach to overcome this problem based on two principles: a) taking into account uncertainty in the automatic phoneme recognition step, b) accounting for the fact that there may be multiple valid pronunciations. We evaluate the model on non-native (L2) English speech of German, Italian and Polish speakers, where it is shown to increase the precision of detecting mispronunciations by up to 18\% (relative) compared to the common approach.      
### 43.Rapid Method for Generation Prioritization during System Restoration with Renewable Resources  [ :arrow_down: ](https://arxiv.org/pdf/2101.06355.pdf)
>  Quick and reliable power system restoration is critically important after natural disasters or other sudden threats, such as cyber-attacks. Leveraging renewable resources in system restoration shortens recovery times, resulting in prevented life-loss and avoided economic-loss, and improves the resilience of the entire grid. However, it is not a common practice today; the inherent variability of these resources represents a challenge for a streamlined restoration process. This paper presents a prioritized method - starting with renewable generator units then lowering priority to conventional units - to plan the operational schedule of a power system during the restoration process. The goal is to achieve a well balanced system in the presence of significant renewable penetration. Validation and benchmarking experiments were performed on a customized version of the RTS-GMLC test system using six months out of year-long data, tested through hourly simulations. After evaluating the performance and computational costs, this method proved faster than common approaches: a MILP Unit Commitment algorithm, widely used today, and an "enable-and-try" algorithm. In summary, herein a more convenient method is provided to be utilized during time-sensitive restoration, as an online operation-planning aid.      
### 44.A Hitchhiker's Guide to Structural Similarity  [ :arrow_down: ](https://arxiv.org/pdf/2101.06354.pdf)
>  The Structural Similarity (SSIM) Index is a very widely used image/video quality model that continues to play an important role in the perceptual evaluation of compression algorithms, encoding recipes and numerous other image/video processing algorithms. Several public implementations of the SSIM and Multiscale-SSIM (MS-SSIM) algorithms have been developed, which differ in efficiency and performance. This "bendable ruler" makes the process of quality assessment of encoding algorithms unreliable. To address this situation, we studied and compared the functions and performances of popular and widely used implementations of SSIM, and we also considered a variety of design choices. Based on our studies and experiments, we have arrived at a collection of recommendations on how to use SSIM most effectively, including ways to reduce its computational burden.      
### 45.Fish Detection Using Morphological Approach Based-on K-Means Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06352.pdf)
>  Image segmentation is a concept that is often used for object detection. This detection has difficulty detecting objects with backgrounds that have many colors and even have a color similar to the object being detected. This study aims to detect fish using segmentation, namely segmenting fish images using k-means clustering. The segmentation process is processed by improving the image first. The initial process is preprocessing to improve the image. Preprocessing is done twice, before segmentation using k-means and after. Preprocessing stage 1 using resize and reshape. Whereas after k-means is the contrast-limited adaptive histogram equalization. Preprocessing results are segmented using k-means clustering. The K-means concept classifies images using segments between the object and the background (using k = 8). The final step is the morphological process with open and close operations to obtain fish contours using black and white images based on grayscale images from color images. Based on the experimental results, the process can run well, with the ssim value close to 1, which means that image information does not change. Processed objects provide a clear picture of fish objects so that this k-means segmentation can help detect fish objects.      
### 46.Iris Recognition Performance in Children: A Longitudinal Study  [ :arrow_down: ](https://arxiv.org/pdf/2101.06346.pdf)
>  There is uncertainty around the effect of aging of children on biometric characteristics impacting applications relying on biometric recognition, particularly as the time between enrollment and query increases. Though there have been studies of such effects for iris recognition in adults, there have been few studies evaluating impact in children. This paper presents longitudinal analysis from 209 subjects aged 4 to 11 years at enrollment and six additional sessions over a period of 3 years. The influence of time, dilation and enrollment age on iris recognition have been analyzed and their statistical importance has been evaluated. A minor aging effect is noted which is statistically significant, but practically insignificant and is comparatively less important than other variability factors. Practical biometric applications of iris recognition in children are feasible for a time frame of at least 3 years between samples, for ages 4 to 11 years, even in presence of aging, though we note practical difficulties in enrolling young children with cameras not designed for the purpose. To the best of our knowledge, the database used in this study is the only dataset of longitudinal iris images from children for this age group and time period that is available for research.      
### 47.Advances In Video Compression System Using Deep Neural Network: A Review And Case Studies  [ :arrow_down: ](https://arxiv.org/pdf/2101.06341.pdf)
>  Significant advances in video compression system have been made in the past several decades to satisfy the nearly exponential growth of Internet-scale video traffic. From the application perspective, we have identified three major functional blocks including pre-processing, coding, and post-processing, that have been continuously investigated to maximize the end-user quality of experience (QoE) under a limited bit rate budget. Recently, artificial intelligence (AI) powered techniques have shown great potential to further increase the efficiency of the aforementioned functional blocks, both individually and jointly. In this article, we review extensively recent technical advances in video compression system, with an emphasis on deep neural network (DNN)-based approaches; and then present three comprehensive case studies. On pre-processing, we show a switchable texture-based video coding example that leverages DNN-based scene understanding to extract semantic areas for the improvement of subsequent video coder. On coding, we present an end-to-end neural video coding framework that takes advantage of the stacked DNNs to efficiently and compactly code input raw videos via fully data-driven learning. On post-processing, we demonstrate two neural adaptive filters to respectively facilitate the in-loop and post filtering for the enhancement of compressed frames. Finally, a companion website hosting the contents developed in this work can be accessed publicly at <a class="link-external link-https" href="https://purdueviper.github.io/dnn-coding/" rel="external noopener nofollow">this https URL</a>.      
### 48.Resource Allocation in NOMA-based Self-Organizing Networks using Stochastic Multi-Armed Bandits  [ :arrow_down: ](https://arxiv.org/pdf/2101.06340.pdf)
>  To achieve high data rates and better connectivity in future communication networks, the deployment of different types of access points (APs) is underway. In order to limit human intervention and reduce costs, the APs are expected to be equipped with self-organizing capabilities. Moreover, due to the spectrum crunch, frequency reuse among the deployed APs is inevitable, aggravating the problem of inter-cell interference (ICI). Therefore, ICI mitigation in self-organizing networks (SONs) is commonly identified as a key radio resource management mechanism to enhance performance in future communication networks. With the aim of reducing ICI in a SON, this paper proposes a novel solution for the uncoordinated channel and power allocation problems. Based on the multi-player multi-armed bandit (MAB) framework, the proposed technique does not require any communication or coordination between the APs. The case of varying channel rewards across APs is considered. In contrast to previous work on channel allocation using the MAB framework, APs are permitted to choose multiple channels for transmission. Moreover, non-orthogonal multiple access (NOMA) is used to allow multiple APs to access each channel simultaneously. This results in an MAB model with varying channel rewards, multiple plays and non-zero reward on collision. The proposed algorithm has an expected regret in the order of O(log^2 T ), which is validated by simulation results. Extensive numerical results also reveal that the proposed technique significantly outperforms the well-known upper confidence bound (UCB) algorithm, by achieving more than a twofold increase in the energy efficiency.      
### 49.Attentional Multi-layer Feature Fusion Convolution Network for Audio-visual Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2101.06268.pdf)
>  Audio-visual speech enhancement system is regarded to be one of promising solutions for isolating and enhancing speech of desired speaker. Conventional methods focus on predicting clean speech spectrum via a naive convolution neural network based encoder-decoder architecture, and these methods a) not adequate to use data fully and effectively, b) cannot process features selectively. The proposed model addresses these drawbacks, by a) applying a model that fuses audio and visual features layer by layer in encoding phase, and that feeds fused audio-visual features to each corresponding decoder layer, and more importantly, b) introducing soft threshold attention into the model to select the informative modality softly. This paper proposes attentional audio-visual multi-layer feature fusion model, in which soft threshold attention unit are applied on feature mapping at every layer of decoder. The proposed model demonstrates the superior performance of the network against the state-of-the-art models.      
### 50.dtControl 2.0: Explainable Strategy Representation via Decision Tree Learning Steered by Experts  [ :arrow_down: ](https://arxiv.org/pdf/2101.07202.pdf)
>  Recent advances have shown how decision trees are apt data structures for concisely representing strategies (or controllers) satisfying various objectives. Moreover, they also make the strategy more explainable. The recent tool dtControl had provided pipelines with tools supporting strategy synthesis for hybrid systems, such as SCOTS and Uppaal Stratego. We present dtControl 2.0, a new version with several fundamentally novel features. Most importantly, the user can now provide domain knowledge to be exploited in the decision tree learning process and can also interactively steer the process based on the dynamically provided information. To this end, we also provide a graphical user interface. It allows for inspection and re-computation of parts of the result, suggesting as well as receiving advice on predicates, and visual simulation of the decision-making process. Besides, we interface model checkers of probabilistic systems, namely Storm and PRISM and provide dedicated support for categorical enumeration-type state variables. Consequently, the controllers are more explainable and smaller.      
### 51.Partial Observability Approach for the Optimal Transparency Problem in Multi-agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.07178.pdf)
>  This paper considers a network of agents, where each agent is assumed to take actions optimally with respect to a predefined payoff function involving the latest actions of the agent's neighbors. Neighborhood relationships stem from payoff functions rather than actual communication channels between the agents. A principal is tasked to optimize the network's performance by controlling the information available to each agent with regard to other agents' latest actions. The information control by the principal is done via a partial observability approach, which comprises a static partitioning of agents into blocks and making the mean of agents' latest actions within each block publicly available. While the problem setup is general in terms of the payoff functions and the network's performance metric, this paper has a narrower focus to illuminate the problem and how it can be addressed in practice. In particular, the performance metric is assumed to be a function of the steady-state behavior of the agents. After conducting a comprehensive steady-state analysis of the network, an efficient algorithm finding optimal partitions with respect to various performance metrics is presented and validated via numerical examples.      
### 52.Deep Reinforcement Learning with Embedded LQR Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2101.07175.pdf)
>  Reinforcement learning is a model-free optimal control method that optimizes a control policy through direct interaction with the environment. For reaching tasks that end in regulation, popular discrete-action methods are not well suited due to chattering in the goal state. We compare three different ways to solve this problem through combining reinforcement learning with classical LQR control. In particular, we introduce a method that integrates LQR control into the action set, allowing generalization and avoiding fixing the computed control in the replay memory if it is based on learned dynamics. We also embed LQR control into a continuous-action method. In all cases, we show that adding LQR control can improve performance, although the effect is more profound if it can be used to augment a discrete action set.      
### 53.Energy Production in Martian Environment -- Powering a Mars Direct-based Habitat  [ :arrow_down: ](https://arxiv.org/pdf/2101.07165.pdf)
>  This thesis work aims to study the possibility of energy production on Martian soil and, in particular, to establish what might be an optimal configuration for an energy system. This goal has been contextualized in the will to feed a scientific base, based the concept of "Mars Direct" (Robert Zubrin, 1990). This habitat has been recreated in its thermal features, in order to perform an analysis of the heat loss over a Martian year (1,88 terrestrial years). As part of this analysis, two possible scenarios have been studied: clear sky with medium solar radiation ("sun season") and sand storm season ("storm season"). Subsequently, a basic life support system have been simulated thanks to Aspen PLUS. Using the results of the thermal analysis, it has been possible to obtain a thermal and electrical demand profile for the Hab. After identifying every possible energy source (solar, wind, nuclear, fuel cells, rtg), a calculation on Excel has been set with the purpose of finding one of the configurations with the lowest possible mass and pave the way for a further, more rigorous, optimization. It is indeed clear that shipping 1 kilogram to Mars has a cost of hundreds of thousand of dollars.      
### 54.Comparison of round- and square-core fibers for sensing, imaging and spectroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2101.07153.pdf)
>  Multimode fibers (MMFs) show great promise as miniature probes for sensing, imaging and spectroscopy applications. Different parameters of the fibers, such as numerical aperture, refractive index profile and length, have been already optimized for better performance. Here we investigate the role of the core shape, in particular for wavefront shaping applications where a focus is formed at the output of the MMF. We demonstrate that in contrast to a conventional round-core MMF, a square-core design doesn't suffer from focus aberrations. Moreover, we find that how the interference pattern behind a square-core fiber decorrelates with the input frequency is largely independent of the input light coupling. Finally, we demonstrate that a square core shape provides an on-average uniform distribution of the output intensity, free from the input-output correlations seen in round fibers, showing great promise for imaging and spectroscopy applications.      
### 55.Multidimensional Information Assisted Deep Learning Realizing Flexible Recognition of Vortex Beam Modes  [ :arrow_down: ](https://arxiv.org/pdf/2101.06987.pdf)
>  Because of the unlimited range of state space, orbital angular momentum (OAM) as a new degree of freedom of light has attracted great attention in optical communication field. Recently there are a number of researches applying deep learning on recognition of OAM modes through atmospheric turbulence. However, there are several limitations in previous deep learning recognition methods. They all require a constant distance between the laser and receiver, which makes them clumsy and not practical. As far as we know, previous deep learning methods cannot sort vortex beams with positive and negative topological charges, which can reduce information capacity. A Multidimensional Information Assisted Deep Learning Flexible Recognition (MIADLFR) method is proposed in this letter. In MIADLR we utilize not only the intensity profile, also spectrum information to recognize OAM modes unlimited by distance and sign of topological charge (TC). As far as we know, we first make use of multidimensional information to recognize OAM modes and we first utilize spectrum information to recognize OAM modes. Recognition of OAM modes unlimited by distance and sign of TC achieved by MIADLFR method can make optical communication and detection by OAM light much more attractive.      
### 56.Motor-Imagery-Based Brain Computer Interface using Signal Derivation and Aggregation Functions  [ :arrow_down: ](https://arxiv.org/pdf/2101.06968.pdf)
>  Brain Computer Interface technologies are popular methods of communication between the human brain and external devices. One of the most popular approaches to BCI is Motor Imagery. In BCI applications, the ElectroEncephaloGraphy is a very popular measurement for brain dynamics because of its non-invasive nature. Although there is a high interest in the BCI topic, the performance of existing systems is still far from ideal, due to the difficulty of performing pattern recognition tasks in EEG signals. BCI systems are composed of a wide range of components that perform signal pre-processing, feature extraction and decision making. In this paper, we define a BCI Framework, named Enhanced Fusion Framework, where we propose three different ideas to improve the existing MI-based BCI frameworks. Firstly, we include aan additional pre-processing step of the signal: a differentiation of the EEG signal that makes it time-invariant. Secondly, we add an additional frequency band as feature for the system and we show its effect on the performance of the system. Finally, we make a profound study of how to make the final decision in the system. We propose the usage of both up to six types of different classifiers and a wide range of aggregation functions (including classical aggregations, Choquet and Sugeno integrals and their extensions and overlap functions) to fuse the information given by the considered classifiers. We have tested this new system on a dataset of 20 volunteers performing motor imagery-based brain-computer interface experiments. On this dataset, the new system achieved a 88.80% of accuracy. We also propose an optimized version of our system that is able to obtain up to 90,76%. Furthermore, we find that the pair Choquet/Sugeno integrals and overlap functions are the ones providing the best results.      
### 57.Improving Physical Layer Security for Reconfigurable Intelligent Surface aided NOMA 6G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.06948.pdf)
>  The intrinsic integration of the nonorthogonal multiple access (NOMA) and reconfigurable intelligent surface (RIS) techniques is envisioned to be a promising approach to significantly improve both the spectrum efficiency and energy efficiency for future wireless communication networks. In this paper, the physical layer security (PLS) for a RIS-aided NOMA 6G networks is investigated, in which a RIS is deployed to assist the two "dead zone" NOMA users and both internal and external eavesdropping are considered. For the scenario with only internal eavesdropping, we consider the worst case that the near-end user is untrusted and may try to intercept the information of far-end user. A joint beamforming and power allocation sub-optimal scheme is proposed to improve the system PLS. Then we extend our work to a scenario with both internal and external eavesdropping. Two sub-scenarios are considered in this scenario: one is the sub-scenario without channel state information (CSI) of eavesdroppers, and another is the sub-scenario where the eavesdroppers' CSI are available. For the both sub-scenarios, a noise beamforming scheme is introduced to be against the external eavesdroppers. An optimal power allocation scheme is proposed to further improve the system physical security for the second sub-scenario. Simulation results show the superior performance of the proposed schemes. Moreover, it has also been shown that increasing the number of reflecting elements can bring more gain in secrecy performance than that of the transmit antennas.      
### 58.Learning DNN networks using un-rectifying ReLU with compressed sensing application  [ :arrow_down: ](https://arxiv.org/pdf/2101.06940.pdf)
>  The un-rectifying technique expresses a non-linear point-wise activation function as a data-dependent variable, which means that the activation variable along with its input and output can all be employed in optimization. The ReLU network in this study was un-rectified means that the activation functions could be replaced with data-dependent activation variables in the form of equations and constraints. The discrete nature of activation variables associated with un-rectifying ReLUs allows the reformulation of deep learning problems as problems of combinatorial optimization. However, we demonstrate that the optimal solution to a combinatorial optimization problem can be preserved by relaxing the discrete domains of activation variables to closed intervals. This makes it easier to learn a network using methods developed for real-domain constrained optimization. We also demonstrate that by introducing data-dependent slack variables as constraints, it is possible to optimize a network based on the augmented Lagrangian approach. This means that our method could theoretically achieve global convergence and all limit points are critical points of the learning problem. In experiments, our novel approach to solving the compressed sensing recovery problem achieved state-of-the-art performance when applied to the MNIST database and natural images.      
### 59.TLU-Net: A Deep Learning Approach for Automatic Steel Surface Defect Detection  [ :arrow_down: ](https://arxiv.org/pdf/2101.06915.pdf)
>  Visual steel surface defect detection is an essential step in steel sheet manufacturing. Several machine learning-based automated visual inspection (AVI) methods have been studied in recent years. However, most steel manufacturing industries still use manual visual inspection due to training time and inaccuracies involved with AVI methods. Automatic steel defect detection methods could be useful in less expensive and faster quality control and feedback. But preparing the annotated training data for segmentation and classification could be a costly process. In this work, we propose to use the Transfer Learning-based U-Net (TLU-Net) framework for steel surface defect detection. We use a U-Net architecture as the base and explore two kinds of encoders: ResNet and DenseNet. We compare these nets' performance using random initialization and the pre-trained networks trained using the ImageNet data set. The experiments are performed using Severstal data. The results demonstrate that the transfer learning performs 5% (absolute) better than that of the random initialization in defect classification. We found that the transfer learning performs 26% (relative) better than that of the random initialization in defect segmentation. We also found the gain of transfer learning increases as the training data decreases, and the convergence rate with transfer learning is better than that of the random initialization.      
### 60.Soft Constrained Autonomous Vehicle Navigation using Gaussian Processes and Instance Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06901.pdf)
>  This paper presents a generic feature-based navigation framework for autonomous vehicles using a soft constrained Particle Filter. Selected map features, such as road and landmark locations, and vehicle states are used for designing soft constraints. After obtaining features of mapped landmarks in instance-based segmented images acquired from a monocular camera, vehicle-to-landmark distances are predicted using Gaussian Process Regression (GPR) models in a mixture of experts approach. Both mean and variance outputs of GPR models are used for implementing adaptive constraints. Experimental results confirm that the use of image segmentation features improves the vehicle-to-landmark distance prediction notably, and that the proposed soft constrained approach reliably localizes the vehicle even with reduced number of landmarks and noisy observations.      
### 61.Multi-Source Data Fusion for Cyberattack Detection in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06897.pdf)
>  Cyberattacks can cause a severe impact on power systems unless detected early. However, accurate and timely detection in critical infrastructure systems presents challenges, e.g., due to zero-day vulnerability exploitations and the cyber-physical nature of the system coupled with the need for high reliability and resilience of the physical system. Conventional rule-based and anomaly-based intrusion detection system (IDS) tools are insufficient for detecting zero-day cyber intrusions in the industrial control system (ICS) networks. Hence, in this work, we show that fusing information from multiple data sources can help identify cyber-induced incidents and reduce false positives. Specifically, we present how to recognize and address the barriers that can prevent the accurate use of multiple data sources for fusion-based detection. We perform multi-source data fusion for training IDS in a cyber-physical power system testbed where we collect cyber and physical side data from multiple sensors emulating real-world data sources that would be found in a utility and synthesizes these into features for algorithms to detect intrusions. Results are presented using the proposed data fusion application to infer False Data and Command injection-based Man-in- The-Middle (MiTM) attacks. Post collection, the data fusion application uses time-synchronized merge and extracts features followed by pre-processing such as imputation and encoding before training supervised, semi-supervised, and unsupervised learning models to evaluate the performance of the IDS. A major finding is the improvement of detection accuracy by fusion of features from cyber, security, and physical domains. Additionally, we observed the co-training technique performs at par with supervised learning methods when fed with our features.      
### 62.Deep Learning for Moving Blockage Predictionusing Real Millimeter Wave Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2101.06886.pdf)
>  Millimeter wave (mmWave) communication is being seriously considered for the next generation communication systems because of its ability to support high bandwidth and high data rates. Unfortunately, these systems perform badly in the presence of blockage. A sudden blockage in the line of sight(LOS) link leads to communication disconnection, which causes a reliability problem. Also, searching alternative base stations(BS) for re-connection results in latency overhead. In this paper, we tackle these problems by predicting the time of blockage occurrence using a machine learning (ML) technique. In our approach, BS learns how to predict that a certain link will experience blockage in the near future using the received signal power. Simulation results on a real dataset show that blockage occurrence can be predicted with 85% accuracy and the exact time instance of blockage occurrence can be obtained with low error. Thus the proposed method reduces the communication disconnections in mmWave communication, thereby increasing reliability and reducing latency of such systems.      
### 63.Hierarchical disentangled representation learning for singing voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2101.06842.pdf)
>  Conventional singing voice conversion (SVC) methods often suffer from operating in high-resolution audio owing to a high dimensionality of data. In this paper, we propose a hierarchical representation learning that enables the learning of disentangled representations with multiple resolutions independently. With the learned disentangled representations, the proposed method progressively performs SVC from low to high resolutions. Experimental results show that the proposed method outperforms baselines that operate with a single resolution in terms of mean opinion score (MOS), similarity score, and pitch accuracy.      
### 64.HyperNTF: A Hypergraph Regularized Nonnegative Tensor Factorization for Dimensionality Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2101.06827.pdf)
>  Most methods for dimensionality reduction are based on either tensor representation or local geometry learning. However, the tensor-based methods severely rely on the assumption of global and multilinear structures in high-dimensional data; and the manifold learning methods suffer from the out-of-sample problem. In this paper, bridging the tensor decomposition and manifold learning, we propose a novel method, called Hypergraph Regularized Nonnegative Tensor Factorization (HyperNTF). HyperNTF can preserve nonnegativity in tensor factorization, and uncover the higher-order relationship among the nearest neighborhoods. Clustering analysis with HyperNTF has low computation and storage costs. The experiments on four synthetic data show a desirable property of hypergraph in uncovering the high-order correlation to unfold the curved manifolds. Moreover, the numerical experiments on six real datasets suggest that HyperNTF robustly outperforms state-of-the-art algorithms in clustering analysis.      
### 65.A Safe Hierarchical Planning Framework for Complex Driving Scenarios based on Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.06778.pdf)
>  Autonomous vehicles need to handle various traffic conditions and make safe and efficient decisions and maneuvers. However, on the one hand, a single optimization/sampling-based motion planner cannot efficiently generate safe trajectories in real time, particularly when there are many interactive vehicles near by. On the other hand, end-to-end learning methods cannot assure the safety of the outcomes. To address this challenge, we propose a hierarchical behavior planning framework with a set of low-level safe controllers and a high-level reinforcement learning algorithm (H-CtRL) as a coordinator for the low-level controllers. Safety is guaranteed by the low-level optimization/sampling-based controllers, while the high-level reinforcement learning algorithm makes H-CtRL an adaptive and efficient behavior planner. To train and test our proposed algorithm, we built a simulator that can reproduce traffic scenes using real-world datasets. The proposed H-CtRL is proved to be effective in various realistic simulation scenarios, with satisfying performance in terms of both safety and efficiency.      
### 66.Spatial Network Decomposition for Fast and Scalable AC-OPF Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.06768.pdf)
>  This paper proposes a novel machine-learning approach for predicting AC-OPF solutions that features a fast and scalable training. It is motivated by the two critical considerations: (1) the fact that topology optimization and the stochasticity induced by renewable energy sources may lead to fundamentally different AC-OPF instances; and (2) the significant training time needed by existing machine-learning approaches for predicting AC-OPF. The proposed approach is a 2-stage methodology that exploits a spatial decomposition of the power network that is viewed as a set of regions. The first stage learns to predict the flows and voltages on the buses and lines coupling the regions, and the second stage trains, in parallel, the machine-learning models for each region. Experimental results on the French transmission system (up to 6,700 buses and 9,000 lines) demonstrate the potential of the approach. Within a short training time, the approach predicts AC-OPF solutions with very high fidelity and minor constraint violations, producing significant improvements over the state-of-the-art. The results also show that the predictions can seed a load flow optimization to return a feasible solution within 0.03% of the AC-OPF objective, while reducing running times significantly.      
### 67.Fully automated 3D segmentation of dopamine transporter SPECT images using an estimation-based approach  [ :arrow_down: ](https://arxiv.org/pdf/2101.06729.pdf)
>  Quantitative measures of uptake in caudate, putamen, and globus pallidus in dopamine transporter (DaT) brain SPECT have potential as biomarkers for the severity of Parkinson disease. Reliable quantification of uptake requires accurate segmentation of these regions. However, segmentation is challenging in DaT SPECT due to partial-volume effects, system noise, physiological variability, and the small size of these regions. To address these challenges, we propose an estimation-based approach to segmentation. This approach estimates the posterior mean of the fractional volume occupied by caudate, putamen, and globus pallidus within each voxel of a 3D SPECT image. The estimate is obtained by minimizing a cost function based on the binary cross-entropy loss between the true and estimated fractional volumes over a population of SPECT images, where the distribution of the true fractional volumes is obtained from magnetic resonance images from clinical populations. The proposed method accounts for both the sources of partial-volume effects in SPECT, namely the limited system resolution and tissue-fraction effects. The method was implemented using an encoder-decoder network and evaluated using realistic clinically guided SPECT simulation studies, where the ground-truth fractional volumes were known. The method significantly outperformed all other considered segmentation methods and yielded accurate segmentation with dice similarity coefficients of ~ 0.80 for all regions. The method was relatively insensitive to changes in voxel size. Further, the method was relatively robust up to +/- 10 degrees of patient head tilt along transaxial, sagittal, and coronal planes. Overall, the results demonstrate the efficacy of the proposed method to yield accurate fully automated segmentation of caudate, putamen, and globus pallidus in 3D DaT-SPECT images.      
### 68.On the Design of Structured Stabilizers for LTI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.06718.pdf)
>  Designing a static state-feedback controller subject to structural constraint achieving asymptotic stability is a relevant problem with many applications, including network decentralized control, coordinated control, and sparse feedback design. Leveraging on the Projection Lemma, this work presents a new solution to a class of state-feedback control problems, in which the controller is constrained to belong to a given linear space. We show through extensive discussion and numerical examples that our approach leads to several advantages with respect to existing methods: first, it is computationally efficient; second, it is less conservative than previous methods, since it relaxes the requirement of restricting the Lyapunov matrix to a block-diagonal form.      
### 69.Fusing Wav2vec2.0 and BERT into End-to-end Model for Low-resource Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.06699.pdf)
>  Self-supervised acoustic pre-training has achieved impressive results on low-resource speech recognition tasks. It indicates that the pretrain-and-finetune paradigm is a promising direction. In this work, we propose an end-to-end model for the low-resource speech recognition, which fuses a pre-trained audio encoder (wav2vec2.0) and a pre-trained text decoder (BERT). The two modules are connected by a linear attention mechanism without parameters. A fully connected layer is introduced for hidden mapping between speech and language modalities. Besides, we design an effective fine-tuning strategy to preserve and utilize the text context modeling ability of the pre-trained decoder. Armed with this strategy, our model exhibits distinct faster convergence and better performance. Our model achieves approaching recognition performance in CALLHOME corpus (15h) as the SOTA pipeline modeling.      
### 70.Trilevel Neural Architecture Search for Efficient Single Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2101.06658.pdf)
>  This paper proposes a trilevel neural architecture search (NAS) method for efficient single image super-resolution (SR). For that, we first define the discrete search space at three-level, i.e., at network-level, cell-level, and kernel-level (convolution-kernel). For modeling the discrete search space, we apply a new continuous relaxation on the discrete search spaces to build a hierarchical mixture of network-path, cell-operations, and kernel-width. Later an efficient search algorithm is proposed to perform optimization in a hierarchical supernet manner that provides a globally optimized and compressed network via joint convolution kernel width pruning, cell structure search, and network path optimization. Unlike current NAS methods, we exploit a sorted sparsestmax activation to let the three-level neural structures contribute sparsely. Consequently, our NAS optimization progressively converges to those neural structures with dominant contributions to the supernet. Additionally, our proposed optimization construction enables a simultaneous search and training in a single phase, which dramatically reduces search and train time compared to the traditional NAS algorithms. Experiments on the standard benchmark datasets demonstrate that our NAS algorithm provides SR models that are significantly lighter in terms of the number of parameters and FLOPS with PSNR value comparable to the current state-of-the-art.      
### 71.Aggregated Network for Massive MIMO CSI Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2101.06618.pdf)
>  In frequency division duplexing (FDD) mode, it is necessary to send the channel state information (CSI) from user equipment to base station. The downlink CSI is essential for the massive multiple-input multiple-output (MIMO) system to acquire the potential gain. Recently, deep learning is widely adopted to massive MIMO CSI feedback task and proved to be effective compared with traditional compressed sensing methods. In this paper, a novel network named ACRNet is designed to boost the feedback performance with network aggregation and parametric RuLU activation. Moreover, valid approach to expand the network architecture in exchange of better performance is first discussed in CSI feedback task. Experiments show that ACRNet outperforms loads of previous state-of-the-art feedback networks without any extra information.      
### 72.New Low Rank Optimization Model and Convex Approach for Robust Spectral Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2101.06433.pdf)
>  This paper investigates recovery of an undamped spectrally sparse signal and its spectral components from a set of regularly spaced samples within the framework of spectral compressed sensing and super-resolution. We show that the existing Hankel-based optimization methods suffer from the fundamental limitation that the prior of undampedness cannot be exploited. We propose a new low rank optimization model partially inspired by forward-backward processing for line spectral estimation and show its capability in restricting the spectral poles on the unit circle. We present convex relaxation approaches with the model and show their provable accuracy and robustness to bounded and sparse noise. All our results are generalized from the 1-D to arbitrary-dimensional spectral compressed sensing. Numerical simulations are provided that corroborate our analysis and show efficiency of our model and advantageous performance of our approach in improved accuracy and resolution as compared to the state-of-the-art Hankel and atomic norm methods.      
### 73.Minimum-volume Multichannel Nonnegative matrix factorization for blind source separation  [ :arrow_down: ](https://arxiv.org/pdf/2101.06398.pdf)
>  Multichannel blind source separation aims to recover the latent sources from their multichannel mixture without priors. A state-of-art blind source separation method called independent low-rank matrix analysis (ILRMA) unified independent vector analysis (IVA) and nonnegative matrix factorization (NMF). However, speech spectra modeled by NMF may not find a compact representation and it may not guarantee that each source is identifiable. To address the problem, here we propose a modified blind source separation method that enhances the identifiability of the source model. It combines ILRMA with penalty item of volume constraint. The proposed method is optimized by standard majorization-minimization framework based multiplication updating rule, which ensures the stability of convergence. Experimental results demonstrate the effectiveness of the proposed method compared with AuxIVA, MNMF and ILRMA.      
### 74.Slider: On the Design and Modeling of a 2D Floating Satellite Platform  [ :arrow_down: ](https://arxiv.org/pdf/2101.06335.pdf)
>  In this article, a floating robotic emulation platform for a virtual demonstration of satellite motion in space is presented. The robotic platform design is characterized by its friction-less, levitating, yet planar motion over a hyper-smooth surface. The robotic platform, integrated with sensor and actuator units, is fully designed and manufactured from the Robotics and Artificial Intelligence Team at Lule University of Technology. A detailed design description along with the mathematical modeling describing the platform's dynamic motion is formulated. Finally, the proposed design is validated in extensive simulation studies, while the overall test bed experimental setup, as well as the vehicle hardware and software architectures, are discussed in detail. Furthermore, the entire design, including 3D printing CAD model and different testbed elements, is provided in an open-source repository and a test campaign is used to showcase its capabilities and illustrate its operations.      
### 75.Compressed Sensing for STM imaging of defects and disorder  [ :arrow_down: ](https://arxiv.org/pdf/2101.06332.pdf)
>  Compressed sensing (CS) is a valuable technique for reconstructing measurements in numerous domains. CS has not yet gained widespread adoption in scanning tunneling microscopy (STM), despite potentially offering the advantages of lower acquisition time and enhanced tolerance to noise. Here we applied a simple CS framework, using a weighted iterative thresholding algorithm for CS reconstruction, to representative high-resolution STM images of superconducting surfaces and adsorbed molecules. We calculated reconstruction diagrams for a range of scanning patterns, sampling densities, and noise intensities, evaluating reconstruction quality for the whole image and chosen defects. Overall we find that typical STM images can be satisfactorily reconstructed down to 30\% sampling - already a strong improvement. We furthermore outline limitations of this method, such as sampling pattern artifacts, which become particularly pronounced for images with intrinsic long-range disorder, and propose ways to mitigate some of them. Finally we investigate compressibility of STM images as a measure of intrinsic noise in the image and a precursor to CS reconstruction, enabling a priori estimation of the effectiveness of CS reconstruction with minimal computational cost.      
### 76.Automated Diagnosis of Intestinal Parasites: A new hybrid approach and its benefits  [ :arrow_down: ](https://arxiv.org/pdf/2101.06310.pdf)
>  Intestinal parasites are responsible for several diseases in human beings. In order to eliminate the error-prone visual analysis of optical microscopy slides, we have investigated automated, fast, and low-cost systems for the diagnosis of human intestinal parasites. In this work, we present a hybrid approach that combines the opinion of two decision-making systems with complementary properties: ($DS_1$) a simpler system based on very fast handcrafted image feature extraction and support vector machine classification and ($DS_2$) a more complex system based on a deep neural network, Vgg-16, for image feature extraction and classification. $DS_1$ is much faster than $DS_2$, but it is less accurate than $DS_2$. Fortunately, the errors of $DS_1$ are not the same of $DS_2$. During training, we use a validation set to learn the probabilities of misclassification by $DS_1$ on each class based on its confidence values. When $DS_1$ quickly classifies all images from a microscopy slide, the method selects a number of images with higher chances of misclassification for characterization and reclassification by $DS_2$. Our hybrid system can improve the overall effectiveness without compromising efficiency, being suitable for the clinical routine -- a strategy that might be suitable for other real applications. As demonstrated on large datasets, the proposed system can achieve, on average, 94.9%, 87.8%, and 92.5% of Cohen's Kappa on helminth eggs, helminth larvae, and protozoa cysts, respectively.      
### 77.Optimal conditions for multiplexing information into ring-core optical fibers  [ :arrow_down: ](https://arxiv.org/pdf/2101.06280.pdf)
>  In optical communications, space-division multiplexing is a promising strategy to augment the fiber network capacity. It relies on modern fiber designs that support the propagation of multiple spatial modes. One of these fibers, the ring-core fiber (RCF), is able to propagate modes that carry orbital angular momentum (OAM), and has been shown to enhance not only classical, but also quantum communication systems. Typically, the RCF spatial modes are used as orthogonal transmission channels for data streams that are coupled into the fiber using different Laguerre-Gaussian (LG) beams. Here, we study the optimal conditions to multiplex information into ring-core fibers in this scheme. We determine which are the most relevant LG beams to be considered, and how their coupling efficiency can be maximized by properly adjusting the beam width with respect to the fiber parameters. Our results show that the coupling efficiency depends upon the OAM value, and that this can limit the achievable transmission rates. In this regard, we show that LG beams are not the optimal choice to couple information into RCF. Rather, another class of OAM-carrying beam, the perfect vortex beam, allows for nearly perfect coupling efficiencies for all spatial modes supported by these fibers.      
### 78.Consecutive Decoding for Speech-to-text Translation  [ :arrow_down: ](https://arxiv.org/pdf/2009.09737.pdf)
>  Speech-to-text translation (ST), which directly translates the source language speech to the target language text, has attracted intensive attention recently. However, the combination of speech recognition and machine translation in a single model poses a heavy burden on the direct cross-modal cross-lingual mapping. To reduce the learning difficulty, we propose COnSecutive Transcription and Translation (COSTT), an integral framework for speech-to-text translation. Our method is verified on three mainstream datasets, including Augmented LibriSpeech English-French dataset, TED English-German dataset, and TED English-Chinese dataset. Experiments show that our proposed COSTT outperforms the previous state-of-the-art methods. Our code is available at <a class="link-external link-https" href="https://github.com/dqqcasia/st" rel="external noopener nofollow">this https URL</a>.      
### 79."Listen, Understand and Translate": Triple Supervision Decouples End-to-end Speech-to-text Translation  [ :arrow_down: ](https://arxiv.org/pdf/2009.09704.pdf)
>  An end-to-end speech-to-text translation (ST) takes audio in a source language and outputs the text in a target language. Inspired by neuroscience, humans have perception systems and cognitive systems to process different information, we propose LUT, Listen-Understand-Translate, a unified framework with triple supervision to decouple the end-to-end speech-to-text translation task. In addition to the target language sentence translation loss, LUT includes two auxiliary supervising signals to guide the acoustic encoder to extracts acoustic features from the input, and the semantic encoder to extract semantic features relevant to the source transcription text. We do experiments on English-French, English-German and English-Chinese speech translation benchmarks and the results demonstrate the reasonability of LUT. Our code is available at <a class="link-external link-https" href="https://github.com/dqqcasia/st" rel="external noopener nofollow">this https URL</a>.      
