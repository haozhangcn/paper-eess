# ArXiv eess --Wed, 15 Dec 2021
### 1.Visualizing Ensemble Predictions of Music Mood  [ :arrow_down: ](https://arxiv.org/pdf/2112.07627.pdf)
>  Music mood classification has been a challenging problem in comparison with some other classification problems (e.g., genre, composer, or period). One solution for addressing this challenging is to use an of ensemble machine learning models. In this paper, we show that visualization techniques can effectively convey the popular prediction as well as uncertainty at different music sections along the temporal axis, while enabling the analysis of individual ML models in conjunction with their application to different musical data. In addition to the traditional visual designs, such as stacked line graph, ThemeRiver, and pixel-based visualization, we introduced a new variant of ThemeRiver, called "dual-flux ThemeRiver", which allows viewers to observe and measure the most popular prediction more easily than stacked line graph and ThemeRiver. Testing indicates that visualizing ensemble predictions is helpful both in model-development workflows and for annotating music using model predictions.      
### 2.Interaction-Aware Trajectory Prediction and Planning for Autonomous Vehicles in Forced Merge Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2112.07624.pdf)
>  Merging is, in general, a challenging task for both human drivers and autonomous vehicles, especially in dense traffic, because the merging vehicle typically needs to interact with other vehicles to identify or create a gap and safely merge into. In this paper, we consider the problem of autonomous vehicle control for forced merge scenarios. We propose a novel game-theoretic controller, called the Leader-Follower Game Controller (LFGC), in which the interactions between the autonomous ego vehicle and other vehicles with a priori uncertain driving intentions is modeled as a partially observable leader-follower game. The LFGC estimates the other vehicles' intentions online based on observed trajectories, and then predicts their future trajectories and plans the ego vehicle's own trajectory using Model Predictive Control (MPC) to simultaneously achieve probabilistically guaranteed safety and merging objectives. To verify the performance of LFGC, we test it in simulations and with the NGSIM data, where the LFGC demonstrates a high success rate of 97.5% in merging.      
### 3.Classification of histopathology images using ConvNets to detect Lupus Nephritis  [ :arrow_down: ](https://arxiv.org/pdf/2112.07555.pdf)
>  Systemic lupus erythematosus (SLE) is an autoimmune disease in which the immune system of the patient starts attacking healthy tissues of the body. Lupus Nephritis (LN) refers to the inflammation of kidney tissues resulting in renal failure due to these attacks. The International Society of Nephrology/Renal Pathology Society (ISN/RPS) has released a classification system based on various patterns observed during renal injury in SLE. Traditional methods require meticulous pathological assessment of the renal biopsy and are time-consuming. Recently, computational techniques have helped to alleviate this issue by using virtual microscopy or Whole Slide Imaging (WSI). With the use of deep learning and modern computer vision techniques, we propose a pipeline that is able to automate the process of 1) detection of various glomeruli patterns present in these whole slide images and 2) classification of each image using the extracted glomeruli features.      
### 4.Improving COVID-19 CXR Detection with Synthetic Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.07529.pdf)
>  Since the beginning of the COVID-19 pandemic, researchers have developed deep learning models to classify COVID-19 induced pneumonia. As with many medical imaging tasks, the quality and quantity of the available data is often limited. In this work we train a deep learning model on publicly available COVID-19 image data and evaluate the model on local hospital chest X-ray data. The data has been reviewed and labeled by two radiologists to ensure a high quality estimation of the generalization capabilities of the model. Furthermore, we are using a Generative Adversarial Network to generate synthetic X-ray images based on this data. Our results show that using those synthetic images for data augmentation can improve the model's performance significantly. This can be a promising approach for many sparse data domains.      
### 5.Active RIS Versus Passive RIS: Which Is Superior with the Same Power Budget?  [ :arrow_down: ](https://arxiv.org/pdf/2112.07510.pdf)
>  This letter theoretically compares the active reconfigurable intelligent surface (RIS)-aided system with the passive RIS-aided system. For fair comparison, we consider that these two systems have the same overall power budget that can be used at both the base station (BS) and the RIS. For active RIS, we first derive the optimal power allocation between the BS's transmit signal power and RIS's output signal power. We also analyze the impact of various system parameters on the optimal power allocation ratio. Then, we compare the performance between the active RIS and the passive RIS, which demonstrates that the active RIS would be superior if the power budget is not very small and the number of RIS elements is not very large.      
### 6.Towards Organic Distribution Systems -- The Vision of Self-Configuring, Self-Organising, Self-Healing, and Self-Optimising Power Distribution Management  [ :arrow_down: ](https://arxiv.org/pdf/2112.07507.pdf)
>  Due to the decarbonisation of energy use, the power system is expected to become the backbone of all energy sectors and thus the basic critical infrastructure. High penetration with distributed energy resources demands the coordination of a large number of prosumers, partly controlled by home energy management systems (HEMS), to be designed in such a way that the power system's operational limits are not violated. On the grid level, distribution management systems (DMS) try to keep the power system in the normal operational state. On the prosumer level, distributed HEMS optimise the internal power flows by using batteries, photovoltaic generators, or flexible loads optimally. The vision of the ODiS (Organic Distribution System) initiative is to develop an architecture to operate a distribution grid reliably, with high resiliency, and fully autonomously by developing "organic" HEMS and DMS which possess multiple self-* capabilities. Thus, ODiS seeks answers to the following question: How can we create the most appropriate models, techniques, and algorithms to develop novel kinds of self-configuring, self-organising, self-healing, and self-optimising DMS that are integrally coupled with the distributed HEMS? In this article, the vision of ODiS is presented in detail based on a thorough review of the state of the art.      
### 7.On the Necessity and Sufficiency of Discrete-Time O'Shea-Zames-Falb Multipliers  [ :arrow_down: ](https://arxiv.org/pdf/2112.07456.pdf)
>  This paper considers the robust stability of a discrete-time Lurye system consisting of the feedback interconnection between a linear system and a bounded and monotone nonlinearity. It has been conjectured that the existence of a suitable linear time-invariant (LTI) O'Shea-Zames-Falb multiplier is not only sufficient but also necessary. Roughly speaking, a successful proof of the conjecture would require: (a) a conic parameterization of a set of multipliers that describes exactly the set of nonlinearities, (b) a lossless S-procedure to show that the non-existence of a multiplier implies that the Lurye system is not uniformly robustly stable over the set of nonlinearities, and (c) the existence of a multiplier in the set of multipliers used in (a) implies the existence of an LTI multiplier. We investigate these three steps, showing the current bottlenecks for proving this conjecture. In addition, we provide an extension of the class of multipliers which may be used to disprove the conjecture.      
### 8.Stochastic Planner-Actor-Critic for Unsupervised Deformable Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2112.07415.pdf)
>  Large deformations of organs, caused by diverse shapes and nonlinear shape changes, pose a significant challenge for medical image registration. Traditional registration methods need to iteratively optimize an objective function via a specific deformation model along with meticulous parameter tuning, but which have limited capabilities in registering images with large deformations. While deep learning-based methods can learn the complex mapping from input images to their respective deformation field, it is regression-based and is prone to be stuck at local minima, particularly when large deformations are involved. To this end, we present Stochastic Planner-Actor-Critic (SPAC), a novel reinforcement learning-based framework that performs step-wise registration. The key notion is warping a moving image successively by each time step to finally align to a fixed image. Considering that it is challenging to handle high dimensional continuous action and state spaces in the conventional reinforcement learning (RL) framework, we introduce a new concept `Plan' to the standard Actor-Critic model, which is of low dimension and can facilitate the actor to generate a tractable high dimensional action. The entire framework is based on unsupervised training and operates in an end-to-end manner. We evaluate our method on several 2D and 3D medical image datasets, some of which contain large deformations. Our empirical results highlight that our work achieves consistent, significant gains and outperforms state-of-the-art methods.      
### 9.Towards a Network Control Theory of Electroconvulsive Therapy Response  [ :arrow_down: ](https://arxiv.org/pdf/2112.07408.pdf)
>  Electroconvulsive Therapy (ECT) is arguably the most effective intervention for treatment-resistant depression. While large interindividual variability exists, a theory capable of predicting individual response to ECT remains elusive. To address this, we posit a quantitative, mechanistic framework of ECT response based on Network Control Theory (NCT). Then, we empirically test our approach and employ it to predict ECT treatment response. To this end, we derive a formal association between Postictal Suppression Index (PSI) - an ECT seizure quality index - and whole-brain modal and average controllability, NCT metrics based on white matter brain network architecture, respectively. Exploiting the known association of ECT response and PSI, we then hypothesized an association between our controllability metrics and ECT response mediated by PSI. We formally tested this conjecture in N=50 depressive patients undergoing ECT. We show that whole-brain controllability metrics based on pre-ECT structural connectome data predict ECT response in accordance with our hypotheses. In addition, we show the expected mediation effects via PSI. Importantly, our theoretically motivated metrics are at least on par with extensive machine learning models based on pre-ECT connectome data. In summary, we derived and tested a control-theoretic framework capable of predicting ECT response based on individual brain network architecture. It makes testable, quantitative predictions regarding individual therapeutic response, which are corroborated by strong empirical evidence. Our work might constitute a starting point for a comprehensive, quantitative theory of personalized ECT interventions rooted in control theory.      
### 10.Robustifying automatic speech recognition by extracting slowly varying features  [ :arrow_down: ](https://arxiv.org/pdf/2112.07400.pdf)
>  In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic speech recognition (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted adversarial attacks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust.      
### 11.Non-Iterative Calculation of Quasi-Dynamic Energy Flow in the Heat and Electricity Integrated Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.07331.pdf)
>  Energy flow calculation plays a vital role in the analysis, operation, and control of heat and electricity integrated energy systems (HE-IESs). The quasi-dynamic energy flow models of HE-IESs are essentially partial differential equations (PDEs) (governing thermal inertia) and non-linear algebraic equations (AEs) (governing temperature, hydraulics, and power flow), which present a complicated system of partial differential algebraic equations (PDAEs). To solve the non-linear PDAEs in an efficient, accurate and robust way, we propose a novel non-iterative semi-analytical method based on differential transformation (DT). Firstly, we define a new DT framework under per unit systems to avoid the numerical problems due to inconsistent base quantities of district heating systems and electrical power systems, and inappropriate base time. Secondly, we discretize the spatial derivative of the PDEs using a semi-discrete difference scheme which converts the PDEs into ordinary differential equations (ODEs). The scheme has total variation decreasing property and hence helps eliminate dissipative and dispersive errors that are often overlooked in the existing literature. Then, we employ the newly defined DT framework as the time-marching solver of the ODEs and further extend DT to non-linear AEs, deriving high-order explicit closed-form solutions of all the variables. In addition, to further improve the convergence and computation efficiency, we propose an adaptive time window strategy based on local truncation error estimation. Case studies in a real DHS and an HE-IES with 225 heating nodes and 118 electrical buses show that the proposed method outperforms the finite-difference-based Newton-Raphson iterative solver in efficiency, accuracy, and robustness.      
### 12.Experimental Data-Driven Model Predictive Control of a Hospital HVAC System During Regular Use  [ :arrow_down: ](https://arxiv.org/pdf/2112.07323.pdf)
>  Herein we report a multi-zone, heating, ventilation and air-conditioning (HVAC) control case study of an industrial plant responsible for cooling a hospital surgery center. The adopted approach to guaranteeing thermal comfort and reducing electrical energy consumption is based on a statistical non-parametric, non-linear regression technique named Gaussian processes. Our study aimed at assessing the suitability of the aforementioned technique to learning the building dynamics and yielding models for our model predictive control (MPC) scheme. Experimental results gathered while the building was under regular use showcase the final controller performance while subject to a number of measured and unmeasured disturbances. Finally, we provide readers with practical details and recommendations on how to manage the computational complexity of the on-line optimization problem and obtain high-quality solutions from solvers.      
### 13.Relative Kinematics Estimation Using Accelerometer Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2112.07307.pdf)
>  Given a network of $N$ static nodes in $D$-dimensional space and the pairwise distances between them, the challenge of estimating the coordinates of the nodes is a well-studied problem. However, for numerous application domains, the nodes are mobile and the estimation of relative kinematics (e.g., position, velocity and acceleration) is a challenge, which has received limited attention in literature. In this paper, we propose a time-varying Grammian-based data model for estimating the relative kinematics of mobile nodes with polynomial trajectories, given the time-varying pairwise distance measurements between the nodes. Furthermore, we consider a scenario where the nodes have on-board accelerometers, and extend the proposed data model to include these accelerometer measurements. We propose closed-form solutions to estimate the relative kinematics, based on the proposed data models. We conduct simulations to showcase the performance of the proposed estimators, which show improvement against state-of-the-art methods.      
### 14.Improving Hybrid CTC/Attention End-to-end Speech Recognition with Pretrained Acoustic and Language Model  [ :arrow_down: ](https://arxiv.org/pdf/2112.07254.pdf)
>  Recently, self-supervised pretraining has achieved impressive results in end-to-end (E2E) automatic speech recognition (ASR). However, the dominant sequence-to-sequence (S2S) E2E model is still hard to fully utilize the self-supervised pre-training methods because its decoder is conditioned on acoustic representation thus cannot be pretrained separately. In this paper, we propose a pretrained Transformer (Preformer) S2S ASR architecture based on hybrid CTC/attention E2E models to fully utilize the pretrained acoustic models (AMs) and language models (LMs). In our framework, the encoder is initialized with a pretrained AM (wav2vec2.0). The Preformer leverages CTC as an auxiliary task during training and inference. Furthermore, we design a one-cross decoder (OCD), which relaxes the dependence on acoustic representations so that it can be initialized with pretrained LM (DistilGPT2). Experiments are conducted on the AISHELL-1 corpus and achieve a $4.6\%$ character error rate (CER) on the test set. Compared with our vanilla hybrid CTC/attention Transformer baseline, our proposed CTC/attention-based Preformer yields $27\%$ relative CER reduction. To the best of our knowledge, this is the first work to utilize both pretrained AM and LM in a S2S ASR system.      
### 15.A Deep Knowledge Distillation framework for EEG assisted enhancement of single-lead ECG based sleep staging  [ :arrow_down: ](https://arxiv.org/pdf/2112.07252.pdf)
>  Automatic Sleep Staging study is presently done with the help of Electroencephalogram (EEG) signals. Recently, Deep Learning (DL) based approaches have enabled significant progress in this area, allowing for near-human accuracy in automated sleep staging. However, EEG based sleep staging requires an extensive as well as an expensive clinical setup. Moreover, the requirement of an expert for setup and the added inconvenience to the subject under study renders it unfavourable in a point of care context. Electrocardiogram (ECG), an unobtrusive alternative to EEG, is more suitable, but its performance, unsurprisingly, remains sub-par compared to EEG-based sleep staging. Naturally, it would be helpful to transfer knowledge from EEG to ECG, ultimately enhancing the model's performance on ECG based inputs. Knowledge Distillation (KD) is a renowned concept in DL that looks to transfer knowledge from a better but potentially more cumbersome teacher model to a compact student model. Building on this concept, we propose a cross-modal KD framework to improve ECG-based sleep staging performance with assistance from features learned through models trained on EEG. Additionally, we also conducted multiple experiments on the individual components of the proposed model to get better insight into the distillation approach. Data of 200 subjects from the Montreal Archive of Sleep Studies (MASS) was utilized for our study. The proposed model showed a 14.3\% and 13.4\% increase in weighted-F1-score in 4-class and 3-class sleep staging, respectively. This demonstrates the viability of KD for performance improvement of single-channel ECG based sleep staging in 4-class(W-L-D-R) and 3-class(W-N-R) classification.      
### 16.Composing MPC with LQR and Neural Networks for Efficient and Stable Control  [ :arrow_down: ](https://arxiv.org/pdf/2112.07238.pdf)
>  Model predictive control (MPC) is a powerful control method that handles dynamical systems with constraints. However, solving MPC iteratively in real time, i.e., implicit MPC, has been a challenge for 1) systems with low-latency requirements, 2) systems with limited computational resources, and 3) systems with fast and complex dynamics. To address this challenge, for low-dimensional linear systems, a classical approach is explicit MPC; for high-dimensional or nonlinear systems, a common approach is function approximation using neural networks. Both methods, whenever applicable, may improve the computational efficiency of the original MPC by several orders of magnitude. The existing methods have the following disadvantages: 1) explicit MPC does not apply to higher-dimensional problems or most of the problems with nonlinear constraints; and 2) function approximation is not guaranteed to find an accurate surrogate policy, the failure of which may lead to closed-loop instability. To address these issues, we propose a triple-mode hybrid control scheme, named Memory-Augmented MPC, by combining an efficient linear quadratic regulator, an efficient neural network, and a costly, fail-safe MPC. From its standard form, we derive two variants of such hybrid control scheme: one customized for chaotic systems and the other for slow systems. We prove stability of the control scheme with any arbitrary neural networks and test its computational performance in simulated numerical experiments.      
### 17.Spatiogram: A phase based directional angular measure and perceptual weighting for ensemble source width  [ :arrow_down: ](https://arxiv.org/pdf/2112.07216.pdf)
>  In concert hall studies, inter-aural cross-correlation (IACC), which is signal dependent, is used as a measure of perceptual source width. The same measure is used for perceptual source width in the case of distributed sources also. In this work, we examine the validity of IACC for both the cases and develop an improved measure for ensemble-like distributed sources. We decompose the new objective measure for perceptual ensemble source width (ESW) into two components (i) phase based directional angular measure, which is timbre independent (spatial measure) and (ii) mean time-bandwidth energy (MTBE), a perceptual weight, (timbre measure). This combination of spatial and timbral measures can be extended as an alternate measure for determining auditory source width (ASW) and listener envelopment (LEV) of arbitrary signals in concert-hall and room acoustics.      
### 18.Formal Estimation of Collision Risks for Autonomous Vehicles: A Compositional Data-Driven Approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.07187.pdf)
>  In this work, we propose a compositional data-driven approach for the formal estimation of collision risks for autonomous vehicles (AVs) acting in a stochastic multi-agent framework. The proposed approach is based on the construction of sub-barrier certificates for each stochastic agent via a set of data collected from its trajectories while providing a-priori guaranteed confidence on the data-driven estimation. In our proposed setting, we first cast the original collision risk problem for each agent as a robust optimization program (ROP). Solving the acquired ROP is not tractable due to an unknown model that appears in one of its constraints. To tackle this difficulty, we collect finite numbers of data from trajectories of each agent and provide a scenario optimization program (SOP) corresponding to the original ROP. We then establish a probabilistic bridge between the optimal value of SOP and that of ROP, and accordingly, we formally construct the sub-barrier certificate for each unknown agent based on the number of data and a required level of confidence. We then propose a compositional technique based on small-gain reasoning to quantify the collision risk for multi-agent AVs with some desirable confidence based on sub-barrier certificates of individual agents constructed from data. For the case that the proposed compositionality conditions are not satisfied, we provide a relaxed version of compositional results without requiring any compositionality conditions but at the cost of providing a potentially conservative collision risk. Eventually, we develop our approaches for non-stochastic multi-agent AVs. We demonstrate the effectiveness of our proposed results by applying them to a vehicle platooning consisting of 100 vehicles with 1 leader and 99 followers. We formally estimate the collision risk for the whole network by collecting sampled data from trajectories of each agent.      
### 19.ImportantAug: a data augmentation agent for speech  [ :arrow_down: ](https://arxiv.org/pdf/2112.07156.pdf)
>  We introduce ImportantAug, a technique to augment training data for speech classification and recognition models by adding noise to unimportant regions of the speech and not to important regions. Importance is predicted for each utterance by a data augmentation agent that is trained to maximize the amount of noise it adds while minimizing its impact on recognition performance. The effectiveness of our method is illustrated on version two of the Google Speech Commands (GSC) dataset. On the standard GSC test set, it achieves a 23.3% relative error rate reduction compared to conventional noise augmentation which applies noise to speech without regard to where it might be most effective. It also provides a 25.4% error rate reduction compared to a baseline without data augmentation. Additionally, the proposed ImportantAug outperforms the conventional noise augmentation and the baseline on two test sets with additional noise added.      
### 20.Output fusion of MPC and PID and its application in intelligent layered water injection of oilfield  [ :arrow_down: ](https://arxiv.org/pdf/2112.07129.pdf)
>  To improve the dynamic response performance of wave code communication in intelligent layered water injection of oilfield, this paper proposes an output optimal fusion control method based on MPC-PID. Firstly, depending on the well structure and the flow-pressure characteristics of the layer, the steady-state model between the differential pressure and flow of the whole well and different layer sections is established for layered water injection, and the corresponding wave code amplitude at the steady-state operating point of different layer sections is solved, the numerical calculation verifies that the increase of the nozzle opening in a single layer section will drive the pressure and flow curve of the whole well downward. Secondly, combining the dynamic response characteristics and steady-state model of the whole-well water distribution equipment, a dynamic model of layered intelligent water injection is established, and the generation process of the wave code is defined; Finally, the MPC-PID optimal fusion control algorithm structure is designed to derive the fusion control law that minimizes the cost function under fixed weights, , and the optimal weights are calculated by combining the internal model structure of controller, so the optimization performance of each algorithm in the optimal fusion control is balanced. By analyzing the control simulation results, the fast response characteristics of the fusion control method are verified. Meanwhile, the simulation comparison experiments of fast wave code communication under different methods are conducted with the actual working conditions, the results show that the fusion control method has both fast tracking control capability and strong robustness, which effectively enhances the efficiency of wave code communication and shortens the wave code operation time.      
### 21.Optimal Memory Scheme for Accelerated Consensus Over Multi-Agent Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.07108.pdf)
>  The consensus over multi-agent networks can be accelerated by introducing agent's memory to the control protocol. In this paper, a more general protocol with the node memory and the state deviation memory is designed. We aim to provide the optimal memory scheme to accelerate consensus. The contributions of this paper are three: (i) For the one-tap memory scheme, we demonstrate that the state deviation memory is useless for the optimal convergence. (ii) In the worst case, we prove that it is a vain to add any tap of the state deviation memory, and the one-tap node memory is sufficient to achieve the optimal convergence. (iii) We show that the two-tap state deviation memory is effective on some special networks, such as star networks. Numerical examples are listed to illustrate the validity and correctness of the obtained results.      
### 22.Hierarchical Stochastic Scheduling of Multi-Community Integrated Energy Systems in Uncertain Environments via Stackelberg Game  [ :arrow_down: ](https://arxiv.org/pdf/2112.07103.pdf)
>  An operating entity utilizing community-integrated energy systems with a large number of small-scale distributed energy sources can easily trade with existing distribution markets. To solve the energy management and pricing problem of multi-community integrated energy systems (MCIESs) with multi-energy interaction, this study investigated a hierarchical stochastic optimal scheduling method for uncertain environments. To handle multiple uncertainties, a Wasserstein generative adversarial network with a gradient penalty was used to generate renewable scenarios, and the Kmeans++ clustering algorithm was employed to generate typical scenarios. A Stackelberg-based hierarchical stochastic schedule with an integrated demand response was constructed, where the MCIES operator acted as the leader pursuing the maximum net profit by setting energy prices, while the building users were followers who adjusted their energy consumption plans to minimize their total costs. Finally, a distributed iterative solution method based on a metaheuristic was designed. The effectiveness of the proposed method was verified using practical examples.      
### 23.COVID-19 Pneumonia and Influenza Pneumonia Detection Using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.07102.pdf)
>  In the research, we developed a computer vision solution to support diagnostic radiology in differentiating between COVID-19 pneumonia, influenza virus pneumonia, and normal biomarkers. The chest radiograph appearance of COVID-19 pneumonia is thought to be nonspecific, having presented a challenge to identify an optimal architecture of a convolutional neural network (CNN) that would classify with a high sensitivity among the pulmonary inflammation features of COVID-19 and non-COVID-19 types of pneumonia. Rahman (2021) states that COVID-19 radiography images observe unavailability and quality issues impacting the diagnostic process and affecting the accuracy of the deep learning detection models. A significant scarcity of COVID-19 radiography images introduced an imbalance in data motivating us to use over-sampling techniques. In the study, we include an extensive set of X-ray imaging of human lungs (CXR) with COVID-19 pneumonia, influenza virus pneumonia, and normal biomarkers to achieve an extensible and accurate CNN model. In the experimentation phase of the research, we evaluated a variety of convolutional network architectures, selecting a sequential convolutional network with two traditional convolutional layers and two pooling layers with maximum function. In its classification performance, the best performing model demonstrated a validation accuracy of 93% and an F1 score of 0.95. We chose the Azure Machine Learning service to perform network experimentation and solution deployment. The auto-scaling compute clusters offered a significant time reduction in network training. We would like to see scientists across fields of artificial intelligence and human biology collaborating and expanding on the proposed solution to provide rapid and comprehensive diagnostics, effectively mitigating the spread of the virus      
### 24.On Control Schemes of Voltage Source Converters  [ :arrow_down: ](https://arxiv.org/pdf/2112.06993.pdf)
>  This paper discusses some aspects of control schemes for voltage source converters under abnormal conditions. The control schemes are developed specifically for the situations when one or more system parameters vary significantly to the extent that the system becomes unstable with a conventional controller. The paper will present some recent works on control of grid-interactive converters for parameter variations in weak grid. The paper will also discuss some methods under abnormal dc-bus variation. Finally, the paper focuses on the control schemes suitable for ac-dc converters that addresses input frequency, voltage and load variation. All the discussed control schemes have shown robust performance under abnormal conditions.      
### 25.The Brain Tumor Sequence Registration Challenge: Establishing Correspondence between Pre-Operative and Follow-up MRI scans of diffuse glioma patients  [ :arrow_down: ](https://arxiv.org/pdf/2112.06979.pdf)
>  Registration of longitudinal brain Magnetic Resonance Imaging (MRI) scans containing pathologies is challenging due to tissue appearance changes, and still an unsolved problem. This paper describes the first Brain Tumor Sequence Registration (BraTS-Reg) challenge, focusing on estimating correspondences between pre-operative and follow-up scans of the same patient diagnosed with a brain diffuse glioma. The BraTS-Reg challenge intends to establish a public benchmark environment for deformable registration algorithms. The associated dataset comprises de-identified multi-institutional multi-parametric MRI (mpMRI) data, curated for each scan's size and resolution, according to a common anatomical template. Clinical experts have generated extensive annotations of landmarks points within the scans, descriptive of distinct anatomical locations across the temporal domain. The training data along with these ground truth annotations will be released to participants to design and develop their registration algorithms, whereas the annotations for the validation and the testing data will be withheld by the organizers and used to evaluate the containerized algorithms of the participants. Each submitted algorithm will be quantitatively evaluated using several metrics, such as the Median Absolute Error (MAE), Robustness, and the Jacobian determinant.      
### 26.On the Use of External Data for Spoken Named Entity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2112.07648.pdf)
>  Spoken language understanding (SLU) tasks involve mapping from speech audio signals to semantic labels. Given the complexity of such tasks, good performance might be expected to require large labeled datasets, which are difficult to collect for each new task and domain. However, recent advances in self-supervised speech representations have made it feasible to consider learning SLU models with limited labeled data. In this work we focus on low-resource spoken named entity recognition (NER) and address the question: Beyond self-supervised pre-training, how can we use external speech and/or text data that are not annotated for the task? We draw on a variety of approaches, including self-training, knowledge distillation, and transfer learning, and consider their applicability to both end-to-end models and pipeline (speech recognition followed by text NER model) approaches. We find that several of these approaches improve performance in resource-constrained settings beyond the benefits from pre-trained representations alone. Compared to prior work, we find improved F1 scores of up to 16%. While the best baseline model is a pipeline approach, the best performance when using external data is ultimately achieved by an end-to-end model. We provide detailed comparisons and analyses, showing for example that end-to-end models are able to focus on the more NER-specific words.      
### 27.Mitigating Channel-wise Noise for Single Image Super Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2112.07589.pdf)
>  In practice, images can contain different amounts of noise for different color channels, which is not acknowledged by existing super-resolution approaches. In this paper, we propose to super-resolve noisy color images by considering the color channels jointly. Noise statistics are blindly estimated from the input low-resolution image and are used to assign different weights to different color channels in the data cost. Implicit low-rank structure of visual data is enforced via nuclear norm minimization in association with adaptive weights, which is added as a regularization term to the cost. Additionally, multi-scale details of the image are added to the model through another regularization term that involves projection onto PCA basis, which is constructed using similar patches extracted across different scales of the input image. The results demonstrate the super-resolving capability of the approach in real scenarios.      
### 28.Robust Graph Neural Networks via Probabilistic Lipschitz Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2112.07575.pdf)
>  Graph neural networks (GNNs) have recently been demonstrated to perform well on a variety of network-based tasks such as decentralized control and resource allocation, and provide computationally efficient methods for these tasks which have traditionally been challenging in that regard. However, like many neural-network based systems, GNNs are susceptible to shifts and perturbations on their inputs, which can include both node attributes and graph structure. In order to make them more useful for real-world applications, it is important to ensure their robustness post-deployment. Motivated by controlling the Lipschitz constant of GNN filters with respect to the node attributes, we propose to constrain the frequency response of the GNN's filter banks. We extend this formulation to the dynamic graph setting using a continuous frequency response constraint, and solve a relaxed variant of the problem via the scenario approach. This allows for the use of the same computationally efficient algorithm on sampled constraints, which provides PAC-style guarantees on the stability of the GNN using results in scenario optimization. We also highlight an important connection between this setup and GNN stability to graph perturbations, and provide experimental results which demonstrate the efficacy and broadness of our approach.      
### 29.Cooperation for Scalable Supervision of Autonomy in Mixed Traffic  [ :arrow_down: ](https://arxiv.org/pdf/2112.07569.pdf)
>  Improvements in autonomy offer the potential for positive outcomes in a number of domains, yet guaranteeing their safe deployment is difficult. This work investigates how humans can intelligently supervise agents to achieve some level of safety even when performance guarantees are elusive. The motivating research question is: In safety-critical settings, can we avoid the need to have one human supervise one machine at all times? The paper formalizes this 'scaling supervision' problem, and investigates its application to the safety-critical context of autonomous vehicles (AVs) merging into traffic. It proposes a conservative, reachability-based method to reduce the burden on the AVs' human supervisors, which allows for the establishment of high-confidence upper bounds on the supervision requirements in this setting. Order statistics and traffic simulations with deep reinforcement learning show analytically and numerically that teaming of AVs enables supervision time sublinear in AV adoption. A key takeaway is that, despite present imperfections of AVs, supervision becomes more tractable as AVs are deployed en masse. While this work focuses on AVs, the scalable supervision framework is relevant to a broader array of autonomous control challenges.      
### 30.Local Output Feedback Stabilization of a Nonlinear Kuramoto-Sivashinsky equation  [ :arrow_down: ](https://arxiv.org/pdf/2112.07568.pdf)
>  This paper is concerned with the local output feedback stabilization of a nonlinear Kuramoto-Sivashinsky equation. The control is located at the boundary of the domain while the measurement is selected as a Neumann trace. This choice of system output requires the study of the system trajectories in $H^2$-norm. Moreover, the choice of the actuation/sensing scheme is discussed and adapted in function of the parameters of the plant in order to avoid the possible loss of controllability/observability property of certain eigenvalues of the underlying operator. This leads in certain cases to a multi-input multi-output control design procedure. The adopted control strategy is finite dimensional and relies on spectral reduction methods. We derive sufficient conditions ensuring the local exponential stabilization of the plant. These control design constraints are shown to be feasible provided the order of the controller is selected to be large enough, ensuring that the reported control design procedure is systematic.      
### 31.Linear Quadratic Control with Risk Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2112.07564.pdf)
>  We propose a new risk-constrained formulation of the classical Linear Quadratic (LQ) stochastic control problem for general partially-observed systems. Our framework is motivated by the fact that the risk-neutral LQ controllers, although optimal in expectation, might be ineffective under relatively infrequent, yet statistically significant extreme events. To effectively trade between average and extreme event performance, we introduce a new risk constraint, which explicitly restricts the total expected predictive variance of the state penalty by a user-prescribed level. We show that, under certain conditions on the process noise, the optimal risk-aware controller can be evaluated explicitly and in closed form. In fact, it is affine relative to the minimum mean square error (mmse) state estimate. The affine term pushes the state away from directions where the noise exhibits heavy tails, by exploiting the third-order moment~(skewness) of the noise. The linear term regulates the state more strictly in riskier directions, where both the prediction error (conditional) covariance and the state penalty are simultaneously large; this is achieved by inflating the state penalty within a new filtered Riccati difference equation. We also prove that the new risk-aware controller is internally stable, regardless of parameter tuning, in the special cases of i) fully-observed systems, and ii) partially-observed systems with Gaussian noise. The properties of the proposed risk-aware LQ framework are lastly illustrated via indicative numerical examples.      
### 32.Multi-Modal Temporal Attention Models for Crop Mapping from Satellite Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2112.07558.pdf)
>  Optical and radar satellite time series are synergetic: optical images contain rich spectral information, while C-band radar captures useful geometrical information and is immune to cloud cover. Motivated by the recent success of temporal attention-based methods across multiple crop mapping tasks, we propose to investigate how these models can be adapted to operate on several modalities. We implement and evaluate multiple fusion schemes, including a novel approach and simple adjustments to the training procedure, significantly improving performance and efficiency with little added complexity. We show that most fusion schemes have advantages and drawbacks, making them relevant for specific settings. We then evaluate the benefit of multimodality across several tasks: parcel classification, pixel-based segmentation, and panoptic parcel segmentation. We show that by leveraging both optical and radar time series, multimodal temporal attention-based models can outmatch single-modality models in terms of performance and resilience to cloud cover. To conduct these experiments, we augment the PASTIS dataset with spatially aligned radar image time series. The resulting dataset, PASTIS-R, constitutes the first large-scale, multimodal, and open-access satellite time series dataset with semantic and instance annotations.      
### 33.Parametric schedulability analysis of a launcher flight control system under reactivity constraints  [ :arrow_down: ](https://arxiv.org/pdf/2112.07548.pdf)
>  The next generation of space systems will have to achieve more and more complex missions. In order to master the development cost and duration of such systems, an alternative to a manual design is to automatically synthesize the main parameters of the system. In this paper, we present an approach for the specific case of the scheduling of the flight control of a space launcher. The approach requires two successive steps: (1) the formalization of the problem to be solved in a parametric formal model and (2) the synthesis of the model parameters with a tool. We first describe the problem of the scheduling of a launcher flight control, then we show how this problem can be formalized with parametric stopwatch automata; we then present the results computed by the parametric timed model checker IMITATOR. We enhance our model by taking into consideration the time for switching context, and we compare the results to those obtained by other tools classically used in scheduling.      
### 34.End-to-end speaker diarization with transformer  [ :arrow_down: ](https://arxiv.org/pdf/2112.07463.pdf)
>  Speaker diarization is connected to semantic segmentation in computer vision. Inspired from MaskFormer \cite{cheng2021per} which treats semantic segmentation as a set-prediction problem, we propose an end-to-end approach to predict a set of targets consisting of binary masks, vocal activities and speaker vectors. Our model, which we coin \textit{DiFormer}, is mainly based on a speaker encoder and a feature pyramid network (FPN) module to extract multi-scale speaker features which are then fed into a transformer encoder-decoder to predict a set of diarization targets from learned query embedding. To account for temporal characteristics of speech signal, bidirectional LSTMs are inserted into the mask prediction module to improve temporal consistency. Our model handles unknown number of speakers, speech overlaps, as well as vocal activity detection in a unified way. Experiments on multimedia and meeting datasets demonstrate the effectiveness of our approach.      
### 35.Supervised Learning for Multi Zone Sound Field Reproduction under Harsh Environmental Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2112.07349.pdf)
>  This manuscript presents an approach for multi zone sound field reproduction using supervised learning. Traditional multi zone sound field reproduction methods assume constant speed of sound, neglecting nonlinear effects like wind and temperature stratification. We show how to overcome these restrictions using supervised learning of transfer functions. The quality of the solution is measured by the acoustic contrast and the reproduction error. Our results show that for the chosen setup, even with relatively small wind speeds, the acoustic contrast and reproduction error can be improved by up to 16 dB, when wind is considered in the trained model.      
### 36.Automatic COVID-19 disease diagnosis using 1D convolutional neural network and augmentation with human respiratory sound based on parameters: cough, breath, and voice  [ :arrow_down: ](https://arxiv.org/pdf/2112.07285.pdf)
>  The issue in respiratory sound classification has attained good attention from the clinical scientists and medical researcher's group in the last year to diagnosing COVID-19 disease. To date, various models of Artificial Intelligence (AI) entered into the real-world to detect the COVID-19 disease from human-generated sounds such as voice/speech, cough, and breath. The Convolutional Neural Network (CNN) model is implemented for solving a lot of real-world problems on machines based on Artificial Intelligence (AI). In this context, one dimension (1D) CNN is suggested and implemented to diagnose respiratory diseases of COVID-19 from human respiratory sounds such as a voice, cough, and breath. An augmentation-based mechanism is applied to improve the preprocessing performance of the COVID-19 sounds dataset and to automate COVID-19 disease diagnosis using the 1D convolutional network. Furthermore, a DDAE (Data De-noising Auto Encoder) technique is used to generate deep sound features such as the input function to the 1D CNN instead of adopting the standard input of MFCC (Mel-frequency cepstral coefficient), and it is performed better accuracy and performance than previous models.      
### 37.Progressive Feature Transmission for Split Inference at the Wireless Edge  [ :arrow_down: ](https://arxiv.org/pdf/2112.07244.pdf)
>  In edge inference, an edge server provides remote-inference services to edge devices. This requires the edge devices to upload high-dimensional features of data samples over resource-constrained wireless channels, which creates a communication bottleneck. The conventional solution of feature pruning requires that the device has access to the inference model, which is unavailable in the current scenario of split inference. To address this issue, we propose the progressive feature transmission (ProgressFTX) protocol, which minimizes the overhead by progressively transmitting features until a target confidence level is reached. The optimal control policy of the protocol to accelerate inference is derived and it comprises two key operations. The first is importance-aware feature selection at the server, for which it is shown to be optimal to select the most important features, characterized by the largest discriminant gains of the corresponding feature dimensions. The second is transmission-termination control by the server for which the optimal policy is shown to exhibit a threshold structure. Specifically, the transmission is stopped when the incremental uncertainty reduction by further feature transmission is outweighed by its communication cost. The indices of the selected features and transmission decision are fed back to the device in each slot. The optimal policy is first derived for the tractable case of linear classification and then extended to the more complex case of classification using a convolutional neural network. Both Gaussian and fading channels are considered. Experimental results are obtained for both a statistical data model and a real dataset. It is seen that ProgressFTX can substantially reduce the communication latency compared to conventional feature pruning and random feature transmission.      
### 38.On the Impact of Channel Estimation on the Design and Analysis of IRSA based Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.07242.pdf)
>  Irregular repetition slotted aloha (IRSA) is a distributed grant-free random access protocol where users transmit multiple replicas of their packets to a base station (BS). The BS recovers the packets using successive interference cancellation. In this paper, we first derive channel estimates for IRSA, exploiting the sparsity structure of IRSA transmissions, when non-orthogonal pilots are employed across users to facilitate channel estimation at the BS. Allowing for the use of non-orthogonal pilots is important, as the length of orthogonal pilots scales linearly with the total number of devices, leading to prohibitive overhead as the number of devices increases. Next, we present a novel analysis of the throughput of IRSA under practical channel estimation errors, with the use of multiple antennas at the BS. Finally, we theoretically characterize the asymptotic throughput performance of IRSA using a density evolution based analysis. Simulation results underline the importance of accounting for channel estimation errors in analyzing IRSA, which can even lead to 70% loss in performance in severely interference-limited regimes. We also provide novel insights on the effect of parameters such as pilot length, SNR, number of antennas at the BS, etc, on the system throughput.      
### 39.Structure-Exploiting Newton-Type Method for Optimal Control of Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.07232.pdf)
>  This study proposes an efficient Newton-type method for the optimal control of switched systems under a given mode sequence. A mesh-refinement-based approach is utilized to discretize continuous-time optimal control problems (OCPs) using the direct multiple-shooting method to formulate a nonlinear program (NLP), which guarantees the local convergence of a Newton-type method. A dedicated structure-exploiting algorithm (Riccati recursion) is proposed that efficiently performs a Newton-type method for the NLP because its sparsity structure is different from a standard OCP. The proposed method computes each Newton step with linear time-complexity for the total number of discretization grids as the standard Riccati recursion algorithm. Additionally, it can always solve the Karush-Kuhn-Tucker (KKT) systems arising in the Newton-type method if the solution is sufficiently close to a local minimum. Conversely, general quadratic programming (QP) solvers cannot accomplish this because the Hessian matrix is inherently indefinite. Moreover, a modification on the reduced Hessian matrix is proposed using the nature of the Riccati recursion algorithm as the dynamic programming for a QP subproblem to enhance the convergence. A numerical comparison is conducted with off-the-shelf NLP solvers, which demonstrates that the proposed method is up to two orders of magnitude faster. Whole-body optimal control of quadrupedal gaits is also demonstrated and shows that the proposed method can achieve the whole-body model predictive control (MPC) of robotic systems with rigid contacts.      
### 40.Noise Reduction and Driving Event Extraction Method for Performance Improvement on Driving Noise-based Surface Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.07214.pdf)
>  Foreign substances on the road surface, such as rainwater or black ice, reduce the friction between the tire and the surface. The above situation will reduce the braking performance and make difficult to control the vehicle body posture. In that case, there is a possibility of property damage at least. In the worst case, personal damage will be occured. To avoid this problem, a road anomaly detection model is proposed based on vehicle driving noise. However, the prior proposal does not consider the extra noise, mixed with driving noise, and skipping calculations for moments without vehicle driving. In this paper, we propose a simple driving event extraction method and noise reduction method for improving computational efficiency and anomaly detection performance.      
### 41.Cross-modal Music Emotion Recognition Using Composite Loss-based Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2112.07192.pdf)
>  Most music emotion recognition approaches use one-way classification or regression that estimates a general emotion from a distribution of music samples, but without considering emotional variations (e.g., happiness can be further categorised into much, moderate or little happiness). We propose a cross-modal music emotion recognition approach that associates music samples with emotions in a common space by considering both of their general and specific characteristics. Since the association of music samples with emotions is uncertain due to subjective human perceptions, we compute composite loss-based embeddings obtained to maximise two statistical characteristics, one being the correlation between music samples and emotions based on canonical correlation analysis, and the other being a probabilistic similarity between a music sample and an emotion with KL-divergence. Experiments on two benchmark datasets demonstrate the superiority of our approach over one-way baselines. In addition, detailed analysis show that our approach can accomplish robust cross-modal music emotion recognition that not only identifies music samples matching with a specific emotion but also detects emotions expressed in a certain music sample.      
### 42.Practical Distributed Reception for Wireless Body Area Networks Using Supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.07174.pdf)
>  Medical applications have driven many areas of engineering to optimize diagnostic capabilities and convenience. In the near future, wireless body area networks (WBANs) are expected to have widespread impact in medicine. To achieve this impact, however, significant advances in research are needed to cope with the changes of the human body's state, which make coherent communications difficult or even impossible. In this paper, we consider a realistic noncoherent WBAN system model where transmissions and receptions are conducted without any channel state information due to the fast-varying channels of the human body. Using distributed reception, we propose several symbol detection approaches where on-off keying (OOK) modulation is exploited, among which a supervised-learning-based approach is developed to overcome the noncoherent system issue. Through simulation results, we compare and verify the performance of the proposed techniques for noncoherent WBANs with OOK transmissions. We show that the well-defined detection techniques with a supervised-learning-based approach enable robust communications for noncoherent WBAN systems.      
### 43.Explore Long-Range Context feature for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2112.07134.pdf)
>  Capturing long-range dependency and modeling long temporal contexts is proven to benefit speaker verification tasks. In this paper, we propose the combination of the Hierarchical-Split block(HS-block) and the Depthwise Separable Self-Attention(DSSA) module to capture richer multi-range context speaker features from a local and global perspective respectively. Specifically, the HS-block splits the feature map and filters into several groups and stacks them in one block, which enlarges the receptive fields(RFs) locally. The DSSA module improves the multi-head self-attention mechanism by the depthwise-separable strategy and explicit sparse attention strategy to model the pairwise relations globally and captures effective long-range dependencies in each channel. Experiments are conducted on the Voxceleb and SITW. Our best system achieves 1.27% EER on the Voxceleb1 test set and 1.56% on SITW by applying the combination of HS-block and DSSA module.      
### 44.Minimal controllability problem on linear structural descriptor systems with forbidden nodes  [ :arrow_down: ](https://arxiv.org/pdf/2112.07124.pdf)
>  We consider a minimal controllability problem (MCP), which determines the minimum number of input nodes for a descriptor system to be structurally controllable. We discuss the "forbidden nodes" of descriptor systems, which cannot be connected to inputs. The three main results of this work are as follows. First, we show a solvability for the MCP with forbidden nodes using graph theory such as a bipartite graph and its Dulmage--Mendelsohn decomposition. Next, we derive the optimal value of the MCP with forbidden nodes. The optimal value is determined by an optimal solution for constrained maximum matching, and this result includes that of the standard MCP in the previous work. Finally, we provide an efficient algorithm for solving the MCP with forbidden nodes based on an alternating path algorithm.      
### 45.Recognition of Tactile-related EEG Signals Generated by Self-touch  [ :arrow_down: ](https://arxiv.org/pdf/2112.07123.pdf)
>  Touch is the first sense among human senses. Not only that, but it is also one of the most important senses that are indispensable. However, compared to sight and hearing, it is often neglected. In particular, since humans use the tactile sense of the skin to recognize and manipulate objects, without tactile sensation, it is very difficult to recognize or skillfully manipulate objects. In addition, the importance and interest of haptic technology related to touch are increasing with the development of technologies such as VR and AR in recent years. So far, the focus is only on haptic technology based on mechanical devices. Especially, there are not many studies on tactile sensation in the field of brain-computer interface based on EEG. There have been some studies that measured the surface roughness of artificial structures in relation to EEG-based tactile sensation. However, most studies have used passive contact methods in which the object moves, while the human subject remains still. Additionally, there have been no EEG-based tactile studies of active skin touch. In reality, we directly move our hands to feel the sense of touch. Therefore, as a preliminary study for our future research, we collected EEG signals for tactile sensation upon skin touch based on active touch and compared and analyzed differences in brain changes during touch and movement tasks. Through time-frequency analysis and statistical analysis, significant differences in power changes in alpha, beta, gamma, and high-gamma regions were observed. In addition, major spatial differences were observed in the sensory-motor region of the brain.      
### 46.Dynamic Coherence-Based EM Ray Tracing Simulations in Vehicular Environments  [ :arrow_down: ](https://arxiv.org/pdf/2112.07115.pdf)
>  5G applications have become increasingly popular in recent years as the spread of 5G network deployment has grown. For vehicular networks, mmWave band signals have been well studied and used for communication and sensing. In this work, we propose a new dynamic ray tracing algorithm that exploits spatial and temporal coherence. We evaluate the performance by comparing the results on typical vehicular communication scenarios with NYUSIM, which builds on stochastic models, and Winprop, which utilizes the deterministic model for simulations with given environment information. We compare the performance of our algorithm on complex, urban models and observe the reduction in computation time by 60% compared to NYUSIM and 30% compared to Winprop, while maintaining similar prediction accuracy.      
### 47.Heuristic Hyperparameter Optimization for Convolutional Neural Networks using Genetic Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2112.07087.pdf)
>  In recent years, people from all over the world are suffering from one of the most severe diseases in history, known as Coronavirus disease 2019, COVID-19 for short. When the virus reaches the lungs, it has a higher probability to cause lung pneumonia and sepsis. X-ray image is a powerful tool in identifying the typical features of the infection for COVID-19 patients. The radiologists and pathologists observe that ground-glass opacity appears in the chest X-ray for infected patient \cite{cozzi2021ground}, and it could be used as one of the criteria during the diagnosis process. In the past few years, deep learning has proven to be one of the most powerful methods in the field of image classification. Due to significant differences in Chest X-Ray between normal and infected people \cite{rousan2020chest}, deep models could be used to identify the presence of the disease given a patient's Chest X-Ray. Many deep models are complex, and it evolves with lots of input parameters. Designers sometimes struggle with the tuning process for deep models, especially when they build up the model from scratch. Genetic Algorithm, inspired by the biological evolution process, plays a key role in solving such complex problems. In this paper, I proposed a genetic-based approach to optimize the Convolutional Neural Network(CNN) for the Chest X-Ray classification task.      
### 48.Real-Time Neural Voice Camouflage  [ :arrow_down: ](https://arxiv.org/pdf/2112.07076.pdf)
>  Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping. We propose a method to camouflage a person's voice over-the-air from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive attacks, which achieve real-time performance by forecasting the attack that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 4.17x more than baselines as measured through word error rate, and 7.27x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments over physical distances.      
### 49.Event Based Time-Vectors for auditory features extraction: a neuromorphic approach for low power audio recognition  [ :arrow_down: ](https://arxiv.org/pdf/2112.07011.pdf)
>  In recent years tremendous efforts have been done to advance the state of the art for Natural Language Processing (NLP) and audio recognition. However, these efforts often translated in increased power consumption and memory requirements for bigger and more complex models. These solutions falls short of the constraints of IoT devices which need low power, low memory efficient computation, and therefore they fail to meet the growing demand of efficient edge computing. Neuromorphic systems have proved to be excellent candidates for low-power low-latency computation in a multitude of applications. For this reason we present a neuromorphic architecture, capable of unsupervised auditory feature recognition. We then validate the network on a subset of Google's Speech Commands dataset.      
### 50.Control-Oriented Modeling of Pipe Flow through Intersecting Pipe Geometries  [ :arrow_down: ](https://arxiv.org/pdf/2112.06974.pdf)
>  We present control-oriented models for transient dynamics of isothermal one-dimensional gas flow through multiple pipes in series and intersecting pipe geometries. These composite models subsume algebraic constraints that would otherwise appear due to boundary conditions, so that our linear state-space models are well-suited for model-based control design for gas flow in pipe networks with non-trivial geometries.      
### 51.Decoding High-level Imagined Speech using Attention-based Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.06922.pdf)
>  Brain-computer interface (BCI) is the technology that enables the communication between humans and devices by reflecting status and intentions of humans. When conducting imagined speech, the users imagine the pronunciation as if actually speaking. In the case of decoding imagined speech-based EEG signals, complex task can be conducted more intuitively, but decoding performance is lower than that of other BCI paradigms. We modified our previous model for decoding imagined speech-based EEG signals. Ten subjects participated in the experiment. The average accuracy of our proposed method was 0.5648 for classifying four words. In other words, our proposed method has significant strength in learning local features. Hence, we demonstrated the feasibility of decoding imagined speech-based EEG signals with robust performance.      
### 52.Boosting Independent Component Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2112.06920.pdf)
>  Independent component analysis is intended to recover the unknown components as independent as possible from their linear mixtures. This technique has been widely used in many fields, such as data analysis, signal processing, and machine learning. In this paper, we present a novel boosting-based algorithm for independent component analysis. Our algorithm fills the gap in the nonparametric independent component analysis by introducing boosting to maximum likelihood estimation. A variety of experiments validate its performance compared with many of the presently known algorithms.      
### 53.Early Stopping for Deep Image Prior  [ :arrow_down: ](https://arxiv.org/pdf/2112.06074.pdf)
>  Deep image prior (DIP) and its variants have showed remarkable potential for solving inverse problems in computer vision, without any extra training data. Practical DIP models are often substantially overparameterized. During the fitting process, these models learn mostly the desired visual content first, and then pick up the potential modeling and observational noise, i.e., overfitting. Thus, the practicality of DIP often depends critically on good early stopping (ES) that captures the transition period. In this regard, the majority of DIP works for vision tasks only demonstrates the potential of the models -- reporting the peak performance against the ground truth, but provides no clue about how to operationally obtain near-peak performance without access to the groundtruth. In this paper, we set to break this practicality barrier of DIP, and propose an efficient ES strategy, which consistently detects near-peak performance across several vision tasks and DIP variants. Based on a simple measure of dispersion of consecutive DIP reconstructions, our ES method not only outpaces the existing ones -- which only work in very narrow domains, but also remains effective when combined with a number of methods that try to mitigate the overfitting. The code is available at <a class="link-external link-https" href="https://github.com/sun-umn/Early_Stopping_for_DIP" rel="external noopener nofollow">this https URL</a>.      
### 54.Multiscale Fractal Analysis on EEG Signals for Music-Induced Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.16310.pdf)
>  Emotion Recognition from EEG signals has long been researched as it can assist numerous medical and rehabilitative applications. However, their complex and noisy structure has proven to be a serious barrier for traditional modeling methods. In this paper, we employ multifractal analysis to examine the behavior of EEG signals in terms of presence of fluctuations and the degree of fragmentation along their major frequency bands, for the task of emotion recognition. In order to extract emotion-related features we utilize two novel algorithms for EEG analysis, based on Multiscale Fractal Dimension and Multifractal Detrended Fluctuation Analysis. The proposed feature extraction methods perform efficiently, surpassing some widely used baseline features on the competitive DEAP dataset, indicating that multifractal analysis could serve as basis for the development of robust models for affective state recognition.      
