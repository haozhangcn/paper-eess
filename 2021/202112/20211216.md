# ArXiv eess --Thu, 16 Dec 2021
### 1.Analysis of the Operation of Industrial Trucks based on Position Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.08258.pdf)
>  Indoor positioning systems (IPSs) can make an important contribution to the analysis and optimization of internal transport processes. The overall aim of this work is to examine how position data can be used to analyze the operation of industrial trucks in warehouses. This is achieved by developing a concept for the analysis of industrial truck operations based merely on position data. The concept consists of a signal processing scheme to derive kinematic data and three analysis methods - Monitoring, Area analysis, and Motion analysis. Schemes for the signal processing and detection of motion events were developed and implemented as part of the TrOpLocerApp (Truck Operation Localization Analyzer-Application) for recording, displaying, and processing position data, according to the proposed system concept. The TrOpLocer-App source code is published on GitLab. Different filter algorithms were examined, as part of the signal processing scheme, from which the low pass Butterworth filter has shown the best results in static experiments. Validation of the motion detection scheme shows good detection quality for distinct events in a realistic movement experiment.      
### 2.RA V-Net: Deep learning network for automated liver segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.08232.pdf)
>  Accurate segmentation of the liver is a prerequisite for the diagnosis of disease. Automated segmentation is an important application of computer-aided detection and diagnosis of liver disease. In recent years, automated processing of medical images has gained breakthroughs. However, the low contrast of abdominal scan CT images and the complexity of liver morphology make accurate automatic segmentation challenging. In this paper, we propose RA V-Net, which is an improved medical image automatic segmentation model based on U-Net. It has the following three main innovations. CofRes Module (Composite Original Feature Residual Module) is proposed. With more complex convolution layers and skip connections to make it obtain a higher level of image feature extraction capability and prevent gradient disappearance or explosion. AR Module (Attention Recovery Module) is proposed to reduce the computational effort of the model. In addition, the spatial features between the data pixels of the encoding and decoding modules are sensed by adjusting the channels and LSTM convolution. Finally, the image features are effectively retained. CA Module (Channel Attention Module) is introduced, which used to extract relevant channels with dependencies and strengthen them by matrix dot product, while weakening irrelevant channels without dependencies. The purpose of channel attention is achieved. The attention mechanism provided by LSTM convolution and CA Module are strong guarantees for the performance of the neural network. The accuracy of U-Net network: 0.9862, precision: 0.9118, DSC: 0.8547, JSC: 0.82. The evaluation metrics of RA V-Net, accuracy: 0.9968, precision: 0.9597, DSC: 0.9654, JSC: 0.9414. The most representative metric for the segmentation effect is DSC, which improves 0.1107 over U-Net, and JSC improves 0.1214.      
### 3.Inverse Optimal Safety Filters  [ :arrow_down: ](https://arxiv.org/pdf/2112.08225.pdf)
>  CBF-QP safety filters are pointwise minimizers of the control effort at a given state vector, i.e., myopically optimal at each time instant. But are they optimal over the entire infinite time horizon? What does it even mean for a controlled dynamic systems to be "optimally safe" as opposed to, conventionally "optimally stable"? When disturbances, deterministic and stochastic, have unknown upper bounds, how should safety be defined to allow a graceful degradation under disturbances? Can safety filters be designed to guarantee such weaker safety properties as well as the optimality of safety over the infinite time horizon? We pose and answer these questions for general systems affine in control and disturbances and illustrate the answers using several examples. In the process, using the existing QP safety filters, as well as more general safety-ensuring feedbacks, we generate entire families of safety filters which are optimal over the infinite horizon though they are conservative (favoring safety over `alertness') relative to the standard QP.      
### 4.Guaranteed Contraction Control in the Presence of Imperfectly Learned Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2112.08222.pdf)
>  This paper presents an approach for trajectory-centric learning control based on contraction metrics and disturbance estimation for nonlinear systems subject to matched uncertainties. The approach allows for the use of a broad class of model learning tools including deep neural networks to learn uncertain dynamics while still providing guarantees of transient tracking performance throughout the learning phase, including the special case of no learning. Within the proposed approach, a disturbance estimation law is proposed to estimate the pointwise value of the uncertainty, with pre-computable estimation error bounds (EEBs). The learned dynamics, the estimated disturbances, and the EEBs are then incorporated in a robust Riemannian energy condition to compute the control law that guarantees exponential convergence of actual trajectories to desired ones throughout the learning phase, even when the learned model is poor. On the other hand, with improved accuracy, the learned model can be incorporated in a high-level planner to plan better trajectories with improved performance, e.g., lower energy consumption and shorter travel time. The proposed framework is validated on a planar quadrotor navigation example.      
### 5.Boosting Neural Image Compression for Machines Using Latent Space Masking  [ :arrow_down: ](https://arxiv.org/pdf/2112.08168.pdf)
>  Today, many image coding scenarios do not have a human as final intended user, but rather a machine fulfilling computer vision tasks on the decoded image. Thereby, the primary goal is not to keep visual quality but maintain the task accuracy of the machine for a given bitrate. Due to the tremendous progress of deep neural networks setting benchmarking results, mostly neural networks are employed to solve the analysis tasks at the decoder side. Moreover, neural networks have also found their way into the field of image compression recently. These two developments allow for an end-to-end training of the neural compression network for an analysis network as information sink. Therefore, we first roll out such a training with a task-specific loss to enhance the coding performance of neural compression networks. Compared to the standard VVC, 41.4 % of bitrate are saved by this method for Mask R-CNN as analysis network on the uncompressed Cityscapes dataset. As a main contribution, we propose LSMnet, a network that runs in parallel to the encoder network and masks out elements of the latent space that are presumably not required for the analysis network. By this approach, additional 27.3 % of bitrate are saved compared to the basic neural compression network optimized with the task loss. In addition, we propose a feature-based loss, which allows for a training without annotated data. We provide extensive analyses on the Cityscapes dataset including cross-evaluation with different analysis networks and present exemplary visual results.      
### 6.Generalized Difference Coder: A Novel Conditional Autoencoder Structure for Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2112.08011.pdf)
>  Motion compensated inter prediction is a common component of all video coders. The concept was established in traditional hybrid coding and successfully transferred to learning-based video compression. To compress the residual signal after prediction, usually the difference of the two signals is compressed using a standard autoencoder. However, information theory tells us that a general conditional coder is more efficient. In this paper, we provide a solid foundation based on information theory and Shannon entropy to show the potentials but also the limits of conditional coding. Building on those results, we then propose the generalized difference coder, a special case of a conditional coder designed to avoid limiting bottlenecks. With this coder, we are able to achieve average rate savings of 27.8% compared to a standard autoencoder, by only adding a moderate complexity overhead of less than 7%.      
### 7.Data-Driven Models for Control Engineering Applications Using the Koopman Operator  [ :arrow_down: ](https://arxiv.org/pdf/2112.07983.pdf)
>  Within this work, we investigate how data-driven numerical approximation methods of the Koopman operator can be used in practical control engineering applications. We refer to the method Extended Dynamic Mode Decomposition (EDMD), which approximates a nonlinear dynamical system as a linear model. This makes the method ideal for control engineering applications, because a linear system description is often assumed for this purpose. Using academic examples, we simulatively analyze the prediction performance of the learned EDMD models and show how relevant system properties like stability, controllability, and observability are reflected by the EDMD model, which is a critical requirement for a successful control design process. Subsequently, we present our experimental results on a mechatronic test bench and evaluate the applicability to the control engineering design process. As a result, the investigated methods are suitable as a low-effort alternative for the design steps of model building and adaptation in the classical model-based controller design method.      
### 8.RawNeXt: Speaker verification system for variable-duration utterances with deep layer aggregation and extended dynamic scaling policies  [ :arrow_down: ](https://arxiv.org/pdf/2112.07935.pdf)
>  Despite achieving satisfactory performance in speaker verification using deep neural networks, variable-duration utterances remain a challenge that threatens the robustness of systems. To deal with this issue, we propose a speaker verification system called RawNeXt that can handle input raw waveforms of arbitrary length by employing the following two components: (1) A deep layer aggregation strategy enhances speaker information by iteratively and hierarchically aggregating features of various time scales and spectral channels output from blocks. (2) An extended dynamic scaling policy flexibly processes features according to the length of the utterance by selectively merging the activations of different resolution branches in each block. Owing to these two components, our proposed model can extract speaker embeddings rich in time-spectral information and operate dynamically on length variations. Experimental results on the VoxCeleb1 test set consisting of various duration utterances demonstrate that RawNeXt achieves state-of-the-art performance compared to the recently proposed systems. Our code and trained model weights are available at <a class="link-external link-https" href="https://github.com/wngh1187/RawNeXt" rel="external noopener nofollow">this https URL</a>.      
### 9.Energy-Efficient Real-Time Heart Monitoring on Edge-Fog-Cloud Internet-of-Medical-Things  [ :arrow_down: ](https://arxiv.org/pdf/2112.07901.pdf)
>  The recent developments in wearable devices and the Internet of Medical Things (IoMT) allow real-time monitoring and recording of electrocardiogram (ECG) signals. However, continuous monitoring of ECG signals is challenging in low-power wearable devices due to energy and memory constraints. Therefore, in this paper, we present a novel and energy-efficient methodology for continuously monitoring the heart for low-power wearable devices. The proposed methodology is composed of three different layers: 1) a Noise/Artifact detection layer to grade the quality of the ECG signals; 2) a Normal/Abnormal beat classification layer to detect the anomalies in the ECG signals, and 3) an Abnormal beat classification layer to detect diseases from ECG signals. Moreover, a distributed multi-output Convolutional Neural Network (CNN) architecture is used to decrease the energy consumption and latency between the edge-fog/cloud. Our methodology reaches an accuracy of 99.2% on the well-known MIT-BIH Arrhythmia dataset. Evaluation on real hardware shows that our methodology is suitable for devices having a minimum RAM of 32KB. Moreover, the proposed methodology achieves $7\times$ more energy efficiency compared to state-of-the-art works.      
### 10.Fast Computation of Generalized Eigenvectors for Manifold Graph Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2112.07862.pdf)
>  Our goal is to efficiently compute low-dimensional latent coordinates for nodes in an input graph -- known as graph embedding -- for subsequent data processing such as clustering. Focusing on finite graphs that are interpreted as uniformly samples on continuous manifolds (called manifold graphs), we leverage existing fast extreme eigenvector computation algorithms for speedy execution. We first pose a generalized eigenvalue problem for sparse matrix pair $(\A,\B)$, where $\A = Ł- \mu \Q + \epsilon \I$ is a sum of graph Laplacian $Ł$ and disconnected two-hop difference matrix $\Q$. Eigenvector $\v$ minimizing Rayleigh quotient $\frac{\v^{\top} \A \v}{\v^{\top} \v}$ thus minimizes $1$-hop neighbor distances while maximizing distances between disconnected $2$-hop neighbors, preserving graph structure. Matrix $\B = \text{diag}(\{\b_i\})$ that defines eigenvector orthogonality is then chosen so that boundary / interior nodes in the sampling domain have the same generalized degrees. $K$-dimensional latent vectors for the $N$ graph nodes are the first $K$ generalized eigenvectors for $(\A,\B)$, computed in $\cO(N)$ using LOBPCG, where $K \ll N$. Experiments show that our embedding is among the fastest in the literature, while producing the best clustering performance for manifold graphs.      
### 11.A Predictive Online Transient Stability Assessment with Hierarchical Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.07840.pdf)
>  Online transient stability assessment (TSA) is essential for secure and stable power system operations. The growing number of Phasor Measurement Units (PMUs) brings about massive sources of data that can enhance online TSA. However, conventional data-driven methods require large amounts of transient data to correctly assess the transient stability state of a system. In this paper, a new data-driven TSA approach is developed for TSA with fewer data compared to the conventional methods. The data reduction is enabled by learning the dynamic behaviors of the historical transient data using generative and adversarial networks (GAN). This knowledge is used online to predict the voltage time series data after a transient event. A classifier embedded in the generative network deploys the predicted post-contingency data to determine the stability of the system following a fault. The developed GAN-based TSA approach preserves the spatial and temporal correlations that exist in multivariate PMU time series data. Hence, in comparison with the state-of-the-art TSA methods, it achieves a higher assessment accuracy using only one sample of the measured data and a shorter response time. Case studies conducted on the IEEE 118-bus system demonstrate the superior performance of the GAN-based method compared to the conventional data-driven techniques.      
### 12.On Recursive State Estimation for Linear State-Space Models Having Quantized Output Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.07828.pdf)
>  In this paper, we study the problem of estimating the state of a dynamic state-space system where the output is subject to quantization. We compare some classical approaches and a new development in the literature to obtain the filtering and smoothing distributions of the state conditioned to quantized data. The classical approaches include the Extended Kalman filter/smoother in which we consider an approximation of the quantizer non-linearity based on the arctan function, the quantized Kalman filter/smoother, the Unscented Kalman filter/smoother, and the Sequential Monte Carlo sampling method also called particle filter/smoother. We consider a new approach based on the Gaussian sum filter/smoother where the probability mass function of the quantized data given the state is modeled as an integral equation and approximated using Gauss-Legendre quadrature. The Particle filter is addressed considering some resampling methods used to deal with the degeneracy problem. Also, the sample impoverishment caused by the resampling method is addressed by introducing diversity in the samples set using the Markov Chain Monte Carlo method. In this paper, we discuss the implementation of the aforementioned algorithms and the Particle filter/smoother implementation is studied by using different resampling methods combined with two Markov Chain algorithms. A numerical simulation is presented to analyze the accuracy of the estimation and the computational cost.      
### 13.TAFA: Design Automation of Analog Mixed-Signal FIR Filters Using Time Approximation Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2112.07825.pdf)
>  A digital finite impulse response (FIR) filter design is fully synthesizable, thanks to the mature CAD support of digital circuitry. On the contrary, analog mixed-signal (AMS) filter design is mostly a manual process, including architecture selection, schematic design, and layout. This work presents a systematic design methodology to automate AMS FIR filter design using a time approximation architecture without any tunable passive component, such as switched capacitor or resistor. It not only enhances the flexibility of the filter but also facilitates design automation with reduced analog complexity. The proposed design flow features a hybrid approximation scheme that automatically optimize the filter's impulse response in light of time quantization effects, which shows significant performance improvement with minimum designer's efforts in the loop. Additionally, a layout-aware regression model based on an artificial neural network (ANN), in combination with gradient-based search algorithm, is used to automate and expedite the filter design. With the proposed framework, we demonstrate rapid synthesis of AMS FIR filters in 65nm process from specification to layout.      
### 14.Learning Rigidity-based Flocking Control with Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2112.07779.pdf)
>  Flocking control of multi-agents system is challenging for agents with partially unknown dynamics. This paper proposes an online learning-based controller to stabilize flocking motion of double-integrator agents with additional unknown nonlinear dynamics by using Gaussian processes (GP). Agents interaction is described by a time-invariant infinitesimally minimally rigid undirected graph. We provide a decentralized control law that exponentially stabilizes the motion of the agents and captures Reynolds boids motion for swarms by using GPs as an online learning-based oracle for the prediction of the unknown dynamics. In particular the presented approach guarantees a probabilistic bounded tracking error with high probability.      
### 15.Nonlinear Discrete-time Systems' Identification without Persistence of Excitation: A Finite-time Concurrent Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.07765.pdf)
>  This paper deals with the problem of finite-time learning for unknown discrete-time nonlinear systems' dynamics, without the requirement of the persistence of excitation. A finite-time concurrent learning approach is presented to approximate the uncertainties of the discrete-time nonlinear systems in an on-line fashion by employing current data along with recorded experienced data satisfying an easy-to-check rank condition on the richness of the recorded data which is less restrictive in comparison with persistence of excitation condition. Rigorous proofs guarantee the finite-time convergence of the estimated parameters to their optimal values based on a discrete-time Lyapunov analysis. Compared with the existing work in the literature, simulation results illustrate that the proposed method can timely and precisely approximate the uncertainties.      
### 16.Ghost Image Processing  [ :arrow_down: ](https://arxiv.org/pdf/2112.07671.pdf)
>  In computational ghost imaging the object is illuminated with a sequence of known patterns, and the scattered light is collected using a detector that has no spatial resolution. Using those patterns and the total intensity measurement from the detector, one can reconstruct the desired image. Here we study how the reconstructed image is modified if the patterns used for the reconstruction are not the same as the illumination patterns, and show that one can choose how to illuminate the object, such that the reconstruction process behaves like a spatial filtering operation on the image. The ability to measure directly a processed image, allows one to bypass the post-processing steps, and thus avoid any noise amplification they imply. As a simple example we show the case of an edge-detection filter.      
### 17.Textless Speech-to-Speech Translation on Real Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.08352.pdf)
>  We present a textless speech-to-speech translation (S2ST) system that can translate speech from one language into another language and can be built without the need of any text data. Different from existing work in the literature, we tackle the challenge in modeling multi-speaker target speech and train the systems with real-world S2ST data. The key to our approach is a self-supervised unit-based speech normalization technique, which finetunes a pre-trained speech encoder with paired audios from multiple speakers and a single reference speaker to reduce the variations due to accents, while preserving the lexical content. With only 10 minutes of paired data for speech normalization, we obtain on average 3.2 BLEU gain when training the S2ST model on the \vp~S2ST dataset, compared to a baseline trained on un-normalized speech target. We also incorporate automatically mined S2ST data and show an additional 2.0 BLEU gain. To our knowledge, we are the first to establish a textless S2ST technique that can be trained with real-world data and works for multiple language pairs.      
### 18.On the optimal consensus of crab submarines in one dimension  [ :arrow_down: ](https://arxiv.org/pdf/2112.08220.pdf)
>  We consider the problem of computing the optimal meeting point of a set of N crab submarines. First, we analyze the case where the submarines are allowed any position on the real line: we provide a constructive proof of optimality and we use it to provide a linear-time algorithm to find the optimal meeting point. Second, we use the results for the continuous case to solve the case where the crab submarines are restricted to integer locations: we show that, given the solution of the corresponding continuous problem, we can find the optimal integer solution in linear time.      
### 19.ST-MTL: Spatio-Temporal Multitask Learning Model to Predict Scanpath While Tracking Instruments in Robotic Surgery  [ :arrow_down: ](https://arxiv.org/pdf/2112.08189.pdf)
>  Representation learning of the task-oriented attention while tracking instrument holds vast potential in image-guided robotic surgery. Incorporating cognitive ability to automate the camera control enables the surgeon to concentrate more on dealing with surgical instruments. The objective is to reduce the operation time and facilitate the surgery for both surgeons and patients. We propose an end-to-end trainable Spatio-Temporal Multi-Task Learning (ST-MTL) model with a shared encoder and spatio-temporal decoders for the real-time surgical instrument segmentation and task-oriented saliency detection. In the MTL model of shared parameters, optimizing multiple loss functions into a convergence point is still an open challenge. We tackle the problem with a novel asynchronous spatio-temporal optimization (ASTO) technique by calculating independent gradients for each decoder. We also design a competitive squeeze and excitation unit by casting a skip connection that retains weak features, excites strong features, and performs dynamic spatial and channel-wise feature recalibration. To capture better long term spatio-temporal dependencies, we enhance the long-short term memory (LSTM) module by concatenating high-level encoder features of consecutive frames. We also introduce Sinkhorn regularized loss to enhance task-oriented saliency detection by preserving computational efficiency. We generate the task-aware saliency maps and scanpath of the instruments on the dataset of the MICCAI 2017 robotic instrument segmentation challenge. Compared to the state-of-the-art segmentation and saliency methods, our model outperforms most of the evaluation metrics and produces an outstanding performance in the challenge.      
### 20.Chimpanzee voice prints? Insights from transfer learning experiments from human voices  [ :arrow_down: ](https://arxiv.org/pdf/2112.08165.pdf)
>  Individual vocal differences are ubiquitous in the animal kingdom. In humans, these differences pervade the entire vocal repertoire and constitute a "voice print". Apes, our closest-living relatives, possess individual signatures within specific call types, but the potential for a unique voice print has been little investigated. This is partially attributed to the limitations associated with extracting meaningful features from small data sets. Advances in machine learning have highlighted an alternative to traditional acoustic features, namely pre-trained learnt extractors. Here, we present an approach building on these developments: leveraging a feature extractor based on a deep neural network trained on over 10,000 human voice prints to provide an informative space over which we identify chimpanzee voice prints. We compare our results with those obtained by using traditional acoustic features and discuss the benefits of our methodology and the significance of our findings for the identification of "voice prints" in non-human animals.      
### 21.Composed Physics- and Data-driven System Identification for Non-autonomous Systems in Control Engineering  [ :arrow_down: ](https://arxiv.org/pdf/2112.08148.pdf)
>  In control design most control strategies are model-based and require accurate models to be applied successfully. Due to simplifications and the model-reality-gap physics-derived models frequently exhibit deviations from real-world-systems. Likewise, purely data-driven methods often do not generalise well enough and may violate physical laws. Recently Physics-Guided Neural Networks (PGNN) and physics-inspired loss functions separately have shown promising results to conquer these drawbacks. In this contribution we extend existing methods towards the identification of non-autonomous systems and propose a combined approach PGNN-L, which uses a PGNN and a physics-inspired loss term (-L) to successfully identify the system's dynamics, while maintaining the consistency with physical laws. The proposed method is demonstrated on two real-world nonlinear systems and outperforms existing techniques regarding complexity and reliability.      
### 22.Ptychographic sensor for large-scale lensless microbial monitoring with high spatiotemporal resolution  [ :arrow_down: ](https://arxiv.org/pdf/2112.08133.pdf)
>  Traditional microbial detection methods often rely on the overall property of microbial cultures and cannot resolve individual growth event at high spatiotemporal resolution. As a result, they require bacteria to grow to confluence and then interpret the results. Here, we demonstrate the application of an integrated ptychographic sensor for lensless cytometric analysis of microbial cultures over a large scale and with high spatiotemporal resolution. The reported device can be placed within a regular incubator or used as a standalone incubating unit for long-term microbial monitoring. For longitudinal study where massive data are acquired at sequential time points, we report a new temporal-similarity constraint to increase the temporal resolution of ptychographic reconstruction by 7-fold. With this strategy, the reported device achieves a centimeter-scale field of view, a half-pitch spatial resolution of 488 nm, and a temporal resolution of 15-second intervals. For the first time, we report the direct observation of bacterial growth in a 15-second interval by tracking the phase wraps of the recovered images, with high phase sensitivity like that in interferometric measurements. We also characterize cell growth via longitudinal dry mass measurement and perform rapid bacterial detection at low concentrations. For drug-screening application, we demonstrate proof-of-concept antibiotic susceptibility testing and perform single-cell analysis of antibiotic-induced filamentation. The combination of high phase sensitivity, high spatiotemporal resolution, and large field of view is unique among existing microscopy techniques. As a quantitative and miniaturized platform, it can improve studies with microorganisms and other biospecimens at resource-limited settings.      
### 23.Ensuring DNN Solution Feasibility for Optimization Problems with Convex Constraints and Its Application to DC Optimal Power Flow Problems  [ :arrow_down: ](https://arxiv.org/pdf/2112.08091.pdf)
>  Ensuring solution feasibility is a key challenge in developing Deep Neural Network (DNN) schemes for solving constrained optimization problems, due to inherent DNN prediction errors. In this paper, we propose a "preventive learning'" framework to systematically guarantee DNN solution feasibility for problems with convex constraints and general objective functions. We first apply a predict-and-reconstruct design to not only guarantee equality constraints but also exploit them to reduce the number of variables to be predicted by DNN. Then, as a key methodological contribution, we systematically calibrate inequality constraints used in DNN training, thereby anticipating prediction errors and ensuring the resulting solutions remain feasible. We characterize the calibration magnitudes and the DNN size sufficient for ensuring universal feasibility. We propose a new Adversary-Sample Aware training algorithm to improve DNN's optimality performance without sacrificing feasibility guarantee. Overall, the framework provides two DNNs. The first one from characterizing the sufficient DNN size can guarantee universal feasibility while the other from the proposed training algorithm further improves optimality and maintains DNN's universal feasibility simultaneously. We apply the preventive learning framework to develop DeepOPF+ for solving the essential DC optimal power flow problem in grid operation. It improves over existing DNN-based schemes in ensuring feasibility and attaining consistent desirable speedup performance in both light-load and heavy-load regimes. Simulation results over IEEE Case-30/118/300 test cases show that DeepOPF+ generates $100\%$ feasible solutions with $&lt;$0.5% optimality loss and up to two orders of magnitude computational speedup, as compared to a state-of-the-art iterative solver.      
### 24.Speech frame implementation for speech analysis and recognition  [ :arrow_down: ](https://arxiv.org/pdf/2112.08027.pdf)
>  Distinctive features of the created speech frame are: the ability to take into account the emotional state of the speaker, sup-port for working with diseases of the speech-forming tract of speakers and the presence of manual segmentation of a num-ber of speech signals. In addition, the system is focused on Russian-language speech material, unlike most analogs.      
### 25.Channel Parameter Estimation in the Presence of Phase Noise Based on Maximum Correntropy Criterion  [ :arrow_down: ](https://arxiv.org/pdf/2112.07955.pdf)
>  Oscillator output generally has phase noise causing the output power spectral density (PSD) to disperse around a Dirac delta function. In this paper, the AWGN channel is considered, where the sent signal accompanying with phase noise is added to the channel Gaussian noise and received at the receiver. Conventional channel estimation algorithms such as least mean square (LMS) and mean MSE criterion are not suitable for this channel estimation. We (i) analyze this phase noise channel estimation with information theoretic learning (ITL) criterion, i.e., maximum correntropy criterion (MCC), leading to robustness in the channel estimator's steady state behavior; and (ii) improve the convergence rate by combining MSE and MCC as a novel mixed-LMS algorithm.      
### 26.Transcoded Video Restoration by Temporal Spatial Auxiliary Network  [ :arrow_down: ](https://arxiv.org/pdf/2112.07948.pdf)
>  In most video platforms, such as Youtube, and TikTok, the played videos usually have undergone multiple video encodings such as hardware encoding by recording devices, software encoding by video editing apps, and single/multiple video transcoding by video application servers. Previous works in compressed video restoration typically assume the compression artifacts are caused by one-time encoding. Thus, the derived solution usually does not work very well in practice. In this paper, we propose a new method, temporal spatial auxiliary network (TSAN), for transcoded video restoration. Our method considers the unique traits between video encoding and transcoding, and we consider the initial shallow encoded videos as the intermediate labels to assist the network to conduct self-supervised attention training. In addition, we employ adjacent multi-frame information and propose the temporal deformable alignment and pyramidal spatial fusion for transcoded video restoration. The experimental results demonstrate that the performance of the proposed method is superior to that of the previous techniques. The code is available at <a class="link-external link-https" href="https://github.com/icecherylXuli/TSAN" rel="external noopener nofollow">this https URL</a>.      
### 27.DRaGon: Mining Latent Radio Channel Information from Geographical Data Leveraging Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.07941.pdf)
>  Radio channel modeling is one of the most fundamental aspects in the process of designing, optimizing, and simulating wireless communication networks. In this field, long-established approaches such as analytical channel models and ray tracing techniques represent the de-facto standard methodologies. However, as demonstrated by recent results, there remains an untapped potential to innovate this research field by enriching model-based approaches with machine learning techniques. In this paper, we present Deep RAdio channel modeling from GeOinformatioN (DRaGon) as a novel machine learning-enabled method for automatic generation of Radio Environmental Maps (REMs) from geographical data. For achieving accurate path loss prediction results, DRaGon combines determining features extracted from a three-dimensional model of the radio propagation environment with raw images of the receiver area within a deep learning model. In a comprehensive performance evaluation and validation campaign, we compare the accuracy of the proposed approach with real world measurements, ray tracing analyses, and well-known channel models. It is found that the combination of expert knowledge from the communications domain and the data analysis capabilities of deep learning allows to achieve a significantly higher prediction accuracy than the reference methods.      
### 28.The exploitation of Multiple Feature Extraction Techniques for Speaker Identification in Emotional States under Disguised Voices  [ :arrow_down: ](https://arxiv.org/pdf/2112.07940.pdf)
>  Due to improvements in artificial intelligence, speaker identification (SI) technologies have brought a great direction and are now widely used in a variety of sectors. One of the most important components of SI is feature extraction, which has a substantial impact on the SI process and performance. As a result, numerous feature extraction strategies are thoroughly investigated, contrasted, and analyzed. This article exploits five distinct feature extraction methods for speaker identification in disguised voices under emotional environments. To evaluate this work significantly, three effects are used: high-pitched, low-pitched, and Electronic Voice Conversion (EVC). Experimental results reported that the concatenated Mel-Frequency Cepstral Coefficients (MFCCs), MFCCs-delta, and MFCCs-delta-delta is the best feature extraction method.      
### 29.Zero-shot Audio Source Separation through Query-based Learning from Weakly-labeled Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.07891.pdf)
>  Deep learning techniques for separating audio into different sound sources face several challenges. Standard architectures require training separate models for different types of audio sources. Although some universal separators employ a single model to target multiple sources, they have difficulty generalizing to unseen sources. In this paper, we propose a three-component pipeline to train a universal audio source separator from a large, but weakly-labeled dataset: AudioSet. First, we propose a transformer-based sound event detection system for processing weakly-labeled training data. Second, we devise a query-based audio separation model that leverages this data for model training. Third, we design a latent embedding processor to encode queries that specify audio targets for separation, allowing for zero-shot generalization. Our approach uses a single model for source separation of multiple sound types, and relies solely on weakly-labeled data for training. In addition, the proposed audio separator can be used in a zero-shot setting, learning to separate types of audio sources that were never seen in training. To evaluate the separation performance, we test our model on MUSDB18, while training on the disjoint AudioSet. We further verify the zero-shot performance by conducting another experiment on audio source types that are held-out from training. The model achieves comparable Source-to-Distortion Ratio (SDR) performance to current supervised models in both cases.      
### 30.A terrain treadmill to study animal locomotion through large obstacles  [ :arrow_down: ](https://arxiv.org/pdf/2112.07854.pdf)
>  A major challenge to understanding locomotion in complex 3-D terrain with large obstacles is to create tools for controlled, systematic lab experiments. Existing terrain arenas only allow observations at small spatiotemporal scales (~10 body length, ~10 stride cycles). Here, we create a terrain treadmill to enable high-resolution observations of animal locomotion through large obstacles over large spatiotemporal scales. An animal moves through modular obstacles on an inner sphere, while a rigidly-attached, concentric, transparent outer sphere rotated with the opposite velocity via closed-loop feedback to keep the animal on top. During sustained locomotion, a discoid cockroach moved through pillar obstacles for 25 minutes ($\approx$2500 strides) over 67 m ($\approx$1500 body lengths), and was contained within a radius of 4 cm (0.9 body length) for 83% of the duration, even at speeds of up to 10 body length/s. The treadmill enabled observation of diverse locomotor behaviors and quantification of animal-obstacle interaction.      
### 31.Communication-Efficient Distributed SGD with Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2112.07836.pdf)
>  We consider large scale distributed optimization over a set of edge devices connected to a central server, where the limited communication bandwidth between the server and edge devices imposes a significant bottleneck for the optimization procedure. Inspired by recent advances in federated learning, we propose a distributed stochastic gradient descent (SGD) type algorithm that exploits the sparsity of the gradient, when possible, to reduce communication burden. At the heart of the algorithm is to use compressed sensing techniques for the compression of the local stochastic gradients at the device side; and at the server side, a sparse approximation of the global stochastic gradient is recovered from the noisy aggregated compressed local gradients. We conduct theoretical analysis on the convergence of our algorithm in the presence of noise perturbation incurred by the communication channels, and also conduct numerical experiments to corroborate its effectiveness.      
### 32.Analog/Mixed-Signal Circuit Synthesis Enabled by the Advancements of Circuit Architectures and Machine Learning Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2112.07824.pdf)
>  Analog mixed-signal (AMS) circuit architecture has evolved towards more digital friendly due to technology scaling and demand for higher flexibility/reconfigurability. Meanwhile, the design complexity and cost of AMS circuits has substantially increased due to the necessity of optimizing the circuit sizing, layout, and verification of a complex AMS circuit. On the other hand, machine learning (ML) algorithms have been under exponential growth over the past decade and actively exploited by the electronic design automation (EDA) community. This paper will identify the opportunities and challenges brought about by this trend and overview several emerging AMS design methodologies that are enabled by the recent evolution of AMS circuit architectures and machine learning algorithms. Specifically, we will focus on using neural-network-based surrogate models to expedite the circuit design parameter search and layout iterations. Lastly, we will demonstrate the rapid synthesis of several AMS circuit examples from specification to silicon prototype, with significantly reduced human intervention.      
### 33.Snake robot traversing large obstacles using vertical bending with force feedback  [ :arrow_down: ](https://arxiv.org/pdf/2112.07815.pdf)
>  Snake robots hold the promise as a versatile platform to traverse complex environments. Previous snake robots often used lateral bending to push against vertical structures on flat surfaces. Recent animal experiments revealed that vertical bending is also important for generating propulsion during traversal of terrain with large height variation. Although snake robots can propagate a vertical bending shape to passively push to traverse such terrain, it is possible that active pushing modulated by contact force and internal torque sensing can further help control propulsion. Here, we explore this question by testing a previously developed robot with contact forces sensors added. We tested the robot using vertical bending to traverse a large obstacle and compared five controllers without and with various sensory feedback using various force and torque information, as well as various load and terrain conditions to perturb the system. Feedforward propagation of vertical bending that conforms to the terrain a priori can produce propulsion but fails with terrain perturbation that breaks conformation. In general, sensory feedback helps better maintain or regain contact and propulsion, but different types of feedback displayed different tradeoffs and varied performance. We also identified issues that needs improvement in further development.      
### 34.FLOWER: A comprehensive dataflow compiler for high-level synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2112.07789.pdf)
>  FPGAs have found their way into data centers as accelerator cards, making reconfigurable computing more accessible for high-performance applications. At the same time, new high-level synthesis compilers like Xilinx Vitis and runtime libraries such as XRT attract software programmers into the reconfigurable domain. While software programmers are familiar with task-level and data-parallel programming, FPGAs often require different types of parallelism. For example, data-driven parallelism is mandatory to obtain satisfactory hardware designs for pipelined dataflow architectures. However, software programmers are often not acquainted with dataflow architectures - resulting in poor hardware designs. <br>In this work we present FLOWER, a comprehensive compiler infrastructure that provides automatic canonical transformations for high-level synthesis from a domain-specific library. This allows programmers to focus on algorithm implementations rather than low-level optimizations for dataflow architectures. We show that FLOWER allows to synthesize efficient implementations for high-performance streaming applications targeting System-on-Chip and FPGA accelerator cards, in the context of image processing and computer vision.      
### 35.Depth-resolved vascular profile features for artery-vein classification in OCT and OCT angiography of human retina  [ :arrow_down: ](https://arxiv.org/pdf/2112.07775.pdf)
>  This study is to characterize reflectance profiles of retinal blood vessels in optical coherence tomography (OCT), and to validate these vascular features to guide artery-vein classification in OCT angiography (OCTA) of human retina. Depth-resolved OCT reveals unique features of retinal arteries and veins. Retinal arteries show hyper-reflective boundaries at both upper (inner side towards the vitreous) and lower (outer side towards the choroid) walls. In contrary, retinal veins reveal hyper-reflectivity at the upper boundary only. Uniform lumen intensity was observed in both small and large arteries. However, the vein lumen intensity was dependent on the vessel size. Small veins exhibit a hyper-reflective zone at the bottom half of the lumen, while large veins show a hypo-reflective zone at the bottom half of the lumen      
### 36.CEM-GD: Cross-Entropy Method with Gradient Descent Planner for Model-Based Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.07746.pdf)
>  Current state-of-the-art model-based reinforcement learning algorithms use trajectory sampling methods, such as the Cross-Entropy Method (CEM), for planning in continuous control settings. These zeroth-order optimizers require sampling a large number of trajectory rollouts to select an optimal action, which scales poorly for large prediction horizons or high dimensional action spaces. First-order methods that use the gradients of the rewards with respect to the actions as an update can mitigate this issue, but suffer from local optima due to the non-convex optimization landscape. To overcome these issues and achieve the best of both worlds, we propose a novel planner, Cross-Entropy Method with Gradient Descent (CEM-GD), that combines first-order methods with CEM. At the beginning of execution, CEM-GD uses CEM to sample a significant amount of trajectory rollouts to explore the optimization landscape and avoid poor local minima. It then uses the top trajectories as initialization for gradient descent and applies gradient updates to each of these trajectories to find the optimal action sequence. At each subsequent time step, however, CEM-GD samples much fewer trajectories from CEM before applying gradient updates. We show that as the dimensionality of the planning problem increases, CEM-GD maintains desirable performance with a constant small number of samples by using the gradient information, while avoiding local optima using initially well-sampled trajectories. Furthermore, CEM-GD achieves better performance than CEM on a variety of continuous control benchmarks in MuJoCo with 100x fewer samples per time step, resulting in around 25% less computation time and 10% less memory usage. The implementation of CEM-GD is available at $\href{<a class="link-external link-https" href="https://github.com/KevinHuang8/CEM-GD" rel="external noopener nofollow">this https URL</a>}{\text{<a class="link-external link-https" href="https://github.com/KevinHuang8/CEM-GD" rel="external noopener nofollow">this https URL</a>}}$.      
### 37.A literature review on COVID-19 disease diagnosis from respiratory sound data  [ :arrow_down: ](https://arxiv.org/pdf/2112.07670.pdf)
>  The World Health Organization (WHO) has announced a COVID-19 was a global pandemic in March 2020. It was initially started in china in the year 2019 December and affected an expanding number of nations in various countries in the last few months. In this particular situation, many techniques, methods, and AI-based classification algorithms are put in the spotlight in reacting to fight against it and reduce the rate of such a global health crisis. COVID-19's main signs are heavy temperature, different cough, cold, breathing shortness, and a combination of loss of sense of smell and chest tightness. The digital world is growing day by day, in this context digital stethoscope can read all of these symptoms and diagnose respiratory disease. In this study, we majorly focus on literature reviews of how SARS-CoV-2 is spreading and in-depth analysis of the diagnosis of COVID-19 disease from human respiratory sounds like cough, voice, and breath by analyzing the respiratory sound parameters. We hope this review will provide an initiative for the clinical scientists and researcher's community to initiate open access, scalable, and accessible work in the collective battle against COVID-19.      
### 38.Multimodal Representation Learning via Maximization of Local Mutual Information  [ :arrow_down: ](https://arxiv.org/pdf/2103.04537.pdf)
>  We propose and demonstrate a representation learning approach by maximizing the mutual information between local features of images and text. The goal of this approach is to learn useful image representations by taking advantage of the rich information contained in the free text that describes the findings in the image. Our method trains image and text encoders by encouraging the resulting representations to exhibit high local mutual information. We make use of recent advances in mutual information estimation with neural network discriminators. We argue that the sum of local mutual information is typically a lower bound on the global mutual information. Our experimental results in the downstream image classification tasks demonstrate the advantages of using local features for image-text representation learning.      
