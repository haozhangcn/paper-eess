# ArXiv eess --Tue, 7 Dec 2021
### 1.A Risk-Averse Preview-based $Q$-Learning Algorithm: Application to Highway Driving of Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2112.03232.pdf)
>  A risk-averse preview-based $Q$-learning planner is presented for navigation of autonomous vehicles. To this end, the multi-lane road ahead of a vehicle is represented by a finite-state non-stationary Markov decision process (MDP). A risk assessment unit module is then presented that leverages the preview information provided by sensors along with a stochastic reachability module to assign reward values to the MDP states and update them as scenarios develop. A sampling-based risk-averse preview-based $Q$-learning algorithm is finally developed that generates samples using the preview information and reward function to learn risk-averse optimal planning strategies without actual interaction with the environment. The risk factor is imposed on the objective function to avoid fluctuation of the $Q$ values, which can jeopardize the vehicle's safety and/or performance. The overall hybrid automaton model of the system is leveraged to develop a feasibility check unit module that detects unfeasible plans and enables the planner system to proactively react to the changes of the environment. Theoretical results are provided to bound the number of samples required to guarantee $\epsilon$-optimal planning with a high probability. Finally, to verify the efficiency of the presented algorithm, its implementation on highway driving of an autonomous vehicle in a varying traffic density is considered.      
### 2.On the Design of Magnetic Resonant Coupling for Wireless Power Transfer in Multi-Coil Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.03139.pdf)
>  Wireless power transfer (WPT) is a promising technology for powering up distributed devices in machine type networks. Over the last decade magnetic resonant coupling (MRC) received significant interest from the research community, since it is suitable for realizing mid-range WPT. In this paper, we investigate the performance of a single cell MRC-WPT network with multiple receivers, each equipped with an electromagnetic coil and a load. We first consider pre-adjusted loads for the receivers and by taking into account spatial randomness, we derive the harvesting outage probability of a receiver; for both the strong and loosely coupling regions. Then, we develop a non-cooperative game for a fixed receiver topology, in order to acquire the optimal load which maximizes each receiver's harvested power. Throughout our work, we obtain insights for key design parameters and present numerical results which validate our analysis.      
### 3.Geometric Constellation Shaping for Phase-noise Channels Using a Differentiable Blind Phase Search  [ :arrow_down: ](https://arxiv.org/pdf/2112.03114.pdf)
>  We perform geometric constellation shaping with optimized bit labeling using a binary autoencoder including a differential blind phase search (BPS). Our approach enables full end-to-end training of optical coherent transceivers taking into account the digital signal processing.      
### 4.Fast 3D registration with accurate optimisation and little learning for Learn2Reg 2021  [ :arrow_down: ](https://arxiv.org/pdf/2112.03053.pdf)
>  Current approaches for deformable medical image registration often struggle to fulfill all of the following criteria: versatile applicability, small computation or training times, and the being able to estimate large deformations. Furthermore, end-to-end networks for supervised training of registration often become overly complex and difficult to train. For the Learn2Reg2021 challenge, we aim to address these issues by decoupling feature learning and geometric alignment. First, we introduce a new very fast and accurate optimisation method. By using discretised displacements and a coupled convex optimisation procedure, we are able to robustly cope with large deformations. With the help of an Adam-based instance optimisation, we achieve very accurate registration performances and by using regularisation, we obtain smooth and plausible deformation fields. Second, to be versatile for different registration tasks, we extract hand-crafted features that are modality and contrast invariant and complement them with semantic features from a task-specific segmentation U-Net. With our results we were able to achieve the overall Learn2Reg2021 challenge's second place, winning Task 1 and being second and third in the other two tasks.      
### 5.A Novel Full-Polarization SAR Images Ship Detector Based on the Scattering Mechanisms and the Wave Polarization Anisotropy  [ :arrow_down: ](https://arxiv.org/pdf/2112.02965.pdf)
>  Synthetic aperture radar (SAR) is considered being a good option for earth observation with its unique advantages. In this paper, we proposed an adaptive ship detector using full-polarization SAR images. First, by thoroughly investigating the scattering characteristics between ships and their background, and the wave polarization anisotropy, a novel ship detector is proposed by jointing the two characteristics, named Scattering-Anisotropy joint (joint-SA). Based on the theoretical analysis, we showed that the joint-SA is an effective physical quantity to show the difference between the ship and its background, and thus joint-SA can be used for ship detection of full-polarization image data. Second, the generalized Gamma distribution was used to characterize the joint-SA statistics of sea clutter with a large range of homogeneity. As a result, an adaptive constant false alarm rate (CFAR) method was implemented based on the joint-SA. Finally, RADARSAT-2 and GF-3 data in C-band and ALOS data in L-band are used for verification. We tested on five datasets, and the experimental results verify the correctness and superiority of the constant false alarm rate (CFAR) method based on the joint-SA. In addition, the experimental results also showed that the signal-clutter ratio (SCR) of the proposed ship detector joint-SA (33.17 dB, 35.98 dB, 57.25 dB) is better than that of DBSP (8.92 dB, 3.43 dB, 25.40 dB) and RsDVH (17.28 dB, 11.17 dB, 54.55 dB). More importantly, the proposed detector joint-SA has higher detection accuracy and a lower false alarm rate.      
### 6.Encrypted dynamic control with unlimited operating time via FIR filters  [ :arrow_down: ](https://arxiv.org/pdf/2112.02931.pdf)
>  Encrypted control enables confidential controller evaluations in cloud-based or networked control systems. From a technical point of view, an encrypted controller is a modified control algorithm that is capable of computing encrypted control actions based on encrypted system outputs. Unsurprisingly, encrypted implementations of controllers using, e.g., homomorphic cryptosystems entail new design challenges. For instance, in order to avoid overflow or high computational loads, only a finite number of operations should be carried out on encrypted data. Clearly, this guideline is hard to satisfy for dynamic controllers due to their recursive nature. To enable an unlimited operating time, existing implementations thus rely on external refreshments of the controller state, internal refreshments using bootstrapping, or recurring controller resets. <br>We show in this paper that simple FIR filter-based controllers allow overcoming many drawbacks of the existing approaches. In fact, since FIR filters consider only a finite amount of the most recent input data, the recursion issue is immediately solved and controller refreshments or resets are no longer required. Moreover, well-designed FIR filters are often less complex than and equally effective as IIR controllers.      
### 7.Steerable discovery of neural audio effects  [ :arrow_down: ](https://arxiv.org/pdf/2112.02926.pdf)
>  Applications of deep learning for audio effects often focus on modeling analog effects or learning to control effects to emulate a trained audio engineer. However, deep learning approaches also have the potential to expand creativity through neural audio effects that enable new sound transformations. While recent work demonstrated that neural networks with random weights produce compelling audio effects, control of these effects is limited and unintuitive. To address this, we introduce a method for the steerable discovery of neural audio effects. This method enables the design of effects using example recordings provided by the user. We demonstrate how this method produces an effect similar to the target effect, along with interesting inaccuracies, while also providing perceptually relevant controls.      
### 8.Tunable Image Quality Control of 3-D Ultrasound using Switchable CycleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2112.02896.pdf)
>  In contrast to 2-D ultrasound (US) for uniaxial plane imaging, a 3-D US imaging system can visualize a volume along three axial planes. This allows for a full view of the anatomy, which is useful for gynecological (GYN) and obstetrical (OB) applications. Unfortunately, the 3-D US has an inherent limitation in resolution compared to the 2-D US. In the case of 3-D US with a 3-D mechanical probe, for example, the image quality is comparable along the beam direction, but significant deterioration in image quality is often observed in the other two axial image planes. To address this, here we propose a novel unsupervised deep learning approach to improve 3-D US image quality. In particular, using {\em unmatched} high-quality 2-D US images as a reference, we trained a recently proposed switchable CycleGAN architecture so that every mapping plane in 3-D US can learn the image quality of 2-D US images. Thanks to the switchable architecture, our network can also provide real-time control of image enhancement level based on user preference, which is ideal for a user-centric scanner setup. Extensive experiments with clinical evaluation confirm that our method offers significantly improved image quality as well user-friendly flexibility.      
### 9.A Fast and Scalable Polyatomic Frank-Wolfe Algorithm for the LASSO  [ :arrow_down: ](https://arxiv.org/pdf/2112.02890.pdf)
>  We propose a fast and scalable Polyatomic Frank-Wolfe (P-FW) algorithm for the resolution of high-dimensional LASSO regression problems. The latter improves upon traditional Frank-Wolfe methods by considering generalized greedy steps with polyatomic (i.e. linear combinations of multiple atoms) update directions, hence allowing for a more efficient exploration of the search space. To preserve sparsity of the intermediate iterates, we moreover re-optimize the LASSO problem over the set of selected atoms at each iteration. For efficiency reasons, the accuracy of this re-optimization step is relatively low for early iterations and gradually increases with the iteration count. We provide convergence guarantees for our algorithm and validate it in simulated compressed sensing setups. Our experiments reveal that P-FW outperforms state-of-the-art methods in terms of runtime, both for FW methods and optimal first-order proximal gradient methods such as the Fast Iterative Soft-Thresholding Algorithm (FISTA).      
### 10.Joint Learning of Localized Representations from Medical Images and Reports  [ :arrow_down: ](https://arxiv.org/pdf/2112.02889.pdf)
>  Contrastive learning has proven effective for pre-training image models on unlabeled data with promising results for tasks such as medical image classification. Using paired text and images (such as radiological reports and images) during pre-training improved the results even further. Still, most existing methods target image classification as downstream tasks and may not be optimal for localized tasks like semantic segmentation or object detection. We therefore propose Localized representation learning from Vision and Text (LoVT), to our best knowledge, the first text-supervised pre-training method that targets localized medical imaging tasks. Our method combines instance-level image-report contrastive learning with local contrastive learning on image region and report sentence representations. We evaluate LoVT and commonly used pre-training methods on a novel evaluation framework consisting of 18 localized tasks on chest X-rays from five public datasets. While there is no single best method, LoVT performs best on 11 out of the 18 studied tasks making it the preferred method of choice for localized tasks.      
### 11.A comparison study of CNN denoisers on PRNU extraction  [ :arrow_down: ](https://arxiv.org/pdf/2112.02858.pdf)
>  Performance of the sensor-based camera identification (SCI) method heavily relies on the denoising filter in estimating Photo-Response Non-Uniformity (PRNU). Given various attempts on enhancing the quality of the extracted PRNU, it still suffers from unsatisfactory performance in low-resolution images and high computational demand. Leveraging the similarity of PRNU estimation and image denoising, we take advantage of the latest achievements of Convolutional Neural Network (CNN)-based denoisers for PRNU extraction. In this paper, a comparative evaluation of such CNN denoisers on SCI performance is carried out on the public "Dresden Image Database". Our findings are two-fold. From one aspect, both the PRNU extraction and image denoising separate noise from the image content. Hence, SCI can benefit from the recent CNN denoisers if carefully trained. From another aspect, the goals and the scenarios of PRNU extraction and image denoising are different since one optimizes the quality of noise and the other optimizes the image quality. A carefully tailored training is needed when CNN denoisers are used for PRNU estimation. Alternative strategies of training data preparation and loss function design are analyzed theoretically and evaluated experimentally. We point out that feeding the CNNs with image-PRNU pairs and training them with correlation-based loss function result in the best PRNU estimation performance. To facilitate further studies of SCI, we also propose a minimum-loss camera fingerprint quantization scheme using which we save the fingerprints as image files in PNG format. Furthermore, we make the quantized fingerprints of the cameras from the "Dresden Image Database" publicly available.      
### 12.Learning Proximal Operator Methods for Massive Connectivity in IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.02830.pdf)
>  Grant-free random access has the potential to support massive connectivity in Internet of Things (IoT) networks, where joint activity detection and channel estimation (JADCE) is a key issue that needs to be tackled. The existing methods for JADCE usually suffer from one of the following limitations: high computational complexity, ineffective in inducing sparsity, and incapable of handling complex matrix estimation. To mitigate all the aforementioned limitations, we in this paper develop an effective unfolding neural network framework built upon the proximal operator method to tackle the JADCE problem in IoT networks, where the base station is equipped with multiple antennas. Specifically, the JADCE problem is formulated as a group-sparse-matrix estimation problem, which is regularized by non-convex minimax concave penalty (MCP). This problem can be iteratively solved by using the proximal operator method, based on which we develop a unfolding neural network structure by parameterizing the algorithmic iterations. By further exploiting the coupling structure among the training parameters as well as the analytical computation, we develop two additional unfolding structures to reduce the training complexity. We prove that the proposed algorithm achieves a linear convergence rate. Results show that our proposed three unfolding structures not only achieve a faster convergence rate but also obtain a higher estimation accuracy than the baseline methods.      
### 13.Optimal activity and battery scheduling algorithm using load and solar generation forecast  [ :arrow_down: ](https://arxiv.org/pdf/2112.02827.pdf)
>  In this report, we provide a technical sequence on tackling the solar PV and demand forecast as well as optimal scheduling problem proposed by the IEEE-CIS 3rd technical challenge on predict + optimize for activity and battery scheduling. Using the historical data provided by the organizers, a simple pre-processing approach with a rolling window was used to detect and replace invalid data points. Upon filling the missing values, advanced time-series forecasting techniques, namely tree-based methods and refined motif discovery, were employed to predict the baseload consumption on six different buildings together with the power production on their associated solar PV panels. An optimization problem is then formulated to use the predicted values and the wholesale electricity prices to create a timetable for a set of activities, including the scheduling of lecture theatres and battery charging and discharging operation, for one month ahead. The valley-filling optimization was done across all the buildings with the objective of minimizing the total energy cost and achieving net-zero imported power from the grid.      
### 14.Identification of Switched Linear Systems: Persistence of Excitation and Numerical Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2112.02802.pdf)
>  This paper investigates two issues on identification of switched linear systems: persistence of excitation and numerical algorithms. The main contribution is a much weaker condition on the regressor to be persistently exciting that guarantees the uniqueness of the parameter sets and also provides new insights in understanding the relation among different subsystems. It is found that for uniquely determining the parameters of switched linear systems, the minimum number of samples needed derived from our condition is much smaller than that reported in the literature. The secondary contribution of the paper concerns the numerical algorithm. Though the algorithm is not new, we show that our surrogate problem, relaxed from an integer optimization to a continuous minimization, has exactly the same solution as the original integer optimization, which is effectively solved by a block-coordinate descent algorithm. Moreover, an algorithm for handling unknown number of subsystems is proposed. Several numerical examples are illustrated to support theoretical analysis.      
### 15.Voltage Stability Constrained Unit Commitment in High IBG-Penetrated Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.02754.pdf)
>  With the increasing penetration of renewable energy sources, power system operation has to be adapted to ensure the system stability and security while considering the distinguished feature of the Power Electronics (PE) interfaced generators. The static voltage stability which is mainly compromised by heavy loading conditions in conventional power systems, faces new challenges due to the large scale integration of PE-interfaced devices. This paper investigates the static voltage stability problem in high PE-penetrated system. The analytic criterion that ensures the voltage stability at the Inverter-Based Generator (IBG) buses are derived with the interaction of different IBGs being considered. Based on this, an optimal system scheduling model is proposed to minimize the overall system operation cost while maintaining the voltage stability during normal operation through dynamically optimizing the active and reactive power output from IBGs. The highly nonlinear voltage stability constraints are effectively converted into Second-Order-Cone (SOC) form, leading to an overall Mixed-Integer SOC Programming (MISOCP), together with the SOC reformulation of AC power flow and frequency constraints. The effectiveness of the proposed model and the impact of various factors on voltage stability are demonstrated in thorough case studies.      
### 16.A new active disturbance controller based on an improved fraction-order extended state observer  [ :arrow_down: ](https://arxiv.org/pdf/2112.02744.pdf)
>  This paper proposes a new fraction-order active disturbance rejection controller based on an improved fraction-order extended state observer (IFESO) for a class of fraction-order systems. Applying the IFESO, the fraction-order system can be approximated as an integer-order integrator (1/s). The parameters that ensure the stability of the IFESO and closed-loop system are provided. The frequency-domain analysis shows that the IFADRC has a stronger disturbance estimation performance for the fraction-order system than an integer-order active disturbance rejection controller (IADRC). The simulation results demonstrates that the proposed IFADRC behaves better than the IADRC and the FADRC.      
### 17.Separated Contrastive Learning for Organ-at-Risk and Gross-Tumor-Volume Segmentation with Limited Annotation  [ :arrow_down: ](https://arxiv.org/pdf/2112.02743.pdf)
>  Automatic delineation of organ-at-risk (OAR) and gross-tumor-volume (GTV) is of great significance for radiotherapy planning. However, it is a challenging task to learn powerful representations for accurate delineation under limited pixel (voxel)-wise annotations. Contrastive learning at pixel-level can alleviate the dependency on annotations by learning dense representations from unlabeled data. Recent studies in this direction design various contrastive losses on the feature maps, to yield discriminative features for each pixel in the map. However, pixels in the same map inevitably share semantics to be closer than they actually are, which may affect the discrimination of pixels in the same map and lead to the unfair comparison to pixels in other maps. To address these issues, we propose a separated region-level contrastive learning scheme, namely SepaReg, the core of which is to separate each image into regions and encode each region separately. Specifically, SepaReg comprises two components: a structure-aware image separation (SIS) module and an intra- and inter-organ distillation (IID) module. The SIS is proposed to operate on the image set to rebuild a region set under the guidance of structural information. The inter-organ representation will be learned from this set via typical contrastive losses cross regions. On the other hand, the IID is proposed to tackle the quantity imbalance in the region set as tiny organs may produce fewer regions, by exploiting intra-organ representations. We conducted extensive experiments to evaluate the proposed model on a public dataset and two private datasets. The experimental results demonstrate the effectiveness of the proposed model, consistently achieving better performance than state-of-the-art approaches. Code is available at <a class="link-external link-https" href="https://github.com/jcwang123/Separate_CL" rel="external noopener nofollow">this https URL</a>.      
### 18.Automated volumetric and statistical shape assessment of cam-type morphology of the femoral head-neck region from 3D magnetic resonance images  [ :arrow_down: ](https://arxiv.org/pdf/2112.02723.pdf)
>  Femoroacetabular impingement (FAI) cam morphology is routinely assessed using two-dimensional alpha angles which do not provide specific data on cam size characteristics. The purpose of this study is to implement a novel, automated three-dimensional (3D) pipeline, CamMorph, for segmentation and measurement of cam volume, surface area and height from magnetic resonance (MR) images in patients with FAI. The CamMorph pipeline involves two processes: i) proximal femur segmentation using an approach integrating 3D U-net with focused shape modelling (FSM); ii) use of patient-specific anatomical information from 3D FSM to simulate healthy femoral bone models and pathological region constraints to identify cam bone mass. Agreement between manual and automated segmentation of the proximal femur was evaluated with the Dice similarity index (DSI) and surface distance measures. Independent t-tests or Mann-Whitney U rank tests were used to compare the femoral head volume, cam volume, surface area and height data between female and male patients with FAI. There was a mean DSI value of 0.964 between manual and automated segmentation of proximal femur volume. Compared to female FAI patients, male patients had a significantly larger mean femoral head volume (66.12cm3 v 46.02cm3, p&lt;0.001). Compared to female FAI patients, male patients had a significantly larger mean cam volume (1136.87mm3 v 337.86mm3, p&lt;0.001), surface area (657.36mm2 v 306.93mm2 , p&lt;0.001), maximum-height (3.89mm v 2.23mm, p&lt;0.001) and average-height (1.94mm v 1.00mm, p&lt;0.001). Automated analyses of 3D MR images from patients with FAI using the CamMorph pipeline showed that, in comparison with female patients, male patients had significantly greater cam volume, surface area and height.      
### 19.Learning Swarm Interaction Dynamics from Density Evolution  [ :arrow_down: ](https://arxiv.org/pdf/2112.02675.pdf)
>  We consider the problem of understanding the coordinated movements of biological or artificial swarms. In this regard, we propose a learning scheme to estimate the coordination laws of the interacting agents from observations of the swarm's density over time. We describe the dynamics of the swarm based on pairwise interactions according to a Cucker-Smale flocking model, and express the swarm's density evolution as the solution to a system of mean-field hydrodynamic equations. We propose a new family of parametric functions to model the pairwise interactions, which allows for the mean-field macroscopic system of integro-differential equations to be efficiently solved as an augmented system of PDEs. Finally, we incorporate the augmented system in an iterative optimization scheme to learn the dynamics of the interacting agents from observations of the swarm's density evolution over time. The results of this work can offer an alternative approach to study how animal flocks coordinate, create new control schemes for large networked systems, and serve as a central part of defense mechanisms against adversarial drone attacks.      
### 20.Modelling Quantum Channels Carrying Classical Information  [ :arrow_down: ](https://arxiv.org/pdf/2112.02665.pdf)
>  We use the concept of coupled quantum harmonic oscillators to model the propagation environment in which a quantum link carrying either classical or quantum information operates. Using the analogy between the paraxial optical wave equation and the stationary Schrodinger equation and applying the Caldirola-Kanai Hamiltonian for solving the time-dependent Schrodinger equation; we calculate the propagation field strength and the corresponding average received signal energy.      
### 21.A Tensor-BTD-based Modulation for Massive Unsourced Random Access  [ :arrow_down: ](https://arxiv.org/pdf/2112.02629.pdf)
>  In this letter, we propose a novel tensor-based modulation scheme for massive unsourced random access. The proposed modulation can be deemed as a summation of third-order tensors, of which the factors are representatives of subspaces. A constellation design based on high-dimensional Grassmann manifold is presented for information encoding. The uniqueness of tensor decomposition provides theoretical guarantee for active user separation. Simulation results show that our proposed method outperforms the state-of-the-art tensor-based modulation.      
### 22.Enhancement of a state-of-the-art RL-based detection algorithm for Massive MIMO radars  [ :arrow_down: ](https://arxiv.org/pdf/2112.02628.pdf)
>  In the present work, a reinforcement learning (RL) based adaptive algorithm to optimise the transmit beampattern for a colocated massive MIMO radar is presented. Under the massive MIMO regime, a robust Wald type detector, able to guarantee certain detection performances under a wide range of practical disturbance models, has been recently proposed. Furthermore, an RL/cognitive methodology has been exploited to improve the detection performance by learning and interacting with the surrounding unknown environment. Building upon previous findings, we develop here a fully adaptive and data driven scheme for the selection of the hyper-parameters involved in the RL algorithm. Such an adaptive selection makes the Wald RL based detector independent of any ad hoc, and potentially suboptimal, manual tuning of the hyper-parameters. Simulation results show the effectiveness of the proposed scheme in harsh scenarios with strong clutter and low SNR values.      
### 23.C-GRBFnet: A Physics-Inspired Generative Deep Neural Network for Channel Representation and Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2112.02615.pdf)
>  In this paper, we aim to efficiently and accurately predict the static channel impulse response (CIR) with only the user's position information and a set of channel instances obtained within a certain wireless communication environment. Such a problem is by no means trivial since it needs to reconstruct the high-dimensional information (here the CIR everywhere) from the extremely low-dimensional data (here the location coordinates), which often results in overfitting and large prediction error. To this end, we resort to a novel physics-inspired generative approach. Specifically, we first use a forward deep neural network to infer the positions of all possible images of the source reflected by the surrounding scatterers within that environment, and then use the well-known Gaussian Radial Basis Function network (GRBF) to approximate the amplitudes of all possible propagation paths. We further incorporate the most recently developed sinusoidal representation network (SIREN) into the proposed network to implicitly represent the highly dynamic phases of all possible paths, which usually cannot be well predicted by the conventional neural networks with non-periodic activators. The resultant framework of Cosine-Gaussian Radial Basis Function network (C-GRBFnet) is also extended to the MIMO channel case. Key performance measures including prediction accuracy, convergence speed, network scale and robustness to channel estimation error are comprehensively evaluated and compared with existing popular networks, which show that our proposed network is much more efficient in representing, learning and predicting wireless channels in a given communication environment.      
### 24.Real-time Virtual Intraoperative CT for Image Guided Surgery  [ :arrow_down: ](https://arxiv.org/pdf/2112.02608.pdf)
>  Abstract. Purpose: This paper presents a scheme for generating virtual intraoperative CT scans in order to improve surgical completeness in Endoscopic Sinus Surgeries (ESS). Approach: The work presents three methods, the tip motion-based, the tip trajectory-based, and the instrument based, along with non-parametric smoothing and Gaussian Process Regression, for virtual intraoperative CT generation. Results: The proposed methods studied and compared on ESS performed on cadavers. Surgical results show all three methods improve the Dice Similarity Coefficients &gt; 86%, with F-score &gt; 92% and precision &gt; 89.91%. The tip trajectory-based method was found to have best performance and reached 96.87% precision in surgical completeness evaluation. Conclusions: This work demonstrated that virtual intraoperative CT scans improves the consistency between the actual surgical scene and the reference model, and improves surgical completeness in ESS. Comparing with actual intraoperative CT scans, the proposed scheme has no impact on existing surgical protocols, does not require extra hardware other than the one is already available in most ESS overcome the high costs, the repeated radiation, and the elongated anesthesia caused by actual intraoperative CTs, and is practical in ESS.      
### 25.CRLB Approaching Pilot-aided Phase and Channel Estimation Algorithm in MIMO Systems with Phase Noise and Quasi-Static Channel Fading  [ :arrow_down: ](https://arxiv.org/pdf/2112.02583.pdf)
>  This paper derives a novel pilot-aided phase and channel estimation algorithm for multiple-input multiple-output (MIMO) systems with phase noise and quasi-static channel fading. Our novel approach allows, for the first time, carrier phase estimation and recovery to be performed before full channel estimation. This in turn enables the channel estimation to be calculated using the whole frame, significantly improving its accuracy. The proposed algorithm is a sequential combination of several linear algorithms, which greatly reduces the computational complexity. Moreover, we also derive, for the first time, the Cramer-Rao lower bound (CRLB) for a MIMO system, where phase noise is estimated using only angular information. Our numerical results show that the performance of our phase estimation algorithm is close to the proposed CRLB. Moreover, when compared with the conventional Kalman based algorithms, our proposed algorithm significantly improves the system BER performance.      
### 26.Iterated Posterior Linearization PMB Filter for 5G SLAM  [ :arrow_down: ](https://arxiv.org/pdf/2112.02575.pdf)
>  5G millimeter wave (mmWave) signals have inherent geometric connections to the propagation channel and the propagation environment. Thus, they can be used to jointly localize the receiver and map the propagation environment, which is termed as simultaneous localization and mapping (SLAM). One of the most important tasks in the 5G SLAM is to deal with the nonlinearity of the measurement model. To solve this problem, existing 5G SLAM approaches rely on sigma-point or extended Kalman filters, linearizing the measurement function with respect to the prior probability density function (PDF). In this paper, we study the linearization of the measurement function with respect to the posterior PDF, and implement the iterated posterior linearization filter into the Poisson multi-Bernoulli SLAM filter. Simulation results demonstrate the accuracy and precision improvements of the resulting SLAM filter.      
### 27.Symplectic and Cosymplectic Reduction for simple hybrid forced mechanical systems with symmetries  [ :arrow_down: ](https://arxiv.org/pdf/2112.02573.pdf)
>  This paper discusses symplectic and cosymplectic reduction for autonomous and non-autonomous simple hybrid forced mechanical systems, respectively. We give general conditions on whether it is possible to perform symmetry reduction for simple hybrid Hamiltonian and Lagrangian systems subject to non-conservative external forces, as well as time-dependent external forces. We illustrate the applicability of the symmetry reduction procedure with an example and numerical simulations.      
### 28.Learning-Based Control Compensation for Multi-Axis Gimbal Systems Using Inverse and Forward Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2112.02561.pdf)
>  Unmanned aerospace vehicles usually carry sensors (i.e., electro-optical and/or infrared imaging cameras) as their primary payload. These sensors are used for image processing, target tracking, surveillance, mapping, and providing high-resolution imagery for environmental surveys. It is crucial to obtain a steady image in all these applications. This is typically accomplished by using multi-axis gimbal systems. This paper concentrates on the modeling and control of a multi-axis gimbal system. A novel and fully outlined procedure is proposed to derive the nonlinear and highly coupled Equations of Motion of the two-axis gimbal system. Different from the existing literature, Forward Dynamics of the two-axis gimbal system is modeled using multi-body dynamics modeling techniques. In addition to the Forward Dynamics model, the Inverse Dynamics model is developed to estimate the complementary torques associated with the state and mechanism-dependent, complex disturbances acting on the system. A disturbance compensator based on multilayer perceptron (MLP) structure is implemented to cope with external and internal disturbances and parameter uncertainties through the torque input channel. Our initial simulations and experimental work show that the new NN (neural network)-based controller is performs better in the full operational range without requiring any tuning or adjustment when compared with well-known controllers such as cascaded PID, ADRC (Active Disturbance Rejection Control), Inverse Dynamics based controllers.      
### 29.Toward Real-World Pathological Voice Detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.02538.pdf)
>  Voice disorders significantly undermine people's ability to speak in their daily lives. Without early diagnoses and treatments, these disorders may drastically deteriorate. Thus, automatic detection systems at home are desired for people inaccessible to disease assessments. However, more accurate systems usually require more cumbersome machine learning models, whereas the memory and computational resources of the systems at home are limited. Moreover, the performance of the systems may be weakened due to domain mismatch between clinic and real-world data. Therefore, we aimed to develop a compressed and domain-robust pathological voice detection system. Domain adversarial training was utilized to address domain mismatch by extracting domain-invariant features. In addition, factorized convolutional neural networks were exploited to compress the feature extractor model. The results showed that only 4% of degradation of unweighted average recall occurred in the target domain compared to the source domain, indicating that the domain mismatch was effectively eliminated. Furthermore, our system reduced both usages of memory and computation by over 73.9%. We concluded that this proposed system successfully resolved domain mismatch and may be applicable to embedded systems at home with limited resources.      
### 30.Deep Open Set Identification for RF Devices  [ :arrow_down: ](https://arxiv.org/pdf/2112.02536.pdf)
>  Artificial intelligence (AI) based device identification improves the security of the internet of things (IoT), and accelerates the authentication process. However, existing approaches rely on the assumption that we can learn all the classes from the training set, namely, closed-set classification. To overcome the closed-set limitation, we propose a novel open set RF device identification method to classify unseen classes in the testing set. First, we design a specific convolution neural network (CNN) with a short-time Fourier transforming (STFT) pre-processing module, which efficiently recognizes the differences of feature maps learned from various RF device signals. Then to generate a representation of known class bounds, we estimate the probability map of the open-set via the OpenMax function. We conduct experiments on sampled data and voice signal sets, considering various pre-processing schemes, network structures, distance metrics, tail sizes, and openness degrees. The simulation results show the superiority of the proposed method in terms of robustness and accuracy.      
### 31.Snapshot HDR Video Construction Using Coded Mask  [ :arrow_down: ](https://arxiv.org/pdf/2112.02522.pdf)
>  This paper study the reconstruction of High Dynamic Range (HDR) video from snapshot-coded LDR video. Constructing an HDR video requires restoring the HDR values for each frame and maintaining the consistency between successive frames. HDR image acquisition from single image capture, also known as snapshot HDR imaging, can be achieved in several ways. For example, the reconfigurable snapshot HDR camera is realized by introducing an optical element into the optical stack of the camera; by placing a coded mask at a small standoff distance in front of the sensor. High-quality HDR image can be recovered from the captured coded image using deep learning methods. This study utilizes 3D-CNNs to perform a joint demosaicking, denoising, and HDR video reconstruction from coded LDR video. We enforce more temporally consistent HDR video reconstruction by introducing a temporal loss function that considers the short-term and long-term consistency. The obtained results are promising and could lead to affordable HDR video capture using conventional cameras.      
### 32.Analysis of Pointing Loss Effects in Deep Space Optical Links  [ :arrow_down: ](https://arxiv.org/pdf/2112.02514.pdf)
>  Owing to the extremely narrow beams, a main issue in optical deep space communications is represented by miss-pointing errors, which may severely degrade the system performance and availability. In this paper, we address pointing losses in the case in which both the receiver and the transmitter are affected by angular errors. Pointing losses are evaluated through two approaches. The first approach is deterministic and only requires knowledge of a maximum angular error. The second approach requires knowledge of the angular error statistical distribution and tackles the problem from an outage probability viewpoint. These tools are then applied to analyze the impact of pointing losses in deep space optical links in which both terminals suffer from miss-pointing effects. The antenna gains are first optimized to maximize the effective system gain. The optimum antenna gains are then applied to evaluate maximum achievable ranges and to perform link design by means of optical link budgets.      
### 33.Uncertainty-Guided Mutual Consistency Learning for Semi-Supervised Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.02508.pdf)
>  Medical image segmentation is a fundamental and critical step in many clinical approaches. Semi-supervised learning has been widely applied to medical image segmentation tasks since it alleviates the heavy burden of acquiring expert-examined annotations and takes the advantage of unlabeled data which is much easier to acquire. Although consistency learning has been proven to be an effective approach by enforcing an invariance of predictions under different distributions, existing approaches cannot make full use of region-level shape constraint and boundary-level distance information from unlabeled data. In this paper, we propose a novel uncertainty-guided mutual consistency learning framework to effectively exploit unlabeled data by integrating intra-task consistency learning from up-to-date predictions for self-ensembling and cross-task consistency learning from task-level regularization to exploit geometric shape information. The framework is guided by the estimated segmentation uncertainty of models to select out relatively certain predictions for consistency learning, so as to effectively exploit more reliable information from unlabeled data. We extensively validate our proposed method on two publicly available benchmark datasets: Left Atrium Segmentation (LA) dataset and Brain Tumor Segmentation (BraTS) dataset. Experimental results demonstrate that our method achieves performance gains by leveraging unlabeled data and outperforms existing semi-supervised segmentation methods.      
### 34.Double-Phase-Shifter based Hybrid Beamforming for mmWave DFRC in the Presence of Extended Target and Clutters  [ :arrow_down: ](https://arxiv.org/pdf/2112.02496.pdf)
>  In millimeter-wave (mmWave) dual-function radar-communication (DFRC) systems, hybrid beamforming (HBF) is recognized as a promising technique utilizing a limited number of radio frequency chains. In this work, in the presence of extended target and clutters, a HBF design based on the subarray connection architecture is proposed for a multiple-input multiple-output (MIMO) DFRC system. In this HBF, the double-phase-shifter (DPS) structure is embedded to further increase the design flexibility. We derive the communication spectral efficiency (SE) and radar signal-to-interference-plus-noise-ratio (SINR) with respect to the transmit HBF and radar receiver, and formulate the HBF design problem as the SE maximization subjecting to the radar SINR and power constraints. To solve the formulated nonconvex problem, the joinT Hybrid bRamforming and Radar rEceiver OptimizatioN (THEREON) is proposed, in which the radar receiver is optimized via the generalized eigenvalue decomposition, and the transmit HBF is updated with low complexity in a parallel manner using the consensus alternating direction method of multipliers (consensus-ADMM). Furthermore, we extend the proposed method to the multi-user multiple-input single-output (MU-MISO) scenario. Numerical simulations demonstrate the efficacy of the proposed algorithm and show that the solution provides a good trade-off between number of phase shifters and performance gain of the DPS HBF.      
### 35.Classification of COVID-19 on chest X-Ray images using Deep Learning model with Histogram Equalization and Lungs Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.02478.pdf)
>  Background and Objective: Artificial intelligence (AI) methods coupled with biomedical analysis has a critical role during pandemics as it helps to release the overwhelming pressure from healthcare systems and physicians. As the ongoing COVID-19 crisis worsens in countries having dense populations and inadequate testing kits like Brazil and India, radiological imaging can act as an important diagnostic tool to accurately classify covid-19 patients and prescribe the necessary treatment in due time. With this motivation, we present our study based on deep learning architecture for detecting covid-19 infected lungs using chest X-rays. Dataset: We collected a total of 2470 images for three different class labels, namely, healthy lungs, ordinary pneumonia, and covid-19 infected pneumonia, out of which 470 X-ray images belong to the covid-19 category. Methods: We first pre-process all the images using histogram equalization techniques and segment them using U-net architecture. VGG-16 network is then used for feature extraction from the pre-processed images which is further sampled by SMOTE oversampling technique to achieve a balanced dataset. Finally, the class-balanced features are classified using a support vector machine (SVM) classifier with 10-fold cross-validation and the accuracy is evaluated. Result and Conclusion: Our novel approach combining well-known pre-processing techniques, feature extraction methods, and dataset balancing method, lead us to an outstanding rate of recognition of 98% for COVID-19 images over a dataset of 2470 X-ray images. Our model is therefore fit to be utilized in healthcare facilities for screening purposes.      
### 36.RIS-Aided D2D Communications Relying on Statistical CSI with Imperfect Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2112.02331.pdf)
>  In this letter, we investigate a reconfigurable intelligent surfaces (RIS)-aided device to device (D2D) communication system over Rician fading channels with imperfect hardware including both hardware impairment at the transceivers and phase noise at the RISs. This paper has optimized the phase shift by a genetic algorithm (GA) method to maximize the achievable rate for the continuous phase shifts (CPSs) and discrete phase shifts (DPSs). We also consider the two special cases of no RIS hardware impairments (N-RIS-HWIs) and no transceiver hardware impairments (N-T-HWIs). We present closed-form expressions for the achievable rate of different cases and study the impact of hardware impairments on the communication quality. Finally, simulation results validate the analytic work.      
### 37.A Novel Two-stage Design Scheme of Equalizers for Uplink FBMC/OQAM-based Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.02324.pdf)
>  The self-equalization property has raised great concern in the combination of offset-quadratic-amplitude-modulation-based filter bank multi-carrier (FBMC/OQAM) and massive multiple-input multiple-output (MIMO) system, which enables to decrease the interference brought by the highly frequency-selective channels as the number of base station (BS) antennas increases. However, existing works show that there remains residual interference after single-tap equalization even with infinite number of BS antennas, leading to a limitation of achievable signal-to-interference-plus-noise ratio (SINR) performance. In this paper, we propose a two-stage design scheme of equalizers to remove the above limitation. In the first stage, we design high-rate equalizers working before FBMC demodulation to avoid the potential loss of channel information obtained at the BS. In the second stage, we transform the high-rate equalizers into the low-rate equalizers after FBMC demodulation to reduce the implementation complexity. Compared with prior works, the proposed scheme has affordable complexity under massive MIMO and only requires instantaneous channel state information (CSI) without statistical CSI and additional equalizers. Simulation results show that the scheme can bring improved SINR performance. Moreover, even with finite number of BS antennas, the interference brought by the channels can be almost eliminated.      
### 38.Deep-Unfolding Beamforming for Intelligent Reflecting Surface assisted Full-Duplex Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.02305.pdf)
>  In this paper, we investigate an intelligent reflecting surface (IRS) assisted multi-user multiple-input multiple-output (MIMO) full-duplex (FD) system. We jointly optimize the active beamforming matrices at the access point (AP) and uplink users, and the passive beamforming matrix at the IRS to maximize the weighted sum-rate of the system. Since it is practically difficult to acquire the channel state information (CSI) for IRS-related links due to its passive operation and large number of elements, we conceive a mixed-timescale beamforming scheme. Specifically, the high-dimensional passive beamforming matrix at the IRS is updated based on the channel statistics while the active beamforming matrices are optimized relied on the low-dimensional real-time effective CSI at each time slot. We propose an efficient stochastic successive convex approximation (SSCA)-based algorithm for jointly designing the active and passive beamforming matrices. Moreover, due to the high computational complexity caused by the matrix inversion computation in the SSCA-based optimization algorithm, we further develop a deep-unfolding neural network (NN) to address this issue. The proposed deep-unfolding NN maintains the structure of the SSCA-based algorithm but introduces a novel non-linear activation function and some learnable parameters induced by the first-order Taylor expansion to approximate the matrix inversion. In addition, we develop a black-box NN as a benchmark. Simulation results show that the proposed mixed-timescale algorithm outperforms the existing single-timescale algorithm and the proposed deep-unfolding NN approaches the performance of the SSCA-based algorithm with much reduced computational complexity when deployed online.      
### 39.Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides  [ :arrow_down: ](https://arxiv.org/pdf/2112.02222.pdf)
>  Objectives: To develop and validate a deep learning (DL)-based primary tumor biopsy signature for predicting axillary lymph node (ALN) metastasis preoperatively in early breast cancer (EBC) patients with clinically negative ALN. <br>Methods: A total of 1,058 EBC patients with pathologically confirmed ALN status were enrolled from May 2010 to August 2020. A DL core-needle biopsy (DL-CNB) model was built on the attention-based multiple instance-learning (AMIL) framework to predict ALN status utilizing the DL features, which were extracted from the cancer areas of digitized whole-slide images (WSIs) of breast CNB specimens annotated by two pathologists. Accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curves, and areas under the ROC curve (AUCs) were analyzed to evaluate our model. <br>Results: The best-performing DL-CNB model with VGG16_BN as the feature extractor achieved an AUC of 0.816 (95% confidence interval (CI): 0.758, 0.865) in predicting positive ALN metastasis in the independent test cohort. Furthermore, our model incorporating the clinical data, which was called DL-CNB+C, yielded the best accuracy of 0.831 (95%CI: 0.775, 0.878), especially for patients younger than 50 years (AUC: 0.918, 95%CI: 0.825, 0.971). The interpretation of DL-CNB model showed that the top signatures most predictive of ALN metastasis were characterized by the nucleus features including density ($p$ = 0.015), circumference ($p$ = 0.009), circularity ($p$ = 0.010), and orientation ($p$ = 0.012). <br>Conclusion: Our study provides a novel DL-based biomarker on primary tumor CNB slides to predict the metastatic status of ALN preoperatively for patients with EBC.      
### 40.A Computational Efficient Maximum Likelihood Direct Position Determination Approach for Multiple Emitters Using Angle and Doppler Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2112.02218.pdf)
>  Emitter localization is widely applied in the military and civilian _elds. In this paper, we tackle the problem of position estimation for multiple stationary emitters using Doppler frequency shifts and angles by moving receivers. The computational load for the exhaustive maximum likelihood (ML) direct position determination (DPD) search is insu_erable. Based on the Pincus' theorem and importance sampling (IS) concept, we propose a novel non-iterative ML DPD method. The proposed method transforms the original multidimensional grid search into random variables generation with multiple low-dimensional pseudo-probability density functions (PDF), and the circular mean is used for superior position estimation performance. The computational complexity of the proposed method is modest, and the o_-grid problem that most existing DPD techniques face is signi_cantly alleviated. Moreover, it can be implemented in parallel separately. Simulation results demonstrate that the proposed ML DPD estimator can achieve better estimation accuracy than state-of-the-art DPD techniques. With a reasonable parameter choice, the estimation performance of the proposed technique is very close to the Cram_er-Rao lower bound (CRLB), even in the adverse conditions of low signal-to-noise ratios (SNR) levels.      
### 41.Optimal Participation of Heterogeneous, RES-based Virtual Power Plants in Energy Markets  [ :arrow_down: ](https://arxiv.org/pdf/2112.02200.pdf)
>  In this work, we present a detailed model of a Renewable Energy Source (RES)-based Virtual Power Plant (VPP) that participates in Day-Ahead Market (DAM) and Intra-Day Market (IDM) with dispatchable and non-dispatchable RESs and flexible demand assets. We propose a demand model with bi-level flexibility which are associated with the market sessions plus an improved solar thermal plant model with piece-wise linear formulation of efficiency. A network-constrained unit commitment model is used by the VPP to submit DAM auctions and consequently participates in IDM to correct for deviations. Finally, we validate our model by assessing its operation on different weather conditions of uncertainty.      
### 42.Bridging the gap between prostate radiology and pathology through machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.02164.pdf)
>  Prostate cancer is the second deadliest cancer for American men. While Magnetic Resonance Imaging (MRI) is increasingly used to guide targeted biopsies for prostate cancer diagnosis, its utility remains limited due to high rates of false positives and false negatives as well as low inter-reader agreements. Machine learning methods to detect and localize cancer on prostate MRI can help standardize radiologist interpretations. However, existing machine learning methods vary not only in model architecture, but also in the ground truth labeling strategies used for model training. In this study, we compare different labeling strategies, namely, pathology-confirmed radiologist labels, pathologist labels on whole-mount histopathology images, and lesion-level and pixel-level digital pathologist labels (previously validated deep learning algorithm on histopathology images to predict pixel-level Gleason patterns) on whole-mount histopathology images. We analyse the effects these labels have on the performance of the trained machine learning models. Our experiments show that (1) radiologist labels and models trained with them can miss cancers, or underestimate cancer extent, (2) digital pathologist labels and models trained with them have high concordance with pathologist labels, and (3) models trained with digital pathologist labels achieve the best performance in prostate cancer detection in two different cohorts with different disease distributions, irrespective of the model architecture used. Digital pathologist labels can reduce challenges associated with human annotations, including labor, time, inter- and intra-reader variability, and can help bridge the gap between prostate radiology and pathology by enabling the training of reliable machine learning models to detect and localize prostate cancer on MRI.      
### 43.Wireless Power Transmission on Martian Surface for Zero-Energy Devices  [ :arrow_down: ](https://arxiv.org/pdf/2112.02154.pdf)
>  Exploration of the Red Planet is essential on the way through both human colonization and establishing a habitat on the planet. Due to the high costs of space missions, the use of distributed sensor networks has been investigated to make in situ explorations affordable. Along with this, the devices with ultra-low-power receivers, which are called zero-energy devices, can pave the way to further discoveries for the environment of Mars. This study focuses on wireless power transmission to provide the power desired by zero-energy devices on the Martian surface. The main motivation of this study is to investigate whether conventional harvesters and communication units can supply the required power for a long distance. The numerical results show that it is possible to deliver power to zero-energy devices without utilizing any sophisticated hardware.      
### 44.NN Based Active Disturbance Rejection Controller for a Multi-Axis Gimbal System  [ :arrow_down: ](https://arxiv.org/pdf/2112.02130.pdf)
>  The increasing demand for target tracking, environmental surveys, surveillance and mapping requires multi-axis gimbal systems with high tracking and stabilization performance. In this paper, first, computed torque model is generated to estimate the complex disturbances acting on the system. Then, two different control strategies based on active disturbance rejection control (ADRC) and computed torque model are implemented on a two-axis gimbal system. The purpose is to improve the robustness, environmental adaptability and tracking accuracy of the system and reduce the tuning effort of ADRC by integrating a neural network (NN) based disturbance compensator (NN assisted ADRC). In the second control strategy, NN is replaced with a computed torque model (CTM assisted ADRC), whose inputs come from plant outputs. The simulation results show that, NN and CTM assisted ADRC structures can decrease mean tracking errors up to 85.4% and 40.8%, respectively.      
### 45.Echocardiography Segmentation with Enforced Temporal Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2112.02102.pdf)
>  Convolutional neural networks (CNN) have demonstrated their ability to segment 2D cardiac ultrasound images. However, despite recent successes according to which the intra-observer variability on end-diastole and end-systole images has been reached, CNNs still struggle to leverage temporal information to provide accurate and temporally consistent segmentation maps across the whole cycle. Such consistency is required to accurately describe the cardiac function, a necessary step in diagnosing many cardiovascular diseases. In this paper, we propose a framework to learn the 2D+time long-axis cardiac shape such that the segmented sequences can benefit from temporal and anatomical consistency constraints. Our method is a post-processing that takes as input segmented echocardiographic sequences produced by any state-of-the-art method and processes it in two steps to (i) identify spatio-temporal inconsistencies according to the overall dynamics of the cardiac sequence and (ii) correct the inconsistencies. The identification and correction of cardiac inconsistencies relies on a constrained autoencoder trained to learn a physiologically interpretable embedding of cardiac shapes, where we can both detect and fix anomalies. We tested our framework on 98 full-cycle sequences from the CAMUS dataset, which will be rendered public alongside this paper. Our temporal regularization method not only improves the accuracy of the segmentation across the whole sequences, but also enforces temporal and anatomical consistency.      
### 46.View-Consistent Metal Segmentation in the Projection Domain for Metal Artifact Reduction in CBCT -- An Investigation of Potential Improvement  [ :arrow_down: ](https://arxiv.org/pdf/2112.02101.pdf)
>  The positive outcome of a trauma intervention depends on an intraoperative evaluation of inserted metallic implants. Due to occurring metal artifacts, the quality of this evaluation heavily depends on the performance of so-called Metal Artifact Reduction methods (MAR). The majority of these MAR methods require prior segmentation of the inserted metal objects. Therefore, typically a rather simple thresholding-based segmentation method in the reconstructed 3D volume is applied, despite some major disadvantages. With this publication, the potential of shifting the segmentation task to a learning-based, view-consistent 2D projection-based method on the downstream MAR's outcome is investigated. For segmenting the present metal, a rather simple learning-based 2D projection-wise segmentation network that is trained using real data acquired during cadaver studies, is examined. To overcome the disadvantages that come along with a 2D projection-wise segmentation, a Consistency Filter is proposed. The influence of the shifted segmentation domain is investigated by comparing the results of the standard fsMAR with a modified fsMAR version using the new segmentation masks. With a quantitative and qualitative evaluation on real cadaver data, the investigated approach showed an increased MAR performance and a high insensitivity against metal artifacts. For cases with metal outside the reconstruction's FoV or cases with vanishing metal, a significant reduction in artifacts could be shown. Thus, increases of up to roughly 3 dB w.r.t. the mean PSNR metric over all slices and up to 9 dB for single slices were achieved. The shown results reveal a beneficial influence of the shift to a 2D-based segmentation method on real data for downstream use with a MAR method, like the fsMAR.      
### 47.Full-Duplex Massive MIMO Cellular Networks with Low Resolution ADC/DAC  [ :arrow_down: ](https://arxiv.org/pdf/2112.02096.pdf)
>  In this paper, we provide an analytical framework for full-duplex (FD) massive multiple-input multiple-output (MIMO) cellular networks with low resolution analog-to-digital and digital-to-analog converters (ADCs and DACs). Matched filters are employed at the FD base stations (BSs) at the transmit and receive sides. For both reverse and forward links, we derive the expressions of the signal-to-quantization-plus-interference-and-noise ratio (SQINR) for general and special cases. We further evaluate the outage probability and spectral efficiency for reverse and forward links, and quantify the effects of the quantization error, loopback self-interference and inter-user interference for cells arranged in a hexagonal lattice and Poisson Point Process (PPP) tessellations. Finally, we derive analytical expressions for spectral efficiency for asymptotic cases as well as for power scaling laws.      
### 48.Novel Local Radiomic Bayesian Classifiers for Non-Invasive Prediction of MGMT Methylation Status in Glioblastoma  [ :arrow_down: ](https://arxiv.org/pdf/2112.03259.pdf)
>  Glioblastoma, an aggressive brain cancer, is amongst the most lethal of all cancers. Expression of the O6-methylguanine-DNA-methyltransferase (MGMT) gene in glioblastoma tumor tissue is of clinical importance as it has a significant effect on the efficacy of Temozolomide, the primary chemotherapy treatment administered to glioblastoma patients. Currently, MGMT methylation is determined through an invasive brain biopsy and subsequent genetic analysis of the extracted tumor tissue. In this work, we present novel Bayesian classifiers that make probabilistic predictions of MGMT methylation status based on radiomic features extracted from FLAIR-sequence magnetic resonance imagery (MRIs). We implement local radiomic techniques to produce radiomic activation maps and analyze MRIs for the MGMT biomarker based on statistical features of raw voxel-intensities. We demonstrate the ability for simple Bayesian classifiers to provide a boost in predictive performance when modelling local radiomic data rather than global features. The presented techniques provide a non-invasive MRI-based approach to determining MGMT methylation status in glioblastoma patients.      
### 49.Modeling synchronization in human musical rhythms using Impulse Pattern Formulation (IPF)  [ :arrow_down: ](https://arxiv.org/pdf/2112.03218.pdf)
>  When musicians perform in an ensemble, synchronizing to a mutual pace is the foundation of their musical interaction. Clock generators, e.g., metronomes, or drum machines, might assist such synchronization, but these means, in general, will also distort this natural, self-organized, inter-human synchronization process. In this work, the synchronization of musicians to an external rhythm is modeled using the Impulse Pattern Formulation (IPF), an analytical modeling approach for synergetic systems motivated by research on musical instruments. Nonlinear coupling of system components is described as the interaction of individually propagating and exponentially damped impulse trains. The derived model is systematically examined by analyzing its behavior when coupled to numerical designed and carefully controlled rhythmical beat sequences. The results are evaluated by comparison in the light of other publications on tapping. Finally, the IPF model can be applied to analyze the personal rhythmical signature of specific musicians or to replace drum machines and click tracks with more musical and creative solutions.      
### 50.Piano Timbre Development Analysis using Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.03214.pdf)
>  All 88 keys of a piano at two stages, right after production (stage 1) and one year after playing (stage 2) are investigated using Music Information Retrieval (MIR) timbre extraction and Machine Learning (ML). In \cite{Plath2019} it was found that listeners clearly distinguished both stages but no clear correlation with acoustics, signal processing tools or verbalizations of perceived differences could be found. Using a Self-Organizing Map (SOM) training single as well as double feature sets it is found that spectral flux is able to perfectly cluster the two pianos. Sound Pressure Level (SPL), roughness, and fractal correlation dimension, as a measure for initial transient chaoticity are furthermore able to order the keys with respect to high and low tones. Combining spectral flux with the three other features in double-feature training sets maintain stage clustering only for SPL and fractal dimension, showing sub-clusters for both stages. These sub-clusters point to a homogenization of SPL for stage 2 with respect to stage 1 and a pronounced ordering and sub-clustering of key regions with respect to initial transient chaoticity.      
### 51.Physically Consistent Neural Networks for building thermal modeling: theory and analysis  [ :arrow_down: ](https://arxiv.org/pdf/2112.03212.pdf)
>  Due to their high energy intensity, buildings play a major role in the current worldwide energy transition. Building models are ubiquitous since they are needed at each stage of the life of buildings, i.e. for design, retrofitting, and control operations. Classical white-box models, based on physical equations, are bound to follow the laws of physics but the specific design of their underlying structure might hinder their expressiveness and hence their accuracy. On the other hand, black-box models are better suited to capture nonlinear building dynamics and thus can often achieve better accuracy, but they require a lot of data and might not follow the laws of physics, a problem that is particularly common for neural network (NN) models. To counter this known generalization issue, physics-informed NNs have recently been introduced, where researchers introduce prior knowledge in the structure of NNs to ground them in known underlying physical laws and avoid classical NN generalization issues. <br>In this work, we present a novel physics-informed NN architecture, dubbed Physically Consistent NN (PCNN), which only requires past operational data and no engineering overhead, including prior knowledge in a linear module running in parallel to a classical NN. We formally prove that such networks are physically consistent -- by design and even on unseen data -- with respect to different control inputs and temperatures outside and in neighboring zones. We demonstrate their performance on a case study, where the PCNN attains an accuracy up to $50\%$ better than a classical physics-based resistance-capacitance model on $3$-day long prediction horizons. Furthermore, despite their constrained structure, PCNNs attain similar performance to classical NNs on the validation data, overfitting the training data less and retaining high expressiveness to tackle the generalization issue.      
### 52.Intelligent Acoustic Module for Autonomous Vehicles using Fast Gated Recurrent approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.03174.pdf)
>  This paper elucidates a model for acoustic single and multi-tone classification in resource constrained edge devices. The proposed model is of State-of-the-art Fast Accurate Stable Tiny Gated Recurrent Neural Network. This model has resulted in improved performance metrics and lower size compared to previous hypothesized methods by using lesser parameters with higher efficiency and employment of a noise reduction algorithm. The model is implemented as an acoustic AI module, focused for the application of sound identification, localization, and deployment on AI systems like that of an autonomous car. Further, the inclusion of localization techniques carries the potential of adding a new dimension to the multi-tone classifiers present in autonomous vehicles, as its demand increases in urban cities and developing countries in the future.      
### 53.VocBench: A Neural Vocoder Benchmark for Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2112.03099.pdf)
>  Neural vocoders, used for converting the spectral representations of an audio signal to the waveforms, are a commonly used component in speech synthesis pipelines. It focuses on synthesizing waveforms from low-dimensional representation, such as Mel-Spectrograms. In recent years, different approaches have been introduced to develop such vocoders. However, it becomes more challenging to assess these new vocoders and compare their performance to previous ones. To address this problem, we present VocBench, a framework that benchmark the performance of state-of-the art neural vocoders. VocBench uses a systematic study to evaluate different neural vocoders in a shared environment that enables a fair comparison between them. In our experiments, we use the same setup for datasets, training pipeline, and evaluation metrics for all neural vocoders. We perform a subjective and objective evaluation to compare the performance of each vocoder along a different axis. Our results demonstrate that the framework is capable of showing the competitive efficacy and the quality of the synthesized samples for each vocoder. VocBench framework is available at <a class="link-external link-https" href="https://github.com/facebookresearch/vocoder-benchmark" rel="external noopener nofollow">this https URL</a>.      
### 54.Deep Learning for automated phase segmentation in EBSD maps. A case study in Dual Phase steel microstructures  [ :arrow_down: ](https://arxiv.org/pdf/2112.03072.pdf)
>  Electron Backscattering Diffraction (EBSD) provides important information to discriminate phase transformation products in steels. This task is conventionally performed by an expert, who carries a high degree of subjectivity and requires time and effort. In this paper, we question if Convolutional Neural Networks (CNNs) are able to extract meaningful features from EBSD-based data in order to automatically classify the present phases within a steel microstructure. The selected case of study is ferrite-martensite discrimination and U-Net has been selected as the network architecture to work with. Pixel-wise accuracies around ~95% have been obtained when inputting raw orientation data, while ~98% has been reached with orientation-derived parameters such as Kernel Average Misorientation (KAM) or pattern quality. Compared to other available approaches in the literature for phase discrimination, the models presented here provided higher accuracies in shorter times. These promising results open a possibility to work on more complex steel microstructures.      
### 55.UAV Formation Preservation for Target Tracking Applications  [ :arrow_down: ](https://arxiv.org/pdf/2112.03012.pdf)
>  This paper presents a collaborative target tracking application with multiple agents and a formulation of an agent-formation problem with desired inter-agent distances and specified bounds. We propose a barrier Lyapunov function-based distributed control law to preserve the formation for target-tracking and assess its stability using a kinematic model. Numerical results with this model are presented to demonstrate the advantages of the proposed control over a quadratic Lyapunov function-based control. A concluding evaluation using experimental ROS simulations is presented to illustrate the applicability of the proposed control approach to a multi-rotor system and a target executing straight line and circular motion.      
### 56.How News Evolves? Modeling News Text and Coverage using Graphs and Hawkes Process  [ :arrow_down: ](https://arxiv.org/pdf/2112.03008.pdf)
>  Monitoring news content automatically is an important problem. The news content, unlike traditional text, has a temporal component. However, few works have explored the combination of natural language processing and dynamic system models. One reason is that it is challenging to mathematically model the nuances of natural language. In this paper, we discuss how we built a novel dataset of news articles collected over time. Then, we present a method of converting news text collected over time to a sequence of directed multi-graphs, which represent semantic triples (Subject ! Predicate ! Object). We model the dynamics of specific topological changes from these graphs using discrete-time Hawkes processes. With our real-world data, we show that analyzing the structures of the graphs and the discrete-time Hawkes process model can yield insights on how the news events were covered and how to predict how it may be covered in the future.      
### 57.Cross-Modality Attentive Feature Fusion for Object Detection in Multispectral Remote Sensing Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2112.02991.pdf)
>  Cross-modality fusing complementary information of multispectral remote sensing image pairs can improve the perception ability of detection algorithms, making them more robust and reliable for a wider range of applications, such as nighttime detection. Compared with prior methods, we think different features should be processed specifically, the modality-specific features should be retained and enhanced, while the modality-shared features should be cherry-picked from the RGB and thermal IR modalities. Following this idea, a novel and lightweight multispectral feature fusion approach with joint common-modality and differential-modality attentions are proposed, named Cross-Modality Attentive Feature Fusion (CMAFF). Given the intermediate feature maps of RGB and IR images, our module parallel infers attention maps from two separate modalities, common- and differential-modality, then the attention maps are multiplied to the input feature map respectively for adaptive feature enhancement or selection. Extensive experiments demonstrate that our proposed approach can achieve the state-of-the-art performance at a low computation cost.      
### 58.Reinforcement Learning for Navigation of Mobile Robot with LiDAR  [ :arrow_down: ](https://arxiv.org/pdf/2112.02954.pdf)
>  This paper presents a technique for navigation of mobile robot with Deep Q-Network (DQN) combined with Gated Recurrent Unit (GRU). The DQN integrated with the GRU allows action skipping for improved navigation performance. This technique aims at efficient navigation of mobile robot such as autonomous parking robot. Framework for reinforcement learning can be applied to the DQN combined with the GRU in a real environment, which can be modeled by the Partially Observable Markov Decision Process (POMDP). By allowing action skipping, the ability of the DQN combined with the GRU in learning key-action can be improved. The proposed algorithm is applied to explore the feasibility of solution in real environment by the ROS-Gazebo simulator, and the simulation results show that the proposed algorithm achieves improved performance in navigation and collision avoidance as compared to the results obtained by DQN alone and DQN combined with GRU without allowing action skipping.      
### 59.The artificial synesthete: Image-melody translations with variational autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2112.02953.pdf)
>  Abstract This project presents a system of neural networks to translate between images and melodies. Autoencoders compress the information in samples to abstract representation. A translation network learns a set of correspondences between musical and visual concepts from repeated joint exposure. The resulting "artificial synesthete" generates simple melodies inspired by images, and images from music. These are novel interpretation (not transposed data), expressing the machine' perception and understanding. Observing the work, one explores the machine's perception and thus, by contrast, one's own.      
### 60.Channel Estimation for Large Intelligent Surface-Based Transceiver Using a Parametric Channel Model  [ :arrow_down: ](https://arxiv.org/pdf/2112.02874.pdf)
>  Large intelligent surface-based transceivers (LISBTs), in which a spatially continuous surface is being used for signal transmission and reception, have emerged as a promising solution for improving the coverage and data rate of wireless communication systems. To realize these objectives, the acquisition of accurate channel state information (CSI) in LISBT-assisted wireless communication systems is crucial. In this paper, we propose a channel estimation scheme based on a parametric physical channel model for line-of-sight dominated communication in millimeter and terahertz wave bands. The proposed estimation scheme requires only five pilot signals to perfectly estimate the channel parameters assuming there is no noise at the receiver. In the presence of noise, we propose an iterative estimation algorithm that decreases the channel estimation error due to noise. The training overhead and computational cost of the proposed scheme do not scale with the number of antennas. The simulation results demonstrate that the proposed estimation scheme significantly outperforms other benchmark schemes.      
### 61.A Dataset-free Self-supervised Disentangled Learning Method for Adaptive Infrared and Visible Images Super-resolution Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2112.02869.pdf)
>  This study proposes a novel general dataset-free self-supervised learning framework based-on physical model named self-supervised disentangled learning (SDL), and proposes a novel method named Deep Retinex fusion (DRF) which applies SDL framework with generative networks and Retinex theory in infrared and visible images super-resolution fusion. Meanwhile, a generative dual-path fusion network ZipperNet and adaptive fusion loss function Retinex loss are designed for effectively high-quality fusion. The core idea of DRF (based-on SDL) consists of two parts: one is generating components which are disentangled from physical model using generative networks; the other is loss functions which are designed based-on physical relation, and generated components are combined by loss functions in training phase. Furthermore, in order to verify the effectiveness of our proposed DRF, qualitative and quantitative comparisons compared with six state-of-the-art methods are performed on three different infrared and visible datasets. Our code will be open source available soon at <a class="link-external link-https" href="https://github.com/GuYuanjie/Deep-Retinex-fusion" rel="external noopener nofollow">this https URL</a>.      
### 62.No-Reference Point Cloud Quality Assessment via Domain Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2112.02851.pdf)
>  We present a novel no-reference quality assessment metric, the image transferred point cloud quality assessment (IT-PCQA), for 3D point clouds. For quality assessment, deep neural network (DNN) has shown compelling performance on no-reference metric design. However, the most challenging issue for no-reference PCQA is that we lack large-scale subjective databases to drive robust networks. Our motivation is that the human visual system (HVS) is the decision-maker regardless of the type of media for quality assessment. Leveraging the rich subjective scores of the natural images, we can quest the evaluation criteria of human perception via DNN and transfer the capability of prediction to 3D point clouds. In particular, we treat natural images as the source domain and point clouds as the target domain, and infer point cloud quality via unsupervised adversarial domain adaptation. To extract effective latent features and minimize the domain discrepancy, we propose a hierarchical feature encoder and a conditional-discriminative network. Considering that the ultimate purpose is regressing objective score, we introduce a novel conditional cross entropy loss in the conditional-discriminative network to penalize the negative samples which hinder the convergence of the quality regression network. Experimental results show that the proposed method can achieve higher performance than traditional no-reference metrics, even comparable results with full-reference metrics. The proposed method also suggests the feasibility of assessing the quality of specific media content without the expensive and cumbersome subjective evaluations.      
### 63.SyntEO: Synthetic Dataset Generation for Earth Observation with Deep Learning -- Demonstrated for Offshore Wind Farm Detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.02829.pdf)
>  With the emergence of deep learning in the last years, new opportunities arose in Earth observation research. Nevertheless, they also brought with them new challenges. The data-hungry training processes of deep learning models demand large, resource expensive, annotated datasets and partly replaced knowledge-driven approaches, so that model behaviour and the final prediction process became a black box. The proposed SyntEO approach enables Earth observation researchers to automatically generate large deep learning ready datasets and thus free up otherwise occupied resources. SyntEO does this by including expert knowledge in the data generation process in a highly structured manner. In this way, fully controllable experiment environments are set up, which support insights in the model training. Thus, SyntEO makes the learning process approachable and model behaviour interpretable, an important cornerstone for explainable machine learning. We demonstrate the SyntEO approach by predicting offshore wind farms in Sentinel-1 images on two of the worlds largest offshore wind energy production sites. The largest generated dataset has 90,000 training examples. A basic convolutional neural network for object detection, that is only trained on this synthetic data, confidently detects offshore wind farms by minimising false detections in challenging environments. In addition, four sequential datasets are generated, demonstrating how the SyntEO approach can precisely define the dataset structure and influence the training process. SyntEO is thus a hybrid approach that creates an interface between expert knowledge and data-driven image analysis.      
### 64.Mitigating Biological Epidemic on Heterogeneous Social Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.02811.pdf)
>  Recent Covid-19 pandemic has demonstrated the need of efficient epidemic outbreak management. We study the optimal control problem of minimizing the fraction of infected population by applying vaccination and treatment control strategies, while at the same time minimizing the cost of implementing them. We model the epidemic using the degree based Susceptible-Infected-Recovered (SIR) compartmental model. We study the impact of varying network topologies on the optimal epidemic management strategies and present results for the Erdos-Renyi, scale free, and real world networks. For efficient computational modeling we form groups of groups of degree classes, and apply separate vaccination and treatment control signals to each group. This allows us to identify the degree classes that play a significant role in mitigating the epidemic for a given network topology. We compare the optimal control strategy with non optimal strategies (constant control and no control) and study the effect of various model parameters on the system. We identify which strategy (vaccination/treatment) plays a significant role in controlling the epidemic on different network topologies. We also study the effect of the cost of vaccination and treatment controls on the resource allocation. We find that the optimal strategy achieves significant improvements over the non optimal heuristics for all networks studied in this paper. Our results may be of interest to governments and healthcare authorities for devising effective vaccination and treatment campaigns during an epidemic outbreak.      
### 65.Multi-User Holographic MIMO Surface: Channel Modeling and Spectral Efficiency Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2112.02803.pdf)
>  The multi-user Holographic Multiple-Input and Multiple-Output Surface (MU-HMIMOS) paradigm, which is capable of realizing large continuous apertures with minimal power consumption, has been recently considered as an energyefficient solution for future wireless networks, offering the increased flexibility in impacting electromagnetic wave propagation according to the desired communication, localization, and sensing objectives. The tractable channel modeling of MU-HMIMOS systems is one of the most critical challenges, mainly due to the coupling effect induced by the excessively large number of closely spaced patch antennas. In this paper, we focus on this challenge for downlink multi-user communications and model the electromagnetic channel in the wavenumber domain using the Fourier plane wave representation. Based on the proposed channel model, we devise the maximum-ratio transmission and Zero-Forcing (ZF) precoding schemes capitalizing on the sampled channel variance that depends on the number and spacing of the patch antennas in MU-HMIMOS, and present their analytical spectral efficiency performance. Moreover, we propose a low computational ZF precoding scheme leveraging Neumann series expansion to replace the matrix inversion, since it is practically impossible to perform direct matrix inversion when the number of patch antennas is extremely large. Our extensive simulation results showcase the impact of the number of patch antennas and their spacing on the spectral efficiency of the considered systems. It is shown that the more patch antennas and larger spacing results in improved performance due to the decreased correlation among the patches.      
### 66.Conditional Deep Hierarchical Variational Autoencoder for Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2112.02796.pdf)
>  Variational autoencoder-based voice conversion (VAE-VC) has the advantage of requiring only pairs of speeches and speaker labels for training. Unlike the majority of the research in VAE-VC which focuses on utilizing auxiliary losses or discretizing latent variables, this paper investigates how an increasing model expressiveness has benefits and impacts on the VAE-VC. Specifically, we first analyze VAE-VC from a rate-distortion perspective, and point out that model expressiveness is significant for VAE-VC because rate and distortion reflect similarity and naturalness of converted speeches. Based on the analysis, we propose a novel VC method using a deep hierarchical VAE, which has high model expressiveness as well as having fast conversion speed thanks to its non-autoregressive decoder. Also, our analysis reveals another problem that similarity can be degraded when the latent variable of VAEs has redundant information. We address the problem by controlling the information contained in the latent variable using $\beta$-VAE objective. In the experiment using VCTK corpus, the proposed method achieved mean opinion scores higher than 3.5 on both naturalness and similarity in inter-gender settings, which are higher than the scores of existing autoencoder-based VC methods.      
### 67.Autonomous Heavy-Duty Mobile Machinery: A Multidisciplinary Collaborative Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2112.02662.pdf)
>  Heavy-duty mobile machines (HDMMs) are a wide range of machinery used in diverse and critical application areas which are currently facing several issues like skilled labor shortage, poor safety records, and harsh work environments. Consequently, efforts are underway to increase automation in HDMMs for increased productivity and safety, eventually transitioning to operator-less autonomous HDMMs to address skilled labor shortages. However, HDMM are complex machines requiring continuous physical and cognitive inputs from human-operators. Thus, developing autonomous HDMM is a huge challenge, with current research and developments being performed in several independent research domains. Through this study, we use the bounded rationality concept to propose multidisciplinary collaborations for new autonomous HDMMs and apply the transaction cost economics framework to suggest future implications in the HDMM industry. Furthermore, we introduce a conceptual understanding of collaborations in the autonomous HDMM as a unified approach, while highlighting the practical implications and challenges of the complex nature of such multidisciplinary collaborations. The collaborative challenges and potentials are mapped out between the following topics: mechanical systems, AI methods, software systems, sensors, connectivity, simulations and process optimization, business cases, organization theories, and finally, regulatory frameworks.      
### 68.Improving Intention Detection in Single-Trial Classification through Fusion of EEG and Eye-tracker Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.02566.pdf)
>  Intention decoding is an indispensable procedure in hands-free human-computer interaction (HCI). Conventional eye-tracking system using single-model fixation duration possibly issues commands ignoring users' real expectation. In the current study, an eye-brain hybrid brain-computer interface (BCI) interaction system was introduced for intention detection through fusion of multi-modal eye-track and ERP (a measurement derived from EEG) features. Eye-track and EEG data were recorded from 64 healthy participants as they performed a 40-min customized free search task of a fixed target icon among 25 icons. The corresponding fixation duration of eye-tracking and ERP were extracted. Five previously-validated LDA-based classifiers (including RLDA, SWLDA, BLDA, SKLDA, and STDA) and the widely-used CNN method were adopted to verify the efficacy of feature fusion from both offline and pseudo-online analysis, and optimal approach was evaluated through modulating the training set and system response duration. Our study demonstrated that the input of multi-modal eye-track and ERP features achieved superior performance of intention detection in the single trial classification of active search task. And compared with single-model ERP feature, this new strategy also induced congruent accuracy across different classifiers. Moreover, in comparison with other classification methods, we found that the SKLDA exhibited the superior performance when fusing feature in offline test (ACC=0.8783, AUC=0.9004) and online simulation with different sample amount and duration length. In sum, the current study revealed a novel and effective approach for intention classification using eye-brain hybrid BCI, and further supported the real-life application of hands-free HCI in a more precise and stable manner.      
### 69.Deblurring via Stochastic Refinement  [ :arrow_down: ](https://arxiv.org/pdf/2112.02475.pdf)
>  Image deblurring is an ill-posed problem with multiple plausible solutions for a given input image. However, most existing methods produce a deterministic estimate of the clean image and are trained to minimize pixel-level distortion. These metrics are known to be poorly correlated with human perception, and often lead to unrealistic reconstructions. We present an alternative framework for blind deblurring based on conditional diffusion models. Unlike existing techniques, we train a stochastic sampler that refines the output of a deterministic predictor and is capable of producing a diverse set of plausible reconstructions for a given input. This leads to a significant improvement in perceptual quality over existing state-of-the-art methods across multiple standard benchmarks. Our predict-and-refine approach also enables much more efficient sampling compared to typical diffusion models. Combined with a carefully tuned network architecture and inference procedure, our method is competitive in terms of distortion metrics such as PSNR. These results show clear benefits of our diffusion-based method for deblurring and challenge the widely used strategy of producing a single, deterministic reconstruction.      
### 70.YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone  [ :arrow_down: ](https://arxiv.org/pdf/2112.02418.pdf)
>  YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.      
### 71.My(o) Armband Leaks Passwords: An EMG and IMU Based Keylogging Side-Channel Attack  [ :arrow_down: ](https://arxiv.org/pdf/2112.02382.pdf)
>  Wearables that constantly collect various sensor data of their users increase the chances for inferences of unintentional and sensitive information such as passwords typed on a physical keyboard. We take a thorough look at the potential of using electromyographic (EMG) data, a sensor modality which is new to the market but has lately gained attention in the context of wearables for augmented reality (AR), for a keylogging side-channel attack. Our approach is based on neural networks for a between-subject attack in a realistic scenario using the Myo Armband to collect the sensor data. In our approach, the EMG data has proven to be the most prominent source of information compared to the accelerometer and gyroscope, increasing the keystroke detection performance. For our end-to-end approach on raw data, we report a mean balanced accuracy of about 76 % for the keystroke detection and a mean top-3 key accuracy of about 32 % on 52 classes for the key identification on passwords of varying strengths. We have created an extensive dataset including more than 310 000 keystrokes recorded from 37 volunteers, which is available as open access along with the source code used to create the given results.      
### 72.Active Sensing for Search and Tracking: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2112.02381.pdf)
>  Active Position Estimation (APE) is the task of localizing one or more targets using one or more sensing platforms. APE is a key task for search and rescue missions, wildlife monitoring, source term estimation, and collaborative mobile robotics. Success in APE depends on the level of cooperation of the sensing platforms, their number, their degrees of freedom and the quality of the information gathered. APE control laws enable active sensing by satisfying either pure-exploitative or pure-explorative criteria. The former minimizes the uncertainty on position estimation; whereas the latter drives the platform closer to its task completion. In this paper, we define the main elements of APE to systematically classify and critically discuss the state of the art in this domain. We also propose a reference framework as a formalism to classify APE-related solutions. Overall, this survey explores the principal challenges and envisages the main research directions in the field of autonomous perception systems for localization tasks. It is also beneficial to promote the development of robust active sensing methods for search and tracking applications.      
### 73.Alpaqa: A matrix-free solver for nonlinear MPC and large-scale nonconvex optimization  [ :arrow_down: ](https://arxiv.org/pdf/2112.02370.pdf)
>  This paper presents alpaqa, an open-source C++ implementation of an augmented Lagrangian method for nonconvex constrained numerical optimization, using the first-order PANOC algorithm as inner solver. The implementation is packaged as an easy-to-use library that can be used in C++ and Python. Furthermore, two improvements to the PANOC algorithm are proposed and their effectiveness is demonstrated in NMPC applications and on the CUTEst benchmarks for numerical optimization. The source code of the alpaqa library is available at <a class="link-external link-https" href="https://github.com/kul-optec/alpaqa" rel="external noopener nofollow">this https URL</a> and binary packages can be installed from <a class="link-external link-https" href="https://pypi.org/project/alpaqa" rel="external noopener nofollow">this https URL</a> .      
### 74.Per-Link Parallel and Distributed Hybrid Beamforming for Multi-User Multi-Cell Massive MIMO Millimeter Wave Full Duplex  [ :arrow_down: ](https://arxiv.org/pdf/2112.02335.pdf)
>  This paper presents two hybrid beamforming (HYBF) designs for a multi-user multi-cell millimeter (mmWave) full-duplex (FD) system. The base stations (BSs) and the users are assumed to be suffering from the limited dynamic range (LDR) noise. Firstly, we present a centralized HYBF (C-HYBF) scheme based on alternating optimization. In general, the complexity of C-HYBF schemes scales quadratically as a function of the number of users, which is very undesirable. Moreover, tremendous computational power is required to optimize numerous variables jointly in FD. Another major drawback is that huge communication overhead is also required to transfer complete channel state information (CSI) to the central node every channel coherence time. To overcome these drawbacks, we present a very low-complexity and highly scalable cooperative per-link parallel and distributed (P$\&amp;$D)-HYBF scheme. It allows each FD BS to update the beamformers for its users independently in parallel on different computational processors. Its complexity scales only linearly as the network size grows, making it desirable for the next generation of large and dense mmWave FD networks. Simulation results show that both designs significantly outperform the fully digital half-duplex (HD) system with only a few radio-frequency (RF) chains, achieve similar performance, and the P$\&amp;$D-HYBF requires considerably less execution time.      
### 75.Speech Separation Using an Asynchronous Fully Recurrent Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2112.02321.pdf)
>  Recent advances in the design of neural network architectures, in particular those specialized in modeling sequences, have provided significant improvements in speech separation performance. In this work, we propose to use a bio-inspired architecture called Fully Recurrent Convolutional Neural Network (FRCNN) to solve the separation task. This model contains bottom-up, top-down and lateral connections to fuse information processed at various time-scales represented by \textit{stages}. In contrast to the traditional approach updating stages in parallel, we propose to first update the stages one by one in the bottom-up direction, then fuse information from adjacent stages simultaneously and finally fuse information from all stages to the bottom stage together. Experiments showed that this asynchronous updating scheme achieved significantly better results with much fewer parameters than the traditional synchronous updating scheme. In addition, the proposed model achieved good balance between speech separation accuracy and computational efficiency as compared to other state-of-the-art models on three benchmark datasets.      
### 76.Feature-based Recognition Framework for Super-resolution Images  [ :arrow_down: ](https://arxiv.org/pdf/2112.02270.pdf)
>  In practical application, the performance of recognition network usually decreases when being applied on super-resolution images. In this paper, we propose a feature-based recognition network combined with GAN (FGAN). Our network improves the recognition accuracy by extracting more features that benefit recognition from SR images. In the experiment, we build three datasets using three different super-resolution algorithm, and our network increases the recognition accuracy by more than 6% comparing with ReaNet50 and DenseNet121.      
### 77.On the Implementation of Fixed-point Exponential Function for Machine Learning and Signal Processing Accelerators  [ :arrow_down: ](https://arxiv.org/pdf/2112.02263.pdf)
>  The natural exponential function is widely used in modeling many engineering and scientific systems. It is also an integral part of many neural network activation function such as sigmoid, tanh, ELU, RBF etc. Dedicated hardware accelerator and processors are designed for faster execution of such applications. Such accelerators can immensely benefit from an optimal implementation of exponential function. This can be achieved for most applications with the knowledge that the exponential function for a negative domain is more widely used than the positive domain. This paper presents an optimized implementation of exponential function for variable precision fixed point negative input. The implementation presented here significantly reduces the number of multipliers and adders. This is further optimized using mixed world-length implementation for the series expansion. The reduction in area and power consumption is more than 30% and 50% respectively over previous equivalent method.      
### 78.Configuring Intelligent Reflecting Surface with Performance Guarantees: Optimal Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2112.02260.pdf)
>  This work proposes linear time strategies to optimally configure the phase shifts for the reflective elements of an intelligent reflecting surface (IRS). Specifically, we show that the binary phase beamforming can be optimally solved in linear time to maximize the received signal-to-noise ratio (SNR). For the general K-ary phase beamforming, we develop a linear time approximation algorithm that guarantees performance within a constant fraction (1+\cos(\pi/K))/2 of the global optimum, e.g., it can attain over 85% of the optimal performance for the quadrature beamforming with K=4. According to the numerical results, the proposed approximation algorithm for discrete IRS beamforming outperforms the existing algorithms significantly in boosting the received SNR.      
### 79.Towards the One Learning Algorithm Hypothesis: A System-theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.02256.pdf)
>  The existence of a universal learning architecture in human cognition is a widely spread conjecture supported by experimental findings from neuroscience. While no low-level implementation can be specified yet, an abstract outline of human perception and learning is believed to entail three basic properties: (a) hierarchical attention and processing, (b) memory-based knowledge representation, and (c) progressive learning and knowledge compaction. We approach the design of such a learning architecture from a system-theoretic viewpoint, developing a closed-loop system with three main components: (i) a multi-resolution analysis pre-processor, (ii) a group-invariant feature extractor, and (iii) a progressive knowledge-based learning module. Multi-resolution feedback loops are used for learning, i.e., for adapting the system parameters to online observations. To design (i) and (ii), we build upon the established theory of wavelet-based multi-resolution analysis and the properties of group convolution operators. Regarding (iii), we introduce a novel learning algorithm that constructs progressively growing knowledge representations in multiple resolutions. The proposed algorithm is an extension of the Online Deterministic Annealing (ODA) algorithm based on annealing optimization, solved using gradient-free stochastic approximation. ODA has inherent robustness and regularization properties and provides a means to progressively increase the complexity of the learning model i.e. the number of the neurons, as needed, through an intuitive bifurcation phenomenon. The proposed multi-resolution approach is hierarchical, progressive, knowledge-based, and interpretable. We illustrate the properties of the proposed architecture in the context of the state-of-the-art learning algorithms and deep learning methods.      
### 80.A Triple-Double Convolutional Neural Network for Panchromatic Sharpening  [ :arrow_down: ](https://arxiv.org/pdf/2112.02237.pdf)
>  Pansharpening refers to the fusion of a panchromatic image with a high spatial resolution and a multispectral image with a low spatial resolution, aiming to obtain a high spatial resolution multispectral image. In this paper, we propose a novel deep neural network architecture with level-domain based loss function for pansharpening by taking into account the following double-type structures, \emph{i.e.,} double-level, double-branch, and double-direction, called as triple-double network (TDNet). By using the structure of TDNet, the spatial details of the panchromatic image can be fully exploited and utilized to progressively inject into the low spatial resolution multispectral image, thus yielding the high spatial resolution output. The specific network design is motivated by the physical formula of the traditional multi-resolution analysis (MRA) methods. Hence, an effective MRA fusion module is also integrated into the TDNet. Besides, we adopt a few ResNet blocks and some multi-scale convolution kernels to deepen and widen the network to effectively enhance the feature extraction and the robustness of the proposed TDNet. Extensive experiments on reduced- and full-resolution datasets acquired by WorldView-3, QuickBird, and GaoFen-2 sensors demonstrate the superiority of the proposed TDNet compared with some recent state-of-the-art pansharpening approaches. An ablation study has also corroborated the effectiveness of the proposed approach.      
### 81.A Divide-and-Conquer Algorithm for Distributed Optimization on Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.02197.pdf)
>  In this paper, we consider networks with topologies described by some connected undirected graph ${\mathcal{G}}=(V, E)$ and with some agents (fusion centers) equipped with processing power and local peer-to-peer communication, and optimization problem $\min_{\boldsymbol x}\big\{F({\boldsymbol x})=\sum_{i\in V}f_i({\boldsymbol x})\big\}$ with local objective functions $f_i$ depending only on neighboring variables of the vertex $i\in V$. We introduce a divide-and-conquer algorithm to solve the above optimization problem in a distributed and decentralized manner. The proposed divide-and-conquer algorithm has exponential convergence, its computational cost is almost linear with respect to the size of the network, and it can be fully implemented at fusion centers of the network. Our numerical demonstrations also indicate that the proposed divide-and-conquer algorithm has superior performance than popular decentralized optimization methods do for the least squares problem with/without $\ell^1$ penalty.      
