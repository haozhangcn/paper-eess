# ArXiv eess --Tue, 21 Dec 2021
### 1.HyperSegNAS: Bridging One-Shot Neural Architecture Search with 3D Medical Image Segmentation using HyperNet  [ :arrow_down: ](https://arxiv.org/pdf/2112.10652.pdf)
>  Semantic segmentation of 3D medical images is a challenging task due to the high variability of the shape and pattern of objects (such as organs or tumors). Given the recent success of deep learning in medical image segmentation, Neural Architecture Search (NAS) has been introduced to find high-performance 3D segmentation network architectures. However, because of the massive computational requirements of 3D data and the discrete optimization nature of architecture search, previous NAS methods require a long search time or necessary continuous relaxation, and commonly lead to sub-optimal network architectures. While one-shot NAS can potentially address these disadvantages, its application in the segmentation domain has not been well studied in the expansive multi-scale multi-path search space. To enable one-shot NAS for medical image segmentation, our method, named HyperSegNAS, introduces a HyperNet to assist super-net training by incorporating architecture topology information. Such a HyperNet can be removed once the super-net is trained and introduces no overhead during architecture search. We show that HyperSegNAS yields better performing and more intuitive architectures compared to the previous state-of-the-art (SOTA) segmentation networks; furthermore, it can quickly and accurately find good architecture candidates under different computing constraints. Our method is evaluated on public datasets from the Medical Segmentation Decathlon (MSD) challenge, and achieves SOTA performances.      
### 2.Optimization for Master-UAV-powered Auxiliary-Aerial-IRS-assisted IoT Networks: An Option-based Multi-agent Hierarchical Deep Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.10630.pdf)
>  This paper investigates a master unmanned aerial vehicle (MUAV)-powered Internet of Things (IoT) network, in which we propose using a rechargeable auxiliary UAV (AUAV) equipped with an intelligent reflecting surface (IRS) to enhance the communication signals from the MUAV and also leverage the MUAV as a recharging power source. Under the proposed model, we investigate the optimal collaboration strategy of these energy-limited UAVs to maximize the accumulated throughput of the IoT network. Depending on whether there is charging between the two UAVs, two optimization problems are formulated. To solve them, two multi-agent deep reinforcement learning (DRL) approaches are proposed, which are centralized training multi-agent deep deterministic policy gradient (CT-MADDPG) and multi-agent deep deterministic policy option critic (MADDPOC). It is shown that the CT-MADDPG can greatly reduce the requirement on the computing capability of the UAV hardware, and the proposed MADDPOC is able to support low-level multi-agent cooperative learning in the continuous action domains, which has great advantages over the existing option-based hierarchical DRL that only support single-agent learning and discrete actions.      
### 3.Privacy-Preserved Nonlinear Cloud-based Model Predictive Control via Affine Masking  [ :arrow_down: ](https://arxiv.org/pdf/2112.10625.pdf)
>  With the advent of 5G technology that presents enhanced communication reliability and ultra low latency, there is renewed interest in employing cloud computing to perform high performance but computationally expensive control schemes like nonlinear model predictive control (MPC). Such a cloud-based control scheme, however, requires data sharing between the plant (agent) and the cloud, which raises privacy concerns. This is because privacy-sensitive information such as system states and control inputs has to be sent to the cloud and thus can be leaked to attackers for various malicious activities. In this paper, we develop a simple yet effective privacy-preserved nonlinear MPC framework via affine masking. Specifically, we consider external eavesdroppers or honest-but-curious cloud servers that wiretap the communication channel and intend to infer the local plant's information including state information, system dynamics, and control inputs. An affine transformation-based privacy-preservation mechanism is designed to mask the true states and control signals while reformulating the original MPC problem into a different but equivalent form. We show that the proposed privacy scheme does not affect the MPC performance and it preserves the privacy of the local plant such that the eavesdropper is unable to find a unique value or even estimate a rough range of the private state and input signals. The proposed method is further extended to achieve privacy preservation in cloud-based output-feedback MPC. Simulations are performed to demonstrate the efficacy of the developed approaches.      
### 4.A Closed-Form Bound on Asymptotic Linear Convergence of Positively Quadratic First-Order Difference Equations  [ :arrow_down: ](https://arxiv.org/pdf/2112.10598.pdf)
>  We present a tight closed-form bound on the convergence of the quadratic first-order difference equation with positive coefficients. Our result offers insight into the convergence behavior of the dynamic system in its convergent regime: while the quadratic term is negligible in the asymptotic regime, it leads to a finite increase in the number of iterations required for a given accuracy relative to the corresponding linear difference equation.      
### 5.Implicit Neural Representation Learning for Hyperspectral Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2112.10541.pdf)
>  Hyperspectral image (HSI) super-resolution without additional auxiliary image remains a constant challenge due to its high-dimensional spectral patterns, where learning an effective spatial and spectral representation is a fundamental issue. Recently, Implicit Neural Representations (INRs) are making strides as a novel and effective representation, especially in the reconstruction task. Therefore, in this work, we propose a novel HSI reconstruction model based on INR which represents HSI by a continuous function mapping a spatial coordinate to its corresponding spectral radiance values. In particular, as a specific implementation of INR, the parameters of parametric model are predicted by a hypernetwork that operates on feature extraction using convolution network. It makes the continuous functions map the spatial coordinates to pixel values in a content-aware manner. Moreover, periodic spatial encoding are deeply integrated with the reconstruction procedure, which makes our model capable of recovering more high frequency details. To verify the efficacy of our model, we conduct experiments on three HSI datasets (CAVE, NUS, and NTIRE2018). Experimental results show that the proposed model can achieve competitive reconstruction performance in comparison with the state-of-the-art methods. In addition, we provide an ablation study on the effect of individual components of our model. We hope this paper could server as a potent reference for future research.      
### 6.High-Cardinality Hybrid Shaping for 4D Modulation Formats in Optical Communications Optimized via End-to-End Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.10471.pdf)
>  In this paper we carry out a joint optimization of probabilistic (PS) and geometric shaping (GS) for four-dimensional (4D) modulation formats in long-haul coherent wavelength division multiplexed (WDM) optical fiber communications using an auto-encoder framework. We propose a 4D 10 bits/symbol constellation which we obtained via end-to-end deep learning over the split-step Fourier model of the fiber channel. The constellation achieved 13.6% reach increase at a data rate of approximately 400 Gbits/second in comparison to the ubiquitously employed polarization multiplexed 32-QAM format at a forward error correction overhead of 20%.      
### 7.Safe multi-agent deep reinforcement learning for joint bidding and maintenance scheduling of generation units  [ :arrow_down: ](https://arxiv.org/pdf/2112.10459.pdf)
>  This paper proposes a safe reinforcement learning algorithm for generation bidding decisions and unit maintenance scheduling in a competitive electricity market environment. In this problem, each unit aims to find a bidding strategy that maximizes its revenue while concurrently retaining its reliability by scheduling preventive maintenance. The maintenance scheduling provides some safety constraints which should be satisfied at all times. Satisfying the critical safety and reliability constraints while the generation units have an incomplete information of each others' bidding strategy is a challenging problem. Bi-level optimization and reinforcement learning are state of the art approaches for solving this type of problems. However, neither bi-level optimization nor reinforcement learning can handle the challenges of incomplete information and critical safety constraints. To tackle these challenges, we propose the safe deep deterministic policy gradient reinforcement learning algorithm which is based on a combination of reinforcement learning and a predicted safety filter. The case study demonstrates that the proposed approach can achieve a higher profit compared to other state of the art methods while concurrently satisfying the system safety constraints.      
### 8.Robust line-of-sight pointing control on-board a stratospheric balloon-borne platform  [ :arrow_down: ](https://arxiv.org/pdf/2112.10458.pdf)
>  This paper addresses the lack of a general methodology for the controller synthesis of an optical instrument on-board a stratospheric balloon-borne platform, such as a telescope or siderostat, to meet pointing requirements that are becoming more and more stringent in the context of astronomy missions. Most often in the literature, a simple control structure is chosen, and the control gains are tuned empirically based on ground testings. However, due to the large dimensions of the balloon and the flight chain, experimental set-ups only involve the pointing system and the platform, whereas flight experience shows that the pointing performance is essentially limited by the rejection of the natural pendulum-like oscillations of the fully deployed system. This observation justifies the need for a model that predicts such flight conditions that cannot be replicated in laboratory, and for an adequate methodology addressing the line-of-sight controller design. In particular, it is necessary to ensure robust stability and performance to the parametric uncertainties inherent to balloon-borne systems, such as complex balloon's properties or release of ballast throughout the flight, especially since experimental validation is limited. In this paper, a dynamical model of the complete system is proposed, based on a multibody approach and accounting for parametric uncertainties with Linear Fractional Transformations. The comparison with flight data shows that the frequency content of the platform's motion is accurately predicted. Then, the robust control of the line-of-sight is tackled as a $\mathcal H_{\infty}$ problem that allows to reach the performance objectives in terms of disturbance rejection, control bandwidth and actuators limitations.      
### 9.Robust interaction control of a dielectric elastomer actuator with variable stiffness  [ :arrow_down: ](https://arxiv.org/pdf/2112.10440.pdf)
>  This paper presents an interaction control algorithm for a dielectric elastomer membrane actuator. The proposed method permits efficient exploitation of the controllable stiffness of the material, allowing to use the membrane as a "programmable spring" in applications such as robotic manipulation or haptic devices. To achieve this goal, we propose a design algorithm based on robust control theory and linear matrix inequalities. The resulting controller permits to arbitrarily shape the stiffness of the elastomer, while providing robust stability and performance with respect to model nonlinearities. A self-sensing displacement estimation algorithm allows implementation of the method without the need of a deformation sensor, thus reducing cost and size of the system. The approach is validated on an experimental prototype consisting of an elastomer membrane preloaded with a bistable biasing spring.      
### 10.MDG and SNR Estimation in SDM Transmission Based on Artificial Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.10432.pdf)
>  The increase in capacity provided by coupled SDM systems is fundamentally limited by MDG and ASE noise. Therefore, monitoring MDG and optical SNR is essential for accurate performance evaluation and troubleshooting. Recent works show that the conventional MDG estimation method based on the transfer matrix of MIMO equalizers optimizing the MMSE underestimates the actual value at low SNR. Besides, estimating the optical SNR itself is not a trivial task in SDM systems, as MDG strongly influences the electrical SNR after the equalizer. In a recent work we propose an MDG and SNR estimation method using ANN. The proposed ANN-based method processes features extracted at the receiver after DSP. In this paper, we discuss the ANN-based method in detail, and validate it in an experimental 73-km 3-mode transmission link with controlled MDG and SNR. After validation, we apply the method in a case study consisting of an experimental long-haul 6-mode link. The results show that the ANN estimates both MDG and SNR with high accuracy, outperforming conventional methods.      
### 11.Artificial Intelligence and Dimensionality Reduction: Tools for approaching future communications  [ :arrow_down: ](https://arxiv.org/pdf/2112.10431.pdf)
>  This article presents a novel application of the t-distributed Stochastic Neighbor Embedding (t-SNE) clustering algorithm to the telecommunication field. t-SNE is a dimensionality reduction (DR) algorithm that allows the visualization of large dataset into a 2D plot. We present the applicability of this algorithm in a communication channel dataset formed by several scenarios (anechoic, reverberation, indoor and outdoor), and by using six channel features. Applying this artificial intelligence (AI) technique, we are able to separate different environments into several clusters allowing a clear visualization of the scenarios. Throughout the article, it is proved that t-SNE has the ability to cluster into several subclasses, obtaining internal classifications within the scenarios themselves. t-SNE comparison with different dimensionality reduction techniques (PCA, Isomap) is also provided throughout the paper. Furthermore, post-processing techniques are used to modify communication scenarios, recreating a real communication scenario from measurements acquired in an anechoic chamber. The dimensionality reduction and classification by using t-SNE and Variational AutoEncoders (VAE) show good performance distinguishing between the recreation and the real communication scenario. The combination of these two techniques opens up the possibility for new scenario recreations for future mobile communications. This work shows the potential of AI as a powerful tool for clustering, classification and generation of new 5G propagation scenarios.      
### 12.Local Opacity Verification for Distributed Discrete Event Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.10416.pdf)
>  This paper studies current-state opacity and initial-state opacity verification of distributed discrete event systems. The distributed system's global model is the parallel composition of multiple local systems: each of which represents a component. We propose sufficient conditions for verifying opacity of the global system model based only on the opacity of the local systems. We also present efficient approaches for the opacity verification problem that only rely on the intruder's observer automata of the local systems.      
### 13.Deep Co-supervision and Attention Fusion Strategy for Automatic COVID-19 Lung Infection Segmentation on CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2112.10368.pdf)
>  Due to the irregular shapes,various sizes and indistinguishable boundaries between the normal and infected tissues, it is still a challenging task to accurately segment the infected lesions of COVID-19 on CT images. In this paper, a novel segmentation scheme is proposed for the infections of COVID-19 by enhancing supervised information and fusing multi-scale feature maps of different levels based on the encoder-decoder architecture. To this end, a deep collaborative supervision (Co-supervision) scheme is proposed to guide the network learning the features of edges and semantics. More specifically, an Edge Supervised Module (ESM) is firstly designed to highlight low-level boundary features by incorporating the edge supervised information into the initial stage of down-sampling. Meanwhile, an Auxiliary Semantic Supervised Module (ASSM) is proposed to strengthen high-level semantic information by integrating mask supervised information into the later stage. Then an Attention Fusion Module (AFM) is developed to fuse multiple scale feature maps of different levels by using an attention mechanism to reduce the semantic gaps between high-level and low-level feature maps. Finally, the effectiveness of the proposed scheme is demonstrated on four various COVID-19 CT datasets. The results show that the proposed three modules are all promising. Based on the baseline (ResUnet), using ESM, ASSM, or AFM alone can respectively increase Dice metric by 1.12\%, 1.95\%,1.63\% in our dataset, while the integration by incorporating three models together can rise 3.97\%. Compared with the existing approaches in various datasets, the proposed method can obtain better segmentation performance in some main metrics, and can achieve the best generalization and comprehensive performance.      
### 14.Multi-Singer: Fast Multi-Singer Singing Voice Vocoder With A Large-Scale Corpus  [ :arrow_down: ](https://arxiv.org/pdf/2112.10358.pdf)
>  High-fidelity multi-singer singing voice synthesis is challenging for neural vocoder due to the singing voice data shortage, limited singer generalization, and large computational cost. Existing open corpora could not meet requirements for high-fidelity singing voice synthesis because of the scale and quality weaknesses. Previous vocoders have difficulty in multi-singer modeling, and a distinct degradation emerges when conducting unseen singer singing voice generation. To accelerate singing voice researches in the community, we release a large-scale, multi-singer Chinese singing voice dataset OpenSinger. To tackle the difficulty in unseen singer modeling, we propose Multi-Singer, a fast multi-singer vocoder with generative adversarial networks. Specifically, 1) Multi-Singer uses a multi-band generator to speed up both training and inference procedure. 2) to capture and rebuild singer identity from the acoustic feature (i.e., mel-spectrogram), Multi-Singer adopts a singer conditional discriminator and conditional adversarial training objective. 3) to supervise the reconstruction of singer identity in the spectrum envelopes in frequency domain, we propose an auxiliary singer perceptual loss. The joint training approach effectively works in GANs for multi-singer voices modeling. Experimental results verify the effectiveness of OpenSinger and show that Multi-Singer improves unseen singer singing voices modeling in both speed and quality over previous methods. The further experiment proves that combined with FastSpeech 2 as the acoustic model, Multi-Singer achieves strong robustness in the multi-singer singing voice synthesis pipeline. Samples are available at <a class="link-external link-https" href="https://Multi-Singer.github.io/" rel="external noopener nofollow">this https URL</a>      
### 15.Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2112.10325.pdf)
>  Due to the constraints of the imaging device and high cost in operation time, computer tomography (CT) scans are usually acquired with low intra-slice resolution. Improving the intra-slice resolution is beneficial to the disease diagnosis for both human experts and computer-aided systems. To this end, this paper builds a novel medical slice synthesis to increase the between-slice resolution. Considering that the ground-truth intermediate medical slices are always absent in clinical practice, we introduce the incremental cross-view mutual distillation strategy to accomplish this task in the self-supervised learning manner. Specifically, we model this problem from three different views: slice-wise interpolation from axial view and pixel-wise interpolation from coronal and sagittal views. Under this circumstance, the models learned from different views can distill valuable knowledge to guide the learning processes of each other. We can repeat this process to make the models synthesize intermediate slice data with increasing inter-slice resolution. To demonstrate the effectiveness of the proposed approach, we conduct comprehensive experiments on a large-scale CT dataset. Quantitative and qualitative comparison results show that our method outperforms state-of-the-art algorithms by clear margins.      
### 16.Robust Data-Driven Linear Power Flow Model with Probability Constrained Worst-Case Errors  [ :arrow_down: ](https://arxiv.org/pdf/2112.10320.pdf)
>  To limit the probability of unacceptable worst-case linearization errors that might yield risks for power system operations, this letter proposes a robust data-driven linear power flow (RD-LPF) model. It is applicable to both transmission and distribution systems and can achieve better robustness than the recent data-driven models. The key idea is to probabilistically constrain the worst-case errors through distributionally robust chance-constrained programming. It also allows guaranteeing the linearization accuracy for a chosen operating point. Comparison results with three recent LPF models demonstrate that the worst-case error of the RD-LPF model is significantly reduced over 2- to 70-fold while reducing the average error. A compromise between computational efficiency and accuracy can be achieved through different ambiguity sets and conversion methods.      
### 17.Skin lesion segmentation and classification using deep learning and handcrafted features  [ :arrow_down: ](https://arxiv.org/pdf/2112.10307.pdf)
>  Accurate diagnostics of a skin lesion is a critical task in classification dermoscopic images. In this research, we form a new type of image features, called hybrid features, which has stronger discrimination ability than single method features. This study involves a new technique where we inject the handcrafted features or feature transfer into the fully connected layer of Convolutional Neural Network (CNN) model during the training process. Based on our literature review until now, no study has examined or investigated the impact on classification performance by injecting the handcrafted features into the CNN model during the training process. In addition, we also investigated the impact of segmentation mask and its effect on the overall classification performance. Our model achieves an 92.3% balanced multiclass accuracy, which is 6.8% better than the typical single method classifier architecture for deep learning.      
### 18.Effect of Interdigital Capacitor on CRLH Leaky Wave Antenna Based on J-Shaped Metamaterial  [ :arrow_down: ](https://arxiv.org/pdf/2112.10278.pdf)
>  This paper aims to present a miniaturized novel reconfigurable composite right/left-handed leaky wave antenna (CRLH LWA) based on metamaterial as well as slow wave structure. In other words, the effect of interdigital capacitor (IDC) on LWA with periodic J-shaped metamaterial is investigated. This microstrip antenna is designed by cascading J-shaped metallic and IDC unit cells. Then it is simulated by full-wave ADS Momentum software. Advantageously, the proposed structure has tunable dispersion diagram that can be tuned by the number of IDC fingers. As will be clarified, altering the number of IDC fingers is able to adapt the equivalent capacitor of the antenna equivalent circuit. Thanks to the availability of RF switches technologies, changing the configuration of the IDCs can be practical. Furthermore, scanning the space from backward to forward region through broadside is one of the distinguishing features of the antenna. Indeed, the CRLH LWA continuously scans the space through broadside from -55 degree to +65 degree in {\phi} = 0 degree plane. The results of the investigation reveal that the LWA with two fingers, as more effective configuration, is a circularly polarized CRLH LWA and it is one of the highly desirable advantages of this structure. The axial ratio in the direction of the main beam for the backward region is lower than 3dB and it is improved in comparison to other regions. The deployment of IDC with variable figures in LWA with J-shaped metamaterial not only brings about the aforementioned significant features but also plays a pioneering role in this paper.      
### 19.Task-Oriented Multi-User Semantic Communications  [ :arrow_down: ](https://arxiv.org/pdf/2112.10255.pdf)
>  While semantic communications have shown the potential in the case of single-modal single-users, its applications to the multi-user scenario remain limited. In this paper, we investigate deep learning (DL) based multi-user semantic communication systems for transmitting single-modal data and multimodal data, respectively. We will adopt three intelligent tasks, including, image retrieval, machine translation, and visual question answering (VQA) as the transmission goal of semantic communication systems. We will then propose a Transformer based unique framework to unify the structure of transmitters for different tasks. For the single-modal multi-user system, we will propose two Transformer based models, named, DeepSC-IR and DeepSC-MT, to perform image retrieval and machine translation, respectively. In this case, DeepSC-IR is trained to optimize the distance in embedding space between images and DeepSC-MT is trained to minimize the semantic errors by recovering the semantic meaning of sentences. For the multimodal multi-user system, we develop a Transformer enabled model, named, DeepSC-VQA, for the VQA task by extracting text-image information at the transmitters and fusing it at the receiver. In particular, a novel layer-wise Transformer is designed to help fuse multimodal data by adding connection between each of the encoder and decoder layers. Numerical results will show that the proposed models are superior to traditional communications in terms of the robustness to channels, computational complexity, transmission delay, and the task-execution performance at various task-specific metrics.      
### 20.On-line Estimation of the Parameters of the Windmill Power Coefficient  [ :arrow_down: ](https://arxiv.org/pdf/2112.10233.pdf)
>  Wind turbines are often controlled to harvest the maximum power from the wind, which corresponds to the operation at the top of the bell-shaped power coefficient graph. Such a mode of operation may be achieved implementing an extremum seeking data-based strategy, which is an invasive technique that requires the injection of harmonic disturbances. Another approach is based on the knowledge of the analytic expression of the power coefficient function, an information usually unreliably provided by the turbine manufacturer. In this paper we propose a globally, exponentially convergent on-line estimator of the parameters entering into the windmill power coefficient function. This corresponds to the solution of an identification problem for a nonlinear, nonlinearly parameterized, underexcited system. To the best of our knowledge we have provided the first solution to this challenging, practically important, problem.      
### 21.Multi-turn RNN-T for streaming recognition of multi-party speech  [ :arrow_down: ](https://arxiv.org/pdf/2112.10200.pdf)
>  Automatic speech recognition (ASR) of single channel far-field recordings with an unknown number of speakers is traditionally tackled by cascaded modules. Recent research shows that end-to-end (E2E) multi-speaker ASR models can achieve superior recognition accuracy compared to modular systems. However, these models do not ensure real-time applicability due to their dependency on full audio context. This work takes real-time applicability as the first priority in model design and addresses a few challenges in previous work on multi-speaker recurrent neural network transducer (MS-RNN-T). First, we introduce on-the-fly overlapping speech simulation during training, yielding 14% relative word error rate (WER) improvement on LibriSpeechMix test set. Second, we propose a novel multi-turn RNN-T (MT-RNN-T) model with an overlap-based target arrangement strategy that generalizes to an arbitrary number of speakers without changes in the model architecture. We investigate the impact of the maximum number of speakers seen during training on MT-RNN-T performance on LibriCSS test set, and report 28% relative WER improvement over the two-speaker MS-RNN-T. Third, we experiment with a rich transcription strategy for joint recognition and segmentation of multi-party speech. Through an in-depth analysis, we discuss potential pitfalls of the proposed system as well as promising future research directions.      
### 22.A Deep Learning Based Workflow for Detection of Lung Nodules With Chest Radiograph  [ :arrow_down: ](https://arxiv.org/pdf/2112.10184.pdf)
>  PURPOSE: This study aimed to develop a deep learning-based tool to detect and localize lung nodules with chest radiographs(CXRs). We expected it to enhance the efficiency of interpreting CXRs and reduce the possibilities of delayed diagnosis of lung cancer. <br>MATERIALS AND METHODS: We collected CXRs from NCKUH database and VBD, an open-source medical image dataset, as our training and validation data. A number of CXRs from the Ministry of Health and Welfare(MOHW) database served as our test data. We built a segmentation model to identify lung areas from CXRs, and sliced them into 16 patches. Physicians labeled the CXRs by clicking the patches. These labeled patches were then used to train and fine-tune a deep neural network(DNN) model, classifying the patches as positive or negative. Finally, we test the DNN model with the lung patches of CXRs from MOHW. <br>RESULTS: Our segmentation model identified the lung regions well from the whole CXR. The Intersection over Union(IoU) between the ground truth and the segmentation result was 0.9228. In addition, our DNN model achieved a sensitivity of 0.81, specificity of 0.82, and AUROC of 0.869 in 98 of 125 cases. For the other 27 difficult cases, the sensitivity was 0.54, specificity 0.494, and AUROC 0.682. Overall, we obtained a sensitivity of 0.78, specificity of 0.79, and AUROC 0.837. <br>CONCLUSIONS: Our two-step workflow is comparable to state-of-the-art algorithms in the sensitivity and specificity of localizing lung nodules from CXRs. Notably, our workflow provides an efficient way for specialists to label the data, which is valuable for relevant researches because of the relative rarity of labeled medical image data.      
### 23.Distributed switched model-based predictive control for distributed large-scale systems with switched topology  [ :arrow_down: ](https://arxiv.org/pdf/2112.10075.pdf)
>  Distributed switched large-scale systems are composed by dynamically coupled subsystems, in which interactions among subsystems vary over time according to an exogenous input signal named switching signal. In this paper, we present a distributed robust switched model-based predictive control (DSwMPC) to control such systems that are subject to local state and input constraints. The proposed method guarantees stabilizing the origin of the whole closed-loop system and ensures the constraints satisfaction in the presence of an unknown switching signal. In the distributed model-based predictive control (DMPC) used in this work, by considering the interactions among subsystems as an additive disturbance, the effect of the switch is reflected on the dynamic equation, local, and consistency constraint sets of the nominal subsystems. In the DSwMPC, to compensate the effect of switching signal which creates a time-varying network topology, a robust tube-based switched model-based predictive control (RSwMPC) with switched robust control invariant (switchRCI) set as the target set robust to unknown mode switching is used as local controller. The scheme performance is assessed using three typical examples. In the first example, the switching times are unknown in prior, but the next neighborhood sets are assumed to be known in prior. In the second and third cases, both of them are supposed to be unknown in prior. The simulation results show that the input and state constraints are satisfied by the proposed DSwMPC at all times. They also validate that the closed-loop system converges to the origin. Also, a comparison of the DSwMPC with a centralized SwMPC (CSwMPC) and a decentralized SwMPC (DeSwMPC) shows that the DSwMPC outperforms the DecSwMPC and also the shapes of response curves under the CSwMPC are very similar to those obtained by the DSwMPC.      
### 24.QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in Brain Tumor Segmentation -- Analysis of Ranking Metrics and Benchmarking Results  [ :arrow_down: ](https://arxiv.org/pdf/2112.10074.pdf)
>  Deep learning (DL) models have provided the state-of-the-art performance in a wide variety of medical imaging benchmarking challenges, including the Brain Tumor Segmentation (BraTS) challenges. However, the task of focal pathology multi-compartment segmentation (e.g., tumor and lesion sub-regions) is particularly challenging, and potential errors hinder the translation of DL models into clinical workflows. Quantifying the reliability of DL model predictions in the form of uncertainties, could enable clinical review of the most uncertain regions, thereby building trust and paving the way towards clinical translation. Recently, a number of uncertainty estimation methods have been introduced for DL medical image segmentation tasks. Developing metrics to evaluate and compare the performance of uncertainty measures will assist the end-user in making more informed decisions. In this study, we explore and evaluate a metric developed during the BraTS 2019-2020 task on uncertainty quantification (QU-BraTS), and designed to assess and rank uncertainty estimates for brain tumor multi-compartment segmentation. This metric (1) rewards uncertainty estimates that produce high confidence in correct assertions, and those that assign low confidence levels at incorrect assertions, and (2) penalizes uncertainty measures that lead to a higher percentages of under-confident correct assertions. We further benchmark the segmentation uncertainties generated by 14 independent participating teams of QU-BraTS 2020, all of which also participated in the main BraTS segmentation task. Overall, our findings confirm the importance and complementary value that uncertainty estimates provide to segmentation algorithms, and hence highlight the need for uncertainty quantification in medical image analyses. Our evaluation code is made publicly available at <a class="link-external link-https" href="https://github.com/RagMeh11/QU-BraTS" rel="external noopener nofollow">this https URL</a>.      
### 25.A New Image Codec Paradigm for Human and Machine Uses  [ :arrow_down: ](https://arxiv.org/pdf/2112.10071.pdf)
>  With the AI of Things (AIoT) development, a huge amount of visual data, e.g., images and videos, are produced in our daily work and life. These visual data are not only used for human viewing or understanding but also for machine analysis or decision-making, e.g., intelligent surveillance, automated vehicles, and many other smart city applications. To this end, a new image codec paradigm for both human and machine uses is proposed in this work. Firstly, the high-level instance segmentation map and the low-level signal features are extracted with neural networks. Then, the instance segmentation map is further represented as a profile with the proposed 16-bit gray-scale representation. After that, both 16-bit gray-scale profile and signal features are encoded with a lossless codec. Meanwhile, an image predictor is designed and trained to achieve the general-quality image reconstruction with the 16-bit gray-scale profile and signal features. Finally, the residual map between the original image and the predicted one is compressed with a lossy codec, used for high-quality image reconstruction. With such designs, on the one hand, we can achieve scalable image compression to meet the requirements of different human consumption; on the other hand, we can directly achieve several machine vision tasks at the decoder side with the decoded 16-bit gray-scale profile, e.g., object classification, detection, and segmentation. Experimental results show that the proposed codec achieves comparable results as most learning-based codecs and outperforms the traditional codecs (e.g., BPG and JPEG2000) in terms of PSNR and MS-SSIM for image reconstruction. At the same time, it outperforms the existing codecs in terms of the mAP for object detection and segmentation.      
### 26.A-ESRGAN: Training Real-World Blind Super-Resolution with Attention U-Net Discriminators  [ :arrow_down: ](https://arxiv.org/pdf/2112.10046.pdf)
>  Blind image super-resolution(SR) is a long-standing task in CV that aims to restore low-resolution images suffering from unknown and complex distortions. Recent work has largely focused on adopting more complicated degradation models to emulate real-world degradations. The resulting models have made breakthroughs in perceptual loss and yield perceptually convincing results. However, the limitation brought by current generative adversarial network structures is still significant: treating pixels equally leads to the ignorance of the image's structural features, and results in performance drawbacks such as twisted lines and background over-sharpening or blurring. In this paper, we present A-ESRGAN, a GAN model for blind SR tasks featuring an attention U-Net based, multi-scale discriminator that can be seamlessly integrated with other generators. To our knowledge, this is the first work to introduce attention U-Net structure as the discriminator of GAN to solve blind SR problems. And the paper also gives an interpretation for the mechanism behind multi-scale attention U-Net that brings performance breakthrough to the model. Through comparison experiments with prior works, our model presents state-of-the-art level performance on the non-reference natural image quality evaluator metric. And our ablation studies have shown that with our discriminator, the RRDB based generator can leverage the structural features of an image in multiple scales, and consequently yields more perceptually realistic high-resolution images compared to prior works.      
### 27.Sub-100uW Multispectral Riemannian Classification for EEG-based Brain--Machine Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2112.10026.pdf)
>  Motor imagery brain--machine interfaces enable us to control machines by merely thinking of performing a motor action. Practical use cases require a wearable solution where the classification of the brain signals is done locally near the sensor using machine learning models embedded on energy-efficient microcontroller units, for assured privacy, user comfort, and long-term usage. In this work, we provide practical insights on the accuracy-cost trade-off for embedded BMI solutions. Our multispectral Riemannian classifier reaches 75.1% accuracy on a 4-class MI task. The accuracy is further improved by tuning different types of classifiers to each subject, achieving 76.4%. We further scale down the model by quantizing it to mixed-precision representations with a minimal accuracy loss of 1% and 1.4%, respectively, which is still up to 4.1% more accurate than the state-of-the-art embedded convolutional neural network. We implement the model on a low-power MCU within an energy budget of merely 198uJ and taking only 16.9ms per classification. Classifying samples continuously, overlapping the 3.5s samples by 50% to avoid missing user inputs allows for operation at just 85uW. Compared to related works in embedded MI-BMIs, our solution sets the new state-of-the-art in terms of accuracy-energy trade-off for near-sensor classification.      
### 28.Supervised laser-speckle image sampling of skin tissue to detect very early stage of diabetes by its effects on skin subcellular properties  [ :arrow_down: ](https://arxiv.org/pdf/2112.10024.pdf)
>  This paper investigates the effectiveness of an expert system based on K-nearest neighbors algorithm for laser speckle image sampling applied to the early detection of diabetes. With the latest developments in artificial intelligent guided laser speckle imaging technologies, it may be possible to optimise laser parameters, such as wavelength, energy level and image texture measures in association with a suitable AI technique to interact effectively with the subcellular properties of a skin tissue to detect early signs of diabetes. The new approach is potentially more effective than the classical skin glucose level observation because of its optimised combination of laser physics and AI techniques, and additionally, it allows non-expert individuals to perform more frequent skin tissue tests for an early detection of diabetes.      
### 29.Cross-Domain Federated Learning in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2112.10001.pdf)
>  Federated learning is increasingly being explored in the field of medical imaging to train deep learning models on large scale datasets distributed across different data centers while preserving privacy by avoiding the need to transfer sensitive patient information. In this manuscript, we explore federated learning in a multi-domain, multi-task setting wherein different participating nodes may contain datasets sourced from different domains and are trained to solve different tasks. We evaluated cross-domain federated learning for the tasks of object detection and segmentation across two different experimental settings: multi-modal and multi-organ. The result from our experiments on cross-domain federated learning framework were very encouraging with an overlap similarity of 0.79 for organ localization and 0.65 for lesion segmentation. Our results demonstrate the potential of federated learning in developing multi-domain, multi-task deep learning models without sharing data from different domains.      
### 30.Curriculum Based Reinforcement Learning of Grid Topology Controllers to Prevent Thermal Cascading  [ :arrow_down: ](https://arxiv.org/pdf/2112.09996.pdf)
>  This paper describes how domain knowledge of power system operators can be integrated into reinforcement learning (RL) frameworks to effectively learn agents that control the grid's topology to prevent thermal cascading. Typical RL-based topology controllers fail to perform well due to the large search/optimization space. Here, we propose an actor-critic-based agent to address the problem's combinatorial nature and train the agent using the RL environment developed by RTE, the French TSO. To address the challenge of the large optimization space, a curriculum-based approach with reward tuning is incorporated into the training procedure by modifying the environment using network physics for enhanced agent learning. Further, a parallel training approach on multiple scenarios is employed to avoid biasing the agent to a few scenarios and make it robust to the natural variability in grid operations. Without these modifications to the training procedure, the RL agent failed for most test scenarios, illustrating the importance of properly integrating domain knowledge of physical systems for real-world RL learning. The agent was tested by RTE for the 2019 learning to run the power network challenge and was awarded the 2nd place in accuracy and 1st place in speed. The developed code is open-sourced for public use.      
### 31.Data-Driven Reachability analysis and Support set Estimation with Christoffel Functions  [ :arrow_down: ](https://arxiv.org/pdf/2112.09995.pdf)
>  We present algorithms for estimating the forward reachable set of a dynamical system using only a finite collection of independent and identically distributed samples. The produced estimate is the sublevel set of a function called an empirical inverse Christoffel function: empirical inverse Christoffel functions are known to provide good approximations to the support of probability distributions. In addition to reachability analysis, the same approach can be applied to general problems of estimating the support of a random variable, which has applications in data science towards detection of novelties and outliers in data sets. In applications where safety is a concern, having a guarantee of accuracy that holds on finite data sets is critical. In this paper, we prove such bounds for our algorithms under the Probably Approximately Correct (PAC) framework. In addition to applying classical Vapnik-Chervonenkis (VC) dimension bound arguments, we apply the PAC-Bayes theorem by leveraging a formal connection between kernelized empirical inverse Christoffel functions and Gaussian process regression models. The bound based on PAC-Bayes applies to a more general class of Christoffel functions than the VC dimension argument, and achieves greater sample efficiency in experiments.      
### 32.Digital RIS (DRIS): The Future of Digital Beam Management in RIS-Assisted OWC Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.09984.pdf)
>  Reconfigurable intelligent surfaces (RIS) have been recently introduced to optical wireless communication (OWC) networks to resolve skip areas and improve the signal-to-noise ratio at the user's end. In OWC networks, RIS are based on mirrors or metasurfaces. Metasurfaces have evolved significantly over the last few years. As a result, coding, digital, programmable, and information metamaterials have been developed. The advantage of these materials is that they can enable digital signal processing (DSP) techniques. For the first time, this paper proposes the use of digital RIS (DRIS) in OWC systems. We discuss the concept of DRIS and the application of DSP methods to the physical material. In addition, we examine metamaterials for optical DRIS with liquid crystals serving as the front row material. Finally, we present a design example and discuss future research directions.      
### 33.3D Structural Analysis of the Optic Nerve Head to Robustly Discriminate Between Papilledema and Optic Disc Drusen  [ :arrow_down: ](https://arxiv.org/pdf/2112.09970.pdf)
>  Purpose: (1) To develop a deep learning algorithm to identify major tissue structures of the optic nerve head (ONH) in 3D optical coherence tomography (OCT) scans; (2) to exploit such information to robustly differentiate among healthy, optic disc drusen (ODD), and papilledema ONHs. <br>It was a cross-sectional comparative study with confirmed ODD (105 eyes), papilledema due to high intracranial pressure (51 eyes), and healthy controls (100 eyes). 3D scans of the ONHs were acquired using OCT, then processed to improve deep-tissue visibility. At first, a deep learning algorithm was developed using 984 B-scans (from 130 eyes) in order to identify: major neural/connective tissues, and ODD regions. The performance of our algorithm was assessed using the Dice coefficient (DC). In a 2nd step, a classification algorithm (random forest) was designed using 150 OCT volumes to perform 3-class classifications (1: ODD, 2: papilledema, 3: healthy) strictly from their drusen and prelamina swelling scores (derived from the segmentations). To assess performance, we reported the area under the receiver operating characteristic curves (AUCs) for each class. <br>Our segmentation algorithm was able to isolate neural and connective tissues, and ODD regions whenever present. This was confirmed by an average DC of 0.93$\pm$0.03 on the test set, corresponding to good performance. Classification was achieved with high AUCs, i.e. 0.99$\pm$0.01 for the detection of ODD, 0.99 $\pm$ 0.01 for the detection of papilledema, and 0.98$\pm$0.02 for the detection of healthy ONHs. <br>Our AI approach accurately discriminated ODD from papilledema, using a single OCT scan. Our classification performance was excellent, with the caveat that validation in a much larger population is warranted. Our approach may have the potential to establish OCT as the mainstay of diagnostic imaging in neuro-ophthalmology.      
### 34.Learning to Model the Relationship Between Brain Structural and Functional Connectomes  [ :arrow_down: ](https://arxiv.org/pdf/2112.09906.pdf)
>  Recent advances in neuroimaging along with algorithmic innovations in statistical learning from network data offer a unique pathway to integrate brain structure and function, and thus facilitate revealing some of the brain's organizing principles at the system level. In this direction, we develop a supervised graph representation learning framework to model the relationship between brain structural connectivity (SC) and functional connectivity (FC) via a graph encoder-decoder system, where the SC is used as input to predict empirical FC. A trainable graph convolutional encoder captures direct and indirect interactions between brain regions-of-interest that mimic actual neural communications, as well as to integrate information from both the structural network topology and nodal (i.e., region-specific) attributes. The encoder learns node-level SC embeddings which are combined to generate (whole brain) graph-level representations for reconstructing empirical FC networks. The proposed end-to-end model utilizes a multi-objective loss function to jointly reconstruct FC networks and learn discriminative graph representations of the SC-to-FC mapping for downstream subject (i.e., graph-level) classification. Comprehensive experiments demonstrate that the learnt representations of said relationship capture valuable information from the intrinsic properties of the subject's brain networks and lead to improved accuracy in classifying a large population of heavy drinkers and non-drinkers from the Human Connectome Project. Our work offers new insights on the relationship between brain networks that support the promising prospect of using graph representation learning to discover more about human brain activity and function.      
### 35.Noisy Speech Based Temporal Decomposition to Improve Fundamental Frequency Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2112.09896.pdf)
>  This paper introduces a novel method to separate noisy speech into low or high frequency frames, in order to improve fundamental frequency (F0) estimation accuracy. In this proposal, the target signal is analyzed by means of the ensemble empirical mode decomposition. Next, the pitch information is extracted from the first decomposition modes. This feature indicates the frequency region where the F0 of speech should be located, thus separating the frames into low-frequency (LF) or high-frequency (HF). The separation is applied to correct candidates extracted from a conventional fundamental frequency detection method, and hence improving the accuracy of F0 estimate. The proposed method is evaluated in experiments with CSTR and TIMIT databases, considering six acoustic noises under various signal-to-noise ratios. A pitch enhancement algorithm is adopted as baseline in the evaluation analysis considering three conventional estimators. Results show that the proposed method outperforms the competing strategies, in terms of low/high frequency separation accuracy. Moreover, the performance metrics of the F0 estimation techniques show that the novel solution is able to better improve F0 detection accuracy when compared to competitive approaches under different noisy conditions.      
### 36.Dynamic Defender-Attacker Blotto Game  [ :arrow_down: ](https://arxiv.org/pdf/2112.09890.pdf)
>  This work studies a dynamic, adversarial resource allocation problem in environments modeled as graphs. A blue team of defender robots are deployed in the environment to protect the nodes from a red team of attacker robots. We formulate the engagement as a discrete-time dynamic game, where the robots can move at most one hop in each time step. The game terminates with the attacker's win if any location has more attacker robots than defender robots at any time. The goal is to identify dynamic resource allocation strategies, as well as the conditions that determines the winner: graph structure, available resources, and initial conditions. We analyze the problem using reachable sets and show how the outdegree of the underlying graph directly influences the difficulty of the defending task. Furthermore, we provide algorithms that identify sufficiency of attacker's victory.      
### 37.Time-efficient Joint Chance-constrained Optimal Power Flow with a Learning-based Robust Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2112.09827.pdf)
>  With the increasing penetration of renewable generation integrated into power networks, how to manage uncertainties in optimal power flow (OPF) has become a major concern for network operators. This paper proposes a joint chance-constrained OPF model to tackle uncertainties. This model jointly guarantees the satisfaction probability of all critical OPF constraints so that it can effectively ensure the feasibility of OPF solutions. Considering that the existing works for handling joint chance constraints (JCCs) are either overly conservative or computationally intractable, we propose a time-efficient learning-based robust approximation method for JCCs. It first adopts the sample average approximation (SAA) to convert JCCs into sample-wise constraints with binary variables. Then, the One-Class Support Vector Clustering is introduced to pre-solve the binary variables in SAA. To further improve the computational performance, we design a robust approximation to replace the large number of sample-wise constraints with only a few robust constraints. As a result, the original complex joint chance-constrained OPF model is formulated into a simple linear form. Moreover, since the proposed model is data-driven, it is applicable to arbitrarily distributed uncertainties. Numerical experiments are conducted to validate the superiority of the proposed method on optimality, feasibility, and computational efficiency.      
### 38.A Joint Beamforming Design and Integrated CPM-LFM Signal for Dual-functional Radar-communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.09825.pdf)
>  The dual-functional radar-communication (DFRC) system is an attractive technique, since it can support both wireless communications and radar by a unified hardware platform with real-time cooperation. Considering the appealing feature of multiple beams, this paper proposes a precoding scheme that simultaneously support multiuser transmission and target detection, with an integrated continuous phase modulation (CPM) and linear frequency modulation (LFM) signal, based on the designed dual mode framework. Similarly to the conception of communication rate, this paper defines radar rate to unify the DFRC system. Then, the maximum sum-rate that includes both the communication and radar rates is set to be the objective function. Regarding as the optimal issue is non-convex, the optimal problem is divided into two sub-issues, one is the user selection issue, and the other is the joint beamforming design and power allocation issue. A successive maximum iteration (SMI) algorithm is presented for the former issue, which can balance the performances between the sum-rate and complexity; and maximum minimization Lagrange multiplier (MMLM) iteration algorithm is utilized to solve the latter optimal issue. Moreover, we deduce the spectrum characteristic, bit error rate (BER) and ambiguity function (AF) for the proposed system. Simulation results show that our proposed system can provide appreciated sum-rate than the classical schemes, validating the efficiency of the proposed system.      
### 39.Comparative Analysis of Radar Cross Section Based UAV Classification Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2112.09774.pdf)
>  This work investigates the problem of unmanned aerial vehicles (UAVs) identification using their radar crosssection (RCS) signature. The RCS of six commercial UAVs are measured at 15 GHz and 25 GHz in an anechoic chamber, for both vertical-vertical and horizontal-horizontal polarization. The RCS signatures are used to train 15 different classification algorithms, each belonging to one of three different categories: statistical learning (SL), machine learning (ML), and deep learning (DL). The study shows that while the classification accuracy of all the algorithms increases with the signal-to-noise ratio (SNR), the ML algorithm achieved better accuracy than the SL and DL algorithms. For example, the classification tree ML achieves an accuracy of 98.66% at 3 dB SNR using the 15 GHz VV-polarized RCS test data from the UAVs. We investigate the classification accuracy using Monte Carlo analysis with the aid of boxplots, confusion matrices, and classification plots. On average, the accuracy of the classification tree ML model performed better than the other algorithms, followed by the Peter Swerling statistical models and the discriminant analysis ML model. In general, the classification accuracy of the ML and SL algorithms outperformed the DL algorithms (Squeezenet, Googlenet, Nasnet, and Resnet 101) considered in the study. Furthermore, the computational time of each algorithm is analyzed. The study concludes that while the SL algorithms achieved good classification accuracy, the computational time was relatively long when compared to the ML and DL algorithms. Also, the study shows that the classification tree achieved the fastest average classification time of about 0.46 ms.      
### 40.Learned Half-Quadratic Splitting Network for Magnetic Resonance Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2112.09760.pdf)
>  Magnetic Resonance (MR) image reconstruction from highly undersampled $k$-space data is critical in accelerated MR imaging (MRI) techniques. In recent years, deep learning-based methods have shown great potential in this task. This paper proposes a learned half-quadratic splitting algorithm for MR image reconstruction and implements the algorithm in an unrolled deep learning network architecture. We compare the performance of our proposed method on a public cardiac MR dataset against DC-CNN and LPDNet, and our method outperforms other methods in both quantitative results and qualitative results with fewer model parameters and faster reconstruction speed. Finally, we enlarge our model to achieve superior reconstruction quality, and the improvement is $1.76$ dB and $2.74$ dB over LPDNet in peak signal-to-noise ratio on $5\times$ and $10\times$ acceleration, respectively. Code for our method is publicly available at <a class="link-external link-https" href="https://github.com/hellopipu/HQS-Net" rel="external noopener nofollow">this https URL</a>.      
### 41.Interpretable and Interactive Deep Multiple Instance Learning for Dental Caries Classification in Bitewing X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2112.09694.pdf)
>  We propose a simple and efficient image classification architecture based on deep multiple instance learning, and apply it to the challenging task of caries detection in dental radiographs. Technically, our approach contributes in two ways: First, it outputs a heatmap of local patch classification probabilities despite being trained with weak image-level labels. Second, it is amenable to learning from segmentation labels to guide training. In contrast to existing methods, the human user can faithfully interpret predictions and interact with the model to decide which regions to attend to. Experiments are conducted on a large clinical dataset of $\sim$38k bitewings ($\sim$316k teeth), where we achieve competitive performance compared to various baselines. When guided by an external caries segmentation model, a significant improvement in classification and localization performance is observed.      
### 42.Discovering State Variables Hidden in Experimental Data  [ :arrow_down: ](https://arxiv.org/pdf/2112.10755.pdf)
>  All physical laws are described as relationships between state variables that give a complete and non-redundant description of the relevant system dynamics. However, despite the prevalence of computing power and AI, the process of identifying the hidden state variables themselves has resisted automation. Most data-driven methods for modeling physical phenomena still assume that observed data streams already correspond to relevant state variables. A key challenge is to identify the possible sets of state variables from scratch, given only high-dimensional observational data. Here we propose a new principle for determining how many state variables an observed system is likely to have, and what these variables might be, directly from video streams. We demonstrate the effectiveness of this approach using video recordings of a variety of physical dynamical systems, ranging from elastic double pendulums to fire flames. Without any prior knowledge of the underlying physics, our algorithm discovers the intrinsic dimension of the observed dynamics and identifies candidate sets of state variables. We suggest that this approach could help catalyze the understanding, prediction and control of increasingly complex systems. Project website is at: <a class="link-external link-https" href="https://www.cs.columbia.edu/~bchen/neural-state-variables" rel="external noopener nofollow">this https URL</a>      
### 43.Learning Spatio-Temporal Specifications for Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.10714.pdf)
>  Learning dynamical systems properties from data provides important insights that help us understand such systems and mitigate undesired outcomes. In this work, we propose a framework for learning spatio-temporal (ST) properties as formal logic specifications from data. We introduce SVM-STL, an extension of Signal Signal Temporal Logic (STL), capable of specifying spatial and temporal properties of a wide range of dynamical systems that exhibit time-varying spatial patterns. Our framework utilizes machine learning techniques to learn SVM-STL specifications from system executions given by sequences of spatial patterns. We present methods to deal with both labeled and unlabeled data. In addition, given system requirements in the form of SVM-STL specifications, we provide an approach for parameter synthesis to find parameters that maximize the satisfaction of such specifications. Our learning framework and parameter synthesis approach are showcased in an example of a reaction-diffusion system.      
### 44.Adversarially Robust Stability Certificates can be Sample-Efficient  [ :arrow_down: ](https://arxiv.org/pdf/2112.10690.pdf)
>  Motivated by bridging the simulation to reality gap in the context of safety-critical systems, we consider learning adversarially robust stability certificates for unknown nonlinear dynamical systems. In line with approaches from robust control, we consider additive and Lipschitz bounded adversaries that perturb the system dynamics. We show that under suitable assumptions of incremental stability on the underlying system, the statistical cost of learning an adversarial stability certificate is equivalent, up to constant factors, to that of learning a nominal stability certificate. Our results hinge on novel bounds for the Rademacher complexity of the resulting adversarial loss class, which may be of independent interest. To the best of our knowledge, this is the first characterization of sample-complexity bounds when performing adversarial learning over data generated by a dynamical system. We further provide a practical algorithm for approximating the adversarial training algorithm, and validate our findings on a damped pendulum example.      
### 45.SelFSR: Self-Conditioned Face Super-Resolution in the Wild via Flow Field Degradation Network  [ :arrow_down: ](https://arxiv.org/pdf/2112.10683.pdf)
>  In spite of the success on benchmark datasets, most advanced face super-resolution models perform poorly in real scenarios since the remarkable domain gap between the real images and the synthesized training pairs. To tackle this problem, we propose a novel domain-adaptive degradation network for face super-resolution in the wild. This degradation network predicts a flow field along with an intermediate low resolution image. Then, the degraded counterpart is generated by warping the intermediate image. With the preference of capturing motion blur, such a model performs better at preserving identity consistency between the original images and the degraded. We further present the self-conditioned block for super-resolution network. This block takes the input image as a condition term to effectively utilize facial structure information, eliminating the reliance on explicit priors, e.g. facial landmarks or boundary. Our model achieves state-of-the-art performance on both CelebA and real-world face dataset. The former demonstrates the powerful generative ability of our proposed architecture while the latter shows great identity consistency and perceptual quality in real-world images.      
### 46.Raw High-Definition Radar for Multi-Task Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.10646.pdf)
>  With their robustness to adverse weather conditions and ability to measure speeds, radar sensors have been part of the automotive landscape for more than two decades. Recent progress toward High Definition (HD) Imaging radar has driven the angular resolution below the degree, thus approaching laser scanning performance. However, the amount of data a HD radar delivers and the computational cost to estimate the angular positions remain a challenge. In this paper, we propose a novel HD radar sensing model, FFT-RadNet, that eliminates the overhead of computing the Range-Azimuth-Doppler 3D tensor, learning instead to recover angles from a Range-Doppler spectrum. FFT-RadNet is trained both to detect vehicles and to segment free driving space. On both tasks, it competes with the most recent radar-based models while requiring less compute and memory. Also, we collected and annotated 2-hour worth of raw data from synchronized automotive-grade sensors (camera, laser, HD radar) in various environments (city street, highway, countryside road). This unique dataset, nick-named RADIal for "Radar, Lidar et al.", is available at <a class="link-external link-https" href="https://github.com/valeoai/RADIal" rel="external noopener nofollow">this https URL</a>.      
### 47.Ultra-Reliable and Low-Latency Short-Packet Communications for Multihop MIMO Relaying  [ :arrow_down: ](https://arxiv.org/pdf/2112.10529.pdf)
>  This work considers the multihop multiple-input multiple-output relay network under short-packet communications to facilitate not only ultra-reliability but also low-latency communications. We assume that the transmit antenna selection (TAS) scheme is utilized at the transmit side, whereas either selection combining (SC) or maximum ratio combining (MRC) is leveraged at the receive side to achieve diversity gains. For quasi-static Rayleigh fading channels and the finite-blocklength regime, we derive the approximate closed-form expressions of the end-to-end (e2e) block error rate (BLER) for both the TAS/MRC and TAS/SC schemes. The asymptotic performance in the high signal-to-noise ratio regime is derived, from which the comparison of TAS/MRC and TAS/SC schemes in terms of the diversity order, e2e BLER loss, and SNR gap is provided. The e2e latency and throughputs are also analyzed for the considered schemes. The correctness of our analysis is confirmed via Monte Carlo simulations.      
### 48.Spectrum Trading for Device-to-Device Communication In Cellular Networks using Incomplete Information Bandwidth-Auction Game  [ :arrow_down: ](https://arxiv.org/pdf/2112.10497.pdf)
>  Device-to-device (D2D) communication that allows proximity users to communicate directly has been recently proposed to improve spectral efficiency of cellular networks. In this paper, we assume a cellular network consisting of multiple cellular user equipments (CUEs), which are the primary users, and a cognitive D2D pair, which is the secondary user. The D2D pair needs a bandwidth for data transmission that can be obtained via spectrum trading. We introduce a bandwidth-auction game for the spectrum trading problem. The base station (BS) and CUEs are able to sell their spectrum or share it with the D2D pair, which allows the D2D pair to operate in orthogonal sharing, cellular, or non-orthogonal sharing (NOS) modes. Operation of the D2D pair in the NOS mode causes interference to the CUEs, which is possible under low interference condition. In the auction, the D2D pair can buy its required spectrum from three different service providers (SPs) corresponding to each mode that operateon different frequency spectrums. The D2D pair bids a price bandwidth demand curve and the SPs offer a price-demand supply curve. Since each player is not aware of the strategy of other players in practical scenarios, the game is assumed to be an incomplete information repeated one. A best response based learning method is proposed for the decision making procedure of all players, the D2D pair and SPs. It is shown that the proposed method converges to the Nash equilibrium (NE) point of the game more rapidly than the state-of-the-art methods when the game is played repeatedly. The sensitivity of the proposed method to the learning rate variable is also less than the state-of-the-art methods and hence can be considered as a robust one.      
### 49.Measuring Salinity and Density of Seawater Samples with Different Salt Compositions and Suspended Materials  [ :arrow_down: ](https://arxiv.org/pdf/2112.10493.pdf)
>  Determining of the solute mass amount in seawater using in situ measurements in seas and oceans remains now an unresolved problem. To solve it, it is necessary to develop both new methods and instruments for measurements. This article analyzes methods for the indirect measuring of salinity and density using parameters that can be measured in situ, including relative electrical conductivity, speed of sound, temperature and hydrostatic pressure. The authors propose an electric conductivity sensor design that allows for obtaining data on solid suspensions along with measuring the impedance of electrodes under various the alternating current frequencies. The authors analyze the joint measurement technique using the CTD and SVP devices in a marine testing area. Based on the results of joint measurements, the authors present tests of water samples of various salt composition for the presence of solid suspensions.      
### 50.On sensor quantization in linear control systems: Krasovskii solutions meet semidefinite programming  [ :arrow_down: ](https://arxiv.org/pdf/2112.10448.pdf)
>  Stability and stabilization for linear state feedback control systems in the presence of sensor quantization are studied. As the closed-loop system is described by a discontinuous right-hand side differential equation, Krasovskii solutions (to the closed-loop system) are considered. Sufficient conditions in the form of matrix inequalities are proposed to characterize uniform global asymptotic stability of a compact set containing the origin. Such conditions are shown to be always feasible whenever the quantization-free closed-loop system is asymptotically stable. Building on the obtained conditions, computationally affordable algorithms for the solution to the considered problems are illustrated. The effectiveness of the proposed methodology is shown in three examples.      
### 51.Lane Departure Prediction Based on Closed-Loop Vehicle Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2112.10379.pdf)
>  An automated driving system should have the ability to supervise its own performance and to request human driver to take over when necessary. In the lane keeping scenario, the prediction of vehicle future trajectory is the key to realize safe and trustworthy driving automation. Previous studies on vehicle trajectory prediction mainly fall into two categories, i.e. physics-based and manoeuvre-based methods. Using a physics-based methodology, this paper proposes a lane departure prediction algorithm based on closed-loop vehicle dynamics model. We use extended Kalman filter to estimate the current vehicle states based on sensing module outputs. Then a Kalman Predictor with actual lane keeping control law is used to predict steering actions and vehicle states in the future. A lane departure assessment module evaluates the probabilistic distribution of vehicle corner positions and decides whether to initiate a human takeover request. The prediction algorithm is capable to describe the stochastic characteristics of future vehicle pose, which is preliminarily proved in simulated tests. Finally, the on-road tests at speeds of 15 to 50 km/h further show that the pro-posed method can accurately predict vehicle future trajectory. It may work as a promising solution to lane departure risk assessment for automated lane keeping functions.      
### 52.Learning for Robust Combinatorial Optimization: Algorithm and Application  [ :arrow_down: ](https://arxiv.org/pdf/2112.10377.pdf)
>  Learning to optimize (L2O) has recently emerged as a promising approach to solving optimization problems by exploiting the strong prediction power of neural networks and offering lower runtime complexity than conventional solvers. While L2O has been applied to various problems, a crucial yet challenging class of problems -- robust combinatorial optimization in the form of minimax optimization -- have largely remained under-explored. In addition to the exponentially large decision space, a key challenge for robust combinatorial optimization lies in the inner optimization problem, which is typically non-convex and entangled with outer optimization. In this paper, we study robust combinatorial optimization and propose a novel learning-based optimizer, called LRCO (Learning for Robust Combinatorial Optimization), which quickly outputs a robust solution in the presence of uncertain context. LRCO leverages a pair of learning-based optimizers -- one for the minimizer and the other for the maximizer -- that use their respective objective functions as losses and can be trained without the need of labels for training problem instances. To evaluate the performance of LRCO, we perform simulations for the task offloading problem in vehicular edge computing. Our results highlight that LRCO can greatly reduce the worst-case cost and improve robustness, while having a very low runtime complexity.      
### 53.Tutorial on Asymptotic Properties of Regularized Least Squares Estimator for Finite Impulse Response Model  [ :arrow_down: ](https://arxiv.org/pdf/2112.10319.pdf)
>  In this paper, we give a tutorial on asymptotic properties of the Least Square (LS) and Regularized Least Squares (RLS) estimators for the finite impulse response model with filtered white noise inputs. We provide three perspectives: the almost sure convergence, the convergence in distribution and the boundedness in probability. On one hand, these properties deepen our understanding of the LS and RLS estimators. On the other hand, we can use them as tools to investigate asymptotic properties of other estimators, such as various hyper-parameter estimators.      
### 54.Design of a synthetic integral feedback circuit: dynamic analysis and DNA implementation  [ :arrow_down: ](https://arxiv.org/pdf/2112.10273.pdf)
>  The design and implementation of regulation motifs ensuring robust perfect adaptation are challenging problems in synthetic biology. Indeed, the design of high-yield robust metabolic pathways producing, for instance, drug precursors and biofuels, could be easily imagined to rely on such a control strategy in order to optimize production levels and reduce production costs, despite the presence of environmental disturbance and model uncertainty. We propose here a motif that ensures tracking and robust perfect adaptation for the controlled reaction network through integral feedback. Its metabolic load on the host is fully tunable and can be made arbitrarily close to the constitutive limit, the universal minimal metabolic load of all possible controllers. A DNA implementation of the controller network is finally provided. Computer simulations using realistic parameters demonstrate the good agreement between the DNA implementation and the ideal controller dynamics.      
### 55.Mobility-Aware Performance in Hybrid RF and Terahertz Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.10249.pdf)
>  Using tools from stochastic geometry, this paper develops a tractable framework to analyze the performance of a mobile user in a two-tier wireless network operating on sub-6GHz and terahertz (THz) transmission frequencies. Specifically, using an equivalence distance approach, we characterize the overall handoff (HO) probability in terms of the horizontal and vertical HO and mobility-aware coverage probability. In addition, we characterize novel coverage probability expressions for THz network in the presence of molecular absorption noise and highlight its significant impact on the users' performance. Specifically, we derive a novel closed-form expression for the Laplace Transform of the cumulative molecular noise and interference observed by a mobile user in a hybrid RF-THz network. Furthermore, we provide a novel approximation to derive the conditional distance distributions of a typical user in a hybrid RF-THz network. Finally, using the overall HO probability and coverage probability expressions, the mobility-aware probability of coverage has been derived in a hybrid RF-THz network. Our mathematical results validate the correctness of the derived expressions using Monte-Carlo simulations. The results offer insights into the adverse impact of users' mobility and molecular noise in THz transmissions on the probability of coverage of mobile users. Our results demonstrate that a small increase in the intensity of terahertz base-stations (TBSs) (about 5 times) can increase the HO probability much more compared to the case when the intensity of RF BSs (RBSs) is increased by 100 times. Furthermore, we note that high molecular absorption can be beneficial (in terms of minimizing interference and molecular noise) for specific deployment intensity of TBSs and the benefits can outweigh the drawbacks of signal degradation due to molecular absorption.      
### 56.Chaotic micro-comb based parallel ranging  [ :arrow_down: ](https://arxiv.org/pdf/2112.10241.pdf)
>  The transition to chaos is ubiquitous in nonlinear systems ranging from fluid dynamics and superconducting circuits to biological organisms. Optical systems driven out of equilibrium such as lasers and supercontinuum generation exhibit chaotic states of light with fluctuations of both amplitude and phase and can give rise to Levy statistics, turbulence, and rogue waves. Spatio-temporal chaos also occurs in continuous-wave driven photonic chip based Kerr micro-resonators, where it is referred to as chaotic modulation instability. Such modulation instability states have generally been considered impractical for applications, in contrast to their coherent light state counterparts, which include soliton or dark-pulse states. Here we demonstrate that incoherent and chaotic states of light in an optical microresonator can be harnessed to implement unambiguous and interference-immune massively parallel coherent laser ranging by using the intrinsic random amplitude and phase modulation of the chaotic comb lines. We utilize 40 distinct lines of a microresonator frequency comb operated in the modulation instability regime. Each line carries more than 1 GHz noise bandwidth, which greatly surpasses the cavity linewidth, and enables to retrieve the distance of objects with cm-scale resolution. Our approach utilizes one of the most widely accessible microcomb states, and offers -- in contrast to dissipative Kerr soliton states -- high conversion efficiency, as well as flat optical spectra, and alleviates the need for complex laser initiation routines. Moreover the approach generates wideband signal modulation without requiring any electro-optical modulator or microwave synthesizer. Viewed more broadly, similar optical systems capable of chaotic dynamics could be applied to random modulation optical ranging as well as spread spectrum communication and optical cryptography systems.      
### 57.Integrating Knowledge in End-to-End Automatic Speech Recognition for Mandarin-English Code-Switching  [ :arrow_down: ](https://arxiv.org/pdf/2112.10202.pdf)
>  Code-Switching (CS) is a common linguistic phenomenon in multilingual communities that consists of switching between languages while speaking. This paper presents our investigations on end-to-end speech recognition for Mandarin-English CS speech. We analyse different CS specific issues such as the properties mismatches between languages in a CS language pair, the unpredictable nature of switching points, and the data scarcity problem. We exploit and improve the state-of-the-art end-to-end system by merging nonlinguistic symbols, by integrating language identification using hierarchical softmax, by modeling sub-word units, by artificially lowering the speaking rate, and by augmenting data using speed perturbed technique and several monolingual datasets to improve the final performance not only on CS speech but also on monolingual benchmarks in order to make the system more applicable on real life settings. Finally, we explore the effect of different language model integration methods on the performance of the proposed model. Our experimental results reveal that all the proposed techniques improve the recognition performance. The best combined system improves the baseline system by up to 35% relatively in terms of mixed error rate and delivers acceptable performance on monolingual benchmarks.      
### 58.Detect what you want: Target Sound Detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.10153.pdf)
>  Human beings can perceive a target sound that we are interested in from a multi-source environment by the selective auditory attention, however, such functionality was hardly ever explored in machine hearing.This paper address the target sound detection (TSD), which aims to detect the target sound signal from a mixture audio when a target sound's reference audio is given.We present a novel target sound detection network (TSDNet) which consists of two main parts: A conditional and a detection network. The former aims at generating a sound-discriminative conditional embedding vector representing the global information of the target sound. The latter takes both the mixture audio and the conditional embedding vector as inputs, and produces the detection result. These two networks can be jointly optimized with a multi-task learning approach to further improve the performance. In addition, we study both supervised and weakly supervised strategies to train <a class="link-external link-http" href="http://TSDNet.To" rel="external noopener nofollow">this http URL</a> evaluate our methods, we build a target sound detection dataset (TSD Dataset) based on URBAN-SED and URBAN-SOUND8K datasets. Experimental results indicate our system can get better performance than universal sound event detection.      
### 59.Information Field Theory as Artificial Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2112.10133.pdf)
>  Information field theory (IFT), the information theory for fields, is a mathematical framework for signal reconstruction and non-parametric inverse problems. Here, fields denote physical quantities that change continuously as a function of space (and time) and information theory refers to Bayesian probabilistic logic equipped with the associated entropic information measures. Reconstructing a signal with IFT is a computational problem similar to training a generative neural network (GNN). In this paper, the inference in IFT is reformulated in terms of GNN training and the cross-fertilization of numerical variational inference methods used in IFT and machine learning are discussed. The discussion suggests that IFT inference can be regarded as a specific form of artificial intelligence. In contrast to classical neural networks, IFT based GNNs can operate without pre-training thanks to incorporating expert knowledge into their architecture.      
### 60.Investigation of Densely Connected Convolutional Networks with Domain Adversarial Learning for Noise Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2112.10108.pdf)
>  We investigate densely connected convolutional networks (DenseNets) and their extension with domain adversarial training for noise robust speech recognition. DenseNets are very deep, compact convolutional neural networks which have demonstrated incredible improvements over the state-of-the-art results in computer vision. Our experimental results reveal that DenseNets are more robust against noise than other neural network based models such as deep feed forward neural networks and convolutional neural networks. Moreover, domain adversarial learning can further improve the robustness of DenseNets against both, known and unknown noise conditions.      
### 61.Expression is enough: Improving traffic signal control with advanced traffic state representation  [ :arrow_down: ](https://arxiv.org/pdf/2112.10107.pdf)
>  Recently, finding fundamental properties for traffic state representation is more critical than complex algorithms for traffic signal control (TSC).In this paper, we (1) present a novel, flexible and straightforward method advanced max pressure (Advanced-MP), taking both running and queueing vehicles into consideration to decide whether to change current phase; (2) novelty design the traffic movement representation with the efficient pressure and effective running vehicles from Advanced-MP, namely advanced traffic state (ATS); (3) develop an RL-based algorithm template Advanced-XLight, by combining ATS with current RL approaches and generate two RL algorithms, "Advanced-MPLight" and "Advanced-CoLight". Comprehensive experiments on multiple real-world datasets show that: (1) the Advanced-MP outperforms baseline methods, which is efficient and reliable for deployment; (2) Advanced-MPLight and Advanced-CoLight could achieve new state-of-the-art. Our code is released on Github.      
### 62.Heterogeneous Transformer: A Scale Adaptable Neural Network Architecture for Device Activity Detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.10086.pdf)
>  To support the modern machine-type communications, a crucial task during the random access phase is device activity detection, which is to detect the active devices from a large number of potential devices based on the received signal at the access point. By utilizing the statistical properties of the channel, state-of-the-art covariance based methods have been demonstrated to achieve better activity detection performance than compressed sensing based methods. However, covariance based methods require to solve a high dimensional nonconvex optimization problem by updating the estimate of the activity status of each device sequentially. Since the number of updates is proportional to the device number, the computational complexity and delay make the iterative updates difficult for real-time implementation especially when the device number scales up. Inspired by the success of deep learning for real-time inference, this paper proposes a learning based method with a customized heterogeneous transformer architecture for device activity detection. By adopting an attention mechanism in the architecture design, the proposed method is able to extract the relevance between device pilots and received signal, is permutation equivariant with respect to devices, and is scale adaptable to different numbers of devices. Simulation results demonstrate that the proposed method achieves better activity detection performance with much shorter computation time than state-of-the-art covariance approach, and generalizes well to different numbers of devices, BS-antennas, and different signal-to-noise ratios.      
### 63.Learning-based methods to model small body gravity fields for proximity operations: Safety and Robustness  [ :arrow_down: ](https://arxiv.org/pdf/2112.09998.pdf)
>  Accurate gravity field models are essential for safe proximity operations around small bodies. State-of-the-art techniques use spherical harmonics or high-fidelity polyhedron shape models. Unfortunately, these techniques can become inaccurate near the surface of the small body or have high computational costs, especially for binary or heterogeneous small bodies. New learning-based techniques do not encode a predefined structure and are more versatile. In exchange for versatility, learning-based techniques can be less robust outside the training data domain. In deployment, the spacecraft trajectory is the primary source of dynamics data. Therefore, the training data domain should include spacecraft trajectories to accurately evaluate the learned model's safety and robustness. We have developed a novel method for learning-based gravity models that directly uses the spacecraft's past trajectories. We further introduce a method to evaluate the safety and robustness of learning-based techniques via comparing accuracy within and outside of the training domain. We demonstrate this safety and robustness method for two learning-based frameworks: Gaussian processes and neural networks. Along with the detailed analysis provided, we empirically establish the need for robustness verification of learned gravity models when used for proximity operations.      
### 64.Equilibrated Zeroth-Order Unrolled Deep Networks for Accelerated MRI  [ :arrow_down: ](https://arxiv.org/pdf/2112.09891.pdf)
>  Recently, model-driven deep learning unrolls a certain iterative algorithm of a regularization model into a cascade network by replacing the first-order information (i.e., (sub)gradient or proximal operator) of the regularizer with a network module, which appears more explainable and predictable compared to common data-driven networks. Conversely, in theory, there is not necessarily such a functional regularizer whose first-order information matches the replaced network module, which means the network output may not be covered by the original regularization model. Moreover, up to now, there is also no theory to guarantee the global convergence and robustness (regularity) of unrolled networks under realistic assumptions. To bridge this gap, this paper propose to present a safeguarded methodology on network unrolling. Specifically, focusing on accelerated MRI, we unroll a zeroth-order algorithm, of which the network module represents the regularizer itself, so that the network output can be still covered by the regularization model. Furthermore, inspired by the ideal of deep equilibrium models, before backpropagating, we carry out the unrolled iterative network to converge to a fixed point to ensure the convergence. In case the measurement data contains noise, we prove that the proposed network is robust against noisy interference. Finally, numerical experiments show that the proposed network consistently outperforms the state-of-the-art MRI reconstruction methods including traditional regularization methods and other deep learning methods.      
### 65.MEMS Sensor for Detection and Measurement of Ultra-Fine Particles: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2112.09837.pdf)
>  This paper investigates the performance of the micro-electro-mechanical systems resonant sensor used for particle detection and concentration measurement. These fine and ultra-fine particles such as particulate matter (PM), ferrous particles, and nanoparticles are known to contaminate the atmosphere, fluids used in industrial machines, and food, respectively. The physical principles involved in the target particles accumulating on the sensor are presented. Micro-gravimetric resonators that use piezoelectric and thermally actuated transducers for particle detection and concentration measurement in air and high-viscosity liquids are analyzed. Critical sensor features, such as maximum possible parametric sensitivity, the detection limit of particle size and mass concentration, linear dynamic range, and output stability, are thoroughly evaluated.      
### 66.Neural Born Iteration Method For Solving Inverse Scattering Problems: 2D Cases  [ :arrow_down: ](https://arxiv.org/pdf/2112.09831.pdf)
>  In this paper, we propose the neural Born iteration method (NeuralBIM) for solving 2D inverse scattering problems (ISPs) by drawing on the scheme of physics-informed supervised residual learning (PhiSRL) to emulate the computing process of the traditional Born iteration method (TBIM). NeuralBIM employs independent convolutional neural networks (CNNs) to learn the alternate update rules of two different candidate solutions with their corresponding residuals. Two different schemes of NeuralBIMs are presented in this paper including supervised and unsupervised learning schemes. With the data set generated by method of moments (MoM), supervised NeuralBIMs are trained with the knowledge of total fields and contrasts. Unsupervised NeuralBIM is guided by the physics-embedded loss functions founding on the governing equations of ISPs, which results in no requirements of total fields and contrasts for training. Representative numerical results further validate the effectiveness and competitiveness of both supervised and unsupervised NeuralBIMs.      
### 67.Coded Consensus Monte Carlo: Robust One-Shot Distributed Bayesian Learning with Stragglers  [ :arrow_down: ](https://arxiv.org/pdf/2112.09794.pdf)
>  This letter studies distributed Bayesian learning in a setting encompassing a central server and multiple workers by focusing on the problem of mitigating the impact of stragglers. The standard one-shot, or embarrassingly parallel, Bayesian learning protocol known as consensus Monte Carlo (CMC) is generalized by proposing two straggler-resilient solutions based on grouping and coding. The proposed methods, referred to as Group-based CMC (G-CMC) and Coded CMC (C-CMC), leverage redundant computing at the workers in order to enable the estimation of global posterior samples at the server based on partial outputs from the workers. Simulation results show that C-CMC may outperform G-GCMC for a small number of workers, while G-CMC is generally preferable for a larger number of workers.      
### 68.Towards Harmonious Decentralization of Energy Systems: A Vision of Interoperable Peer-to-Peer Energy Markets  [ :arrow_down: ](https://arxiv.org/pdf/2112.09756.pdf)
>  We present a hierarchical framework aimed at decentralizing the distribution systems market operations using localized peer-to-peer energy markets. Hierarchically designed decision-making algorithm approaches the power systems market operations from a bottom-up perspective. The three layers of the hierarchical framework operate in orchestration to enable prosumers (the grass-root actors) to maximize their revenues - hence, a prosumer-centric framework. The design of the framework incorporates existing smart grid technologies (Virtual Power Plants, Microgrids, Distributed Energy Resources) and redefine their functional objectives to align them with the decentralization paradigm focused on empowering bottom-up grid operations approach. On one hand, the framework is enabling prosumers with simultaneous access to the buy-sell choices that help them maximize their cost savings while ensuring their consumption patterns and preferences are not being tradeoff as a result of top-down operational decisions. On the other hand, it is designed to operate in harmony with the existing top-down grid operations mechanisms - thereby reducing the potential friction in its adaptation. This marriage of the top-down and bottom-up operational approaches is facilitated through meticulous orchestration of operational timescales. Framework's novel design also incorporates scalability and interoperability considerations, thereby tackling the challenge of decentralization holistically.      
### 69.Soundify: Matching Sound Effects to Video  [ :arrow_down: ](https://arxiv.org/pdf/2112.09726.pdf)
>  In the art of video editing, sound is really half the story. A skilled video editor overlays sounds, such as effects and ambients, over footage to add character to an object or immerse the viewer within a space. However, through formative interviews with professional video editors, we found that this process can be extremely tedious and time-consuming. We introduce Soundify, a system that matches sound effects to video. By leveraging labeled, studio-quality sound effects libraries and extending CLIP, a neural network with impressive zero-shot image classification capabilities, into a "zero-shot detector", we are able to produce high-quality results without resource-intensive correspondence learning or audio generation. We encourage you to have a look at, or better yet, have a listen to the results at <a class="link-external link-https" href="https://chuanenlin.com/soundify" rel="external noopener nofollow">this https URL</a>.      
### 70.Can uncertainty boost the reliability of AI-based diagnostic methods in digital pathology?  [ :arrow_down: ](https://arxiv.org/pdf/2112.09693.pdf)
>  Deep learning (DL) has shown great potential in digital pathology applications. The robustness of a diagnostic DL-based solution is essential for safe clinical deployment. In this work we evaluate if adding uncertainty estimates for DL predictions in digital pathology could result in increased value for the clinical applications, by boosting the general predictive performance or by detecting mispredictions. We compare the effectiveness of model-integrated methods (MC dropout and Deep ensembles) with a model-agnostic approach (Test time augmentation, TTA). Moreover, four uncertainty metrics are compared. Our experiments focus on two domain shift scenarios: a shift to a different medical center and to an underrepresented subtype of cancer. Our results show that uncertainty estimates can add some reliability and reduce sensitivity to classification threshold selection. While advanced metrics and deep ensembles perform best in our comparison, the added value over simpler metrics and TTA is small. Importantly, the benefit of all evaluated uncertainty estimation methods is diminished by domain shift.      
