# ArXiv eess --Mon, 6 Dec 2021
### 1.Real Time Monitoring and Control of Neonatal Incubator using IOT  [ :arrow_down: ](https://arxiv.org/pdf/2112.02071.pdf)
>  The care of new born babies are the most important and sensitive part of bio-medical domain. Some new born babies have a higher risk of mortality due to their gestational age or their birth weight. Most of the premature babies born on 32-37 weeks of gestation and are deceased due to their unmet need for warmth. The neonatal incubator is a device used to nourish the premature babies by providing a controlled and closed environment. This incubator provides the babies with optimum temperature, relative humidity, optimum light and appropriate level of oxygen which are same as that in the womb. But babies in the incubators have a risk of losing those babies lives due to the improper monitoring of the it which causes accidents like gas leakage and short circuits due to overheating which leads to bursting of incubators. Thus, the objective of this paper is to overcome the drawbacks of an unmonitored incubator and develops an affordable and safe device for real-time monitoring of the neonatal incubator. a low cost yet effective apparatus for monitoring the important parameters like pulse rate, temperature, humidity, gas and light of the premature baby inside an incubator. The sensed data are passed to the doctors or nurses wirelessly by the Arduino UNO via Internet of Things (IoT) so as to take necessary actions at times to maintain an appropriate environment for the safety of the lives of premature babies.      
### 2.Socially Compatible Control Design of Automated Vehicle in Mixed Traffic  [ :arrow_down: ](https://arxiv.org/pdf/2112.02041.pdf)
>  In the car-following scenarios, automated vehicles (AVs) usually plan motions without considering the impacts of their actions on the following human drivers. This paper aims to leverage such impacts to plan more efficient and socially desirable AV behaviors in human-AV interactions. Specifically, we introduce a socially compatible control design for the AV that benefits mixed traffic in the car-following scenarios. The proposed design enables the altruistic AV in human-AV interaction by integrating the social value orientation from psychology into its decision-making process. The altruistic AV generates socially desirable behaviors by optimizing both its own reward and courtesy to the following human driver's original plan in the longitudinal motion. The results show that as compared to the egoistic AV, the altruistic AV significantly avoids disrupting the following human driver's initial plan and leads the following human driver to achieve considerably smaller car-following gap distance and time headway. Moreover, we investigated the impacts of the socially compatible control design with different altruism levels of the AV using statistical assessments. The results collectively demonstrate the significant improvement in traffic-level metrics as a result of the AV's altruistic behaviors in human-AV interactions.      
### 3.Scale up to infinity: the UWB Indoor Global Positioning System  [ :arrow_down: ](https://arxiv.org/pdf/2112.01950.pdf)
>  Determining assets position with high accuracy and scalability is one of the most investigated technology on the market. The accuracy provided by satellites-based positioning systems (i.e., GLONASS or Galileo) is not always sufficient when a decimeter-level accuracy is required or when there is the need of localising entities that operate inside indoor environments. Scalability is also a recurrent problem when dealing with indoor positioning systems. This paper presents an innovative UWB Indoor GPS-Like local positioning system able to tracks any number of assets without decreasing measurements update rate. To increase the system's accuracy the mathematical model and the sources of uncertainties are investigated. Results highlight how the proposed implementation provides positioning information with an absolute maximum error below 20 cm. Scalability is also resolved thanks to DTDoA transmission mechanisms not requiring an active role from the asset to be tracked.      
### 4.Towards Super-Resolution CEST MRI for Visualization of Small Structures  [ :arrow_down: ](https://arxiv.org/pdf/2112.01905.pdf)
>  The onset of rheumatic diseases such as rheumatoid arthritis is typically subclinical, which results in challenging early detection of the disease. However, characteristic changes in the anatomy can be detected using imaging techniques such as MRI or CT. Modern imaging techniques such as chemical exchange saturation transfer (CEST) MRI drive the hope to improve early detection even further through the imaging of metabolites in the body. To image small structures in the joints of patients, typically one of the first regions where changes due to the disease occur, a high resolution for the CEST MR imaging is necessary. Currently, however, CEST MR suffers from an inherently low resolution due to the underlying physical constraints of the acquisition. In this work we compared established up-sampling techniques to neural network-based super-resolution approaches. We could show, that neural networks are able to learn the mapping from low-resolution to high-resolution unsaturated CEST images considerably better than present methods. On the test set a PSNR of 32.29dB (+10%), a NRMSE of 0.14 (+28%), and a SSIM of 0.85 (+15%) could be achieved using a ResNet neural network, improving the baseline considerably. This work paves the way for the prospective investigation of neural networks for super-resolution CEST MRI and, followingly, might lead to a earlier detection of the onset of rheumatic diseases.      
### 5.Learning-Based Adaptive IRS Control with Limited Feedback Codebooks  [ :arrow_down: ](https://arxiv.org/pdf/2112.01874.pdf)
>  Intelligent reflecting surfaces (IRS) consist of configurable meta-atoms, which can change the wireless propagation environment through design of their reflection coefficients. We consider a practical setting where (i) the IRS reflection coefficients are achieved by adjusting tunable elements embedded in the meta-atoms, (ii) the IRS reflection coefficients are affected by the incident angles of the incoming signals, (iii) the IRS is deployed in multi-path, time-varying channels, and (iv) the feedback link from the base station to the IRS has a low data rate. Conventional optimization-based IRS control protocols, which rely on channel estimation and conveying the optimized variables to the IRS, are not applicable in this setting due to the difficulty of channel estimation and the low feedback rate. Therefore, we develop a novel adaptive codebook-based limited feedback protocol where only a codeword index is transferred to the IRS. We propose two solutions for adaptive codebook design: random adjacency (RA) and deep neural network policy-based IRS control (DPIC), both of which only require the end-to-end compound channels. We further develop several augmented schemes based on the RA and DPIC. Numerical evaluations show that the data rate and average data rate over one coherence time are improved substantially by our schemes.      
### 6.A Practical Method for Automated Modeling and Parametric Stability Analysis of VSC with Periodical Steady State  [ :arrow_down: ](https://arxiv.org/pdf/2112.01865.pdf)
>  Linear Time Periodic (LTP) framework-based analysis of Voltage Source Converters (VSCs) is becoming popular, a driven factor is that many of the existing VSC applications inevitably exhibit the periodic steady-state (PSS), e.g., VSCs with unbalanced grid connections and the operation of a modular multilevel converter (MMC). In these studies, acquisition of the VSC's PSS conditions is a necessary precondition for proper linearization and stability analysis, and the efficiency of this process is particularly important for parametric studies. To this end, this work develops a computational method for automating the LTP analyses of VSCs with an integrated PSS solver. The core of the method lies in a unified frequency-domain iteration process that is developed by applying the generalized averaging principle. Given this, modeling, stability analysis, as well as the solution of PSS conditions can be unified in one process. The algorithmic implementation of the method in MATLAB is elaborated. Application of the obtained tool in impedance generation and parametric stability test is presented with an unbalanced grid-tied VSC as the exemplification. Finally, PSCAD/EMTDC simulations further consolidate the validity of the results.      
### 7.Synthesis of Lyapunov Functions using Formal Verification  [ :arrow_down: ](https://arxiv.org/pdf/2112.01835.pdf)
>  Recent employments of SMT solvers within the Lyapunov function synthesis provided effective tools for automated construction of Lyapunov functions alongside with sound computer-assisted certificates. The main benefit of the suggested approach is the formal correctness and elimination of the numerical uncertainty. In the present work, we extend the SMT-based synthesis approach for wider classes of continuous and discrete-time systems. Additionally, we address constructions of Lyapunov functions for state-dependent switching systems. We illustrate our approach by means of various examples from the control systems literature.      
### 8.Detection of Large Vessel Occlusions using Deep Learning by Deforming Vessel Tree Segmentations  [ :arrow_down: ](https://arxiv.org/pdf/2112.01797.pdf)
>  Computed Tomography Angiography is a key modality providing insights into the cerebrovascular vessel tree that are crucial for the diagnosis and treatment of ischemic strokes, in particular in cases of large vessel occlusions (LVO). Thus, the clinical workflow greatly benefits from an automated detection of patients suffering from LVOs. This work uses convolutional neural networks for case-level classification trained with elastic deformation of the vessel tree segmentation masks to artificially augment training data. Using only masks as the input to our model uniquely allows us to apply such deformations much more aggressively than one could with conventional image volumes while retaining sample realism. <br>The neural network classifies the presence of an LVO and the affected hemisphere. In a 5-fold cross validated ablation study, we demonstrate that the use of the suggested augmentation enables us to train robust models even from few data sets. Training the EfficientNetB1 architecture on 100 data sets, the proposed augmentation scheme was able to raise the ROC AUC to 0.85 from a baseline value of 0.57 using no augmentation. The best performance was achieved using a 3D-DenseNet yielding an AUC of 0.88. The augmentation had positive impact in classification of the affected hemisphere as well, where the 3D-DenseNet reached an AUC of 0.93 on both sides.      
### 9.Fully automatic integration of dental CBCT images and full-arch intraoral impressions with stitching error correction via individual tooth segmentation and identification  [ :arrow_down: ](https://arxiv.org/pdf/2112.01784.pdf)
>  We present a fully automated method of integrating intraoral scan (IOS) and dental cone-beam computerized tomography (CBCT) images into one image by complementing each image's weaknesses. Dental CBCT alone may not be able to delineate precise details of the tooth surface due to limited image resolution and various CBCT artifacts, including metal-induced artifacts. IOS is very accurate for the scanning of narrow areas, but it produces cumulative stitching errors during full-arch scanning. The proposed method is intended not only to compensate the low-quality of CBCT-derived tooth surfaces with IOS, but also to correct the cumulative stitching errors of IOS across the entire dental arch. Moreover, the integration provide both gingival structure of IOS and tooth roots of CBCT in one image. The proposed fully automated method consists of four parts; (i) individual tooth segmentation and identification module for IOS data (TSIM-IOS); (ii) individual tooth segmentation and identification module for CBCT data (TSIM-CBCT); (iii) global-to-local tooth registration between IOS and CBCT; and (iv) stitching error correction of full-arch IOS. The experimental results show that the proposed method achieved landmark and surface distance errors of 0.11mm and 0.30mm, respectively.      
### 10.Fast Data-Driven Adaptation of Radar Detection via Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2112.01780.pdf)
>  This paper addresses the problem of fast learning of radar detectors with a limited amount of training data. In current data-driven approaches for radar detection, re-training is generally required when the operating environment changes, incurring large overhead in terms of data collection and training time. In contrast, this paper proposes two novel deep learning-based approaches that enable fast adaptation of detectors based on few data samples from a new environment. The proposed methods integrate prior knowledge regarding previously encountered radar operating environments in two different ways. One approach is based on transfer learning: it first pre-trains a detector such that it works well on data collected in previously observed environments, and then it adapts the pre-trained detector to the specific current environment. The other approach targets explicitly few-shot training via meta-learning: based on data from previous environments, it finds a common initialization that enables fast adaptation to a new environment. Numerical results validate the benefits of the proposed two approaches compared with the conventional method based on training with no prior knowledge. Furthermore, the meta-learning-based detector outperforms the transfer learning-based detector when the clutter is Gaussian.      
### 11.THz Band Channel Measurements and Statistical Modeling for Urban Microcellular Environments  [ :arrow_down: ](https://arxiv.org/pdf/2112.01770.pdf)
>  The THz band (0.1-10 THz) has attracted considerable attention for next-generation wireless communications, due to the large amount of available bandwidth that may be key to meet the rapidly increasing data rate requirements. Before deploying a system in this band, a detailed wireless channel analysis is required as the basis for proper design and testing of system implementations. One of the most important deployment scenarios of this band is the outdoor microcellular environment, where the Transmitter (Tx) and the Receiver (Rx) have a significant height difference (typically $ \ge 10$ m). In this paper, we present double-directional (i.e., directionally resolved at both link ends) channel measurements in such a microcellular scenario encompassing street canyons and an open square. Measurements are done for a 1 GHz bandwidth between 145-146 GHz and an antenna beamwidth of 13 degree; distances between Tx and Rx are up to 85 m and the Tx is at a height of 11.5 m from the ground. The measurements are analyzed to estimate path loss, shadowing, delay spread, angular spread, and multipath component (MPC) power distribution. These results allow the development of more realistic and detailed THz channel models and system performance assessment.      
### 12.MT-TransUNet: Mediating Multi-Task Tokens in Transformers for Skin Lesion Segmentation and Classification  [ :arrow_down: ](https://arxiv.org/pdf/2112.01767.pdf)
>  Recent advances in automated skin cancer diagnosis have yielded performance on par with board-certified dermatologists. However, these approaches formulated skin cancer diagnosis as a simple classification task, dismissing the potential benefit from lesion segmentation. We argue that an accurate lesion segmentation can supplement the classification task with additive lesion information, such as asymmetry, border, intensity, and physical size; in turn, a faithful lesion classification can support the segmentation task with discriminant lesion features. To this end, this paper proposes a new multi-task framework, named MT-TransUNet, which is capable of segmenting and classifying skin lesions collaboratively by mediating multi-task tokens in Transformers. Furthermore, we have introduced dual-task and attended region consistency losses to take advantage of those images without pixel-level annotation, ensuring the model's robustness when it encounters the same image with an account of augmentation. Our MT-TransUNet exceeds the previous state of the art for lesion segmentation and classification tasks in ISIC-2017 and PH2; more importantly, it preserves compelling computational efficiency regarding model parameters (48M~vs.~130M) and inference speed (0.17s~vs.~2.02s per image). Code will be available at <a class="link-external link-https" href="https://github.com/JingyeChen/MT-TransUNet" rel="external noopener nofollow">this https URL</a>.      
### 13.Localized Feature Aggregation Module for Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.01702.pdf)
>  We propose a new information aggregation method which called Localized Feature Aggregation Module based on the similarity between the feature maps of an encoder and a decoder. The proposed method recovers positional information by emphasizing the similarity between decoder's feature maps with superior semantic information and encoder's feature maps with superior positional information. The proposed method can learn positional information more efficiently than conventional concatenation in the U-net and attention U-net. Additionally, the proposed method also uses localized attention range to reduce the computational cost. Two innovations contributed to improve the segmentation accuracy with lower computational cost. By experiments on the Drosophila cell image dataset and COVID-19 image dataset, we confirmed that our method outperformed conventional methods.      
### 14.The impact of varying electrical stimulation parameters on neuromuscular response  [ :arrow_down: ](https://arxiv.org/pdf/2112.01650.pdf)
>  High density neurostimulation systems are coming to market to help spinal cord injury patients by stimulating and recording neuromuscular function. However, the parameter space that these systems have to explore is exceedingly large, and would need an artificial intelligence (AI) system to optimize. We need a platform that will allow us to determine the optimal parameter space for these systems. Our project aims to build a platform for mapping and controlling neuromuscular activity, as a high-throughput testbed for implementing and testing closed-loop neuromuscular activity. This abstract presents the first phase (the mapping phase) of building that testbed by combining multi-electrode stimulation/recording with visual motion-tracking. A 3D-printed rectangular raceway was used with 4 pairs of differential recording electrodes, and two stimulation electrodes embedded in the raceway bed. Non-anesthetized earthworms were placed on the raceway with their head section on the stimulating electrodes. Bipolar sinusoidal stimulation pulses of a range of voltages (2 to 6Vp-p), pulse durations (2 ms to 6.7 ms), and a burst rate of 1 pulse per second were applied, and action potentials and physical motion were recorded and analyzed. Action potentials were found to correlate with expansion/contraction displacements of worm segments, and voltage increases were shown to increase action potential propagation amplitude. Using the multiple electrode recording allowed us to capture the wave propagation of action potential pulse over the length of the worm. Feasibility of a platform to simultaneously monitor action potentials and motion of earthworms with real-time mapping was demonstrated.      
### 15.Engineering AI Tools for Systematic and Scalable Quality Assessment in Magnetic Resonance Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2112.01629.pdf)
>  A desire to achieve large medical imaging datasets keeps increasing as machine learning algorithms, parallel computing, and hardware technology evolve. Accordingly, there is a growing demand in pooling data from multiple clinical and academic institutes to enable large-scale clinical or translational research studies. Magnetic resonance imaging (MRI) is a frequently used, non-invasive imaging modality. However, constructing a big MRI data repository has multiple challenges related to privacy, data size, DICOM format, logistics, and non-standardized images. Not only building the data repository is difficult, but using data pooled from the repository is also challenging, due to heterogeneity in image acquisition, reconstruction, and processing pipelines across MRI vendors and imaging sites. This position paper describes challenges in constructing a large MRI data repository and using data downloaded from such data repositories in various aspects. To help address the challenges, the paper proposes introducing a quality assessment pipeline, with considerations and general design principles.      
### 16.High-Precision Inversion of Dynamic Radiography Using Hydrodynamic Features  [ :arrow_down: ](https://arxiv.org/pdf/2112.01627.pdf)
>  Radiography is often used to probe complex, evolving density fields in dynamic systems and in so doing gain insight into the underlying physics. This technique has been used in numerous fields including materials science, shock physics, inertial confinement fusion, and other national security applications. In many of these applications, however, complications resulting from noise, scatter, complex beam dynamics, etc. prevent the reconstruction of density from being accurate enough to identify the underlying physics with sufficient confidence. As such, density reconstruction from static/dynamic radiography has typically been limited to identifying discontinuous features such as cracks and voids in a number of these applications. <br>In this work, we propose a fundamentally new approach to reconstructing density from a temporal sequence of radiographic images. Using only the robust features identifiable in radiographs, we combine them with the underlying hydrodynamic equations of motion using a machine learning approach, namely, conditional generative adversarial networks (cGAN), to determine the density fields from a dynamic sequence of radiographs. Next, we seek to further enhance the hydrodynamic consistency of the ML-based density reconstruction through a process of parameter estimation and projection onto a hydrodynamic manifold. In this context, we note that the distance from the hydrodynamic manifold given by the training data to the test data in the parameter space considered both serves as a diagnostic of the robustness of the predictions and serves to augment the training database, with the expectation that the latter will further reduce future density reconstruction errors. Finally, we demonstrate the ability of this method to outperform a traditional radiographic reconstruction in capturing allowable hydrodynamic paths even when relatively small amounts of scatter are present.      
### 17.Active Disturbance Rejection Control (ADRC) Toolbox for MATLAB/Simulink  [ :arrow_down: ](https://arxiv.org/pdf/2112.01614.pdf)
>  In this paper, an active disturbance rejection control (ADRC) toolbox for MATLAB/Simulink is introduced. Although ADRC has already been established as a powerful robust control framework with successful industrial implementations and strong theoretical foundations, a comprehensive tool for computer-aided design of ADRC has not been developed until now. The proposed ADRC Toolbox is a response to a growing need of both scientific community and control industry looking for a straightforward software utilization of the ADRC methodology. Its main purpose is to fill the gap between current theories and applications of ADRC and to provide an easy-to-use solution to users in various control fields wanting to employ the ADRC scheme in their applications. The ADRC Toolbox contains a single, general-purpose, drag-and-drop function block allowing to synthesize a predefined ADRC-based strategy with minimal design effort. Its efficacy is validated here in both simulations and hardware experiments, conducted using a variety of problems known from motion, process, and power control areas. The proposed ADRC Toolbox is an open-source project.      
### 18.The Gardner problem and cycle slipping bifurcation for type 2 phase-locked loops  [ :arrow_down: ](https://arxiv.org/pdf/2112.01604.pdf)
>  In the present work, a second-order type 2 PLL with a piecewise-linear phase detector characteristic is analysed. An exact solution to the Gardner problem on the lock-in range is obtained for the considered model. The solution is based on a study of cycle slipping bifurcation and improves well-known engineering estimates.      
### 19.The conservative lock-in range for PLL with lead-lag filter and triangular phase detector characteristic  [ :arrow_down: ](https://arxiv.org/pdf/2112.01602.pdf)
>  In the present work, a second-order PLL with lead-lag loop filter and triangular phase detector characteristic is analysed. An exact value of the conservative lock-in range is obtained for the considered model. The solution is based on analytical integration of the considered model on the linear segments.      
### 20.Quantifying the uncertainty of neural networks using Monte Carlo dropout for deep learning based quantitative MRI  [ :arrow_down: ](https://arxiv.org/pdf/2112.01587.pdf)
>  Dropout is conventionally used during the training phase as regularization method and for quantifying uncertainty in deep learning. We propose to use dropout during training as well as inference steps, and average multiple predictions to improve the accuracy, while reducing and quantifying the uncertainty. The results are evaluated for fractional anisotropy (FA) and mean diffusivity (MD) maps which are obtained from only 3 direction scans. With our method, accuracy can be improved significantly compared to network outputs without dropout, especially when the training dataset is small. Moreover, confidence maps are generated which may aid in diagnosis of unseen pathology or artifacts.      
### 21.Robust End-to-End Focal Liver Lesion Detection using Unregistered Multiphase Computed Tomography Images  [ :arrow_down: ](https://arxiv.org/pdf/2112.01535.pdf)
>  The computer-aided diagnosis of focal liver lesions (FLLs) can help improve workflow and enable correct diagnoses; FLL detection is the first step in such a computer-aided diagnosis. Despite the recent success of deep-learning-based approaches in detecting FLLs, current methods are not sufficiently robust for assessing misaligned multiphase data. By introducing an attention-guided multiphase alignment in feature space, this study presents a fully automated, end-to-end learning framework for detecting FLLs from multiphase computed tomography (CT) images. Our method is robust to misaligned multiphase images owing to its complete learning-based approach, which reduces the sensitivity of the model's performance to the quality of registration and enables a standalone deployment of the model in clinical practice. Evaluation on a large-scale dataset with 280 patients confirmed that our method outperformed previous state-of-the-art methods and significantly reduced the performance degradation for detecting FLLs using misaligned multiphase CT images. The robustness of the proposed method can enhance the clinical adoption of the deep-learning-based computer-aided detection system.      
### 22.Learning to automate cryo-electron microscopy data collection with Ptolemy  [ :arrow_down: ](https://arxiv.org/pdf/2112.01534.pdf)
>  Over the past decade, cryogenic electron microscopy (cryo-EM) has emerged as a primary method for determining near-native, near-atomic resolution 3D structures of biological macromolecules. In order to meet increasing demand for cryo-EM, automated methods to improve throughput and efficiency while lowering costs are needed. Currently, the process of collecting high-magnification cryo-EM micrographs, data collection, requires human input and manual tuning of parameters, as expert operators must navigate low- and medium-magnification images to find good high-magnification collection locations. Automating this is non-trivial: the images suffer from low signal-to-noise ratio and are affected by a range of experimental parameters that can differ for each collection session. Here, we use various computer vision algorithms, including mixture models, convolutional neural networks (CNNs), and U-Nets to develop the first pipeline to automate low- and medium-magnification targeting with purpose-built algorithms. Learned models in this pipeline are trained on a large internal dataset of images from real world cryo-EM data collection sessions, labeled with locations that were selected by operators. Using these models, we show that we can effectively detect and classify regions of interest (ROIs) in low- and medium-magnification images, and can generalize to unseen sessions, as well as to images captured using different microscopes from external facilities. We expect our pipeline, Ptolemy, will be both immediately useful as a tool for automation of cryo-EM data collection, and serve as a foundation for future advanced methods for efficient and automated cryo-EM microscopy.      
### 23.Automatic tumour segmentation in H&amp;E-stained whole-slide images of the pancreas  [ :arrow_down: ](https://arxiv.org/pdf/2112.01533.pdf)
>  Pancreatic cancer will soon be the second leading cause of cancer-related death in Western society. Imaging techniques such as CT, MRI and ultrasound typically help providing the initial diagnosis, but histopathological assessment is still the gold standard for final confirmation of disease presence and prognosis. In recent years machine learning approaches and pathomics pipelines have shown potential in improving diagnostics and prognostics in other cancerous entities, such as breast and prostate cancer. A crucial first step in these pipelines is typically identification and segmentation of the tumour area. Ideally this step is done automatically to prevent time consuming manual annotation. We propose a multi-task convolutional neural network to balance disease detection and segmentation accuracy. We validated our approach on a dataset of 29 patients (for a total of 58 slides) at different resolutions. The best single task segmentation network achieved a median Dice of 0.885 (0.122) IQR at a resolution of 15.56 $\mu$m. Our multi-task network improved on that with a median Dice score of 0.934 (0.077) IQR.      
### 24.I-WKNN: Fast-Speed and High-Accuracy WIFI Positioning for Intelligent Stadiums  [ :arrow_down: ](https://arxiv.org/pdf/2112.02058.pdf)
>  Based on various existing wireless fingerprint location algorithms in intelligent sports venues, a high-precision and fast indoor location algorithm improved weighted k-nearest neighbor (I-WKNN) is proposed. In order to meet the complex environment of sports venues and the demand of high-speed sampling, this paper proposes an AP selection algorithm for offline and online stages. Based on the characteristics of the signal intensity distribution in intelligent venues, an asymmetric Gaussian filter algorithm is proposed. This paper introduces the application of the positioning algorithm in the intelligent stadium system, and completes the data acquisition and real-time positioning of the stadium. Compared with traditional WKNN and KNN algorithms, the I-WKNN algorithm has advantages in fingerprint positioning database processing, environmental noise adaptability, real-time positioning accuracy and positioning speed, etc. The experimental results show that the I-WKNN algorithm has obvious advantages in positioning accuracy and positioning time in a complex noise environment and has obvious application potential in a smart stadium.      
### 25.Low-Resolution Massive MIMO Under Hardware Power Consumption Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2112.02021.pdf)
>  We consider a fully digital massive multiple-input multiple-output architecture with low-resolution analog-to-digital/digital-to-analog converters (ADCs/DACs) at the base station (BS) and analyze the performance trade-off between the number of BS antennas, the resolution of the ADCs/DACs, and the bandwidth. Assuming a hardware power consumption constraint, we determine the relationship between these design parameters by using a realistic model for the power consumption of the ADCs/DACs and the radio frequency chains. Considering uplink pilot-aided channel estimation, we build on the Bussgang decomposition to derive tractable expressions for uplink and downlink ergodic achievable sum rates. Numerical results show that the ergodic performance is boosted when many BS antennas with very low resolution (i.e., 2 to 3 bits) are adopted in both the uplink and the downlink.      
### 26.Learning to Broadcast for Ultra-Reliable Communication with Differential Quality of Service via the Conditional Value at Risk  [ :arrow_down: ](https://arxiv.org/pdf/2112.02007.pdf)
>  Broadcast/multicast communication systems are typically designed to optimize the outage rate criterion, which neglects the performance of the fraction of clients with the worst channel conditions. Targeting ultra-reliable communication scenarios, this paper takes a complementary approach by introducing the conditional value-at-risk (CVaR) rate as the expected rate of a worst-case fraction of clients. To support differential quality-of-service (QoS) levels in this class of clients, layered division multiplexing (LDM) is applied, which enables decoding at different rates. Focusing on a practical scenario in which the transmitter does not know the fading distribution, layer allocation is optimized based on a dataset sampled during deployment. The optimality gap caused by the availability of limited data is bounded via a generalization analysis, and the sample complexity is shown to increase as the designated fraction of worst-case clients decreases. Considering this theoretical result, meta-learning is introduced as a means to reduce sample complexity by leveraging data from previous deployments. Numerical experiments demonstrate that LDM improves spectral efficiency even for small datasets; that, for sufficiently large datasets, the proposed mirror-descent-based layer optimization scheme achieves a CVaR rate close to that achieved when the transmitter knows the fading distribution; and that meta-learning can significantly reduce data requirements.      
### 27.Fixed-Gain AF Relaying for RF-THz Wireless System over $α$-$κ$-$μ$ Shadowed and $α$-$μ$ Channels  [ :arrow_down: ](https://arxiv.org/pdf/2112.01984.pdf)
>  Recent research investigates the decode-and-forward (DF) relaying for mixed radio frequency (RF) and terahertz (THz) wireless links with zero-boresight pointing errors. In this letter, we analyze the performance of a fixed-gain amplify-and-forward (AF) relaying for the RF-THz link to interface the access network on the RF technology with wireless THz transmissions. We develop probability density function (PDF) and cumulative distribution function (CDF) of the end-to-end SNR for the relay-assisted system in terms of bivariate Fox's H function considering $\alpha$-$\mu$ fading for the THz system with non-zero boresight pointing errors and $\alpha$-$\kappa$-$\mu$ shadowed ($\alpha$-KMS) fading model for the RF link. Using the derived PDF and CDF, we present exact analytical expressions of the outage probability, average bit-error-rate (BER), and ergodic capacity of the considered system. We also analyze the outage probability and average BER asymptotically for a better insight into the system behavior at high SNR. We use simulations to compare the performance of the AF relaying having a semi-blind gain factor with the recently proposed DF relaying for THz-RF transmissions.      
### 28.Multi-Content Complementation Network for Salient Object Detection in Optical Remote Sensing Images  [ :arrow_down: ](https://arxiv.org/pdf/2112.01932.pdf)
>  In the computer vision community, great progresses have been achieved in salient object detection from natural scene images (NSI-SOD); by contrast, salient object detection in optical remote sensing images (RSI-SOD) remains to be a challenging emerging topic. The unique characteristics of optical RSIs, such as scales, illuminations and imaging orientations, bring significant differences between NSI-SOD and RSI-SOD. In this paper, we propose a novel Multi-Content Complementation Network (MCCNet) to explore the complementarity of multiple content for RSI-SOD. Specifically, MCCNet is based on the general encoder-decoder architecture, and contains a novel key component named Multi-Content Complementation Module (MCCM), which bridges the encoder and the decoder. In MCCM, we consider multiple types of features that are critical to RSI-SOD, including foreground features, edge features, background features, and global image-level features, and exploit the content complementarity between them to highlight salient regions over various scales in RSI features through the attention mechanism. Besides, we comprehensively introduce pixel-level, map-level and metric-aware losses in the training phase. Extensive experiments on two popular datasets demonstrate that the proposed MCCNet outperforms 23 state-of-the-art methods, including both NSI-SOD and RSI-SOD methods. The code and results of our method are available at <a class="link-external link-https" href="https://github.com/MathLee/MCCNet" rel="external noopener nofollow">this https URL</a>.      
### 29.In situ process quality monitoring and defect detection for direct metal laser melting  [ :arrow_down: ](https://arxiv.org/pdf/2112.01921.pdf)
>  Quality control and quality assurance are challenges in Direct Metal Laser Melting (DMLM). Intermittent machine diagnostics and downstream part inspections catch problems after undue cost has been incurred processing defective parts. In this paper we demonstrate two methodologies for in-process fault detection and part quality prediction that can be readily deployed on existing commercial DMLM systems with minimal hardware modification. Novel features were derived from the time series of common photodiode sensors along with standard machine control signals. A Bayesian approach attributes measurements to one of multiple process states and a least squares regression model predicts severity of certain material defects.      
### 30.Hybrid Digital Twin for process industry using Apros simulation environment  [ :arrow_down: ](https://arxiv.org/pdf/2112.01903.pdf)
>  Making an updated and as-built model plays an important role in the life-cycle of a process plant. In particular, Digital Twin models must be precise to guarantee the efficiency and reliability of the systems. Data-driven models can simulate the latest behavior of the sub-systems by considering uncertainties and life-cycle related changes. This paper presents a step-by-step concept for hybrid Digital Twin models of process plants using an early implemented prototype as an example. It will detail the steps for updating the first-principles model and Digital Twin of a brownfield process system using data-driven models of the process equipment. The challenges for generation of an as-built hybrid Digital Twin will also be discussed. With the help of process history data to teach Machine Learning models, the implemented Digital Twin can be continually improved over time and this work in progress can be further optimized.      
### 31.Reinforcement Learning-Based Automatic Berthing System  [ :arrow_down: ](https://arxiv.org/pdf/2112.01879.pdf)
>  Previous studies on automatic berthing systems based on artificial neural network (ANN) showed great berthing performance by training the ANN with ship berthing data as training data. However, because the ANN requires a large amount of training data to yield robust performance, the ANN-based automatic berthing system is somewhat limited due to the difficulty in obtaining the berthing data. In this study, to overcome this difficulty, the automatic berthing system based on one of the reinforcement learning (RL) algorithms, proximal policy optimization (PPO), is proposed because the RL algorithms can learn an optimal control policy through trial-and-error by interacting with a given environment and does not require any pre-obtained training data, where the control policy in the proposed PPO-based automatic berthing system controls revolutions per second (RPS) and rudder angle of a ship. Finally, it is shown that the proposed PPO-based automatic berthing system eliminates the need for obtaining the training dataset and shows great potential for the actual berthing application.      
### 32.Disentangling modes with crossover instantaneous frequencies by synchrosqueezed chirplet transforms, from theory to application  [ :arrow_down: ](https://arxiv.org/pdf/2112.01857.pdf)
>  Analysis of signals with oscillatory modes with crossover instantaneous frequencies is a challenging problem in time series analysis. One way to handle this problem is lifting the 2-dimensional time-frequency representation to a 3-dimensional representation, called time-frequency-chirp rate (TFC) representation, by adding one extra chirp rate parameter so that crossover frequencies are disentangles in higher dimension. The chirplet transform is an algorithm for this lifting idea. However, in practice we found that it has a stronger "blurring" effect in the chirp rate axis, which limits its application in real world data. Moreover, to our knowledge, we have limited mathematical understanding of the chirplet transform in the literature. Motivated by real world data challenges, in this paper, we propose the synchrosqueezed chirplet transform (SCT) that gives a concentrated TFC representation that the contrast is enhanced so that one can distinguish different modes even with crossover instantaneous frequencies. We also analyze chirplet transform and provide theoretical guarantee of SCT.      
### 33.Optimal Probing Sequences for Polarization-Multiplexed Coherent Phase OTDR  [ :arrow_down: ](https://arxiv.org/pdf/2112.01848.pdf)
>  We introduce dual-polarization probing codes based on two circularly shifted frequency sweep signals enabling perfect channel estimation. This is achieved with a probing length equal to at least twice the fiber round-trip propagation time.      
### 34.Semantic Map Injected GAN Training for Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2112.01845.pdf)
>  Image-to-image translation is the recent trend to transform images from one domain to another domain using generative adversarial network (GAN). The existing GAN models perform the training by only utilizing the input and output modalities of transformation. In this paper, we perform the semantic injected training of GAN models. Specifically, we train with original input and output modalities and inject a few epochs of training for translation from input to semantic map. Lets refer the original training as the training for the translation of input image into target domain. The injection of semantic training in the original training improves the generalization capability of the trained GAN model. Moreover, it also preserves the categorical information in a better way in the generated image. The semantic map is only utilized at the training time and is not required at the test time. The experiments are performed using state-of-the-art GAN models over CityScapes and RGB-NIR stereo datasets. We observe the improved performance in terms of the SSIM, FID and KID scores after injecting semantic training as compared to original training.      
### 35.Blackbox Untargeted Adversarial Testing of Automatic Speech Recognition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.01821.pdf)
>  Automatic speech recognition (ASR) systems are prevalent, particularly in applications for voice navigation and voice control of domestic appliances. The computational core of ASRs are deep neural networks (DNNs) that have been shown to be susceptible to adversarial perturbations; easily misused by attackers to generate malicious outputs. To help test the correctness of ASRS, we propose techniques that automatically generate blackbox (agnostic to the DNN), untargeted adversarial attacks that are portable across ASRs. Much of the existing work on adversarial ASR testing focuses on targeted attacks, i.e generating audio samples given an output text. Targeted techniques are not portable, customised to the structure of DNNs (whitebox) within a specific ASR. In contrast, our method attacks the signal processing stage of the ASR pipeline that is shared across most ASRs. Additionally, we ensure the generated adversarial audio samples have no human audible difference by manipulating the acoustic signal using a psychoacoustic model that maintains the signal below the thresholds of human perception. We evaluate portability and effectiveness of our techniques using three popular ASRs and three input audio datasets using the metrics - WER of output text, Similarity to original audio and attack Success Rate on different ASRs. We found our testing techniques were portable across ASRs, with the adversarial audio samples producing high Success Rates, WERs and Similarities to the original audio.      
### 36.Music-to-Dance Generation with Optimal Transport  [ :arrow_down: ](https://arxiv.org/pdf/2112.01806.pdf)
>  Dance choreography for a piece of music is a challenging task, having to be creative in presenting distinctive stylistic dance elements while taking into account the musical theme and rhythm. It has been tackled by different approaches such as similarity retrieval, sequence-to-sequence modeling and generative adversarial networks, but their generated dance sequences are often short of motion realism, diversity and music consistency. In this paper, we propose a Music-to-Dance with Optimal Transport Network (MDOT-Net) for learning to generate 3D dance choreographs from music. We introduce an optimal transport distance for evaluating the authenticity of the generated dance distribution and a Gromov-Wasserstein distance to measure the correspondence between the dance distribution and the input music. This gives a well defined and non-divergent training objective that mitigates the limitation of standard GAN training which is frequently plagued with instability and divergent generator loss issues. Extensive experiments demonstrate that our MDOT-Net can synthesize realistic and diverse dances which achieve an organic unity with the input music, reflecting the shared intentionality and matching the rhythmic articulation.      
### 37.A Survey: Deep Learning for Hyperspectral Image Classification with Few Labeled Samples  [ :arrow_down: ](https://arxiv.org/pdf/2112.01800.pdf)
>  With the rapid development of deep learning technology and improvement in computing capability, deep learning has been widely used in the field of hyperspectral image (HSI) classification. In general, deep learning models often contain many trainable parameters and require a massive number of labeled samples to achieve optimal performance. However, in regard to HSI classification, a large number of labeled samples is generally difficult to acquire due to the difficulty and time-consuming nature of manual labeling. Therefore, many research works focus on building a deep learning model for HSI classification with few labeled samples. In this article, we concentrate on this topic and provide a systematic review of the relevant literature. Specifically, the contributions of this paper are twofold. First, the research progress of related methods is categorized according to the learning paradigm, including transfer learning, active learning and few-shot learning. Second, a number of experiments with various state-of-the-art approaches has been carried out, and the results are summarized to reveal the potential research directions. More importantly, it is notable that although there is a vast gap between deep learning models (that usually need sufficient labeled samples) and the HSI scenario with few labeled samples, the issues of small-sample sets can be well characterized by fusion of deep learning methods and related techniques, such as transfer learning and a lightweight model. For reproducibility, the source codes of the methods assessed in the paper can be found at <a class="link-external link-https" href="https://github.com/ShuGuoJ/HSI-Classification.git" rel="external noopener nofollow">this https URL</a>.      
### 38.Unsupervised Low-Light Image Enhancement via Histogram Equalization Prior  [ :arrow_down: ](https://arxiv.org/pdf/2112.01766.pdf)
>  Deep learning-based methods for low-light image enhancement typically require enormous paired training data, which are impractical to capture in real-world scenarios. Recently, unsupervised approaches have been explored to eliminate the reliance on paired training data. However, they perform erratically in diverse real-world scenarios due to the absence of priors. To address this issue, we propose an unsupervised low-light image enhancement method based on an effective prior termed histogram equalization prior (HEP). Our work is inspired by the interesting observation that the feature maps of histogram equalization enhanced image and the ground truth are similar. Specifically, we formulate the HEP to provide abundant texture and luminance information. Embedded into a Light Up Module (LUM), it helps to decompose the low-light images into illumination and reflectance maps, and the reflectance maps can be regarded as restored images. However, the derivation based on Retinex theory reveals that the reflectance maps are contaminated by noise. We introduce a Noise Disentanglement Module (NDM) to disentangle the noise and content in the reflectance maps with the reliable aid of unpaired clean images. Guided by the histogram equalization prior and noise disentanglement, our method can recover finer details and is more capable to suppress noise in real-world low-light scenarios. Extensive experiments demonstrate that our method performs favorably against the state-of-the-art unsupervised low-light enhancement algorithms and even matches the state-of-the-art supervised algorithms.      
### 39.BBS-KWS:The Mandarin Keyword Spotting System Won the Video Keyword Wakeup Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2112.01757.pdf)
>  This paper introduces the system submitted by the Yidun NISP team to the video keyword wakeup challenge. We propose a mandarin keyword spotting system (KWS) with several novel and effective improvements, including a big backbone (B) model, a keyword biasing (B) mechanism and the introduction of syllable modeling units (S). By considering this, we term the total system BBS-KWS as an abbreviation. The BBS-KWS system consists of an end-to-end automatic speech recognition (ASR) module and a KWS module. The ASR module converts speech features to text representations, which applies a big backbone network to the acoustic model and takes syllable modeling units into consideration as well. In addition, the keyword biasing mechanism is used to improve the recall rate of keywords in the ASR inference stage. The KWS module applies multiple criteria to determine the absence or presence of the keywords, such as multi-stage matching, fuzzy matching, and connectionist temporal classification (CTC) prefix score. To further improve our system, we conduct semi-supervised learning on the CN-Celeb dataset for better generalization. In the VKW task, the BBS-KWS system achieves significant gains over the baseline and won the first place in two tracks.      
### 40.Joint User Scheduling and Beamforming Design for Multiuser MISO Downlink Systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.01738.pdf)
>  In multiuser communication systems, user scheduling and beamforming design are two fundamental problems, which are usually investigated separately in the existing literature. In this work, we focus on the joint optimization of user scheduling and beamforming design with the goal of maximizing the set cardinality of scheduled users. Observing that this problem is computationally challenging due to the non-convex objective function and coupled constraints in continuous and binary variables. To tackle these difficulties, we first propose an iterative optimization algorithm (IOA) relying on the successive convex approximation and uplink-downlink duality theory. Then, motivated by IOA and graph neural networks, a joint user scheduling and power allocation network (JEEPON) is developed to address the investigated problem in an unsupervised manner. The effectiveness of IOA and JEEPON is verified by various numerical results, and the latter achieves a close performance but lower complexity compared with IOA and the greedy-based algorithm. Remarkably, the proposed JEEPON is also competitive in terms of the generalization ability in dynamic wireless network scenarios.      
### 41.Adversarial Attacks against a Satellite-borne Multispectral Cloud Detector  [ :arrow_down: ](https://arxiv.org/pdf/2112.01723.pdf)
>  Data collected by Earth-observing (EO) satellites are often afflicted by cloud cover. Detecting the presence of clouds -- which is increasingly done using deep learning -- is crucial preprocessing in EO applications. In fact, advanced EO satellites perform deep learning-based cloud detection on board the satellites and downlink only clear-sky data to save precious bandwidth. In this paper, we highlight the vulnerability of deep learning-based cloud detection towards adversarial attacks. By optimising an adversarial pattern and superimposing it into a cloudless scene, we bias the neural network into detecting clouds in the scene. Since the input spectra of cloud detectors include the non-visible bands, we generated our attacks in the multispectral domain. This opens up the potential of multi-objective attacks, specifically, adversarial biasing in the cloud-sensitive bands and visual camouflage in the visible bands. We also investigated mitigation strategies against the adversarial attacks. We hope our work further builds awareness of the potential of adversarial attacks in the EO community.      
### 42.Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2112.01715.pdf)
>  Self-supervised learning aims to learn image feature representations without the usage of manually annotated labels. It is often used as a precursor step to obtain useful initial network weights which contribute to faster convergence and superior performance of downstream tasks. While self-supervision allows one to reduce the domain gap between supervised and unsupervised learning without the usage of labels, the self-supervised objective still requires a strong inductive bias to downstream tasks for effective transfer learning. In this work, we present our material and texture based self-supervision method named MATTER (MATerial and TExture Representation Learning), which is inspired by classical material and texture methods. Material and texture can effectively describe any surface, including its tactile properties, color, and specularity. By extension, effective representation of material and texture can describe other semantic classes strongly associated with said material and texture. MATTER leverages multi-temporal, spatially aligned remote sensing imagery over unchanged regions to learn invariance to illumination and viewing angle as a mechanism to achieve consistency of material and texture representation. We show that our self-supervision pre-training method allows for up to 24.22% and 6.33% performance increase in unsupervised and fine-tuned setups, and up to 76% faster convergence on change detection, land cover classification, and semantic segmentation tasks.      
### 43.LMR-CBT: Learning Modality-fused Representations with CB-Transformer for Multimodal Emotion Recognition from Unaligned Multimodal Sequences  [ :arrow_down: ](https://arxiv.org/pdf/2112.01697.pdf)
>  Learning modality-fused representations and processing unaligned multimodal sequences are meaningful and challenging in multimodal emotion recognition. Existing approaches use directional pairwise attention or a message hub to fuse language, visual, and audio modalities. However, those approaches introduce information redundancy when fusing features and are inefficient without considering the complementarity of modalities. In this paper, we propose an efficient neural network to learn modality-fused representations with CB-Transformer (LMR-CBT) for multimodal emotion recognition from unaligned multimodal sequences. Specifically, we first perform feature extraction for the three modalities respectively to obtain the local structure of the sequences. Then, we design a novel transformer with cross-modal blocks (CB-Transformer) that enables complementary learning of different modalities, mainly divided into local temporal learning,cross-modal feature fusion and global self-attention representations. In addition, we splice the fused features with the original features to classify the emotions of the sequences. Finally, we conduct word-aligned and unaligned experiments on three challenging datasets, IEMOCAP, CMU-MOSI, and CMU-MOSEI. The experimental results show the superiority and efficiency of our proposed method in both settings. Compared with the mainstream methods, our approach reaches the state-of-the-art with a minimum number of parameters.      
### 44.Data-enabled Gradient Flow as Feedback Controller: Regulation of Linear Dynamical Systems to Minimizers of Unknown Functions  [ :arrow_down: ](https://arxiv.org/pdf/2112.01652.pdf)
>  This paper considers the problem of regulating a linear dynamical system to the solution of a convex optimization problem with an unknown or partially-known cost. We design a data-driven feedback controller - based on gradient flow dynamics - that (i) is augmented with learning methods to estimate the cost function based on infrequent (and possibly noisy) functional evaluations; and, concurrently, (ii) is designed to drive the inputs and outputs of the dynamical system to the optimizer of the problem. We derive sufficient conditions on the learning error and the controller gain to ensure that the error between the optimizer of the problem and the state of the closed-loop system is ultimately bounded; the error bound accounts for the functional estimation errors and the temporal variability of the unknown disturbance affecting the linear dynamical system. Our results directly lead to exponential input-to-state stability of the closed-loop system. The proposed method and the theoretical bounds are validated numerically.      
