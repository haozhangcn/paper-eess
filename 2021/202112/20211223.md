# ArXiv eess --Thu, 23 Dec 2021
### 1.On the prescribed-time attractivity and frozen-time eigenvalues of linear time-varying systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.12120.pdf)
>  A system is called prescribed-time attractive if its solution converges at an arbitrary user-defined finite time. In this note, necessary and sufficient conditions are developed for the prescribed-time attractivity of linear time-varying (LTV) systems. It is proved that the frozen-time eigenvalues of a prescribed-time attractive LTV system have negative real parts when the time is sufficiently close to the convergence moment. This result shows that the ubiquitous singularity problem of prescribed-time attractive LTV systems can be avoided without instability effects by switching to the corresponding frozen-time system at an appropriate time. Consequently, it is proved that the time-varying state-feedback gain of a prescribed-time controller, designed for an unknown linear time-invariant system, approaches the set of stabilizing constant state-feedback gains.      
### 2.IDCAIS: Inter-Defender Collision-Aware Interception Strategy against Multiple Attackers  [ :arrow_down: ](https://arxiv.org/pdf/2112.12098.pdf)
>  This paper presents an Inter-Defender Collision-Aware Interception Strategy (IDCAIS) for defenders to intercept attackers in order to defend a protected area, such that each defender also avoids collision with other defenders. In particular, the defenders are assigned to intercept attackers using a mixed-integer quadratic program (MIQP) that: 1)minimizes the sum of times taken by defenders to capture the attackers under time-optimal control, and2) helps eliminate or delay possible future collisions among the defenders on the optimal trajectories. To prevent inevitable collisions on optimal trajectories or collisions arising due to time-sub-optimal behavior by the attackers, a minimally augmented control using exponential control barrier function (ECBF) is provided. Simulations show the efficacy of the approach.      
### 3.Chua Circuit based on the Exponential Characteristics of Semiconductor Devices  [ :arrow_down: ](https://arxiv.org/pdf/2112.12080.pdf)
>  The use of non-ideal features of semiconductor devices is an interesting option for implementations of nonlinear electronic systems. This paper analyzes the Chua circuit with nonlinearity based on the exponential hyperbolic characteristics of semiconductor devices. The stability analysis using describing functions predicts the dynamics of this nonlinear system, which is corroborated by numerical investigations and experimental results. The dynamic behaviors and bifurcations of this nonlinear system are mapped in parameter space in order to create a base for studies, analyses, and designs. The dynamic behavior of the experimental high speed implementation of this version of Chua circuit differs from the expected dynamics for a conventional Chua circuit due to effects of unmodelled non-idealities of the real semiconductor devices, displaying that new and different dynamics for the Chua circuit can be obtained exploring different nonlinearities.      
### 4.Adaptive model reduction and state estimation of agro-hydrological systems  [ :arrow_down: ](https://arxiv.org/pdf/2112.12061.pdf)
>  Closed-loop irrigation can deliver a promising solution for precision irrigation. The accurate soil moisture (state) estimation is critical in implementing the closed-loop irrigation of agrohydrological systems. In general, the agricultural fields are high dimensional systems. Due to the high dimensionality for a large field, it is very challenging to solve an optimizationbased advanced state estimator like moving horizon estimation (MHE). This work addresses the aforementioned challenge and proposes a systematic approach for state estimation of large agricultural fields. We use a non-linear state-space model based on discretization of the cylindrical coordinate version of Richards equation to describe the agro-hydrological systems equipped with a central pivot irrigation system. We propose a structure-preserving adaptive model reduction method using trajectory-based unsupervised machine learning techniques. Furthermore, the adaptive MHE algorithm is developed based on an adaptive reduced model. The proposed algorithms are applied to a small simulated field to compare the performance of adaptive MHE over original MHE. Finally, the proposed approach is applied to a large-scale real agricultural field to test the effectiveness and superiority to address the current challenges. Extensive simulations are carried out to show the efficiency of the proposed approach.      
### 5.Community Detection in Medical Image Datasets: Using Wavelets and Spectral Methods  [ :arrow_down: ](https://arxiv.org/pdf/2112.12021.pdf)
>  Medical image datasets can have large number of images representing patients with different health conditions and various disease severity. When dealing with raw unlabeled image datasets, the large number of samples often makes it hard for experts and non-experts to understand the variety of images present in a dataset. Supervised learning methods rely on labeled images which requires a considerable effort by medical experts to first understand the communities of images present in the data and then labeling the images. Here, we propose an algorithm to facilitate the automatic identification of communities in medical image datasets. We further explain that such analysis can also be insightful in a supervised setting, when the images are already labeled. Such insights are useful because in reality, health and disease severity can be considered a continuous spectrum, and within each class, there usually are finer communities worthy of investigation, especially when they have similarities to communities in other classes. In our approach, we use wavelet decomposition of images in tandem with spectral methods. We show that the eigenvalues of a graph Laplacian can reveal the number of notable communities in an image dataset. In our experiments, we use a dataset of images labeled with different conditions for COVID patients. We detect 25 communities in the dataset and then observe that only 6 of those communities contain patients with pneumonia. We also investigate the contents of a colorectal cancer histopathology dataset.      
### 6.Compressive Scanning Transmission Electron Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2112.11955.pdf)
>  Scanning Transmission Electron Microscopy (STEM) offers high-resolution images that are used to quantify the nanoscale atomic structure and composition of materials and biological specimens. In many cases, however, the resolution is limited by the electron beam damage, since in traditional STEM, a focused electron beam scans every location of the sample in a raster fashion. In this paper, we propose a scanning method based on the theory of Compressive Sensing (CS) and subsampling the electron probe locations using a line hop sampling scheme that significantly reduces the electron beam damage. We experimentally validate the feasibility of the proposed method by acquiring real CS-STEM data, and recovering images using a Bayesian dictionary learning approach. We support the proposed method by applying a series of masks to fully-sampled STEM data to simulate the expectation of real CS-STEM. Finally, we perform the real data experimental series using a constrained-dose budget to limit the impact of electron dose upon the results, by ensuring that the total electron count remains constant for each image.      
### 7.Deep learning for brain metastasis detection and segmentation in longitudinal MRI data  [ :arrow_down: ](https://arxiv.org/pdf/2112.11833.pdf)
>  Brain metastases occur frequently in patients with metastatic cancer. Early and accurate detection of brain metastases is very essential for treatment planning and prognosis in radiation therapy. To improve brain metastasis detection performance with deep learning, a custom detection loss called volume-level sensitivity-specificity (VSS) is proposed, which rates individual metastasis detection sensitivity and specificity in (sub-)volume levels. As sensitivity and precision are always a trade-off in a metastasis level, either a high sensitivity or a high precision can be achieved by adjusting the weights in the VSS loss without decline in dice score coefficient for segmented metastases. To reduce metastasis-like structures being detected as false positive metastases, a temporal prior volume is proposed as an additional input of the neural network. Our proposed VSS loss improves the sensitivity of brain metastasis detection, increasing the sensitivity from 86.7% to 95.5%. Alternatively, it improves the precision from 68.8% to 97.8%. With the additional temporal prior volume, about 45% of the false positive metastases are reduced in the high sensitivity model and the precision reaches 99.6% for the high specificity model. The mean dice coefficient for all metastases is about 0.81. With the ensemble of the high sensitivity and high specificity models, on average only 1.5 false positive metastases per patient needs further check, while the majority of true positive metastases are confirmed. The ensemble learning is able to distinguish high confidence true positive metastases from metastases candidates that require special expert review or further follow-up, being particularly well-fit to the requirements of expert support in real clinical practice.      
### 8.Carrier Phase Ranging for Indoor Positioning with 5G NR Signals  [ :arrow_down: ](https://arxiv.org/pdf/2112.11772.pdf)
>  Indoor positioning is one of the core technologies of Internet of Things (IoT) and artificial intelligence (AI), and is expected to play a significant role in the upcoming era of AI. However, affected by the complexity of indoor environments, it is still highly challenging to achieve continuous and reliable indoor positioning. Currently, 5G cellular networks are being deployed worldwide, the new technologies of which have brought the approaches for improving the performance of wireless indoor positioning. In this paper, we investigate the indoor positioning under the 5G new radio (NR), which has been standardized and being commercially operated in massive markets. Specifically, a solution is proposed and a software defined receiver (SDR) is developed for indoor positioning. With our SDR indoor positioning system, the 5G NR signals are firstly sampled by universal software radio peripheral (USRP), and then, coarse synchronization is achieved via detecting the start of the synchronization signal block (SSB). Then, with the assistance of the pilots transmitted on the physical broadcasting channel (PBCH), multipath acquisition and delay tracking are sequentially carried out to estimate the time of arrival (ToA) of received signals. Furthermore, to improve the ToA ranging accuracy, the carrier phase of the first arrived path is estimated. Finally, to quantify the accuracy of our ToA estimation method, indoor field tests are carried out in an office environment, where a 5G NR base station (known as gNB) is installed for commercial use. Our test results show that, in the static test scenarios, the ToA accuracy measured by the 1-{\sigma} error interval is about 0.5 m, while in the pedestrian mobile environment, the probability of range accuracy within 0.8 m is 95%.      
### 9.Learning Based Model Predictive Control for Quadcopters with Dual Gaussian Process  [ :arrow_down: ](https://arxiv.org/pdf/2112.11667.pdf)
>  An important issue in quadcopter control is that an accurate dynamic model of the system is nonlinear, complex, and costly to obtain. This limits achievable control performance in practice. Gaussian process (GP) based estimation is an effective tool to learn unknown dynamics from input/output data. However, conventional GP-based control methods often ignore the computational cost associated with accumulating data during the operation of the system and how to handle forgetting in continuous adaption. In this paper, we present a novel Dual Gaussian Process (DGP) based model predictive control strategy that improves the performance of a quadcopter during trajectory tracking. The bio-inspired DGP structure is a combination of a long-term GP and a short-term GP, where the long-term GP is used to keep the learned knowledge in memory and the short-term GP is employed to rapidly compensate unknown dynamics during online operation. Furthermore, a novel recursive online update strategy for the short-term GP is proposed to successively improve the learnt model during online operation in an efficient way. Numerical simulations are used to demonstrate the effectiveness of the proposed strategy.      
### 10.Energy efficient deployment solutions in high density heterogeneous networks  [ :arrow_down: ](https://arxiv.org/pdf/2112.11636.pdf)
>  This study deals with the problem of optimizing transmit power in high density heterogeneous networks. In the communication network, effective methods of allocating transmit power, in order to reduce the total transmit power, but still ensure the quality of service of the user equipment, is a big challenge. number of power consumption optimization problems in core station links, with the goal of maximizing network energy efficiency while ensuring user experience. To solve this non-convex optimization problem, the authors first propose some iterative algorithms to find the convergence point such as the "descent" method, the "Lagrange" method. Then, the authors evaluate the convergence point of each method as well as consider the complexity of each algorithm when put into application. Finally, the simulation results will show the convergence value and compare the performance with the technologies being used today to confirm the effectiveness of the proposed algorithm.      
### 11.Warm-started Semionline Trajectory Planner for Ship's Automatic Docking (Berthing)  [ :arrow_down: ](https://arxiv.org/pdf/2112.11626.pdf)
>  In the usual framework of control, a reference trajectory is needed as the set point for a feedback controller. This leads to a problem on how to scientifically generate the reference trajectory. Such a problem is termed trajectory optimization which is done in a trajectory planner. It is desired that this reference trajectory is kept feasible with respect to the ship's dynamics, the dynamics of the environment (wind), and the surrounding boundary. For an underactuated conventional vessel, its mathematical model can be very intricate. This causes significant computational time. This article demonstrates that the balance between the feasibility of the reference trajectory and the computational time can be achieved for an underactuated vessel in a disturbed and restricted environment. This is done by: (1) using an almost-global offline solution as a warm start in a semionline trajectory optimization to speed up the calculation, (2) including the prediction of wind dynamics, and (3) using a predefined boundary to generate the necessary spatial constraints that guarantee a collision-free trajectory. Incorporation of these three things results in a feasible and safe trajectory, with a considerable computational time speedup. In addition, the warm start generally gives better results than that without warm start.      
### 12.Teacher-Student Architecture for Mixed Supervised Lung Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2112.11541.pdf)
>  Purpose: Automating tasks such as lung tumor localization and segmentation in radiological images can free valuable time for radiologists and other clinical personnel. Convolutional neural networks may be suited for such tasks, but require substantial amounts of labeled data to train. Obtaining labeled data is a challenge, especially in the medical domain. Methods: This paper investigates the use of a teacher-student design to utilize datasets with different types of supervision to train an automatic model performing pulmonary tumor segmentation on computed tomography images. The framework consists of two models: the student that performs end-to-end automatic tumor segmentation and the teacher that supplies the student additional pseudo-annotated data during training. Results: Using only a small proportion of semantically labeled data and a large number of bounding box annotated data, we achieved competitive performance using a teacher-student design. Models trained on larger amounts of semantic annotations did not perform better than those trained on teacher-annotated data. Conclusions: Our results demonstrate the potential of utilizing teacher-student designs to reduce the annotation load, as less supervised annotation schemes may be performed, without any real degradation in segmentation accuracy.      
### 13.The Phonetic Footprint of Parkinson's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2112.11514.pdf)
>  As one of the most prevalent neurodegenerative disorders, Parkinson's disease (PD) has a significant impact on the fine motor skills of patients. The complex interplay of different articulators during speech production and realization of required muscle tension become increasingly difficult, thus leading to a dysarthric speech. Characteristic patterns such as vowel instability, slurred pronunciation and slow speech can often be observed in the affected individuals and were analyzed in previous studies to determine the presence and progression of PD. In this work, we used a phonetic recognizer trained exclusively on healthy speech data to investigate how PD affected the phonetic footprint of patients. We rediscovered numerous patterns that had been described in previous contributions although our system had never seen any pathological speech previously. Furthermore, we could show that intermediate activations from the neural network could serve as feature vectors encoding information related to the disease state of individuals. We were also able to directly correlate the expert-rated intelligibility of a speaker with the mean confidence of phonetic predictions. Our results support the assumption that pathological data is not necessarily required to train systems that are capable of analyzing PD speech.      
### 14.Quantitative phase imaging through an ultra-thin lensless fiber endoscope  [ :arrow_down: ](https://arxiv.org/pdf/2112.12055.pdf)
>  Quantitative phase imaging (QPI) is a label-free technique providing both morphology and quantitative biophysical information in biomedicine. However, applying such a powerful technique to in vivo pathological diagnosis remains challenging. Multi-core fiber bundles (MCFs) enable ultra-thin probes for in vivo imaging, but current MCF imaging techniques are limited to amplitude imaging modalities. We demonstrate a computational lensless microendoscope that uses an ultra-thin bare MCF to perform quantitative phase imaging of biomedical samples with up to 1 {\mu}m lateral resolution and nanoscale axial resolution. The incident complex light field at the measurement side is precisely reconstructed from a single-shot far-field speckle pattern at the detection side, enabling digital focusing and 3D volumetric reconstruction without any mechanical movement. The accuracy of the quantitative phase reconstruction is validated by imaging the phase target and hydrogel beads through the MCF. With the proposed imaging modality, 3D imaging of human cancer cells is achieved through the ultra-thin fiber endoscope, promising widespread clinical applications.      
### 15.Graph-Theoretic Models of Resource Distribution for Cyber-Physical Systems of Disaster-Affected Regions  [ :arrow_down: ](https://arxiv.org/pdf/2112.12046.pdf)
>  We propose a tool-supported framework to reason about requirements constraining resource distributions and devise strategies for routing essential services in a disaster-affected region. At the core of our approach is the Route Advisor for Disaster-Affected Regions (RADAR) framework that operates on high-level algebraic representations of the region, modelled as a cyber-physical system (cps) where resource distribution is carried out over an infrastructure connecting physical geographical locations. The Satisfiable-Modulo Theories (SMT) and graph-theoretic algorithms used by the framework supports disaster management decision-making during response and preparedness phases. We demonstrate our approach on a case study in disaster management and describe scenarios to illustrate the usefulness of RADAR.      
### 16.Compromised ACC vehicles can degrade current mixed-autonomy traffic performance while remaining stealthy against detection  [ :arrow_down: ](https://arxiv.org/pdf/2112.11986.pdf)
>  We demonstrate that a supply-chain level compromise of the adaptive cruise control (ACC) capability on equipped vehicles can be used to significantly degrade system level performance of current day mixed-autonomy freeway networks. Via a simple threat model which causes random deceleration attacks (RDAs), compromised vehicles create congestion waves in the traffic that decrease average speed and network throughput. We use a detailed and realistic traffic simulation environment to quantify the impacts of the attack on a model of a real high-volume freeway in the United States. We find that the effect of the attack depends both on the level of underlying traffic congestion, and what percentage of ACC vehicles can be compromised. In moderate congestion regimes the attack can degrade mean commuter speed by over 7%. In high density regimes overall network throughput can be reduced by up to 3%. And, in moderate to high congestion regimes, it can cost commuters on the network over 300 USD/km hr. All of these results motivate that the proposed attack is able to significantly degrade performance of the traffic network. <br>We also develop an anomaly detection technique that uses GPS traces on vehicles to identify malicious/compromised vehicles. We employ this technique on data from the simulation experiments and find that it is unable to identify compromised ACCs compared to benign/normal drivers. That is, these attacks are stealthy to detection. Stronger attacks can be accurately labeled as malicious, motivating that there is a limit to how impactful attacks can be before they are no longer stealthy. <br>Finally, we experimentally execute the attack on a real and commercially available ACC vehicle, demonstrating the possible real world feasibility of an RDA.      
### 17.Optimizing Vaccine Allocation Strategies in Pandemic Outbreaks: An Optimal Control Approach  [ :arrow_down: ](https://arxiv.org/pdf/2112.11908.pdf)
>  Since early 2020, the world has been dealing with a raging pandemic outbreak: COVID-19. A year later, vaccines have become accessible, but in limited quantities, so that governments needed to devise a strategy to decide which part of the population to prioritize when assigning the available doses, and how to manage the interval between doses for multi-dose vaccines. In this paper, we present an optimization framework to address the dynamic double-dose vaccine allocation problem whereby the available vaccine doses must be administered to different age-groups to minimize specific societal objectives. In particular, we first identify an age-dependent Susceptible-Exposed-Infected-Recovered (SEIR) epidemic model including an extension capturing partially and fully vaccinated people, whereby we account for age-dependent immunity and infectiousness levels together with disease severity. Second, we leverage our model to frame the dynamic age-dependent vaccine allocation problem for different societal objectives, such as the minimization of infections or fatalities, and solve it with nonlinear programming techniques. Finally, we carry out a numerical case study with real-world data from The Netherlands. Our results show how different societal objectives can significantly alter the optimal vaccine allocation strategy. For instance, we find that minimizing the overall number of infections results in delaying second doses, whilst to minimize fatalities it is important to fully vaccinate the elderly first.      
### 18.Introducing the quadratically-constrained quadratic programming framework in HPIPM  [ :arrow_down: ](https://arxiv.org/pdf/2112.11872.pdf)
>  This paper introduces the quadratically-constrained quadratic programming (QCQP) framework recently added in HPIPM alongside the original quadratic-programming (QP) framework. The aim of the new framework is unchanged, namely providing the building blocks to efficiently and reliably solve (more general classes of) optimal control problems (OCP). The newly introduced QCQP framework provides full features parity with the original QP framework: three types of QCQPs (dense, optimal control and tree-structured optimal control QCQPs) and interior point method (IPM) solvers as well as (partial) condensing and other pre-processing routines. Leveraging the modular structure of HPIPM, the new QCQP framework builds on the QP building blocks and similarly provides fast and reliable IPM solvers.      
### 19.DRF Codes: Deep SNR-Robust Feedback Codes  [ :arrow_down: ](https://arxiv.org/pdf/2112.11789.pdf)
>  We present a new deep-neural-network (DNN) based error correction code for fading channels with output feedback, called deep SNR-robust feedback (DRF) code. At the encoder, parity symbols are generated by a long short term memory (LSTM) network based on the message as well as the past forward channel outputs observed by the transmitter in a noisy fashion. The decoder uses a bi-directional LSTM architecture along with a signal to noise ratio (SNR)-aware attention NN to decode the message. The proposed code overcomes two major shortcomings of the previously proposed DNN-based codes over channels with passive output feedback: (i) the SNR-aware attention mechanism at the decoder enables reliable application of the same trained NN over a wide range of SNR values; (ii) curriculum training with batch-size scheduling is used to speed up and stabilize training while improving the SNR-robustness of the resulting code. We show that the DRF codes significantly outperform state-of-the-art in terms of both the SNR-robustness and the error rate in additive white Gaussian noise (AWGN) channel with feedback. In fading channels with perfect phase compensation at the receiver, DRF codes learn to efficiently exploit knowledge of the instantaneous fading amplitude (which is available to the encoder through feedback) to reduce the overhead and complexity associated with channel estimation at the decoder. Finally, we show the effectiveness of DRF codes in multicast channels with feedback, where linear feedback codes are known to be strictly suboptimal.      
### 20.Exploring Inter-frequency Guidance of Image for Lightweight Gaussian Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2112.11779.pdf)
>  Image denoising is of vital importance in many imaging or computer vision related areas. With the convolutional neural networks showing strong capability in computer vision tasks, the performance of image denoising has also been brought up by CNN based methods. Though CNN based image denoisers show promising results on this task, most of the current CNN based methods try to learn the mapping from noisy image to clean image directly, which lacks the explicit exploration of prior knowledge of images and noises. Natural images are observed to obey the reciprocal power law, implying the low-frequency band of image tend to occupy most of the energy. Thus in the condition of AGWN (additive gaussian white noise) deterioration, low-frequency band tend to preserve a higher PSNR than high-frequency band. Considering the spatial morphological consistency of different frequency bands, low-frequency band with more fidelity can be used as a guidance to refine the more contaminated high-frequency bands. Based on this thought, we proposed a novel network architecture denoted as IGNet, in order to refine the frequency bands from low to high in a progressive manner. Firstly, it decomposes the feature maps into high- and low-frequency subbands using DWT (discrete wavelet transform) iteratively, and then each low band features are used to refine the high band features. Finally, the refined feature maps are processed by a decoder to recover the clean result. With this design, more inter-frequency prior and information are utilized, thus the model size can be lightened while still perserves competitive results. Experiments on several public datasets show that our model obtains competitive performance comparing with other state-of-the-art methods yet with a lightweight structure.      
### 21.Comparing radiologists' gaze and saliency maps generated by interpretability methods for chest x-rays  [ :arrow_down: ](https://arxiv.org/pdf/2112.11716.pdf)
>  The interpretability of medical image analysis models is considered a key research field. We use a dataset of eye-tracking data from five radiologists to compare the outputs of interpretability methods against the heatmaps representing where radiologists looked. We conduct a class-independent analysis of the saliency maps generated by two methods selected from the literature: Grad-CAM and attention maps from an attention-gated model. For the comparison, we use shuffled metrics, which avoid biases from fixation locations. We achieve scores comparable to an interobserver baseline in one shuffled metric, highlighting the potential of saliency maps from Grad-CAM to mimic a radiologist's attention over an image. We also divide the dataset into subsets to evaluate in which cases similarities are higher.      
### 22.New metal-plastic hybrid additive manufacturing strategy: Fabrication of arbitrary metal-patterns on external and even internal surfaces of 3D plastic structures  [ :arrow_down: ](https://arxiv.org/pdf/2112.11661.pdf)
>  Constructing precise micro-nano metal patterns on complex three-dimensional (3D) plastic parts allows the fabrication of functional devices for advanced applications. However, this patterning is currently expensive and requires complex processes with long manufacturing lead time. The present work demonstrates a process for the fabrication of micro-nano 3D metal-plastic composite structures with arbitrarily complex shapes. In this approach, a light-cured resin is modified to prepare an active precursor capable of allowing subsequent electroless plating (ELP). A multi-material digital light processing 3D printer was newly developed to enable the fabrication of parts containing regions made of either standard resin or active precursor resin nested within each other. Selective 3D ELP processing of such parts provided various metal-plastic composite parts having complicated hollow micro-nano structures with specific topological relationships on a size scale as small as 40 um. Using this technique, 3D metal topologies that cannot be manufactured by traditional methods are possible, and metal patterns can be produced inside plastic parts as a means of further miniaturizing electronic devices. The proposed method can also generate metal coatings exhibiting improved adhesion of metal to plastic substrate. Based on this technique, several sensors composed of different functional nonmetallic materials and specific metal patterns were designed and fabricated. The present results demonstrate the viability of the proposed method and suggest potential applications in the fields of smart 3D micro-nano electronics, 3D wearable devices, micro/nano-sensors, and health care.      
### 23.Continuous Optimization-Based Drift Counteraction Optimal Control: A Spacecraft Attitude Control Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2112.11611.pdf)
>  This paper presents a continuous optimization approach to DCOC and its application to spacecraft high-precision attitude control. The approach computes a control input sequence that maximizes the time-before-exit by solving a nonlinear programming problem with an exponentially weighted cost function and purely continuous variables. Based on results from sensitivity analysis and exact penalty method, we prove the optimality guarantee of our approach. The practical application of our approach is demonstrated through a spacecraft high-precision attitude control example. A nominal case with three functional reaction wheels (RWs) and an underactuated case with only two functional RWs were considered. Simulation results illustrate the effectiveness of our approach as a contingency method for extending spacecraft's effective mission time in the case of RW failures.      
### 24.Identifying Mixtures of Bayesian Network Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2112.11602.pdf)
>  A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (identified with the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the rv's that is Markovian on the graph. A finite mixture of such models is the projection on these variables of a BND on the larger graph which has an additional "hidden" (or "latent") random variable $U$, ranging in $\{1,\ldots,k\}$, and a directed edge from $U$ to every other vertex. <br>Models of this type are fundamental to research in Causal Inference, where $U$ models a confounding effect. One extremely special case has been of longstanding interest in the theory literature: the empty graph. Such a distribution is simply a mixture of $k$ product distributions. A longstanding problem has been, given the joint distribution of a mixture of $k$ product distributions, to identify each of the product distributions, and their mixture weights. Our results are: <br>(1) We improve the sample complexity (and runtime) for identifying mixtures of $k$ product distributions from $\exp(O(k^2))$ to $\exp(O(k \log k))$. This is almost best possible in view of a known $\exp(\Omega(k))$ lower bound. <br>(2) We give the first algorithm for the case of non-empty graphs. The complexity for a graph of maximum degree $\Delta$ is $\exp(O(k(\Delta^2 + \log k)))$. <br>(The above complexities are approximate and suppress dependence on secondary parameters.)      
### 25.Mixed Precision of Quantization of Transformer Language Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2112.11540.pdf)
>  State-of-the-art neural language models represented by Transformers are becoming increasingly complex and expensive for practical applications. Low-bit deep neural network quantization techniques provides a powerful solution to dramatically reduce their model size. Current low-bit quantization methods are based on uniform precision and fail to account for the varying performance sensitivity at different parts of the system to quantization errors. To this end, novel mixed precision DNN quantization methods are proposed in this paper. The optimal local precision settings are automatically learned using two techniques. The first is based on a quantization sensitivity metric in the form of Hessian trace weighted quantization perturbation. The second is based on mixed precision Transformer architecture search. Alternating direction methods of multipliers (ADMM) are used to efficiently train mixed precision quantized DNN systems. Experiments conducted on Penn Treebank (PTB) and a Switchboard corpus trained LF-MMI TDNN system suggest the proposed mixed precision Transformer quantization techniques achieved model size compression ratios of up to 16 times over the full precision baseline with no recognition performance degradation. When being used to compress a larger full precision Transformer LM with more layers, overall word error rate (WER) reductions up to 1.7% absolute (18% relative) were obtained.      
### 26.Performance Analysis of IOS-Assisted NOMA System with Channel Correlation and Phase Errors  [ :arrow_down: ](https://arxiv.org/pdf/2112.11512.pdf)
>  In this paper, we investigate the performance of an intelligent omni-surface (IOS) assisted downlink non-orthogonal multiple access (NOMA) network with phase quantization errors and channel estimation errors, where the channels related to the IOS are spatially correlated. First, upper bounds on the average achievable rates of the two users are derived. Then, channel hardening is shown to occur in the proposed system, based on which we derive approximations of the average achievable rates of the two users. The analytical results illustrate that the proposed upper bound and approximation on the average achievable rate of the strong user are asymptotically equivalent in the number of elements. Furthermore, it is proved that the average achievable rates with correlated and uncorrelated channels are asymptotically equivalent for a large number of elements. Simulation results corroborate the theoretical analysis and show that the channel hardening effect appears even for a few elements. The impact of channel correlation on the system performance in terms of average achievable rates is negligible for a large number of elements.      
### 27.Do Androids Dream of Electric Fences? Safety-Aware Reinforcement Learning with Latent Shielding  [ :arrow_down: ](https://arxiv.org/pdf/2112.11490.pdf)
>  The growing trend of fledgling reinforcement learning systems making their way into real-world applications has been accompanied by growing concerns for their safety and robustness. In recent years, a variety of approaches have been put forward to address the challenges of safety-aware reinforcement learning; however, these methods often either require a handcrafted model of the environment to be provided beforehand, or that the environment is relatively simple and low-dimensional. We present a novel approach to safety-aware deep reinforcement learning in high-dimensional environments called latent shielding. Latent shielding leverages internal representations of the environment learnt by model-based agents to "imagine" future trajectories and avoid those deemed unsafe. We experimentally demonstrate that this approach leads to improved adherence to formally-defined safety specifications.      
### 28.Deep Reinforcement Learning for Optimal Power Flow with Renewables Using Spatial-Temporal Graph Information  [ :arrow_down: ](https://arxiv.org/pdf/2112.11461.pdf)
>  Renewable energy resources (RERs) have been increasingly integrated into modern power systems, especially in large-scale distribution networks (DNs). In this paper, we propose a deep reinforcement learning (DRL)-based approach to dynamically search for the optimal operation point, i.e., optimal power flow (OPF), in DNs with a high uptake of RERs. Considering uncertainties and voltage fluctuation issues caused by RERs, we formulate OPF into a multi-objective optimization (MOO) problem. To solve the MOO problem, we develop a novel DRL algorithm leveraging the graphical information of the distribution network. Specifically, we employ the state-of-the-art DRL algorithm, i.e., deep deterministic policy gradient (DDPG), to learn an optimal strategy for OPF. Since power flow reallocation in the DN is a consecutive process, where nodes are self-correlated and interrelated in temporal and spatial views, to make full use of DNs' graphical information, we develop a multi-grained attention-based spatial-temporal graph convolution network (MG-ASTGCN) for spatial-temporal graph information extraction, preparing for its sequential DDPG. We validate our proposed DRL-based approach in modified IEEE 33, 69, and 118-bus radial distribution systems (RDSs) and show that our DRL-based approach outperforms other benchmark algorithms. Our experimental results also reveal that MG-ASTGCN can significantly accelerate the DDPG training process and improve DDPG's capability in reallocating power flow for OPF. The proposed DRL-based approach also promotes DNs' stability in the presence of node faults, especially for large-scale DNs.      
