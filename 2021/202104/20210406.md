# ArXiv eess --Tue, 6 Apr 2021
### 1.Neurological Status Classification Using Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.02058.pdf)
>  In this study we show that a Convolutional Neural Network (CNN) model is able to accuratelydiscriminate between 4 different phases of neurological status in a non-Electroencephalogram(EEG) dataset recorded in an experiment in which subjects are exposed to physical, cognitiveand emotional stress. We demonstrate that the proposed model is able to obtain 99.99% AreaUnder the Curve (AUC) of Receiver Operation characteristic (ROC) and 99.82% classificationaccuracy on the test dataset. Furthermore, for comparison, we show that our models outperformstraditional classification methods such as SVM, and RF. Finally, we show the advantage of CNN models, in comparison to other methods, in robustness to noise by 97.46% accuracy on a noisy dataset.      
### 2.Quick Line Outage Identification in Urban Distribution Grids via Smart Meters  [ :arrow_down: ](https://arxiv.org/pdf/2104.02056.pdf)
>  The growing integration of distributed energy resources (DERs) in distribution grids raises various reliability issues due to DER's uncertain and complex behaviors. With a large-scale DER penetration in distribution grids, traditional outage detection methods, which rely on customers report and smart meters' last gasp signals, will have poor performance, because the renewable generators and storages and the mesh structure in urban distribution grids can continue supplying power after line outages. To address these challenges, we propose a data-driven outage monitoring approach based on the stochastic time series analysis with a theoretical guarantee. Specifically, we prove via power flow analysis that the dependency of time-series voltage measurements exhibits significant statistical changes after line outages. This makes the theory on optimal change-point detection suitable to identify line outages. However, existing change point detection methods require post-outage voltage distribution, which is unknown in distribution systems. Therefore, we design a maximum likelihood estimator to directly learn the distribution parameters from voltage data. We prove that the estimated parameters-based detection also achieves the optimal performance, making it extremely useful for fast distribution grid outage identifications. Furthermore, since smart meters have been widely installed in distribution grids and advanced infrastructure (e.g., PMU) has not widely been available, our approach only requires voltage magnitude for quick outage identification. Simulation results show highly accurate outage identification in eight distribution grids with 14 configurations with and without DERs using smart meter data.      
### 3.Data augmentation for dealing with low sampling rates in NILM  [ :arrow_down: ](https://arxiv.org/pdf/2104.02055.pdf)
>  Data have an important role in evaluating the performance of NILM algorithms. The best performance of NILM algorithms is achieved with high-quality evaluation data. However, many existing real-world data sets come with a low sampling quality, and often with gaps, lacking data for some recording periods. As a result, in such data, NILM algorithms can hardly recognize devices and estimate their power consumption properly. An important step towards improving the performance of these energy disaggregation methods is to improve the quality of the data sets. In this paper, we carry out experiments using several methods to increase the sampling rate of low sampling rate data. Our results show that augmentation of low-frequency data can support the considered NILM algorithms in estimating appliances' consumption with a higher F-score measurement.      
### 4.DeepMI: Deep Multi-lead ECG Fusion for Identifying Myocardial Infarction and its Occurrence-time  [ :arrow_down: ](https://arxiv.org/pdf/2104.02054.pdf)
>  Myocardial Infarction (MI) has the highest mortality of all cardiovascular diseases (CVDs). Detection of MI and information regarding its occurrence-time in particular, would enable timely interventions that may improve patient outcomes, thereby reducing the global rise in CVD deaths. Electrocardiogram (ECG) recordings are currently used to screen MI patients. However, manual inspection of ECGs is time-consuming and prone to subjective bias. Machine learning methods have been adopted for automated ECG diagnosis, but most approaches require extraction of ECG beats or consider leads independently of one another. We propose an end-to-end deep learning approach, DeepMI, to classify MI from normal cases as well as identifying the time-occurrence of MI (defined as acute, recent and old), using a collection of fusion strategies on 12 ECG leads at data-, feature-, and decision-level. In order to minimise computational overhead, we employ transfer learning using existing computer vision networks. Moreover, we use recurrent neural networks to encode the longitudinal information inherent in ECGs. We validated DeepMI on a dataset collected from 17,381 patients, in which over 323,000 samples were extracted per ECG lead. We were able to classify normal cases as well as acute, recent and old onset cases of MI, with AUROCs of 96.7%, 82.9%, 68.6% and 73.8%, respectively. We have demonstrated a multi-lead fusion approach to detect the presence and occurrence-time of MI. Our end-to-end framework provides flexibility for different levels of multi-lead ECG fusion and performs feature extraction via transfer learning.      
### 5.A robust extended Kalman filter for power system dynamic state estimation using PMU measurements  [ :arrow_down: ](https://arxiv.org/pdf/2104.02045.pdf)
>  This paper develops a robust extended Kalman filter to estimate the rotor angles and the rotor speeds of synchronous generators of a multimachine power system. Using a batch-mode regression form, the filter processes together predicted state vector and PMU measurements to track the system dynamics faster than the standard extended Kalman filter. Our proposed filter is based on a robust GM-estimator that bounds the influence of vertical outliers and bad leverage points, which are identified by means of the projection statistics. Good statistical efficiency under the Gaussian distribution assumption of the process and the observation noise is achieved thanks to the use of the Huber cost function, which is minimized via the iteratively reweighted least squares algorithm. The asymptotic covariance matrix of the state estimation error vector is derived via the covariance matrix of the total influence function of the GM-estimator. Simulations carried out on the IEEE 39-bus test system reveal that our robust extended Kalman filter exhibits good tracking capabilities under Gaussian process and observation noise while suppressing observation outliers, even in position of leverage. These good performances are obtained only under the validity of the linear approximation of the power system model.      
### 6.Automated lung segmentation from CT images of normal and COVID-19 pneumonia patients  [ :arrow_down: ](https://arxiv.org/pdf/2104.02042.pdf)
>  Automated semantic image segmentation is an essential step in quantitative image analysis and disease diagnosis. This study investigates the performance of a deep learning-based model for lung segmentation from CT images for normal and COVID-19 patients. Chest CT images and corresponding lung masks of 1200 confirmed COVID-19 cases were used for training a residual neural network. The reference lung masks were generated through semi-automated/manual segmentation of the CT images. The performance of the model was evaluated on two distinct external test datasets including 120 normal and COVID-19 subjects, and the results of these groups were compared to each other. Different evaluation metrics such as dice coefficient (DSC), mean absolute error (MAE), relative mean HU difference, and relative volume difference were calculated to assess the accuracy of the predicted lung masks. The proposed deep learning method achieved DSC of 0.980 and 0.971 for normal and COVID-19 subjects, respectively, demonstrating significant overlap between predicted and reference lung masks. Moreover, MAEs of 0.037 HU and 0.061 HU, relative mean HU difference of -2.679% and -4.403%, and relative volume difference of 2.405% and 5.928% were obtained for normal and COVID-19 subjects, respectively. The comparable performance in lung segmentation of the normal and COVID-19 patients indicates the accuracy of the model for the identification of the lung tissue in the presence of the COVID-19 induced infections (though slightly better performance was observed for normal patients). The promising results achieved by the proposed deep learning-based model demonstrated its reliability in COVID-19 lung segmentation. This prerequisite step would lead to a more efficient and robust pneumonia lesion analysis.      
### 7.Hybrid Relay-Reflecting Intelligent Surface-Aided Wireless Communications: Opportunities, Challenges, and Future Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2104.02039.pdf)
>  Reconfigurable intelligent surfaces (RISs) have emerged as a cost- and energy-efficient technology that can customize and program the physical propagation environment by reflecting radio waves in preferred directions. However, the purely passive reflection of RISs not only limits the end-to-end channel beamforming gains, but also hinders the acquisition of accurate channel state information for the phase control at RISs. In this paper, we provide an overview of a hybrid relay-reflecting intelligent surface (HR-RIS) architecture, in which only a few elements are active and connected to power amplifiers and radio frequency chains. The introduction of a small number of active elements enables a remarkable system performance improvement which can also compensate for losses due to hardware impairments such as the deployment of limited-resolution phase shifters. Particularly, the active processing facilitates efficient channel estimation and localization at HR-RISs. We present two practical architectures for HR-RISs, namely, fixed and dynamic HR-RISs, and discuss their applications to beamforming, channel estimation, and localization. The benefits, key challenges, and future research directions for HR-RIS-aided communications are also highlighted. Numerical results for an exemplary deployment scenario show that HR-RISs with only four active elements can attain up to 42.8 percent and 41.8 percent improvement in spectral efficiency and energy efficiency, respectively, compared with conventional RISs.      
### 8.Modelling and Analysis of Magnetic Fields from Skeletal Muscle for Valuable Physiological Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2104.02036.pdf)
>  MagnetoMyoGraphy (MMG) is a method of studying muscle function via weak magnetic fields generated from human active organs and tissues. The correspondence between MMG and electromyography means directly derived from the Maxwell-AmpÃ¨re law. Here, upon briefly describing the principles of voltage distribution inside skeletal muscles due to the electrical stimulation, we provide a protocol to determine the effects of the magnetic field generated from a time-changing action potential propagating in a group of skeletal muscle cells. The position-dependent and the magnetic field behaviour on account of the different currents in muscle fibres are performed in temporal, spectral and spatial domains. The procedure covers identification of the fibre subpopulations inside the fascicles of a given nerve section, characterization of soleus skeletal muscle currents, check of axial intracellular currents, calculation of the generated magnetic field ultimately. We expect this protocol to take approximately 2-3 hours to complete for the whole finite-element analysis.      
### 9.Robust Control Co-Design with Receding-Horizon MPC  [ :arrow_down: ](https://arxiv.org/pdf/2104.02025.pdf)
>  Control co-design (CCD) is a technique for improving the closed-loop performance of systems through the coordinated design of both plant parameters and an optimal control policy. While model predictive control (MPC) is an attractive control strategy for many systems, embedding it within a CCD algorithm presents challenges because obtaining a closed-form solution for this receding-horizon optimization strategy is often not feasible. This paper meets that challenge by including a robust MPC formulation within the inner loop of a CCD algorithm. As exemplified by application to an aircraft thermal management system, the proposed algorithm closely matches the plant design of an open-loop benchmark. However, unlike the open-loop approach, the proposed algorithm can leverage MPC control variables designed a priori to achieve robust online operation under disturbance profiles that differ from those used for design.      
### 10.Personalized Speech Enhancement through Self-Supervised Data Augmentation and Purification  [ :arrow_down: ](https://arxiv.org/pdf/2104.02018.pdf)
>  Training personalized speech enhancement models is innately a no-shot learning problem due to privacy constraints and limited access to noise-free speech from the target user. If there is an abundance of unlabeled noisy speech from the test-time user, a personalized speech enhancement model can be trained using self-supervised learning. One straightforward approach to model personalization is to use the target speaker's noisy recordings as pseudo-sources. Then, a pseudo denoising model learns to remove injected training noises and recover the pseudo-sources. However, this approach is volatile as it depends on the quality of the pseudo-sources, which may be too noisy. As a remedy, we propose an improvement to the self-supervised approach through data purification. We first train an SNR predictor model to estimate the frame-by-frame SNR of the pseudo-sources. Then, the predictor's estimates are converted into weights which adjust the frame-by-frame contribution of the pseudo-sources towards training the personalized model. We empirically show that the proposed data purification step improves the usability of the speaker-specific noisy data in the context of personalized speech enhancement. Without relying on any clean speech recordings or speaker embeddings, our approach may be seen as privacy-preserving.      
### 11.Self-Supervised Learning for Personalized Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.02017.pdf)
>  Speech enhancement systems can show improved performance by adapting the model towards a single test-time speaker. In this personalization context, the test-time user might only provide a small amount of noise-free speech data, likely insufficient for traditional fully-supervised learning. One way to overcome the lack of personal data is to transfer the model parameters from a speaker-agnostic model to initialize the personalized model, and then to finetune the model using the small amount of personal speech data. This baseline marginally adapts over the scarce clean speech data. Alternatively, we propose self-supervised methods that are designed specifically to learn personalized and discriminative features from abundant in-the-wild noisy, but still personal speech recordings. Our experiment shows that the proposed self-supervised learning methods initialize personalized speech enhancement models better than the baseline fully-supervised methods, yielding superior speech enhancement performance. The proposed methods also result in a more robust feature set under the real-world conditions: compressed model sizes and fewness of the labeled data.      
### 12.Graph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids  [ :arrow_down: ](https://arxiv.org/pdf/2104.02012.pdf)
>  False data injection attacks (FDIAs) represent a major class of attacks that aim to break the integrity of measurements by injecting false data into the smart metering devices in power grid. To the best of authors' knowledge, no study has attempted to design a detector that automatically models the underlying graph topology and spatially correlated measurement data of the smart grids to better detect cyber attacks. The contributions of this paper to detect and mitigate FDIAs are twofold. First, we present a generic, localized, and stealth (unobservable) attack generation methodology and a publicly accessible dataset for researchers to develop and test their algorithms. Second, we propose a Graph Neural Network (GNN) based, scalable and real-time detector of FDIAs that efficiently combines model-driven and data-driven approaches by incorporating the inherent physical connections of modern AC power grids and exploiting the spatial correlations of the measurement data. It is experimentally verified by comparing the proposed GNN based detector with the currently available FDIA detectors in literature that our algorithm outperforms the best available solutions by 6.21\%, 0.69\%, and 2.73\% in detection rate and by 3.65\%, 0.34\% and 1.38\% in F1 score for standard IEEE testbeds with 14, 118, and 300 buses, respectively.      
### 13.Using spatial-temporal ensembles of convolutional neural networks for lumen segmentation in ureteroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2104.01985.pdf)
>  Purpose: Ureteroscopy is an efficient endoscopic minimally invasive technique for the diagnosis and treatment of upper tract urothelial carcinoma (UTUC). During ureteroscopy, the automatic segmentation of the hollow lumen is of primary importance, since it indicates the path that the endoscope should follow. In order to obtain an accurate segmentation of the hollow lumen, this paper presents an automatic method based on Convolutional Neural Networks (CNNs). <br>Methods: The proposed method is based on an ensemble of 4 parallel CNNs to simultaneously process single and multi-frame information. Of these, two architectures are taken as core-models, namely U-Net based in residual blocks($m_1$) and Mask-RCNN($m_2$), which are fed with single still-frames $I(t)$. The other two models ($M_1$, $M_2$) are modifications of the former ones consisting on the addition of a stage which makes use of 3D Convolutions to process temporal information. $M_1$, $M_2$ are fed with triplets of frames ($I(t-1)$, $I(t)$, $I(t+1)$) to produce the segmentation for $I(t)$. <br>Results: The proposed method was evaluated using a custom dataset of 11 videos (2,673 frames) which were collected and manually annotated from 6 patients. We obtain a Dice similarity coefficient of 0.80, outperforming previous state-of-the-art methods. <br>Conclusion: The obtained results show that spatial-temporal information can be effectively exploited by the ensemble model to improve hollow lumen segmentation in ureteroscopic images. The method is effective also in presence of poor visibility, occasional bleeding, or specular reflections.      
### 14.Cascaded Robust Learning at Imperfect Labels for Chest X-ray Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.01975.pdf)
>  The superior performance of CNN on medical image analysis heavily depends on the annotation quality, such as the number of labeled image, the source of image, and the expert experience. The annotation requires great expertise and labour. To deal with the high inter-rater variability, the study of imperfect label has great significance in medical image segmentation tasks. In this paper, we present a novel cascaded robust learning framework for chest X-ray segmentation with imperfect annotation. Our model consists of three independent network, which can effectively learn useful information from the peer networks. The framework includes two stages. In the first stage, we select the clean annotated samples via a model committee setting, the networks are trained by minimizing a segmentation loss using the selected clean samples. In the second stage, we design a joint optimization framework with label correction to gradually correct the wrong annotation and improve the network performance. We conduct experiments on the public chest X-ray image datasets collected by Shenzhen Hospital. The results show that our methods could achieve a significant improvement on the accuracy in segmentation tasks compared to the previous methods.      
### 15.Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem  [ :arrow_down: ](https://arxiv.org/pdf/2104.01954.pdf)
>  We recently proposed DOVER-Lap, a method for combining overlap-aware speaker diarization system outputs. DOVER-Lap improved upon its predecessor DOVER by using a label mapping method based on globally-informed greedy search. In this paper, we analyze this label mapping in the framework of a maximum orthogonal graph partitioning problem, and present three inferences. First, we show that DOVER-Lap label mapping is exponential in the input size, which poses a challenge when combining a large number of hypotheses. We then revisit the DOVER label mapping algorithm and propose a modification which performs similar to DOVER-Lap while being computationally tractable. We also derive an approximation bound for the algorithm in terms of the maximum number of hypotheses speakers. Finally, we describe a randomized local search algorithm which provides a near-optimal $(1-\epsilon)$-approximate solution to the problem with high probability. We empirically demonstrate the effectiveness of our methods on the AMI meeting corpus. Our code is publicly available: <a class="link-external link-https" href="https://github.com/desh2608/dover-lap" rel="external noopener nofollow">this https URL</a>.      
### 16.A Minimum-Footprint Implementation of Discrete-Time ADRC  [ :arrow_down: ](https://arxiv.org/pdf/2104.01943.pdf)
>  To foster the adoption of active disturbance rejection control (ADRC) and support its deployment even on low-cost embedded systems, this article introduces the most efficient implementation of linear discrete-time ADRC to date. While maintaining all features and the exact performance characteristics of the state-space form, computational efforts and storage requirements are reduced to a minimum compared to all existing implementations. This opens up new possibilities to use ADRC in applications with high sample rates, tight timing constraints, or low computational power.      
### 17.Real-time Streaming Wave-U-Net with Temporal Convolutions for Multichannel Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.01923.pdf)
>  In this paper, we describe the work that we have done to participate in Task1 of the ConferencingSpeech2021 challenge. This task set a goal to develop the solution for multi-channel speech enhancement in a real-time manner. We propose a novel system for streaming speech enhancement. We employ Wave-U-Net architecture with temporal convolutions in encoder and decoder. We incorporate self-attention in the decoder to apply attention mask retrieved from skip-connection on features from down-blocks. We explore history cache mechanisms that work like hidden states in recurrent networks and implemented them in proposal solution. It helps us to run an inference with chunks length 40ms and Real-Time Factor 0.4 with the same precision.      
### 18.Cross-Validated Tuning of Shrinkage Factors for MVDR Beamforming Based on Regularized Covariance Matrix Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2104.01909.pdf)
>  This paper considers the regularized estimation of covariance matrices (CM) of high-dimensional (compound) Gaussian data for minimum variance distortionless response (MVDR) beamforming. Linear shrinkage is applied to improve the accuracy and condition number of the CM estimate for low-sample-support cases. We focus on data-driven techniques that automatically choose the linear shrinkage factors for shrinkage sample covariance matrix ($\text{S}^2$CM) and shrinkage Tyler's estimator (STE) by exploiting cross validation (CV). We propose leave-one-out cross-validation (LOOCV) choices for the shrinkage factors to optimize the beamforming performance, referred to as $\text{S}^2$CM-CV and STE-CV. The (weighted) out-of-sample output power of the beamfomer is chosen as a proxy of the beamformer performance and concise expressions of the LOOCV cost function are derived to allow fast optimization. For the large system regime, asymptotic approximations of the LOOCV cost functions are derived, yielding the $\text{S}^2$CM-AE and STE-AE. In general, the proposed algorithms are able to achieve near-oracle performance in choosing the linear shrinkage factors for MVDR beamforming. Simulation results are provided for validating the proposed methods.      
### 19.Global Guidance Network for Breast Lesion Segmentation in Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.01896.pdf)
>  Automatic breast lesion segmentation in ultrasound helps to diagnose breast cancer, which is one of the dreadful diseases that affect women globally. Segmenting breast regions accurately from ultrasound image is a challenging task due to the inherent speckle artifacts, blurry breast lesion boundaries, and inhomogeneous intensity distributions inside the breast lesion regions. Recently, convolutional neural networks (CNNs) have demonstrated remarkable results in medical image segmentation tasks. However, the convolutional operations in a CNN often focus on local regions, which suffer from limited capabilities in capturing long-range dependencies of the input ultrasound image, resulting in degraded breast lesion segmentation accuracy. In this paper, we develop a deep convolutional neural network equipped with a global guidance block (GGB) and breast lesion boundary detection (BD) modules for boosting the breast ultrasound lesion segmentation. The GGB utilizes the multi-layer integrated feature map as a guidance information to learn the long-range non-local dependencies from both spatial and channel domains. The BD modules learn additional breast lesion boundary map to enhance the boundary quality of a segmentation result refinement. Experimental results on a public dataset and a collected dataset show that our network outperforms other medical image segmentation methods and the recent semantic segmentation methods on breast ultrasound lesion segmentation. Moreover, we also show the application of our network on the ultrasound prostate segmentation, in which our method better identifies prostate regions than state-of-the-art networks.      
### 20.Adaptive Gradient Balancing for UndersampledMRI Reconstruction and Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2104.01889.pdf)
>  Recent accelerated MRI reconstruction models have used Deep Neural Networks (DNNs) to reconstruct relatively high-quality images from highly undersampled k-space data, enabling much faster MRI scanning. However, these techniques sometimes struggle to reconstruct sharp images that preserve fine detail while maintaining a natural appearance. In this work, we enhance the image quality by using a Conditional Wasserstein Generative Adversarial Network combined with a novel Adaptive Gradient Balancing (AGB) technique that automates the process of combining the adversarial and pixel-wise terms and streamlines hyperparameter tuning. In addition, we introduce a Densely Connected Iterative Network, which is an undersampled MRI reconstruction network that utilizes dense connections. In MRI, our method minimizes artifacts, while maintaining a high-quality reconstruction that produces sharper images than other techniques. To demonstrate the general nature of our method, it is further evaluated on a battery of image-to-image translation experiments, demonstrating an ability to recover from sub-optimal weighting in multi-term adversarial training.      
### 21.Nodal Frequency Performance of Power Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.01884.pdf)
>  This paper investigates how a disturbance in the power network affects the nodal frequencies of certain network buses. To begin with, we show that the inertia of a single generator is in inverse proportion to the initial rate of change of frequency (RoCoF) under disturbances. Then, we present how the initial RoCoF of the nodal frequencies are related to the inertia constants of multiple generators in a power network, which leads to a performance metric to analyze nodal frequency performance. To be specific, the proposed metric evaluates the impact of disturbances on the nodal frequency performance. The validity and effectiveness of the proposed metric are illustrated via simulations on a multi-machine power system.      
### 22.Speaker diarization assisted ASR for multi-speaker conversations  [ :arrow_down: ](https://arxiv.org/pdf/2104.01882.pdf)
>  In this paper, we propose a novel approach for the transcription of speech conversations with natural speaker overlap, from single channel recordings. We propose a combination of a speaker diarization system and a hybrid automatic speech recognition (ASR) system with speaker activity assisted acoustic model (AM). An end-to-end neural network system is used for speaker diarization. Two architectures, (i) input conditioned AM, and (ii) gated features AM, are explored to incorporate the speaker activity information. The models output speaker specific senones. The experiments on Switchboard telephone conversations show the advantage of incorporating speaker activity information in the ASR system for recordings with overlapped speech. In particular, an absolute improvement of $11\%$ in word error rate (WER) is seen for the proposed approach on natural conversation speech with automatic diarization.      
### 23.Integrating 2D and 3D Digital Plant Information Towards Automatic Generation of Digital Twins  [ :arrow_down: ](https://arxiv.org/pdf/2104.01854.pdf)
>  Ongoing standardization in Industry 4.0 supports tool vendor neutral representations of Piping and Instrumentation diagrams as well as 3D pipe routing. However, a complete digital plant model requires combining these two representations. 3D pipe routing information is essential for building any accurate first-principles process simulation model. Piping and instrumentation diagrams are the primary source for control loops. In order to automatically integrate these information sources to a unified digital plant model, it is necessary to develop algorithms for identifying corresponding elements such as tanks and pumps from piping and instrumentation diagrams and 3D CAD models. One approach is to raise these two information sources to a common level of abstraction and to match them at this level of abstraction. Graph matching is a potential technique for this purpose. This article focuses on automatic generation of the graphs as a prerequisite to graph matching. Algorithms for this purpose are proposed and validated with a case study. The paper concludes with a discussion of further research needed to reprocess the generated graphs in order to enable effective matching.      
### 24.A Lossless Intra Reference Block Recompression Scheme for Bandwidth Reduction in HEVC-IBC  [ :arrow_down: ](https://arxiv.org/pdf/2104.01846.pdf)
>  The reference frame memory accesses in inter prediction result in high DRAM bandwidth requirement and power consumption. This problem is more intensive by the adoption of intra block copy (IBC), a new coding tool in the screen content coding (SCC) extension to High Efficiency Video Coding (HEVC). In this paper, we propose a lossless recompression scheme that compresses the reference blocks in intra prediction, i.e., intra block copy, before storing them into DRAM to alleviate this problem. The proposal performs pixel-wise texture analysis with an edge-based adaptive prediction method yet no signaling for direction in bitstreams, thus achieves a high gain for compression. Experimental results demonstrate that the proposed scheme shows a 72% data reduction rate on average, which solves the memory bandwidth problem.      
### 25.Suboptimal multirate MPC for five-level inverters  [ :arrow_down: ](https://arxiv.org/pdf/2104.01844.pdf)
>  The application of multilevel converters to renewable energy systems is a growing topic due to their advantages in energy efficiency. Regarding its control, model predictive control (MPC) has become very appealing due to its natural consideration of discrete inputs, its optimization capability, and the present-day availability of powerful processing hardware. The main drawback of MPC compared to other control techniques in this field is that the control input is held constant during the sampling period, and it is usually difficult or even impossible to reduce this sampling period because of hardware limitations. For this reason, a multirate MPC algorithm is proposed, which allows to change the control input several times within the sampling period. The optimization problem is simplified and made suboptimal to substantially decrease computational burden. This approach is tested in simulation on a three-phase, five-level diode-clamped converter (DCC) operating in inverted mode with a three-phase resistive load. Results show significant reduction in harmonic distortion at the cost of an increase in the number of commutations with respect to a standard MPC operating at the same sampling period.      
### 26.The Multi-speaker Multi-style Voice Cloning Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2104.01818.pdf)
>  The Multi-speaker Multi-style Voice Cloning Challenge (M2VoC) aims to provide a common sizable dataset as well as a fair testbed for the benchmarking of the popular voice cloning task. Specifically, we formulate the challenge to adapt an average TTS model to the stylistic target voice with limited data from target speaker, evaluated by speaker identity and style similarity. The challenge consists of two tracks, namely few-shot track and one-shot track, where the participants are required to clone multiple target voices with 100 and 5 samples respectively. There are also two sub-tracks in each track. For sub-track a, to fairly compare different strategies, the participants are allowed to use only the training data provided by the organizer strictly. For sub-track b, the participants are allowed to use any data publicly available. In this paper, we present a detailed explanation on the tasks and data used in the challenge, followed by a summary of submitted systems and evaluation results.      
### 27.Analysis of bio-electro-chemical signals from passive sweat-based wearable electro-impedance spectroscopy (EIS) towards assessing blood glucose modulations  [ :arrow_down: ](https://arxiv.org/pdf/2104.01793.pdf)
>  There has been a recent tremendous interest in label-free detection of biomarkers which is a critical enabler of point-of-need diagnostics. A low-power, small form factor, multiplexed wearable system is proposed for continuous detection of glucose in passively expressed sweat using electrochemical impedance spectroscopy (EIS) measurement. The wearable EIS system consists of a sensing analog front end integrated with low-volume (1-5 $\mu$L) ultra-sensitive flexible biosensors. A passive sweat sensor was designed to integrate a glucose oxidase electrochemical system on active semiconducting material. The non-faradaic EIS response of the biosensor was used to calibrate the analog front end response using ratiometric Discrete Fourier Transform (DFT) for a shorter measurement time. In this work, a stringent assessment of a continuous glucose sensing platform is performed in a bottom-up approach, going from the biosensor to the system to the interaction with a human subject. The active semiconductor-based biosensors are dosed with glucose concentrations ranging from 5-200 mg/dL and detection is performed using the analog front end. In addition, a detailed analysis of battery life and performance of a wearable EIS system is discussed to define a figure of merit for an optimally integrated design. Moreover, a continuous glucose detection test is performed on a healthy human subject cohort to investigate the stability of the sensor-system mechanism for an 8-hour period, and a time-series-based, auto-regressive (AR) model was created for the system.      
### 28.FocusNetv2: Imbalanced Large and Small Organ Segmentation with Adversarial Shape Constraint for Head and Neck CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.01771.pdf)
>  Radiotherapy is a treatment where radiation is used to eliminate cancer cells. The delineation of organs-at-risk (OARs) is a vital step in radiotherapy treatment planning to avoid damage to healthy organs. For nasopharyngeal cancer, more than 20 OARs are needed to be precisely segmented in advance. The challenge of this task lies in complex anatomical structure, low-contrast organ contours, and the extremely imbalanced size between large and small organs. Common segmentation methods that treat them equally would generally lead to inaccurate small-organ labeling. We propose a novel two-stage deep neural network, FocusNetv2, to solve this challenging problem by automatically locating, ROI-pooling, and segmenting small organs with specifically designed small-organ localization and segmentation sub-networks while maintaining the accuracy of large organ segmentation. In addition to our original FocusNet, we employ a novel adversarial shape constraint on small organs to ensure the consistency between estimated small-organ shapes and organ shape prior knowledge. Our proposed framework is extensively tested on both self-collected dataset of 1,164 CT scans and the MICCAI Head and Neck Auto Segmentation Challenge 2015 dataset, which shows superior performance compared with state-of-the-art head and neck OAR segmentation methods.      
### 29.Opportunistic Screening of Osteoporosis Using Plain Film Chest X-ray  [ :arrow_down: ](https://arxiv.org/pdf/2104.01734.pdf)
>  Osteoporosis is a common chronic metabolic bone disease that is often under-diagnosed and under-treated due to the limited access to bone mineral density (BMD) examinations, Dual-energy X-ray Absorptiometry (DXA). In this paper, we propose a method to predict BMD from Chest X-ray (CXR), one of the most common, accessible, and low-cost medical image examinations. Our method first automatically detects Regions of Interest (ROIs) of local and global bone structures from the CXR. Then a multi-ROI model is developed to exploit both local and global information in the chest X-ray image for accurate BMD estimation. Our method is evaluated on 329 CXR cases with ground truth BMD measured by DXA. The model predicted BMD has a strong correlation with the gold standard DXA BMD (Pearson correlation coefficient 0.840). When applied for osteoporosis screening, it achieves a high classification performance (AUC 0.936). As the first effort in the field to use CXR scans to predict the spine BMD, the proposed algorithm holds strong potential in enabling early osteoporosis screening through routine chest X-rays and contributing to the enhancement of public health.      
### 30.Learning in Centralized Nonlinear Model Predictive Control: Application to an Autonomous Tractor-Trailer System  [ :arrow_down: ](https://arxiv.org/pdf/2104.01728.pdf)
>  One of the most critical tasks in tractor operation is the accurate steering during field operations, e.g., accurate trajectory following during mechanical weeding or spraying, to avoid damaging the crop or planting when there is no crop yet. To automate the trajectory following problem of an autonomous tractor-trailer system and also increase its steering accuracy, a nonlinear model predictive control approach has been proposed in this paper. For the state and parameter estimation, moving horizon estimation has been chosen since it considers the state and the parameter estimation within the same problem and also constraints both on inputs and states can be incorporated. The experimental results show the accuracy and the efficiency of the proposed control scheme in which the mean values of the Euclidean error for the tractor and the trailer, respectively, are 6.44 and 3.61 cm for a straight line trajectory and 49.78 and 41.52 cm for a curved line trajectory.      
### 31.DSRC-Enabled Train Safety Communication System at Unmanned Crossings  [ :arrow_down: ](https://arxiv.org/pdf/2104.01727.pdf)
>  Although wireless technology is available for safety-critical applications, few applications have been used to improve train crossing safety. To prevent potential collisions between trains and vehicles, we present a Dedicated Short-Range Communication (DSRC)-enabled train safety communication system targeting to implement at unmanned crossings. Since our application's purpose is preventing collisions between trains and vehicles, we present a method to calculate the minimum required warning time for head-to-head collision at the train crossing. Furthermore, we define the best- and worst-case scenarios and provide practical measurements at six operating crossings in the U.S. with numerous system configurations such as modulation scheme, transmission power, antenna type, train speed, and vehicle braking distances. From our measurements, we find that the warning application coverage range is independent of the train speed, that the omnidirectional antenna with high transmission power is the best configuration for our system, and that the latency values are mostly less than 5 ms. We use the radio communication coverage to evaluate the time to avoid collision and introduce the safeness level metric. From the measured data, we observe that the DSRC-enabled train safety communication system is feasible for up to 35 mph train speeds which is providing more than 25-30 s time to avoid the collision for 25-65 mph vehicle speeds. Higher train speeds are expected to be safe, but more measurements beyond the 200 m mark with respect to a crossing considered here are needed for a definite conclusion.      
### 32.An Energy-efficient Aerial Backhaul System with Reconfigurable Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2104.01723.pdf)
>  In this paper, we propose a novel wireless architecture, mounted on a high-altitude aerial platform, which is enabled by reconfigurable intelligent surface (RIS). By installing RIS on the aerial platform, rich line-of-sight and full-area coverage can be achieved, thereby, overcoming the limitations of the conventional terrestrial RIS. We consider a scenario where a sudden increase in traffic in an urban area triggers authorities to rapidly deploy unmanned-aerial vehicle base stations (UAV- BSs) to serve the ground users. In this scenario, since the direct backhaul link from the ground source can be blocked due to several obstacles from the urban area, we propose reflecting the backhaul signal using aerial-RIS so that it successfully reaches the UAV-BSs. We jointly optimize the placement and array-partition strategies of aerial-RIS and the phases of RIS elements, which leads to an increase in energy-efficiency of every UAV-BS. We show that the complexity of our algorithm can be bounded by the quadratic order, thus implying high computational efficiency. We verify the performance of the proposed algorithm via extensive numerical evaluations and show that our method achieves an outstanding performance in terms of energy-efficiency compared to benchmark schemes.      
### 33.Citrinet: Closing the Gap between Non-Autoregressive and Autoregressive End-to-End Models for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.01721.pdf)
>  We propose Citrinet - a new end-to-end convolutional Connectionist Temporal Classification (CTC) based automatic speech recognition (ASR) model. Citrinet is deep residual neural model which uses 1D time-channel separable convolutions combined with sub-word encoding and squeeze-and-excitation. The resulting architecture significantly reduces the gap between non-autoregressive and sequence-to-sequence and transducer models. We evaluate Citrinet on LibriSpeech, TED-LIUM2, AISHELL-1 and Multilingual LibriSpeech (MLS) English speech datasets. Citrinet accuracy on these datasets is close to the best autoregressive Transducer models.      
### 34.Identification of Nonlinear Dynamic Systems Using Type-2 Fuzzy Neural Networks -- A Novel Learning Algorithm and a Comparative Study  [ :arrow_down: ](https://arxiv.org/pdf/2104.01713.pdf)
>  In order to achieve faster and more robust convergence (especially under noisy working environments), a sliding mode theory-based learning algorithm has been proposed to tune both the premise and consequent parts of type-2 fuzzy neural networks in this paper. Differently from recent studies, where sliding mode control theory-based rules are proposed for only the consequent part of the network, the developed algorithm applies fully sliding mode parameter update rules for both the premise and consequent parts of the type-2 fuzzy neural networks. In addition, the responsible parameter for sharing the contributions of the lower and upper parts of the type-2 fuzzy membership functions is also tuned. Moreover, the learning rate of the network is updated during the online training. The stability of the proposed learning algorithm has been proved by using an appropriate Lyapunov function. Several comparisons have been realized and shown that the proposed algorithm has faster convergence speed than the existing methods such as gradient-based and swarm intelligence-based methods. Moreover, the proposed learning algorithm has a closed form, and it is easier to implement than the other existing methods.      
### 35.3D Convolutional Neural Networks for Stalled Brain Capillary Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.01687.pdf)
>  Adequate blood supply is critical for normal brain function. Brain vasculature dysfunctions such as stalled blood flow in cerebral capillaries are associated with cognitive decline and pathogenesis in Alzheimer's disease. Recent advances in imaging technology enabled generation of high-quality 3D images that can be used to visualize stalled blood vessels. However, localization of stalled vessels in 3D images is often required as the first step for downstream analysis, which can be tedious, time-consuming and error-prone, when done manually. Here, we describe a deep learning-based approach for automatic detection of stalled capillaries in brain images based on 3D convolutional neural networks. Our networks employed custom 3D data augmentations and were used weight transfer from pre-trained 2D models for initialization. We used an ensemble of several 3D models to produce the winning submission to the Clog Loss: Advance Alzheimer's Research with Stall Catchers machine learning competition that challenged the participants with classifying blood vessels in 3D image stacks as stalled or flowing. In this setting, our approach outperformed other methods and demonstrated state-of-the-art results, achieving 0.85 Matthews correlation coefficient, 85% sensitivity, and 99.3% specificity. The source code for our solution is made publicly available.      
### 36.Development and Modeling of a Low-voltage DC Distribution Nanogrid with Distributed Generation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01686.pdf)
>  The concept of direct current distribution minigrids has been gaining ground in academia and industry regarding the development of distribution grid applications with high penetration of distributed energy sources and storage systems. The adoption of a direct current distribution system facilitates the integration of sources such as photovoltaic and wind generation and storage systems such as batteries, as these technologies in general operate intrinsically in direct current. This work presents the development of a direct current distribution nanogrid (DCDN) installed in the laboratory of the Grupo de Estudos e Desenvolvimento de Alternativas Energeticas (GEDAE), of the Universidade Federal do Para. The developed grid is composed of three photovoltaic generation and storage systems in battery banks and three load banks, distributed over the 200 m grid in a ring topology, with a 24 Vdc bus. Two simulation methodologies were developed and can reproduce the nanogrid operational behavior under static and dynamic conditions, allowing the evaluation of the grid performance over a day of operation. Tests are also presented with measurements at strategic points of the grid to evaluate the system behavior under specific operating conditions, being normal or under contingency. The results attest the nanogrid ability to reliably supply the loads, as long as it respects the limitations of the implemented power generation and storage capacities. In addition, it was found that the characteristics related to the topology of the commercial charge controller that is used to form the DC distribution nanogrid benefits the power quality for the developed grid size and topology.      
### 37.Unsupervised Classification for Polarimetric SAR Data Using Variational Bayesian Wishart Mixture Model with Inverse Gamma-Gamma Prior  [ :arrow_down: ](https://arxiv.org/pdf/2104.01656.pdf)
>  Although various clustering methods have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image clustering tasks, most of the available approaches fail to realize automatic determination of cluster number, nor have they derived an exact distribution for the number of looks. To overcome these limitations and achieve robust unsupervised classification of PolSAR images, this paper proposes the variational Bayesian Wishart mixture model (VBWMM), where variational Bayesian expectation maximization (VBEM) technique is applied to estimate the variational posterior distribution of model parameters iteratively. Besides, covariance matrix similarity and geometric similarity are combined to incorporate spatial information of PolSAR images. Furthermore, we derive a new distribution named inverse gamma-gamma (IGG) prior that originates from the log-likelihood function of proposed model to enable efficient handling of number of looks. As a result, we obtain a closed-form variational lower bound, which can be used to evaluate the convergence of proposed model. We validate the superiority of proposed method in clustering performance on four real-measured datasets and demonstrate significant improvements towards conventional methods. As a by-product, the experiments show that our proposed IGG prior is effective in estimating the number of looks.      
### 38.Perception through 2D-MIMO FMCW Automotive Radar Under Adverse Weather  [ :arrow_down: ](https://arxiv.org/pdf/2104.01639.pdf)
>  Millimeter-wave (mmWave) radars are being increasingly integrated in commercial vehicles to support new Adaptive Driver Assisted Systems (ADAS) features that require accurate location, velocity, and angle estimates of objects, largely independent of environmental conditions. To explore radar-based ADAS applications, we have updated our frequency-modulated continuous wave (FMCW) radar test-bed with Texas Instrument's (TI) 4-chip cascaded radar that forms large 2D MIMO virtual array. In this paper, we develop the necessary received signal models for applying different direction of arrival (DoA) estimation algorithms and experimentally validating their performance under controlled scenarios. To test the robustness of mmWave radars under adverse weather conditions, we collected raw radar data (I-Q samples post demodulated) dataset for various objects by a driven vehicle-mounted platform, specifically for snowy and foggy situations where cameras are largely ineffective. Initial results from radar imaging algorithms to this dataset are presented.      
### 39.A Federated Learning Framework for Non-Intrusive Load Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2104.01618.pdf)
>  Non-intrusive load monitoring (NILM) aims at decomposing the total reading of the household power consumption into appliance-wise ones, which is beneficial for consumer behavior analysis as well as energy conservation. NILM based on deep learning has been a focus of research. To train a better neural network, it is necessary for the network to be fed with massive data containing various appliances and reflecting consumer behavior habits. Therefore, data cooperation among utilities and DNOs (distributed network operators) who own the NILM data has been increasingly significant. During the cooperation, however, risks of consumer privacy leakage and losses of data control rights arise. To deal with the problems above, a framework to improve the performance of NILM with federated learning (FL) has been set up. In the framework, model weights instead of the local data are shared among utilities. The global model is generated by weighted averaging the locally-trained model weights to gather the locally-trained model information. Optimal model selection help choose the model which adapts to the data from different domains best. Experiments show that this proposal improves the performance of local NILM runners. The performance of this framework is close to that of the centrally-trained model obtained by the convergent data without privacy protection.      
### 40.Multi-Feature Semi-Supervised Learning for COVID-19 Diagnosis from Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.01617.pdf)
>  Computed tomography (CT) and chest X-ray (CXR) have been the two dominant imaging modalities deployed for improved management of Coronavirus disease 2019 (COVID-19). Due to faster imaging, less radiation exposure, and being cost-effective CXR is preferred over CT. However, the interpretation of CXR images, compared to CT, is more challenging due to low image resolution and COVID-19 image features being similar to regular pneumonia. Computer-aided diagnosis via deep learning has been investigated to help mitigate these problems and help clinicians during the decision-making process. The requirement for a large amount of labeled data is one of the major problems of deep learning methods when deployed in the medical domain. To provide a solution to this, in this work, we propose a semi-supervised learning (SSL) approach using minimal data for training. We integrate local-phase CXR image features into a multi-feature convolutional neural network architecture where the training of SSL method is obtained with a teacher/student paradigm. Quantitative evaluation is performed on 8,851 normal (healthy), 6,045 pneumonia, and 3,795 COVID-19 CXR scans. By only using 7.06% labeled and 16.48% unlabeled data for training, 5.53% for validation, our method achieves 93.61\% mean accuracy on a large-scale (70.93%) test data. We provide comparison results against fully supervised and SSL methods.      
### 41.Contrast-enhanced MRI Synthesis Using 3D High-Resolution ConvNets  [ :arrow_down: ](https://arxiv.org/pdf/2104.01592.pdf)
>  Gadolinium-based contrast agents (GBCAs) have been widely used to better visualize disease in brain magnetic resonance imaging (MRI). However, gadolinium deposition within the brain and body has raised safety concerns about the use of GBCAs. Therefore, the development of novel approaches that can decrease or even eliminate GBCA exposure while providing similar contrast information would be of significant use clinically. For brain tumor patients, standard-of-care includes repeated MRI with gadolinium-based contrast for disease monitoring, increasing the risk of gadolinium deposition. In this work, we present a deep learning based approach for contrast-enhanced T1 synthesis on brain tumor patients. A 3D high-resolution fully convolutional network (FCN), which maintains high resolution information through processing and aggregates multi-scale information in parallel, is designed to map pre-contrast MRI sequences to contrast-enhanced MRI sequences. Specifically, three pre-contrast MRI sequences, T1, T2 and apparent diffusion coefficient map (ADC), are utilized as inputs and the post-contrast T1 sequences are utilized as target output. To alleviate the data imbalance problem between normal tissues and the tumor regions, we introduce a local loss to improve the contribution of the tumor regions, which leads to better enhancement results on tumors. Extensive quantitative and visual assessments are performed, with our proposed model achieving a PSNR of 28.24dB in the brain and 21.2dB in tumor regions. Our results suggests the potential of substituting GBCAs with synthetic contrast images generated via deep learning.      
### 42.Active Trajectory Estimation for Partially Observed Markov Decision Processes via Conditional Entropy  [ :arrow_down: ](https://arxiv.org/pdf/2104.01545.pdf)
>  In this paper, we consider the problem of controlling a partially observed Markov decision process (POMDP) in order to actively estimate its state trajectory over a fixed horizon with minimal uncertainty. We pose a novel active smoothing problem in which the objective is to directly minimise the smoother entropy, that is, the conditional entropy of the (joint) state trajectory distribution of concern in fixed-interval Bayesian smoothing. Our formulation contrasts with prior active approaches that minimise the sum of conditional entropies of the (marginal) state estimates provided by Bayesian filters. By establishing a novel form of the smoother entropy in terms of the POMDP belief (or information) state, we show that our active smoothing problem can be reformulated as a (fully observed) Markov decision process with a value function that is concave in the belief state. The concavity of the value function is of particular importance since it enables the approximate solution of our active smoothing problem using piecewise-linear function approximations in conjunction with standard POMDP solvers. We illustrate the approximate solution of our active smoothing problem in simulation and compare its performance to alternative approaches based on minimising marginal state estimate uncertainties.      
### 43.Attention Back-end for Automatic Speaker Verification with Multiple Enrollment Utterances  [ :arrow_down: ](https://arxiv.org/pdf/2104.01541.pdf)
>  A back-end model is a key element of modern speaker verification systems. Probabilistic linear discriminant analysis (PLDA) has been widely used as a back-end model in speaker verification. However, it cannot fully make use of multiple utterances from enrollment speakers. In this paper, we propose a novel attention-based back-end model, which can be used for both text-independent (TI) and text-dependent (TD) speaker verification with multiple enrollment utterances, and employ scaled-dot self-attention and feed-forward self-attention networks as architectures that learn the intra-relationships of the enrollment utterances. In order to verify the proposed attention back-end, we combine it with two completely different but dominant speaker encoders, which are time delay neural network (TDNN) and ResNet trained using the additive-margin-based softmax loss and the uniform loss, and compare them with the conventional PLDA or cosine scoring approaches. Experimental results on a multi-genre dataset called CN-Celeb show that the performance of our proposed approach outperforms PLDA scoring with TDNN and cosine scoring with ResNet by around 14.1% and 7.8% in relative EER, respectively. Additionally, an ablation experiment is also reported in this paper for examining the impact of some significant hyper-parameters for the proposed back-end model.      
### 44.TSNAT: Two-Step Non-Autoregressvie Transformer Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.01522.pdf)
>  The autoregressive (AR) models, such as attention-based encoder-decoder models and RNN-Transducer, have achieved great success in speech recognition. They predict the output sequence conditioned on the previous tokens and acoustic encoded states, which is inefficient on GPUs. The non-autoregressive (NAR) models can get rid of the temporal dependency between the output tokens and predict the entire output tokens in at least one step. However, the NAR model still faces two major problems. On the one hand, there is still a great gap in performance between the NAR models and the advanced AR models. On the other hand, it's difficult for most of the NAR models to train and converge. To address these two problems, we propose a new model named the two-step non-autoregressive transformer(TSNAT), which improves the performance and accelerating the convergence of the NAR model by learning prior knowledge from a parameters-sharing AR model. Furthermore, we introduce the two-stage method into the inference process, which improves the model performance greatly. All the experiments are conducted on a public Chinese mandarin dataset ASIEHLL-1. The results show that the TSNAT can achieve a competitive performance with the AR model and outperform many complicated NAR models.      
### 45.Late fusion of machine learning models using passively captured interpersonal social interactions and motion from smartphones predicts decompensation in heart failure  [ :arrow_down: ](https://arxiv.org/pdf/2104.01511.pdf)
>  Objective: Worldwide, heart failure (HF) is a major cause of morbidity and mortality and one of the leading causes of hospitalization. Early detection of HF symptoms and pro-active management may reduce adverse events. Approach: Twenty-eight participants were monitored using a smartphone app after discharge from hospitals, and each clinical event during the enrollment (N=110 clinical events) was recorded. Motion, social, location, and clinical survey data collected via the smartphone-based monitoring system were used to develop and validate an algorithm for predicting or classifying HF decompensation events (hospitalizations or clinic visit) versus clinic monitoring visits in which they were determined to be compensated or stable. Models based on single modality as well as early and late fusion approaches combining patient-reported outcomes and passive smartphone data were evaluated. Results: The highest AUCPr for classifying decompensation with a late fusion approach was 0.80 using leave one subject out cross-validation. Significance: Passively collected data from smartphones, especially when combined with weekly patient-reported outcomes, may reflect behavioral and physiological changes due to HF and thus could enable prediction of HF decompensation.      
### 46.Detection of COVID-19 Disease using Deep Neural Networks with Ultrasound Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2104.01509.pdf)
>  The new coronavirus 2019 (COVID-2019) has rapidly become a pandemic and has had a devastating effect on both everyday life, public health and the global economy. It is critical to detect positive cases as early as possible to prevent the further spread of this epidemic and to treat affected patients quickly. The need for auxiliary diagnostic tools has increased as accurate automated tool kits are not available. This paper presents a work in progress that proposes the analysis of images of lung ultrasound scans using a convolutional neural network. The trained model will be used on a Raspberry Pi to predict on new images.      
### 47.STL Robustness Risk over Discrete-Time Stochastic Processes  [ :arrow_down: ](https://arxiv.org/pdf/2104.01503.pdf)
>  We present a framework to interpret signal temporal logic (STL) formulas over discrete-time stochastic processes in terms of the induced risk. Each realization of a stochastic process either satisfies or violates an STL formula. In fact, we can assign a robustness value to each realization that indicates how robustly this realization satisfies an STL formula. We then define the risk of a stochastic process not satisfying an STL formula robustly, referred to as the "STL robustness risk". In our definition, we permit general classes of risk measures such as, but not limited to, the value-at-risk. While in general hard to compute, we propose an approximation of the STL robustness risk. This approximation has the desirable property of being an upper bound of the STL robustness risk when the chosen risk measure is monotone, a property satisfied by most risk measures. Motivated by the interest in data-driven approaches, we present a sampling-based method for calculating an upper bound of the approximate STL robustness risk for the value-at-risk that holds with high probability. While we consider the case of the value-at-risk, we highlight that such sampling-based methods are viable for other risk measures.      
### 48.Hi-Fi Multi-Speaker English TTS Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2104.01497.pdf)
>  This paper introduces a new multi-speaker English dataset for training text-to-speech models. The dataset is based on public audiobooks from LibriVox and texts from Project Gutenberg. The new dataset contains about 300 hours of speech from 11speakers with at least 16 hours per speaker sampled at 44.1 kHz. To select speech samples with high quality, we considered audio recordings with a signal bandwidth of at least 13 kHz and a signal-to-noise ratio (SNR) of at least 32 dB. The dataset will be released publicly at OpenSLR.      
### 49.Adversarial Joint Training with Self-Attention Mechanism for Robust End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.01471.pdf)
>  Lately, the self-attention mechanism has marked a new milestone in the field of automatic speech recognition (ASR). Nevertheless, its performance is susceptible to environmental intrusions as the system predicts the next output symbol depending on the full input sequence and the previous predictions. Inspired by the extensive applications of the generative adversarial networks (GANs) in speech enhancement and ASR tasks, we propose an adversarial joint training framework with the self-attention mechanism to boost the noise robustness of the ASR system. Generally, it consists of a self-attention speech enhancement GAN and a self-attention end-to-end ASR model. There are two highlights which are worth noting in this proposed framework. One is that it benefits from the advancement of both self-attention mechanism and GANs; while the other is that the discriminator of GAN plays the role of the global discriminant network in the stage of the adversarial joint training, which guides the enhancement front-end to capture more compatible structures for the subsequent ASR module and thereby offsets the limitation of the separate training and handcrafted loss functions. With the adversarial joint optimization, the proposed framework is expected to learn more robust representations suitable for the ASR task. We execute systematic experiments on the corpus AISHELL-1, and the experimental results show that on the artificial noisy test set, the proposed framework achieves the relative improvements of 66% compared to the ASR model trained by clean data solely, 35.1% compared to the speech enhancement &amp; ASR scheme without joint training, and 5.3% compared to multi-condition training.      
### 50.ECAPA-TDNN Embeddings for Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2104.01466.pdf)
>  Learning robust speaker embeddings is a crucial step in speaker diarization. Deep neural networks can accurately capture speaker discriminative characteristics and popular deep embeddings such as x-vectors are nowadays a fundamental component of modern diarization systems. Recently, some improvements over the standard TDNN architecture used for x-vectors have been proposed. The ECAPA-TDNN model, for instance, has shown impressive performance in the speaker verification domain, thanks to a carefully designed neural model. <br>In this work, we extend, for the first time, the use of the ECAPA-TDNN model to speaker diarization. Moreover, we improved its robustness with a powerful augmentation scheme that concatenates several contaminated versions of the same signal within the same training batch. The ECAPA-TDNN model turned out to provide robust speaker embeddings under both close-talking and distant-talking conditions. Our results on the popular AMI meeting corpus show that our system significantly outperforms recently proposed approaches.      
### 51.MR-Contrast-Aware Image-to-Image Translations with Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.01449.pdf)
>  Purpose <br>A Magnetic Resonance Imaging (MRI) exam typically consists of several sequences that yield different image contrasts. Each sequence is parameterized through multiple acquisition parameters that influence image contrast, signal-to-noise ratio, acquisition time, and/or resolution. Depending on the clinical indication, different contrasts are required by the radiologist to make a diagnosis. As MR sequence acquisition is time consuming and acquired images may be corrupted due to motion, a method to synthesize MR images with adjustable contrast properties is required. <br>Methods <br>Therefore, we trained an image-to-image generative adversarial network conditioned on the MR acquisition parameters repetition time and echo time. Our approach is motivated by style transfer networks, whereas the "style" for an image is explicitly given in our case, as it is determined by the MR acquisition parameters our network is conditioned on. <br>Results <br>This enables us to synthesize MR images with adjustable image contrast. We evaluated our approach on the fastMRI dataset, a large set of publicly available MR knee images, and show that our method outperforms a benchmark pix2pix approach in the translation of non-fat-saturated MR images to fat-saturated images. Our approach yields a peak signal-to-noise ratio and structural similarity of 24.48 and 0.66, surpassing the pix2pix benchmark model significantly. <br>Conclusion <br>Our model is the first that enables fine-tuned contrast synthesis, which can be used to synthesize missing MR contrasts or as a data augmentation technique for AI training in MRI.      
### 52.A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents with the Ability to Learn  [ :arrow_down: ](https://arxiv.org/pdf/2104.01445.pdf)
>  Pursuit-evasion games are ubiquitous in nature and in an artificial world. In nature, pursuer(s) and evader(s) are intelligent agents that can learn from experience, and dynamics (i.e., Newtonian or Lagrangian) is vital for the pursuer and the evader in some scenarios. To this end, this paper addresses the pursuit-evasion game of intelligent agents from the perspective of dynamics. A bio-inspired dynamics formulation of a pursuit-evasion game and baseline pursuit and evasion strategies are introduced at first. Then, reinforcement learning techniques are used to mimic the ability of intelligent agents to learn from experience. Based on the dynamics formulation and reinforcement learning techniques, the effects of improving both pursuit and evasion strategies based on experience on pursuit-evasion games are investigated at two levels 1) individual runs and 2) ranges of the parameters of pursuit-evasion games. Results of the investigation are consistent with nature observations and the natural law - survival of the fittest. More importantly, with respect to the result of a pursuit-evasion game of agents with baseline strategies, this study achieves a different result. It is shown that, in a pursuit-evasion game with a dynamics formulation, an evader is not able to escape from a slightly faster pursuer with an effective learned pursuit strategy, based on agile maneuvers and an effective learned evasion strategy.      
### 53.Deep Feature CycleGANs: Speaker Identity Preserving Non-parallel Microphone-Telephone Domain Adaptation for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2104.01433.pdf)
>  With the increase in the availability of speech from varied domains, it is imperative to use such out-of-domain data to improve existing speech systems. Domain adaptation is a prominent pre-processing approach for this. We investigate it for adapt microphone speech to the telephone domain. Specifically, we explore CycleGAN-based unpaired translation of microphone data to improve the x-vector/speaker embedding network for Telephony Speaker Verification. We first demonstrate the efficacy of this on real challenging data and then, to improve further, we modify the CycleGAN formulation to make the adaptation task-specific. We modify CycleGAN's identity loss, cycle-consistency loss, and adversarial loss to operate in the deep feature space. Deep features of a signal are extracted from an auxiliary (speaker embedding) network and, hence, preserves speaker identity. Our 3D convolution-based Deep Feature Discriminators (DFD) show relative improvements of 5-10% in terms of equal error rate. To dive deeper, we study a challenging scenario of pooling (adapted) microphone and telephone data with data augmentations and telephone codecs. Finally, we highlight the sensitivity of CycleGAN hyper-parameters and introduce a parameter called probability of adaptation.      
### 54.Transceiver Noise Characterization based on Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2104.01428.pdf)
>  In this paper, we discuss a new technique for measuring transceiver noise, skew, and for the detection of uncompensated transceiver impairments. The method consists on the introduction of frequency domain notch or notches at the transmitter, which allows to estimate of the Signal-to-Noise and Distortion Ratio (SNDR) at different stages over the transmission chain. The proposed technique requires the detection of the signal spectrum using either: a modem receiver, an Optical Spectrum Analyzer (OSA), an oscilloscope, or an Electrical Spectrum Analyzer (ESA), depending on the stage where the spectrum is measured and requiring minimal processing of the received signal. <br>Our analysis is focused on Ciena's WaveLogic Ai commercial transceiver and a 95 Gbaud DAC. We demonstrate that symmetrically placed frequency domain notches can be used to mitiguate the influence of crosstalk on the SNDR estimates. <br>Finally, we show how a single notch spectrum can be used to detect and compensate for impairments, and we perform skew estimation as an example.      
### 55.Diff-TTS: A Denoising Diffusion Model for Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2104.01409.pdf)
>  Although neural text-to-speech (TTS) models have attracted a lot of attention and succeeded in generating human-like speech, there is still room for improvements to its naturalness and architectural efficiency. In this work, we propose a novel non-autoregressive TTS model, namely Diff-TTS, which achieves highly natural and efficient speech synthesis. Given the text, Diff-TTS exploits a denoising diffusion framework to transform the noise signal into a mel-spectrogram via diffusion time steps. In order to learn the mel-spectrogram distribution conditioned on the text, we present a likelihood-based optimization method for TTS. Furthermore, to boost up the inference speed, we leverage the accelerated sampling method that allows Diff-TTS to generate raw waveforms much faster without significantly degrading perceptual quality. Through experiments, we verified that Diff-TTS generates 28 times faster than the real-time with a single NVIDIA 2080Ti GPU.      
### 56.Sparse Code Multiple Access for 6G Wireless Communication Networks: Recent Advances and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2104.01402.pdf)
>  As 5G networks rolling out in many different countries nowadays, the time has come to investigate how to upgrade and expand them towards 6G, where the latter is expected to realize the interconnection of everything as well as the development of a ubiquitous intelligent mobile world for intelligent life. To enable this epic leap in communications, this article provides an overview and outlook on the application of sparse code multiple access (SCMA) for 6G wireless communication systems, which is an emerging disruptive non-orthogonal multiple access (NOMA) scheme for the enabling of massive connectivity. We propose to apply SCMA to a massively distributed access system (MDAS), whose architecture is based on fiber-based visible light communication (FVLC), ultra-dense network (UDN), and NOMA. Under this framework, we consider the interactions between optical front-hauls and wireless access links. In order to stimulate more upcoming research in this area, we outline a number of promising directions associated with SCMA for faster, more reliable, and more efficient multiple access in future 6G communication networks.      
### 57.A Specification-Guided Framework for Temporal Logic Control of Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01385.pdf)
>  This paper proposes a specification-guided framework for control of nonlinear systems with linear temporal logic (LTL) specifications. In contrast with well-known abstraction-based methods, the proposed framework directly characterizes the winning set, i.e., the set of initial conditions from which a given LTL formula can be realized, over the continuous state space of the system via a monotonic operator. Following this characterization, an algorithm is proposed to practically approximate the operator via an adaptive interval subdivision scheme, which yields a finite-memory control strategy. We show that the proposed algorithm is sound for full LTL specifications, and robustly complete for specifications recognizable by deterministic BÃ¼chi automata (DBA), the latter in the sense that control strategies can be found whenever the given specification can be satisfied with additional bounded disturbances. Without having to compute and store the abstraction and the resulting product system with the DBA, the proposed method is more memory efficient, which is demonstrated by complexity analysis and performance tests. A pre-processing stage is also devised to reduce computational cost via a decomposition of the specification. We show that the proposed method can effectively solve real-world control problems such as jet engine compressor control and motion planning for manipulators and mobile robots.      
### 58.ExKaldi-RT: A Real-Time Automatic Speech Recognition Extension Toolkit of Kaldi  [ :arrow_down: ](https://arxiv.org/pdf/2104.01384.pdf)
>  The availability of open-source software is playing a remarkable role in automatic speech recognition (ASR). Kaldi, for instance, is widely used to develop state-of-the-art offline and online ASR systems. This paper describes the "ExKaldi-RT," online ASR toolkit implemented based on Kaldi and Python language. ExKaldi-RT provides tools for providing a real-time audio stream pipeline, extracting acoustic features, transmitting packets with a remote connection, estimating acoustic probabilities with a neural network, and online decoding. While similar functions are available built on Kaldi, a key feature of ExKaldi-RT is completely working on Python language, which has an easy-to-use interface for online ASR system developers to exploit original research, for example, by applying neural network-based signal processing and acoustic model trained with deep learning frameworks. We performed benchmark experiments on the minimum LibriSpeech corpus, and showed that ExKaldi-RT could achieve competitive ASR performance in real-time.      
### 59.Removing Pixel Noises and Spatial Artifacts with Generative Diversity Denoising Methods  [ :arrow_down: ](https://arxiv.org/pdf/2104.01374.pdf)
>  Image denoising and artefact removal are complex inverse problems admitting many potential solutions. Variational Autoencoders (VAEs) can be used to learn a whole distribution of sensible solutions, from which one can sample efficiently. However, such a generative approach to image restoration is only studied in the context of pixel-wise noise removal (e.g. Poisson or Gaussian noise). While important, a plethora of application domains suffer from imaging artefacts (structured noises) that alter groups of pixels in correlated ways. In this work we show, for the first time, that generative diversity denoising (GDD) approaches can learn to remove structured noises without supervision. To this end, we investigate two existing GDD architectures, introduce a new one based on hierarchical VAEs, and compare their performances against a total of seven state-of-the-art baseline methods on five sources of structured noise (including tomography reconstruction artefacts and microscopy artefacts). We find that GDD methods outperform all unsupervised baselines and in many cases not lagging far behind supervised results (in some occasions even superseding them). In addition to structured noise removal, we also show that our new GDD method produces new state-of-the-art (SOTA) results on seven out of eight benchmark datasets for pixel-noise removal. Finally, we offer insights into the daunting question of how GDD methods distinguish structured noise, which we like to see removed, from image signals, which we want to see retained.      
### 60.Prototype Filters and Filtered Waveforms for Radio Air-Interfaces: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2104.01373.pdf)
>  The perspective for the next generation of wireless communications prognosticates that the communication should take place with high heterogeneity in terms of services and specifications. The emergence of new communication networks, especially between devices like internet of things (IoT) networks, machine type communications (MTC) and unmanned aerial vehicles (UAV), makes the redesign of the radio air-interfaces even higher significant. High data rate, efficient use of the spectrum, low latency, flexibility, scalable ability, energy efficiency and reduced complexity are in the vanguard of the challenging needs. This highlights the necessity to overrides classical waveforms and propose new air interface that best fits these requirements. Several attempts were conducted to propose the most suitable prototype filters and their associated waveforms that support the future applications with these crucial prerequisites. In the present paper, we analyze the most important marked prototype filters reported in literature, and their corresponding waveforms proposed as prominent candidates for wireless air interface. We will show that the filter properties impact the waveform performances and that a close filter-waveform interrelationship is there. The principal contribution is to give a deep insight on the structure of these filters and waveforms and to come up with a fair comparison regarding different criteria and distinct figures of merit.      
### 61.BlinQS: Blind Quality Scalable Image Compression Algorithm without using PCRD Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2104.01361.pdf)
>  Quality Scalability is one of the important features of interactive imaging to obtain better perceptual quality at a specified target bit rate. In JPEG 2000, it is achieved using quality layers obtained by Rate-Distortion (R-D) optimization techniques in Tier-II coding. Some important concerns here are: (i) inefficient conventional Post-Compression Rate-Distortion (PCRD) optimization algorithms, (ii) lack of quality scalability for less or single quality layer string. This paper takes the above mentioned concerns into account and proposes a Blind Quality Scalable (BlinQS) algorithm that provides scalability with the least computational complexity. The novel part of this method is to eliminate the Tier-II coding and add a blind string selection algorithm through a normal distribution for efficient rate control. The results obtained suggest that the proposed method achieves better results than JPEG-2000 at single quality layer and achieves results close to JPEG-2000 without using PCRD optimization algorithms.      
### 62.On the Dynamism of User Rejections in Mobility-on-Demand Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01326.pdf)
>  Mobility-on-demand (MoD) systems, especially ride-hailing systems, have seen tremendous growth in recent years. These systems provide user-centric mobility services, whose users expect a high level of convenience. Waiting for a response after an app request and eventually learning after a long period of time that no vehicle is available is hardly acceptable. This study investigates the use-case where users should be served within a certain maximum waiting time. Under certain assumptions, which are reasonable for an attractive MoD business model, it can be shown that an operator using dynamic state optimization can communicate a rejection to users after the first iteration, thereby eliminating unnecessary waiting time before these users would leave the system. Furthermore, early operator rejections reduce the dimension of subsequent customer-vehicle assignment problems, thereby saving computational resources and solving the problems faster. In turn, this allows shorter re-optimization cycles and once again faster responses, i.e. a better user experience.      
### 63.An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01320.pdf)
>  Spoofing countermeasure (CM) systems are critical in speaker verification; they aim to discern spoofing attacks from bona fide speech trials. In practice, however, acoustic condition variability in speech utterances may significantly degrade the performance of CM systems. In this paper, we conduct a cross-dataset study on several state-of-the-art CM systems and observe significant performance degradation compared with their single-dataset performance. Observing differences of average magnitude spectra of bona fide utterances across the datasets, we hypothesize that channel mismatch among these datasets is one important reason. We then verify it by demonstrating a similar degradation of CM systems trained on original but evaluated on channel-shifted data. Finally, we propose several channel robust strategies (data augmentation, multi-task learning, adversarial learning) for CM systems, and observe a significant performance improvement on cross-dataset experiments.      
### 64.Extraction of instantaneous frequencies and amplitudes in nonstationary time-series data  [ :arrow_down: ](https://arxiv.org/pdf/2104.01293.pdf)
>  Time-series analysis is critical for a diversity of applications in science and engineering. By leveraging the strengths of modern gradient descent algorithms, the Fourier transform, multi-resolution analysis, and Bayesian spectral analysis, we propose a data-driven approach to time-frequency analysis that circumvents many of the shortcomings of classic approaches, including the extraction of nonstationary signals with discontinuities in their behavior. The method introduced is equivalent to a {\em nonstationary Fourier mode decomposition} (NFMD) for nonstationary and nonlinear temporal signals, allowing for the accurate identification of instantaneous frequencies and their amplitudes. The method is demonstrated on a diversity of time-series data, including on data from cantilever-based electrostatic force microscopy to quantify the time-dependent evolution of charging dynamics at the nanoscale.      
### 65.A GPU Implementation of a Look-Ahead Optimal Controller for Eco-Driving Based on Dynamic Programming  [ :arrow_down: ](https://arxiv.org/pdf/2104.01284.pdf)
>  Predictive energy management of Connected and Automated Vehicles (CAVs), in particular those with multiple power sources, has the potential to significantly improve energy savings in real-world driving conditions. In particular, the eco-driving problem seeks to design optimal speed and power usage profiles based upon available information from connectivity and advanced mapping features to minimize the fuel consumption between two designated locations. <br>In this work, the eco-driving problem is formulated as a three-state receding horizon optimal control problem and solved via Dynamic Programming (DP). The optimal solution, in terms of vehicle speed and battery State of Charge (SoC) trajectories, allows a connected and automated hybrid electric vehicle to intelligently pass the signalized intersections and minimize fuel consumption over a prescribed route. To enable real-time implementation, a parallel architecture of DP is proposed for an NVIDIA GPU with CUDA programming. Simulation results indicate that the proposed optimal controller delivers more than 15% fuel economy benefits compared to a baseline control strategy and that the solver time can be reduced by more than 90% by the parallel implementation when compared to a serial implementation.      
### 66.Multi-class motion-based semantic segmentation for ureteroscopy and laser lithotripsy  [ :arrow_down: ](https://arxiv.org/pdf/2104.01268.pdf)
>  Kidney stones represent a considerable burden for public health-care systems. Ureteroscopy with laser lithotripsy has evolved as the most commonly used technique for the treatment of kidney stones. Automated segmentation of kidney stones and laser fiber is an important initial step to performing any automated quantitative analysis of the stones, particularly stone-size estimation, that helps the surgeon decide if the stone requires more fragmentation. Factors such as turbid fluid inside the cavity, specularities, motion blur due to kidney movements and camera motion, bleeding, and stone debris impact the quality of vision within the kidney and lead to extended operative times. To the best of our knowledge, this is the first attempt made towards multi-class segmentation in ureteroscopy and laser lithotripsy data. We propose an end-to-end CNN-based framework for the segmentation of stones and laser fiber. The proposed approach utilizes two sub-networks: HybResUNet, a version of residual U-Net, that uses residual connections in the encoder path of U-Net and a DVFNet that generates DVF predictions which are then used to prune the prediction maps. We also present ablation studies that combine dilated convolutions, recurrent and residual connections, ASPP and attention gate. We propose a compound loss function that improves our segmentation performance. We have also provided an ablation study to determine the optimal data augmentation strategy. Our qualitative and quantitative results illustrate that our proposed method outperforms SOTA methods such as UNet and DeepLabv3+ showing an improvement of 5.2% and 15.93%, respectively, for the combined mean of DSC and JI in our invivo test dataset. We also show that our proposed model generalizes better on a new clinical dataset showing a mean improvement of 25.4%, 20%, and 11% over UNet, HybResUNet, and DeepLabv3+, respectively, for the same metric.      
### 67.MetricNet: Towards Improved Modeling For Non-Intrusive Speech Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2104.01227.pdf)
>  The objective speech quality assessment is usually conducted by comparing received speech signal with its clean reference, while human beings are capable of evaluating the speech quality without any reference, such as in the mean opinion score (MOS) tests. Non-intrusive speech quality assessment has attracted much attention recently due to the lack of access to clean reference signals for objective evaluations in real scenarios. In this paper, we propose a novel non-intrusive speech quality measurement model, MetricNet, which leverages label distribution learning and joint speech reconstruction learning to achieve significantly improved performance compared to the existing non-intrusive speech quality measurement models. We demonstrate that the proposed approach yields promisingly high correlation to the intrusive objective evaluation of speech quality on clean, noisy and processed speech data.      
### 68.Scan Specific Artifact Reduction in K-space (SPARK) Neural Networks Synergize with Physics-based Reconstruction to Accelerate MRI  [ :arrow_down: ](https://arxiv.org/pdf/2104.01188.pdf)
>  Purpose: To develop a scan-specific model that estimates and corrects k-space errors made when reconstructing accelerated Magnetic Resonance Imaging (MRI) data. <br>Methods: Scan-Specific Artifact Reduction in k-space (SPARK) trains a convolutional neural network to estimate k-space errors made by an input reconstruction technique by back-propagating from the mean-squared-error loss between an auto-calibration signal (ACS) and the input technique's reconstructed ACS. First, SPARK is applied to GRAPPA and demonstrates improved robustness over other scan-specific models. Then, SPARK is shown to synergize with advanced reconstruction techniques by improving image quality when applied to 2D virtual coil (VC-) GRAPPA, 2D LORAKS, 3D GRAPPA without an integrated ACS region, and 2D/3D wave-encoded imaging. <br>Results: SPARK yields 1.5 - 2x RMSE reduction when applied to GRAPPA and improves robustness to ACS size for various acceleration rates in comparison to other scan-specific techniques. When applied to advanced parallel imaging techniques such as 2D VC-GRAPPA and LORAKS, SPARK achieves up to 20% RMSE improvement. SPARK with 3D GRAPPA also improves RMSE performance and perceived image quality without a fully sampled ACS region. Finally, SPARK synergizes with non-cartesian, 2D and 3D wave-encoding imaging by reducing RMSE between 20 - 25% and providing qualitative improvements. <br>Conclusion: SPARK synergizes with physics-based reconstruction techniques to improve accelerated MRI by training scan-specific models to estimate and correct reconstruction errors in k-space.      
### 69.Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation  [ :arrow_down: ](https://arxiv.org/pdf/2104.02026.pdf)
>  There are rich synchronized audio and visual events in our daily life. Inside the events, audio scenes are associated with the corresponding visual objects; meanwhile, sounding objects can indicate and help to separate their individual sounds in the audio track. Based on this observation, in this paper, we propose a cyclic co-learning (CCoL) paradigm that can jointly learn sounding object visual grounding and audio-visual sound separation in a unified framework. Concretely, we can leverage grounded object-sound relations to improve the results of sound separation. Meanwhile, benefiting from discriminative information from separated sounds, we improve training example sampling for sounding object grounding, which builds a co-learning cycle for the two tasks and makes them mutually beneficial. Extensive experiments show that the proposed framework outperforms the compared recent approaches on both tasks, and they can benefit from each other with our cyclic co-learning.      
### 70.SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.02014.pdf)
>  In the English speech-to-text (STT) machine learning task, acoustic models are conventionally trained on uncased Latin characters, and any necessary orthography (such as capitalization, punctuation, and denormalization of non-standard words) is imputed by separate post-processing models. This adds complexity and limits performance, as many formatting tasks benefit from semantic information present in the acoustic signal but absent in transcription. Here we propose a new STT task: end-to-end neural transcription with fully formatted text for target labels. We present baseline Conformer-based models trained on a corpus of 5,000 hours of professionally transcribed earnings calls, achieving a CER of 1.7. As a contribution to the STT research community, we release the corpus free for non-commercial use (\url{<a class="link-external link-https" href="https://datasets.kensho.com/datasets/scribe" rel="external noopener nofollow">this https URL</a>}).      
### 71.Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.02005.pdf)
>  Recently, sound-based COVID-19 detection studies have shown great promise to achieve scalable and prompt digital pre-screening. However, there are still two unsolved issues hindering the practice. First, collected datasets for model training are often imbalanced, with a considerably smaller proportion of users tested positive, making it harder to learn representative and robust features. Second, deep learning models are generally overconfident in their predictions. Clinically, false predictions aggravate healthcare costs. Estimation of the uncertainty of screening would aid this. To handle these issues, we propose an ensemble framework where multiple deep learning models for sound-based COVID-19 detection are developed from different but balanced subsets from original data. As such, data are utilized more effectively compared to traditional up-sampling and down-sampling approaches: an AUC of 0.74 with a sensitivity of 0.68 and a specificity of 0.69 is achieved. Simultaneously, we estimate uncertainty from the disagreement across multiple models. It is shown that false predictions often yield higher uncertainty, enabling us to suggest the users with certainty higher than a threshold to repeat the audio test on their phones or to take clinical tests if digital diagnosis still fails. This study paves the way for a more robust sound-based COVID-19 automated screening system.      
### 72.Can audio-visual integration strengthen robustness under multimodal attacks?  [ :arrow_down: ](https://arxiv.org/pdf/2104.02000.pdf)
>  In this paper, we propose to make a systematic study on machines multisensory perception under attacks. We use the audio-visual event recognition task against multimodal adversarial attacks as a proxy to investigate the robustness of audio-visual learning. We attack audio, visual, and both modalities to explore whether audio-visual integration still strengthens perception and how different fusion mechanisms affect the robustness of audio-visual models. For interpreting the multimodal interactions under attacks, we learn a weakly-supervised sound source visual localization model to localize sounding regions in videos. To mitigate multimodal attacks, we propose an audio-visual defense approach based on an audio-visual dissimilarity constraint and external feature memory banks. Extensive experiments demonstrate that audio-visual models are susceptible to multimodal adversarial attacks; audio-visual integration could decrease the model robustness rather than strengthen under multimodal attacks; even a weakly-supervised sound source visual localization model can be successfully fooled; our defense method can improve the invulnerability of audio-visual networks without significantly sacrificing clean model performance.      
### 73.Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.01978.pdf)
>  Key challenges in developing generalized automatic emotion recognition systems include scarcity of labeled data and lack of gold-standard references. Even for the cues that are labeled as the same emotion category, the variability of associated expressions can be high depending on the elicitation context e.g., emotion elicited during improvised conversations vs. acted sessions with predefined scripts. In this work, we regard the emotion elicitation approach as domain knowledge, and explore domain transfer learning techniques on emotional utterances collected under different emotion elicitation approaches, particularly with limited labeled target samples. Our emotion recognition model combines the gradient reversal technique with an entropy loss function as well as the softlabel loss, and the experiment results show that domain transfer learning methods can be employed to alleviate the domain mismatch between different elicitation approaches. Our work provides new insights into emotion data collection, particularly the impact of its elicitation strategies, and the importance of domain adaptation in emotion recognition aiming for generalized systems.      
### 74.Self-Healing First-Order Distributed Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2104.01959.pdf)
>  In this paper we describe a parameterized family of first-order distributed optimization algorithms that enable a network of agents to collaboratively calculate a decision variable that minimizes the sum of cost functions at each agent. These algorithms are self-healing in that their correctness is guaranteed even if they are initialized randomly, agents drop in or out of the network, local cost functions change, or communication packets are dropped. Our algorithms are the first single-Laplacian methods to exhibit all of these characteristics. We achieve self-healing by sacrificing internal stability, a fundamental trade-off for single-Laplacian methods.      
### 75.A Generalized Unscented Transformation for Probability Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2104.01958.pdf)
>  The unscented transform uses a weighted set of samples called sigma points to propagate the means and covariances of nonlinear transformations of random variables. However, unscented transforms developed using either the Gaussian assumption or a minimum set of sigma points typically fall short when the random variable is not Gaussian distributed and the nonlinearities are substantial. In this paper, we develop the generalized unscented transform (GenUT), which uses adaptable sigma points that can be positively constrained, and accurately approximates the mean, covariance, and skewness of an independent random vector of most probability distributions, while being able to partially approximate the kurtosis. For correlated random vectors, the GenUT can accurately approximate the mean and covariance. In addition to its superior accuracy in propagating means and covariances, the GenUT uses the same order of calculations as most unscented transforms that guarantee third-order accuracy, which makes it applicable to a wide variety of applications, including the assimilation of observations in the modeling of the coronavirus (SARS-CoV-2) causing COVID-19.      
### 76.An Artificial Intelligence Framework for Bidding Optimization with Uncertainty inMultiple Frequency Reserve Markets  [ :arrow_down: ](https://arxiv.org/pdf/2104.01865.pdf)
>  The global ambitions of a carbon-neutral society necessitate a stable and robust smart grid that capitalises on frequency reserves of renewable energy. Frequency reserves are resources that adjust power production or consumption in real time to react to a power grid frequency deviation. Revenue generation motivates the availability of these resources for managing such deviations. However, limited research has been conducted on data-driven decisions and optimal bidding strategies for trading such capacities in multiple frequency reserves markets. We address this limitation by making the following research contributions. Firstly, a generalised model is designed based on an extensive study of critical characteristics of global frequency reserves markets. Secondly, three bidding strategies are proposed, based on this market model, to capitalise on price peaks in multi-stage markets. Two strategies are proposed for non-reschedulable loads, in which case the bidding strategy aims to select the market with the highest anticipated price, and the third bidding strategy focuses on rescheduling loads to hours on which highest reserve market prices are anticipated. The third research contribution is an Artificial Intelligence (AI) based bidding optimization framework that implements these three strategies, with novel uncertainty metrics that supplement data-driven price prediction. Finally, the framework is evaluated empirically using a case study of multiple frequency reserves markets in Finland. The results from this evaluation confirm the effectiveness of the proposed bidding strategies and the AI-based bidding optimization framework in terms of cumulative revenue generation, leading to an increased availability of frequency reserves.      
### 77.Fast Channel Estimation in the Transformed Spatial Domain for Analog Millimeter Wave Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01857.pdf)
>  Fast channel estimation in millimeter-wave (mmWave) systems is a fundamental enabler of high-gain beamforming, which boosts coverage and capacity. The channel estimation stage typically involves an initial beam training process where a subset of the possible beam directions at the transmitter and receiver is scanned along a predefined codebook. Unfortunately, the high number of transmit and receive antennas deployed in mmWave systems increase the complexity of the beam selection and channel estimation tasks. In this work, we tackle the channel estimation problem in analog systems from a different perspective than used by previous works. In particular, we propose to move the channel estimation problem from the angular domain into the transformed spatial domain, in which estimating the angles of arrivals and departures corresponds to estimating the angular frequencies of paths constituting the mmWave channel. The proposed approach, referred to as transformed spatial domain channel estimation (TSDCE) algorithm, exhibits robustness to additive white Gaussian noise by combining low-rank approximations and sample autocorrelation functions for each path in the transformed spatial domain. Numerical results evaluate the mean square error of the channel estimation and the direction of arrival estimation capability. TSDCE significantly reduces the first, while exhibiting a remarkably low computational complexity compared with well-known benchmarking schemes.      
### 78.Actuator Placement for Structural Controllability beyond Strong Connectivity and towards Robustness  [ :arrow_down: ](https://arxiv.org/pdf/2104.01850.pdf)
>  Actuator placement is a fundamental problem in control design for large-scale networks. In this paper, we study the problem of finding a set of actuator positions by minimizing a given metric, while satisfying a structural controllability requirement and a constraint on the number of actuators. We first extend the classical forward greedy algorithm for applications to graphs that are not necessarily strongly connected. We then improve this greedy algorithm by extending its horizon. This is done by evaluating the actuator position set expansions at the further steps of the classical greedy algorithm. We prove that this new method attains a better performance, when this evaluation considers the final actuator position set. Moreover, we study the problem of minimal backup placements. The goal is to ensure that the system stays structurally controllable even when any of the selected actuators goes offline, with minimum number of backup actuators. We show that this problem is equivalent to the well-studied NP-hard hitting set problem. Our results are verified by a numerical case study.      
### 79.Fault-tolerant Control of Robot Manipulators with Sensory Faults using Unbiased Active Inference  [ :arrow_down: ](https://arxiv.org/pdf/2104.01817.pdf)
>  This work presents a novel fault-tolerant control scheme based on active inference. Specifically, a new formulation of active inference which, unlike previous solutions, provides unbiased state estimation and simplifies the definition of probabilistically robust thresholds for fault-tolerant control of robotic systems using the free-energy. The proposed solution makes use of the sensory prediction errors in the free-energy for the generation of residuals and thresholds for fault detection and isolation of sensory faults, and it does not require additional controllers for fault recovery. Results validating the benefits in a simulated 2-DOF manipulator are presented, and future directions to improve the current fault recovery approach are discussed.      
### 80.StarGAN-based Emotional Voice Conversion for Japanese Phrases  [ :arrow_down: ](https://arxiv.org/pdf/2104.01807.pdf)
>  This paper shows that StarGAN-VC, a spectral envelope transformation method for non-parallel many-to-many voice conversion (VC), is capable of emotional VC (EVC). Although StarGAN-VC has been shown to enable speaker identity conversion, its capability for EVC for Japanese phrases has not been clarified. In this paper, we describe the direct application of StarGAN-VC to an EVC task with minimal fundamental frequency and aperiodicity processing. Through subjective evaluation experiments, we evaluated the performance of our StarGAN-EVC system in terms of its ability to achieve EVC for Japanese phrases. The subjective evaluation is conducted in terms of subjective classification and mean opinion score of neutrality and similarity. In addition, the interdependence between the source and target emotional domains was investigated from the perspective of the quality of EVC.      
### 81.Federated Learning Meets Blockchain in Edge Computing: Opportunities and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2104.01776.pdf)
>  Mobile edge computing (MEC) has been envisioned as a promising paradigm to handle the massive volume of data generated from ubiquitous mobile devices for enabling intelligent services with the help of artificial intelligence (AI). Traditionally, AI techniques often require centralized data collection and training in a single entity, e.g., an MEC server, which is now becoming a weak point due to data privacy concerns and high data communication overheads. In this context, federated learning (FL) has been proposed to provide collaborative data training solutions, by coordinating multiple mobile devices to train a shared AI model without exposing their data, which enjoys considerable privacy enhancement. To improve the security and scalability of FL implementation, blockchain as a ledger technology is attractive for realizing decentralized FL training without the need for any central server. Particularly, the integration of FL and blockchain leads to a new paradigm, called FLchain, which potentially transforms intelligent MEC networks into decentralized, secure, and privacy-enhancing systems. This article presents an overview of the fundamental concepts and explores the opportunities of FLchain in MEC networks. We identify several main topics in FLchain design, including communication cost, resource allocation, incentive mechanism, security and privacy protection. The key solutions for FLchain design are provided, and the lessons learned as well as the outlooks are also discussed. Then, we investigate the applications of FLchain in popular MEC domains, such as edge data sharing, edge content caching and edge crowdsensing. Finally, important research challenges and future directions are also highlighted.      
### 82.Deep Unfolding for Nonlinear Maximum Hands-off Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.01755.pdf)
>  This paper proposes a computational technique based on ``deep unfolding'' to solving the finite-time maximum hands-off control problem for discrete-time nonlinear stochastic systems. In particular, we seek a sparse control input sequence that stabilizes the system such that the expected value of the square of the final states is small by training a deep neural network. The proposed technique is demonstrated by a numerical experiment.      
### 83.Safe Control Synthesis via Input Constrained Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2104.01704.pdf)
>  This paper introduces the notion of an Input Constrained Control Barrier Function (ICCBF), as a method to synthesize safety-critical controllers for non-linear control affine systems with input constraints. The method identifies a subset of the safe set of states, and constructs a controller to render the subset forward invariant. The feedback controller is represented as the solution to a quadratic program, which can be solved efficiently for real-time implementation. Furthermore, we show that ICCBFs are a generalization of Higher Order Control Barrier Functions, and thus are applicable to systems of non-uniform relative degree. Simulation results are presented for the adaptive cruise control problem, and a spacecraft rendezvous problem.      
### 84.Learning Linear Policies for Robust Bipedal Locomotion on Terrains with Varying Slopes  [ :arrow_down: ](https://arxiv.org/pdf/2104.01662.pdf)
>  In this paper, with a view toward deployment of light-weight control frameworks for bipedal walking robots, we realize end-foot trajectories that are shaped by a single linear feedback policy. We learn this policy via a model-free and a gradient-free learning algorithm, Augmented Random Search (ARS), in the two robot platforms Rabbit and Digit. Our contributions are two-fold: a) By using torso and support plane orientation as inputs, we achieve robust walking on slopes of up to 20 degrees in simulation. b) We demonstrate additional behaviors like walking backwards, stepping-in-place, and recovery from external pushes of up to 120 N. The end result is a robust and a fast feedback control law for bipedal walking on terrains with varying slopes. Towards the end, we also provide preliminary results of hardware transfer to Digit.      
### 85.Towards Lifelong Learning of End-to-end ASR  [ :arrow_down: ](https://arxiv.org/pdf/2104.01616.pdf)
>  Automatic speech recognition (ASR) technologies today are primarily optimized for given datasets; thus, any changes in the application environment (e.g., acoustic conditions or topic domains) may inevitably degrade the performance. We can collect new data describing the new environment and fine-tune the system, but this naturally leads to higher error rates for the earlier datasets, referred to as catastrophic forgetting. The concept of lifelong learning (LLL) aiming to enable a machine to sequentially learn new tasks from new datasets describing the changing real world without forgetting the previously learned knowledge is thus brought to attention. This paper reports, to our knowledge, the first effort to extensively consider and analyze the use of various approaches of LLL in end-to-end (E2E) ASR, including proposing novel methods in saving data for past domains to mitigate the catastrophic forgetting problem. An overall relative reduction of 28.7% in WER was achieved compared to the fine-tuning baseline when sequentially learning on three very different benchmark corpora. This can be the first step toward the highly desired ASR technologies capable of synchronizing with the continuously changing real world.      
### 86.Laser-patterned multifunctional sensor array with graphene nanosheets as a smart biomonitoring fashion accessory  [ :arrow_down: ](https://arxiv.org/pdf/2104.01615.pdf)
>  Biomonitoring wearable sensors based on two-dimensional nanomaterials have lately elicited keen research interest and potential for a new range of flexible nanoelectronic devices. Practical nanomaterial-based devices suited for real-world service, which have first-rate performance while being an attractive accessory, are still distant. We report a multifunctional flexible wearable sensor fabricated using an ultra-thin percolative layer of microwave exfoliated graphene nanosheets on laser-patterned gold circular inter-digitated electrodes for monitoring vital human physiological parameters. This Graphene on Laser-patterned Electrodes (GLE) sensor displays an ultra-high strain resolution of 0.024% and a record gauge factor of 6.3e7 and exceptional stability and repeatability in its operating range. The sensor was subjected to biomonitoring experiments like measurement of heart rate, breathing rate, body temperature, and hydration level, which are vital health parameters, especially considering the current pandemic scenario. The sensor also served in applications such as a pedometer, limb movement tracking, and control switch for human interaction. The innovative laser-etch process used to pattern gold thin-film electrodes and shapes, with the multifunctional incognizable graphene layer, provides a technique for integrating multiple sensors in a wearable fashion accessory. The reported work marks a giant leap from the conventional banal devices to a highly marketable multifunctional sensor array as a biomonitoring fashion accessory.      
### 87.Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers  [ :arrow_down: ](https://arxiv.org/pdf/2104.01604.pdf)
>  This paper introduces Timers and Such, a new open source dataset of spoken English commands for common voice control use cases involving numbers. We describe the gap in existing spoken language understanding datasets that Timers and Such fills, the design and creation of the dataset, and experiments with a number of ASR-based and end-to-end baseline models, the code for which has been made available as part of the SpeechBrain toolkit.      
### 88.Few-Shot Keyword Spotting in Any Language  [ :arrow_down: ](https://arxiv.org/pdf/2104.01454.pdf)
>  We introduce a few-shot transfer learning method for keyword spotting in any language. Leveraging open speech corpora in nine languages, we automate the extraction of a large multilingual keyword bank and use it to train an embedding model. With just five training examples, we fine-tune the embedding model for keyword spotting and achieve an average F1 score of 0.75 on keyword classification for 180 new keywords unseen by the embedding model in these nine languages. This embedding model also generalizes to new languages. We achieve an average F1 score of 0.65 on 5-shot models for 260 keywords sampled across 13 new languages unseen by the embedding model. We investigate streaming accuracy for our 5-shot models in two contexts: keyword spotting and keyword search. Across 440 keywords in 22 languages, we achieve an average streaming keyword spotting accuracy of 85.2% with a false acceptance rate of 1.2%, and observe promising initial results on keyword search.      
### 89.Uplink Coverage in Heterogeneous mmWave Cellular Networks with Clustered Users  [ :arrow_down: ](https://arxiv.org/pdf/2104.01447.pdf)
>  A K-tier heterogeneous mmWave uplink cellular network with clustered user equipments (UEs) is considered in this paper. In particular, UEs are assumed to be clustered around small-cell base stations (BSs) according to a Gaussian distribution, leading to the Thomas cluster process based modeling. Specific and practical line-of-sight (LOS) and non-line-of-sight (NLOS) models are adopted with different parameters for different tiers. The probability density functions (PDFs) and complementary cumulative distribution functions (CCDFs) of different distances from UEs to BSs are characterized. Coupled association strategy and largest long-term averaged biased received power criterion are considered, and general expressions for association probabilities are provided. Following the identification of the association probabilities, the Laplace transforms of the inter-cell interference and the intra-cluster interference are characterized. Using tools from stochastic geometry, general expressions of the SINR coverage probability are provided. As extensions, fractional power control is incorporated into the analysis, tractable closed-form expressions are provided for special cases, and average ergodic spectral efficiency is analyzed. Via numerical and simulation results, analytical characterizations are confirmed and the impact of key system and network parameters on the performance is identified.      
### 90.Mixture of orthogonal sequences made from extended time-stretched pulses enables measurement of involuntary voice fundamental frequency response to pitch perturbation  [ :arrow_down: ](https://arxiv.org/pdf/2104.01444.pdf)
>  Auditory feedback plays an essential role in the regulation of the fundamental frequency of voiced sounds. The fundamental frequency also responds to auditory stimulation other than the speaker's voice. We propose to use this response of the fundamental frequency of sustained vowels to frequency-modulated test signals for investigating involuntary control of voice pitch. This involuntary response is difficult to identify and isolate by the conventional paradigm, which uses step-shaped pitch perturbation. We recently developed a versatile measurement method using a mixture of orthogonal sequences made from a set of extended time-stretched pulses (TSP). In this article, we extended our approach and designed a set of test signals using the mixture to modulate the fundamental frequency of artificial signals. For testing the response, the experimenter presents the modulated signal aurally while the subject is voicing sustained vowels. We developed a tool for conducting this test quickly and interactively. We make the tool available as an open-source and also provide executable GUI-based applications. Preliminary tests revealed that the proposed method consistently provides compensatory responses with about 100 ms latency, representing involuntary control. Finally, we discuss future applications of the proposed method for objective and non-invasive auditory response measurements.      
### 91.Block Scrambling Image Encryption Used in Combination with Data Augmentation for Privacy-Preserving DNNs  [ :arrow_down: ](https://arxiv.org/pdf/2104.01398.pdf)
>  In this paper, we propose a novel learnable image encryption method for privacy-preserving deep neural networks (DNNs). The proposed method is carried out on the basis of block scrambling used in combination with data augmentation techniques such as random cropping, horizontal flip and grid mask. The use of block scrambling enhances robustness against various attacks, and in contrast, the combination with data augmentation enables us to maintain a high classification accuracy even when using encrypted images. In an image classification experiment, the proposed method is demonstrated to be effective in privacy-preserving DNNs.      
### 92.On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR  [ :arrow_down: ](https://arxiv.org/pdf/2104.01393.pdf)
>  We propose an on-the-fly data augmentation method for automatic speech recognition (ASR) that uses alignment information to generate effective training samples. Our method, called Aligned Data Augmentation (ADA) for ASR, replaces transcribed tokens and the speech representations in an aligned manner to generate previously unseen training pairs. The speech representations are sampled from an audio dictionary that has been extracted from the training corpus and inject speaker variations into the training examples. The transcribed tokens are either predicted by a language model such that the augmented data pairs are semantically close to the original data, or randomly sampled. Both strategies result in training pairs that improve robustness in ASR training. Our experiments on a Seq-to-Seq architecture show that ADA can be applied on top of SpecAugment, and achieves about 9-23% and 4-15% relative improvements in WER over SpecAugment alone on LibriSpeech 100h and LibriSpeech 960h test datasets, respectively.      
### 93.No Need for Interactions: Robust Model-Based Imitation Learning using Neural ODE  [ :arrow_down: ](https://arxiv.org/pdf/2104.01390.pdf)
>  Interactions with either environments or expert policies during training are needed for most of the current imitation learning (IL) algorithms. For IL problems with no interactions, a typical approach is Behavior Cloning (BC). However, BC-like methods tend to be affected by distribution shift. To mitigate this problem, we come up with a Robust Model-Based Imitation Learning (RMBIL) framework that casts imitation learning as an end-to-end differentiable nonlinear closed-loop tracking problem. RMBIL applies Neural ODE to learn a precise multi-step dynamics and a robust tracking controller via Nonlinear Dynamics Inversion (NDI) algorithm. Then, the learned NDI controller will be combined with a trajectory generator, a conditional VAE, to imitate an expert's behavior. Theoretical derivation shows that the controller network can approximate an NDI when minimizing the training loss of Neural ODE. Experiments on Mujoco tasks also demonstrate that RMBIL is competitive to the state-of-the-art generative adversarial method (GAIL) and achieves at least 30% performance gain over BC in uneven surfaces.      
### 94.speechocean762: An Open-Source Non-native English Speech Corpus For Pronunciation Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2104.01378.pdf)
>  This paper introduces a new open-source speech corpus named "speechocean762" designed for pronunciation assessment use, consisting of 5000 English utterances from 250 non-native speakers, where half of the speakers are children. Five experts annotated each of the utterances at sentence-level, word-level and phoneme-level. A baseline system is released in open source to illustrate the phoneme-level pronunciation assessment workflow on this corpus. This corpus is allowed to be used freely for commercial and non-commercial purposes. It is available for free download from OpenSLR, and the corresponding baseline system is published in the Kaldi speech recognition toolkit.      
### 95.Private Computation of Polynomials over Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.01369.pdf)
>  This study concentrates on preserving privacy in a network of agents where each agent desires to evaluate a polynomial function over the private values of its immediate neighbors. We provide an algorithm for the exact evaluation of this function while preserving privacy of the involved agents. The solution is based on two cryptographic primitives: Paillier as a Partially Homomorphic Encryption scheme and multiplicative-additive secret sharing. The provided scheme covers a large class of polynomial functions in distributed systems. Moreover, conditions guaranteeing the privacy preservation of the private value of an agent against a set of colluding agents are derived. The simulation results demonstrate that the proposed scheme can be employed in a network to enhance privacy at the cost of extra communication and computation budgets.      
### 96.A Survey on Social-Physical Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2104.01360.pdf)
>  Propelled by versatile data capture, communication, and computing technologies, physical sensing has revolutionized the avenue for spontaneously capturing and interpreting real-world phenomenon. Despite its virtues, various limitations (e.g., high application specificity, partial autonomy, and sparse coverage) hinder physical sensing's effectiveness in critical scenarios such as disaster response. Meanwhile, social sensing is contriving as a pervasive sensing paradigm that leverages the observations from human participants equipped with portable devices and ubiquitous Internet connectivity (i.e., through social media or crowdsensing apps) to perceive the environment. While social sensing possesses a plethora of benefits, it also inherently suffers from a few drawbacks (e.g., inconsistent reliability, uncertain data provenance, and limited sensing availability). Motivated by the complementary virtues of both physical and social sensing, social-physical sensing (SPS) is protruding as an emerging sensing paradigm that tightly integrates social and physical sensors at an unprecedented scale. The vision of SPS centers on mitigating the individual weaknesses of physical and social sensing while exploiting their collective strengths in reconstructing the "state of the world", both physically and socially. While a good amount of interesting SPS applications has been explored, several important unsolved challenges and open research questions prevail in the way of developing dependable SPS systems, which require careful study to address. In this paper, we provide a comprehensive survey of SPS, with an emphasis on its definition and key enablers, state-of-the-art applications, potential research challenges, and road-map for future work. This paper intends to bridge the knowledge gap in current literature by thoroughly examining the various aspects of SPS crucial for building potent SPS systems.      
### 97.Tighter bounds on transient moments of stochastic chemical systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01309.pdf)
>  The use of approximate solution techniques for the Chemical Master Equation is common practice for the analysis of stochastic chemical systems. Despite their widespread use, however, many such techniques rely on unverifiable assumptions and only few provide mechanisms to control the approximation error quantitatively. Addressing this gap, Dowdy and Barton [The Journal of Chemical Physics, 149(7), 074103 (2018)] proposed a method for the computation of guaranteed bounds on the moment trajectories associated with stochastic chemical systems described by the Chemical Master Equation, thereby providing a general framework for error quantification. Here, we present an extension of this method. The key contribution is a new hierarchy of convex necessary moment conditions crucially reflecting the temporal causality and other regularity conditions that are inherent to the moment trajectories associated with stochastic processes described by the Chemical Master Equation. Analogous to the original method, these conditions generate a hierarchy of semidefinite programs that furnishes monotonically improving bounds on the trajectories of the moments and related statistics. Compared to its predecessor, the presented hierarchy produces bounds that are at least as tight and it often enables the computation of dramatically tighter bounds as it enjoys superior scaling properties and the generated semidefinite programs are highly structured. We analyze the properties of the presented hierarchy, discuss some aspects of its practical implementation and demonstrate its merits with several examples.      
### 98.Diarization of Legal Proceedings. Identifying and Transcribing Judicial Speech from Recorded Court Audio  [ :arrow_down: ](https://arxiv.org/pdf/2104.01304.pdf)
>  United States Courts make audio recordings of oral arguments available as public record, but these recordings rarely include speaker annotations. This paper addresses the Speech Audio Diarization problem, answering the question of "Who spoke when?" in the domain of judicial oral argument proceedings. We present a workflow for diarizing the speech of judges using audio recordings of oral arguments, a process we call Reference-Dependent Speaker Verification. We utilize a speech embedding network trained with the Generalized End-to-End Loss to encode speech into d-vectors and a pre-defined reference audio library based on annotated data. We find that by encoding reference audio for speakers and full arguments and computing similarity scores we achieve a 13.8% Diarization Error Rate for speakers covered by the reference audio library on a held-out test set. We evaluate our method on the Supreme Court of the United States oral arguments, accessed through the Oyez Project, and outline future work for diarizing legal proceedings. A code repository for this research is available at <a class="link-external link-http" href="http://github.com/JeffT13/rd-diarization" rel="external noopener nofollow">this http URL</a>      
### 99.Visual Servoing Approach for Autonomous UAV Landing on a Moving Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2104.01272.pdf)
>  We present a method to autonomously land an Unmanned Aerial Vehicle on a moving vehicle with a circular (or elliptical) pattern on the top. A visual servoing controller approaches the ground vehicle using velocity commands calculated directly in image space. The control laws generate velocity commands in all three dimensions, eliminating the need for a separate height controller. The method has shown the ability to approach and land on the moving deck in simulation, indoor and outdoor environments, and compared to the other available methods, it has provided the fastest landing approach. It does not rely on additional external setup, such as RTK, motion capture system, ground station, offboard processing, or communication with the vehicle, and it requires only a minimal set of hardware and localization sensors. The videos and source codes can be accessed from <a class="link-external link-http" href="http://theairlab.org/landing-on-vehicle" rel="external noopener nofollow">this http URL</a>.      
### 100.PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification  [ :arrow_down: ](https://arxiv.org/pdf/2104.01271.pdf)
>  We propose using an adversarial autoencoder (AAE) to replace generative adversarial network (GAN) in the private aggregation of teacher ensembles (PATE), a solution for ensuring differential privacy in speech applications. The AAE architecture allows us to obtain good synthetic speech leveraging upon a discriminative training of latent vectors. Such synthetic speech is used to build a privacy-preserving classifier when non-sensitive data is not sufficiently available in the public domain. This classifier follows the PATE scheme that uses an ensemble of noisy outputs to label the synthetic samples and guarantee $\varepsilon$-differential privacy (DP) on its derived classifiers. <br>Our proposed framework thus consists of an AAE-based generator and a PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands Dataset Version II, the proposed PATE-AAE improves the average classification accuracy by +$2.11\%$ and +$6.60\%$, respectively, when compared with alternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while maintaining a strong level of privacy target at $\varepsilon$=0.01 with a fixed $\delta$=10$^{-5}$.      
### 101.FBCNet: A Multi-view Convolutional Neural Network for Brain-Computer Interface  [ :arrow_down: ](https://arxiv.org/pdf/2104.01233.pdf)
>  Lack of adequate training samples and noisy high-dimensional features are key challenges faced by Motor Imagery (MI) decoding algorithms for electroencephalogram (EEG) based Brain-Computer Interface (BCI). To address these challenges, inspired from neuro-physiological signatures of MI, this paper proposes a novel Filter-Bank Convolutional Network (FBCNet) for MI classification. FBCNet employs a multi-view data representation followed by spatial filtering to extract spectro-spatially discriminative features. This multistage approach enables efficient training of the network even when limited training data is available. More significantly, in FBCNet, we propose a novel Variance layer that effectively aggregates the EEG time-domain information. With this design, we compare FBCNet with state-of-the-art (SOTA) BCI algorithm on four MI datasets: The BCI competition IV dataset 2a (BCIC-IV-2a), the OpenBMI dataset, and two large datasets from chronic stroke patients. The results show that, by achieving 76.20% 4-class classification accuracy, FBCNet sets a new SOTA for BCIC-IV-2a dataset. On the other three datasets, FBCNet yields up to 8% higher binary classification accuracies. Additionally, using explainable AI techniques we present one of the first reports about the differences in discriminative EEG features between healthy subjects and stroke patients. Also, the FBCNet source code is available at <a class="link-external link-https" href="https://github.com/ravikiran-mane/FBCNet" rel="external noopener nofollow">this https URL</a>.      
### 102.A Review of Particle Detectors for Space-Borne Self-Adaptive Fault-Tolerant Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.01206.pdf)
>  The soft error rate (SER) of integrated circuits (ICs) operating in space environment may vary by several orders of magnitude due to the variable intensity of radiation exposure. To ensure the radiation hardness without compromising the system performance, it is necessary to implement the dynamic hardening mechanisms which can be activated under the critical radiation exposure. Such operating scenario requires the real-time detection of energetic particles responsible for the soft errors. Although numerous particle detection solutions have been reported, very few works address the on-chip particle detectors suited for the self-adaptive fault tolerant microprocessor systems for space missions. This work reviews the state-of-the-art particle detectors, with emphasis on two solutions for the self-adaptive systems: particle detector based on embedded SRAM and particle detector based on pulse stretching inverters.      
### 103.Monitoring of Particle Flux and LET Variations with Pulse Stretching Inverters  [ :arrow_down: ](https://arxiv.org/pdf/2104.01202.pdf)
>  This work investigates the use of pulse stretching inverters for monitoring the variation of flux and Linear Energy Transfer (LET) of energetic particles. The basic particle detector consists of two cascaded pulse stretching (skew-sized) inverters designed in CMOS technology, and the required sensing area is obtained by connecting multiple two-inverter pulse stretching cells in parallel, and employing the required number of parallel arrays. The particle strikes are detected in terms of the Single Event Transients (SETs), and the detector provides the information on the SET count rate and SET pulse width variation, from which the particle flux and LET can be determined. The main advantage of the proposed solution is the possibility to sense the LET variations using purely digital processing logic. The SPICE simulations done on IHP 130 nm bulk CMOS technology have shown that the SET pulse width at the output of detector changes by 550 ps over the LET range from 1 to 100 MeVcm2mg-1. The proposed solution is intended to operate as an on-chip particle detector within the self-adaptive multiprocessing systems.      
