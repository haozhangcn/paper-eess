# ArXiv eess --Fri, 9 Apr 2021
### 1.Fingerprint Presentation Attack Detection utilizing Time-Series, Color Fingerprint Captures  [ :arrow_down: ](https://arxiv.org/pdf/2104.03933.pdf)
>  Fingerprint capture systems can be fooled by widely accessible methods to spoof the system using fake fingers, known as presentation attacks. As biometric recognition systems become more extensively relied upon at international borders and in consumer electronics, presentation attacks are becoming an increasingly serious issue. A robust solution is needed that can handle the increased variability and complexity of spoofing techniques. This paper demonstrates the viability of utilizing a sensor with time-series and color-sensing capabilities to improve the robustness of a traditional fingerprint sensor and introduces a comprehensive fingerprint dataset with over 36,000 image sequences and a state-of-the-art set of spoofing techniques. The specific sensor used in this research captures a traditional gray-scale static capture and a time-series color capture simultaneously. Two different methods for Presentation Attack Detection (PAD) are used to assess the benefit of a color dynamic capture. The first algorithm utilizes Static-Temporal Feature Engineering on the fingerprint capture to generate a classification decision. The second generates its classification decision using features extracted by way of the Inception V3 CNN trained on ImageNet. Classification performance is evaluated using features extracted exclusively from the static capture, exclusively from the dynamic capture, and on a fusion of the two feature sets. With both PAD approaches we find that the fusion of the dynamic and static feature-set is shown to improve performance to a level not individually achievable.      
### 2.A transfer-learning approach for lesion detection in endoscopic images from the urinary tract  [ :arrow_down: ](https://arxiv.org/pdf/2104.03927.pdf)
>  Ureteroscopy and cystoscopy are the gold standard methods to identify and treat tumors along the urinary tract. It has been reported that during a normal procedure a rate of 10-20 % of the lesions could be missed. In this work we study the implementation of 3 different Convolutional Neural Networks (CNNs), using a 2-steps training strategy, to classify images from the urinary tract with and without lesions. A total of 6,101 images from ureteroscopy and cystoscopy procedures were collected. The CNNs were trained and tested using transfer learning in a two-steps fashion on 3 datasets. The datasets used were: 1) only ureteroscopy images, 2) only cystoscopy images and 3) the combination of both of them. For cystoscopy data, VGG performed better obtaining an Area Under the ROC Curve (AUC) value of 0.846. In the cases of ureteroscopy and the combination of both datasets, ResNet50 achieved the best results with AUC values of 0.987 and 0.940. The use of a training dataset that comprehends both domains results in general better performances, but performing a second stage of transfer learning achieves comparable ones. There is no single model which performs better in all scenarios, but ResNet50 is the network that achieves the best performances in most of them. The obtained results open the opportunity for further investigation with a view for improving lesion detection in endoscopic images of the urinary system.      
### 3.Unsupervised Speech Representation Learning for Behavior Modeling using Triplet Enhanced Contextualized Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.03899.pdf)
>  Speech encodes a wealth of information related to human behavior and has been used in a variety of automated behavior recognition tasks. However, extracting behavioral information from speech remains challenging including due to inadequate training data resources stemming from the often low occurrence frequencies of specific behavioral patterns. Moreover, supervised behavioral modeling typically relies on domain-specific construct definitions and corresponding manually-annotated data, rendering generalizing across domains challenging. In this paper, we exploit the stationary properties of human behavior within an interaction and present a representation learning method to capture behavioral information from speech in an unsupervised way. We hypothesize that nearby segments of speech share the same behavioral context and hence map onto similar underlying behavioral representations. We present an encoder-decoder based Deep Contextualized Network (DCN) as well as a Triplet-Enhanced DCN (TE-DCN) framework to capture the behavioral context and derive a manifold representation, where speech frames with similar behaviors are closer while frames of different behaviors maintain larger distances. The models are trained on movie audio data and validated on diverse domains including on a couples therapy corpus and other publicly collected data (e.g., stand-up comedy). With encouraging results, our proposed framework shows the feasibility of unsupervised learning within cross-domain behavioral modeling.      
### 4.Active Power Control of Waked Wind Farms: Compensation of Turbine Saturation and Thrust Force Balance  [ :arrow_down: ](https://arxiv.org/pdf/2104.03894.pdf)
>  Active power control regulates the total power generated by wind farms with the power consumed on the electricity grid. Due to wake effects, the available power is reduced and turbulence is increased at downstream wind turbines. Such effects lead to a design challenge for wind farm control, where the delicate balance between supply and demand should be maintained, while considering the load balancing in the wind turbine structures. We propose a control architecture based on simple feedback controllers that adjusts the demanded power set points of individual wind turbines to compensate for turbine saturations and to balance thrust forces. For compensation purposes, the dynamics of power tracking in the wind turbines is approximated as a pure time-delay process, and the thrust force balance design is based on an identified linear model of the turbines. In this paper, we show that the proposed control architecture allows the generated power to track its reference even when turbines saturate, while the thrust forces are balanced. In addition, the result shows that the proposed power dispatch strategy, which considers thrust force balance, also avoids turbine saturation, being thus beneficial for energy production. The effectiveness of the proposed feedback controller is demonstrated using high-fidelity computational fluid dynamics simulations of a small wind farm.      
### 5.A Differential-Cascaded Approach for Adaptive Control of Robot Manipulators  [ :arrow_down: ](https://arxiv.org/pdf/2104.03853.pdf)
>  This paper investigates adaptive control of nonlinear robot manipulators with parametric uncertainty. Motivated by generating closed-loop robot dynamics with enhanced transmission capability of a reference torque and with connection to linear dynamics, we develop a new adaptive approach by exploiting forwardstepping design and inertia invariance, yielding differential-cascaded closed-loop dynamics. With the proposed approach, we propose a new class of adaptive controllers for nonlinear robot manipulators. Our particular study concerning adaptive control of robots exhibits a design methodology towards establishing the connection between adaptive control of highly nonlinear uncertain systems (e.g., with a variable inertia matrix) and linear dynamics (typically with the same or increased order), which is a long-standing intractable issue in the literature.      
### 6.Uncertainty-Aware Temporal Self-Learning (UATS): Semi-Supervised Learning for Segmentation of Prostate Zones and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2104.03840.pdf)
>  Various convolutional neural network (CNN) based concepts have been introduced for the prostate's automatic segmentation and its coarse subdivision into transition zone (TZ) and peripheral zone (PZ). However, when targeting a fine-grained segmentation of TZ, PZ, distal prostatic urethra (DPU) and the anterior fibromuscular stroma (AFS), the task becomes more challenging and has not yet been solved at the level of human performance. One reason might be the insufficient amount of labeled data for supervised training. Therefore, we propose to apply a semi-supervised learning (SSL) technique named uncertainty-aware temporal self-learning (UATS) to overcome the expensive and time-consuming manual ground truth labeling. We combine the SSL techniques temporal ensembling and uncertainty-guided self-learning to benefit from unlabeled images, which are often readily available. Our method significantly outperforms the supervised baseline and obtained a Dice coefficient (DC) of up to 78.9% , 87.3%, 75.3%, 50.6% for TZ, PZ, DPU and AFS, respectively. The obtained results are in the range of human inter-rater performance for all structures. Moreover, we investigate the method's robustness against noise and demonstrate the generalization capability for varying ratios of labeled data and on other challenging tasks, namely the hippocampus and skin lesion segmentation. UATS achieved superiority segmentation quality compared to the supervised baseline, particularly for minimal amounts of labeled data.      
### 7.Detection of Cyber-Attacks in Collaborative Intersection Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.03801.pdf)
>  Road intersections are widely recognized as a lead cause for accidents and traffic delays. In a future scenario with a significant adoption of Cooperative Autonomous Vehicles, solutions based on fully automatic, signage-less Intersection Control would become viable. Such a solution, however, requires communication between vehicles and, possibly, the infrastructure over wireless networks. This increases the attack surface available to a malicious actor, which could lead to dangerous situations. In this paper, we address the safety of Intersection Control algorithms, and design a Sliding-Mode-Observer based solution capable of detecting and estimating false data injection attacks affecting vehicles' communication. With respect to previous literature, a novel detection logic with improved detection performances is presented. Simulation results are provided to show the effectiveness of the proposed approach.      
### 8.Detection of Network and Sensor Cyber-Attacks in Platoons of Cooperative Autonomous Vehicles: a Sliding-Mode Observer Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.03798.pdf)
>  Platoons of autonomous vehicles are being investigated as a way to increase road capacity and fuel efficiency. Cooperative Adaptive Cruise Control (CACC) is an approach to achieve such platoons, in which vehicles collaborate using wireless communication. While this collaboration improves performance, it also makes the vehicles vulnerable to cyber-attacks. In this paper the performance of a sliding mode observer (SMO) based approach to cyber-attack detection is analysed, considering simultaneous attacks on the communication and local sensors. To this end, the considered cyber-attacks are divided into three classes for which relevant theoretical properties are proven. Furthermore, the harm that attacks within each of these classes can do to the system while avoiding detection is analysed based on simulation examples.      
### 9.Design and assessment of an eco--driving PMP algorithm for optimal deceleration and gear shifting in trucks  [ :arrow_down: ](https://arxiv.org/pdf/2104.03797.pdf)
>  In this paper, an eco--driving Pontryagin maximum principle (PMP) algorithm is designed for optimal deceleration and gear shifting in trucks based on switching among a finite set of driving modes. The PMP algorithm is implemented and assessed in the IPG TruckMaker traffic simulator as an eco--driving assistance system (EDAS). The developed EDAS strategy reduces fuel consumption with an optimized velocity profile and, in practice, allows contextual feedback incorporation from the driver for safety. Furthermore, the optimization over driving modes is computationally inexpensive, allowing the methodology to be used online, in real--time. Simulation results show that significant fuel savings can be achieved proportional to the number of velocity events and the difference between current velocity and final desired velocity for each event.      
### 10.A Topology-Switching Coalitional Control and Observation Scheme with Stability Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2104.03787.pdf)
>  In this paper a coalitional control and observation scheme is presented in which the coalitions are changed online by enabling and disabling communication links. Transitions between coalitions are made to best balance overall system performance and communication costs. Linear Matrix Inequalities are used to design the controller and observer, guaranteeing stability of the switching system. Simulation results for vehicle platoon control are presented to illustrate the proposed method.      
### 11.(Integral-)ISS of switched and time-varying impulsive systems based on global state weak linearization  [ :arrow_down: ](https://arxiv.org/pdf/2104.03772.pdf)
>  It is shown that impulsive systems of nonlinear, time-varying and/or switched form that allow a stable global state weak linearization are jointly input-to-state stable (ISS) under small inputs and integral ISS (iISS). The system is said to allow a global state weak linearization if its flow and jump equations can be written as a (time-varying, switched) linear part plus a (nonlinear) pertubation satisfying a bound of affine form on the state. This bound reduces to a linear form under zero input but does not force the system to be linear under zero input. The given results generalize and extend previously existing ones in many directions: (a) no (dwell-time or other) constraints are placed on the impulse-time sequence, (b) the system need not be linear under zero input, (c) existence of a (common) Lyapunov function is not required, (d) the perturbation bound need not be linear on the input.      
### 12.BEFD: Boundary Enhancement and Feature Denoising for Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.03768.pdf)
>  Blood vessel segmentation is crucial for many diagnostic and research applications. In recent years, CNN-based models have leaded to breakthroughs in the task of segmentation, however, such methods usually lose high-frequency information like object boundaries and subtle structures, which are vital to vessel segmentation. To tackle this issue, we propose Boundary Enhancement and Feature Denoising (BEFD) module to facilitate the network ability of extracting boundary information in semantic segmentation, which can be integrated into arbitrary encoder-decoder architecture in an end-to-end way. By introducing Sobel edge detector, the network is able to acquire additional edge prior, thus enhancing boundary in an unsupervised manner for medical image segmentation. In addition, we also utilize a denoising block to reduce the noise hidden in the low-level features. Experimental results on retinal vessel dataset and angiocarpy dataset demonstrate the superior performance of the new BEFD module.      
### 13.Phoneme-based Distribution Regularization for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.03759.pdf)
>  Existing speech enhancement methods mainly separate speech from noises at the signal level or in the time-frequency domain. They seldom pay attention to the semantic information of a corrupted signal. In this paper, we aim to bridge this gap by extracting phoneme identities to help speech enhancement. Specifically, we propose a phoneme-based distribution regularization (PbDr) for speech enhancement, which incorporates frame-wise phoneme information into speech enhancement network in a conditional manner. As different phonemes always lead to different feature distributions in frequency, we propose to learn a parameter pair, i.e. scale and bias, through a phoneme classification vector to modulate the speech enhancement network. The modulation parameter pair includes not only frame-wise but also frequency-wise conditions, which effectively map features to phoneme-related distributions. In this way, we explicitly regularize speech enhancement features by recognition vectors. Experiments on public datasets demonstrate that the proposed PbDr module can not only boost the perceptual quality for speech enhancement but also the recognition accuracy of an ASR system on the enhanced speech. This PbDr module could be readily incorporated into other speech enhancement networks as well.      
### 14.Sensor-Aided Beamwidth and Power Control for Next Generation Vehicular Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.03754.pdf)
>  Ultra-reliable low-latency Vehicle-to-Everything (V2X) communications are needed to meet the extreme requirements of enhanced driving applications. Millimeter-Wave (24.25-52.6 GHz) or sub-THz (&gt;100 GHz) V2X communications are a viable solution, provided that the highly collimated beams are kept aligned during vehicles' maneuverings. In this work, we propose a sensor-assisted dynamic Beamwidth and Power Control (BPC) system to counteract the detrimental effect of vehicle dynamics, exploiting data collected by on-board inertial and positioning sensors, mutually exchanged among vehicles over a parallel low-rate link, e.g., 5G New Radio (NR) Frequency Range 1 (FR1). The proposed BPC solution works on top of a sensor-aided Beam Alignment and Tracking (BAT) system, overcoming the limitations of fixed-beamwidth systems and optimizing the performance in challenging Vehicle-to-Vehicle (V2V) scenarios, even if extensions to Vehicle-to-Infrastructure (V2I) use-cases are feasible. We validate the sensor-assisted dynamic BPC on real trajectories and sensors' data collected by a dedicated experimental campaign. The goal is to show the advantages of the proposed BPC strategy in a high data-rate Line-Of-Sight (LOS) V2V context, and to outline the requirements in terms of sensors' sampling time and accuracy, along with the end-to-end latency on the control channel.      
### 15.Atrous Residual Interconnected Encoder to Attention Decoder Framework for Vertebrae Segmentation via 3D Volumetric CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.03715.pdf)
>  Automatic medical image segmentation based on Computed Tomography (CT) has been widely applied for computer-aided surgery as a prerequisite. With the development of deep learning technologies, deep convolutional neural networks (DCNNs) have shown robust performance in automated semantic segmentation of medical images. However, semantic segmentation algorithms based on DCNNs still meet the challenges of feature loss between encoder and decoder, multi-scale object, restricted field of view of filters, and lack of medical image data. This paper proposes a novel algorithm for automated vertebrae segmentation via 3D volumetric spine CT images. The proposed model is based on the structure of encoder to decoder, using layer normalization to optimize mini-batch training performance. To address the concern of the information loss between encoder and decoder, we designed an Atrous Residual Path to pass more features from encoder to decoder instead of an easy shortcut connection. The proposed model also applied the attention module in the decoder part to extract features from variant scales. The proposed model is evaluated on a publicly available dataset by a variety of metrics. The experimental results show that our model achieves competitive performance compared with other state-of-the-art medical semantic segmentation methods.      
### 16.Advanced Image Enhancement Method for Distant Vessels and Structures in Capsule Endoscopy  [ :arrow_down: ](https://arxiv.org/pdf/2104.03668.pdf)
>  This paper proposes an advanced method for contrast enhancement of capsule endoscopic images, with the main objective to obtain sufficient information about the vessels and structures in more distant (or darker) parts of capsule endoscopic images. The proposed method (PM) combines two algorithms for the enhancement of darker and brighter areas of capsule endoscopic images, respectively. The half-unit weighted bilinear algorithm (HWB) proposed in our previous work is used to enhance darker areas according to the darker map content of its HSV's component V. Enhancement of brighter areas is achieved thanks to the novel thresholded weighted-bilinear algorithm (TWB) developed to avoid overexposure and enlargement of specular highlight spots while preserving the hue, in such areas. The TWB performs enhancement operations following a gradual increment of the brightness of the brighter map content of its HSV's component V. In other words, the TWB decreases its averaged-weights as the intensity content of the component V increases. Extensive experimental demonstrations were conducted, and based on evaluation of the reference and PM enhanced images, a gastroenterologist (Ã˜H) concluded that the PM enhanced images were the best ones based on the information about the vessels, contrast in the images, and the view or visibility of the structures in more distant parts of the capsule endoscopy images.      
### 17.Electromagnetic Radiation Reduction in 5G Networks and Beyond using Thermal Radiation Mode  [ :arrow_down: ](https://arxiv.org/pdf/2104.03655.pdf)
>  With the massive increase in the popularity of smartphones and mobile data applications demanding bandwidth requiring data rates of the order of Gigabits per second, exploration of untapped frequency spectrum such as millimeter-wave has begun. Along with providing seamless connectivity and catering to achieving high Quality of Service and Quality of Experience, investigations are ongoing to enhance our knowledge about biological safety at high frequencies. There is a need to ensure safety and reliability for the exposed public and updating the government policies regarding safety standards and regulations. This article is consecrated to provide an insight into health effects pertaining to millimeter frequencies, addressing aspects such as thermal heating in the body tissues with temperature rise, specific absorption rate, power density. As a solution, a proposal has been given for Electromagnetic radiation reduction for the mobile communication system in the form of a proposed mode that is, Thermal Radiation mode endorsing its safe use, promoting Green WCN along with increased energy efficiency and reduced complexity for the future generations to come. The proposal also validates reduced power density, Specific Absorption Rate, and temperature elevation produced in the human tissue when compared to other models in the form of simulation results obtained. It can increase the safety and reliability of 5G and beyond i.e. 6G networks in the future.      
### 18.Graph Attention Networks for Anti-Spoofing  [ :arrow_down: ](https://arxiv.org/pdf/2104.03654.pdf)
>  The cues needed to detect spoofing attacks against automatic speaker verification are often located in specific spectral sub-bands or temporal segments. Previous works show the potential to learn these using either spectral or temporal self-attention mechanisms but not the relationships between neighbouring sub-bands or segments. This paper reports our use of graph attention networks (GATs) to model these relationships and to improve spoofing detection performance. GATs leverage a self-attention mechanism over graph structured data to model the data manifold and the relationships between nodes. Our graph is constructed from representations produced by a ResNet. Nodes in the graph represent information either in specific sub-bands or temporal segments. Experiments performed on the ASVspoof 2019 logical access database show that our GAT-based model with temporal attention outperforms all of our baseline single systems. Furthermore, GAT-based systems are complementary to a set of existing systems. The fusion of GAT-based models with more conventional countermeasures delivers a 47% relative improvement in performance compared to the best performing single GAT system.      
### 19.MRI-based Alzheimer's disease prediction via distilling the knowledge in multi-modal data  [ :arrow_down: ](https://arxiv.org/pdf/2104.03618.pdf)
>  Mild cognitive impairment (MCI) conversion prediction, i.e., identifying MCI patients of high risks converting to Alzheimer's disease (AD), is essential for preventing or slowing the progression of AD. Although previous studies have shown that the fusion of multi-modal data can effectively improve the prediction accuracy, their applications are largely restricted by the limited availability or high cost of multi-modal data. Building an effective prediction model using only magnetic resonance imaging (MRI) remains a challenging research topic. In this work, we propose a multi-modal multi-instance distillation scheme, which aims to distill the knowledge learned from multi-modal data to an MRI-based network for MCI conversion prediction. In contrast to existing distillation algorithms, the proposed multi-instance probabilities demonstrate a superior capability of representing the complicated atrophy distributions, and can guide the MRI-based network to better explore the input MRI. To our best knowledge, this is the first study that attempts to improve an MRI-based prediction model by leveraging extra supervision distilled from multi-modal information. Experiments demonstrate the advantage of our framework, suggesting its potentials in the data-limited clinical settings.      
### 20.Stable deep neural network architectures for mitochondria segmentation on electron microscopy volumes  [ :arrow_down: ](https://arxiv.org/pdf/2104.03577.pdf)
>  Electron microscopy (EM) allows the identification of intracellular organelles such as mitochondria, providing insights for clinical and scientific studies. In recent years, a number of novel deep learning architectures have been published reporting superior performance, or even human-level accuracy, compared to previous approaches on public mitochondria segmentation datasets. Unfortunately, many of these publications do not make neither the code nor the full training details public to support the results obtained, leading to reproducibility issues and dubious model comparisons. For that reason, and following a recent code of best practices for reporting experimental results, we present an extensive study of the state-of-the-art deep learning architectures for the segmentation of mitochondria on EM volumes, and evaluate the impact in performance of different variations of 2D and 3D U-Net-like models for this task. To better understand the contribution of each component, a common set of pre- and post-processing operations has been implemented and tested with each approach. Moreover, an exhaustive sweep of hyperparameters values for all architectures have been performed and each configuration has been run multiple times to report the mean and standard deviation values of the evaluation metrics. Using this methodology, we found very stable architectures and hyperparameter configurations that consistently obtain state-of-the-art results in the well-known EPFL Hippocampus mitochondria segmentation dataset. Furthermore, we have benchmarked our proposed models on two other available datasets, Lucchi++ and Kasthuri++, where they outperform all previous works. The code derived from this research and its documentation are publicly available.      
### 21.M-Net with Bidirectional ConvLSTM for Cup and Disc Segmentation in Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.03549.pdf)
>  Glaucoma is a severe eye disease that is known to deteriorate optic never fibers, causing cup size to increase, which could result in permanent loss of vision. Glaucoma is the second leading cause of blindness after cataract, but glaucoma being more dangerous as it is not curable. Early diagnoses and treatment of glaucoma can help to slow the progression of glaucoma and its damages. For the detection of glaucoma, the Cup to Disc ratio (CDR) provides significant information. The CDR depends heavily on the accurate segmentation of cup and disc regions. In this paper, we have proposed a modified M-Net with bidirectional convolution long short-term memory (LSTM), based on joint cup and disc segmentation. The proposed network combines features of encoder and decoder, with bidirectional LSTM. Our proposed model segments cup and disc regions based on which the abnormalities in cup to disc ratio can be observed. The proposed model is tested on REFUGE2 data, where our model achieves a dice score of 0.92 for optic disc and an accuracy of 98.99% in segmenting cup and disc regions      
### 22.Map-based Channel Modeling and Generation for U2V mmWave Communication  [ :arrow_down: ](https://arxiv.org/pdf/2104.03540.pdf)
>  Unmanned aerial vehicle (UAV) aided millimeter wave (mmWave) technologies have a promising prospect in the future communication networks. By considering the factors of three-dimensional (3D) scattering space, 3D trajectory, and 3D antenna array, a non-stationary channel model for UAV-to-vehicle (U2V) mmWave communications is proposed. The computation and generation methods of channel parameters including interpath and intra-path are analyzed in detail. The inter-path parameters are calculated in a deterministic way, while the parameters of intra-path rays are generated in a stochastic way. The statistical properties are obtained by using a Gaussian mixture model (GMM) on the massive ray tracing (RT) data. Then, a modified method of equal areas (MMEA) is developed to generate the random intra-path variables. Meanwhile, to reduce the complexity of RT method, the 3D propagation space is reconstructed based on the user-defined digital map. The simulated and analyzed results show that the proposed model and generation method can reproduce non-stationary U2V channels in accord with U2V scenarios. The generated statistical properties are consistent with the theoretical and measured ones as well.      
### 23.A Centralized Optimization Approach for Bidirectional PEV Impacts Analysis in a Commercial Building-Integrated Microgrid  [ :arrow_down: ](https://arxiv.org/pdf/2104.03498.pdf)
>  Building sector is the largest energy user in the United States. Conventional building energy studies mostly involve Heating, Ventilation, and Air Conditioning (HVAC), and lighting energy consumptions. Recent additions of solar Photovoltaics (PV) along with other Distributed Energy Resources (DER), particularly Plug-in Electric Vehicles (PEV) have added a new dimension to this problem and made it more complex. This paper presents an avant-garde framework for selecting the best charging/discharging level of PEV for a commercial building-integrated microgrid. A typical commercial building is used as a microgrid testbed incorporating all the DERs presented in a smart building. A Mixed Integer Linear Programming (MILP) problem is formulated to optimize the energy and demand cost associated with this building operation. The cost function is solved in conjunction with real data and modified to assess the bidirectional PEV impacts on the flexible building loads that are contributing factors in making energy usage decisions. Finally, the impacts of optimized DERs are investigated on a Distribution System (DS) to show the necessity of a holistic approach for selecting the suitable PEV strategies. The results show that bidirectional fast PEV activities can provide higher cost reduction and less voltage deviation in comparison to slow PEV activities.      
### 24.A Deep Ensemble-based Wireless Receiver Architecture for Mitigating Adversarial Interference in Automatic Modulation Classification  [ :arrow_down: ](https://arxiv.org/pdf/2104.03494.pdf)
>  Deep learning-based automatic modulation classification (AMC) models are susceptible to adversarial attacks. Such attacks inject specifically crafted (non-random) wireless interference into transmitted signals to induce erroneous classification predictions. Furthermore, adversarial interference is transferable in black box environments, allowing an adversary to attack multiple deep learning models with a single perturbation crafted for a particular classification model. In this work, we propose a novel wireless receiver architecture to mitigate the effects of adversarial interference in various black box attack environments. We begin by evaluating the architecture uncertainty environment, where we show that adversarial attacks crafted to fool specific AMC DL architectures are not directly transferable to different DL architectures. Next, we consider the domain uncertainty environment, where we show that adversarial attacks crafted on time domain and frequency domain features to not directly transfer to the altering domain. Using these insights, we develop our Assorted Deep Ensemble (ADE) defense, which is an ensemble of deep learning architectures trained on time and frequency domain representations of received signals. Through evaluation on two wireless signal datasets under different sources of uncertainty, we demonstrate that our ADE obtains substantial improvements in AMC classification performance compared with baseline defenses across different adversarial attacks and potencies.      
### 25.Design of a Power Amplifying-RIS for Free-Space Optical Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.03449.pdf)
>  The steering dynamics of re-configurable intelligent surfaces (RIS) have hoisted them to the front row of technologies that can be exploited to solve skip-zones in wireless communication systems. They can enable a programmable wireless environment, turning it into a partially deterministic space that plays an active role in determining how wireless signals propagate. However, RIS-based communication systems' practical implementation may face challenges such as noise generated by the RIS structure. Besides, the transmitted signal may face a double-fading effect over the two portions of the channel. This article tackles this double-fading problem in near-terrestrial free-space optical (nT-FSO) communication systems using a RIS module based upon liquid-crystal (LC) on silicon (LCoS). A doped LC layer can directly amplify a light when placed in an external field. Leveraging on this capacity of a doped LC, we mitigate the double-attenuation faced by the transmitted signal. We first revisit the nT-FSO power loss scenario, then discuss the direct-light amplification, and consider the system performance. Results show that at 51 degrees of the incoming light incidence angle, the proposed LCoS design has minimal RIS depth, implying less LC's material. The performance results show that the number of bit per unit bandwidth is upper-bounded and grows with the ratio of the sub-links distances. Finally, we present and discuss open issues to enable new research opportunities towards the use of RIS and amplifying-RIS in nT-FSO systems.      
### 26.Pushing the Limits of Non-Autoregressive Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.03416.pdf)
>  We combine recent advancements in end-to-end speech recognition to non-autoregressive automatic speech recognition. We push the limits of non-autoregressive state-of-the-art results for multiple datasets: LibriSpeech, Fisher+Switchboard and Wall Street Journal. Key to our recipe, we leverage CTC on giant Conformer neural network architectures with SpecAugment and wav2vec2 pre-training. We achieve 1.8%/3.6% WER on LibriSpeech test/test-other sets, 5.1%/9.8% WER on Switchboard, and 3.4% on the Wall Street Journal, all without a language model.      
### 27.Leaderless collective motions in affine formation control  [ :arrow_down: ](https://arxiv.org/pdf/2104.03412.pdf)
>  This paper proposes a novel distributed technique to induce collective motions in affine formation control. Instead of the traditional leader-follower strategy, we propose modifying the original weights that build the Laplacian matrix so that a designed steady-state motion of the desired shape emerges from the agents' local interactions. The proposed technique allows a rich collection of collective motions such as rotations around the centroid, translations, scalings, and shearings of a reference shape. These motions can be applied in useful collective behaviors such as \emph{shaped} consensus (the rendezvous with a particular shape), escorting one of the team agents, or area coverage. We prove the global stability and effectiveness of our proposed technique rigorously, and we provide some illustrative numerical simulations.      
### 28.A simple and robust method for noise variance estimation for time-varying signals  [ :arrow_down: ](https://arxiv.org/pdf/2104.03378.pdf)
>  In this brief paper, we present a simple approach to estimate the variance of measurement noise with time-varying 1-D signals. The proposed approach exploits the relationship between the noise variance and the variance of the prediction errors (or innovation sequence) of a linear estimator, the idea that was pioneered by [9] and [2]. Compared with the classic and more recent methods in the same category, the proposed method can render more robust estimates with the presence of unmodelled dynamics and outliers in the measurement.      
### 29.Value of information in networked control systems subject to delay  [ :arrow_down: ](https://arxiv.org/pdf/2104.03355.pdf)
>  In this paper, we study the trade-off between the transmission cost and the control performance of the multi-loop networked control system subject to network-induced delay. Within the linear-quadratic-Gaussian (LQG) framework, the joint design of control policy and networking strategy is decomposed into separation optimization problems. Based on the trade-off analysis, a scalable, delay-dependent Value-of-Information (VoI) based scheduling policy is constructed to quantify the value of transmitting the data packet, and enables the decision-makers embedded in subsystems to determine the transmission policy. The proposed scalable VoI inherits the task criticality of the previous VoI metric meanwhile is sensitive to the system parameters such as information freshness and network delays. The VoI-based scheduling policy is proved to outperform the periodical triggering policy and existing Age-of-Information (AoI) based policy for network control system under transmission delay. The effectiveness of the constructed VoI with arbitrary network delay is validated through numerical simulations.      
### 30.Machine Learning Based on Natural Language Processing to Detect Cardiac Failure in Clinical Narratives  [ :arrow_down: ](https://arxiv.org/pdf/2104.03934.pdf)
>  The purpose of the study presented herein is to develop a machine learning algorithm based on natural language processing that automatically detects whether a patient has a cardiac failure or a healthy condition by using physician notes in Research Data Warehouse at CHU Sainte Justine Hospital. First, a word representation learning technique was employed by using bag-of-word (BoW), term frequency inverse document frequency (TFIDF), and neural word embeddings (word2vec). Each representation technique aims to retain the words semantic and syntactic analysis in critical care data. It helps to enrich the mutual information for the word representation and leads to an advantage for further appropriate analysis steps. Second, a machine learning classifier was used to detect the patients condition for either cardiac failure or stable patient through the created word representation vector space from the previous step. This machine learning approach is based on a supervised binary classification algorithm, including logistic regression (LR), Gaussian Naive-Bayes (GaussianNB), and multilayer perceptron neural network (MLPNN). Technically, it mainly optimizes the empirical loss during training the classifiers. As a result, an automatic learning algorithm would be accomplished to draw a high classification performance, including accuracy (acc), precision (pre), recall (rec), and F1 score (f1). The results show that the combination of TFIDF and MLPNN always outperformed other combinations with all overall performance. In the case without any feature selection, the proposed framework yielded an overall classification performance with acc, pre, rec, and f1 of 84% and 82%, 85%, and 83%, respectively. Significantly, if the feature selection was well applied, the overall performance would finally improve up to 4% for each evaluation.      
### 31.Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.03893.pdf)
>  For lower arm amputees, robotic prosthetic hands offer the promise to regain the capability to perform fine object manipulation in activities of daily living. Current control methods based on physiological signals such as EEG and EMG are prone to poor inference outcomes due to motion artifacts, variability of skin electrode junction impedance over time, muscle fatigue, and other factors. Visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, variable shapes of objects depending on view-angle, among other factors. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities. <br>In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of time as the hand approaches the object to grasp it. For this purpose, we have also developed novel data processing and augmentation techniques to train neural network components. Our experimental data analyses demonstrate that EMG and visual evidence show complementary strengths, and as a consequence, fusion of multimodal evidence can outperform each individual evidence modality at any given time. Specifically, results indicate that, on average, fusion improves the instantaneous upcoming grasp type classification accuracy while in the reaching phase by 13.66% and 14.8%, relative to EMG and visual evidence individually. An overall fusion accuracy of 95.3% among 13 labels (compared to a chance level of 7.7%) is achieved, and more detailed analysis indicate that the correct grasp is inferred sufficiently early and with high confidence compared to the top contender, in order to allow successful robot actuation to close the loop.      
### 32.SerumRNN: Step by Step Audio VST Effect Programming  [ :arrow_down: ](https://arxiv.org/pdf/2104.03876.pdf)
>  Learning to program an audio production VST synthesizer is a time consuming process, usually obtained through inefficient trial and error and only mastered after years of experience. As an educational and creative tool for sound designers, we propose SerumRNN: a system that provides step-by-step instructions for applying audio effects to change a user's input audio towards a desired sound. We apply our system to Xfer Records Serum: currently one of the most popular and complex VST synthesizers used by the audio production community. Our results indicate that SerumRNN is consistently able to provide useful feedback for a variety of different audio effects and synthesizer presets. We demonstrate the benefits of using an iterative system and show that SerumRNN learns to prioritize effects and can discover more efficient effect order sequences than a variety of baselines.      
### 33.Massive Access in Media Modulation Based Massive Machine-Type Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.03874.pdf)
>  The massive machine-type communications (mMTC) paradigm based on media modulation in conjunction with massive MIMO base stations (BSs) is emerging as a viable solution to support the massive connectivity for the future Internet-of-Things, in which the inherent massive access at the BSs poses significant challenges for device activity and data detection (DADD). This paper considers the DADD problem for both uncoded and coded media modulation based mMTC with a slotted access frame structure, where the device activity remains unchanged within one frame. Specifically, due to the slotted access frame structure and the adopted media modulated symbols, the access signals exhibit a doubly structured sparsity in both the time domain and the modulation domain. Inspired by this, a doubly structured approximate message passing (DS-AMP) algorithm is proposed for reliable DADD in the uncoded case. Also, we derive the state evolution of the DS-AMP algorithm to theoretically characterize its performance. As for the coded case, we develop a bit-interleaved coded media modulation scheme and propose an iterative DS-AMP (IDS-AMP) algorithm based on successive inference cancellation (SIC), where the signal components associated with the detected active devices are successively subtracted to improve the data decoding performance. In addition, the channel estimation problem for media modulation based mMTC is discussed and an efficient data-aided channel state information (CSI) update strategy is developed to reduce the training overhead in block fading channels. Finally, simulation results and computational complexity analysis verify the superiority of the proposed algorithms in both uncoded and coded cases. Also, our results verify the validity of the proposed data-aided CSI update strategy.      
### 34.RNN Transducer Models For Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2104.03842.pdf)
>  We present a comprehensive study on building and adapting RNN transducer (RNN-T) models for spoken language understanding(SLU). These end-to-end (E2E) models are constructed in three practical settings: a case where verbatim transcripts are available, a constrained case where the only available annotations are SLU labels and their values, and a more restrictive case where transcripts are available but not corresponding audio. We show how RNN-T SLU models can be developed starting from pre-trained automatic speech recognition (ASR) systems, followed by an SLU adaptation step. In settings where real audio data is not available, artificially synthesized speech is used to successfully adapt various SLU models. When evaluated on two SLU data sets, the ATIS corpus and a customer call center data set, the proposed models closely track the performance of other E2E models and achieve state-of-the-art results.      
### 35.Speech Denoising without Clean Training Data: a Noise2Noise Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.03838.pdf)
>  This paper tackles the problem of the heavy dependence of clean speech data required by deep learning based audio-denoising methods by showing that it is possible to train deep speech denoising networks using only noisy speech samples. Conventional wisdom dictates that in order to achieve good speech denoising performance, there is a requirement for a large quantity of both noisy speech samples and perfectly clean speech samples, resulting in a need for expensive audio recording equipment and extremely controlled soundproof recording studios. These requirements pose significant challenges in data collection, especially in economically disadvantaged regions and for low resource languages. This work shows that speech denoising deep neural networks can be successfully trained utilizing only noisy training audio. Furthermore it is revealed that such training regimes achieve superior denoising performance over conventional training regimes utilizing clean training audio targets, in cases involving complex noise distributions and low Signal-to-Noise ratios (high noise environments). This is demonstrated through experiments studying the efficacy of our proposed approach over both real-world noises and synthetic noises using the 20 layered Deep Complex U-Net architecture.      
### 36.Exploring Machine Speech Chain for Domain Adaptation and Few-Shot Speaker Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2104.03815.pdf)
>  Machine Speech Chain, which integrates both end-to-end (E2E) automatic speech recognition (ASR) and text-to-speech (TTS) into one circle for joint training, has been proven to be effective in data augmentation by leveraging large amounts of unpaired data. In this paper, we explore the TTS-&gt;ASR pipeline in speech chain to do domain adaptation for both neural TTS and E2E ASR models, with only text data from target domain. We conduct experiments by adapting from audiobook domain (LibriSpeech) to presentation domain (TED-LIUM), there is a relative word error rate (WER) reduction of 10% for the E2E ASR model on the TED-LIUM test set, and a relative WER reduction of 51.5% in synthetic speech generated by neural TTS in the presentation domain. Further, we apply few-shot speaker adaptation for the E2E ASR by using a few utterances from target speakers in an unsupervised way, results in additional gains.      
### 37.Multi-Objective Optimization of a Path-following MPC for Vehicle Guidance: A Bayesian Optimization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.03773.pdf)
>  This paper tackles the multi-objective optimization of the cost functional of a path-following model predictive control for vehicle longitudinal and lateral control. While the inherent optimal character of the model predictive control and the direct consideration of constraints gives a very powerful tool for many applications, is the determination of an appropriate cost functional a non-trivial task. This results on the one hand from the number of degrees of freedom or the multitude of adjustable parameters and on the other hand from the coupling of these. To overcome this situation a Bayesian optimization procedure is present, which gives the possibility to determine optimal cost functional parameters for a given desire. Moreover, a Pareto-front for a whole set of possible configurations can be computed.      
### 38.Detection of Message Injection Attacks onto theCAN Bus using Similarity of SuccessiveMessages-Sequence Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2104.03763.pdf)
>  The smart features of modern cars are enabled by a number of Electronic Control Units (ECUs) components that communicate through an in-vehicle network, known as Controller Area Network (CAN) bus. The fundamental challenge is the security of the communication link where an attacker can inject messages (e.g., increase the speed) that may impact the safety of the driver. Developing an effective defensive security solution depends on the knowledge of the identity of the ECUs, which is proprietary information. This paper proposes a message injection attack detection mechanism that is independent of the IDs of the ECUs, which is achieved by capturing the patterns in the message sequences. First, we represent the sequencing ofther messages in a given time-interval as a direct graph and compute the similarities of the successive graphs using the cosine similarity and Pearson correlation. Then, we apply threshold, change point detection, and Long Short-Term Memory (LSTM)-Recurrent NeuralNetwork (RNN) to detect and predict malicious message injections into the CAN bus. The evaluation of the methods using a dataset collected from a moving vehicle under malicious RPM and speed reading message injections show a detection accuracy of 98.45% when using LSTM-RNN and 97.32% when using a threshold method. Further, the pace of detecting the change isfast for the case of injection of RPM reading messagesbut slow for the case of injection of speed readingsmessages.      
### 39.On tuning consistent annealed sampling for denoising score matching  [ :arrow_down: ](https://arxiv.org/pdf/2104.03725.pdf)
>  Score-based generative models provide state-of-the-art quality for image and audio synthesis. Sampling from these models is performed iteratively, typically employing a discretized series of noise levels and a predefined scheme. In this note, we first overview three common sampling schemes for models trained with denoising score matching. Next, we focus on one of them, consistent annealed sampling, and study its hyper-parameter boundaries. We then highlight a possible formulation of such hyper-parameter that explicitly considers those boundaries and facilitates tuning when using few or a variable number of steps. Finally, we highlight some connections of the formulation with other sampling schemes.      
### 40.Optimal Resource Allocation for Full-Duplex IoT Systems Underlaying Cellular Networks with Mutual SIC NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2104.03720.pdf)
>  Device-to-device (D2D) and non-orthogonal multiple access (NOMA) are promising technologies to meet the challenges of the next generations of mobile communications in terms of network density and diversity for internet of things (IoT) services. This paper tackles the problem of maximizing the D2D sum-throughput in an IoT system underlaying a cellular network, through optimal channel and power allocation. NOMA is used to manage the interference between cellular users and full-duplex (FD) IoT devices. To this aim, mutual successive interference cancellation (SIC) conditions are identified to allow simultaneously the removal of the D2D devices interference at the level of the base station and the removal of the cellular users (CU) interference at the level of D2D devices. To optimally solve the joint channel and power allocation (PA) problem, a time-efficient solution of the PA problem in the FD context is elaborated. By means of graphical representation, the complex non-convex PA problem is efficiently solved in constant time complexity. This enables the global optimal resolution by successively solving the separate PA and channel assignment problems. The performance of the proposed strategy is compared against the classical state-of-the-art FD and HD scenarios, where SIC is not applied between CUs and IoT devices. The results show that important gains can be achieved by applying mutual SIC NOMA in the IoT-cellular context, in either HD or FD scenarios.      
### 41.Contextual Semi-Supervised Learning: An Approach To Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.03643.pdf)
>  Air traffic management and specifically air-traffic control (ATC) rely mostly on voice communications between Air Traffic Controllers (ATCos) and pilots. In most cases, these voice communications follow a well-defined grammar that could be leveraged in Automatic Speech Recognition (ASR) technologies. The callsign used to address an airplane is an essential part of all ATCo-pilot communications. We propose a two-steps approach to add contextual knowledge during semi-supervised training to reduce the ASR system error rates at recognizing the part of the utterance that contains the callsign. Initially, we represent in a WFST the contextual knowledge (i.e. air-surveillance data) of an ATCo-pilot communication. Then, during Semi-Supervised Learning (SSL) the contextual knowledge is added by second-pass decoding (i.e. lattice re-scoring). Results show that `unseen domains' (e.g. data from airports not present in the supervised training data) are further aided by contextual SSL when compared to standalone SSL. For this task, we introduce the Callsign Word Error Rate (CA-WER) as an evaluation metric, which only assesses ASR performance of the spoken callsign in an utterance. We obtained a 32.1% CA-WER relative improvement applying SSL with an additional 17.5% CA-WER improvement by adding contextual knowledge during SSL on a challenging ATC-based test set gathered from LiveATC.      
### 42.CineMPC: Controlling Camera Intrinsics and Extrinsics for Autonomous Cinematography  [ :arrow_down: ](https://arxiv.org/pdf/2104.03634.pdf)
>  We present CineMPC, an algorithm to autonomously control a UAV-borne video camera in a nonlinear MPC loop. CineMPC controls both the position and orientation of the camera-the camera extrinsics-as well as the lens focal length, focal distance, and aperture-the camera intrinsics. While some existing solutions autonomously control the position and orientation of the camera, no existing solutions also control the intrinsic parameters, which are essential tools for rich cinematographic expression. The intrinsic parameters control the parts of the scene that are focused or blurred, and the viewers' perception of depth in the scene. Cinematographers commonly use the camera intrinsics to direct the viewers' attention through the use of focus, to convey suspense through telephoto views, inspire awe through wide-angle views, and generally to convey an emotionally rich viewing experience. Our algorithm can use any existing approach to detect the subjects in the scene, and tracks those subjects throughout a user-specified desired camera trajectory that includes camera intrinsics. CineMPC closes the loop from camera images to UAV trajectory in order to follow the desired relative trajectory as the subjects move through the scene. The cinematographer can use CineMPC to autonomously record scenes using the full array of cinematographic tools for artistic expression.      
### 43.Half-Truth: A Partially Fake Audio Detection Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2104.03617.pdf)
>  Diverse promising datasets have been designed to hold back the development of fake audio detection, such as ASVspoof databases. However, previous datasets ignore an attacking situation, in which the hacker hides some small fake clips in real speech audio. This poses a serious threat since that it is difficult to distinguish the small fake clip from the whole speech utterance. Therefore, this paper develops such a dataset for half-truth audio detection (HAD). Partially fake audio in the HAD dataset involves only changing a few words in an utterance.The audio of the words is generated with the very latest state-of-the-art speech synthesis technology. We can not only detect fake uttrances but also localize manipulated regions in a speech using this dataset. Some benchmark results are presented on this dataset. The results show that partially fake audio presents much more challenging than fully fake audio for fake audio detection.      
### 44.AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario  [ :arrow_down: ](https://arxiv.org/pdf/2104.03603.pdf)
>  In this paper, we present AISHELL-4, a sizable real-recorded Mandarin speech dataset collected by 8-channel circular microphone array for speech processing in conference scenario. The dataset consists of 211 recorded meeting sessions, each containing 4 to 8 speakers, with a total length of 118 hours. This dataset aims to bride the advanced research on multi-speaker processing and the practical application scenario in three aspects. With real recorded meetings, AISHELL-4 provides realistic acoustics and rich natural speech characteristics in conversation such as short pause, speech overlap, quick speaker turn, noise, etc. Meanwhile, the accurate transcription and speaker voice activity are provided for each meeting in AISHELL-4. This allows the researchers to explore different aspects in meeting processing, ranging from individual tasks such as speech front-end processing, speech recognition and speaker diarization, to multi-modality modeling and joint optimization of relevant tasks. Given most open source dataset for multi-speaker tasks are in English, AISHELL-4 is the only Mandarin dataset for conversation speech, providing additional value for data diversity in speech community.      
### 45.WNARS: WFST based Non-autoregressive Streaming End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.03587.pdf)
>  Recently, attention-based encoder-decoder (AED) end-to-end (E2E) models have drawn more and more attention in the field of automatic speech recognition (ASR). AED models, however, still have drawbacks when deploying in commercial applications. Autoregressive beam search decoding makes it inefficient for high-concurrency applications. It is also inconvenient to integrate external word-level language models. The most important thing is that AED models are difficult for streaming recognition due to global attention mechanism. In this paper, we propose a novel framework, namely WNARS, using hybrid CTC-attention AED models and weighted finite-state transducers (WFST) to solve these problems together. We switch from autoregressive beam search to CTC branch decoding, which performs first-pass decoding with WFST in chunk-wise streaming way. The decoder branch then performs second-pass rescoring on the generated hypotheses non-autoregressively. On the AISHELL-1 task, our WNARS achieves a character error rate of 5.22% with 640ms latency, to the best of our knowledge, which is the state-of-the-art performance for online ASR. Further experiments on our 10,000-hour Mandarin task show the proposed method achieves more than 20% improvements with 50% latency compared to a strong TDNN-BLSTM lattice-free MMI baseline.      
### 46.Attack-Resilient Weighted $\ell_1$ Observer with Prior Pruning  [ :arrow_down: ](https://arxiv.org/pdf/2104.03580.pdf)
>  Security related questions for Cyber Physical Systems (CPS) have attracted much research attention in searching for novel methods for attack-resilient control and/or estimation. Specifically, false data injection attacks (FDIAs) have been shown to be capable of bypassing bad data detection (BDD), while arbitrarily compromising the integrity of state estimators and robust controller even with very sparse measurements corruption. Moreover, based on the inherent sparsity of pragmatic attack signals, $\ell_1$-minimization scheme has been used extensively to improve the design of attack-resilient estimators. For this, the theoretical maximum for the percentage of compromised nodes that can be accommodated has been shown to be $50\%$. In order to guarantee correct state recoveries for larger percentage of attacked nodes, researchers have begun to incorporate prior information into the underlying resilient observer design framework. For the most pragmatic cases, this prior information is often obtained through some data-driven machine learning process. Existing results have shown strong positive correlation between the tolerated attack percentages and the precision of the prior information. In this paper, we present a pruning method to improve the precision of the prior information, given corresponding stochastic uncertainty characteristics of the underlying machine learning model. Then a weighted $\ell_1$-minimization is proposed based on the pruned prior. The theoretical and simulation results show that the pruning method significantly improves the observer performance for much larger attack percentages, even when moderately accurate machine learning model used.      
### 47.MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.03538.pdf)
>  The discrepancy between the cost function used for training a speech enhancement model and human auditory perception usually makes the quality of enhanced speech unsatisfactory. Objective evaluation metrics which consider human perception can hence serve as a bridge to reduce the gap. Our previously proposed MetricGAN was designed to optimize objective metrics by connecting the metric with a discriminator. Because only the scores of the target evaluation functions are needed during training, the metrics can even be non-differentiable. In this study, we propose a MetricGAN+ in which three training techniques incorporating domain-knowledge of speech processing are proposed. With these techniques, experimental results on the VoiceBank-DEMAND dataset show that MetricGAN+ can increase PESQ score by 0.3 compared to the previous MetricGAN and achieve state-of-the-art results (PESQ score = 3.15).      
### 48.Towards Multi-Scale Style Control for Expressive Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2104.03521.pdf)
>  This paper introduces a multi-scale speech style modeling method for end-to-end expressive speech synthesis. The proposed method employs a multi-scale reference encoder to extract both the global-scale utterance-level and the local-scale quasi-phoneme-level style features of the target speech, which are then fed into the speech synthesis model as an extension to the input phoneme sequence. During training time, the multi-scale style model could be jointly trained with the speech synthesis model in an end-to-end fashion. By applying the proposed method to style transfer task, experimental results indicate that the controllability of the multi-scale speech style model and the expressiveness of the synthesized speech are greatly improved. Moreover, by assigning different reference speeches to extraction of style on each scale, the flexibility of the proposed method is further revealed.      
### 49.Py-Feat: Python Facial Expression Analysis Toolbox  [ :arrow_down: ](https://arxiv.org/pdf/2104.03509.pdf)
>  Studying facial expressions is a notoriously difficult endeavor. Recent advances in the field of affective computing have yielded impressive progress in automatically detecting facial expressions from pictures and videos. However, much of this work has yet to be widely disseminated in social science domains such as psychology. Current state of the art models require considerable domain expertise that is not traditionally incorporated into social science training programs. Furthermore, there is a notable absence of user-friendly and open-source software that provides a comprehensive set of tools and functions that support facial expression research. In this paper, we introduce Py-Feat, an open-source Python toolbox that provides support for detecting, preprocessing, analyzing, and visualizing facial expression data. Py-Feat makes it easy for domain experts to disseminate and benchmark computer vision models and also for end users to quickly process, analyze, and visualize face expression data. We hope this platform will facilitate increased use of facial expression data in human behavior research.      
### 50.Emotion Recognition from Speech Using Wav2vec 2.0 Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2104.03502.pdf)
>  Emotion recognition datasets are relatively small, making the use of the more sophisticated deep learning approaches challenging. In this work, we propose a transfer learning method for speech emotion recognition where features extracted from pre-trained wav2vec 2.0 models are modeled using simple neural networks. We propose to combine the output of several layers from the pre-trained model using trainable weights which are learned jointly with the downstream model. Further, we compare performance using two different wav2vec 2.0 models, with and without finetuning for speech recognition. We evaluate our proposed approaches on two standard emotion databases IEMOCAP and RAVDESS, showing superior performance compared to results in the literature.      
### 51.Centrality-Weighted Opinion Dynamics: Disagreement and Social Network Partition  [ :arrow_down: ](https://arxiv.org/pdf/2104.03485.pdf)
>  This paper proposes a network model of opinion dynamics based on both the social network structure and network centralities. The conceptual novelty in this model is that the opinion of each individual is weighted by the associated network centrality in characterizing the opinion spread on social networks. Following a degree-centrality-weighted opinion dynamics model, we provide an algorithm to partition nodes of any graph into two and multiple clusters based on opinion disagreements. Furthermore, the partition algorithm is applied to real-world social networks including the Zachary karate club network [1] and the southern woman network [2] and these application examples indirectly verify the effectiveness of the degree-centrality-weighted opinion dynamics model. Finally, properties of general centrality-weighted opinion dynamics model are established.      
### 52.One-bit Spectrum Sensing with the Eigenvalue Moment Ratio Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.03481.pdf)
>  One-bit analog-to-digital converter (ADC), performing signal sampling as an extreme simple comparator, is an overwhelming technology for spectrum sensing due to its low-cost, low-power consumptions and high sampling rate. In this letter, we propose a novel one-bit sensing approach based on the eigenvalue moment ratio (EMR), which has been proved to be highly efficient for conventional multi-antenna spectrum sensing in $\infty$-bit situation. Particularly, we determine the asymptotic distribution of one-bit EMR under null hypothesis via the central limited theorem (CLT), allowing us to perform spectrum sensing with one-bit samples directly. Theoretical and simulation analysis show the new approach can provide reasonably good sensing performance at a low hardware cost.      
### 53.Learning Graph Structures with Transformer for Multivariate Time Series Anomaly Detection in IoT  [ :arrow_down: ](https://arxiv.org/pdf/2104.03466.pdf)
>  Many real-world IoT systems comprising various internet-connected sensory devices generate substantial amounts of multivariate time series data. Meanwhile, those critical IoT infrastructures, such as smart power grids and water distribution networks, are often targets of cyber-attacks, making anomaly detection of high research value. However, considering the complex topological and nonlinear dependencies that are initially unknown among sensors, modeling such relatedness is inevitable for any efficient and accurate anomaly detection system. Additionally, due to multivariate time series' temporal dependency and stochasticity, their anomaly detection remains a big challenge. This work proposed a novel framework, namely GTA, for multivariate time series anomaly detection by automatically learning a graph structure followed by the graph convolution and modeling the temporal dependency through a Transformer-based architecture. The core idea of learning graph structure is called the connection learning policy based on the Gumbel-softmax sampling strategy to learn bi-directed associations among sensors directly. We also devised a novel graph convolution named Influence Propagation convolution to model the anomaly information flow between graph nodes. Moreover, we proposed a multi-branch attention mechanism to substitute for original multi-head self-attention to overcome the quadratic complexity challenge. The extensive experiments on four public anomaly detection benchmarks further demonstrate our approach's superiority over other state-of-the-arts.      
### 54.Securing NOMA Networks by Exploiting Intelligent Reflecting Surface  [ :arrow_down: ](https://arxiv.org/pdf/2104.03460.pdf)
>  This paper investigates the security enhancement of an intelligent reflecting surface (IRS) assisted non-orthogonal multiple access (NOMA) network, where a base station (BS) serves users securely in the assistance of distributed IRSs. Considering that eavesdropper's instantaneous channel state information (CSI) is challenging to acquire in practice, we utilize secrecy outage probability (SOP) as the security metric. A problem of maximizing the minimum secrecy rate among users, by jointly optimizing transmit beamforming of base station (BS) and phase shifts at IRSs, is formulated. For special case with a single-antenna BS, we derive the closed-form SOP expressions and propose a novel ring-penalty based successive convex approximation (SCA) algorithm to design power allocation and phase shifts jointly. While for general case with a multi-antenna BS, we develop a Bernstein-type inequality based alternating optimization (AO) algorithm to solve the challenging problem. Numerical results validate the advantages of the proposed algorithms over the baseline schemes. Particularly, we reveal that: 1) the secrecy rate peak is achieved only when distributed IRSs share the reflecting elements equally; 2) the distributed IRS deployment does not always outperform the centralized IRS deployment, due to the tradeoff between the number of IRSs and the reflecting elements equipped at each IRS.      
### 55.Heuristic Strategies for Solving Complex Interacting Large-Scale Stockpile Blending Problems  [ :arrow_down: ](https://arxiv.org/pdf/2104.03440.pdf)
>  The Stockpile blending problem is an important component of mine production scheduling, where stockpiles are used to store and blend raw material. The goal of blending material from stockpiles is to create parcels of concentrate which contain optimal metal grades based on the material available. The volume of material that each stockpile provides to a given parcel is dependent on a set of mine schedule conditions and customer demands. Therefore, the problem can be formulated as a continuous optimization problem. In the real-world application, there are several constraints required to guarantee parcels that meet the demand of downstream customers. It is a challenge in solving the stockpile blending problems since its scale can be very large. We introduce two repaired operators for the problems to convert the infeasible solutions into the solutions without violating the two tight constraints. Besides, we introduce a multi-component fitness function for solving the large-scale stockpile blending problem which can maximize the volume of metal over the plan and maintain the balance between stockpiles according to the usage of metal. Furthermore, we investigate the well-known approach in this paper, which is used to solve optimization problems over continuous space, namely the differential evolution (DE) algorithm. The experimental results show that the DE algorithm combined with two proposed duration repair methods is significantly better in terms of the values of results than the results on real-world instances for both one-month problems and large-scale problems.      
### 56.Semi-supervised on-device neural network adaptation for remote and portable laser-induced breakdown spectroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2104.03439.pdf)
>  Laser-induced breakdown spectroscopy (LIBS) is a popular, fast elemental analysis technique used to determine the chemical composition of target samples, such as in industrial analysis of metals or in space exploration. Recently, there has been a rise in the use of machine learning (ML) techniques for LIBS data processing. However, ML for LIBS is challenging as: (i) the predictive models must be lightweight since they need to be deployed in highly resource-constrained and battery-operated portable LIBS systems; and (ii) since these systems can be remote, the models must be able to self-adapt to any domain shift in input distributions which could be due to the lack of different types of inputs in training data or dynamic environmental/sensor noise. This on-device retraining of model should not only be fast but also unsupervised due to the absence of new labeled data in remote LIBS systems. We introduce a lightweight multi-layer perceptron (MLP) model for LIBS that can be adapted on-device without requiring labels for new input data. It shows 89.3% average accuracy during data streaming, and up to 2.1% better accuracy compared to an MLP model that does not support adaptation. Finally, we also characterize the inference and retraining performance of our model on Google Pixel2 phone.      
### 57.Monitoring Social-distance in Wide Areas during Pandemics: a Density Map and Segmentation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.03361.pdf)
>  With the relaxation of the containment measurements around the globe, monitoring the social distancing in crowded public places is of grate importance to prevent a new massive wave of COVID-19 infections. Recent works in that matter have limited themselves by detecting social distancing in corridors up to small crowds by detecting each person individually considering the full body in the image. In this work, we propose a new framework for monitoring the social-distance using end-to-end Deep Learning, to detect crowds violating the social-distance in wide areas where important occlusions may be present. Our framework consists in the creation of a new ground truth based on the ground truth density maps and the proposal of two different solutions, a density-map-based and a segmentation-based, to detect the crowds violating the social-distance constrain. We assess the results of both approaches by using the generated ground truth from the PET2009 and CityStreet datasets. We show that our framework performs well at providing the zones where people are not following the social-distance even when heavily occluded or far away from one camera.      
