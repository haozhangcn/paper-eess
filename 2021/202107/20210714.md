# ArXiv eess --Wed, 14 Jul 2021
### 1.Attention based CNN-LSTM Network for Pulmonary Embolism Prediction on Chest Computed Tomography Pulmonary Angiograms  [ :arrow_down: ](https://arxiv.org/pdf/2107.06276.pdf)
>  With more than 60,000 deaths annually in the United States, Pulmonary Embolism (PE) is among the most fatal cardiovascular diseases. It is caused by an artery blockage in the lung; confirming its presence is time-consuming and is prone to over-diagnosis. The utilization of automated PE detection systems is critical for diagnostic accuracy and efficiency. In this study we propose a two-stage attention-based CNN-LSTM network for predicting PE, its associated type (chronic, acute) and corresponding location (leftsided, rightsided or central) on computed tomography (CT) examinations. We trained our model on the largest available public Computed Tomography Pulmonary Angiogram PE dataset (RSNA-STR Pulmonary Embolism CT (RSPECT) Dataset, N=7279 CT studies) and tested it on an in-house curated dataset of N=106 studies. Our framework mirrors the radiologic diagnostic process via a multi-slice approach so that the accuracy and pathologic sequela of true pulmonary emboli may be meticulously assessed, enabling physicians to better appraise the morbidity of a PE when present. Our proposed method outperformed a baseline CNN classifier and a single-stage CNN-LSTM network, achieving an AUC of 0.95 on the test set for detecting the presence of PE in the study.      
### 2.Attention-Guided Progressive Neural Texture Fusion for High Dynamic Range Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2107.06211.pdf)
>  High Dynamic Range (HDR) imaging via multi-exposure fusion is an important task for most modern imaging platforms. In spite of recent developments in both hardware and algorithm innovations, challenges remain over content association ambiguities caused by saturation, motion, and various artifacts introduced during multi-exposure fusion such as ghosting, noise, and blur. In this work, we propose an Attention-guided Progressive Neural Texture Fusion (APNT-Fusion) HDR restoration model which aims to address these issues within one framework. An efficient two-stream structure is proposed which separately focuses on texture feature transfer over saturated regions and multi-exposure tonal and texture feature fusion. A neural feature transfer mechanism is proposed which establishes spatial correspondence between different exposures based on multi-scale VGG features in the masked saturated HDR domain for discriminative contextual clues over the ambiguous image areas. A progressive texture blending module is designed to blend the encoded two-stream features in a multi-scale and progressive manner. In addition, we introduce several novel attention mechanisms, i.e., the motion attention module detects and suppresses the content discrepancies among the reference images; the saturation attention module facilitates differentiating the misalignment caused by saturation from those caused by motion; and the scale attention module ensures texture blending consistency between different coder/decoder scales. We carry out comprehensive qualitative and quantitative evaluations and ablation studies, which validate that these novel modules work coherently under the same framework and outperform state-of-the-art methods.      
### 3.Learning Coded Apertures for Time-Division Multiplexing Light Field Display  [ :arrow_down: ](https://arxiv.org/pdf/2107.06205.pdf)
>  Conventional stereoscopic displays suffer from vergence-accommodation conflict which cause visual fatigue. Integral imaging-based (II) displays resolves this problem by directly projecting light field sub-views into the eye using microlens arrays. However, II-based light field displays has inherent trade-off between angular and spatial resolutions. In this paper, we propose a novel display concept called coded time-division light field display (C-TDM-LFD), which projects encoded light field sub-views to the viewers' eyes, offering correct cues for vergence-accommodation reflex. By jointly optimizing display inputs and pattern of coded apertures, our pipeline can render high resolution refocused images from sparse light field sub-views with minimal aliasing effects. By simulating light transport and image formation with Fourier optics, we can learn display inputs and coded aperture patterns via deep learning in an end-to-end fashion. To our knowledge, we are among the first to optimize the light field display pipeline with deep learning. We verify our concept with objective image quality metrics (PSNR, SSIM) and optics software simulation, and perform extensive studies on the various customizable design variables in our display pipeline. Experiments results show that our method can generate refocused images with higher quality both quantitatively and qualitatively compared to baseline display designs.      
### 4.A new method for vehicle system safety design based on data mining with uncertainty modeling  [ :arrow_down: ](https://arxiv.org/pdf/2107.06185.pdf)
>  In this research, a new data mining-based design approach has been developed for designing complex mechanical systems such as a crashworthy passenger car with uncertainty modeling. The method allows exploring the big crash simulation dataset to design the vehicle at multi-levels in a top-down manner (main energy absorbing system, components, and geometric features) and derive design rules based on the whole vehicle body safety requirements to make decisions towards the component and sub-component level design. Full vehicle and component simulation datasets are mined to build decision trees, where the interrelationship among parameters can be revealed and the design rules are derived to produce designs with good performance. This method has been extended by accounting for the uncertainty in the design variables. A new decision tree algorithm for uncertain data (DTUD) is developed to produce the desired designs and evaluate the design performance variations due to the uncertainty in design variables. The framework of this method is implemented by combining the design of experiments (DOE) and crash finite element analysis (FEA) and then demonstrated by designing a passenger car subject to front impact. The results show that the new methodology could achieve the design objectives efficiently and effectively. By applying the new method, the reliability of the final designs is also increased greatly. This approach has the potential to be applied as a general design methodology for a wide range of complex structures and mechanical systems.      
### 5.AI Algorithm for Mode Classification of PCF SPR Sensor Design  [ :arrow_down: ](https://arxiv.org/pdf/2107.06184.pdf)
>  Photonic Crystal Fiber design based on surface plasmon resonance phenomenon (PCF SPR) is optimized before it is fabricated for a particular application. An artificial intelligence algorithm is evaluated here to increase the ease of the simulation process for common users. COMSOL MultiPhysics is used. The algorithm suggests best among eight standard machine learning and one deep learning model to automatically select the desired mode, chosen visually by the experts otherwise. Total seven performance indices: namely Precision, Recall, Accuracy, F1-Score, Specificity, Matthew correlation coefficient, are utilized to make the optimal decision. Robustness towards variations in sensor geometry design is also considered as an optimal parameter. Several PCF-SPR based Photonic sensor designs are tested, and a large range optimal (based on phase matching) design is proposed. For this design algorithm has selected Support Vector Machine (SVM) as the best option with an accuracy of 96%, F1-Score is 95.83%, and MCC of 92.30%. The average sensitivity of the proposed sensor design with respect to change in refractive index (1.37-1.41) is 5500 nm/RIU. Resolution is 2.0498x10^(-5) RIU^(-1). The algorithm can be integrated into commercial software as an add-on or as a module in academic codes. The proposed novel step has saved approximately 75 minutes in the overall design process. The present work is equally applicable for mode selection of sensor other than PCF-SPR sensing geometries.      
### 6.A Self-Regulated and Reconfigurable CMOS Physically Unclonable Function Featuring Zero-Overhead Stabilization  [ :arrow_down: ](https://arxiv.org/pdf/2107.06183.pdf)
>  This article presents a reconfigurable physically unclonable function (PUF) design fabricated using 65-nm CMOS technology. A subthreshold-inverter-based static PUF cell achieves 0.3% native bit error rate (BER) at 0.062-fJ per bit core energy efficiency. A flexible, native transistor-based voltage regulation scheme achieves low-overhead supply regulation with 6-mV/V line sensitivity, making the PUF resistant against voltage variations. Additionally, the PUF cell is designed to be reconfigurable with no area overhead, which enables stabilization without redundancy on chip. Thanks to the highly stable and self-regulated PUF cell and the zero-overhead stabilization scheme, a 0.00182% native BER is obtained after reconfiguration. The proposed design shows 0.12%/10 °C and 0.057%/0.1-V bit error across the military-grade temperature range from -55 °C to 125 °C and supply voltage variation from 0.7 to 1.4 V. The total energy per bit is 15.3 fJ. Furthermore, the unstable bits can be detected by sweeping the body bias instead of temperature during enrollment, thereby significantly reducing the testing costs. Last but not least, the prototype exhibits almost ideal uniqueness and randomness, with a mean inter-die Hamming distance (HD) of 0.4998 and a 1020x inter-/intra-die HD separation. It also passes both NIST 800-22 and 800-90B randomness tests.      
### 7.Intermittent Jamming against Telemetry and Telecommand of Satellite Systems and A Learning-driven Detection Strategy  [ :arrow_down: ](https://arxiv.org/pdf/2107.06181.pdf)
>  Towards sixth-generation networks (6G), satellite communication systems, especially based on Low Earth Orbit (LEO) networks, become promising due to their unique and comprehensive capabilities. These advantages are accompanied by a variety of challenges such as security vulnerabilities, management of hybrid systems, and high mobility. In this paper, firstly, a security deficiency in the physical layer is addressed with a conceptual framework, considering the cyber-physical nature of the satellite systems, highlighting the potential attacks. Secondly, a learning-driven detection scheme is proposed, and the lightweight convolutional neural network (CNN) is designed. The performance of the designed CNN architecture is compared with a prevalent machine learning algorithm, support vector machine (SVM). The results show that deficiency attacks against the satellite systems can be detected by employing the proposed scheme.      
### 8.Raspberry PI for compact autonomous home farm control  [ :arrow_down: ](https://arxiv.org/pdf/2107.06180.pdf)
>  This manuscript presented an autonomous home farm for predicting metrological characteristics that can not only automate the process of growing crops but also, due to a neural network, significantly increase the productivity of the farm. The developed farm monitors and manages the following indicators: illumination, soil PH, air temperature, ground temperature, air humidity, CO2 concentration, and soil moisture. The presented farm can also be considered as a device for testing various weather conditions to determine the optimal temperature characteristics for different crops. This farm as a result is completely autonomous grows tomatoes at home.      
### 9.A Survey of Applications of Artificial Intelligence for Myocardial Infarction Disease Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2107.06179.pdf)
>  Myocardial infarction disease (MID) is caused to the rapid progress of undiagnosed coronary artery disease (CAD) that indicates the injury of a heart cell by decreasing the blood flow to the cardiac muscles. MID is the leading cause of death in middle-aged and elderly subjects all over the world. In general, raw Electrocardiogram (ECG) signals are tested for MID identification by clinicians that is exhausting, time-consuming, and expensive. Artificial intelligence-based methods are proposed to handle the problems to diagnose MID on the ECG signals automatically. Hence, in this survey paper, artificial intelligence-based methods, including machine learning and deep learning, are review for MID diagnosis on the ECG signals. Using the methods demonstrate that the feature extraction and selection of ECG signals required to be handcrafted in the ML methods. In contrast, these tasks are explored automatically in the DL methods. Based on our best knowledge, Deep Convolutional Neural Network (DCNN) methods are highly required methods developed for the early diagnosis of MID on the ECG signals. Most researchers have tended to use DCNN methods, and no studies have surveyed using artificial intelligence methods for MID diagnosis on the ECG signals.      
### 10.An Ecological Robustness-Oriented Approach for Power System Network Expansion  [ :arrow_down: ](https://arxiv.org/pdf/2107.06178.pdf)
>  Electric power grids are critical infrastructure that support modern society by supplying electric energy to critical infrastructure systems. Incidents are increasing that range from natural disasters to cyber attacks. These incidents threaten the reliability of power systems and create disturbances that affect the whole society. While existing standards and technologies are being applied to proactively improve power system reliability and resilience, there are still widespread electricity outages that cause billions of dollars in economic loss annually and threaten societal function and safety. Improving resilience in preparation for such events warrants strategic network design to harden the system. This paper presents an approach to strengthen power system security and reliability against disturbances by expanding the network structure from an ecosystems perspective. <br>Ecosystems have survived a wide range of disturbances over a long time period, and an ecosystem's robust structure has been identified as the key element for its survivability. In this paper, we first present a study of the correlation of ecological robustness and power system structures. Then, we present a mixed-integer nonlinear programming problem (MINLP) that expands the transmission network structure to maximize ecological robustness with power system constraints for an improved ability to absorb disturbances. We solve the MINLP problem for the IEEE 24 Bus Reliability Test System and three synthetic power grids with 200-, 500- and 2000-buses, respectively. Our evaluation results show the optimized power systems have increased the network's robustness, more equally distributed power flows, and less violations under different levels of contingencies.      
### 11.Impedance-based Capacity Estimation for Lithium-Ion Batteries Using Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.06177.pdf)
>  This paper proposes a fully unsupervised methodology for the reliable extraction of latent variables representing the characteristics of lithium-ion batteries (LIBs) from electrochemical impedance spectroscopy (EIS) data using information maximizing generative adversarial networks. Meaningful representations can be obtained from EIS data even when measured with direct current and without relaxation, which are difficult to express when using circuit models. The extracted latent variables were investigated as capacity degradation progressed and were used to estimate the discharge capacity of the batteries by employing Gaussian process regression. The proposed method was validated under various conditions of EIS data during charging and discharging. The results indicate that the proposed model provides more robust capacity estimations than the direct capacity estimations obtained from EIS. We demonstrate that the latent variables extracted from the EIS data measured with direct current and without relaxation reliably represent the degradation characteristics of LIBs.      
### 12.K-Nearest Neighbors based Shock Advice Algorithm for Automated External Defibrillators  [ :arrow_down: ](https://arxiv.org/pdf/2107.06176.pdf)
>  Shockable rhythms, namely ventricular fibrillation and ventricular tachycardia, are the main cause of sudden cardiac arrests, which can be detected quickly by the automated external defibrillator (AED) devices. In this paper, a simple but effective algorithm is proposed as the shock advice algorithm applied in AED. The proposed algorithm consists of K-nearest neighbor classifier and an optimal set of 36 features, which are extracted from original ECG and shockable, non-shockable signals using modified variational mode decomposition technique. Cross-validation procedure and sequential forward feature selection are carefully applied to select an optimal set from entire feature space. The performance results show that the MVMD is the key element for SCA detection performance, and the proposed algorithm is simpler while remaining relatively high detection performance compared to previous publications.      
### 13.Triple Coding Empowered FDMA-CDMA Mode High Security CAOS Camera  [ :arrow_down: ](https://arxiv.org/pdf/2107.06175.pdf)
>  For the first time, the hybrid triple coding empowered Frequency Division Multiple Access (FDMA) Code Division Multiple Access (CDMA) mode of the CAOS (i.e., Coded Access Optical Sensor) camera is demonstrated. Compared to the independent FDMA and CDMA modes, the FDMA-CDMA mode has a novel high security space-time-frequency triple signal encoding design for robust, faster, linear irradiance extraction at a moderately High Dynamic Range (HDR). Specifically, this hybrid mode simultaneously combines the linear HDR strength of the FDMA mode Fast Fourier Transform (FFT) Digital Signal Processing (DSP)-based spectrum analysis with the high Signal to Noise Ratio (SNR) provided by the many simultaneous CAOS pixels photodetection of the CDMA mode. In particular, the demonstrated FDMA CDMA mode with P FDMA channels provides a P times faster camera operation versus the equivalent linear HDR Frequency Modulation (FM)CDMA mode. The active FDMA CDMA mode CAOS camera operation is also demonstrated using P equal to 3 LED light sources, each with its unique optical spectral content driven by its independent FDMA frequency. This illuminated target spectral signature matched active CAOS mode allows simultaneous capture of P images without the use of P time multiplexed slots operation tunable optical filter.      
### 14.National-scale electricity peak load forecasting: Traditional, machine learning, or hybrid model?  [ :arrow_down: ](https://arxiv.org/pdf/2107.06174.pdf)
>  As the volatility of electricity demand increases owing to climate change and electrification, the importance of accurate peak load forecasting is increasing. Traditional peak load forecasting has been conducted through time series-based models; however, recently, new models based on machine or deep learning are being introduced. This study performs a comparative analysis to determine the most accurate peak load-forecasting model for Korea, by comparing the performance of time series, machine learning, and hybrid models. Seasonal autoregressive integrated moving average with exogenous variables (SARIMAX) is used for the time series model. Artificial neural network (ANN), support vector regression (SVR), and long short-term memory (LSTM) are used for the machine learning models. SARIMAX-ANN, SARIMAX-SVR, and SARIMAX-LSTM are used for the hybrid models. The results indicate that the hybrid models exhibit significant improvement over the SARIMAX model. The LSTM-based models outperformed the others; the single and hybrid LSTM models did not exhibit a significant performance difference. In the case of Korea's highest peak load in 2019, the predictive power of the LSTM model proved to be greater than that of the SARIMAX-LSTM model. The LSTM, SARIMAX-SVR, and SARIMAX-LSTM models outperformed the current time series-based forecasting model used in Korea. Thus, Korea's peak load-forecasting performance can be improved by including machine learning or hybrid models.      
### 15.Orthogonal and Non-Orthogonal Signal Representations Using New Transformation Matrices Having NPM Structure  [ :arrow_down: ](https://arxiv.org/pdf/2107.06173.pdf)
>  In this paper, we introduce two types of real-valued sums known as Complex Conjugate Pair Sums (CCPSs) denoted as CCPS$^{(1)}$ and CCPS$^{(2)}$, and discuss a few of their properties. Using each type of CCPSs and their circular shifts, we construct two non-orthogonal Nested Periodic Matrices (NPMs). As NPMs are non-singular, this introduces two non-orthogonal transforms known as Complex Conjugate Periodic Transforms (CCPTs) denoted as CCPT$^{(1)}$ and CCPT$^{(2)}$. We propose another NPM, which uses both types of CCPSs such that its columns are mutually orthogonal, this transform is known as Orthogonal CCPT (OCCPT). After a brief study of a few OCCPT properties like periodicity, circular shift, etc., we present two different interpretations of it. Further, we propose a Decimation-In-Time (DIT) based fast computation algorithm for OCCPT (termed as FOCCPT), whenever the length of the signal is equal to $2^v,\ v{\in} \mathbb{N}$. The proposed sums and transforms are inspired by Ramanujan sums and Ramanujan Period Transform (RPT). Finally, we show that the period (both divisor and non-divisor) and frequency information of a signal can be estimated using the proposed transforms with a significant reduction in the computational complexity over Discrete Fourier Transform (DFT).      
### 16.Robust Blind Source Separation by Soft Decision-Directed Non-Unitary Joint Diagonalization  [ :arrow_down: ](https://arxiv.org/pdf/2107.06170.pdf)
>  Approximate joint diagonalization of a set of matrices provides a powerful framework for numerous statistical signal processing applications. For non-unitary joint diagonalization (NUJD) based on the least-squares (LS) criterion, outliers, also referred to as anomaly or discordant observations, have a negative influence on the performance, since squaring the residuals magnifies the effects of them. To solve this problem, we propose a novel cost function that incorporates the soft decision-directed scheme into the least-squares algorithm and develops an efficient algorithm. The influence of the outliers is mitigated by applying decision-directed weights which are associated with the residual error at each iterative step. Specifically, the mixing matrix is estimated by a modified stationary point method, in which the updating direction is determined based on the linear approximation to the gradient function. Simulation results demonstrate that the proposed algorithm outperforms conventional non-unitary diagonalization algorithms in terms of both convergence performance and robustness to outliers.      
### 17.Deep Learning Assisted Compact Modeling of Nanoscale Transistor  [ :arrow_down: ](https://arxiv.org/pdf/2107.06167.pdf)
>  Transistors are the basic building blocks for all electronics. Accurate prediction of their current-voltage (IV) characteristics enables circuit simulations before the expensive silicon tape-out. In this work, we propose using deep neural network to improve the accuracy for the conventional, physics-based compact model for nanoscale transistors. Physics-driven requirements on the neural network are discussed. Using finite element simulation as the input dataset, together with a neural network with roughly 30 neurons, the final IV model can well-predict the IV to within 1%. The trained model can readily be implemented by the hardware description language (HDL) such as VerilogA for circuit simulation.      
### 18.Hybrid Beamforming Design for Wideband MmWave Full-Duplex Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.06166.pdf)
>  Full duplex (FD), which allows bidirectional transmission over the same resources, has the potential to reduce latency and double spectral efficiency. Recently, FD has been studied in 5G LTE millimeter wave cellular communications for New Radio in 3GPP releases 15--17. The primary drawback of FD is self-interference (SI). SI arises in the receiver for system 1 because it receives transmissions from itself and system 2. Because system 1 is much closer, SI can be 100-1000x the received power from system 2, thereby severely degrading communication. In this paper, we investigate a FD relay extending mmWave coverage to a single user. We propose to use alternating projections in designing the precoder and combiner to maximize the sum of the uplink and downlink spectral efficiency while bringing the SI below the noise floor. Our contributions include (1) all-digital and hybrid beamforming design algorithms for SI cancellation; and (2) communication performance analysis in terms of spectral efficiency, energy efficiency and outage probability. We compare the proposed algorithms against beam steering, singular value decomposition, and angle search techniques.      
### 19.Adaptive dynamic programming-based adaptive-gain sliding mode tracking control for fixed-wing UAV with disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2107.06151.pdf)
>  This paper proposes an adaptive dynamic programming-based adaptive-gain sliding mode control (ADP-ASMC) scheme for a fixed-wing unmanned aerial vehicle (UAV) with matched and unmatched disturbances. Starting from the dynamic of fixed-wing UAV, the control-oriented model composed of attitude subsystem and airspeed subsystem is established. According to the different issues in two subsystems, two novel adaptive-gain generalized super-twisting (AGST) algorithms are developed to eliminate the effects of disturbances in two subsystems and make the system trajectories tend to the designed integral sliding manifolds (ISMs) in finite time. Then, based on the expected equivalent sliding-mode dynamics, the modified adaptive dynamic programming (ADP) approach with actor-critic (AC) structure is utilized to generate the nearly optimal control laws and achieve the nearly optimal performance of the sliding-mode dynamics. Furthermore, through the Lyapunov stability theorem, the tracking errors and the weight estimation errors of two neural networks (NNs) are all uniformly ultimately bounded (UUB). Finally, comparative simulations demonstrate the superior performance of the proposed control scheme for the fixed-wing UAV.      
### 20.On the Realization of Impulse Invariant Bilinear Volterra Kernels  [ :arrow_down: ](https://arxiv.org/pdf/2107.06144.pdf)
>  As previously shown, the direct extension of the impulse invariance principle to Volterra kernels has to be modified in order to provide a condition for the exact modeling of mixed-signal chains. At first sight this would seem to seriously complicate the otherwise simple discrete-time realization of separable kernels (among which bilinear kernels are of particular importance). We show here, however, that this not the case. By defining a cascade operator, the structure of a generalized impulse invariance can be unveiled, leading to a realization without an inordinate increase in computational complexity.      
### 21.Error Processing of Sparse Identification of Nonlinear Dynamical Systems via $L_\infty$ Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2107.06142.pdf)
>  Sparse identification of nonlinear dynamical systems(SINDy) is a recently presented framework in the reverse engineering field. It soon gains general interests due to its interpretability and efficiency. Error processing, as an important issue in the SINDy framework, yet remains to be an open problem. To date, literature about error processing focuses on data processing methods which aim to improve the accuracy of data. However, the relationship between data and the identification framework is largely ignored. In this paper, error processing is studied from an optimization perspective. In detail, $L_\infty$ approximation is introduced to the objective function in SINDy framework in place of the former $L_2$ approximation. This is especially appropriate for dealing with the derivative approximation error in SINDy because the derivative approximation error has no exact distribution. To verify the effectiveness of $L_\infty$ approximation, identification scenarios with different types of derivative approximation error are tested. The results indicate that $L_\infty$ approximation could become an alternative of $L_2$ approximation especially when lacking prior knowledge of derivative approximation error. The performances of $L_\infty$ approximation and $L_2$ approximation are evaluated in the cases where the measurement noise of system state is considered. Experimental results show that $L_\infty$ approximation has equal performance compared to $L_2$ approximation under the assumption of Gaussian measurement noise, which is promising in applications.      
### 22.A Deep Reinforcement Learning Approach for Traffic Signal Control Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2107.06115.pdf)
>  Inefficient traffic signal control methods may cause numerous problems, such as traffic congestion and waste of energy. Reinforcement learning (RL) is a trending data-driven approach for adaptive traffic signal control in complex urban traffic networks. Although the development of deep neural networks (DNN) further enhances its learning capability, there are still some challenges in applying deep RLs to transportation networks with multiple signalized intersections, including non-stationarity environment, exploration-exploitation dilemma, multi-agent training schemes, continuous action spaces, etc. In order to address these issues, this paper first proposes a multi-agent deep deterministic policy gradient (MADDPG) method by extending the actor-critic policy gradient algorithms. MADDPG has a centralized learning and decentralized execution paradigm in which critics use additional information to streamline the training process, while actors act on their own local observations. The model is evaluated via simulation on the Simulation of Urban MObility (SUMO) platform. Model comparison results show the efficiency of the proposed algorithm in controlling traffic lights.      
### 23.Functional Magnetic Resonance Imaging data augmentation through conditional ICA  [ :arrow_down: ](https://arxiv.org/pdf/2107.06104.pdf)
>  Advances in computational cognitive neuroimaging research are related to the availability of large amounts of labeled brain imaging data, but such data are scarce and expensive to generate. While powerful data generation mechanisms, such as Generative Adversarial Networks (GANs), have been designed in the last decade for computer vision, such improvements have not yet carried over to brain imaging. A likely reason is that GANs training is ill-suited to the noisy, high-dimensional and small-sample data available in functional <a class="link-external link-http" href="http://neuroimaging.In" rel="external noopener nofollow">this http URL</a> this paper, we introduce Conditional Independent Components Analysis (Conditional ICA): a fast functional Magnetic Resonance Imaging (fMRI) data augmentation technique, that leverages abundant resting-state data to create images by sampling from an ICA decomposition. We then propose a mechanism to condition the generator on classes observed with few samples. We first show that the generative mechanism is successful at synthesizing data indistinguishable from observations, and that it yields gains in classification accuracy in brain decoding problems. In particular it outperforms GANs while being much easier to optimize and interpret. Lastly, Conditional ICA enhances classification accuracy in eight datasets without further parameters tuning.      
### 24.Dynamic Modeling and Control of a Two-Reactor Metal Hydride Energy Storage System  [ :arrow_down: ](https://arxiv.org/pdf/2107.06095.pdf)
>  Metal hydrides have been studied for use in energy storage, hydrogen storage, and air-conditioning (A/C) systems. A common architecture for A/C and energy storage systems is two metal hydride reactors connected to each other so that hydrogen can flow between them, allowing for cyclic use of the hydrogen. This paper presents a nonlinear dynamic model and multivariate control strategy of such a system. Each reactor is modelled as a shell-and-tube heat exchanger connected to a circulating fluid, and a compressor drives hydrogen flow between the reactors. We further develop a linear state-space version of this model integrated with a model predictive controller to determine the fluid mass flow rates and compressor pressure difference required to achieve desired heat transfer rates between the metal hydride and the fluid. A series of case studies demonstrates that this controller can track desired heat transfer rates in each reactor, even in the presence of time-varying circulating fluid inlet temperatures, thereby enabling the use of a two-reactor system for energy storage or integration with a heat pump.      
### 25.Fragility curves for power transmission towers in Odisha, India, based on observed damage during 2019 Cyclone Fani  [ :arrow_down: ](https://arxiv.org/pdf/2107.06072.pdf)
>  Lifeline infrastructure systems such as a power transmission network in coastal regions are vulnerable to strong winds generated during tropical cyclones. Understanding the fragility of individual towers is helpful in improving the resilience of such systems. Fragility curves have been developed in the past for some regions, but without considering relevant epistemic uncertainties. Further, risk and resilience studies are best performed using the fragility curves specific to a region. Such studies become particularly important if the region is exposed to cyclones rather frequently. This paper presents the development of fragility curves for high-voltage power transmission towers in the state of Odisha, India, based on macro-level damage data from 2019 cyclone Fani, which was obtained through concerned government offices. Two types of damages were identified, namely, collapse and partial damage. Accordingly, fragility curves for collapse and functionality disruption damage states were developed considering relevant aleatory and epistemic uncertainties. The latter class of uncertainties included that associated with wind speed estimation at a location and the finite sample uncertainty. The most significant contribution in the epistemic uncertainty was due to the wind speed estimation at a location. The median and logarithmic standard deviation for the 50th percentile fragility curve associated with collapse was close to that for the functionality disruption damage state. These curves also compared reasonably well with those reported for similar structures in other parts of the world.      
### 26.Learning based E2E Energy Efficient in Joint Radio and NFV Resource Allocation for 5G and Beyond Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.05991.pdf)
>  In this paper, we propose a joint radio and core resource allocation framework for NFV-enabled networks. In the proposed system model, the goal is to maximize energy efficiency (EE), by guaranteeing end-to-end (E2E) quality of service (QoS) for different service types. To this end, we formulate an optimization problem in which power and spectrum resources are allocated in the radio part. In the core part, the chaining, placement, and scheduling of functions are performed to ensure the QoS of all users. This joint optimization problem is modeled as a Markov decision process (MDP), considering time-varying characteristics of the available resources and wireless channels. A soft actor-critic deep reinforcement learning (SAC-DRL) algorithm based on the maximum entropy framework is subsequently utilized to solve the above MDP. Numerical results reveal that the proposed joint approach based on the SAC-DRL algorithm could significantly reduce energy consumption compared to the case in which R-RA and NFV-RA problems are optimized separately.      
### 27.Combining 3D Image and Tabular Data via the Dynamic Affine Feature Map Transform  [ :arrow_down: ](https://arxiv.org/pdf/2107.05990.pdf)
>  Prior work on diagnosing Alzheimer's disease from magnetic resonance images of the brain established that convolutional neural networks (CNNs) can leverage the high-dimensional image information for classifying patients. However, little research focused on how these models can utilize the usually low-dimensional tabular information, such as patient demographics or laboratory measurements. We introduce the Dynamic Affine Feature Map Transform (DAFT), a general-purpose module for CNNs that dynamically rescales and shifts the feature maps of a convolutional layer, conditional on a patient's tabular clinical information. We show that DAFT is highly effective in combining 3D image and tabular information for diagnosis and time-to-dementia prediction, where it outperforms competing CNNs with a mean balanced accuracy of 0.622 and mean c-index of 0.748, respectively. Our extensive ablation study provides valuable insights into the architectural properties of DAFT. Our implementation is available at <a class="link-external link-https" href="https://github.com/ai-med/DAFT" rel="external noopener nofollow">this https URL</a>.      
### 28.Detecting when pre-trained nnU-Net models fail silently for Covid-19  [ :arrow_down: ](https://arxiv.org/pdf/2107.05975.pdf)
>  Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly.      
### 29.Single-shot structured illumination microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2107.05930.pdf)
>  Structured illumination microscopy (SIM) can double the resolution beyond the light diffraction limit, but it comes at the cost of multiple camera exposures and the heavy computation burden of multiple Fourier transforms. In this paper, we report a novel technique termed single-shot SIM, to overcome these limitations. A multi-task joint deep-learning strategy is proposed. Generative adversative networks (GAN) are employed to generate five structured illumination images based on the single-shot structured illumination image. U-Net is employed to reconstruct the super-resolution image from these six generated images without time-consuming Fourier transform. By imaging a self-assembling DNB array, we experimentally verified that this technique could perform single-shot super-resolution reconstruction comparing favorably with conventional SIM. This single-shot SIM technique may ultimately overcome the limitations of multiple exposures and Fourier transforms and is potentially applied for high-throughput gene sequencing.      
### 30.Dynamic State Estimation for Integrated Natural Gas and Electric Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.05891.pdf)
>  A dynamic state estimation method of integrated natural gas and electric power systems (IGESs) in proposed. Firstly, the coupling model of gas pipeline networks and power systems by gas turbine units (GTUs) is established. Secondly, the Kalman filter based linear DSE model for the IGES is built. The gas density and mass flow rate, as well as the real and imaginary parts of bus voltages are taken as states, which are predicted by the linearized fluid dynamic equations of gases and exponential smoothing techniques. Boundary conditions of pipeline networks are used as supplementary constraints in the system model. At last, the proposed method is applied to an IGES including a 30-node pipeline network and IEEE 39-bus system coupled by two GTUs. Two indexes are used to evaluate the DSE performance under three measurement error conditions, and the results show that the DSE can obtain the accurate dynamic states in different conditions.      
### 31.Minimizing the Risk of Spreading Processes via Surveillance Schedules and Sparse Control  [ :arrow_down: ](https://arxiv.org/pdf/2107.05878.pdf)
>  In this paper, we propose an optimization framework that combines surveillance schedules and sparse control to bound the risk of spreading processes such as epidemics and wildfires. Here, risk is considered the risk of an undetected outbreak, i.e. the product of the probability of an outbreak and the impact of that outbreak, and we can bound or minimize the risk by resource allocation and persistent monitoring schedules. The presented framework utilizes the properties of positive systems and convex optimization to provide scalable algorithms for both surveillance and intervention purposes. We demonstrate with different spreading process examples how the method can incorporate different parameters and scenarios such as a vaccination strategy for epidemics and the effect of vegetation, wind and outbreak rate on a wildfire in persistent monitoring scenarios.      
### 32.A Configurable Multilingual Model is All You Need to Recognize All Languages  [ :arrow_down: ](https://arxiv.org/pdf/2107.05876.pdf)
>  Multilingual automatic speech recognition (ASR) models have shown great promise in recent years because of the simplified model training and deployment process. Conventional methods either train a universal multilingual model without taking any language information or with a 1-hot language ID (LID) vector to guide the recognition of the target language. In practice, the user can be prompted to pre-select several languages he/she can speak. The multilingual model without LID cannot well utilize the language information set by the user while the multilingual model with LID can only handle one pre-selected language. In this paper, we propose a novel configurable multilingual model (CMM) which is trained only once but can be configured as different models based on users' choices by extracting language-specific modules together with a universal model from the trained CMM. Particularly, a single CMM can be deployed to any user scenario where the users can pre-select any combination of languages. Trained with 75K hours of transcribed anonymized Microsoft multilingual data and evaluated with 10-language test sets, the proposed CMM improves from the universal multilingual model by 26.0%, 16.9%, and 10.4% relative word error reduction when the user selects 1, 2, or 3 languages, respectively. CMM also performs significantly better on code-switching test sets.      
### 33.AUC Optimization for Robust Small-footprint Keyword Spotting with Limited Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.05859.pdf)
>  Deep neural networks provide effective solutions to small-footprint keyword spotting (KWS). However, if training data is limited, it remains challenging to achieve robust and highly accurate KWS in real-world scenarios where unseen sounds that are out of the training data are frequently encountered. Most conventional methods aim to maximize the classification accuracy on the training set, without taking the unseen sounds into account. To enhance the robustness of the deep neural networks based KWS, in this paper, we introduce a new loss function, named the maximization of the area under the receiver-operating-characteristic curve (AUC). The proposed method not only maximizes the classification accuracy of keywords on the closed training set, but also maximizes the AUC score for optimizing the performance of non-keyword segments detection. Experimental results on the Google Speech Commands dataset v1 and v2 show that our method achieves new state-of-the-art performance in terms of most evaluation metrics.      
### 34.Design of a Smooth Landing Trajectory Tracking System for a Fixed-wing Aircraft  [ :arrow_down: ](https://arxiv.org/pdf/2107.05803.pdf)
>  This paper presents a landing controller for a fixed-wing aircraft during the landing phase, ensuring the aircraft reaches the touchdown point smoothly. The landing problem is converted to a finite-time linear quadratic tracking (LQT) problem in which an aircraft needs to track the desired landing path in the longitudinal-vertical plane while satisfying performance requirements and flight constraints. First, we design a smooth trajectory that meets flight performance requirements and constraints. Then, an optimal controller is designed to minimize the tracking error, while landing the aircraft within the desired time frame. For this purpose, a linearized model of an aircraft developed under the assumption of a small flight path angle and a constant approach speed is used. The resulting Differential Riccati equation is solved backward in time using the Dormand Prince algorithm. Simulation results show a satisfactory tracking performance and the finite-time convergence of tracking errors for different initial conditions of the flare-out phase of landing.      
### 35.A 125$μ$W 8kS/s Sub-pA Area-Efficient Current Sensing 45nm CMOS ADC for Biosensing  [ :arrow_down: ](https://arxiv.org/pdf/2107.05794.pdf)
>  This paper presents a 125$\mu$W, area efficient (0.042mm2) 81dB DR, 8kS/s current sensing ADC in 45nm CMOS capable of sensing sub-pA currents. Our approach combines the transimpedance amplifier (TIA) and ADC into a unified structure by folding a low-noise capacitive TIA into the first stage integrator of a 2nd order Delta-Sigma modulator. The dominant DAC feedback noise is mitigated by utilizing current scaling via slope modification by an integrator and differentiator pair.      
### 36.Reinforcement Learning based Proactive Control for Transmission Grid Resilience to Wildfire  [ :arrow_down: ](https://arxiv.org/pdf/2107.05756.pdf)
>  Power grid operation subject to an extreme event requires decision-making by human operators under stressful condition with high cognitive load. Decision support under adverse dynamic events, specially if forecasted, can be supplemented by intelligent proactive control. Power system operation during wildfires require resiliency-driven proactive control for load shedding, line switching and resource allocation considering the dynamics of the wildfire and failure propagation. However, possible number of line- and load-switching in a large system during an event make traditional prediction-driven and stochastic approaches computationally intractable, leading operators to often use greedy algorithms. We model and solve the proactive control problem as a Markov decision process and introduce an integrated testbed for spatio-temporal wildfire propagation and proactive power-system operation. We transform the enormous wildfire-propagation observation space and utilize it as part of a heuristic for proactive de-energization of transmission assets. We integrate this heuristic with a reinforcement-learning based proactive policy for controlling the generating assets. Our approach allows this controller to provide setpoints for a part of the generation fleet, while a myopic operator can determine the setpoints for the remaining set, which results in a symbiotic action. We evaluate our approach utilizing the IEEE 24-node system mapped on a hypothetical terrain. Our results show that the proposed approach can help the operator to reduce load loss during an extreme event, reduce power flow through lines that are to be de-energized, and reduce the likelihood of infeasible power-flow solutions, which would indicate violation of short-term thermal limits of transmission lines.      
### 37.Quality of Service Guarantees for Physical Unclonable Functions  [ :arrow_down: ](https://arxiv.org/pdf/2107.05675.pdf)
>  We consider a secret key agreement problem in which noisy physical unclonable function (PUF) outputs facilitate reliable, secure, and private key agreement with the help of public, noiseless, and authenticated storage. PUF outputs are highly correlated, so transform coding methods have been combined with scalar quantizers to extract uncorrelated bit sequences with reliability guarantees. For PUF circuits with continuous-valued outputs, the models for transformed outputs are made more realistic by replacing the fitted distributions with corresponding truncated ones. The state-of-the-art PUF methods that provide reliability guarantees to each extracted bit are shown to be inadequate to guarantee the same reliability level for all PUF outputs. Thus, a quality of service parameter is introduced to control the percentage of PUF outputs for which a target reliability level can be guaranteed. A public ring oscillator (RO) output dataset is used to illustrate that a truncated Gaussian distribution can be fitted to transformed RO outputs that are inputs to uniform scalar quantizers such that reliability guarantees can be provided for each bit extracted from any PUF device under additive Gaussian noise components by eliminating a small subset of PUF outputs. Furthermore, we conversely show that it is not possible to provide such reliability guarantees without eliminating any PUF output if no extra secrecy and privacy leakage is allowed.      
### 38.Challenges for machine learning in clinical translation of big data imaging studies  [ :arrow_down: ](https://arxiv.org/pdf/2107.05630.pdf)
>  The combination of deep learning image analysis methods and large-scale imaging datasets offers many opportunities to imaging neuroscience and epidemiology. However, despite the success of deep learning when applied to many neuroimaging tasks, there remain barriers to the clinical translation of large-scale datasets and processing tools. Here, we explore the main challenges and the approaches that have been explored to overcome them. We focus on issues relating to data availability, interpretability, evaluation and logistical challenges, and discuss the challenges we believe are still to be overcome to enable the full success of big data deep learning approaches to be experienced outside of the research field.      
### 39.Smoothed Bernstein Online Aggregation for Day-Ahead Electricity Demand Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2107.06268.pdf)
>  We present a winning method of the IEEE DataPort Competition on Day-Ahead Electricity Demand Forecasting: Post-COVID Paradigm. The day-ahead load forecasting approach is based on online forecast combination of multiple point prediction models. It contains four steps: i) data cleaning and preprocessing, ii) a holiday adjustment procedure, iii) training of individual forecasting models, iv) forecast combination by smoothed Bernstein Online Aggregation (BOA). The approach is flexible and can quickly adopt to new energy system situations as they occurred during and after COVID-19 shutdowns. The pool of individual prediction models ranges from rather simple time series models to sophisticated models like generalized additive models (GAMs) and high-dimensional linear models estimated by lasso. They incorporate autoregressive, calendar and weather effects efficiently. All steps contain novel concepts that contribute to the excellent forecasting performance of the proposed method. This holds particularly for the holiday adjustment procedure and the fully adaptive smoothed BOA approach.      
### 40.Dance2Music: Automatic Dance-driven Music Generation  [ :arrow_down: ](https://arxiv.org/pdf/2107.06252.pdf)
>  Dance and music typically go hand in hand. The complexities in dance, music, and their synchronisation make them fascinating to study from a computational creativity perspective. While several works have looked at generating dance for a given music, automatically generating music for a given dance remains under-explored. This capability could have several creative expression and entertainment applications. We present some early explorations in this direction. We present a search-based offline approach that generates music after processing the entire dance video and an online approach that uses a deep neural network to generate music on-the-fly as the video proceeds. We compare these approaches to a strong heuristic baseline via human studies and present our findings. We have integrated our online approach in a live demo! A video of the demo can be found here: <a class="link-external link-https" href="https://sites.google.com/view/dance2music/live-demo" rel="external noopener nofollow">this https URL</a>.      
### 41.Timbre Classification of Musical Instruments with a Deep Learning Multi-Head Attention-Based Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.06231.pdf)
>  The aim of this work is to define a model based on deep learning that is able to identify different instrument timbres with as few parameters as possible. For this purpose, we have worked with classical orchestral instruments played with different dynamics, which are part of a few instrument families and which play notes in the same pitch range. It has been possible to assess the ability to classify instruments by timbre even if the instruments are playing the same note with the same intensity. The network employed uses a multi-head attention mechanism, with 8 heads and a dense network at the output taking as input the log-mel magnitude spectrograms of the sound samples. This network allows the identification of 20 instrument classes of the classical orchestra, achieving an overall F$_1$ value of 0.62. An analysis of the weights of the attention layer has been performed and the confusion matrix of the model is presented, allowing us to assess the ability of the proposed architecture to distinguish timbre and to establish the aspects on which future work should focus.      
### 42.Transfer Learning in Multi-Agent Reinforcement Learning with Double Q-Networks for Distributed Resource Sharing in V2X Communication  [ :arrow_down: ](https://arxiv.org/pdf/2107.06195.pdf)
>  This paper addresses the problem of decentralized spectrum sharing in vehicle-to-everything (V2X) communication networks. The aim is to provide resource-efficient coexistence of vehicle-to-infrastructure(V2I) and vehicle-to-vehicle(V2V) links. A recent work on the topic proposes a multi-agent reinforcement learning (MARL) approach based on deep Q-learning, which leverages a fingerprint-based deep Q-network (DQN) architecture. This work considers an extension of this framework by combining Double Q-learning (via Double DQN) and transfer learning. The motivation behind is that Double Q-learning can alleviate the problem of overestimation of the action values present in conventional Q-learning, while transfer learning can leverage knowledge acquired by an expert model to accelerate learning in the MARL setting. The proposed algorithm is evaluated in a realistic V2X setting, with synthetic data generated based on a geometry-based propagation model that incorporates location-specific geographical descriptors of the simulated environment(outlines of buildings, foliage, and vehicles). The advantages of the proposed approach are demonstrated via numerical simulations.      
### 43.Predictive models for wind speed using artificial intelligence and copula  [ :arrow_down: ](https://arxiv.org/pdf/2107.06182.pdf)
>  Electricity generation from burning fossil fuels is one of the major contributors to global warming. Renewable energy sources are a viable alternative to produce electrical energy and to reduce the emission from the power industry. These energy sources are the building blocks of green energy, which all have different characteristics. Their availabilities are also diverse, depending on geographical locations and other parameters. Low implementation cost and distributed availability all over the world uplifts their popularity exponentially. Therefore, it has unlocked opportunities for consumers to produce electricity locally and use it on-site, which reduces dependency on centralized utility companies. The research considers two main objectives: the prediction of wind speed that simplifies wind farm planning and feasibility study. Secondly, the need to understand the dependency structure of the wind speeds of multiple distant locations. To address the first objective, twelve artificial intelligence algorithms were used for wind speed prediction from collected meteorological parameters. The model performances were compared to determine the wind speed prediction accuracy. The results show a deep learning approach, long short-term memory (LSTM) outperforms other models with the highest accuracy of 97.8%. For dependency, a multivariate cumulative distribution function, Copula, was used to find the joint distribution of two or more distant location wind speeds, followed by a case study. We found that the appropriate copula family and the parameters vary based on the distance in between. For the case study, Joe-Frank (BB8) copula shows an efficient joint distribution fit for a wind speed pair with a standard error of 0.0094. Finally, some insights about the uncertainty aspects of wind speed dependency were addressed.      
### 44.Arrhenius.jl: A Differentiable Combustion SimulationPackage  [ :arrow_down: ](https://arxiv.org/pdf/2107.06172.pdf)
>  Combustion kinetic modeling is an integral part of combustion simulation, and extensive studies have been devoted to developing both high fidelity and computationally affordable models. Despite these efforts, modeling combustion kinetics is still challenging due to the demand for expert knowledge and optimization against experiments, as well as the lack of understanding of the associated uncertainties. Therefore, data-driven approaches that enable efficient discovery and calibration of kinetic models have received much attention in recent years, the core of which is the optimization based on big data. Differentiable programming is a promising approach for learning kinetic models from data by efficiently computing the gradient of objective functions to model parameters. However, it is often challenging to implement differentiable programming in practice. Therefore, it is still not available in widely utilized combustion simulation packages such as CHEMKIN and Cantera. Here, we present a differentiable combustion simulation package leveraging the eco-system in Julia, including DifferentialEquations.jl for solving differential equations, ForwardDiff.jl for auto-differentiation, and Flux.jl for incorporating neural network models into combustion simulations and optimizing neural network models using the state-of-the-art deep learning optimizers. We demonstrate the benefits of differentiable programming in efficient and accurate gradient computations, with applications in uncertainty quantification, kinetic model reduction, data assimilation, and model discovery.      
### 45.The IWSLT 2021 BUT Speech Translation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.06155.pdf)
>  The paper describes BUT's English to German offline speech translation(ST) systems developed for IWSLT2021. They are based on jointly trained Automatic Speech Recognition-Machine Translation models. Their performances is evaluated on MustC-Common test set. In this work, we study their efficiency from the perspective of having a large amount of separate ASR training data and MT training data, and a smaller amount of speech-translation training data. Large amounts of ASR and MT training data are utilized for pre-training the ASR and MT models. Speech-translation data is used to jointly optimize ASR-MT models by defining an end-to-end differentiable path from speech to translations. For this purpose, we use the internal continuous representations from the ASR-decoder as the input to MT module. We show that speech translation can be further improved by training the ASR-decoder jointly with the MT-module using large amount of text-only MT training data. We also show significant improvements by training an ASR module capable of generating punctuated text, rather than leaving the punctuation task to the MT module.      
### 46.A model of systems with modes and mode transitions  [ :arrow_down: ](https://arxiv.org/pdf/2107.06152.pdf)
>  We propose a method of classifying the operation of a system into finitely many modes. Each mode has its own objectives for the system's behaviour and its own mathematical models and algorithms designed to accomplish its objectives. A central problem is deciding when to transition from one mode to some other mode, a decision that may be contested and involve partial or inconsistent information or evidence. We model formally the concept of modes for a system and derive a family of data types for analysing mode transitions. The data types are simplicial complexes, both abstract and realised in euclidean space $\mathbb{R}^{n}$. In the data type, a mode is represented by a simplex. Each state of a system can be evaluated relative to different modes by mapping it into one or more simplices. This calibration measures the extent to which distinct modes are appropriate for the state and can decide on a transition. We explain this methodology based on modes, introduce the mathematical ideas about simplicial objects we need and use them to build a theoretical framework for modes and mode transitions. To illustrate the general model in some detail, we work though a case study of an autonomous racing car.      
### 47.DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual Network for the DiCOVA Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2107.06126.pdf)
>  In this paper, we propose a deep residual network-based method, namely the DiCOVA-Net, to identify COVID-19 infected patients based on the acoustic recording of their coughs. Since there are far more healthy people than infected patients, this classification problem faces the challenge of imbalanced data. To improve the model's ability to recognize minority class (the infected patients), we introduce data augmentation and cost-sensitive methods into our model. Besides, considering the particularity of this task, we deploy some fine-tuning techniques to adjust the pre-training ResNet50. Furthermore, to improve the model's generalizability, we use ensemble learning to integrate prediction results from multiple base classifiers generated using different random seeds. To evaluate the proposed DiCOVA-Net's performance, we conducted experiments with the DiCOVA challenge dataset. The results show that our method has achieved 85.43\% in AUC, among the top of all competing teams.      
### 48.Force-in-domain GAN inversion  [ :arrow_down: ](https://arxiv.org/pdf/2107.06050.pdf)
>  Empirical works suggest that various semantics emerge in the latent space of Generative Adversarial Networks (GANs) when being trained to generate images. To perform real image editing, it requires an accurate mapping from the real image to the latent space to leveraging these learned semantics, which is important yet difficult. An in-domain GAN inversion approach is recently proposed to constraint the inverted code within the latent space by forcing the reconstructed image obtained from the inverted code within the real image space. Empirically, we find that the inverted code by the in-domain GAN can deviate from the latent space significantly. To solve this problem, we propose a force-in-domain GAN based on the in-domain GAN, which utilizes a discriminator to force the inverted code within the latent space. The force-in-domain GAN can also be interpreted by a cycle-GAN with slight modification. Extensive experiments show that our force-in-domain GAN not only reconstructs the target image at the pixel level, but also align the inverted code with the latent space well for semantic editing.      
### 49.The Piano Inpainting Application  [ :arrow_down: ](https://arxiv.org/pdf/2107.05944.pdf)
>  Autoregressive models are now capable of generating high-quality minute-long expressive MIDI piano performances. Even though this progress suggests new tools to assist music composition, we observe that generative algorithms are still not widely used by artists due to the limited control they offer, prohibitive inference times or the lack of integration within musicians' workflows. In this work, we present the Piano Inpainting Application (PIA), a generative model focused on inpainting piano performances, as we believe that this elementary operation (restoring missing parts of a piano performance) encourages human-machine interaction and opens up new ways to approach music composition. Our approach relies on an encoder-decoder Linear Transformer architecture trained on a novel representation for MIDI piano performances termed Structured MIDI Encoding. By uncovering an interesting synergy between Linear Transformers and our inpainting task, we are able to efficiently inpaint contiguous regions of a piano performance, which makes our model suitable for interactive and responsive A.I.-assisted composition. Finally, we introduce our freely-available Ableton Live PIA plugin, which allows musicians to smoothly generate or modify any MIDI clip using PIA within a widely-used professional Digital Audio Workstation.      
### 50.Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music  [ :arrow_down: ](https://arxiv.org/pdf/2107.05916.pdf)
>  Modern keyboards allow a musician to play multiple instruments at the same time by assigning zones -- fixed pitch ranges of the keyboard -- to different instruments. In this paper, we aim to further extend this idea and examine the feasibility of automatic instrumentation -- dynamically assigning instruments to notes in solo music during performance. In addition to the online, real-time-capable setting for performative use cases, automatic instrumentation can also find applications in assistive composing tools in an offline setting. Due to the lack of paired data of original solo music and their full arrangements, we approach automatic instrumentation by learning to separate parts (e.g., voices, instruments and tracks) from their mixture in symbolic multitrack music, assuming that the mixture is to be played on a keyboard. We frame the task of part separation as a sequential multi-class classification problem and adopt machine learning to map sequences of notes into sequences of part labels. To examine the effectiveness of our proposed models, we conduct a comprehensive empirical evaluation over four diverse datasets of different genres and ensembles -- Bach chorales, string quartets, game music and pop music. Our experiments show that the proposed models outperform various baselines. We also demonstrate the potential for our proposed models to produce alternative convincing instrumentations for an existing arrangement by separating its mixture into parts. All source code and audio samples can be found at <a class="link-external link-https" href="https://salu133445.github.io/arranger/" rel="external noopener nofollow">this https URL</a> .      
### 51.Conformer-based End-to-end Speech Recognition With Rotary Position Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2107.05907.pdf)
>  Transformer-based end-to-end speech recognition models have received considerable attention in recent years due to their high training speed and ability to model a long-range global context. Position embedding in the transformer architecture is indispensable because it provides supervision for dependency modeling between elements at different positions in the input sequence. To make use of the time order of the input sequence, many works inject some information about the relative or absolute position of the element into the input sequence. In this work, we investigate various position embedding methods in the convolution-augmented transformer (conformer) and adopt a novel implementation named rotary position embedding (RoPE). RoPE encodes absolute positional information into the input sequence by a rotation matrix, and then naturally incorporates explicit relative position information into a self-attention module. To evaluate the effectiveness of the RoPE method, we conducted experiments on AISHELL-1 and LibriSpeech corpora. Results show that the conformer enhanced with RoPE achieves superior performance in the speech recognition task. Specifically, our model achieves a relative word error rate reduction of 8.70% and 7.27% over the conformer on test-clean and test-other sets of the LibriSpeech corpus respectively.      
### 52.Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021  [ :arrow_down: ](https://arxiv.org/pdf/2107.05899.pdf)
>  We present a system for the Zero Resource Speech Challenge 2021, which combines a Contrastive Predictive Coding (CPC) with deep cluster. In deep cluster, we first prepare pseudo-labels obtained by clustering the outputs of a CPC network with k-means. Then, we train an additional autoregressive model to classify the previously obtained pseudo-labels in a supervised manner. Phoneme discriminative representation is achieved by executing the second-round clustering with the outputs of the final layer of the autoregressive model. We show that replacing a Transformer layer with a Conformer layer leads to a further gain in a lexical metric. Experimental results show that a relative improvement of 35% in a phonetic metric, 1.5% in the lexical metric, and 2.3% in a syntactic metric are achieved compared to a baseline method of CPC-small which is trained on LibriSpeech 460h data. We achieve top results in this challenge with the syntactic metric.      
### 53.Monotonic Filtering for Distributed Collection  [ :arrow_down: ](https://arxiv.org/pdf/2107.05791.pdf)
>  Distributed data collection is a fundamental task in open systems. In such networks, data is aggregated across a network to produce a single aggregated result at a source device. Though self-stabilizing, algorithms performing data collection can produce large overestimates in the transient phase. For example, in [1] we demonstrated that in a line graph, a switch of sources after initial stabilization may produce overestimates that are quadratic in the network diameter. We also proposed monotonic filtering as a strategy for removing such large overestimates. Monotonic filtering prevents the transfer of data from device A to device B unless the distance estimate at A is more than that at B at the previous iteration. For a line graph, [1] shows that monotonic filtering prevents quadratic overestimates. This paper analyzes monotonic filtering for an arbitrary graph topology, showing that for an N device network, the largest overestimate after switching sources is at most 2N.      
### 54.Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task  [ :arrow_down: ](https://arxiv.org/pdf/2107.05782.pdf)
>  Pretraining and multitask learning are widely used to improve the speech to text translation performance. In this study, we are interested in training a speech to text translation model along with an auxiliary text to text translation task. We conduct a detailed analysis to understand the impact of the auxiliary task on the primary task within the multitask learning framework. Our analysis confirms that multitask learning tends to generate similar decoder representations from different modalities and preserve more information from the pretrained text translation modules. We observe minimal negative transfer effect between the two tasks and sharing more parameters is helpful to transfer knowledge from the text task to the speech task. The analysis also reveals that the modality representation difference at the top decoder layers is still not negligible, and those layers are critical for the translation quality. Inspired by these findings, we propose three methods to improve translation quality. First, a parameter sharing and initialization strategy is proposed to enhance information sharing between the tasks. Second, a novel attention-based regularization is proposed for the encoders and pulls the representations from different modalities closer. Third, an online knowledge distillation is proposed to enhance the knowledge transfer from the text to the speech task. Our experiments show that the proposed approach improves translation performance by more than 2 BLEU over a strong baseline and achieves state-of-the-art results on the \textsc{MuST-C} English-German, English-French and English-Spanish language pairs.      
### 55.Detect and Defense Against Adversarial Examples in Deep Learning using Natural Scene Statistics and Adaptive Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2107.05780.pdf)
>  Despite the enormous performance of deepneural networks (DNNs), recent studies have shown theirvulnerability to adversarial examples (AEs), i.e., care-fully perturbed inputs designed to fool the targetedDNN. Currently, the literature is rich with many ef-fective attacks to craft such AEs. Meanwhile, many de-fenses strategies have been developed to mitigate thisvulnerability. However, these latter showed their effec-tiveness against specific attacks and does not general-ize well to different attacks. In this paper, we proposea framework for defending DNN classifier against ad-versarial samples. The proposed method is based on atwo-stage framework involving a separate detector anda denoising block. The detector aims to detect AEs bycharacterizing them through the use of natural scenestatistic (NSS), where we demonstrate that these statis-tical features are altered by the presence of adversarialperturbations. The denoiser is based on block matching3D (BM3D) filter fed by an optimum threshold valueestimated by a convolutional neural network (CNN) toproject back the samples detected as AEs into theirdata manifold. We conducted a complete evaluation onthree standard datasets namely MNIST, CIFAR-10 andTiny-ImageNet. The experimental results show that theproposed defense method outperforms the state-of-the-art defense techniques by improving the robustnessagainst a set of attacks under black-box, gray-box and white-box settings. The source code is available at: <a class="link-external link-https" href="https://github.com/kherchouche-anouar/2DAE" rel="external noopener nofollow">this https URL</a>      
### 56.Bayesian Atlas Building with Hierarchical Priors for Subject-specific Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2107.05698.pdf)
>  This paper presents a novel hierarchical Bayesian model for unbiased atlas building with subject-specific regularizations of image registration. We develop an atlas construction process that automatically selects parameters to control the smoothness of diffeomorphic transformation according to individual image data. To achieve this, we introduce a hierarchical prior distribution on regularization parameters that allows multiple penalties on images with various degrees of geometric transformations. We then treat the regularization parameters as latent variables and integrate them out from the model by using the Monte Carlo Expectation Maximization (MCEM) algorithm. Another advantage of our algorithm is that it eliminates the need for manual parameter tuning, which can be tedious and infeasible. We demonstrate the effectiveness of our model on 3D brain MR images. Experimental results show that our model provides a sharper atlas compared to the current atlas building algorithms with single-penalty regularizations. Our code is publicly available at <a class="link-external link-https" href="https://github.com/jw4hv/HierarchicalBayesianAtlasBuild" rel="external noopener nofollow">this https URL</a>.      
### 57.Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2107.05680.pdf)
>  Generative Adversarial Networks (GANs) are commonly used for modeling complex distributions of data. Both the generators and discriminators of GANs are often modeled by neural networks, posing a non-transparent optimization problem which is non-convex and non-concave over the generator and discriminator, respectively. Such networks are often heuristically optimized with gradient descent-ascent (GDA), but it is unclear whether the optimization problem contains any saddle points, or whether heuristic methods can find them in practice. In this work, we analyze the training of Wasserstein GANs with two-layer neural network discriminators through the lens of convex duality, and for a variety of generators expose the conditions under which Wasserstein GANs can be solved exactly with convex optimization approaches, or can be represented as convex-concave games. Using this convex duality interpretation, we further demonstrate the impact of different activation functions of the discriminator. Our observations are verified with numerical results demonstrating the power of the convex interpretation, with applications in progressive training of convex architectures corresponding to linear generators and quadratic-activation discriminators for CelebA image generation. The code for our experiments is available at <a class="link-external link-https" href="https://github.com/ardasahiner/ProCoGAN" rel="external noopener nofollow">this https URL</a>.      
### 58.Codified audio language modeling learns useful representations for music information retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2107.05677.pdf)
>  We demonstrate that language models pre-trained on codified (discretely-encoded) music audio learn representations that are useful for downstream MIR tasks. Specifically, we explore representations from Jukebox (Dhariwal et al. 2020): a music generation system containing a language model trained on codified audio from 1M songs. To determine if Jukebox's representations contain useful information for MIR, we use them as input features to train shallow models on several MIR tasks. Relative to representations from conventional MIR models which are pre-trained on tagging, we find that using representations from Jukebox as input features yields 30% stronger performance on average across four MIR tasks: tagging, genre classification, emotion recognition, and key detection. For key detection, we observe that representations from Jukebox are considerably stronger than those from models pre-trained on tagging, suggesting that pre-training via codified audio language modeling may address blind spots in conventional approaches. We interpret the strength of Jukebox's representations as evidence that modeling audio instead of tags provides richer representations for MIR.      
### 59.A prediction perspective on the Wiener-Hopf equations for discrete time series  [ :arrow_down: ](https://arxiv.org/pdf/2107.04994.pdf)
>  The Wiener-Hopf equations are a Toeplitz system of linear equations that have several applications in time series. These include the update and prediction step of the stationary Kalman filter equations and the prediction of bivariate time series. The Wiener-Hopf technique is the classical tool for solving the equations, and is based on a comparison of coefficients in a Fourier series expansion. The purpose of this note is to revisit the (discrete) Wiener-Hopf equations and obtain an alternative expression for the solution that is more in the spirit of time series analysis. Specifically, we propose a solution to the Wiener-Hopf equations that combines linear prediction with deconvolution. <br>The solution of the Wiener-Hopf equations requires one to obtain the spectral factorization of the underlying spectral density function. For general spectral density functions this is infeasible. Therefore, it is usually assumed that the spectral density is rational, which allows one to obtain a computationally tractable solution. This leads to an approximation error when the underlying spectral density is not a rational function. We use the proposed solution together with Baxter's inequality to derive an error bound for the rational spectral density approximation.      
