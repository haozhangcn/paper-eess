# ArXiv eess --Thu, 22 Jul 2021
### 1.Constrained Power Reference Control for Wind Turbines  [ :arrow_down: ](https://arxiv.org/pdf/2107.10213.pdf)
>  The cost of wind energy can be reduced by controlling the power reference of a turbine to increase energy capture, while maintaining load and generator speed constraints. We apply standard torque and pitch controllers to the direct inputs of the turbine and use their set points to change the power output and reduce generator speed and blade load transients. A power reference controller increases the power output when conditions are safe and decreases it when problematic transient events are expected. Transient generator speeds and blade loads are estimated using a gust measure derived from a wind speed estimate. A hybrid controller decreases the power rating from a maximum allowable power. Compared to a baseline controller, with a constant power reference, the proposed controller results in generator speeds and blade loads that do not exceed the original limits, increases tower fore-aft damage equivalent loads by 1%, and increases the annual energy production by 5%.      
### 2.3D fluorescence microscopy data synthesis for segmentation and benchmarking  [ :arrow_down: ](https://arxiv.org/pdf/2107.10180.pdf)
>  Automated image processing approaches are indispensable for many biomedical experiments and help to cope with the increasing amount of microscopy image data in a fast and reproducible way. Especially state-of-the-art deep learning-based approaches most often require large amounts of annotated training data to produce accurate and generalist outputs, but they are often compromised by the general lack of those annotated data sets. In this work, we propose how conditional generative adversarial networks can be utilized to generate realistic image data for 3D fluorescence microscopy from annotation masks of 3D cellular structures. In combination with mask simulation approaches, we demonstrate the generation of fully-annotated 3D microscopy data sets that we make publicly available for training or benchmarking. An additional positional conditioning of the cellular structures enables the reconstruction of position-dependent intensity characteristics and allows to generate image data of different quality levels. A patch-wise working principle and a subsequent full-size reassemble strategy is used to generate image data of arbitrary size and different organisms. We present this as a proof-of-concept for the automated generation of fully-annotated training data sets requiring only a minimum of manual interaction to alleviate the need of manual annotations.      
### 3.A Network Control Theory Approach to Longitudinal Symptom Dynamics in Major Depressive Disorder  [ :arrow_down: ](https://arxiv.org/pdf/2107.10178.pdf)
>  Background: The evolution of symptoms over time is at the heart of understanding and treating mental disorders. However, a principled, quantitative framework explaining symptom dynamics remains elusive. Here, we propose a Network Control Theory of Psychopathology allowing us to formally derive a theoretical control energy which we hypothesize quantifies resistance to future symptom improvement in Major Depressive Disorder (MDD). We test this hypothesis and investigate the relation to genetic and environmental risk as well as resilience. <br>Methods: We modelled longitudinal symptom-network dynamics derived from N=2,059 Beck Depression Inventory measurements acquired over a median of 134 days in a sample of N=109 patients suffering from MDD. We quantified the theoretical energy required for each patient and time-point to reach a symptom-free state given individual symptom-network topology (E 0 ) and 1) tested if E 0 predicts future symptom improvement and 2) whether this relationship is moderated by Polygenic Risk Scores (PRS) of mental disorders, childhood maltreatment experience, and self-reported resilience. <br>Outcomes: We show that E 0 indeed predicts symptom reduction at the next measurement and reveal that this coupling between E 0 and future symptom change increases with higher genetic risk and childhood maltreatment while it decreases with resilience. <br>Interpretation: Our study provides a mechanistic framework capable of predicting future symptom improvement based on individual symptom-network topology and clarifies the role of genetic and environmental risk as well as resilience. Our control-theoretic framework makes testable, quantitative predictions for individual therapeutic response and provides a starting-point for the theory-driven design of personalized interventions. <br>Funding: German Research Foundation and Interdisciplinary Centre for Clinical Research, MÃ¼nster      
### 4.Controlling the Remixing of Separated Dialogue with a Non-Intrusive Quality Estimate  [ :arrow_down: ](https://arxiv.org/pdf/2107.10151.pdf)
>  Remixing separated audio sources trades off interferer attenuation against the amount of audible deteriorations. This paper proposes a non-intrusive audio quality estimation method for controlling this trade-off in a signal-adaptive manner. The recently proposed 2f-model is adopted as the underlying quality measure, since it has been shown to correlate strongly with basic audio quality in source separation. An alternative operation mode of the measure is proposed, more appropriate when considering material with long inactive periods of the target source. The 2f-model requires the reference target source as an input, but this is not available in many applications. Deep neural networks (DNNs) are trained to estimate the 2f-model intrusively using the reference target (iDNN2f), non-intrusively using the input mix as reference (nDNN2f), and reference-free using only the separated output signal (rDNN2f). It is shown that iDNN2f achieves very strong correlation with the original measure on the test data (Pearson r=0.99), while performance decreases for nDNN2f (r&gt;=0.91) and rDNN2f (r&gt;=0.82). The non-intrusive estimate nDNN2f is mapped to select item-dependent remixing gains with the aim of maximizing the interferer attenuation under a constraint on the minimum quality of the remixed output (e.g., audible but not annoying deteriorations). A listening test shows that this is successfully achieved even with very different selected gains (up to 23 dB difference).      
### 5.HistoCartography: A Toolkit for Graph Analytics in Digital Pathology  [ :arrow_down: ](https://arxiv.org/pdf/2107.10073.pdf)
>  Advances in entity-graph based analysis of histopathology images have brought in a new paradigm to describe tissue composition, and learn the tissue structure-to-function relationship. Entity-graphs offer flexible and scalable representations to characterize tissue organization, while allowing the incorporation of prior pathological knowledge to further support model interpretability and explainability. However, entity-graph analysis requires prerequisites for image-to-graph translation and knowledge of state-of-the-art machine learning algorithms applied to graph-structured data, which can potentially hinder their adoption. In this work, we aim to alleviate these issues by developing HistoCartography, a standardized python API with necessary preprocessing, machine learning and explainability tools to facilitate graph-analytics in computational pathology. Further, we have benchmarked the computational time and performance on multiple datasets across different imaging types and histopathology tasks to highlight the applicability of the API for building computational pathology workflows.      
### 6.Two Efficient and Easy-to-Use NLOS Mitigation Solutions to Indoor 3-D AOA-Based Localization  [ :arrow_down: ](https://arxiv.org/pdf/2107.10071.pdf)
>  This paper proposes two efficient and easy-to-use error mitigation solutions to the problem of three-dimensional (3-D) angle-of-arrival (AOA) source localization in the mixed line-of-sight (LOS) and non-line-of-sight (NLOS) indoor environments. A weighted linear least squares estimator is derived first for the LOS AOA components in terms of the direction vectors of arrival, albeit in a sub-optimal manner. Next, data selection exploiting the sum of squared residuals is carried out to discard the error-prone NLOS connections. In so doing, the first approach is constituted and more accurate closed-form location estimates can be obtained. The second method applies a simulated annealing stochastic framework to realize the robust $\ell_1$-minimization criterion, which therefore falls into the methodology of statistical robustification. Computer simulations and ultrasonic onsite experiments are conducted to evaluate the performance of the two proposed methods, demonstrating their outstanding positioning results in the respective scenarios.      
### 7.KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2107.10043.pdf)
>  Real-time state estimation of dynamical systems is a fundamental task in signal processing and control. For systems that are well-represented by a fully known linear Gaussian state space (SS) model, the celebrated Kalman filter (KF) is a low complexity optimal solution. However, both linearity of the underlying SS model and accurate knowledge of it are often not encountered in practice. Here, we present KalmanNet, a real-time state estimator that learns from data to carry out Kalman filtering under non-linear dynamics with partial information. By incorporating the structural SS model with a dedicated recurrent neural network module in the flow of the KF, we retain data efficiency and interpretability of the classic algorithm while implicitly learning complex dynamics from data. We numerically demonstrate that KalmanNet overcomes nonlinearities and model mismatch, outperforming classic filtering methods operating with both mismatched and accurate domain knowledge.      
### 8.Optimal Operation of Power Systems with Energy Storage under Uncertainty: A Scenario-based Method with Strategic Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2107.10013.pdf)
>  The multi-period dynamics of energy storage (ES), intermittent renewable generation and uncontrollable power loads, make the optimization of power system operation (PSO) challenging. A multi-period optimal PSO under uncertainty is formulated using the chance-constrained optimization (CCO) modeling paradigm, where the constraints include the nonlinear energy storage and AC power flow models. Based on the emerging scenario optimization method which does not rely on pre-known probability distribution functions, this paper develops a novel solution method for this challenging CCO problem. The proposed meth-od is computationally effective for mainly two reasons. First, the original AC power flow constraints are approximated by a set of learning-assisted quadratic convex inequalities based on a generalized least absolute shrinkage and selection operator. Second, considering the physical patterns of data and motived by learning-based sampling, the strategic sampling method is developed to significantly reduce the required number of scenarios through different sampling strategies. The simulation results on IEEE standard systems indicate that 1) the proposed strategic sampling significantly improves the computational efficiency of the scenario-based approach for solving the chance-constrained optimal PSO problem, 2) the data-driven convex approximation of power flow can be promising alternatives of nonlinear and nonconvex AC power flow.      
### 9.Conditional Sound Generation Using Neural Discrete Time-Frequency Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.09998.pdf)
>  Deep generative models have recently achieved impressive performance in speech synthesis and music generation. However, compared to the generation of those domain-specific sounds, the generation of general sounds (such as car horn, dog barking, and gun shot) has received less attention, despite their wide potential applications. In our previous work, sounds are generated in the time domain using SampleRNN. However, it is difficult to capture long-range dependencies within sound recordings using this method. In this work, we propose to generate sounds conditioned on sound classes via neural discrete time-frequency representation learning. This offers an advantage in modelling long-range dependencies and retaining local fine-grained structure within a sound clip. We evaluate our proposed approach on the UrbanSound8K dataset, as compared to a SampleRNN baseline, with the performance metrics measuring the quality and diversity of the generated sound samples. Experimental results show that our proposed method offers significantly better performance in diversity and comparable performance in quality, as compared to the baseline method.      
### 10.CL4AC: A Contrastive Loss for Audio Captioning  [ :arrow_down: ](https://arxiv.org/pdf/2107.09990.pdf)
>  Automated Audio captioning (AAC) is a cross-modal translation task that aims to use natural language to describe the content of an audio clip. As shown in the submissions received for Task 6 of the DCASE 2021 Challenges, this problem has received increasing interest in the community. The existing AAC systems are usually based on an encoder-decoder architecture, where the audio signal is encoded into a latent representation, and aligned with its corresponding text descriptions, then a decoder is used to generate the captions. However, training of an AAC system often encounters the problem of data scarcity, which may lead to inaccurate representation and audio-text alignment. To address this problem, we propose a novel encoder-decoder framework called Contrastive Loss for Audio Captioning (CL4AC). In CL4AC, the self-supervision signals derived from the original audio-text paired data are used to exploit the correspondences between audio and texts by contrasting samples, which can improve the quality of latent representation and the alignment between audio and texts, while trained with limited data. Experiments are performed on the Clotho dataset to show the effectiveness of our proposed approach.      
### 11.High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network with Attention and Cyclic Loss  [ :arrow_down: ](https://arxiv.org/pdf/2107.09989.pdf)
>  Magnetic resonance imaging (MRI) is an important medical imaging modality, but its acquisition speed is quite slow due to the physiological limitations. Recently, super-resolution methods have shown excellent performance in accelerating MRI. In some circumstances, it is difficult to obtain high-resolution images even with prolonged scan time. Therefore, we proposed a novel super-resolution method that uses a generative adversarial network (GAN) with cyclic loss and attention mechanism to generate high-resolution MR images from low-resolution MR images by a factor of 2. We implemented our model on pelvic images from healthy subjects as training and validation data, while those data from patients were used for testing. The MR dataset was obtained using different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four methods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison. Structural similarity, peak signal to noise ratio, root mean square error, and variance inflation factor were used as calculation indicators to evaluate the performances of the proposed method. Various experimental results showed that our method can better restore the details of the high-resolution MR image as compared to the other methods. In addition, the reconstructed high-resolution MR image can provide better lesion textures in the tumor patients, which is promising to be used in clinical diagnosis.      
### 12.Vehicle 24-Color Long Tail Recognition Based on Smooth Modulation Neural Network with Multi-layer Feature Representation  [ :arrow_down: ](https://arxiv.org/pdf/2107.09944.pdf)
>  Vehicle color recognition plays an important role in intelligent traffic management and criminal investigation assistance. However, the current vehicle color recognition research involves at most 13 types of colors and the recognition accuracy is low, which is difficult to meet practical applications. To this end, this paper has built a benchmark dataset (Vehicle Color-24) that includes 24 types of vehicle colors, including 10091 vehicle pictures taken from 100 hours of urban road surveillance videos. In addition, in order to solve the problem of long tail distribution in Vehicle Color-24 dataset and low recognition rate of existing methods, this paper proposes a Smooth Modulated Neural Network with Multi-layer Feature Representation (SMNN-MFR) is used for 24 types of vehicle color recognition. SMNN-MFR includes four parts: feature extraction, multi-scale feature fusion, suggestion frame generation and smooth modulation. The model is trained and verified on the Vehicle Color-24 benchmark dataset. Comprehensive experiments show that the average recognition accuracy of the algorithm in the 24 categories of color benchmark databases is 94.96%, which is 33.47% higher than the Faster RCNN network. In addition, the average accuracy rate of the model when recognizing 8 types of colors is 97.25%, and the detection accuracy of algorithms in similar databases is improved. At the same time, visualization and ablation experiments also proved the rationality of our network settings and the effectiveness of each module. The code and database are published at: <a class="link-external link-https" href="https://github.com/mendy-2013" rel="external noopener nofollow">this https URL</a>.      
### 13.A Point Cloud Generative Model via Tree-Structured Graph Convolutions for 3D Brain Shape Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2107.09923.pdf)
>  Fusing medical images and the corresponding 3D shape representation can provide complementary information and microstructure details to improve the operational performance and accuracy in brain surgery. However, compared to the substantial image data, it is almost impossible to obtain the intraoperative 3D shape information by using physical methods such as sensor scanning, especially in minimally invasive surgery and robot-guided surgery. In this paper, a general generative adversarial network (GAN) architecture based on graph convolutional networks is proposed to reconstruct the 3D point clouds (PCs) of brains by using one single 2D image, thus relieving the limitation of acquiring 3D shape data during surgery. Specifically, a tree-structured generative mechanism is constructed to use the latent vector effectively and transfer features between hidden layers accurately. With the proposed generative model, a spontaneous image-to-PC conversion is finished in real-time. Competitive qualitative and quantitative experimental results have been achieved on our model. In multiple evaluation methods, the proposed model outperforms another common point cloud generative model PointOutNet.      
### 14.Convolutional Sparse Coding based Channel Estimation for OTFS-SCMA in Uplink  [ :arrow_down: ](https://arxiv.org/pdf/2107.09893.pdf)
>  Orthogonal time frequency space (OTFS) has emerged as the most sought-after modulation technique in a high mobility scenario. Sparse code multiple access (SCMA) is an attractive code-domain non-orthogonal multiple access (NOMA) technique. Recently a code-domain NOMA approach for OTFS, named OTFS-SCMA, is proposed. OTFS-SCMA is a promising framework that meets the demands of high mobility and massive connectivity. This paper presents a channel estimation technique based on the convolutional sparse coding (CSC) approach for OTFS-SCMA in the uplink. The channel estimation task is formulated as a CSC problem following a careful rearrangement of the OTFS input-output relation. We use an embedded pilot-aided sparse-pilot structure that enjoys the features of both OTFS and SCMA. The existing channel estimation techniques for OTFS in multi-user scenarios for uplink demand extremely high overhead for pilot and guard symbols, proportional to the number of users. The proposed method maintains a minimal overhead equivalent to a single user without compromising on the estimation error. The results show that the proposed channel estimation algorithm is very efficient in bit error rate (BER), normalized mean square error (NMSE), and spectral efficiency (SE).      
### 15.Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal Learning with Robustness to Out-of-Distribution Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.09892.pdf)
>  Radiation exposure in positron emission tomography (PET) imaging limits its usage in the studies of radiation-sensitive populations, e.g., pregnant women, children, and adults that require longitudinal imaging. Reducing the PET radiotracer dose or acquisition time reduces photon counts, which can deteriorate image quality. Recent deep-neural-network (DNN) based methods for image-to-image translation enable the mapping of low-quality PET images (acquired using substantially reduced dose), coupled with the associated magnetic resonance imaging (MRI) images, to high-quality PET images. However, such DNN methods focus on applications involving test data that match the statistical characteristics of the training data very closely and give little attention to evaluating the performance of these DNNs on new out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that models the (i) underlying sinogram-based physics of the PET imaging system and (ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity of the residuals between the predicted and the high-quality reference images. Our sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a standard-dose PET image using multimodal input in the form of (i) a low-dose/low-count PET image and (ii) the corresponding multi-contrast MRI images, leading to improved robustness of suDNN to OOD acquisitions. Results on in vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show the benefits of suDNN over the current state of the art, quantitatively and qualitatively.      
### 16.Encoding Impact of Network Modification on Controllability via Edge Centrality Matrix  [ :arrow_down: ](https://arxiv.org/pdf/2107.09890.pdf)
>  This paper develops tools to quantify the importance of agent interactions and its impact on global performance metrics for networks modeled as linear time-invariant systems. We consider Gramian-based performance metrics and propose a novel notion of edge centrality that encodes the first-order variation in the metric with respect to the modification of the corresponding edge weight, including for those edges not present in the network. The proposed edge centrality matrix (ECM) is additive over the set of inputs, i.e., it captures the specific contribution to each edge's centrality of the presence of any given actuator. We provide a full characterization of the ECM structure for the class of directed stem-bud networks, showing that non-zero entries are only possible at specific sub/super-diagonals determined by the network size and the length of its bud. We also provide bounds on the value of the trace, trace inverse, and log-det of the Gramian before and after single-edge modifications, and on the edge-modification weight to ensure the modified network retains stability. Simulations show the utility of the proposed edge centrality notion and validate our results.      
### 17.Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum Cognition Models  [ :arrow_down: ](https://arxiv.org/pdf/2107.09888.pdf)
>  State-of-the-art driver-assist systems have failed to effectively mitigate driver inattention and had minimal impacts on the ever-growing number of road mishaps (e.g. life loss, physical injuries due to accidents caused by various factors that lead to driver inattention). This is because traditional human-machine interaction settings are modeled in classical and behavioral game-theoretic domains which are technically appropriate to characterize strategic interaction between either two utility maximizing agents, or human decision makers. Therefore, in an attempt to improve the persuasive effectiveness of driver-assist systems, we develop a novel strategic and personalized driver-assist system which adapts to the driver's mental state and choice behavior. First, we propose a novel equilibrium notion in human-system interaction games, where the system maximizes its expected utility and human decisions can be characterized using any general decision model. Then we use this novel equilibrium notion to investigate the strategic driver-vehicle interaction game where the car presents a persuasive recommendation to steer the driver towards safer driving decisions. We assume that the driver employs an open-quantum system cognition model, which captures complex aspects of human decision making such as violations to classical law of total probability and incompatibility of certain mental representations of information. We present closed-form expressions for players' final responses to each other's strategies so that we can numerically compute both pure and mixed equilibria. Numerical results are presented to illustrate both kinds of equilibria.      
### 18.Instabilizability Conditions for Continuous-Time Stochastic Systems Under Control Input Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2107.09882.pdf)
>  In this paper, we investigate constrained control of continuous-time linear stochastic systems. We show that for certain system parameter settings, constrained control policies can never achieve stabilization. Specifically, we explore a class of control policies that are constrained to have a bounded average second moment for Ito-type stochastic differential equations with additive and multiplicative noise. We prove that in certain settings of the system parameters and the bounding constant of the control constraint, divergence of the second moment of the system state is inevitable regardless of the initial state value and regardless of how the control policy is designed.      
### 19.EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based Stochastic Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2107.09853.pdf)
>  Electromyogram (EMG) has been utilized to interface signals for prosthetic hands and information devices owing to its ability to reflect human motion intentions. Although various EMG classification methods have been introduced into EMG-based control systems, they do not fully consider the stochastic characteristics of EMG signals. This paper proposes an EMG pattern classification method incorporating a scale mixture-based generative model. A scale mixture model is a stochastic EMG model in which the EMG variance is considered as a random variable, enabling the representation of uncertainty in the variance. This model is extended in this study and utilized for EMG pattern classification. The proposed method is trained by variational Bayesian learning, thereby allowing the automatic determination of the model complexity. Furthermore, to optimize the hyperparameters of the proposed method with a partial discriminative approach, a mutual information-based determination method is introduced. Simulation and EMG analysis experiments demonstrated the relationship between the hyperparameters and classification accuracy of the proposed method as well as the validity of the proposed method. The comparison using public EMG datasets revealed that the proposed method outperformed the various conventional classifiers. These results indicated the validity of the proposed method and its applicability to EMG-based control systems. In EMG pattern recognition, a classifier based on a generative model that reflects the stochastic characteristics of EMG signals can outperform the conventional general-purpose classifier.      
### 20.Modality-aware Mutual Learning for Multi-modal Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.09842.pdf)
>  Liver cancer is one of the most common cancers worldwide. Due to inconspicuous texture changes of liver tumor, contrast-enhanced computed tomography (CT) imaging is effective for the diagnosis of liver cancer. In this paper, we focus on improving automated liver tumor segmentation by integrating multi-modal CT images. To this end, we propose a novel mutual learning (ML) strategy for effective and robust multi-modal liver tumor segmentation. Different from existing multi-modal methods that fuse information from different modalities by a single model, with ML, an ensemble of modality-specific models learn collaboratively and teach each other to distill both the characteristics and the commonality between high-level representations of different modalities. The proposed ML not only enables the superiority for multi-modal learning but can also handle missing modalities by transferring knowledge from existing modalities to missing ones. Additionally, we present a modality-aware (MA) module, where the modality-specific models are interconnected and calibrated with attention weights for adaptive information exchange. The proposed modality-aware mutual learning (MAML) method achieves promising results for liver tumor segmentation on a large-scale clinical dataset. Moreover, we show the efficacy and robustness of MAML for handling missing modalities on both the liver tumor and public brain tumor (BRATS 2018) datasets. Our code is available at <a class="link-external link-https" href="https://github.com/YaoZhang93/MAML" rel="external noopener nofollow">this https URL</a>.      
### 21.Audio Captioning Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2107.09817.pdf)
>  Audio captioning aims to automatically generate a natural language description of an audio clip. Most captioning models follow an encoder-decoder architecture, where the decoder predicts words based on the audio features extracted by the encoder. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are often used as the audio encoder. However, CNNs can be limited in modelling temporal relationships among the time frames in an audio signal, while RNNs can be limited in modelling the long-range dependencies among the time frames. In this paper, we propose an Audio Captioning Transformer (ACT), which is a full Transformer network based on an encoder-decoder architecture and is totally convolution-free. The proposed method has a better ability to model the global information within an audio signal as well as capture temporal relationships between audio events. We evaluate our model on AudioCaps, which is the largest audio captioning dataset publicly available. Our model shows competitive performance compared to other state-of-the-art approaches.      
### 22.Frequency-Domain Data-Driven Controller Synthesis for Unstable LPV Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.09712.pdf)
>  Synthesizing controllers directly from frequency-domain measurement data is a powerful tool in the linear time-invariant framework. Ever-increasing performance requirements necessitate extending these approaches to account for plant variations. The aim of this paper is to develop frequency-domain analysis and synthesis conditions for local internal stability and $\mathcal{H}_\infty$-performance of single-input single-output linear parameter-varying systems. The developed synthesis procedure only requires frequency-domain measurement data of the system and does not need a parametric model of the plant. The capabilities of the synthesis procedure are demonstrated on an unstable nonlinear system.      
### 23.3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative Modeling of Three-Dimensional Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.09700.pdf)
>  Image synthesis via Generative Adversarial Networks (GANs) of three-dimensional (3D) medical images has great potential that can be extended to many medical applications, such as, image enhancement and disease progression modeling. However, current GAN technologies for 3D medical image synthesis need to be significantly improved to be readily adapted to real-world medical problems. In this paper, we extend the state-of-the-art StyleGAN2 model, which natively works with two-dimensional images, to enable 3D image synthesis. In addition to the image synthesis, we investigate the controllability and interpretability of the 3D-StyleGAN via style vectors inherited form the original StyleGAN2 that are highly suitable for medical applications: (i) the latent space projection and reconstruction of unseen real images, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and feasibility with ~12,000 three-dimensional full brain MR T1 images, although it can be applied to any 3D volumetric images. Furthermore, we explore different configurations of hyperparameters to investigate potential improvement of the image synthesis with larger networks. The codes and pre-trained networks are available online: <a class="link-external link-https" href="https://github.com/sh4174/3DStyleGAN" rel="external noopener nofollow">this https URL</a>.      
### 24.Genetic, Individual, and Familial Risk Correlates of Brain Network Controllability in Major Depressive Disorder  [ :arrow_down: ](https://arxiv.org/pdf/2107.10169.pdf)
>  Background: A therapeutic intervention in psychiatry can be viewed as an attempt to influence the brain's large-scale, dynamic network state transitions underlying cognition and behavior. Building on connectome-based graph analysis and control theory, Network Control Theory is emerging as a powerful tool to quantify network controllability - i.e., the influence of one brain region over others regarding dynamic network state transitions. If and how network controllability is related to mental health remains elusive. <br>Methods: From Diffusion Tensor Imaging data, we inferred structural connectivity and inferred calculated network controllability parameters to investigate their association with genetic and familial risk in patients diagnosed with major depressive disorder (MDD, n=692) and healthy controls (n=820). <br>Results: First, we establish that controllability measures differ between healthy controls and MDD patients while not varying with current symptom severity or remission status. Second, we show that controllability in MDD patients is associated with polygenic scores for MDD and psychiatric cross-disorder risk. Finally, we provide evidence that controllability varies with familial risk of MDD and bipolar disorder as well as with body mass index. <br>Conclusions: We show that network controllability is related to genetic, individual, and familial risk in MDD patients. We discuss how these insights into individual variation of network controllability may inform mechanistic models of treatment response prediction and personalized intervention-design in mental health.      
### 25.Global Outliers Detection in Wireless Sensor Networks: A Novel Approach Integrating Time-Series Analysis, Entropy, and Random Forest-based Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.10135.pdf)
>  Wireless Sensor Networks (WSNs) have recently attracted greater attention worldwide due to their practicality in monitoring, communicating, and reporting specific physical phenomena. The data collected by WSNs is often inaccurate as a result of unavoidable environmental factors, which may include noise, signal weakness, or intrusion attacks depending on the specific situation. Sending high-noise data has negative effects not just on data accuracy and network reliability, but also regarding the decision-making processes in the base station. Anomaly detection, or outlier detection, is the process of detecting noisy data amidst the contexts thus described. The literature contains relatively few noise detection techniques in the context of WSNs, particularly for outlier-detection algorithms applying time series analysis, which considers the effective neighbors to ensure a global-collaborative detection. Hence, the research presented in this paper is intended to design and implement a global outlier-detection approach, which allows us to find and select appropriate neighbors to ensure an adaptive collaborative detection based on time-series analysis and entropy techniques. The proposed approach applies a random forest algorithm for identifying the best results. To measure the effectiveness and efficiency of the proposed approach, a comprehensive and real scenario provided by the Intel Berkeley Research lab has been simulated. Noisy data have been injected into the collected data randomly. The results obtained from the experiment then conducted experimentation demonstrate that our approach can detect anomalies with up to 99% accuracy.      
### 26.Modeling and analysis of Duhem hysteresis operators with butterfly loops  [ :arrow_down: ](https://arxiv.org/pdf/2107.10101.pdf)
>  In this work we study and analyze a class of Duhem hysteresis operators that can exhibit butterfly loops. We study firstly the consistency property of such operator which corresponds to the existence of an attractive periodic solution when the operator is subject to a periodic input signal. Subsequently, we study the two defining functions of the Duhem operator such that the corresponding periodic solutions can admit a butterfly input-output phase plot. We present a number of examples where the Duhem butterfly hysteresis operators are constructed using two zero-level set curves that satisfy some mild conditions.      
### 27.A Tandem Framework Balancing Privacy and Security for Voice User Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2107.10045.pdf)
>  Speech synthesis, voice cloning, and voice conversion techniques present severe privacy and security threats to users of voice user interfaces (VUIs). These techniques transform one or more elements of a speech signal, e.g., identity and emotion, while preserving linguistic information. Adversaries may use advanced transformation tools to trigger a spoofing attack using fraudulent biometrics for a legitimate speaker. Conversely, such techniques have been used to generate privacy-transformed speech by suppressing personally identifiable attributes in the voice signals, achieving anonymization. Prior works have studied the security and privacy vectors in parallel, and thus it raises alarm that if a benign user can achieve privacy by a transformation, it also means that a malicious user can break security by bypassing the anti-spoofing mechanism. In this paper, we take a step towards balancing two seemingly conflicting requirements: security and privacy. It remains unclear what the vulnerabilities in one domain imply for the other, and what dynamic interactions exist between them. A better understanding of these aspects is crucial for assessing and mitigating vulnerabilities inherent with VUIs and building effective defenses. In this paper,(i) we investigate the applicability of the current voice anonymization methods by deploying a tandem framework that jointly combines anti-spoofing and authentication models, and evaluate the performance of these methods;(ii) examining analytical and empirical evidence, we reveal a duality between the two mechanisms as they offer different ways to achieve the same objective, and we show that leveraging one vector significantly amplifies the effectiveness of the other;(iii) we demonstrate that to effectively defend from potential attacks against VUIs, it is necessary to investigate the attacks from multiple complementary perspectives(security and privacy).      
### 28.Deep Iterative 2D/3D Registration  [ :arrow_down: ](https://arxiv.org/pdf/2107.10004.pdf)
>  Deep Learning-based 2D/3D registration methods are highly robust but often lack the necessary registration accuracy for clinical application. A refinement step using the classical optimization-based 2D/3D registration method applied in combination with Deep Learning-based techniques can provide the required accuracy. However, it also increases the runtime. In this work, we propose a novel Deep Learning driven 2D/3D registration framework that can be used end-to-end for iterative registration tasks without relying on any further refinement step. We accomplish this by learning the update step of the 2D/3D registration framework using Point-to-Plane Correspondences. The update step is learned using iterative residual refinement-based optical flow estimation, in combination with the Point-to-Plane correspondence solver embedded as a known operator. Our proposed method achieves an average runtime of around 8s, a mean re-projection distance error of 0.60 $\pm$ 0.40 mm with a success ratio of 97 percent and a capture range of 60 mm. The combination of high registration accuracy, high robustness, and fast runtime makes our solution ideal for clinical applications.      
### 29.Multi-Agent Belief Sharing through Autonomous Hierarchical Multi-Level Clustering  [ :arrow_down: ](https://arxiv.org/pdf/2107.09973.pdf)
>  Coordination in multi-agent systems is challenging for agile robots such as unmanned aerial vehicles (UAVs), where relative agent positions frequently change due to unconstrained movement. The problem is exacerbated through the individual take-off and landing of agents for battery recharging leading to a varying number of active agents throughout the whole mission. This work proposes autonomous hierarchical multi-level clustering (MLC), which forms a clustering hierarchy utilizing decentralized methods. Through periodic cluster maintenance executed by cluster-heads, stable multi-level clustering is achieved. The resulting hierarchy is used as a backbone to solve the communication problem for locally-interactive applications such as UAV tracking problems. Using observation aggregation, compression, and dissemination, agents share local observations throughout the hierarchy, giving every agent a total system belief with spatially dependent resolution and freshness. Extensive simulations show that MLC yields a stable cluster hierarchy under different motion patterns and that the proposed belief sharing is highly applicable in wildfire front monitoring scenarios.      
### 30.DOA Estimation for Hybrid Massive MIMO Systems using Mixed-ADCs: Performance Loss and Energy Efficiency  [ :arrow_down: ](https://arxiv.org/pdf/2107.09934.pdf)
>  Due to the power consumption and high circuit cost in antenna arrays, the practical application of massive multipleinput multiple-output (MIMO) in the sixth generation (6G) and future wireless networks is still challenging. Employing lowresolution analog-to-digital converters (ADCs) and hybrid analog and digital (HAD) structure is two low-cost choice with acceptable performance loss. In this paper, the combination of the mixedADC architecture and HAD structure employed at receiver is proposed for direction of arrival (DOA) estimation, which will be applied to the beamforming tracking and alignment in 6G. By adopting the additive quantization noise model, the exact closedform expression of the Cramer-Rao lower bound (CRLB) for the HAD architecture with mixed-ADCs is derived. Moreover, the closed-form expression of the performance loss factor is derived as a benchmark. In addition, to take power consumption into account, energy efficiency is also investigated in our paper. The numerical results reveal that the HAD structure with mixedADCs can significantly reduce the power consumption and hardware cost. Furthermore, that architecture is able to achieve a better trade-off between the performance loss and the power consumption. Finally, adopting 2-4 bits of resolution may be a good choice in practical massive MIMO systems.      
### 31.Risk-Based Safety Envelopes for Autonomous Vehicles Under Perception Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2107.09918.pdf)
>  Ensuring the safety of autonomous vehicles, given the uncertainty in sensing other road users, is an open problem. Moreover, separate safety specifications for perception and planning components raise how to assess the overall system safety. This work provides a probabilistic approach to calculate safety envelopes under perception uncertainty. The probabilistic envelope definition is based on a risk threshold. It limits the cumulative probability that the actual safety envelope in a fully observable environment is larger than an applied envelope and is solved using iterative worst-case analysis of envelopes. Our approach extends non-probabilistic envelopes - in this work, the Responsibility-Sensitive Safety (RSS) - to handle uncertainties. To evaluate our probabilistic envelope approach, we compare it in a simulated highway merging scenario against several baseline safety architectures. Our evaluation shows that our model allows adjusting safety and performance based on a chosen risk level and the amount of perception uncertainty. We conclude with an outline of how to formally argue safety under perception uncertainty using our formulation of envelope violation risk.      
### 32.THz Transmission meets Untrusted UAV-Relaying; Trajectory and Communication Co-design for Secrecy Energy Efficiency Maximization  [ :arrow_down: ](https://arxiv.org/pdf/2107.09896.pdf)
>  Unmanned aerial vehicles (UAVs) and Terahertz (THz) technology are envisioned to play paramount roles in next-generation wireless communications. Hence, this paper presents a novel secure UAV-assisted mobile relaying system operating at THz bands for data acquisition from multiple ground user equipments towards a destination. We assume that the UAV-mounted relay may act, besides providing relaying services, as a potential adversary called the untrusted UAV relay. To safeguard end-to-end communications, we present a secure two-phase transmission strategy with cooperative jamming. Then, we formulate an optimization problem in terms of a new measure $-$ secrecy energy efficiency (SEE), defined as the ratio of achievable average secrecy rate to average system power consumption, which enables us to obtain the best possible security level while taking UAV's inherent flight power limitation into account. This optimization problem leads to a joint design of key system parameters, including UAV's trajectory and velocity, communication scheduling, and power allocations. Since the formulated problem is a mixed-integer nonconvex optimization and computationally intractable, we propose alternative algorithms to solve it efficiently via greedy/sequential block coordinated descent, successive convex approximation, and non-linear fractional programming techniques. Numerical results demonstrate significant SEE performance improvement of our designs when compared to other known benchmarks.      
### 33.Music Plagiarism Detection via Bipartite Graph Matching  [ :arrow_down: ](https://arxiv.org/pdf/2107.09889.pdf)
>  Nowadays, with the prevalence of social media and music creation tools, musical pieces are spreading much quickly, and music creation is getting much easier. The increasing number of musical pieces have made the problem of music plagiarism prominent. There is an urgent need for a tool that can detect music plagiarism automatically. Researchers have proposed various methods to extract low-level and high-level features of music and compute their similarities. However, low-level features such as cepstrum coefficients have weak relation with the copyright protection of musical pieces. Existing algorithms considering high-level features fail to detect the case in which two musical pieces are not quite similar overall, but have some highly similar regions. This paper proposes a new method named MESMF, which innovatively converts the music plagiarism detection problem into the bipartite graph matching task. It can be solved via the maximum weight matching and edit distances model. We design several kinds of melody representations and the similarity computation methods according to the music theory. The proposed method can deal with the shift, swapping, transposition, and tempo variance problems in music plagiarism. It can also effectively pick out the local similar regions from two musical pieces with relatively low global similarity. We collect a new music plagiarism dataset from real legally-judged music plagiarism cases and conduct detailed ablation studies. Experimental results prove the excellent performance of the proposed algorithm. The source code and our dataset are available at https://anonymous.4open.science/r/a41b8fb4-64cf-4190-a1e1-09b7499a15f5/      
### 34.Melody Structure Transfer Network: Generating Music with Separable Self-Attention  [ :arrow_down: ](https://arxiv.org/pdf/2107.09877.pdf)
>  Symbolic music generation has attracted increasing attention, while most methods focus on generating short piece (mostly less than 8 bars, and up to 32 bars). Generating long music calls for effective expression of the coherent music structure. Despite their success on long sequences, self-attention architectures still have challenge in dealing with long-term music as it requires additional care on the subtle music structure. In this paper, we propose to transfer the structure of training samples for new music generation, and develop a novel separable self-attention based model which enable the learning and transferring of the structure embedding. We show that our transfer model can generate music sequences (up to 100 bars) with interpretable structures, which bears similar structures and composition techniques with the template music from training set. Extensive experiments show its ability of generating music with target structure and well diversity. The generated 3,000 sets of music is uploaded as supplemental material.      
### 35.ECG Heartbeat Classification Using Multimodal Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2107.09869.pdf)
>  Electrocardiogram (ECG) is an authoritative source to diagnose and counter critical cardiovascular syndromes such as arrhythmia and myocardial infarction (MI). Current machine learning techniques either depend on manually extracted features or large and complex deep learning networks which merely utilize the 1D ECG signal directly. Since intelligent multimodal fusion can perform at the stateof-the-art level with an efficient deep network, therefore, in this paper, we propose two computationally efficient multimodal fusion frameworks for ECG heart beat classification called Multimodal Image Fusion (MIF) and Multimodal Feature Fusion (MFF). At the input of these frameworks, we convert the raw ECG data into three different images using Gramian Angular Field (GAF), Recurrence Plot (RP) and Markov Transition Field (MTF). In MIF, we first perform image fusion by combining three imaging modalities to create a single image modality which serves as input to the Convolutional Neural Network (CNN). In MFF, we extracted features from penultimate layer of CNNs and fused them to get unique and interdependent information necessary for better performance of classifier. These informational features are finally used to train a Support Vector Machine (SVM) classifier for ECG heart-beat classification. We demonstrate the superiority of the proposed fusion models by performing experiments on PhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which are consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for Myocardial Infarction (MI) classification. We achieved classification accuracy of 99.7% and 99.2% on arrhythmia and MI classification, respectively.      
### 36.Bidirectional Approximate Message Passing for RIS-Assisted Multi-User MISO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2107.09836.pdf)
>  Reconfigurable intelligent surfaces (RISs) have been recently considered as a promising candidate for energy-efficient solutions in future wireless networks. Their dynamic and lowpower configuration enables coverage extension, massive connectivity, and low-latency communications. Due to a large number of unknown variables referring to the RIS unit elements and the transmitted signals, channel estimation and signal recovery in RIS-based systems are the ones of the most critical technical challenges. To address this problem, we focus on the RIS-assisted multi-user wireless communication system and present a joint channel estimation and signal recovery algorithm in this paper. Specifically, we propose a bidirectional approximate message passing algorithm that applies the Taylor series expansion and Gaussian approximation to simplify the sum-product algorithm in the formulated problem. Our simulation results show that the proposed algorithm shows the superiority over a state-of-art benchmark method. We also provide insights on the impact of different RIS parameter settings on the proposed algorithms.      
### 37.Bayesian Controller Fusion: Leveraging Control Priors in Deep Reinforcement Learning for Robotics  [ :arrow_down: ](https://arxiv.org/pdf/2107.09822.pdf)
>  We present Bayesian Controller Fusion (BCF): a hybrid control strategy that combines the strengths of traditional hand-crafted controllers and model-free deep reinforcement learning (RL). BCF thrives in the robotics domain, where reliable but suboptimal control priors exist for many tasks, but RL from scratch remains unsafe and data-inefficient. By fusing uncertainty-aware distributional outputs from each system, BCF arbitrates control between them, exploiting their respective strengths. We study BCF on two real-world robotics tasks involving navigation in a vast and long-horizon environment, and a complex reaching task that involves manipulability maximisation. For both these domains, there exist simple handcrafted controllers that can solve the task at hand in a risk-averse manner but do not necessarily exhibit the optimal solution given limitations in analytical modelling, controller miscalibration and task variation. As exploration is naturally guided by the prior in the early stages of training, BCF accelerates learning, while substantially improving beyond the performance of the control prior, as the policy gains more experience. More importantly, given the risk-aversity of the control prior, BCF ensures safe exploration \emph{and} deployment, where the control prior naturally dominates the action distribution in states unknown to the policy. We additionally show BCF's applicability to the zero-shot sim-to-real setting and its ability to deal with out-of-distribution states in the real-world. BCF is a promising approach for combining the complementary strengths of deep RL and traditional robotic control, surpassing what either can achieve independently. The code and supplementary video material are made publicly available at \url{<a class="link-external link-https" href="https://krishanrana.github.io/bcf" rel="external noopener nofollow">this https URL</a>}.      
### 38.High-dimensional Multivariate Time Series Forecasting in IoT Applications using Embedding Non-stationary Fuzzy Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2107.09785.pdf)
>  In Internet of things (IoT), data is continuously recorded from different data sources and devices can suffer faults in their embedded electronics, thus leading to a high-dimensional data sets and concept drift events. Therefore, methods that are capable of high-dimensional non-stationary time series are of great value in IoT applications. Fuzzy Time Series (FTS) models stand out as data-driven non-parametric models of easy implementation and high accuracy. Unfortunately, FTS encounters difficulties when dealing with data sets of many variables and scenarios with concept drift. We present a new approach to handle high-dimensional non-stationary time series, by projecting the original high-dimensional data into a low dimensional embedding space and using FTS approach. Combining these techniques enables a better representation of the complex content of non-stationary multivariate time series and accurate forecasts. Our model is able to explain 98% of the variance and reach 11.52% of RMSE, 2.68% of MAE and 2.91% of MAPE.      
### 39.Conjugate Beamforming with Fractional-Exponent Normalization and Scalable Power Control in Cell-Free Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2107.09777.pdf)
>  This paper considers a cell-free massive MIMO (CF-mMIMO) system using conjugate beamforming (CB) with fractional-exponent normalization. Assuming independent Rayleigh fading channels, a generalized closed-form expression for the achievable downlink spectral efficiency is derived, which subsumes, as special cases, the spectral efficiency expressions previously reported for plain CB and its variants, i.e. normalized CB and enhanced CB. Downlink power control is also tackled, and a reduced-complexity power allocation strategy is proposed, wherein only one coefficient for access point (AP) is optimized based on the long-term fading realizations. Numerical results unveil the performance of CF-mMIMO with CB and fractional-exponent normalization, and show that the proposed power optimization rule incurs a moderate performance loss with respect to the traditional max-min power control rule, but with lower complexity and much smaller overall power consumption.      
### 40.Online Projected Gradient Descent for Stochastic Optimization with Decision-Dependent Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2107.09721.pdf)
>  This paper investigates the problem of tracking solutions of stochastic optimization problems with time-varying costs and decision-dependent distributions. In this context, the paper focuses on the online stochastic gradient descent method, and establishes its convergence to the sequence of optimizers (within a bounded error) in expectation and in high probability. In particular, high-probability convergence results are derived by modeling the gradient error as a sub-Weibull random variable. The theoretical findings are validated via numerical simulations in the context of charging optimization of a fleet of electric vehicles.      
### 41.An Efficient Multi-objective Evolutionary Approach for Solving the Operation of Multi-Reservoir System Scheduling in Hydro-Power Plants  [ :arrow_down: ](https://arxiv.org/pdf/2107.09718.pdf)
>  This paper tackles the short-term hydro-power unit commitment problem in a multi-reservoir system - a cascade-based operation scenario. For this, we propose a new mathematical modelling in which the goal is to maximize the total energy production of the hydro-power plant in a sub-daily operation, and, simultaneously, to maximize the total water content (volume) of reservoirs. For solving the problem, we discuss the Multi-objective Evolutionary Swarm Hybridization (MESH) algorithm, a recently proposed multi-objective swarm intelligence-based optimization method which has obtained very competitive results when compared to existing evolutionary algorithms in specific applications. The MESH approach has been applied to find the optimal water discharge and the power produced at the maximum reservoir volume for all possible combinations of turbines in a hydro-power plant. The performance of MESH has been compared with that of well-known evolutionary approaches such as NSGA-II, NSGA-III, SPEA2, and MOEA/D in a realistic problem considering data from a hydro-power energy system with two cascaded hydro-power plants in Brazil. Results indicate that MESH showed a superior performance than alternative multi-objective approaches in terms of efficiency and accuracy, providing a profit of \$412,500 per month in a projection analysis carried out.      
### 42.Regularized Classification-Aware Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2107.09716.pdf)
>  Traditionally, quantization is designed to minimize the reconstruction error of a data source. When considering downstream classification tasks, other measures of distortion can be of interest; such as the 0-1 classification loss. Furthermore, it is desirable that the performance of these quantizers not deteriorate once they are deployed into production, as relearning the scheme online is not always possible. In this work, we present a class of algorithms that learn distributed quantization schemes for binary classification tasks. Our method performs well on unseen data, and is faster than previous methods proportional to a quadratic term of the dataset size. It works by regularizing the 0-1 loss with the reconstruction error. We present experiments on synthetic mixture and bivariate Gaussian data and compare training, testing, and generalization errors with a family of benchmark quantization schemes from the literature. Our method is called Regularized Classification-Aware Quantization.      
### 43.Human Perception of Audio Deepfakes  [ :arrow_down: ](https://arxiv.org/pdf/2107.09667.pdf)
>  The recent emergence of deepfakes, computerized realistic multimedia fakes, brought the detection of manipulated and generated content to the forefront. While many machine learning models for deepfakes detection have been proposed, the human detection capabilities have remained far less explored. This is of special importance as human perception differs from machine perception and deepfakes are generally designed to fool the human. So far, this issue has only been addressed in the area of images and video. <br>To compare the ability of humans and machines in detecting audio deepfakes, we conducted an online gamified experiment in which we asked users to discern bonda-fide audio samples from spoofed audio, generated with a variety of algorithms. 200 users competed for 8976 game rounds with an artificial intelligence (AI) algorithm trained for audio deepfake detection. With the collected data we found that the machine generally outperforms the humans in detecting audio deepfakes, but that the converse holds for a certain attack type, for which humans are still more accurate. Furthermore, we found that younger participants are on average better at detecting audio deepfakes than older participants, while IT-professionals hold no advantage over laymen. We conclude that it is important to combine human and machine knowledge in order to improve audio deepfake detection.      
