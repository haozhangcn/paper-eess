# ArXiv eess --Thu, 29 Jul 2021
### 1.TEDS-Net: Enforcing Diffeomorphisms in Spatial Transformers to Guarantee Topology Preservation in Segmentations  [ :arrow_down: ](https://arxiv.org/pdf/2107.13542.pdf)
>  Accurate topology is key when performing meaningful anatomical segmentations, however, it is often overlooked in traditional deep learning methods. In this work we propose TEDS-Net: a novel segmentation method that guarantees accurate topology. Our method is built upon a continuous diffeomorphic framework, which enforces topology preservation. However, in practice, diffeomorphic fields are represented using a finite number of parameters and sampled using methods such as linear interpolation, violating the theoretical guarantees. We therefore introduce additional modifications to more strictly enforce it. Our network learns how to warp a binary prior, with the desired topological characteristics, to complete the segmentation task. We tested our method on myocardium segmentation from an open-source 2D heart dataset. TEDS-Net preserved topology in 100% of the cases, compared to 90% from the U-Net, without sacrificing on Hausdorff Distance or Dice performance. Code will be made available at: <a class="link-external link-http" href="http://www.github.com/mwyburd/TEDS-Net" rel="external noopener nofollow">this http URL</a>      
### 2.Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.13530.pdf)
>  We present a method for continual learning of speech representations for multiple languages using self-supervised learning (SSL) and applying these for automatic speech recognition. There is an abundance of unannotated speech, so creating self-supervised representations from raw audio and finetuning on a small annotated datasets is a promising direction to build speech recognition systems. Wav2vec models perform SSL on raw audio in a pretraining phase and then finetune on a small fraction of annotated data. SSL models have produced state of the art results for ASR. However, these models are very expensive to pretrain with self-supervision. We tackle the problem of learning new language representations continually from audio without forgetting a previous language representation. We use ideas from continual learning to transfer knowledge from a previous task to speed up pretraining a new language task. Our continual-wav2vec2 model can decrease pretraining times by 32% when learning a new language task, and learn this new audio-language representation without forgetting previous language representation.      
### 3.Minimum Structural Sensor Placement for Switched Linear Time-Invariant Systems and Unknown Inputs  [ :arrow_down: ](https://arxiv.org/pdf/2107.13493.pdf)
>  In this paper, we study the structural state and input observability of continuous-time switched linear time-invariant systems and unknown inputs. First, we provide necessary and sufficient conditions for their structural state and input observability that can be efficiently verified in $O((m(n+p))^2)$, where $n$ is the number of state variables, $p$ is the number of unknown inputs, and $m$ is the number of modes. Moreover, we address the minimum sensor placement problem for these systems by adopting a feed-forward analysis and by providing an algorithm with a computational complexity of $ O((m(n+p)+\alpha)^{2.373})$, where $\alpha$ is the number of target strongly connected components of the system's digraph representation. Lastly, we explore different assumptions on both the system and unknown inputs (latent space) dynamics that add more structure to the problem, and thereby, enable us to render algorithms with lower computational complexity, which are suitable for implementation in large-scale systems.      
### 4.The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation  [ :arrow_down: ](https://arxiv.org/pdf/2107.13473.pdf)
>  Electroencephalography (EEG) is a method of measuring the brain's electrical activity, using non-invasive scalp electrodes. In this article, we propose the Portiloop, a deep learning-based portable and low-cost device enabling the neuroscience community to capture EEG, process it in real time, detect patterns of interest, and respond with precisely-timed stimulation. The core of the Portiloop is a System on Chip composed of an Analog to Digital Converter (ADC) and a Field-Programmable Gate Array (FPGA). After being converted to digital by the ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc Artificial Neural Network (ANN) with convolutional and recurrent units, directly implemented in hardware. The output of the ANN is then used to trigger the user-defined feedback. We use the Portiloop to develop a real-time sleep spindle stimulating application, as a case study. Sleep spindles are a specific type of transient oscillation ($\sim$2.5 s, 12-16 Hz) that are observed in EEG recordings, and are related to memory consolidation during sleep. We tested the Portiloop's capacity to detect and stimulate sleep spindles in real time using an existing database of EEG sleep recordings. With 71% for both precision and recall as compared with expert labels, the system is able to stimulate spindles within $\sim$300 ms of their onset, enabling experimental manipulation of early the entire spindle. The Portiloop can be extended to detect and stimulate other neural events in EEG. It is fully available to the research community as an open science project.      
### 5.Operationally-Safe Peer-to-Peer Energy Trading in Distribution Grids: A Game-Theoretic Market-Clearing Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2107.13444.pdf)
>  In future distribution grids, prosumers (i.e., energy consumers with storage and/or production capabilities) will trade energy with each other and with the main grid. To ensure an efficient and safe operation of energy trading, in this paper, we formulate a peer-to-peer energy market of prosumers as a generalized aggregative game, in which a network operator is only responsible for the operational constraints of the system. We design a distributed market-clearing mechanism with convergence guarantee to an economically-efficient and operationally-safe configuration (i.e., a variational generalized Nash equilibrium). Numerical studies on the IEEE 37-bus testcase show the scalability of the proposed approach and suggest that active participation in the market is beneficial for both prosumers and the network operator.      
### 6.AI assisted method for efficiently generating breast ultrasound screening reports  [ :arrow_down: ](https://arxiv.org/pdf/2107.13431.pdf)
>  Ultrasound is the preferred choice for early screening of dense breast cancer. Clinically, doctors have to manually write the screening report which is time-consuming and laborious, and it is easy to miss and miswrite. Therefore, this paper proposes a method for efficiently generating personalized breast ultrasound screening preliminary reports by AI, especially for benign and normal cases which account for the majority. Doctors then make simple adjustments or corrections to quickly generate final reports. The proposed approach has been tested using a database of 1133 breast tumor instances. Experimental results indicate this pipeline improves doctors' work efficiency by up to 90%, which greatly reduces repetitive work.      
### 7.Vowel-based Meeteilon dialect identification using a Random Forest classifier  [ :arrow_down: ](https://arxiv.org/pdf/2107.13419.pdf)
>  This paper presents a vowel-based dialect identification system for Meeteilon. For this work, a vowel dataset is created by using Meeteilon Speech Corpora available at Linguistic Data Consortium for Indian Languages (LDC-IL). Spectral features such as formant frequencies (F1, F1 and F3) and prosodic features such as pitch (F0), energy, intensity and segment duration values are extracted from monophthong vowel sounds. Random forest classifier, a decision tree-based ensemble algorithm is used for classification of three major dialects of Meeteilon namely, Imphal, Kakching and Sekmai. Model has shown an average dialect identification performance in terms of accuracy of around 61.57%. The role of spectral and prosodic features are found to be significant in Meeteilon dialect classification.      
### 8.High-speed object detection with a single-photon time-of-flight image sensor  [ :arrow_down: ](https://arxiv.org/pdf/2107.13407.pdf)
>  3D time-of-flight (ToF) imaging is used in a variety of applications such as augmented reality (AR), computer interfaces, robotics and autonomous systems. Single-photon avalanche diodes (SPADs) are one of the enabling technologies providing accurate depth data even over long ranges. By developing SPADs in array format with integrated processing combined with pulsed, flood-type illumination, high-speed 3D capture is possible. However, array sizes tend to be relatively small, limiting the lateral resolution of the resulting depth maps, and, consequently, the information that can be extracted from the image for applications such as object detection. In this paper, we demonstrate that these limitations can be overcome through the use of convolutional neural networks (CNNs) for high-performance object detection. We present outdoor results from a portable SPAD camera system that outputs 16-bin photon timing histograms with 64x32 spatial resolution. The results, obtained with exposure times down to 2 ms (equivalent to 500 FPS) and in signal-to-background (SBR) ratios as low as 0.05, point to the advantages of providing the CNN with full histogram data rather than point clouds alone. Alternatively, a combination of point cloud and active intensity data may be used as input, for a similar level of performance. In either case, the GPU-accelerated processing time is less than 1 ms per frame, leading to an overall latency (image acquisition plus processing) in the millisecond range, making the results relevant for safety-critical computer vision applications which would benefit from faster than human reaction times.      
### 9.A Complete End-To-End Open Source Toolchain for the Versatile Video Coding (VVC) Standard  [ :arrow_down: ](https://arxiv.org/pdf/2107.13385.pdf)
>  Versatile Video Coding (VVC) is the most recent international video coding standard jointly developed by ITU-T and ISO/IEC, which has been finalized in July 2020. VVC allows for significant bit-rate reductions around 50% for the same subjective video quality compared to its predecessor, High Efficiency Video Coding (HEVC). One year after finalization, VVC support in devices and chipsets is still under development, which is aligned with the typical development cycles of new video coding standards. This paper presents open-source software packages that allow building a complete VVC end-to-end toolchain already one year after its finalization. This includes the Fraunhofer HHI VVenC library for fast and efficient VVC encoding as well as HHI's VVdeC library for live decoding. An experimental integration of VVC in the GPAC software tools and FFmpeg media framework allows packaging VVC bitstreams, e.g. encoded with VVenC, in MP4 file format and using DASH for content creation and streaming. The integration of VVdeC allows playback on the receiver. Given these packages, step-by-step tutorials are provided for two possible application scenarios: VVC file encoding plus playback and adaptive streaming with DASH.      
### 10.Deep learning based cough detection camera using enhanced features  [ :arrow_down: ](https://arxiv.org/pdf/2107.13260.pdf)
>  Coughing is a typical symptom of COVID-19. To detect and localize coughing sounds remotely, a convolutional neural network (CNN) based deep learning model was developed in this work and integrated with a sound camera for the visualization of the cough sounds. The cough detection model is a binary classifier of which the input is a two second acoustic feature and the output is one of two inferences (Cough or Others). Data augmentation was performed on the collected audio files to alleviate class imbalance and reflect various background noises in practical environments. For effective featuring of the cough sound, conventional features such as spectrograms, mel-scaled spectrograms, and mel-frequency cepstral coefficients (MFCC) were reinforced by utilizing their velocity (V) and acceleration (A) maps in this work. VGGNet, GoogLeNet, and ResNet were simplified to binary classifiers, and were named V-net, G-net, and R-net, respectively. To find the best combination of features and networks, training was performed for a total of 39 cases and the performance was confirmed using the test F1 score. Finally, a test F1 score of 91.9% (test accuracy of 97.2%) was achieved from G-net with the MFCC-V-A feature (named Spectroflow), an acoustic feature effective for use in cough detection. The trained cough detection model was integrated with a sound camera (i.e., one that visualizes sound sources using a beamforming microphone array). In a pilot test, the cough detection camera detected coughing sounds with an F1 score of 90.0% (accuracy of 96.0%), and the cough location in the camera image was tracked in real time.      
### 11.A Visual Domain Transfer Learning Approach for Heartbeat Sound Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.13237.pdf)
>  Heart disease is the most common reason for human mortality that causes almost one-third of deaths throughout the world. Detecting the disease early increases the chances of survival of the patient and there are several ways a sign of heart disease can be detected early. This research proposes to convert cleansed and normalized heart sound into visual mel scale spectrograms and then using visual domain transfer learning approaches to automatically extract features and categorize between heart sounds. Some of the previous studies found that the spectrogram of various types of heart sounds is visually distinguishable to human eyes, which motivated this study to experiment on visual domain classification approaches for automated heart sound classification. It will use convolution neural network-based architectures i.e. ResNet, MobileNetV2, etc as the automated feature extractors from spectrograms. These well-accepted models in the image domain showed to learn generalized feature representations of cardiac sounds collected from different environments with varying amplitude and noise levels. Model evaluation criteria used were categorical accuracy, precision, recall, and AUROC as the chosen dataset is unbalanced. The proposed approach has been implemented on datasets A and B of the PASCAL heart sound collection and resulted in ~ 90% categorical accuracy and AUROC of ~0.97 for both sets.      
### 12.Collision-free Formation Control of Multiple Nano-quadrotors  [ :arrow_down: ](https://arxiv.org/pdf/2107.13203.pdf)
>  The utilisation of unmanned aerial vehicles has witnessed significant growth in real-world applications including surveillance tasks, military missions, and transportation deliveries. This letter investigates practical problems of formation control for multiple nano-quadrotor systems. To be more specific, the first aim of this work is to develop a theoretical framework for the time-varying formation flight of the multi-quadrotor system regarding anti-collisions. In order to achieve this goal, the finite cut-off potential function is devoted to avoiding collisions among vehicles in the group as well as between vehicles and an obstacle. The control algorithm navigates the group of nano-quadrotors to asymptotically reach an anticipated time-varying formation. The second aim is to implement the proposed algorithm on Crazyflies nanoquadrotors, one of the most ubiquitous indoor experimentation platforms. Several practical scenarios are conducted to tendentiously expose anti-collision abilities among group members as well as between vehicles and an obstacle. The experimental outcomes validate the effectiveness of the proposed method in the formation tracking and the collision avoidance of multiple nano-quadrotors.      
### 13.An explainable two-dimensional single model deep learning approach for Alzheimer's disease diagnosis and brain atrophy localization  [ :arrow_down: ](https://arxiv.org/pdf/2107.13200.pdf)
>  Early and accurate diagnosis of Alzheimer's disease (AD) and its prodromal period mild cognitive impairment (MCI) is essential for the delayed disease progression and the improved quality of patients'life. The emerging computer-aided diagnostic methods that combine deep learning with structural magnetic resonance imaging (sMRI) have achieved encouraging results, but some of them are limit of issues such as data leakage and unexplainable diagnosis. In this research, we propose a novel end-to-end deep learning approach for automated diagnosis of AD and localization of important brain regions related to the disease from sMRI data. This approach is based on a 2D single model strategy and has the following differences from the current approaches: 1) Convolutional Neural Network (CNN) models of different structures and capacities are evaluated systemically and the most suitable model is adopted for AD diagnosis; 2) a data augmentation strategy named Two-stage Random RandAugment (TRRA) is proposed to alleviate the overfitting issue caused by limited training data and to improve the classification performance in AD diagnosis; 3) an explainable method of Grad-CAM++ is introduced to generate the visually explainable heatmaps that localize and highlight the brain regions that our model focuses on and to make our model more transparent. Our approach has been evaluated on two publicly accessible datasets for two classification tasks of AD vs. cognitively normal (CN) and progressive MCI (pMCI) vs. stable MCI (sMCI). The experimental results indicate that our approach outperforms the state-of-the-art approaches, including those using multi-model and 3D CNN methods. The resultant localization heatmaps from our approach also highlight the lateral ventricle and some disease-relevant regions of cortex, coincident with the commonly affected regions during the development of AD.      
### 14.Label Design-based ELM Network for Timing Synchronization in OFDM Systems with Nonlinear Distortion  [ :arrow_down: ](https://arxiv.org/pdf/2107.13177.pdf)
>  Due to the nonlinear distortion in Orthogonal frequency division multiplexing (OFDM) systems, the timing synchronization (TS) performance is inevitably degraded at the receiver. To relieve this issue, an extreme learning machine (ELM)-based network with a novel learning label is proposed to the TS of OFDM system in our work and increases the possibility of symbol timing offset (STO) estimation residing in inter-symbol interference (ISI)-free region. Especially, by exploiting the prior information of the ISI-free region, two types of learning labels are developed to facilitate the ELM-based TS network. With designed learning labels, a timing-processing by classic TS scheme is first executed to capture the coarse timing metric (TM) and then followed by an ELM network to refine the TM. According to experiments and analysis, our scheme shows its effectiveness in the improvement of TS performance and reveals its generalization performance in different training and testing channel scenarios.      
### 15.Retinal Microvasculature as Biomarker for Diabetes and Cardiovascular Diseases  [ :arrow_down: ](https://arxiv.org/pdf/2107.13157.pdf)
>  Purpose: To demonstrate that retinal microvasculature per se is a reliable biomarker for Diabetic Retinopathy (DR) and, by extension, cardiovascular diseases. Methods: Deep Learning Convolutional Neural Networks (CNN) applied to color fundus images for semantic segmentation of the blood vessels and severity classification on both vascular and full images. Vessel reconstruction through harmonic descriptors is also used as a smoothing and de-noising tool. The mathematical background of the theory is also outlined. Results: For diabetic patients, at least 93.8% of DR No-Refer vs. Refer classification can be related to vasculature defects. As for the Non-Sight Threatening vs. Sight Threatening case, the ratio is as high as 96.7%. Conclusion: In the case of DR, most of the disease biomarkers are related topologically to the vasculature. Translational Relevance: Experiments conducted on eye blood vasculature reconstruction as a biomarker shows a strong correlation between vasculature shape and later stages of DR.      
### 16.Insights from Generative Modeling for Neural Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2107.13136.pdf)
>  While recent machine learning research has revealed connections between deep generative models such as VAEs and rate-distortion losses used in learned compression, most of this work has focused on images. In a similar spirit, we view recently proposed neural video coding algorithms through the lens of deep autoregressive and latent variable modeling. We present recent neural video codecs as instances of a generalized stochastic temporal autoregressive transform, and propose new avenues for further improvements inspired by normalizing flows and structured priors. We propose several architectures that yield state-of-the-art video compression performance on full-resolution video and discuss their tradeoffs and ablations. In particular, we propose (i) improved temporal autoregressive transforms, (ii) improved entropy models with structured and temporal dependencies, and (iii) variable bitrate versions of our algorithms. Since our improvements are compatible with a large class of existing models, we provide further evidence that the generative modeling viewpoint can advance the neural video coding field.      
### 17.Learning Site-Specific Probing Beams for Fast mmWave Beam Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2107.13121.pdf)
>  Beam alignment - the process of finding an optimal directional beam pair - is a challenging procedure crucial to millimeter wave (mmWave) communication systems. We propose a novel beam alignment method that learns a site-specific probing codebook and uses the probing codebook measurements to predict the optimal narrow beam. An end-to-end neural network (NN) architecture is designed to jointly learn the probing codebook and the beam predictor. The learned codebook consists of site-specific probing beams that can capture particular characteristics of the propagation environment. The proposed method relies on beam sweeping of the learned probing codebook, does not require additional context information, and is compatible with the beam sweeping-based beam alignment framework in 5G. Using realistic ray-tracing datasets, we demonstrate that the proposed method can achieve high beam alignment accuracy and signal-to-noise ratio (SNR) while significantly - by roughly a factor of 3 in our setting - reducing the beam sweeping complexity and latency.      
### 18.Combining physics-based modeling and deep learning for ultrasound elastography  [ :arrow_down: ](https://arxiv.org/pdf/2107.13120.pdf)
>  Ultrasound elasticity images which enable the visualization of quantitative maps of tissue stiffness can be reconstructed by solving an inverse problem. Classical model-based approaches for ultrasound elastography use deterministic finite element methods (FEMs) to incorporate the governing physical laws resulting in poor performance in noisy conditions. Moreover, these approaches utilize fixed regularizers for various tissue patterns while appropriate data-adaptive priors might be required for capturing the complex spatial elasticity distribution. In this regard, we propose a joint model-based and learning-based framework for estimating the elasticity distribution by solving a regularized optimization problem. We present an integrated objective function composed of a statistical physics-based forward model and a data-driven regularizer to leverage deep neural networks for learning the underlying elasticity prior. This constrained optimization problem is solved using the gradient descent (GD) method and the gradient of regularizer is simply replaced by the residual of the trained denoiser network for having an explicit objective function with reduced computation time.      
### 19.A Highly Linear and Flexible FPGA-Based Time-to-Digital Converter  [ :arrow_down: ](https://arxiv.org/pdf/2107.13053.pdf)
>  Time-to-Digital Converters (TDCs) are major components for the measurements of time intervals. Recent developments in Field-Programmable Gate Array (FPGA) have enabled the opportunity to implement high-performance TDCs, which were only possible using dedicated hardware. In order to eliminate empty histogram bins and achieve a higher level of linearity, FPGA-based TDCs typically apply compensation methods either using multiple delay lines consuming more resources or post-processing, leading to a permanent loss of temporal information. We propose a novel TDC with a single delay line and without compensation to realize a highly linear TDC by encoding the states of the delay lines instead of the thermometer code used in the conventional TDCs. Experimental results show that the empty histogram bins are reduced to less than 0.1% at the time resolution of 5.00ps, and have not been observed in the selected time resolutions of 10.04ps, 21.65ps, 43.87ps, 64.11ps, and 87.73ps. Our states-based approach achieves an improved Differential Non-Linearity (DNL) of [-1.00, -1.53] for 5.00ps, [-0.44,0.49] for 10.04ps, and [-0.07, 0.05] for 87.73ps. We have achieved a TDC with higher raw linearity, reduced empty bins, and a simpler structure compared with the previous FPGA-based TDC.      
### 20.Whole Slide Images are 2D Point Clouds: Context-Aware Survival Prediction using Patch-based Graph Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.13048.pdf)
>  Cancer prognostication is a challenging task in computational pathology that requires context-aware representations of histology features to adequately infer patient survival. Despite the advancements made in weakly-supervised deep learning, many approaches are not context-aware and are unable to model important morphological feature interactions between cell identities and tissue types that are prognostic for patient survival. In this work, we present Patch-GCN, a context-aware, spatially-resolved patch-based graph convolutional network that hierarchically aggregates instance-level histology features to model local- and global-level topological structures in the tumor microenvironment. We validate Patch-GCN with 4,370 gigapixel WSIs across five different cancer types from the Cancer Genome Atlas (TCGA), and demonstrate that Patch-GCN outperforms all prior weakly-supervised approaches by 3.58-9.46%. Our code and corresponding models are publicly available at <a class="link-external link-https" href="https://github.com/mahmoodlab/Patch-GCN" rel="external noopener nofollow">this https URL</a>.      
### 21.Deep Recurrent Semi-Supervised EEG Representation Learning for Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.13505.pdf)
>  EEG-based emotion recognition often requires sufficient labeled training samples to build an effective computational model. Labeling EEG data, on the other hand, is often expensive and time-consuming. To tackle this problem and reduce the need for output labels in the context of EEG-based emotion recognition, we propose a semi-supervised pipeline to jointly exploit both unlabeled and labeled data for learning EEG representations. Our semi-supervised framework consists of both unsupervised and supervised components. The unsupervised part maximizes the consistency between original and reconstructed input data using an autoencoder, while simultaneously the supervised part minimizes the cross-entropy between the input and output labels. We evaluate our framework using both a stacked autoencoder and an attention-based recurrent autoencoder. We test our framework on the large-scale SEED EEG dataset and compare our results with several other popular semi-supervised methods. Our semi-supervised framework with a deep attention-based recurrent autoencoder consistently outperforms the benchmark methods, even when small sub-sets (3\%, 5\% and 10\%) of the output labels are available during training, achieving a new state-of-the-art semi-supervised performance.      
### 22.A Proof-of-Concept Study of Artificial Intelligence Assisted Contour Revision  [ :arrow_down: ](https://arxiv.org/pdf/2107.13465.pdf)
>  Automatic segmentation of anatomical structures is critical for many medical applications. However, the results are not always clinically acceptable and require tedious manual revision. Here, we present a novel concept called artificial intelligence assisted contour revision (AIACR) and demonstrate its feasibility. The proposed clinical workflow of AIACR is as follows given an initial contour that requires a clinicians revision, the clinician indicates where a large revision is needed, and a trained deep learning (DL) model takes this input to update the contour. This process repeats until a clinically acceptable contour is achieved. The DL model is designed to minimize the clinicians input at each iteration and to minimize the number of iterations needed to reach acceptance. In this proof-of-concept study, we demonstrated the concept on 2D axial images of three head-and-neck cancer datasets, with the clinicians input at each iteration being one mouse click on the desired location of the contour segment. The performance of the model is quantified with Dice Similarity Coefficient (DSC) and 95th percentile of Hausdorff Distance (HD95). The average DSC/HD95 (mm) of the auto-generated initial contours were 0.82/4.3, 0.73/5.6 and 0.67/11.4 for three datasets, which were improved to 0.91/2.1, 0.86/2.4 and 0.86/4.7 with three mouse clicks, respectively. Each DL-based contour update requires around 20 ms. We proposed a novel AIACR concept that uses DL models to assist clinicians in revising contours in an efficient and effective way, and we demonstrated its feasibility by using 2D axial CT images from three head-and-neck cancer datasets.      
### 23.Marine Vehicles Localization Using Grid Cells for Path Integration  [ :arrow_down: ](https://arxiv.org/pdf/2107.13461.pdf)
>  Autonomous Underwater Vehicles (AUVs) are platforms used for research and exploration of marine environments. However, these types of vehicles face many challenges that hinder their widespread use in the industry. One of the main limitations is obtaining accurate position estimation, due to the lack of GPS signal underwater. This estimation is usually done with Kalman filters. However, new developments in the neuroscience field have shed light on the mechanisms by which mammals are able to obtain a reliable estimation of their current position based on external and internal motion cues. A new type of neuron, called Grid cells, has been shown to be part of path integration system in the brain. In this article, we show how grid cells can be used for obtaining a position estimation of underwater vehicles. The model of grid cells used requires only the linear velocities together with heading orientation and provides a reliable estimation of the vehicle's position. We provide simulation results for an AUV which show the feasibility of our proposed methodology.      
### 24.A Signal Detection Scheme Based on Deep Learning in OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.13423.pdf)
>  Channel estimation and signal detection are essential steps to ensure the quality of end-to-end communication in orthogonal frequency-division multiplexing (OFDM) systems. In this paper, we develop a DDLSD approach, i.e., Data-driven Deep Learning for Signal Detection in OFDM systems. First, the OFDM system model is established. Then, the long short-term memory (LSTM) is introduced into the OFDM system model. Wireless channel data is generated through simulation, the preprocessed time series feature information is input into the LSTM to complete the offline training. Finally, the trained model is used for online recovery of transmitted signal. The difference between this scheme and existing OFDM receiver is that explicit estimated channel state information (CSI) is transformed into invisible estimated CSI, and the transmit symbol is directly restored. Simulation results show that the DDLSD scheme outperforms the existing traditional methods in terms of improving channel estimation and signal detection performance.      
### 25.Automatic Unstructured Handwashing Recognition using Smartwatch to Reduce Contact Transmission of Pathogens  [ :arrow_down: ](https://arxiv.org/pdf/2107.13405.pdf)
>  Current guidelines from the World Health Organization indicate that the SARSCoV-2 coronavirus, which results in the novel coronavirus disease (COVID-19), is transmitted through respiratory droplets or by contact. Contact transmission occurs when contaminated hands touch the mucous membrane of the mouth, nose, or eyes. Moreover, pathogens can also be transferred from one surface to another by contaminated hands, which facilitates transmission by indirect contact. Consequently, hands hygiene is extremely important to prevent the spread of the SARSCoV-2 virus. Additionally, hand washing and/or hand rubbing disrupts also the transmission of other viruses and bacteria that cause common colds, flu and pneumonia, thereby reducing the overall disease burden. The vast proliferation of wearable devices, such as smartwatches, containing acceleration, rotation, magnetic field sensors, etc., together with the modern technologies of artificial intelligence, such as machine learning and more recently deep-learning, allow the development of accurate applications for recognition and classification of human activities such as: walking, climbing stairs, running, clapping, sitting, sleeping, etc. In this work we evaluate the feasibility of an automatic system, based on current smartwatches, which is able to recognize when a subject is washing or rubbing its hands, in order to monitor parameters such as frequency and duration, and to evaluate the effectiveness of the gesture. Our preliminary results show a classification accuracy of about 95% and of about 94% for respectively deep and standard learning techniques.      
### 26.Nonlinear State Space Modeling and Control of the Impact of Patients' Modifiable Lifestyle Behaviors on the Emergence of Multiple Chronic Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2107.13394.pdf)
>  The emergence and progression of multiple chronic conditions (MCC) over time often form a dynamic network that depends on patient's modifiable risk factors and their interaction with non-modifiable risk factors and existing conditions. Continuous time Bayesian networks (CTBNs) are effective methods for modeling the complex network of MCC relationships over time. However, CTBNs are not able to effectively formulate the dynamic impact of patient's modifiable risk factors on the emergence and progression of MCC. Considering a functional CTBN (FCTBN) to represent the underlying structure of the MCC relationships with respect to individuals' risk factors and existing conditions, we propose a nonlinear state-space model based on Extended Kalman filter (EKF) to capture the dynamics of the patients' modifiable risk factors and existing conditions on the MCC evolution over time. We also develop a tensor control chart to dynamically monitor the effect of changes in the modifiable risk factors of individual patients on the risk of new chronic conditions emergence. We validate the proposed approach based on a combination of simulation and real data from a dataset of 385 patients from Cameron County Hispanic Cohort (CCHC) over multiple years. The dataset examines the emergence of 5 chronic conditions (Diabetes, Obesity, Cognitive Impairment, Hyperlipidemia, and Hypertension) based on 4 modifiable risk factors representing lifestyle behaviors (Diet, Exercise, Smoking Habit, and Drinking Habit) and 3 non-modifiable risk factors, including demographic information (Age, Gender, Education). The results demonstrate the effectiveness of the proposed methodology for dynamic prediction and monitoring of the risk of MCC emergence in individual patients.      
### 27.Snippet Policy Network for Multi-class Varied-length ECG Early Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.13361.pdf)
>  Arrhythmia detection from ECG is an important research subject in the prevention and diagnosis of cardiovascular diseases. The prevailing studies formulate arrhythmia detection from ECG as a time series classification problem. Meanwhile, early detection of arrhythmia presents a real-world demand for early prevention and diagnosis. In this paper, we address a problem of cardiovascular disease early classification, which is a varied-length and long-length time series early classification problem as well. For solving this problem, we propose a deep reinforcement learning-based framework, namely Snippet Policy Network (SPN), consisting of four modules, snippet generator, backbone network, controlling agent, and discriminator. Comparing to the existing approaches, the proposed framework features flexible input length, solves the dual-optimization solution of the earliness and accuracy goals. Experimental results demonstrate that SPN achieves an excellent performance of over 80\% in terms of accuracy. Compared to the state-of-the-art methods, at least 7% improvement on different metrics, including the precision, recall, F1-score, and harmonic mean, is delivered by the proposed SPN. To the best of our knowledge, this is the first work focusing on solving the cardiovascular early classification problem based on varied-length ECG data. Based on these excellent features from SPN, it offers a good exemplification for addressing all kinds of varied-length time series early classification problems.      
### 28.Fast Wireless Sensor Anomaly Detection based on Data Stream in Edge Computing Enabled Smart Greenhouse  [ :arrow_down: ](https://arxiv.org/pdf/2107.13353.pdf)
>  Edge computing enabled smart greenhouse is a representative application of Internet of Things technology, which can monitor the environmental information in real time and employ the information to contribute to intelligent decision-making. In the process, anomaly detection for wireless sensor data plays an important role. However, traditional anomaly detection algorithms originally designed for anomaly detection in static data have not properly considered the inherent characteristics of data stream produced by wireless sensor such as infiniteness, correlations and concept drift, which may pose a considerable challenge on anomaly detection based on data stream, and lead to low detection accuracy and efficiency. First, data stream usually generates quickly which means that it is infinite and enormous, so any traditional off-line anomaly detection algorithm that attempts to store the whole dataset or to scan the dataset multiple times for anomaly detection will run out of memory space. Second, there exist correlations among different data streams, which traditional algorithms hardly consider. Third, the underlying data generation process or data distribution may change over time. Thus, traditional anomaly detection algorithms with no model update will lose their effects. Considering these issues, a novel method (called DLSHiForest) on basis of Locality-Sensitive Hashing and time window technique in this paper is proposed to solve these problems while achieving accurate and efficient detection. Comprehensive experiments are executed using real-world agricultural greenhouse dataset to demonstrate the feasibility of our approach. Experimental results show that our proposal is practicable in addressing challenges of traditional anomaly detection while ensuring accuracy and efficiency.      
### 29.Introduction of a Novel MoM Solution for 2-D Source-type EFIE in MI Problems  [ :arrow_down: ](https://arxiv.org/pdf/2107.13308.pdf)
>  This paper presents a novel formulation and consequently a new solution for two dimensional TM electromagnetic integral equations by the method of moments in polar coordination. The main idea is the reformulation of the 2-D problem according to addition theorem for Hankel functions that appear in Green function of 2-D homogeneous media. In this regard, recursive formulas in spatial frequency domain are derived and the scattering field is rewritten into inward and outward components and, then, the primary 2-D problem can be solved using 1D FFT in the stabilized biconjugate-gradient fast Fourier transform BCGS-FFT algorithm. Because the emerging method obtains 1D FFT over a circle, there is no need to expand an object region by zero padding, whereas it is necessary for conventional 2D FFT approach. Therefore, the method saves lots of memory and time over the conventional approach. other interesting aspect of the proposed method is that the field on a circle outside a scattering object, can be calculated efficiently using an analytical formula. This is, particularly, attractive in electromagnetic inverse scattering problems and microwave imaging. The numerical examples for 2-D TM problems demonstrate merits of proposed technique in terms of the accuracy and computational efficiency.      
### 30.On Perceived Emotion in Expressive Piano Performance: Further Experimental Evidence for the Relevance of Mid-level Perceptual Features  [ :arrow_down: ](https://arxiv.org/pdf/2107.13231.pdf)
>  Despite recent advances in audio content-based music emotion recognition, a question that remains to be explored is whether an algorithm can reliably discern emotional or expressive qualities between different performances of the same piece. In the present work, we analyze several sets of features on their effectiveness in predicting arousal and valence of six different performances (by six famous pianists) of Bach's Well-Tempered Clavier Book 1. These features include low-level acoustic features, score-based features, features extracted using a pre-trained emotion model, and Mid-level perceptual features. We compare their predictive power by evaluating them on several experiments designed to test performance-wise or piece-wise variations of emotion. We find that Mid-level features show significant contribution in performance-wise variation of both arousal and valence -- even better than the pre-trained emotion model. Our findings add to the evidence of Mid-level perceptual features being an important representation of musical attributes for several tasks -- specifically, in this case, for capturing the expressive aspects of music that manifest as perceived emotion of a musical performance.      
### 31.Synthesis of Output-Feedback Controllers for Mixed Traffic Systems in Presence of Disturbances and Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2107.13216.pdf)
>  In this paper, we study mixed traffic systems that move along a single-lane ring-road or open-road. The traffic flow forms a platoon, which includes a number of heterogeneous human-driven vehicles (HDVs) together with only one connected and automated vehicle (CAV) that receives information from several neighbors. The dynamics of HDVs are assumed to follow the optimal velocity model (OVM), and the acceleration of the single CAV is directly controlled by a dynamical output-feedback controller. The ultimate goal of this work is to present a robust control strategy that can smoothen the traffic flow in the presence of undesired disturbances (e.g. abrupt deceleration) and parametric uncertainties. A prerequisite for synthesizing a dynamical output controller is the stabilizability and detectability of the underlying system. Accordingly, a theoretical analysis is presented first to prove the stabilizability and detectability of the mixed traffic flow system. Then, two H-infinity control strategies, with and without considering uncertainties in the system dynamics, are designed. The efficiency of the two control methods is subsequently illustrated through numerical simulations, and various experimental results are presented to demonstrate the effectiveness of the proposed controller to mitigate disturbance amplification and achieve platoon stability.      
### 32.Squeeze-Excitation Convolutional Recurrent Neural Networks for Audio-Visual Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.13180.pdf)
>  The use of multiple and semantically correlated sources can provide complementary information to each other that may not be evident when working with individual modalities on their own. In this context, multi-modal models can help producing more accurate and robust predictions in machine learning tasks where audio-visual data is available. This paper presents a multi-modal model for automatic scene classification that exploits simultaneously auditory and visual information. The proposed approach makes use of two separate networks which are respectively trained in isolation on audio and visual data, so that each network specializes in a given modality. The visual subnetwork is a pre-trained VGG16 model followed by a bidiretional recurrent layer, while the residual audio subnetwork is based on stacked squeeze-excitation convolutional blocks trained from scratch. After training each subnetwork, the fusion of information from the audio and visual streams is performed at two different stages. The early fusion stage combines features resulting from the last convolutional block of the respective subnetworks at different time steps to feed a bidirectional recurrent structure. The late fusion stage combines the output of the early fusion stage with the independent predictions provided by the two subnetworks, resulting in the final prediction. We evaluate the method using the recently published TAU Audio-Visual Urban Scenes 2021, which contains synchronized audio and video recordings from 12 European cities in 10 different scene classes. The proposed model has been shown to provide an excellent trade-off between prediction performance (86.5%) and system complexity (15M parameters) in the evaluation results of the DCASE 2021 Challenge.      
### 33.CycleGAN-based Non-parallel Speech Enhancement with an Adaptive Attention-in-attention Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2107.13143.pdf)
>  Non-parallel training is a difficult but essential task for DNN-based speech enhancement methods, for the lack of adequate noisy and paired clean speech corpus in many real scenarios. In this paper, we propose a novel adaptive attention-in-attention CycleGAN (AIA-CycleGAN) for non-parallel speech enhancement. In previous CycleGAN-based non-parallel speech enhancement methods, the limited mapping ability of the generator may cause performance degradation and insufficient feature learning. To alleviate this degradation, we propose an integration of adaptive time-frequency attention (ATFA) and adaptive hierarchical attention (AHA) to form an attention-in-attention (AIA) module for more flexible feature learning during the mapping procedure. More specifically, ATFA can capture the long-range temporal-spectral contextual information for more effective feature representations, while AHA can flexibly aggregate different intermediate feature maps by weights depending on the global context. Numerous experimental results demonstrate that the proposed approach achieves consistently more superior performance over previous GAN-based and CycleGAN-based methods in non-parallel training. Moreover, experiments in parallel training verify that the proposed AIA-CycleGAN also outperforms most advanced GAN-based speech enhancement approaches, especially in maintaining speech integrity and reducing speech distortion.      
### 34.Subjective evaluation of traditional and learning-based image coding methods  [ :arrow_down: ](https://arxiv.org/pdf/2107.13122.pdf)
>  We conduct a subjective experiment to compare the performance of traditional image coding methods and learning-based image coding methods. HEVC and VVC, the state-of-the-art traditional coding methods, are used as the representative traditional methods. The learning-based methods used contain not only CNN-based methods, but also a GAN-based method, all of which are advanced or typical. Single Stimuli (SS), which is also called Absolute Category Rating (ACR), is adopted as the methodology of the experiment to obtain perceptual quality of images. Additionally, we utilize some typical and frequently used objective quality metrics to evaluate the coding methods in the experiment as comparison. The experiment shows that CNN-based and GAN-based methods can perform better than traditional methods in low bit-rates. In high bit-rates, however, it is hard to verify whether CNN-based methods are superior to traditional methods. Because the GAN method does not provide models with high target bit-rates, we cannot exactly tell the performance of the GAN method in high bit-rates. Furthermore, some popular objective quality metrics have not shown the ability well to measure quality of images generated by learning-based coding methods, especially the GAN-based one.      
### 35.A-star path planning simulation for UAS Traffic Management (UTM) application  [ :arrow_down: ](https://arxiv.org/pdf/2107.13103.pdf)
>  This paper presents a Robot Operating System and Gazebo application to calculate and simulate an optimal route for a drone in an urban environment by developing new ROS packages and executing them along with open-source tools. Firstly, the current regulations about UAS are presented to guide the building of the simulated environment, and multiple path planning algorithms are reviewed to guide the search method selection. After selecting the A-star algorithm, both the 2D and 3D versions of them were implemented in this paper, with both Manhattan and Euclidean distances heuristics. The performance of these algorithms was evaluated considering the distance to be covered by the drone and the execution time of the route planning method, aiming to support algorithm's choice based on the environment in which it will be applied. The algorithm execution time was 3.2 and 17.2 higher when using the Euclidean distance for the 2D and 3D A-star algorithm, respectively. Along with the performance analysis of the algorithm, this paper is also the first step for building a complete UAS Traffic Management (UTM) system simulation using ROS and Gazebo.      
### 36.A strawberry harvest-aiding system with crop-transport co-robots: Design, development, and field evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2107.13063.pdf)
>  Mechanizing the manual harvesting of fresh market fruits constitutes one of the biggest challenges to the sustainability of the fruit industry. During manual harvesting of some fresh-market crops like strawberries and table grapes, pickers spend significant amounts of time walking to carry full trays to a collection station at the edge of the field. A step toward increasing harvest automation for such crops is to deploy harvest-aid collaborative robots (co-bots) that transport the empty and full trays, thus increasing harvest efficiency by reducing pickers' non-productive walking times. This work presents the development of a co-robotic harvest-aid system and its evaluation during commercial strawberry harvesting. At the heart of the system lies a predictive stochastic scheduling algorithm that minimizes the expected non-picking time, thus maximizing the harvest efficiency. During the evaluation experiments, the co-robots improved the mean harvesting efficiency by around 10% and reduced the mean non-productive time by 60%, when the robot-to-picker ratio was 1:3. The concepts developed in this work can be applied to robotic harvest-aids for other manually harvested crops that involve walking for crop transportation.      
### 37.Event-triggered Partitioning for Non-centralized Predictive-Control-based Economic Dispatch of Interconnected Microgrids: Technical Report  [ :arrow_down: ](https://arxiv.org/pdf/2007.07786.pdf)
>  A non-centralized model predictive control (MPC) scheme for solving an economic dispatch problem of electrical networks is proposed in this paper. The scheme consists of two parts. The first part is an event-triggered repartitioning method that splits the network into a fixed number of non-overlapping sub-systems {(microgrids)}. The objective of the repartitioning procedure is to obtain self-sufficient microgrids, i.e., those that can meet their local loads using their own generation units. However, since the algorithm does not guarantee that all the resulting microgrids are self-sufficient, the microgrids that are not self-sufficient must then form a coalition with some of their neighboring microgrids. This process becomes the second part of the scheme. By performing the coalition formation, we can decompose the economic dispatch problem of the network into coalition-based sub-problems such that each subproblem is feasible. Furthermore, we also show that the solution obtained by solving the coalition-based sub-problems is a feasible but sub-optimal solution to the centralized problem. Additionally, some numerical simulations are also carried out to show the effectiveness of the proposed method.      
