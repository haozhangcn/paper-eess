# ArXiv eess --Tue, 20 Jul 2021
### 1.Deep Open Snake Tracker for Vessel Tracing  [ :arrow_down: ](https://arxiv.org/pdf/2107.09049.pdf)
>  Vessel tracing by modeling vascular structures in 3D medical images with centerlines and radii can provide useful information for vascular health. Existing algorithms have been developed but there are certain persistent problems such as incomplete or inaccurate vessel tracing, especially in complicated vascular beds like the intracranial arteries. We propose here a deep learning based open curve active contour model (DOST) to trace vessels in 3D images. Initial curves were proposed from a centerline segmentation neural network. Then data-driven machine knowledge was used to predict the stretching direction and vessel radius of the initial curve, while the active contour model (as human knowledge) maintained smoothness and intensity fitness of curves. Finally, considering the nonloop topology of most vasculatures, individually traced vessels were connected into a tree topology by applying a minimum spanning tree algorithm on a global connection graph. We evaluated DOST on a Time-of-Flight (TOF) MRA intracranial artery dataset and demonstrated its superior performance over existing segmentation-based and tracking-based vessel tracing methods. In addition, DOST showed strong adaptability on different imaging modalities (CTA, MR T1 SPACE) and vascular beds (coronary arteries).      
### 2.On the Veracity of Local, Model-agnostic Explanations in Audio Classification: Targeted Investigations with Adversarial Examples  [ :arrow_down: ](https://arxiv.org/pdf/2107.09045.pdf)
>  Local explanation methods such as LIME have become popular in MIR as tools for generating post-hoc, model-agnostic explanations of a model's classification decisions. The basic idea is to identify a small set of human-understandable features of the classified example that are most influential on the classifier's prediction. These are then presented as an explanation. Evaluation of such explanations in publications often resorts to accepting what matches the expectation of a human without actually being able to verify if what the explanation shows is what really caused the model's prediction. This paper reports on targeted investigations where we try to get more insight into the actual veracity of LIME's explanations in an audio classification task. We deliberately design adversarial examples for the classifier, in a way that gives us knowledge about which parts of the input are potentially responsible for the model's (wrong) prediction. Asking LIME to explain the predictions for these adversaries permits us to study whether local explanations do indeed detect these regions of interest. We also look at whether LIME is more successful in finding perturbations that are more prominent and easily noticeable for a human. Our results suggest that LIME does not necessarily manage to identify the most relevant input features and hence it remains unclear whether explanations are useful or even misleading.      
### 3.Frequency-Supervised MR-to-CT Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2107.08962.pdf)
>  This paper strives to generate a synthetic computed tomography (CT) image from a magnetic resonance (MR) image. The synthetic CT image is valuable for radiotherapy planning when only an MR image is available. Recent approaches have made large strides in solving this challenging synthesis problem with convolutional neural networks that learn a mapping from MR inputs to CT outputs. In this paper, we find that all existing approaches share a common limitation: reconstruction breaks down in and around the high-frequency parts of CT images. To address this common limitation, we introduce frequency-supervised deep networks to explicitly enhance high-frequency MR-to-CT image reconstruction. We propose a frequency decomposition layer that learns to decompose predicted CT outputs into low- and high-frequency components, and we introduce a refinement module to improve high-frequency reconstruction through high-frequency adversarial learning. Experimental results on a new dataset with 45 pairs of 3D MR-CT brain images show the effectiveness and potential of the proposed approach. Code is available at \url{<a class="link-external link-https" href="https://github.com/shizenglin/Frequency-Supervised-MR-to-CT-Image-Synthesis" rel="external noopener nofollow">this https URL</a>}.      
### 4.Automatic and explainable grading of meningiomas from histopathology images  [ :arrow_down: ](https://arxiv.org/pdf/2107.08850.pdf)
>  Meningioma is one of the most prevalent brain tumors in adults. To determine its malignancy, it is graded by a pathologist into three grades according to WHO standards. This grade plays a decisive role in treatment, and yet may be subject to inter-rater discordance. In this work, we present and compare three approaches towards fully automatic meningioma grading from histology whole slide images. All approaches are following a two-stage paradigm, where we first identify a region of interest based on the detection of mitotic figures in the slide using a state-of-the-art object detection deep learning network. This region of highest mitotic rate is considered characteristic for biological tumor behavior. In the second stage, we calculate a score corresponding to tumor malignancy based on information contained in this region using three different settings. In a first approach, image patches are sampled from this region and regression is based on morphological features encoded by a ResNet-based network. We compare this to learning a logistic regression from the determined mitotic count, an approach which is easily traceable and explainable. Lastly, we combine both approaches in a single network. We trained the pipeline on 951 slides from 341 patients and evaluated them on a separate set of 141 slides from 43 patients. All approaches yield a high correlation to the WHO grade. The logistic regression and the combined approach had the best results in our experiments, yielding correct predictions in 32 and 33 of all cases, respectively, with the image-based approach only predicting 25 cases correctly. Spearman's correlation was 0.716, 0.792 and 0.790 respectively. It may seem counterintuitive at first that morphological features provided by image patches do not improve model performance. Yet, this mirrors the criteria of the grading scheme, where mitotic count is the only unequivocal parameter.      
### 5.Channel-wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2107.08803.pdf)
>  Existing approaches for anti-spoofing in automatic speaker verification (ASV) still lack generalizability to unseen attacks. The Res2Net approach designs a residual-like connection between feature groups within one block, which increases the possible receptive fields and improves the system's detection generalizability. However, such a residual-like connection is performed by a direct addition between feature groups without channel-wise priority. We argue that the information across channels may not contribute to spoofing cues equally, and the less relevant channels are expected to be suppressed before adding onto the next feature group, so that the system can generalize better to unseen attacks. This argument motivates the current work that presents a novel, channel-wise gated Res2Net (CG-Res2Net), which modifies Res2Net to enable a channel-wise gating mechanism in the connection between feature groups. This gating mechanism dynamically selects channel-wise features based on the input, to suppress the less relevant channels and enhance the detection generalizability. Three gating mechanisms with different structures are proposed and integrated into Res2Net. Experimental results conducted on ASVspoof 2019 logical access (LA) demonstrate that the proposed CG-Res2Net significantly outperforms Res2Net on both the overall LA evaluation set and individual difficult unseen attacks, which also outperforms other state-of-the-art single systems, depicting the effectiveness of our method.      
### 6.Improving Interpretability of Deep Neural Networks in Medical Diagnosis by Investigating the Individual Units  [ :arrow_down: ](https://arxiv.org/pdf/2107.08767.pdf)
>  As interpretability has been pointed out as the obstacle to the adoption of Deep Neural Networks (DNNs), there is an increasing interest in solving a transparency issue to guarantee the impressive performance. In this paper, we demonstrate the efficiency of recent attribution techniques to explain the diagnostic decision by visualizing the significant factors in the input image. By utilizing the characteristics of objectness that DNNs have learned, fully decomposing the network prediction visualizes clear localization of target lesion. To verify our work, we conduct our experiments on Chest X-ray diagnosis with publicly accessible datasets. As an intuitive assessment metric for explanations, we report the performance of intersection of Union between visual explanation and bounding box of lesions. Experiment results show that recently proposed attribution methods visualize the more accurate localization for the diagnostic decision compared to the traditionally used CAM. Furthermore, we analyze the inconsistency of intentions between humans and DNNs, which is easily obscured by high performance. By visualizing the relevant factors, it is possible to confirm that the criterion for decision is in line with the learning strategy. Our analysis of unmasking machine intelligence represents the necessity of explainability in the medical diagnostic decision.      
### 7.Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.08751.pdf)
>  Deep learning for medical imaging suffers from temporal and privacy-related restrictions on data availability. To still obtain viable models, continual learning aims to train in sequential order, as and when data is available. The main challenge that continual learning methods face is to prevent catastrophic forgetting, i.e., a decrease in performance on the data encountered earlier. This issue makes continuous training of segmentation models for medical applications extremely difficult. Yet, often, data from at least two different domains is available which we can exploit to train the model in a way that it disregards domain-specific information. We propose an architecture that leverages the simultaneous availability of two or more datasets to learn a disentanglement between the content and domain in an adversarial fashion. The domain-invariant content representation then lays the base for continual semantic segmentation. Our approach takes inspiration from domain adaptation and combines it with continual learning for hippocampal segmentation in brain MRI. We showcase that our method reduces catastrophic forgetting and outperforms state-of-the-art continual learning methods.      
### 8.Managing Interference and Leveraging Secondary Reflections Amongst Multiple IRSs  [ :arrow_down: ](https://arxiv.org/pdf/2107.08704.pdf)
>  Intelligent reflecting surface (IRS) has recently been emerging as an enabler for smart radio environment in which passive antenna arrays can be used to actively tailor/control the radio propagation (e.g., to support users under adverse channel conditions). With multiple IRSs being launched (e.g., coated on various buildings) to support various group of users, it is critical to jointly optimize the phase-shifts of all IRSs to mitigate the interference as well as leverage the secondary reflections amongst IRSs. This work takes the first step by considering the uplink of multiple users that are grouped and supported by multiple IRSs to a multi-antenna base station. Each IRS with multiple controllable phase-shift elements is intended to serve a group of near-by users. We first formulate the minimum achievable rate (from all users) maximization problem by jointly optimizing phase-shifts of elements from all IRSs and the received beamformers at the MIMO base station. The problem turns out to be non-convex. We then derive its solution using the alternating optimization mechanism. Our simulations show that by properly managing interference and leveraging the secondary reflections amongst IRSs, there is a great benefit of deploying more IRSs to support different groups of users to achieve a higher rate per user. For example, we can see about 0.8 bps/Hz or 1.4 bps/Hz gain for a 2 or 4 IRSs system as compared to a single IRS system, respectively, or a 1.6 bps/Hz gain when the number of IRS elements is increased from 16 to 32.      
### 9.Input Agnostic Deep Learning for Alzheimer's Disease Classification Using Multimodal MRI Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.08673.pdf)
>  Alzheimer's disease (AD) is a progressive brain disorder that causes memory and functional impairments. The advances in machine learning and publicly available medical datasets initiated multiple studies in AD diagnosis. In this work, we utilize a multi-modal deep learning approach in classifying normal cognition, mild cognitive impairment and AD classes on the basis of structural MRI and diffusion tensor imaging (DTI) scans from the OASIS-3 dataset. In addition to a conventional multi-modal network, we also present an input agnostic architecture that allows diagnosis with either sMRI or DTI scan, which distinguishes our method from previous multi-modal machine learning-based methods. The results show that the input agnostic model achieves 0.96 accuracy when both structural MRI and DTI scans are provided as inputs.      
### 10.A Radiomics-Boosted Deep-Learning Model for COVID-19 and Non-COVID-19 Pneumonia Detection Using Chest X-ray Image  [ :arrow_down: ](https://arxiv.org/pdf/2107.08667.pdf)
>  To develop a deep-learning model that integrates radiomics analysis for enhanced performance of COVID-19 and Non-COVID-19 pneumonia detection using chest X-ray image, two deep-learning models were trained based on a pre-trained VGG-16 architecture: in the 1st model, X-ray image was the sole input; in the 2nd model, X-ray image and 2 radiomic feature maps (RFM) selected by the saliency map analysis of the 1st model were stacked as the input. Both models were developed using 812 chest X-ray images with 262/288/262 COVID-19/Non-COVID-19 pneumonia/healthy cases, and 649/163 cases were assigned as training-validation/independent test sets. In 1st model using X-ray as the sole input, the 1) sensitivity, 2) specificity, 3) accuracy, and 4) ROC Area-Under-the-Curve of COVID-19 vs Non-COVID-19 pneumonia detection were 1) 0.90$\pm$0.07 vs 0.78$\pm$0.09, 2) 0.94$\pm$0.04 vs 0.94$\pm$0.04, 3) 0.93$\pm$0.03 vs 0.89$\pm$0.03, and 4) 0.96$\pm$0.02 vs 0.92$\pm$0.04. In the 2nd model, two RFMs, Entropy and Short-Run-Emphasize, were selected with their highest cross-correlations with the saliency maps of the 1st model. The corresponding results demonstrated significant improvements (p&lt;0.05) of COVID-19 vs Non-COVID-19 pneumonia detection: 1) 0.95$\pm$0.04 vs 0.85$\pm$0.04, 2) 0.97$\pm$0.02 vs 0.96$\pm$0.02, 3) 0.97$\pm$0.02 vs 0.93$\pm$0.02, and 4) 0.99$\pm$0.01 vs 0.97$\pm$0.02. The reduced variations suggested a superior robustness of 2nd model design.      
### 11.Delay-Compensated Distributed PDE Control of Traffic with Connected/Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2107.08651.pdf)
>  We develop an input delay-compensating design for stabilization of an Aw-Rascle-Zhang (ARZ) traffic model in congested regime which is governed by a $2\times 2$ first-order hyperbolic nonlinear PDE. The traffic flow consists of both adaptive cruise control-equipped (ACC-equipped) and manually-driven vehicles. The control input is the time gap of ACC-equipped and connected vehicles, which is subject to delays resulting from communication lag. For the linearized system, a novel three-branch bakcstepping transformation with explicit kernel functions is introduced to compensate the input delay. The transformation is proved æto be bounded, continuous and invertible, with explicit inverse transformation derived. Based on the transformation, we obtain the explicit predictor-feedback controller. We prove exponential stability of the closed-loop system with the delay compensator in $L_2$ norm. The performance improvement of the closed-loop system under the proposed controller is illustrated in simulation.      
### 12.Design of robust controller applied for series elastic actuators in controlling humanoid's joint  [ :arrow_down: ](https://arxiv.org/pdf/2107.08610.pdf)
>  Although the application of Series elastic actuators (SEAs) in the biomechatronic field has proved its appropriation in many aspects so far, the problems of maintaining the stability for the SEAs still remains. This paper proposes a robust controller so that to overcome the drawbacks of the previous researches. Firstly, a mathematical model considering both the SEAs and the hip joint of humanoid UXA-90 is obtained. Secondly, a reference input of the proposed controller that is achieved from desired hip joint's angle in a walking cycle is utilized. Then, a backstepping based sliding mode force control approach is employed to ensure the precise movement of robot's link as well as meeting the requirement of robustness for the whole system, which is significant for the task of walking of a humanoid. Finally, some simulations are carried out to verify the quality and effectiveness of the proposed controller.      
### 13.Joint Power and Gain Allocation in MDM-WDM Optical Communication Networks Based on Extended Gaussian Noise Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.08602.pdf)
>  Achieving reliable communication over different channels and modes is one of the main goals of Mode Division Multiplexing-Wavelength Division Multiplexing (MDM-WDM) communication networks. The reliability can be described by minimum Signal to Noise Ratio (SNR) margin which dependents on launched power, Multimode-Erbium Doped Fiber Amplification (MM-EDFA) gain, and MMF nonlinearity. In this paper, an analytical model for MMF nonlinearity is derived based on Extended Gaussian Noise (EGN) model formulation by considering carrier phase estimation and the first four dispersion terms. The proposed EGN model is verified through the split step Fourier method simulation. Considering a multi-node linear network, the joint optimized power and gain allocation based on minimum SNR margin maximization is formulated. The practical constraints including MM-EDFA saturation power and maximum gain are considered and the problem is solved by using convex optimization. Three scenarios are assumed including best equal power, optimized power, and joint optimized power and gain. In the first scenario, equal powers are considered for different channels and modes with equal MM-EDFA gain in all spans. It is worth mentioning that the MM-EDFA gain is equal to span loss. In the second scenario, different powers are allocated to different channels and modes with equal MM-EDFA gain in all spans. In the third case, allocated powers to each channel and mode are optimized. Moreover, the MM-EDFA gain for each span is optimized separately.      
### 14.Zero-Shot Domain Adaptation in CT Segmentation by Filtered Back Projection Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.08543.pdf)
>  Domain shift is one of the most salient challenges in medical computer vision. Due to immense variability in scanners' parameters and imaging protocols, even images obtained from the same person and the same scanner could differ significantly. We address variability in computed tomography (CT) images caused by different convolution kernels used in the reconstruction process, the critical domain shift factor in CT. The choice of a convolution kernel affects pixels' granularity, image smoothness, and noise level. We analyze a dataset of paired CT images, where smooth and sharp images were reconstructed from the same sinograms with different kernels, thus providing identical anatomy but different style. Though identical predictions are desired, we show that the consistency, measured as the average Dice between predictions on pairs, is just 0.54. We propose Filtered Back-Projection Augmentation (FBPAug), a simple and surprisingly efficient approach to augment CT images in sinogram space emulating reconstruction with different kernels. We apply the proposed method in a zero-shot domain adaptation setup and show that the consistency boosts from 0.54 to 0.92 outperforming other augmentation approaches. Neither specific preparation of source domain data nor target domain data is required, so our publicly released FBPAug can be used as a plug-and-play module for zero-shot domain adaptation in any CT-based task.      
### 15.A Multi-Channel Ratio-of-Ratios Method for Noncontact Hand Video Based SpO2 Monitoring Using Smartphone Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2107.08528.pdf)
>  Blood oxygen saturation (SpO2) is an important indicator for pulmonary and respiratory functionalities. Clinical findings on COVID-19 show that many patients had dangerously low blood oxygen levels not long before conditions worsened. It is therefore recommended, especially for the vulnerable population, to regularly monitor the blood oxygen level for precaution. Recent works have investigated how ubiquitous smartphone cameras can be used to infer SpO2. Most of these works are contact-based, requiring users to cover a phone's camera and its nearby light source with a finger to capture reemitted light from the illuminated tissue. Contact-based methods may lead to skin irritation and sanitary concerns, especially during a pandemic. In this paper, we propose a noncontact method for SpO2 monitoring using hand videos acquired by smartphones. Considering the optical broadband nature of the red (R), green (G), and blue (B) color channels of the smartphone cameras, we exploit all three channels of RGB sensing to distill the SpO2 information beyond the traditional ratio-of-ratios (RoR) method that uses only two wavelengths. To further facilitate an accurate SpO2 prediction, we design adaptive narrow bandpass filters based on accurately estimated heart rate to obtain the most cardiac-related AC component for each color channel. Experimental results show that our proposed blood oxygen estimation method can reach a mean absolute error of 1.26% when a pulse oximeter is used as a reference, outperforming the traditional RoR method by 25%.      
### 16.Classification of Upper Arm Movements from EEG signals using Machine Learning with ICA Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2107.08514.pdf)
>  The Brain-Computer Interface system is a profoundly developing area of experimentation for Motor activities which plays vital role in decoding cognitive activities. Classification of Cognitive-Motor Imagery activities from EEG signals is a critical task. Hence proposed a unique algorithm for classifying left/right-hand movements by utilizing Multi-layer Perceptron Neural Network. Handcrafted statistical Time domain and Power spectral density frequency domain features were extracted and obtained a combined accuracy of 96.02%. Results were compared with the deep learning framework. In addition to accuracy, Precision, F1-Score, and recall was considered as the performance metrics. The intervention of unwanted signals contaminates the EEG signals which influence the performance of the algorithm. Therefore, a novel approach was approached to remove the artifacts using Independent Components Analysis which boosted the performance. Following the selection of appropriate feature vectors that provided acceptable accuracy. The same method was used on all nine subjects. As a result, intra-subject accuracy was obtained for 9 subjects 94.72%. The results show that the proposed approach would be useful to classify the upper limb movements accurately.      
### 17.ANFIC: Image Compression Using Augmented Normalizing Flows  [ :arrow_down: ](https://arxiv.org/pdf/2107.08470.pdf)
>  This paper introduces an end-to-end learned image compression system, termed ANFIC, based on Augmented Normalizing Flows (ANF). ANF is a new type of flow model, which stacks multiple variational autoencoders (VAE) for greater model expressiveness. The VAE-based image compression has gone mainstream, showing promising compression performance. Our work presents the first attempt to leverage VAE-based compression in a flow-based framework. ANFIC advances further compression efficiency by stacking and extending hierarchically multiple VAE's. The invertibility of ANF, together with our training strategies, enables ANFIC to support a wide range of quality levels without changing the encoding and decoding networks. Extensive experimental results show that in terms of PSNR-RGB, ANFIC performs comparably to or better than the state-of-the-art learned image compression. Moreover, it performs close to VVC intra coding, from low-rate compression up to nearly-lossless compression. In particular, ANFIC achieves the state-of-the-art performance, when extended with conditional convolution for variable rate compression with a single model.      
### 18.Residual Attention Based Network for Automatic Classification of Phonation Modes  [ :arrow_down: ](https://arxiv.org/pdf/2107.08425.pdf)
>  Phonation mode is an essential characteristic of singing style as well as an important expression of performance. It can be classified into four categories, called neutral, breathy, pressed and flow. Previous studies used voice quality features and feature engineering for classification. While deep learning has achieved significant progress in other fields of music information retrieval (MIR), there are few attempts in the classification of phonation modes. In this study, a Residual Attention based network is proposed for automatic classification of phonation modes. The network consists of a convolutional network performing feature processing and a soft mask branch enabling the network focus on a specific area. In comparison experiments, the models with proposed network achieve better results in three of the four datasets than previous works, among which the highest classification accuracy is 94.58%, 2.29% higher than the baseline.      
### 19.Co-designing Intelligent Control of Building HVACs and Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2107.08378.pdf)
>  Building loads consume roughly 40% of the energy produced in developed countries, a significant part of which is invested towards building temperature-control infrastructure. Therein, renewable resource-based microgrids offer a greener and cheaper alternative. This communication explores the possible co-design of microgrid power dispatch and building HVAC (heating, ventilation and air conditioning system) actuations with the objective of effective temperature control under minimised operating cost. For this, we attempt control designs with various levels of abstractions based on information available about microgrid and HVAC system models using the Deep Reinforcement Learning (DRL) technique. We provide control architectures that consider model information ranging from completely determined system models to systems with fully unknown parameter settings and illustrate the advantages of DRL for the design prescriptions.      
### 20.Scalable Image Coding for Humans and Machines  [ :arrow_down: ](https://arxiv.org/pdf/2107.08373.pdf)
>  At present, and increasingly so in the future, much of the captured visual content will not be seen by humans. Instead, it will be used for automated machine vision analytics and may require occasional human viewing. Examples of such applications include traffic monitoring, visual surveillance, autonomous navigation, and industrial machine vision. To address such requirements, we develop an end-to-end learned image codec whose latent space is designed to support scalability from simpler to more complicated tasks. The simplest task is assigned to a subset of the latent space (the base layer), while more complicated tasks make use of additional subsets of the latent space, i.e., both the base and enhancement layer(s). For the experiments, we establish a 2-layer and a 3-layer model, each of which offers input reconstruction for human vision, plus machine vision task(s), and compare them with relevant benchmarks. The experiments show that our scalable codecs offer 37%-80% bitrate savings on machine vision tasks compared to best alternatives, while being comparable to state-of-the-art image codecs in terms of input reconstruction.      
### 21.A Duality-based Approach for Real-time Obstacle Avoidance between Polytopes with Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2107.08360.pdf)
>  Developing controllers for obstacle avoidance between polytopes is a challenging and necessary problem for navigation in a tight space. Traditional approaches can only formulate the obstacle avoidance problem as an offline optimization problem. To address these challenges, we propose a duality-based safety-critical optimal control using control barrier functions for obstacle avoidance between polytopes, which can be solved in real-time with a QP-based optimization problem. A dual optimization problem is introduced to represent the minimum distance between polytopes and the Lagrangian function for the dual form is applied to construct a control barrier function. We demonstrate the proposed controller on a moving sofa problem where non-conservative maneuvers can be achieved in a tight space.      
### 22.Fully Polarimetric SAR and Single-Polarization SAR Image Fusion Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.08355.pdf)
>  The data fusion technology aims to aggregate the characteristics of different data and obtain products with multiple data advantages. To solves the problem of reduced resolution of PolSAR images due to system limitations, we propose a fully polarimetric synthetic aperture radar (PolSAR) images and single-polarization synthetic aperture radar SAR (SinSAR) images fusion network to generate high-resolution PolSAR (HR-PolSAR) images. To take advantage of the polarimetric information of the low-resolution PolSAR (LR-PolSAR) image and the spatial information of the high-resolution single-polarization SAR (HR-SinSAR) image, we propose a fusion framework for joint LR-PolSAR image and HR-SinSAR image and design a cross-attention mechanism to extract features from the joint input data. Besides, based on the physical imaging mechanism, we designed the PolSAR polarimetric loss function for constrained network training. The experimental results confirm the superiority of fusion network over traditional algorithms. The average PSNR is increased by more than 3.6db, and the average MAE is reduced to less than 0.07. Experiments on polarimetric decomposition and polarimetric signature show that it maintains polarimetric information well.      
### 23.Employing Altruistic Vehicles at On-ramps to Improve the Social Traffic Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2107.08339.pdf)
>  Highway on-ramps are regarded as typical bottlenecks in transportation networks. In previous work, mainline vehicles' selfish lane choice behavior at on-ramps is studied and regarded as one cause leading to on-ramp inefficiency. When on-ramp vehicles plan to merge into the mainline of the highway, mainline vehicles choose to either stay steadfast on the current lane or bypass the merging area by switching to a neighboring lane farther from the on-ramp. Selfish vehicles make the decisions to minimize their own travel delay, which compromises the efficiency of the whole on-ramp. Results in previous work have shown that, if we can encourage a proper portion of mainline vehicles to bypass rather than to stay steadfast, the social traffic conditions can be improved. In this work, we consider employing a proportion of altruistic vehicles among the selfish mainline vehicles to improve the efficiency of the on-ramps. The altruistic vehicles are individual optimizers, making decisions whether to stay steadfast or bypass to minimize their own altruistic cost, which is a weighted sum of the travel delay and their negative impact on other vehicles. We first consider the ideal case that altruistic costs can be perfectly measured by altruistic vehicles. We give the conditions for the proportion of altruistic vehicles and the weight configuration of the altruistic costs, under which the social delay can be decreased or reach the optimal. Subsequently, we consider the impact of uncertainty in the measurement of altruistic costs and we give the optimal weight configuration for altruistic vehicles which minimizes the worst-case social delay under such uncertainty.      
### 24.Silent Tracker: In-band Beam Management for Soft Handover for mm-Wave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.08335.pdf)
>  In mm-wave networks, cell sizes are small due to high path and penetration losses. Mobiles need to frequently switch softly from one cell to another to preserve network connections and context. Each soft handover involves the mobile performing directional neighbor cell search, tracking cell beam, completing cell access request, and finally, context switching. The mobile must independently discover cell beams, derive timing information, and maintain beam alignment throughout the process to avoid packet loss and hard handover. We propose Silent tracker which enables a mobile to reliably manage handover events by maintaining an aligned beam until the successful handover completion. It is entirely in-band beam mechanism that does not need any side information. Experimental evaluations show that Silent Tracker maintains the mobile's receive beam aligned to the potential target base station's transmit beam till the successful conclusion of handover in three mobility scenarios: human walk, device rotation, and 20 mph vehicular speed.      
### 25.Attention-based Multi-scale Gated Recurrent Encoder with Novel Correlation Loss for COVID-19 Progression Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2107.08330.pdf)
>  COVID-19 image analysis has mostly focused on diagnostic tasks using single timepoint scans acquired upon disease presentation or admission. We present a deep learning-based approach to predict lung infiltrate progression from serial chest radiographs (CXRs) of COVID-19 patients. Our method first utilizes convolutional neural networks (CNNs) for feature extraction from patches within the concerned lung zone, and also from neighboring and remote boundary regions. The framework further incorporates a multi-scale Gated Recurrent Unit (GRU) with a correlation module for effective predictions. The GRU accepts CNN feature vectors from three different areas as input and generates a fused representation. The correlation module attempts to minimize the correlation loss between hidden representations of concerned and neighboring area feature vectors, while maximizing the loss between the same from concerned and remote regions. Further, we employ an attention module over the output hidden states of each encoder timepoint to generate a context vector. This vector is used as an input to a decoder module to predict patch severity grades at a future timepoint. Finally, we ensemble the patch classification scores to calculate patient-wise grades. Specifically, our framework predicts zone-wise disease severity for a patient on a given day by learning representations from the previous temporal CXRs. Our novel multi-institutional dataset comprises sequential CXR scans from N=93 patients. Our approach outperforms transfer learning and radiomic feature-based baseline approaches on this dataset.      
### 26.Learning Sparse Privacy-Preserving Representations for Smart Meters Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.08315.pdf)
>  Fine-grained Smart Meters (SMs) data recording and communication has enabled several features of Smart Grids (SGs) such as power quality monitoring, load forecasting, fault detection, and so on. In addition, it has benefited the users by giving them more control over their electricity consumption. However, it is well-known that it also discloses sensitive information about the users, i.e., an attacker can infer users' private information by analyzing the SMs data. In this study, we propose a privacy-preserving approach based on non-uniform down-sampling of SMs data. We formulate this as the problem of learning a sparse representation of SMs data with minimum information leakage and maximum utility. The architecture is composed of a releaser, which is a recurrent neural network (RNN), that is trained to generate the sparse representation by masking the SMs data, and an utility and adversary networks (also RNNs), which help the releaser to minimize the leakage of information about the private attribute, while keeping the reconstruction error of the SMs data minimum (i.e., maximum utility). The performance of the proposed technique is assessed based on actual SMs data and compared with uniform down-sampling, random (non-uniform) down-sampling, as well as the state-of-the-art in privacy-preserving methods using a data manipulation approach. It is shown that our method performs better in terms of the privacy-utility trade-off while releasing much less data, thus also being more efficient.      
### 27.Learning to Equalize OTFS  [ :arrow_down: ](https://arxiv.org/pdf/2107.08236.pdf)
>  Orthogonal Time Frequency Space (OTFS) is a novel framework that processes modulation symbols via a time-independent channel characterized by the delay-Doppler domain. The conventional waveform, orthogonal frequency division multiplexing (OFDM), requires tracking frequency selective fading channels over the time, whereas OTFS benefits from full time-frequency diversity by leveraging appropriate equalization techniques. In this paper, we consider a neural network-based supervised learning framework for OTFS equalization. Learning of the introduced neural network is conducted in each OTFS frame fulfilling an online learning framework: the training and testing datasets are within the same OTFS-frame over the air. Utilizing reservoir computing, a special recurrent neural network, the resulting one-shot online learning is sufficiently flexible to cope with channel variations among different OTFS frames (e.g., due to the link/rank adaptation and user scheduling in cellular networks). The proposed method does not require explicit channel state information (CSI) and simulation results demonstrate a lower bit error rate (BER) than conventional equalization methods in the low signal-to-noise (SNR) regime under large Doppler spreads. When compared with its neural network-based counterparts for OFDM, the introduced approach for OTFS will lead to a better tradeoff between the processing complexity and the equalization performance.      
### 28.Dynamic Prioritization of Emergency Vehicles For Self-Organizing Traffic using VTL+EV *  [ :arrow_down: ](https://arxiv.org/pdf/2107.08232.pdf)
>  Cooperative vehicular technology in recent times has aided in realizing some state-of-art technologies like autonomous driving. Effective and efficient prioritization of emergency vehicles (EVs) using cooperative vehicular technology can undoubtedly aid in saving property and lives. Contemporary EV prioritization, called preemption, is highly dependent on existing traffic infrastructure. Accessing crucial decision parameters for preemption like speed, position and acceleration data in real-time is almost impossible in current systems. The connected vehicle can provide such data in real-time, which makes EV preemption more responsive and effective. Also, autonomous vehicles can help in optimizing the timing in traffic phases and minimize human-related loss like higher headway times and inconsistent inter-vehicle spacing when following each other. In this paper, we introduce self-coordinating a decentralized traffic control system termed as Virtual Traffic Light plus for Emergency Vehicle (VTL+EV) to prioritize EVs in an intersection. The proposed system can expedite EVs movement through intersections and impose minimal waiting time for ordinary vehicles. The VTL+EV algorithm also can improve overall throughput making an intersection more efficient.      
### 29.Proactive Rolling-Horizon based Scheduling of Hydrogen Systems for Resilient Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2107.08200.pdf)
>  Deploying distributed energy resources (DERs) and other smart grid technologies have increased the complexity of power grids and made them more vulnerable to natural disasters and cyber-physical-human (CPH) threats. To deal with these extreme events, proactive plans are required by utilities to minimize the damages caused by CPH threats. This paper proposes a proactive rolling-horizon-based scheme for the resilience-oriented operation of hydrogen (H2) systems in integrated distribution and transmission networks. The proposed framework is a bi-level model in which the upper-level is focused on distribution system operation in both normal and emergency operation modes, and the lower-level problem accounts for the transmission network operation. Two preeminent aspects of H2 systems are considered in this paper, 1) to show the flexibility of H2 systems, capacity-based demand response signals are considered for electrolyzers, stationary fuel cell (FC) units, and H2 storage tanks are considered in both normal and emergency operation modes; 2) unlike the batteries which can only charge and discharge energy based on maximum duration times and power ratings, H2 systems can be considered as the flexible long-term energy storage by storing H2 for days and supplying power to FC in the case of \textit{N-m} outages lasting for more than 10 hours. Moreover, H2 production cost based on water electrolysis and storage costs is calculated. Simulation results demonstrate that utilities can improve the system-level resilience using H2 systems as long-term backup power resources.      
### 30.Developing Synthetic Spectroscopy Noise and Chemometric Database for Computational Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.08196.pdf)
>  There has been little to no work in the area of spectroscopy noise in order to create data sets for analytical algorithms to be challenged on the ability to separate chemicals. We present a framework on how to build off of a sparse about of experimental data in order to expand your chemometric database and create realistic instrumentation noise. The combination of various interactions of chemicals combined with various random permutations of spectroscopy noises enables researchers to better capture and model the multitude of types of signals and variations that can be present within an experimental reading.      
### 31.Energy-Efficient Tethered UAV Deployment in B5G for Smart Environments and Disaster Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2107.08169.pdf)
>  Due to Unmanned aerial vehicles (UAVs) limitations in processing power and battery lifetime. The tethered UAV (TUAV) offers an attractive approach to answer these shortcomings. Since a tethered connected to UAV is one potential energy solution to provide a stable power supply that connects to the ground would achieve impressive performances in smart environments and disaster recovery. The proposed solution is intended to provide stable energy and increase the coverage area of TUAV for smart environments and disaster recovery. This paper proposed that the tethered connected to UAV will provide the continuous supply and exchange the data with ground terminals. Besides the adjustable tether length, elevation angels act to increase the hovering region, leading to the scalability of coverage in many applications. Moreover, the power consumption and transmission the distance while achieving a trade-off between the hovering and coverage probabilities. The simulation results demonstrate efficient performance in terms of line-of-sight probability, path loss, and coverage probability for scalability coverage smart environments and disaster recovery scenarios. Furthermore, maximum coverage probability is achieved versus increased tethered length because of the gain and fly over a region of maximum tethered.      
### 32.Routing Autonomous Emergency Vehicles in Smart Cities Using Real Time Systems Analogy: A Conceptual Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.08167.pdf)
>  Emergency service vehicles like ambulance, fire, police etc. should respond to emergencies on time. Existing barriers like increased congestion, multiple signalized intersections, queued vehicles, traffic phase timing etc. can prevent emergency vehicles (EVs) achieving desired response times. Existing solutions to route EVs have not been successful because they do not use dynamic traffic parameters. Real time information on increased congestion, halts on road, pedestrian flow, queued vehicles, real and adaptive speed, can be used to properly actuate pre-emption and minimise the impact that EV movement can have on other traffic. Smart cities provide the necessary infrastructure to enable two critical factors in EV routing: real-time traffic data and connectivity. In addition, using autonomous vehicles (AVs) in place of normal emergency service vehicles can have further advantages in terms of safety and adaptability in smart city environments. AVs feature several sensors and connectivity that can help them make real-time decisions. We propose a novel idea of using autonomous emergency vehicles (AEVs) that can meet the critical response time and drive through a complex road network in smart cities efficiently and safely. This is achieved by considering traffic network analogous to real-time systems (RTS) where we use mixed-criticality real-time system (MCRTS) task scheduling to schedule AEVs for meeting response time.      
### 33.Real-Time Mapping of Tissue Properties for Magnetic Resonance Fingerprinting  [ :arrow_down: ](https://arxiv.org/pdf/2107.08120.pdf)
>  Magnetic resonance Fingerprinting (MRF) is a relatively new multi-parametric quantitative imaging method that involves a two-step process: (i) reconstructing a series of time frames from highly-undersampled non-Cartesian spiral k-space data and (ii) pattern matching using the time frames to infer tissue properties (e.g., T1 and T2 relaxation times). In this paper, we introduce a novel end-to-end deep learning framework to seamlessly map the tissue properties directly from spiral k-space MRF data, thereby avoiding time-consuming processing such as the nonuniform fast Fourier transform (NUFFT) and the dictionary-based Fingerprint matching. Our method directly consumes the non-Cartesian k- space data, performs adaptive density compensation, and predicts multiple tissue property maps in one forward pass. Experiments on both 2D and 3D MRF data demonstrate that quantification accuracy comparable to state-of-the-art methods can be accomplished within 0.5 second, which is 1100 to 7700 times faster than the original MRF framework. The proposed method is thus promising for facilitating the adoption of MRF in clinical settings.      
### 34.Federated Whole Prostate Segmentation in MRI with Personalized Neural Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2107.08111.pdf)
>  Building robust deep learning-based models requires diverse training data, ideally from several sources. However, these datasets cannot be combined easily because of patient privacy concerns or regulatory hurdles, especially if medical data is involved. Federated learning (FL) is a way to train machine learning models without the need for centralized datasets. Each FL client trains on their local data while only sharing model parameters with a global server that aggregates the parameters from all clients. At the same time, each client's data can exhibit differences and inconsistencies due to the local variation in the patient population, imaging equipment, and acquisition protocols. Hence, the federated learned models should be able to adapt to the local particularities of a client's data. In this work, we combine FL with an AutoML technique based on local neural architecture search by training a "supernet". Furthermore, we propose an adaptation scheme to allow for personalized model architectures at each FL client's site. The proposed method is evaluated on four different datasets from 3D prostate MRI and shown to improve the local models' performance after adaptation through selecting an optimal path through the AutoML supernet.      
### 35.Introducing Introspective Transmission for Reflection Characterization in High Frame-Rate Ultrasound Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2107.08069.pdf)
>  In ultrasound imaging, most of the transmit and receive beamforming schemes assume a homogenous diffuse medium and are evaluated based on contrast, temporal and spatial resolutions. However, most medium are constituted by both diffuse and specular regions and the assumption of a homogeneous medium does not hold good in all cases. Eventhough, there are some adaptive beamforming approaches proposed in literature, they are mostly for receive beamforming. This study is aimed at investigating the relevance of transmission schemes in characterizing the diffuse and specular reflections, particularly at high frame rates. The transmit wavefront interaction behavior on the tissue interfaces for two high frame-rate transmission modalities, i.e. conventional synthetic transmit aperture imaging and multi-angle plane-wave imaging, are analyzed for multiple in-vitro and in-vivo radio-frequency datasets. Two novel visualization perspectives are proposed called contour isolines and directivity variance to understand the wave interaction with different tissue interfaces by considering the scalar and vector aspects of the reflected intensities respectively. We also rationalize the relevance of choosing the appropriate receive beamforming scheme according to the transmission modality through a comparison of delay and sum, filtered delay multiply and sum, minimum variance distortionless response, and specular beamforming algorithms. It is found that a synergistic blend of transmit and receive beamforming schemes adaptive to the tissue is inevitable to avoid any misdiagnosis.      
### 36.Space-Time Finite Element for Sensor Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2107.09021.pdf)
>  Drones estimate their position and orientation with the help of various sensors. Their data streams, that differ with respect to the sampling rate and standard deviation, need to be fused to get an accurate position and orientation estimate. It is subsequently shown that a nonlinear space-time finite element and static condensation can be used to accomplish this task. This is done, for the sake of clarity, in three stages. The first stage estimates the local magnetic north vector with the help of magnetometers and gyroscopes. The second stage projects the remaining sensor data onto the plane that is orthogonal to the local magnetic north vector and the third stage solves the corresponding two-dimensional problem.      
### 37.A symbiotic relationship: the feasibility of community-scale energy storage deployed with local network tariffs  [ :arrow_down: ](https://arxiv.org/pdf/2107.09019.pdf)
>  Distribution networks (DNs) that contain large amounts of distributed energy resources (DER) may experience peer-to-peer power flows between customers. These power flows can create technical challenges and their pricing poses socio-economic questions regarding fairness and equity. This paper demonstrates how these challenges can be addressed in unison by deploying Community-scale Energy Storage (CES) and updating DN pricing structures with a tier of local network tariffs. While both of these interventions have been studied in isolation, we for the first time show how their combination can be symbiotic and resolve the shortcomings that each faces when deployed in isolation - the feasibility of CES is no longer blocked by network tariffs and local network tariffs are no longer a zero-sum trade off between DN operators and customer segments. Our study simulates the operation of a CES under a range of local network tariff models, using current Australian electricity prices and current network prices as a reference. We assess the financial outcomes for solar and non-solar owning customers and the DN operator, as well as the self-sufficiency of the local network and self-consumption of locally generated solar power. Our results establish that it is critical for local network tariffs to be set to less than half the standard distribution network tariff in order for the CES to achieve its full potential and for all stakeholders to benefit. This finding provides clear guidance to regulators and policy makers and promises to make both innovations financially and politically feasible.      
### 38.Over-Parameterization and Generalization in Audio Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.08933.pdf)
>  Convolutional Neural Networks (CNNs) have been dominating classification tasks in various domains, such as machine vision, machine listening, and natural language processing. In machine listening, while generally exhibiting very good generalization capabilities, CNNs are sensitive to the specific audio recording device used, which has been recognized as a substantial problem in the acoustic scene classification (DCASE) community. In this study, we investigate the relationship between over-parameterization of acoustic scene classification models, and their resulting generalization abilities. Specifically, we test scaling CNNs in width and depth, under different conditions. Our results indicate that increasing width improves generalization to unseen devices, even without an increase in the number of parameters.      
### 39.Generalized Outer Bounds on the Finite Geometric Sum of Ellipsoids  [ :arrow_down: ](https://arxiv.org/pdf/2107.08912.pdf)
>  General results on convex bodies are reviewed and used to derive an exact closed-form parametric formula for the boundary of the geometric (Minkowski) sum of $k$ ellipsoids in $n$-dimensional Euclidean space. Previously this was done through iterative algorithms in which each new ellipsoid was added to an ellipsoid approximation of the sum of the previous ellipsoids. Here we provide one shot formulas to add $k$ ellipsoids directly with no intermediate approximations required. This allows us to observe a new degree of freedom in the family of ellipsoidal bounds on the geometric sum. We demonstrate an application of these tools to compute the reachable set of a discrete-time dynamical system.      
### 40.Regular Perturbation and Achievable Rates of Space-Division Multiplexed Optical Channels  [ :arrow_down: ](https://arxiv.org/pdf/2107.08858.pdf)
>  Regular perturbation is applied to space-division multiplexing (SDM) on optical fibers and motivates a correlated rotation-and-additive noise (CRAN) model. For S spatial modes, or 2S complex-alphabet channels, the model has 4S(S+1) hidden independent real Gauss-Markov processes, of which 2S model phase noise, 2S(2S-1) model spatial mode rotation, and 4S model additive noise. Achievable information rates of multi-carrier communication are computed by using particle filters. For S=2 spatial modes with strong coupling and a 1000 km link, joint processing of the spatial modes gains 0.5 bits/s/Hz/channel in rate and 1.4 dB in power with respect to separate processing of 2S complex-alphabet channels without considering CRAN.      
### 41.Time Series Anomaly Detection for Smart Grids: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2107.08835.pdf)
>  With the rapid increase in the integration of renewable energy generation and the wide adoption of various electric appliances, power grids are now faced with more and more challenges. One prominent challenge is to implement efficient anomaly detection for different types of anomalous behaviors within power grids. These anomalous behaviors might be induced by unusual consumption patterns of the users, faulty grid infrastructures, outages, external cyberattacks, or energy fraud. Identifying such anomalies is of critical importance for the reliable and efficient operation of modern power grids. Various methods have been proposed for anomaly detection on power grid time-series data. This paper presents a short survey of the recent advances in anomaly detection for power grid time-series data. Specifically, we first outline current research challenges in the power grid anomaly detection domain and further review the major anomaly detection approaches. Finally, we conclude the survey by identifying the potential directions for future research.      
### 42.GenSys: A Scalable Fixed-point Engine for Maximal Controller Synthesis over Infinite State Spaces  [ :arrow_down: ](https://arxiv.org/pdf/2107.08794.pdf)
>  The synthesis of maximally-permissive controllers in infinite-state systems has many practical applications. Such controllers directly correspond to maximal winning strategies in logically specified infinite-state two-player games. In this paper, we introduce a tool called GenSys which is a fixed-point engine for computing maximal winning strategies for players in infinite-state safety games. A key feature of GenSys is that it leverages the capabilities of existing off-the-shelf solvers to implement its fixed point engine. GenSys outperforms state-of-the-art tools in this space by a significant margin. Our tool has solved some of the challenging problems in this space, is scalable, and also synthesizes compact controllers. These controllers are comparatively small in size and easier to comprehend. GenSys is freely available for use and is available under an open-source license.      
### 43.Anomaly Detection Based on Multiple-Hypothesis Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2107.08790.pdf)
>  Recently Autoencoder(AE) based models are widely used in the field of anomaly detection. A model trained with normal data generates a larger restoration error for abnormal data. Whether or not abnormal data is determined by observing the restoration error. It takes a lot of cost and time to obtain abnormal data in the industrial field. Therefore the model trains only normal data and detects abnormal data in the inference phase. However, the restoration area for the input data of AE is limited in the latent space. To solve this problem, we propose Multiple-hypothesis Autoencoder(MH-AE) model composed of several decoders. MH-AE model increases the restoration area through contention between decoders. The proposed method shows that the anomaly detection performance is improved compared to the traditional AE for various input datasets.      
### 44.Measuring a Six-hole Recorder Flute's Response to Breath Pressure Variations and Fitting a Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.08727.pdf)
>  We propose the Siamese-flute method that measures the breath pressure and the acoustic sound in parallel. We fit a 6-DoF model to describe how the breath pressure affects the octave and the microtonal pitch bend, revealing the octave hysteresis. We release both our model parameters and our data analysis tools.      
### 45.Compact User-Side Reconfigurable Intelligent Surfaces for Uplink Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2107.08698.pdf)
>  Large-scale antenna arrays employed by the base station (BS) constitute an essential next-generation communications technique. However, due to the constraints of size, cost, and power consumption, it is usually considered unrealistic to use a large-scale antenna array at the user side. Inspired by the emerging technique of reconfigurable intelligent surfaces (RIS), we firstly propose the concept of user-side RIS (US-RIS) for facilitating the employment of a large-scale antenna array at the user side in a cost- and energy-efficient way. In contrast to the existing employments of RIS, which belong to the family of base-station-side RISs (BSS-RISs), the US-RIS concept by definition facilitates the employment of RIS at the user side for the first time. This is achieved by conceiving a multi-layer structure to realize a compact form-factor. Furthermore, our theoretical results demonstrate that, in contrast to the existing single-layer structure, where only the phase of the signal reflected from RIS can be adjusted, the amplitude of the signal penetrating multi-layer US-RIS can also be partially controlled, which brings about a new degree of freedom (DoF) for beamformer design that can be beneficially exploited for performance enhancement. In addition, based on the proposed multi-layer US-RIS, we formulate the signal-to-noise ratio (SNR) maximization problem of US-RIS-aided communications. Due to the non-convexity of the problem introduced by this multi-layer structure, we propose a multi-layer transmit beamformer design relying on an iterative algorithm for finding the optimal solution by alternately updating each variable. Finally, our simulation results verify the superiority of the proposed multi-layer US-RIS as a compact realization of a large-scale antenna array at the user side for uplink transmission.      
### 46.Translatotron 2: Robust direct speech-to-speech translation  [ :arrow_down: ](https://arxiv.org/pdf/2107.08661.pdf)
>  We present Translatotron 2, a neural direct speech-to-speech translation model that can be trained end-to-end. Translatotron 2 consists of a speech encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention module that connects all the previous three components. Experimental results suggest that Translatotron 2 outperforms the original Translatotron by a large margin in terms of translation quality and predicted speech naturalness, and drastically improves the robustness of the predicted speech by mitigating over-generation, such as babbling or long pause. We also propose a new method for retaining the source speaker's voice in the translated speech. The trained model is restricted to retain the source speaker's voice, and unlike the original Translatotron, it is not able to generate speech in a different speaker's voice, making the model more robust for production deployment, by mitigating potential misuse for creating spoofing audio artifacts. When the new method is used together with a simple concatenation-based data augmentation, the trained Translatotron 2 model is able to retain each speaker's voice for input with speaker turns.      
### 47.Controlled invariant sets: implicit closed-form representations and applications  [ :arrow_down: ](https://arxiv.org/pdf/2107.08566.pdf)
>  In this paper we revisit the problem of computing robust controlled invariant sets for discrete-time linear systems. The key idea is that by considering controllers that exhibit eventually periodic behavior, we obtain a closed-form expression for an implicit representation of a robust controlled invariant set in the space of states and finite input sequences. Due to the derived closed-form expression, our method is suitable for high dimensional systems. Optionally, one obtains an explicit robust controlled invariant set by projecting the implicit representation to the original state space. The proposed method is complete in the absence of disturbances, with a weak completeness result established when disturbances are present. Moreover, we show that a specific controller choice yields a hierarchy of robust controlled invariant sets. To validate the proposed method, we present thorough case studies illustrating that in safety-critical scenarios the implicit representation suffices in place of the explicit invariant set.      
### 48.Scalable Distributed Planning for Multi-Robot, Multi-Target Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2107.08550.pdf)
>  In multi-robot multi-target tracking, robots coordinate to monitor groups of targets moving about an environment. We approach planning for such scenarios by formulating a receding-horizon, multi-robot sensing problem with a mutual information objective. Such problems are NP-Hard in general. Yet, our objective is submodular which enables certain greedy planners to guarantee constant-factor suboptimality. However, these greedy planners require robots to plan their actions in sequence, one robot at a time, so planning time is at least proportional to the number of robots. Solving these problems becomes intractable for large teams, even for distributed implementations. Our prior work proposed a distributed planner (RSP) which reduces this number of sequential steps to a constant, even for large numbers of robots, by allowing robots to plan in parallel while ignoring some of each others' decisions. Although that analysis is not applicable to target tracking, we prove a similar guarantee, that RSP planning approaches performance guarantees for fully sequential planners, by employing a novel bound which takes advantage of the independence of target motions to quantify effective redundancy between robots' observations and actions. Further, we present analysis that explicitly accounts for features of practical implementations including approximations to the objective and anytime planning. Simulation results -- available via open source release -- for target tracking with ranging sensors demonstrate that our planners consistently approach the performance of sequential planning (in terms of position uncertainty) given only 2--8 planning steps and for as many as 96 robots with a 24x reduction in the number of sequential steps in planning. Thus, this work makes planning for multi-robot target tracking tractable at much larger scales than before, for practical planners and general tracking problems.      
### 49.Distributed Planning for Serving Cooperative Tasks with Time Windows: A Game Theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2107.08540.pdf)
>  We study distributed planning for multi-robot systems to provide optimal service to cooperative tasks that are distributed over space and time. Each task requires service by sufficiently many robots at the specified location within the specified time window. Tasks arrive over episodes and the robots try to maximize the total value of service in each episode by planning their own trajectories based on the specifications of incoming tasks. Robots are required to start and end each episode at their assigned stations in the environment. We present a game theoretic solution to this problem by mapping it to a game, where the action of each robot is its trajectory in an episode, and using a suitable learning algorithm to obtain optimal joint plans in a distributed manner. We present a systematic way to design minimal action sets (subsets of feasible trajectories) for robots based on the specifications of incoming tasks to facilitate fast learning. We then provide the performance guarantees for the cases where all the robots follow a best response or noisy best response algorithm to iteratively plan their trajectories. While the best response algorithm leads to a Nash equilibrium, the noisy best response algorithm leads to globally optimal joint plans with high probability. We show that the proposed game can in general have arbitrarily poor Nash equilibria, which makes the noisy best response algorithm preferable unless the task specifications are known to have some special structure. We also describe a family of special cases where all the equilibria are guaranteed to have bounded suboptimality. Simulations and experimental results are provided to demonstrate the proposed approach.      
### 50.Enhancing synchronization by optimal correlated noise  [ :arrow_down: ](https://arxiv.org/pdf/2107.08509.pdf)
>  From the flashes of fireflies to Josephson junctions and power infrastructure, networks of coupled phase oscillators provide a powerful framework to describe synchronization phenomena in many natural and engineered systems. Most real-world networks are under the influence of noisy, random inputs, potentially inhibiting synchronization. While noise is unavoidable, here we show that there exist optimal noise patterns which minimize desynchronizing effects and even enhance order. Specifically, using analytical arguments we show that in the case of a two-oscillator model, there exists a sharp transition from a regime where the optimal synchrony-enhancing noise is perfectly anti-correlated, to one where the optimal noise is correlated. More generally, we then use numerical optimization methods to demonstrate that there exist anti-correlated noise patterns that optimally enhance synchronization in large complex oscillator networks. Our results may have implications in real-world networks such as power grids and neuronal networks, which are subject to significant amounts of correlated input noise.      
### 51.System-Wide Security for Offline Payment Terminals  [ :arrow_down: ](https://arxiv.org/pdf/2107.08490.pdf)
>  Most self-service payment terminals require network connectivity for processing electronic payments. The necessity to maintain network connectivity increases costs, introduces cybersecurity risks, and significantly limits the number of places where the terminals can be installed. Leading payment service providers have proposed offline payment solutions that rely on algorithmically generated payment tokens. Existing payment token solutions, however, require complex mechanisms for authentication, transaction management, and most importantly, security risk management. In this paper, we present VolgaPay, a blockchain-based system that allows merchants to deploy secure offline payment terminal infrastructure that does not require collection and storage of any sensitive data. We design a novel payment protocol which mitigates security threats for all the participants of VolgaPay, such that the maximum loss from gaining full access to any component by an adversary incurs only a limited scope of harm. We achieve significant enhancements in security, operation efficiency, and cost reduction via a combination of polynomial multi-hash chain micropayment channels and blockchain grafting for off-chain channel state transition. We implement the VolgaPay payment system, and with thorough evaluation and security analysis, we demonstrate that VolgaPay is capable of delivering a fast, secure, and cost-efficient solution for offline payment terminals.      
### 52.Reference Governor-Based Fault-Tolerant Constrained Control  [ :arrow_down: ](https://arxiv.org/pdf/2107.08457.pdf)
>  This paper presents a fault-tolerant control scheme for constrained linear systems. First, a new variant of the Reference Governor (RG) called At Once Reference Governor (AORG) is introduced. The AORG is distinguished from the conventional RG by computing the Auxiliary Reference (AR) sequence so that to optimize performance over a prescribed time interval instead of only at the current time instant; this enables the integration of the AORG with fault detection schemes. In particular, it is shown that, when the AORG is combined with a Multi-Model Adaptive Estimator (MMAE), the AR sequence can be determined such that the tracking properties are guaranteed and constraints are satisfied at all times, while the detection performance is optimized, i.e., faults can be detected with a high probability of correctness. In addition a reconfiguration scheme is presented that ensures system viability despite the presence of faults based on recoverable sets. Simulations on a Boeing 747-100 aircraft model are carried out to evaluate the effectiveness of the AORG scheme in enforcing constraints and tracking the desired roll and side-slip angles. The effectiveness of the presented fault-tolerant control scheme in maintaining the airplane viability in the presence of damaged vertical stabilizer is also demonstrated.      
### 53.Sleep Staging Based on Serialized Dual Attention Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.08442.pdf)
>  Sleep staging assumes an important role in the diagnosis of sleep disorders. In general, experts classify sleep stages manually based on polysomnography (PSG), which is quite time-consuming. Meanwhile, the acquisition of multiple signals is complex, which can affect the subject's sleep. Therefore, the use of single-channel electroencephalogram (EEG) for automatic sleep staging has become mainstream. In the literature, a large number of sleep staging methods based on single-channel EEG have been proposed with good results and realize the preliminary automation of sleep staging. However, the performance for most of these methods in the N1 stage is generally not high. In this paper, we propose a deep learning model SDAN based on raw EEG. The method utilises a one-dimensional convolutional neural network (CNN) to automatically extract features from raw EEG. It serially combines the channel attention and spatial attention mechanisms to filter and highlight key information and then uses soft threshold to eliminate redundant information. Additionally, we introduce a residual network to avoid degradation problems caused by network deepening. Experiments were conducted using two datasets with 5-fold cross-validation and hold-out validation method. The final average accuracy, overall accuracy, macro F1 score and Cohen's Kappa coefficient of the model reach 96.74%, 91.86%, 82.64% and 0.8742 on the Sleep-EDF dataset, and 95.98%, 89.96%, 79.08% and 0.8216 on the Sleep-EDFx dataset. Significantly, our model performed superiorly in the N1 stage, with F1 scores of 54.08% and 52.49% on the two datasets respectively. The results show the superiority of our network over the best existing methods, reaching a new state-of-the-art. In particular, the present method achieves excellent results in the N1 sleep stage compared to other methods.      
### 54.A Miniature Biological Eagle-Eye Vision System for Small Target Detection  [ :arrow_down: ](https://arxiv.org/pdf/2107.08406.pdf)
>  Small target detection is known to be a challenging problem. Inspired by the structural characteristics and physiological mechanism of eagle-eye, a miniature vision system is designed for small target detection in this paper. First, a hardware platform is established, which consists of a pan-tilt, a short-focus camera and a long-focus camera. Then, based on the visual attention mechanism of eagle-eye, the cameras with different focal lengths are controlled cooperatively to achieve small target detection. Experimental results show that the designed biological eagle-eye vision system can accurately detect small targets, which has a strong adaptive ability.      
### 55.Detecting Braess Routes: an Algorithm Accounting for Queuing Delays With an Extended Graph  [ :arrow_down: ](https://arxiv.org/pdf/2107.08374.pdf)
>  The Braess paradox is a counter-intuitive phenomenon whereby adding roads to a network results in higher travel time at equilibrium. In this paper we present an algorithm to detect the occurrence of this paradox in real-world networks with the help of an improved graph representation accounting for queues. The addition of queues to the network representation enables a closer match with real data. Moreover, we search for routes causing this phenomenon ("Braess routes") rather than links, and advocate removing such routes virtually from navigation systems so that the associated links can continue to serve other routes. Our algorithm relies on a convex optimization problem utilizing Beckmann potentials for road links as well as queues, and results in a route reconfiguration with reduced delay. We assume the availability of historical data to build the optimization model. We also assume the existence of a centralized navigation system to manage the routing options and remove the Braess routes. The theoretical solution demonstrates up to 12% delay reduction in a network from Montgomery County, Maryland. We validate the improvement with simulations.      
### 56.An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice Quality and Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.08361.pdf)
>  Emotional Voice Conversion (EVC) aims to convert the emotional style of a source speech signal to a target style while preserving its content and speaker identity information. Previous emotional conversion studies do not disentangle emotional information from emotion-independent information that should be preserved, thus transforming it all in a monolithic manner and generating audio of low quality, with linguistic distortions. To address this distortion problem, we propose a novel StarGAN framework along with a two-stage training process that separates emotional features from those independent of emotion by using an autoencoder with two encoders as the generator of the Generative Adversarial Network (GAN). The proposed model achieves favourable results in both the objective evaluation and the subjective evaluation in terms of distortion, which reveals that the proposed model can effectively reduce distortion. Furthermore, in data augmentation experiments for end-to-end speech emotion recognition, the proposed StarGAN model achieves an increase of 2% in Micro-F1 and 5% in Macro-F1 compared to the baseline StarGAN model, which indicates that the proposed model is more valuable for data augmentation.      
### 57.Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors  [ :arrow_down: ](https://arxiv.org/pdf/2107.08337.pdf)
>  Listening in noisy environments can be difficult even for individuals with a normal hearing thresholds. The speech signal can be masked by noise, which may lead to word misperceptions on the side of the listener, and overall difficulty to understand the message. To mitigate hearing difficulties on listeners, a co-operative speaker utilizes voice modulation strategies like Lombard speech to generate noise-robust utterances, and similar solutions have been developed for speech synthesis systems. In this work, we propose an alternate solution of choosing noise-robust lexical paraphrases to represent an intended meaning. Our results show that lexical paraphrases differ in their intelligibility in noise. We evaluate the intelligibility of synonyms in context and find that choosing a lexical unit that is less risky to be misheard than its synonym introduced an average gain in comprehension of 37% at SNR -5 dB and 21% at SNR 0 dB for babble noise.      
### 58.Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.08325.pdf)
>  Autonomous car racing is a challenging task in the robotic control area. Traditional modular methods require accurate mapping, localization and planning, which makes them computationally inefficient and sensitive to environmental changes. Recently, deep-learning-based end-to-end systems have shown promising results for autonomous driving/racing. However, they are commonly implemented by supervised imitation learning (IL), which suffers from the distribution mismatch problem, or by reinforcement learning (RL), which requires a huge amount of risky interaction data. In this work, we present a general deep imitative reinforcement learning approach (DIRL), which successfully achieves agile autonomous racing using visual inputs. The driving knowledge is acquired from both IL and model-based RL, where the agent can learn from human teachers as well as perform self-improvement by safely interacting with an offline world model. We validate our algorithm both in a high-fidelity driving simulation and on a real-world 1/20-scale RC-car with limited onboard computation. The evaluation results demonstrate that our method outperforms previous IL and RL methods in terms of sample efficiency and task performance. Demonstration videos are available at <a class="link-external link-https" href="https://caipeide.github.io/autorace-dirl/" rel="external noopener nofollow">this https URL</a>      
### 59.Downlink MIMO-RSMA with Successive Null-Space Precoding  [ :arrow_down: ](https://arxiv.org/pdf/2107.08294.pdf)
>  In this paper, we consider the precoder design for an underloaded or critically loaded downlink multi-user multiple-input multiple-output (MIMO) communication system. We propose novel precoding and decoding schemes which enhance system performance based on rate splitting at the transmitter and single-stage successive interference cancellation at the receivers. The proposed successive null-space (SNS) precoding utilizes linear combinations of the null-space basis vectors of the successively augmented MIMO channel matrices of the users as precoding vectors to adjust the inter-user-interference experienced by the receivers. We formulate a non-convex weighted sum rate optimization problem for the precoding vectors and the associated power allocation for the proposed SNS-based MIMO-rate-splitting multiple access (RSMA) scheme. We obtain a suboptimal solution for this problem via successive convex approximation. Moreover, we study the robustness of the proposed precoding scheme to imperfect channel state information (CSI) at the base station via derivative-based sensitivity analysis. Our analysis and simulation results reveal the enhanced performance and robustness of the proposed SNS-based MIMO-RSMA scheme over several baseline multi-user MIMO schemes, especially for imperfect CSI.      
### 60.Design and Fabrication of a Microfluidic System with Nozzle/Diffuser Micropump and Viscosity  [ :arrow_down: ](https://arxiv.org/pdf/2107.08284.pdf)
>  Micropumps are one of the most important parts of a microfluidic system. In particular, for biomedical applications such as Lab-on-Chip systems, micropumps are used to transport and manipulate test fluids in a controlled manner. In this work, a low-cost, structurally simple, piezoelectrically actuated micropump was simulated and fabricated using poly-dimethylsiloxane (PDMS). The channels in PDMS were fabricated using patterned SU-8 structures. The pump flow rate was measured to be 9.49 uL/min, 14.06 uL/min, 20.87 uL/min for applied voltages of 12 V, 14 V, 16 V respectively. Further, we report finite element analysis (FEA) simulation to confirm the operation of the micropump and compare favorably the experimentally obtained flowrate with the one predicted by simulation. By taking these flow rates as a reference, the chamber pressure was found to be 1.1 to 1.5 kPa from FEA simulations. <br>Viscosity measurement has wide-ranging applications from the oil industry to the pharmaceutical industry. This work provides an elaborate mathematical model and study of measurement of viscosity in real-time using pressure sensors. For a given flowrate, a change in liquid viscosity gives rise to a change in pressure difference across a particular section of the pipe. Hence, by recording the pressure change, viscosity can be calculated dynamically. Mathematical modeling as well as finite element analysis (FEA) modeling has been presented. A set of pressure sensors were placed at a fixed distance from each other to get the real-time pressure change. Knowing the flow rate in the channel, the viscosity has been calculated from the pressure difference. For the finite element analysis, the pressure sensors were placed 60 mm away from each other. A different ratio of the mixture of water and glycerol was used to provide variable viscosity, which led to the variation in pressure-difference values.      
### 61.Lesion-based Contrastive Learning for Diabetic Retinopathy Grading from Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.08274.pdf)
>  Manually annotating medical images is extremely expensive, especially for large-scale datasets. Self-supervised contrastive learning has been explored to learn feature representations from unlabeled images. However, unlike natural images, the application of contrastive learning to medical images is relatively limited. In this work, we propose a self-supervised framework, namely lesion-based contrastive learning for automated diabetic retinopathy (DR) grading. Instead of taking entire images as the input in the common contrastive learning scheme, lesion patches are employed to encourage the feature extractor to learn representations that are highly discriminative for DR grading. We also investigate different data augmentation operations in defining our contrastive prediction task. Extensive experiments are conducted on the publicly-accessible dataset EyePACS, demonstrating that our proposed framework performs outstandingly on DR grading in terms of both linear evaluation and transfer capacity evaluation.      
### 62.Learning De-identified Representations of Prosody from Raw Audio  [ :arrow_down: ](https://arxiv.org/pdf/2107.08248.pdf)
>  We propose a method for learning de-identified prosody representations from raw audio using a contrastive self-supervised signal. Whereas prior work has relied on conditioning models on bottlenecks, we introduce a set of inductive biases that exploit the natural structure of prosody to minimize timbral information and decouple prosody from speaker representations. Despite aggressive downsampling of the input and having no access to linguistic information, our model performs comparably to state-of-the-art speech representations on DAMMP, a new benchmark we introduce for spoken language understanding. We use minimum description length probing to show that our representations have selectively learned the subcomponents of non-timbral prosody, and that the product quantizer naturally disentangles them without using bottlenecks. We derive an information-theoretic definition of speech de-identifiability and use it to demonstrate that our prosody representations are less identifiable than other speech representations.      
### 63.On Constraints in First-Order Optimization: A View from Non-Smooth Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.08225.pdf)
>  We introduce a class of first-order methods for smooth constrained optimization that are based on an analogy to non-smooth dynamical systems. Two distinctive features of our approach are that (i) projections or optimizations over the entire feasible set are avoided, in stark contrast to projected gradient methods or the Frank-Wolfe method, and (ii) iterates are allowed to become infeasible, which differs from active set or feasible direction methods, where the descent motion stops as soon as a new constraint is encountered. The resulting algorithmic procedure is simple to implement even when constraints are nonlinear, and is suitable for large-scale constrained optimization problems in which the feasible set fails to have a simple structure. The key underlying idea is that constraints are expressed in terms of velocities instead of positions, which has the algorithmic consequence that optimizations over feasible sets at each iteration are replaced with optimizations over local, sparse convex approximations. The result is a simplified suite of algorithms and an expanded range of possible applications in machine learning.      
### 64.Computer-free, all-optical reconstruction of holograms using diffractive networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.08177.pdf)
>  Reconstruction of in-line holograms of unknown objects in general suffers from twin-image artifacts due to the appearance of an out-of-focus image overlapping with the desired image to be reconstructed. Computer-based iterative phase retrieval algorithms and learning-based methods have been used for the suppression of such image artifacts in digital holography. Here we report an all-optical hologram reconstruction method that can instantly retrieve the image of an unknown object from its in-line hologram and eliminate twin-image artifacts without using a digital processor or a computer. Multiple transmissive diffractive layers are trained using deep learning so that the diffracted light from an arbitrary input hologram is processed all-optically, through light-matter interaction, to reconstruct the image of an unknown object at the speed of light propagation and without the need for any external power. This passive all-optical processor composed of spatially-engineered transmissive layers forms a diffractive network, which successfully generalizes to reconstruct in-line holograms of unknown, new objects and exhibits improved diffraction efficiency as well as extended depth-of-field at the hologram recording distance. This all-optical hologram processor and the underlying design framework can find numerous applications in coherent imaging and holographic display-related applications owing to its major advantages in terms of image reconstruction speed and computer-free operation.      
### 65.Large field-of-view non-invasive imaging through scattering layers using fluctuating random illumination  [ :arrow_down: ](https://arxiv.org/pdf/2107.08158.pdf)
>  On-invasive optical imaging techniques are essential diagnostic tools in many fields. Although various recent methods have been proposed to utilize and control light in multiple scattering media, non-invasive optical imaging through and inside scattering layers across a large field of view remains elusive due to the physical limits set by the optical memory effect, especially without wavefront shaping techniques. Here, we demonstrate an approach that enables non-invasive fluorescence imaging behind scattering layers with field-of-views extending well beyond the optical memory effect. The method consists in demixing the speckle patterns emitted by a fluorescent object under variable unknown random illumination, using matrix factorization and a novel fingerprint-based reconstruction. Experimental validation shows the efficiency and robustness of the method with various fluorescent samples, covering a field of view up to three times the optical memory effect range. Our non-invasive imaging technique is simple, neither requires a spatial light modulator nor a guide star, and can be generalized to a wide range of incoherent contrast mechanisms and illumination schemes.      
### 66.Reliability and User-Plane Latency Analysis of mmWave Massive MIMO for Grant-Free URLLC Applications  [ :arrow_down: ](https://arxiv.org/pdf/2107.08151.pdf)
>  5G cellular networks are designed to support a new range of applications not supported by previous standards. Among these, ultra-reliable low-latency communication (URLLC) applications are arguably the most challenging. URLLC service requires the user equipment (UE) to be able to transmit its data under strict latency constraints with high reliability. To address these requirements, new technologies, such as mini-slots, semi-persistent scheduling and grant-free access were introduced in 5G standards. In this work, we formulate a spatiotemporal mathematical model to evaluate the user-plane latency and reliability performance of millimetre wave (mmWave) massive multiple-input multiple-output (MIMO) URLLC with reactive and K-repetition hybrid automatic repeat request (HARQ) protocols. We derive closed-form approximate expressions for the latent access failure probability and validate them using numerical simulations. The results show that, under certain conditions, mmWave massive MIMO can reduce the failure probability by a factor of 32. Moreover, we identify that beyond a certain number of antennas there is no significant improvement in reliability. Finally, we conclude that mmWave massive MIMO alone is not enough to provide the performance guarantees required by the most stringent URLLC applications.      
### 67.A Comparison of Methods for OOV-word Recognition on a New Public Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2107.08091.pdf)
>  A common problem for automatic speech recognition systems is how to recognize words that they did not see during training. Currently there is no established method of evaluating different techniques for tackling this problem. We propose using the CommonVoice dataset to create test sets for multiple languages which have a high out-of-vocabulary (OOV) ratio relative to a training set and release a new tool for calculating relevant performance metrics. We then evaluate, within the context of a hybrid ASR system, how much better subword models are at recognizing OOVs, and how much benefit one can get from incorporating OOV-word information into an existing system by modifying WFSTs. Additionally, we propose a new method for modifying a subword-based language model so as to better recognize OOV-words. We showcase very large improvements in OOV-word recognition and make both the data and code available.      
### 68.Partially-Observed Decoupled Data-based Control (POD2C) for Complex Robotic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.08086.pdf)
>  This paper develops a systematic data-based approach to the closed-loop feedback control of high-dimensional robotic systems using only partial state observation. We first develop a model-free generalization of the iterative Linear Quadratic Regulator (iLQR) to partially-observed systems using an Autoregressive Moving Average (ARMA) model, that is generated using only the input-output data. The ARMA model results in an information state, which has dimension less than or equal to the underlying actual state dimension. This open-loop trajectory optimization solution is then used to design a local feedback control law, and the composite law then provides a solution to the partially observed feedback design problem. The efficacy of the developed method is shown by controlling complex high dimensional nonlinear robotic systems in the presence of model and sensing uncertainty and for which analytical models are either unavailable or inaccurate.      
