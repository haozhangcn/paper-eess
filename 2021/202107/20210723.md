# ArXiv eess --Fri, 23 Jul 2021
### 1.HARP-Net: Hyper-Autoencoded Reconstruction Propagation\\for Scalable Neural Audio Coding  [ :arrow_down: ](https://arxiv.org/pdf/2107.10843.pdf)
>  An autoencoder-based codec employs quantization to turn its bottleneck layer activation into bitstrings, a process that hinders information flow between the encoder and decoder parts. To circumvent this issue, we employ additional skip connections between the corresponding pair of encoder-decoder layers. The assumption is that, in a mirrored autoencoder topology, a decoder layer reconstructs the intermediate feature representation of its corresponding encoder layer. Hence, any additional information directly propagated from the corresponding encoder layer helps the reconstruction. We implement this kind of skip connections in the form of additional autoencoders, each of which is a small codec that compresses the massive data transfer between the paired encoder-decoder layers. We empirically verify that the proposed hyper-autoencoded architecture improves perceptual audio quality compared to an ordinary autoencoder baseline.      
### 2.Whole Heart Mesh Generation For Image-Based Computational Simulations By Learning Free-From Deformations  [ :arrow_down: ](https://arxiv.org/pdf/2107.10839.pdf)
>  Image-based computer simulation of cardiac function can be used to probe the mechanisms of (patho)physiology, and guide diagnosis and personalized treatment of cardiac diseases. This paradigm requires constructing simulation-ready meshes of cardiac structures from medical image data--a process that has traditionally required significant time and human effort, limiting large-cohort analyses and potential clinical translations. We propose a novel deep learning approach to reconstruct simulation-ready whole heart meshes from volumetric image data. Our approach learns to deform a template mesh to the input image data by predicting displacements of multi-resolution control point grids. We discuss the methods of this approach and demonstrate its application to efficiently create simulation-ready whole heart meshes for computational fluid dynamics simulations of the cardiac flow. Our source code is available at <a class="link-external link-https" href="https://github.com/fkong7/HeartFFDNet" rel="external noopener nofollow">this https URL</a>.      
### 3.Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.10833.pdf)
>  Though many attempts have been made in blind super-resolution to restore low-resolution images with unknown and complex degradations, they are still far from addressing general real-world degraded images. In this work, we extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data. Specifically, a high-order degradation modeling process is introduced to better simulate complex real-world degradations. We also consider the common ringing and overshoot artifacts in the synthesis process. In addition, we employ a U-Net discriminator with spectral normalization to increase discriminator capability and stabilize the training dynamics. Extensive comparisons have shown its superior visual performance than prior works on various real datasets. We also provide efficient implementations to synthesize training pairs on the fly.      
### 4.Self-transfer learning via patches: A prostate cancer triage approach based on bi-parametric MRI  [ :arrow_down: ](https://arxiv.org/pdf/2107.10806.pdf)
>  Prostate cancer (PCa) is the second most common cancer diagnosed among men worldwide. The current PCa diagnostic pathway comes at the cost of substantial overdiagnosis, leading to unnecessary treatment and further testing. Bi-parametric magnetic resonance imaging (bp-MRI) based on apparent diffusion coefficient maps (ADC) and T2-weighted (T2w) sequences has been proposed as a triage test to differentiate between clinically significant (cS) and non-clinically significant (ncS) prostate lesions. However, analysis of the sequences relies on expertise, requires specialized training, and suffers from inter-observer variability. Deep learning (DL) techniques hold promise in tasks such as classification and detection. Nevertheless, they rely on large amounts of annotated data which is not common in the medical field. In order to palliate such issues, existing works rely on transfer learning (TL) and ImageNet pre-training, which has been proven to be sub-optimal for the medical imaging domain. In this paper, we present a patch-based pre-training strategy to distinguish between cS and ncS lesions which exploit the region of interest (ROI) of the patched source domain to efficiently train a classifier in the full-slice target domain which does not require annotations by making use of transfer learning (TL). We provide a comprehensive comparison between several CNNs architectures and different settings which are presented as a baseline. Moreover, we explore cross-domain TL which exploits both MRI modalities and improves single modality results. Finally, we show how our approaches outperform the standard approaches by a considerable margin      
### 5.Interpretable SincNet-based Deep Learning for Emotion Recognition from EEG brain activity  [ :arrow_down: ](https://arxiv.org/pdf/2107.10790.pdf)
>  Machine learning methods, such as deep learning, show promising results in the medical domain. However, the lack of interpretability of these algorithms may hinder their applicability to medical decision support systems. This paper studies an interpretable deep learning technique, called SincNet. SincNet is a convolutional neural network that efficiently learns customized band-pass filters through trainable sinc-functions. In this study, we use SincNet to analyze the neural activity of individuals with Autism Spectrum Disorder (ASD), who experience characteristic differences in neural oscillatory activity. In particular, we propose a novel SincNet-based neural network for detecting emotions in ASD patients using EEG signals. The learned filters can be easily inspected to detect which part of the EEG spectrum is used for predicting emotions. We found that our system automatically learns the high-$\alpha$ (9-13 Hz) and $\beta$ (13-30 Hz) band suppression often present in individuals with ASD. This result is consistent with recent neuroscience studies on emotion recognition, which found an association between these band suppressions and the behavioral deficits observed in individuals with ASD. The improved interpretability of SincNet is achieved without sacrificing performance in emotion recognition.      
### 6.High Frequency EEG Artifact Detection with Uncertainty via Early Exit Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2107.10746.pdf)
>  Electroencephalography (EEG) is crucial for the monitoring and diagnosis of brain disorders. However, EEG signals suffer from perturbations caused by non-cerebral artifacts limiting their efficacy. Current artifact detection pipelines are resource-hungry and rely heavily on hand-crafted features. Moreover, these pipelines are deterministic in nature, making them unable to capture predictive uncertainty. We propose E4G, a deep learning framework for high frequency EEG artifact detection. Our framework exploits the early exit paradigm, building an implicit ensemble of models capable of capturing uncertainty. We evaluate our approach on the Temple University Hospital EEG Artifact Corpus (v2.0) achieving state-of-the-art classification results. In addition, E4G provides well-calibrated uncertainty metrics comparable to sampling techniques like Monte Carlo dropout in just a single forward pass. E4G opens the door to uncertainty-aware artifact detection supporting clinicians-in-the-loop frameworks.      
### 7.Multi-modal Residual Perceptron Network for Audio-Video Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.10742.pdf)
>  Emotion recognition is an important research field for Human-Computer Interaction(HCI). Audio-Video Emotion Recognition (AVER) is now attacked with Deep Neural Network (DNN) modeling tools. In published papers, as a rule, the authors show only cases of the superiority of multi modalities over audio-only or video-only modalities. However, there are cases superiority in single modality can be found. In our research, we hypothesize that for fuzzy categories of emotional events, the higher noise of one modality can amplify the lower noise of the second modality represented indirectly in the parameters of the modeling neural network. To avoid such cross-modal information interference we define a multi-modal Residual Perceptron Network (MRPN) which learns from multi-modal network branches creating deep feature representation with reduced noise. For the proposed MRPN model and the novel time augmentation for streamed digital movies, the state-of-art average recognition rate was improved to 91.4% for The Ryerson Audio-Visual Database of Emotional Speech and Song(RAVDESS) dataset and to 83.15% for Crowd-sourced Emotional multi-modal Actors Dataset(Crema-d). Moreover, the MRPN concept shows its potential for multi-modal classifiers dealing with signal sources not only of optical and acoustical type.      
### 8.Segmentation of Cardiac Structures via Successive Subspace Learning with Saab Transform from Cine MRI  [ :arrow_down: ](https://arxiv.org/pdf/2107.10718.pdf)
>  Assessment of cardiovascular disease (CVD) with cine magnetic resonance imaging (MRI) has been used to non-invasively evaluate detailed cardiac structure and function. Accurate segmentation of cardiac structures from cine MRI is a crucial step for early diagnosis and prognosis of CVD, and has been greatly improved with convolutional neural networks (CNN). There, however, are a number of limitations identified in CNN models, such as limited interpretability and high complexity, thus limiting their use in clinical practice. In this work, to address the limitations, we propose a lightweight and interpretable machine learning model, successive subspace learning with the subspace approximation with adjusted bias (Saab) transform, for accurate and efficient segmentation from cine MRI. Specifically, our segmentation framework is comprised of the following steps: (1) sequential expansion of near-to-far neighborhood at different resolutions; (2) channel-wise subspace approximation using the Saab transform for unsupervised dimension reduction; (3) class-wise entropy guided feature selection for supervised dimension reduction; (4) concatenation of features and pixel-wise classification with gradient boost; and (5) conditional random field for post-processing. Experimental results on the ACDC 2017 segmentation database, showed that our framework performed better than state-of-the-art U-Net models with 200$\times$ fewer parameters in delineating the left ventricle, right ventricle, and myocardium, thus showing its potential to be used in clinical practice.      
### 9.Project Achoo: A Practical Model and Application for COVID-19 Detection from Recordings of Breath, Voice, and Cough  [ :arrow_down: ](https://arxiv.org/pdf/2107.10716.pdf)
>  The COVID-19 pandemic created a significant interest and demand for infection detection and monitoring solutions. In this paper we propose a machine learning method to quickly triage COVID-19 using recordings made on consumer devices. The approach combines signal processing methods with fine-tuned deep learning networks and provides methods for signal denoising, cough detection and classification. We have also developed and deployed a mobile application that uses symptoms checker together with voice, breath and cough signals to detect COVID-19 infection. The application showed robust performance on both open sourced datasets and on the noisy data collected during beta testing by the end users.      
### 10.CarneliNet: Neural Mixture Model for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.10708.pdf)
>  End-to-end automatic speech recognition systems have achieved great accuracy by using deeper and deeper models. However, the increased depth comes with a larger receptive field that can negatively impact model performance in streaming scenarios. We propose an alternative approach that we call Neural Mixture Model. The basic idea is to introduce a parallel mixture of shallow networks instead of a very deep network. To validate this idea we design CarneliNet -- a CTC-based neural network composed of three mega-blocks. Each mega-block consists of multiple parallel shallow sub-networks based on 1D depthwise-separable convolutions. We evaluate the model on LibriSpeech, MLS and AISHELL-2 datasets and achieved close to state-of-the-art results for CTC-based models. Finally, we demonstrate that one can dynamically reconfigure the number of parallel sub-networks to accommodate the computational requirements without retraining.      
### 11.Multitask-Based Joint Learning Approach To Robust ASR For Radio Communication Speech  [ :arrow_down: ](https://arxiv.org/pdf/2107.10701.pdf)
>  To realize robust end-to-end Automatic Speech Recognition(E2E ASR) under radio communication condition, we propose a multitask-based method to joint train a Speech Enhancement (SE) module as the front-end and an E2E ASR model as the back-end in this paper. One of the advantage of the proposed method is that the entire system can be trained from scratch. Different from prior works, either component here doesn't need to perform pre-training and fine-tuning processes separately. Through analysis, we found that the success of the proposed method lies in the following aspects. Firstly, multitask learning is essential, that is the SE network is not only learning to produce more Intelligent speech, it is also aimed to generate speech that is beneficial to recognition. Secondly, we also found speech phase preserved from noisy speech is critical for improving ASR performance. Thirdly, we propose a dual channel data augmentation training method to obtain further improvement.Specifically, we combine the clean and enhanced speech to train the whole system. We evaluate the proposed method on the RATS English data set, achieving a relative WER reduction of 4.6% with the joint training method, and up to a relative WER reduction of 11.2% with the proposed data augmentation method.      
### 12.Leveraging PID Gain Selection Towards Adaptive Backstepping Control for a Class of Second-Order Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.10697.pdf)
>  In this work, we establish a convenient similarity between an adaptive backstepping control law and a standard proportional-integral-derivative (PID) controller for a class of second-order systems. The extracted similarity provides a deeper understanding of the adaptive backstepping design from a performance perspective via an intuitive method to select its otherwise abstract controller gains, on top of its traditional stability perspective. Such a similarity analysis opens the door for researchers to use well-established PID tuning methods to predict the performance of Lyapunov stability-based controllers. At the same time, the obtained formulation reveals how the corresponding PID control law can be linked to Lyapunov stability theory.      
### 13.A Tethered Quadrotor UAV$-$Buoy System for Marine Locomotion  [ :arrow_down: ](https://arxiv.org/pdf/2107.10690.pdf)
>  Unmanned aerial vehicles (UAVs) are finding their way into offshore applications. In this work, we postulate an original system that entails a marine locomotive quadrotor UAV that manipulates the velocity of a floating buoy by means of a cable. By leveraging the advantages of UAVs relative to high speed, maneuverability, ease of deployment, and wide field of vision, the proposed UAV$-$buoy system paves the way in front of a variety of novel applications. The dynamic model that couples the buoy, UAV, cable, and water environment is presented using the Euler-Lagrange method. A stable control system design is proposed to manipulate the forward-surge speed of the buoy under two constraints: maintaining the cable in a taut state, and keeping the buoy in contact with the water surface. Polar coordinates are used in the controller design process to attain correlated effects on the tracking performance, whereby each control channel independently affects one control parameter. This results in improved performance over traditional Cartesian-based velocity controllers, as demonstrated via numerical simulations in wave-free and wavy seas.      
### 14.CNN Classifier for Just-in-Time Woodpeckers Detection and Deterrent  [ :arrow_down: ](https://arxiv.org/pdf/2107.10676.pdf)
>  Woodpeckers can cause significant damage to homes, especially in suburban areas. There are a number of preventing and repelling methods including passive decoys, though these may only provide temporary relief. Subsequently, it may be more efficient to implement a woodpecker deterrent, such as motion, light, sound, or ultrasound that would be triggered by detection of woodpecker signature drumming. To detect the typical 25 Hz drumming frequency, sampling periods under 10 milliseconds with frequent FFTs are required with considerable computational costs. An in-hardware spectrum analyzer may avoid these costs by trading off frequency for time resolutions. The trained model converted to TF Lite Micro, ported to an MCU, and identifies a variety of the prerecorded woodpecker drumming. The plan is to integrate the prototype with a deterrent device making it a completely autonomous solution.      
### 15.Joint Range and Doppler Adaptive Processing for CBM based DFRC systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.10664.pdf)
>  Recently, dual-function radar communication (DFRC) systems have been proposed to integrate radar and communication into one platform for spectrum sharing. Various signalling strategies have been proposed to embed communication information into the radar transmitted waveforms. Among these, complex beampattern modulation (CBM) embeds communication information into the complex transmit beampattens via changing the amplitude and phase of the beampatterns towards the communication receiver. The embedding of random communication information causes the clutter modulation and high range-Doppler sidelobe. What's more, transmitting different waveforms on a pulse to pulse basis degrades the radar target detection capacity when traditional sequential pulse compression (SPC) and moving-target detection (MTD) is utilized. In this paper, a minimum mean square error (MMSE) based filter, denoted as joint range and Doppler adaptive processing (JRDAP) is proposed. The proposed method estimates the targets' impulse response coefficients at each range-Doppler cell adaptively to suppress high range-Doppler sidelobe and clutter modulation. The performance of proposed method is very close to the full-dimension adaptive multiple pulses compression (AMPC) while reducing computational complexity greatly.      
### 16.A Multimodal Deep Learning Model for Cardiac Resynchronisation Therapy Response Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2107.10662.pdf)
>  We present a novel multimodal deep learning framework for cardiac resynchronisation therapy (CRT) response prediction from 2D echocardiography and cardiac magnetic resonance (CMR) data. The proposed method first uses the `nnU-Net' segmentation model to extract segmentations of the heart over the full cardiac cycle from the two modalities. Next, a multimodal deep learning classifier is used for CRT response prediction, which combines the latent spaces of the segmentation models of the two modalities. At inference time, this framework can be used with 2D echocardiography data only, whilst taking advantage of the implicit relationship between CMR and echocardiography features learnt from the model. We evaluate our pipeline on a cohort of 50 CRT patients for whom paired echocardiography/CMR data were available, and results show that the proposed multimodal classifier results in a statistically significant improvement in accuracy compared to the baseline approach that uses only 2D echocardiography data. The combination of multimodal data enables CRT response to be predicted with 77.38% accuracy (83.33% sensitivity and 71.43% specificity), which is comparable with the current state-of-the-art in machine learning-based CRT response prediction. Our work represents the first multimodal deep learning approach for CRT response prediction.      
### 17.Digital Einstein Experience: Fast Text-to-Speech for Conversational AI  [ :arrow_down: ](https://arxiv.org/pdf/2107.10658.pdf)
>  We describe our approach to create and deliver a custom voice for a conversational AI use-case. More specifically, we provide a voice for a Digital Einstein character, to enable human-computer interaction within the digital conversation experience. To create the voice which fits the context well, we first design a voice character and we produce the recordings which correspond to the desired speech attributes. We then model the voice. Our solution utilizes Fastspeech 2 for log-scaled mel-spectrogram prediction from phonemes and Parallel WaveGAN to generate the waveforms. The system supports a character input and gives a speech waveform at the output. We use a custom dictionary for selected words to ensure their proper pronunciation. Our proposed cloud architecture enables for fast voice delivery, making it possible to talk to the digital version of Albert Einstein in real-time.      
### 18.A baseline model for computationally inexpensive speech recognition for Kazakh using the Coqui STT framework  [ :arrow_down: ](https://arxiv.org/pdf/2107.10637.pdf)
>  Mobile devices are transforming the way people interact with computers, and speech interfaces to applications are ever more important. Automatic Speech Recognition systems recently published are very accurate, but often require powerful machinery (specialised Graphical Processing Units) for inference, which makes them impractical to run on commodity devices, especially in streaming mode. Impressed by the accuracy of, but dissatisfied with the inference times of the baseline Kazakh ASR model of (Khassanov et al.,2021) when not using a GPU, we trained a new baseline acoustic model (on the same dataset as the aforementioned paper) and three language models for use with the Coqui STT framework. Results look promising, but further epochs of training and parameter sweeping or, alternatively, limiting the vocabulary that the ASR system must support, is needed to reach a production-level accuracy.      
### 19.Kramers-Kronig Receiver Combined With Digital Resolution Enhancer  [ :arrow_down: ](https://arxiv.org/pdf/2107.10626.pdf)
>  A Kramers-Kronig receiver with a continuous wave tone added digitally at the transmitter is combined with a digital resolution enhancer to limit the increase in transmitter quantization noise. Performance increase is demonstrated, as well as the ability to reduce the number of bits in the digital-to-analog converter.      
### 20.Application-driven Test and Evaluation Framework for Indoor Localization Systems in Warehouses  [ :arrow_down: ](https://arxiv.org/pdf/2107.10597.pdf)
>  Despite their potential of increasing operational efficiency, transparency, and safety, the use of Localization and Tracking Systems (LTSs) in warehouse environments remains seldom. One reason is the lack of market transparency and stakeholder's trust in the systems' performance as a consequence of poor use of Test and Evaluation (T&amp;E) methods and transferability of the obtained T&amp;E results. The T&amp;E 4Log (Test and Evaluation for Logistics) Framework was developed to examine how the transferability of T&amp;E results to practical scenarios in warehouse environments can be increased. Conventional T&amp;E approaches are integrated and extended under consideration of the warehouse environment, logistics applications, and domain-specific requirements, into an application-driven T&amp;E framework. The application of the proposed framework in standard and application-dependent test cases leads to a set of performance criteria and corresponding application-specific requirements. This enables a well-founded identification of suitable LTSs for given warehouse applications. The T&amp;E 4Log Framework was implemented at the Institute for Technical Logistics (ITL) and validated by T&amp;E of a reflector-based Light Detection and Ranging (LiDAR) LTS, a contour-based LiDAR LTS, and an Ultra-Wideband (UWB) LTS for the exemplary applications Automated Pallet Booking, Goods Tracking, and Autonomous Forklift Navigation.      
### 21.UAV-aided Radio Map Construction for Wireless Communications and Localization  [ :arrow_down: ](https://arxiv.org/pdf/2107.10574.pdf)
>  Radio maps can be used for source localization, link performance prediction, and wireless relay planning. This paper constructs an air-to-ground radio map to predict the channel gain for each link that connects a ground terminal with a low altitude unmanned aerial vehicle (UAV). The challenge is the insufficiency of measurement samples for a radio map in full dimension, where each data point is 6-dimensional as the transmitter and the receiver each has three spatial degrees of freedom. Classical methods, such as k-nearest neighbor (KNN) and Kriging, may fail for insufficient data. This paper proposes to exploit the propagation property in the geometry of the environment to assist the radio map construction. Specifically, the radio map is built via reconstructing a virtual geometry environment. A multi-class virtual obstacle model embedded in a multi-degree channel model is developed, and a least squares problem is formulated to learn the virtual obstacle map and the model parameters. The paper investigates the partial quasiconvexity of the least squares problem, and based on that, an efficient radio map learning algorithm is developed. In addition, a data driven approach is employed to build a residual shadowing map to further improve the details of the constructed radio map. Our numerical results confirm that the proposed method significantly increases the prediction accuracy compared to a Kriging baseline, and reduces the required measurements by more than a half. When the constructed radio map is applied to received signal strength (RSS) based localization in a dense urban environment, substantial performance improvement is observed where a sub-20-meter accuracy is achieved.      
### 22.Fristograms: Revealing and Exploiting Light Field Internals  [ :arrow_down: ](https://arxiv.org/pdf/2107.10563.pdf)
>  In recent years, light field (LF) capture and processing has become an integral part of media production. The richness of information available in LFs has enabled novel applications like post-capture depth-of-field editing, 3D reconstruction, segmentation and matting, saliency detection, object detection and recognition, and mixed reality. The efficacy of such applications depends on certain underlying requirements, which are often ignored. For example, some operations such as noise-reduction, or hyperfan-filtering are only possible if a scene point Lambertian radiator. Some other operations such as the removal of obstacles or looking behind objects are only possible if there is at least one ray capturing the required scene point. Consequently, the ray distribution representing a certain scene point is an important characteristic for evaluating processing possibilities. The primary idea in this paper is to establish a relation between the capturing setup and the rays of the LF. To this end, we discretize the view frustum. Traditionally, a uniform discretization of the view frustum results in voxels that represents a single sample on a regularly spaced, 3-D grid. Instead, we use frustum-shaped voxels (froxels), by using depth and capturing-setup dependent discretization of the view frustum. Based on such discretization, we count the number of rays mapping to the same pixel on the capturing device(s). By means of this count, we propose histograms of ray-counts over the froxels (fristograms). Fristograms can be used as a tool to analyze and reveal interesting aspects of the underlying LF, like the number of rays originating from a scene point and the color distribution of these rays. As an example, we show its ability by significantly reducing the number of rays which enables noise reduction while maintaining the realistic rendering of non-Lambertian or partially occluded regions.      
### 23.Controlling the Perceived Sound Quality for Dialogue Enhancement with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.10562.pdf)
>  Speech enhancement attenuates interfering sounds in speech signals but may introduce artifacts that perceivably deteriorate the output signal. We propose a method for controlling the trade-off between the attenuation of the interfering background signal and the loss of sound quality. A deep neural network estimates the attenuation of the separated background signal such that the sound quality, quantified using the Artifact-related Perceptual Score, meets an adjustable target. Subjective evaluations indicate that consistent sound quality is obtained across various input signals. Our experiments show that the proposed method is able to control the trade-off with an accuracy that is adequate for real-world dialogue enhancement applications.      
### 24.A Sensor Fusion-based Cutting Device Attitude Control to Improve the Accuracy of Korean Cabbage Harvesting  [ :arrow_down: ](https://arxiv.org/pdf/2107.10513.pdf)
>  Korean cabbage harvesting lacks mechanization and depends on human power; thus, conducting research on Korean cabbage harvesters is of immense importance. Although these harvesters have been developed in various forms, they have not yet attained commercialization. Most Korean cabbage fields have slopes; thus there are several challenges, that can prevent accurate harvesting. Therefore, to address these challenges at the site, we adopt two cylinders in this study, develop a mechanism that enables attitude control of the cutting device, not driving platform body, to cope with slopes. By maintaining the level, angle, height of cutting, we can reduce loss and improve harvest performance. It is difficult to find examples where these mechanisms have been applied. For basic research, sensor fusion has been carried out based on the Kalman filter, which is commonly utilized for attitude control. The hydraulic cylinder was controlled using the data obtained for maintaining the attitude. Furthermore, field tests were conducted to validate this system, and the root mean square error (RMSE) was obtained and verified to quantitatively assess the presence or absence of attitude control. Therefore, the purpose of this study is to suggest a development direction for Korean cabbage harvesters via the proposed attitude control system.      
### 25.A Deep Learning-based Quality Assessment and Segmentation System with a Large-scale Benchmark Dataset for Optical Coherence Tomographic Angiography Image  [ :arrow_down: ](https://arxiv.org/pdf/2107.10476.pdf)
>  Optical Coherence Tomography Angiography (OCTA) is a non-invasive and non-contacting imaging technique providing visualization of microvasculature of retina and optic nerve head in human eyes in vivo. The adequate image quality of OCTA is the prerequisite for the subsequent quantification of retinal microvasculature. Traditionally, the image quality score based on signal strength is used for discriminating low quality. However, it is insufficient for identifying artefacts such as motion and off-centration, which rely specialized knowledge and need tedious and time-consuming manual identification. One of the most primary issues in OCTA analysis is to sort out the foveal avascular zone (FAZ) region in the retina, which highly correlates with any visual acuity disease. However, the variations in OCTA visual quality affect the performance of deep learning in any downstream marginally. Moreover, filtering the low-quality OCTA images out is both labor-intensive and time-consuming. To address these issues, we develop an automated computer-aided OCTA image processing system using deep neural networks as the classifier and segmentor to help ophthalmologists in clinical diagnosis and research. This system can be an assistive tool as it can process OCTA images of different formats to assess the quality and segment the FAZ area. The source code is freely available at <a class="link-external link-https" href="https://github.com/shanzha09/COIPS.git" rel="external noopener nofollow">this https URL</a>. <br>Another major contribution is the large-scale OCTA dataset, namely OCTA-25K-IQA-SEG we publicize for performance evaluation. It is comprised of four subsets, namely sOCTA-3$\times$3-10k, sOCTA-6$\times$6-14k, sOCTA-3$\times$3-1.1k-seg, and dOCTA-6$\times$6-1.1k-seg, which contains a total number of 25,665 images. The large-scale OCTA dataset is available at <a class="link-external link-https" href="https://doi.org/10.5281/zenodo.5111975" rel="external noopener nofollow">this https URL</a>, <a class="link-external link-https" href="https://doi.org/10.5281/zenodo.5111972" rel="external noopener nofollow">this https URL</a>.      
### 26.Improving Polyphonic Sound Event Detection on Multichannel Recordings with the Sørensen-Dice Coefficient Loss and Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.10471.pdf)
>  The Sørensen--Dice Coefficient has recently seen rising popularity as a loss function (also known as Dice loss) due to its robustness in tasks where the number of negative samples significantly exceeds that of positive samples, such as semantic segmentation, natural language processing, and sound event detection. Conventional training of polyphonic sound event detection systems with binary cross-entropy loss often results in suboptimal detection performance as the training is often overwhelmed by updates from negative samples. In this paper, we investigated the effect of the Dice loss, intra- and inter-modal transfer learning, data augmentation, and recording formats, on the performance of polyphonic sound event detection systems with multichannel inputs. Our analysis showed that polyphonic sound event detection systems trained with Dice loss consistently outperformed those trained with cross-entropy loss across different training settings and recording formats in terms of F1 score and error rate. We achieved further performance gains via the use of transfer learning and an appropriate combination of different data augmentation techniques.      
### 27.What Makes Sound Event Localization and Detection Difficult? Insights from Error Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2107.10469.pdf)
>  Sound event localization and detection (SELD) is an emerging research topic that aims to unify the tasks of sound event detection and direction-of-arrival estimation. As a result, SELD inherits the challenges of both tasks, such as noise, reverberation, interference, polyphony, and non-stationarity of sound sources. Furthermore, SELD often faces an additional challenge of assigning correct correspondences between the detected sound classes and directions of arrival to multiple overlapping sound events. Previous studies have shown that unknown interferences in reverberant environments often cause major degradation in the performance of SELD systems. To further understand the challenges of the SELD task, we performed a detailed error analysis on two of our SELD systems, which both ranked second in the team category of DCASE SELD Challenge, one in 2020 and one in 2021. Experimental results indicate polyphony as the main challenge in SELD, due to the difficulty in detecting all sound events of interest. In addition, the SELD systems tend to make fewer errors for the polyphonic scenario that is dominant in the training set.      
### 28.A Two-Part Controller Synthesis Approach for Nonlinear Stochastic Systems Perturbed by Lévy Noise Using Renewal Theory and HJB-Based Impulse Control  [ :arrow_down: ](https://arxiv.org/pdf/2107.10441.pdf)
>  We are motivated by the lack of discussion surrounding methodological control design procedures for nonlinear shot and Lévy noise stochastic systems to propose a hierarchical controller synthesis method with two parts. The first part is a primitive pattern-learning component which recognizes specific state sequences and stores in memory the corresponding control action that needs to be taken when the sequence has occurred. The second part is a modulation control component which computes the optimal control action for a pattern when it has occurred for the first time. Throughout our presentation of both components, we provide a self-contained discussion of theoretical concepts from Poisson processes theory, renewal theory, and impulse control, all of which are necessary as background. We demonstrate application of this controller to the simplified, concrete case studies of fault-tolerance and vehicle congestion control.      
### 29.Investigating Shift-Variance of Convolutional Neural Networks in Ultrasound Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.10431.pdf)
>  While accuracy is an evident criterion for ultrasound image segmentation, output consistency across different tests is equally crucial for tracking changes in regions of interest in applications such as monitoring the patients' response to treatment, measuring the progression or regression of the disease, reaching a diagnosis, or treatment planning. Convolutional neural networks (CNNs) have attracted rapidly growing interest in automatic ultrasound image segmentation recently. However, CNNs are not shift-equivariant, meaning that if the input translates, e.g., in the lateral direction by one pixel, the output segmentation may drastically change. To the best of our knowledge, this problem has not been studied in ultrasound image segmentation or even more broadly in ultrasound images. Herein, we investigate and quantify the shift-variance problem of CNNs in this application and further evaluate the performance of a recently published technique, called BlurPooling, for addressing the problem. In addition, we propose the Pyramidal BlurPooling method that outperforms BlurPooling in both output consistency and segmentation accuracy. Finally, we demonstrate that data augmentation is not a replacement for the proposed method. Source code is available at <a class="link-external link-https" href="https://git.io/pbpunet" rel="external noopener nofollow">this https URL</a> and <a class="link-external link-http" href="http://code.sonography.ai" rel="external noopener nofollow">this http URL</a>.      
### 30.Wideband photonic interference cancellation based on free space optical communication  [ :arrow_down: ](https://arxiv.org/pdf/2107.10415.pdf)
>  We propose and experimentally demonstrate an interference management system that removes wideband wireless interference by using photonic signal processing and free space optical communication. The receiver separates radio frequency interferences by upconverting the mixed signals to optical frequencies and processing the signals with the photonic circuits. Signals with GHz bandwidth are processed and separated in real-time. The reference signals for interference cancellation are transmitted in a free space optical communication link, which provides large bandwidth for multi-band operation and accelerates the mixed signal separation process by reducing the dimensions of the un-known mixing matrix. Experimental results show that the system achieves 30dB real-time cancellation depth with over 6GHz bandwidth. Multiple radio frequency bands can be processed at the same time with a single system. In addition, multiple radio frequency bands can be processed at the same time with a single system.      
### 31.Online-Learning Deep Neuro-Adaptive Dynamic Inversion Controller for Model Free Control  [ :arrow_down: ](https://arxiv.org/pdf/2107.10383.pdf)
>  Adaptive methods are popular within the control literature due to the flexibility and forgiveness they offer in the area of modelling. Neural network adaptive control is favorable specifically for the powerful nature of the machine learning algorithm to approximate unknown functions and for the ability to relax certain constraints within traditional adaptive control. Deep neural networks are large framework networks with vastly superior approximation characteristics than their shallow counterparts. However, implementing a deep neural network can be difficult due to size specific complications such as vanishing/exploding gradients in training. In this paper, a neuro-adaptive controller is implemented featuring a deep neural network trained on a new weight update law that escapes the vanishing/exploding gradient problem by only incorporating the sign of the gradient. The type of controller designed is an adaptive dynamic inversion controller utilizing a modified state observer in a secondary estimation loop to train the network. The deep neural network learns the entire plant model on-line, creating a controller that is completely model free. The controller design is tested in simulation on a 2 link planar robot arm. The controller is able to learn the nonlinear plant quickly and displays good performance in the tracking control problem.      
### 32.Speed Advisory System Using Real-Time Actuated Traffic Light Phase Length Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2107.10372.pdf)
>  Speed advisory systems for connected vehicles rely on the estimation of green (or red) light duration at signalized intersections. A particular challenge is to predict the signal phases of semi- and fully-actuated traffic lights. In this paper, we introduce an algorithm that processes traffic measurement data collected from advanced detectors on road links and assigns "PASS"/"WAIT" labels to connected vehicles according to their predicted ability to go through the upcoming signalized intersection within the current phase. Additional computations provide an estimate for the duration of the current green phase that can be used by the Speed Advisory System to minimize fuel consumption. Simulation results show 95% prediction accuracy, which yields up to 30% reduction in fuel consumption when used in a driver-assistance system. Traffic progression quality also benefits from our algorithm demonstrating an improvement of 20% at peak for medium traffic demand, reducing delays and idling at intersections.      
### 33.Wideband photonic blind source separation with optical pulse sampling  [ :arrow_down: ](https://arxiv.org/pdf/2107.10357.pdf)
>  We propose and experimentally demonstrate an optical pulse sampling method for photonic blind source separation. The photonic system processes and separates wideband signals based on the statistical information of the mixed signals and thus the sampling frequency can be orders of magnitude lower than the bandwidth of the signals. The ultra-fast optical pulse functions as a tweezer that collects samples of the signals at very low sampling rates, and each sample is short enough to maintain the statistical properties of the signals. The low sampling frequency reduces the workloads of the analog to digital conversion and digital signal processing systems. In the meantime, the short pulse sampling maintains the accuracy of the sampled signals, so the statistical properties of the undersampling signals are the same as the statistical properties of the original signals. With the optical pulses generated from a mode-locked laser, the optical pulse sampling system is able to process and separate mixed signals with bandwidth over 100GHz and achieves a dynamic range of 30dB.      
### 34.Dynamic Realtime z-Shimming: A Feasibility Study  [ :arrow_down: ](https://arxiv.org/pdf/2107.10331.pdf)
>  Respiration causes time-varying frequency offsets that can result in ghosting artifacts. We propose a solution, which we term dynamic realtime z-shimming, wherein linear gradients are adjusted dynamically (slice-wise) and in real-time, to reflect magnetic field inhomogeneities that arise during image acquisition. In dynamic z-shimming, a method that is commonly used to reduce static frequency offsets in MR images of the spinal cord and brain, in-plane (static) frequency offsets are assumed to be homogeneous. Here we investigate whether or not that same assumption can be made for time-varying frequency offsets in the cervical spinal cord region. In order to explore the feasibility of dynamic realtime z-shimming, we acquired images using a pneumatic phantom setup, as well as in-vivo. We then simulated the effects of time-varying frequency offsets on MR images acquired with and without dynamic realtime z-shimming in different scenarios. We found that dynamic realtime z-shimming can reduce ghosting if the time-varying frequency offsets have an in-plane variability (standard deviation) of approximately less than 1 Hz. This scenario was achieved in our phantom setup, where we observed a 50.2% reduction in ghosting within multi-echo gradient echo images acquired with dynamic realtime z-shimming, compared to without. On the other hand, we observed that the in-plane variability of the time-varying frequency offsets is too high within the cervical spinal cord region for dynamic realtime z-shimming to be successful. These results can serve as a guideline and starting point for future dynamic realtime z-shimming experiments in which the in-plane variability of frequency offsets are minimized.      
### 35.mmPose-NLP: A Natural Language Processing Approach to Precise Skeletal Pose Estimation using mmWave Radars  [ :arrow_down: ](https://arxiv.org/pdf/2107.10327.pdf)
>  In this paper we presented mmPose-NLP, a novel Natural Language Processing (NLP) inspired Sequence-to-Sequence (Seq2Seq) skeletal key-point estimator using millimeter-wave (mmWave) radar data. To the best of the author's knowledge, this is the first method to precisely estimate upto 25 skeletal key-points using mmWave radar data alone. Skeletal pose estimation is critical in several applications ranging from autonomous vehicles, traffic monitoring, patient monitoring, gait analysis, to defense security forensics, and aid both preventative and actionable decision making. The use of mmWave radars for this task, over traditionally employed optical sensors, provide several advantages, primarily its operational robustness to scene lighting and adverse weather conditions, where optical sensor performance degrade significantly. The mmWave radar point-cloud (PCL) data is first voxelized (analogous to tokenization in NLP) and $N$ frames of the voxelized radar data (analogous to a text paragraph in NLP) is subjected to the proposed mmPose-NLP architecture, where the voxel indices of the 25 skeletal key-points (analogous to keyword extraction in NLP) are predicted. The voxel indices are converted back to real world 3-D coordinates using the voxel dictionary used during the tokenization process. Mean Absolute Error (MAE) metrics were used to measure the accuracy of the proposed system against the ground truth, with the proposed mmPose-NLP offering &lt;3 cm localization errors in the depth, horizontal and vertical axes. The effect of the number of input frames vs performance/accuracy was also studied for N = {1,2,..,10}. A comprehensive methodology, results, discussions and limitations are presented in this paper. All the source codes and results are made available on GitHub for furthering research and development in this critical yet emerging domain of skeletal key-point estimation using mmWave radars.      
### 36.Optimal Joint Beamforming and Power Control in Cell-Free Massive MIMO Downlink  [ :arrow_down: ](https://arxiv.org/pdf/2107.10749.pdf)
>  In this paper, a novel optimization model for joint beamforming and power control in the downlink (DL) of a cell-free massive MIMO (CFmMIMO) system is presented. The objective of the proposed optimization model is to minimize the maximum user interference while satisfying quality of service (QoS) constraints and power consumption limits. The proposed min-max optimization model is formulated as a mixed-integer nonlinear program, that is directly tractable. Numerical results show that the proposed joint beamforming and power control scheme is effective and outperforms competing schemes in terms of data rate, power consumption, and energy efficiency.      
### 37.Cell-free Massive MIMO with Short Packets  [ :arrow_down: ](https://arxiv.org/pdf/2107.10707.pdf)
>  In this paper, we adapt to cell-free Massive MIMO (multiple-input multiple-output) the finite-blocklength framework introduced by Östman et al. (2020) for the characterization of the packet error probability achievable with Massive MIMO, in the ultra-reliable low-latency communications (URLLC) regime. The framework considered in this paper encompasses a cell-free architecture with imperfect channel-state information, and arbitrary linear signal processing performed at a central-processing unit connected to the access points via fronthaul links. By means of numerical simulations, we show that, to achieve the high reliability requirements in URLLC, MMSE signal processing must be used. Comparisons are also made with both small-cell and Massive MIMO cellular networks. Both require a much larger number of antennas to achieve comparable performance to cell-free Massive MIMO.      
### 38.Recognizing three-dimensional phase images with deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.10584.pdf)
>  Optical phase contains key information for biomedical and astronomical imaging. However, it is often obscured by layers of heterogeneous and scattering media, which render optical phase imaging at different depths an utmost challenge. Limited by the memory effect, current methods for phase imaging in strong scattering media are inapplicable to retrieving phases at different depths. To address this challenge, we developed a speckle three-dimensional reconstruction network (STRN) to recognize phase objects behind scattering media, which circumvents the limitations of memory effect. From the single-shot, reference-free and scanning-free speckle pattern input, STRN distinguishes depth-resolving quantitative phase information with high fidelity. Our results promise broad applications in biomedical tomography and endoscopy.      
### 39.Robust low-rank covariance matrix estimation with a general pattern of missing values  [ :arrow_down: ](https://arxiv.org/pdf/2107.10505.pdf)
>  This paper tackles the problem of robust covariance matrix estimation when the data is incomplete. Classical statistical estimation methodologies are usually built upon the Gaussian assumption, whereas existing robust estimation ones assume unstructured signal models. The former can be inaccurate in real-world data sets in which heterogeneity causes heavy-tail distributions, while the latter does not profit from the usual low-rank structure of the signal. Taking advantage of both worlds, a covariance matrix estimation procedure is designed on a robust (compound Gaussian) low-rank model by leveraging the observed-data likelihood function within an expectation-maximization algorithm. It is also designed to handle general pattern of missing values. The proposed procedure is first validated on simulated data sets. Then, its interest for classification and clustering applications is assessed on two real data sets with missing values, which include multispectral and hyperspectral time series.      
### 40.CURE: Enabling RF Energy Harvesting using Cell-Free Massive MIMO UAVs Assisted by RIS  [ :arrow_down: ](https://arxiv.org/pdf/2107.10412.pdf)
>  The ever-evolving internet of things (IoT) has led to the growth of numerous wireless sensors, communicating through the internet infrastructure. When designing a network using these sensors, one critical aspect is the longevity and self-sustainability of these devices. For extending the lifetime of these sensors, radio frequency energy harvesting (RFEH) technology has proved to be promising. In this paper, we propose CURE, a novel framework for RFEH that effectively combines the benefits of cell-free massive MIMO (CFmMIMO), unmanned aerial vehicles (UAVs), and reconfigurable intelligent surfaces (RISs) to provide seamless energy harvesting to IoT devices. We consider UAV as an access point (AP) in the CFmMIMO framework. To enhance the signal strength of the RFEH and information transfer, we leverage RISs owing to their passive reflection capability. Based on an extensive simulation, we validate our framework's performance by comparing the max-min fairness (MMF) algorithm for the amount of harvested energy.      
### 41.Distributed Asynchronous Policy Iteration for Sequential Zero-Sum Games and Minimax Control  [ :arrow_down: ](https://arxiv.org/pdf/2107.10406.pdf)
>  We introduce a contractive abstract dynamic programming framework and related policy iteration algorithms, specifically designed for sequential zero-sum games and minimax problems with a general structure. Aside from greater generality, the advantage of our algorithms over alternatives is that they resolve some long-standing convergence difficulties of the ``natural" policy iteration algorithm, which have been known since the Pollatschek and Avi-Itzhak method [PoA69] for finite-state Markov games. Mathematically, this ``natural" algorithm is a form of Newton's method for solving Bellman's equation, but Newton's method, contrary to the case of single-player DP problems, is not globally convergent in the case of a minimax problem, because the Bellman operator may have components that are neither convex nor concave. Our algorithms address this difficulty by introducing alternating player choices, and by using a policy-dependent mapping with a uniform sup-norm contraction property, similar to earlier works by Bertsekas and Yu [BeY10], [BeY12], [YuB13]. Moreover, our algorithms allow a convergent and highly parallelizable implementation, which is based on state space partitioning, and distributed asynchronous policy evaluation and policy improvement operations within each set of the partition. Our framework is also suitable for the use of reinforcement learning methods based on aggregation, which may be useful for large-scale problem instances.      
### 42.StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for Natural-Sounding Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2107.10394.pdf)
>  We present an unsupervised non-parallel many-to-many voice conversion (VC) method using a generative adversarial network (GAN) called StarGAN v2. Using a combination of adversarial source classifier loss and perceptual loss, our model significantly outperforms previous VC models. Although our model is trained only with 20 English speakers, it generalizes to a variety of voice conversion tasks, such as any-to-many, cross-lingual, and singing conversion. Using a style encoder, our framework can also convert plain reading speech into stylistic speech, such as emotional and falsetto speech. Subjective and objective evaluation experiments on a non-parallel many-to-many voice conversion task revealed that our model produces natural sounding voices, close to the sound quality of state-of-the-art text-to-speech (TTS) based voice conversion methods without the need for text labels. Moreover, our model is completely convolutional and with a faster-than-real-time vocoder such as Parallel WaveGAN can perform real-time voice conversion.      
### 43.JS Fake Chorales: a Synthetic Dataset of Polyphonic Music with Human Annotation  [ :arrow_down: ](https://arxiv.org/pdf/2107.10388.pdf)
>  High quality datasets for learning-based modelling of polyphonic symbolic music remain less readily-accessible at scale than in other domains, such as language modelling or image classification. In particular, datasets which contain information revealing insights about human responses to the given music samples are rare. The issue of scale persists as a general hindrance towards breakthroughs in the field, while the lack of listener evaluation is especially relevant to the generative modelling problem-space, where clear objective metrics correlating strongly with qualitative success remain elusive. <br>We propose the JS Fake Chorales, a dataset of 500 pieces generated by a new learning-based algorithm, provided in MIDI form. We take consecutive outputs from the algorithm and avoid cherry-picking in order to validate the potential to further scale this dataset on-demand. We conduct an online experiment for human evaluation, designed to be as fair to the listener as possible, and find that respondents were on average only 7\% better than random guessing at distinguishing JS Fake Chorales from real chorales composed by JS Bach. Furthermore, we make anonymised data collected from experiments available along with the MIDI samples, such as the respondents' musical experience and how long they took to submit their response for each sample. Finally, we conduct ablation studies to demonstrate the effectiveness of using the synthetic pieces for research in polyphonic music modelling, and find that we can improve on state-of-the-art validation set loss for the canonical JSB Chorales dataset, using a known algorithm, by simply augmenting the training set with the JS Fake Chorales.      
### 44.Reading Race: AI Recognises Patient's Racial Identity In Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.10356.pdf)
>  Background: In medical imaging, prior studies have demonstrated disparate AI performance by race, yet there is no known correlation for race on medical imaging that would be obvious to the human expert interpreting the images. <br>Methods: Using private and public datasets we evaluate: A) performance quantification of deep learning models to detect race from medical images, including the ability of these models to generalize to external environments and across multiple imaging modalities, B) assessment of possible confounding anatomic and phenotype population features, such as disease distribution and body habitus as predictors of race, and C) investigation into the underlying mechanism by which AI models can recognize race. <br>Findings: Standard deep learning models can be trained to predict race from medical images with high performance across multiple imaging modalities. Our findings hold under external validation conditions, as well as when models are optimized to perform clinically motivated tasks. We demonstrate this detection is not due to trivial proxies or imaging-related surrogate covariates for race, such as underlying disease distribution. Finally, we show that performance persists over all anatomical regions and frequency spectrum of the images suggesting that mitigation efforts will be challenging and demand further study. <br>Interpretation: We emphasize that model ability to predict self-reported race is itself not the issue of importance. However, our findings that AI can trivially predict self-reported race -- even from corrupted, cropped, and noised medical images -- in a setting where clinical experts cannot, creates an enormous risk for all model deployments in medical imaging: if an AI model secretly used its knowledge of self-reported race to misclassify all Black patients, radiologists would not be able to tell using the same data the model has access to.      
### 45.Uncertainty-Aware Task Allocation for Distributed Autonomous Robots  [ :arrow_down: ](https://arxiv.org/pdf/2107.10350.pdf)
>  This paper addresses task-allocation problems with uncertainty in situational awareness for distributed autonomous robots (DARs). The uncertainty propagation over a task-allocation process is done by using the Unscented transform that uses the Sigma-Point sampling mechanism. It has great potential to be employed for generic task-allocation schemes, in the sense that there is no need to modify an existing task-allocation method that has been developed without considering the uncertainty in the situational awareness. The proposed framework was tested in a simulated environment where the decision-maker needs to determine an optimal allocation of multiple locations assigned to multiple mobile flying robots whose locations come as random variables of known mean and covariance. The simulation result shows that the proposed stochastic task allocation approach generates an assignment with 30% less overall cost than the one without considering the uncertainty.      
### 46.iReason: Multimodal Commonsense Reasoning using Videos and Natural Language with Interpretability  [ :arrow_down: ](https://arxiv.org/pdf/2107.10300.pdf)
>  Causality knowledge is vital to building robust AI systems. Deep learning models often perform poorly on tasks that require causal reasoning, which is often derived using some form of commonsense knowledge not immediately available in the input but implicitly inferred by humans. Prior work has unraveled spurious observational biases that models fall prey to in the absence of causality. While language representation models preserve contextual knowledge within learned embeddings, they do not factor in causal relationships during training. By blending causal relationships with the input features to an existing model that performs visual cognition tasks (such as scene understanding, video captioning, video question-answering, etc.), better performance can be achieved owing to the insight causal relationships bring about. Recently, several models have been proposed that have tackled the task of mining causal data from either the visual or textual modality. However, there does not exist widespread research that mines causal relationships by juxtaposing the visual and language modalities. While images offer a rich and easy-to-process resource for us to mine causality knowledge from, videos are denser and consist of naturally time-ordered events. Also, textual information offers details that could be implicit in videos. We propose iReason, a framework that infers visual-semantic commonsense knowledge using both videos and natural language captions. Furthermore, iReason's architecture integrates a causal rationalization module to aid the process of interpretability, error analysis and bias detection. We demonstrate the effectiveness of iReason using a two-pronged comparative analysis with language representation learning models (BERT, GPT-2) as well as current state-of-the-art multimodal causality models.      
### 47.Rethinking Trajectory Forecasting Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2107.10297.pdf)
>  Forecasting the behavior of other agents is an integral part of the modern robotic autonomy stack, especially in safety-critical scenarios with human-robot interaction, such as autonomous driving. In turn, there has been a significant amount of interest and research in trajectory forecasting, resulting in a wide variety of approaches. Common to all works, however, is the use of the same few accuracy-based evaluation metrics, e.g., displacement error and log-likelihood. While these metrics are informative, they are task-agnostic and predictions that are evaluated as equal can lead to vastly different outcomes, e.g., in downstream planning and decision making. In this work, we take a step back and critically evaluate current trajectory forecasting metrics, proposing task-aware metrics as a better measure of performance in systems where prediction is being deployed. We additionally present one example of such a metric, incorporating planning-awareness within existing trajectory forecasting metrics.      
### 48.Cell-Free SUCRe Protocol: A User-Centric Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2107.10294.pdf)
>  The motivation of this paper is to introduce a cell-free adaptation of the strongest-user collision resolution (SUCRe) protocol originally proposed for cellular massive multiple-input multiple-output (MIMO) networks. Our goal with this adaptation is to show that a cell-free network can better handle the access attempts of users' equipment (UEs) due to the augmented macro-diversity brought by the disposition of access points (APs) over the coverage area. Moreover, we aim to introduce a cell-free version of the protocol that follows the so-called user-centric perspective, meaning that the protocol is scalable from the point of view of computational complexity and the increase in the number of antennas and UEs in the system.      
### 49.Predicting Power Electronics Device Reliability under Extreme Conditions with Machine Learning Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2107.10292.pdf)
>  Power device reliability is a major concern during operation under extreme environments, as doing so reduces the operational lifetime of any power system or sensing infrastructure. Due to a potential for system failure, devices must be experimentally validated before implementation, which is expensive and time-consuming. In this paper, we have utilized machine learning algorithms to predict device reliability, significantly reducing the need for conducting experiments. To train the models, we have tested 224 power devices from 10 different manufacturers. First, we describe a method to process the data for modeling purposes. Based on the in-house testing data, we implemented various ML models and observed that computational models such as Gradient Boosting and LSTM encoder-decoder networks can predict power device failure with high accuracy.      
### 50.Multiple Sensor Interface by the same hardware to USB and serial connection  [ :arrow_down: ](https://arxiv.org/pdf/2107.10258.pdf)
>  The Multiple Sensor Interface is a simplistic sensor interface to USB, RS485, GPIO, that allows to make measurements of a variety of sensors based on the variation of inductance, resistance, capacitance, frequency using exactly the same connector and same electronic interface circuit between the sensor and the microcontroler. The same device also provides some additional connectors for small voltage measurement. Any sensors for the measurement of distinct phenomena can be used as long the sensor output is based on inductance, resistance, capacitance, frequency within the measurement range of the device, obtaining a variable precision depending of used sensor. The device is not meant for precision/accuracy measurement, is meant to be a reusable hardware that can be reused for most distinct situations, providing to the user more freedom of sensor selection as well more options for device/system maintenance or reuse.      
