# ArXiv eess --Fri, 16 Jul 2021
### 1.VAD-free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording  [ :arrow_down: ](https://arxiv.org/pdf/2107.07509.pdf)
>  In this work, we propose novel decoding algorithms to enable streaming automatic speech recognition (ASR) on unsegmented long-form recordings without voice activity detection (VAD), based on monotonic chunkwise attention (MoChA) with an auxiliary connectionist temporal classification (CTC) objective. We propose a block-synchronous beam search decoding to take advantage of efficient batched output-synchronous and low-latency input-synchronous searches. We also propose a VAD-free inference algorithm that leverages CTC probabilities to determine a suitable timing to reset the model states to tackle the vulnerability to long-form data. Experimental evaluations demonstrate that the block-synchronous decoding achieves comparable accuracy to the label-synchronous one. Moreover, the VAD-free inference can recognize long-form speech robustly for up to a few hours.      
### 2.Filtered Noise Shaping for Time Domain Room Impulse Response Estimation From Reverberant Speech  [ :arrow_down: ](https://arxiv.org/pdf/2107.07503.pdf)
>  Deep learning approaches have emerged that aim to transform an audio signal so that it sounds as if it was recorded in the same room as a reference recording, with applications both in audio post-production and augmented reality. In this work, we propose FiNS, a Filtered Noise Shaping network that directly estimates the time domain room impulse response (RIR) from reverberant speech. Our domain-inspired architecture features a time domain encoder and a filtered noise shaping decoder that models the RIR as a summation of decaying filtered noise signals, along with direct sound and early reflection components. Previous methods for acoustic matching utilize either large models to transform audio to match the target room or predict parameters for algorithmic reverberators. Instead, blind estimation of the RIR enables efficient and realistic transformation with a single convolution. An evaluation demonstrates our model not only synthesizes RIRs that match parameters of the target room, such as the $T_{60}$ and DRR, but also more accurately reproduces perceptual characteristics of the target room, as shown in a listening test when compared to deep learning baselines.      
### 3.A modular U-Net for automated segmentation of X-ray tomography images in composite materials  [ :arrow_down: ](https://arxiv.org/pdf/2107.07468.pdf)
>  X-ray Computed Tomography (XCT) techniques have evolved to a point that high-resolution data can be acquired so fast that classic segmentation methods are prohibitively cumbersome, demanding automated data pipelines capable of dealing with non-trivial 3D images. Deep learning has demonstrated success in many image processing tasks, including material science applications, showing a promising alternative for a humanfree segmentation pipeline. In this paper a modular interpretation of UNet (Modular U-Net) is proposed and trained to segment 3D tomography images of a three-phased glass fiber-reinforced Polyamide 66. We compare 2D and 3D versions of our model, finding that the former is slightly better than the latter. We observe that human-comparable results can be achievied even with only 10 annotated layers and using a shallow U-Net yields better results than a deeper one. As a consequence, Neural Network (NN) show indeed a promising venue to automate XCT data processing pipelines needing no human, adhoc intervention.      
### 4.Multiclass Permanent Magnets Superstructure for Indoor Localization using Artificial Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2107.07425.pdf)
>  Smartphones have become a popular tool for indoor localization and position estimation of users. Existing solutions mainly employ Wi-Fi, RFID, and magnetic sensing techniques to track movements in crowded venues. These are highly sensitive to magnetic clutters and depend on local ambient magnetic fields, which frequently degrades their performance. Also, these techniques often require pre-known mapping surveys of the area, or the presence of active beacons, which are not always available. We embed small-volume and large-moment magnets in pre-known locations and arrange them in specific geometric constellations that create magnetic superstructure patterns of supervised magnetic signatures. These signatures constitute an unambiguous magnetic environment with respect to the moving sensor carrier. The localization algorithm learns the unique patterns of the scattered magnets during training and detects them from the ongoing streaming of data during localization. Our contribution is twofold. First, we deploy passive permanent magnets that do not require a power supply, in contrast to active magnetic transmitters. Second, we perform localization based on smartphone motion rather than on static positioning of the magnetometer. In our previous study, we considered a single superstructure pattern. Here, we present an extended version of that algorithm for multi-superstructure localization, which covers a broader localization area of the user. Experimental results demonstrate localization accuracy of 95% with a mean localization error of less than 1m using artificial intelligence.      
### 5.Untrained DNN for Channel Estimation of RIS-Assisted Multi-User OFDM System with Hardware Impairments  [ :arrow_down: ](https://arxiv.org/pdf/2107.07423.pdf)
>  Reconfigurable intelligent surface (RIS) is an emerging technology for improving performance in fifth-generation (5G) and beyond networks. Practically channel estimation of RIS-assisted systems is challenging due to the passive nature of the RIS. The purpose of this paper is to introduce a deep learning-based, low complexity channel estimator for the RIS-assisted multi-user single-input-multiple-output (SIMO) orthogonal frequency division multiplexing (OFDM) system with hardware impairments. We propose an untrained deep neural network (DNN) based on the deep image prior (DIP) network to denoise the effective channel of the system obtained from the conventional pilot-based least-square (LS) estimation and acquire a more accurate estimation. We have shown that our proposed method has high performance in terms of accuracy and low complexity compared to conventional methods. Further, we have shown that the proposed estimator is robust to interference caused by the hardware impairments at the transceiver and RIS.      
### 6.Assign Hysteresis Parameter For Ericsson BTS Power Saving Algorithm Using Unsupervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.07412.pdf)
>  Gaza Strip suffers from a chronic electricity deficit that affects all industries including the telecommunication field, so there is a need to optimize and reduce power consumption of the telecommunication equipment. In this paper we propose a new model that helps GSM radio frequency engineers to choose the optimal value of hysteresis parameter for Ericsson BTS power saving algorithm which aims to switch OFF unused frequency channels, our model is based on unsupervised machine learning clustering K-means algorithm. By using our model with BTS power saving algorithm we reduce number of active TRX by 20.9%.      
### 7.Requisitos para um rádio digital interativo no Brasil e América Latina  [ :arrow_down: ](https://arxiv.org/pdf/2107.07408.pdf)
>  This article discusses the feasibility and requirements for using Ginga as the middleware of a Digital Radio System. Ginga was adopted by Brazil and several other countries in Latin America as the standard for interactivity in Digital TV (ISDB-T International). In this article the two digital radio standards being considered for adoption by Brazil are briefly presented, a discussion about the requirements for broadcast radio interactivity is presented, and finally a prototype of a Ginga interactive application for digital radio that was transmitted and received over the air using a digital radio standard is detailed.      
### 8.A Method for Detecting Abnormal Data of Network Nodes Based on Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.07407.pdf)
>  Abnormal data detection is an important step to ensure the accuracy and reliability of node data in wireless sensor networks. In this paper, a data classification method based on convolutional neural network is proposed to solve the problem of data anomaly detection in wireless sensor networks. First, Normal data and abnormal data generated after injection fault are normalized and mapped to gray image as input data of the convolutional neural network. Then, based on the classical convolution neural network, three new convolutional neural network models are designed by designing the parameters of the convolutional layer and the fully connected layer. This model solves the problem that the performance of traditional detection algorithm is easily affected by relevant threshold through self-learning data characteristics of convolution layer. The experimental results show that this method has better detection performance and higher reliability.      
### 9.Spectral Processing and Optimization of Static and Dynamic 3D Geometries  [ :arrow_down: ](https://arxiv.org/pdf/2107.07379.pdf)
>  Geometry processing of 3D objects is of primary interest in many areas of computer vision and graphics, including robot navigation, 3D object recognition, classification, feature extraction, etc. The recent introduction of cheap range sensors has created a great interest in many new areas, driving the need for developing efficient algorithms for 3D object processing. Previously, in order to capture a 3D object, expensive specialized sensors were used, such as lasers or dedicated range images, but now this limitation has changed. The current approaches of 3D object processing require a significant amount of manual intervention and they are still time-consuming making them unavailable for use in real-time applications. The aim of this thesis is to present algorithms, mainly inspired by the spectral analysis, subspace tracking, etc, that can be used and facilitate many areas of low-level 3D geometry processing (i.e., reconstruction, outliers removal, denoising, compression), pattern recognition tasks (i.e., significant features extraction) and high-level applications (i.e., registration and identification of 3D objects in partially scanned and cluttered scenes), taking into consideration different types of 3D models (i.e., static and dynamic point clouds, static and dynamic 3D meshes).      
### 10.FMNet: Latent Feature-wise Mapping Network for Cleaning up Noisy Micro-Doppler Spectrogram  [ :arrow_down: ](https://arxiv.org/pdf/2107.07312.pdf)
>  Micro-Doppler signatures contain considerable information about target dynamics. However, the radar sensing systems are easily affected by noisy surroundings, resulting in uninterpretable motion patterns on the micro-Doppler spectrogram. Meanwhile, radar returns often suffer from multipath, clutter and interference. These issues lead to difficulty in, for example motion feature extraction, activity classification using micro Doppler signatures ($\mu$-DS), etc. In this paper, we propose a latent feature-wise mapping strategy, called Feature Mapping Network (FMNet), to transform measured spectrograms so that they more closely resemble the output from a simulation under the same conditions. Based on measured spectrogram and the matched simulated data, our framework contains three parts: an Encoder which is used to extract latent representations/features, a Decoder outputs reconstructed spectrogram according to the latent features, and a Discriminator minimizes the distance of latent features of measured and simulated data. We demonstrate the FMNet with six activities data and two experimental scenarios, and final results show strong enhanced patterns and can keep actual motion information to the greatest extent. On the other hand, we also propose a novel idea which trains a classifier with only simulated data and predicts new measured samples after cleaning them up with the FMNet. From final classification results, we can see significant improvements.      
### 11.Panicle Counting in UAV Images For Estimating Flowering Time in Sorghum  [ :arrow_down: ](https://arxiv.org/pdf/2107.07308.pdf)
>  Flowering time (time to flower after planting) is important for estimating plant development and grain yield for many crops including sorghum. Flowering time of sorghum can be approximated by counting the number of panicles (clusters of grains on a branch) across multiple dates. Traditional manual methods for panicle counting are time-consuming and tedious. In this paper, we propose a method for estimating flowering time and rapidly counting panicles using RGB images acquired by an Unmanned Aerial Vehicle (UAV). We evaluate three different deep neural network structures for panicle counting and location. Experimental results demonstrate that our method is able to accurately detect panicles and estimate sorghum flowering time.      
### 12.Passivity-based Decentralized Control for Discrete-time Large-scale Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.07277.pdf)
>  Passivity theory has recently contributed to developing decentralized control schemes for large-scale systems. Many decentralized passivity-based control schemes are designed in continuous-time. It is well-known, however, that the passivity properties of continuous-time systems may be lost under discretization. In this work, we present a novel stabilizing decentralized control scheme by ensuring passivity for discrete-time systems directly and thus avoiding the issue of passivity preservation. The controller is synthesized by locally solving a semidefinite program offline for each subsystem in a decentralized fashion. This program comprises local conditions ensuring that the corresponding subsystem is locally passive. Passivity is ensured with respect to a local virtual output which is different from the local actual output. The program also comprises local conditions ensuring that the local passivity of all subsystems implies the asymptotic stability of the whole system. The performance of the proposed controller is evaluated on a case study in DC microgrids.      
### 13.Multi-Channel Auto-Encoders and a Novel Dataset for Learning Domain Invariant Representations of Histopathology Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.07271.pdf)
>  Domain shift is a problem commonly encountered when developing automated histopathology pipelines. The performance of machine learning models such as convolutional neural networks within automated histopathology pipelines is often diminished when applying them to novel data domains due to factors arising from differing staining and scanning protocols. The Dual-Channel Auto-Encoder (DCAE) model was previously shown to produce feature representations that are less sensitive to appearance variation introduced by different digital slide scanners. In this work, the Multi-Channel Auto-Encoder (MCAE) model is presented as an extension to DCAE which learns from more than two domains of data. Additionally, a synthetic dataset is generated using CycleGANs that contains aligned tissue images that have had their appearance synthetically modified. Experimental results show that the MCAE model produces feature representations that are less sensitive to inter-domain variations than the comparative StaNoSA method when tested on the novel synthetic data. Additionally, the MCAE and StaNoSA models are tested on a novel tissue classification task. The results of this experiment show the MCAE model out performs the StaNoSA model by 5 percentage-points in the f1-score. These results show that the MCAE model is able to generalise better to novel data and tasks than existing approaches by actively learning normalised feature representations.      
### 14.PHiLIP on the HiL: Automated Multi-platform OS Testing with External Reference Devices  [ :arrow_down: ](https://arxiv.org/pdf/2107.07255.pdf)
>  Developing an operating system (OS) for low-end embedded devices requires continuous adaptation to new hardware architectures and components, while serviceability of features needs to be assured for each individual platform under tight resource constraints. It is challenging to design a versatile and accurate heterogeneous test environment that is agile enough to cover a continuous evolution of the code base and platforms. This mission is even morehallenging when organized in an agile open-source community process with many contributors such as for the RIOT OS. Hardware in the Loop (HiL) testing and Continuous Integration (CI) are automatable approaches to verify functionality, prevent regressions, and improve the overall quality at development speed in large community projects. In this paper, we present PHiLIP (Primitive Hardware in the Loop Integration Product), an open-source external reference device together with tools that validate the system software while it controls hardware and interprets physical signals. Instead of focusing on a specific test setting, PHiLIP takes the approach of a tool-assisted agile HiL test process, designed for continuous evolution and deployment cycles. We explain its design, describe how it supports HiL tests, evaluate performance metrics, and report on practical experiences of employing PHiLIP in an automated CI test infrastructure. Our initial deployment comprises 22 unique platforms, each of which executes 98 peripheral tests every night. PHiLIP allows for easy extension of low-cost, adaptive testing infrastructures but serves testing techniques and tools to a much wider range of applications.      
### 15.Variable-Horizon Guidance for Autonomous Rendezvous and Docking to a Tumbling Target  [ :arrow_down: ](https://arxiv.org/pdf/2107.07254.pdf)
>  In this paper, the trajectory planning problem for autonomous rendezvous and docking between a controlled spacecraft and a tumbling target is addressed. The use of a variable planning horizon is proposed in order to construct an appropriate maneuver plan, within an optimization-based framework. The involved optimization problem is nonconvex and features nonlinear constraints. The main contribution is to show that such problem can be tackled effectively by solving a finite number of linear programs. To this aim, a specifically conceived horizon search algorithm is employed in combination with a polytopic constraint approximation technique. The resulting guidance scheme provides the ability to identify favourable docking configurations, by exploiting the time-varying nature of the optimization problem endpoint. Simulation results involving the capture of the nonoperational EnviSat spacecraft indicate that the method is able to generate optimal trajectories at a fraction of the computational cost incurred by a state-of-the-art nonlinear solver.      
### 16.Graph-Embedded Multi-Agent Learning for Smart Reconfigurable THz MIMO-NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.07198.pdf)
>  With the accelerated development of immersive applications and the explosive increment of internet-of-things (IoT) terminals, 6G would introduce terahertz (THz) massive multiple-input multiple-output non-orthogonal multiple access (MIMO-NOMA) technologies to meet the ultra-high-speed transmission and massive connectivity requirements. Nevertheless, the unreliability of THz transmissions and the extreme heterogeneity of device requirements pose critical challenges for practical applications. To address these challenges, we propose a novel smart reconfigurable THz MIMO-NOMA framework, which can realize customizable and intelligent communications by flexibly and coordinately reconfiguring hybrid beams through the cooperation between access points (APs) and reconfigurable intelligent surfaces (RISs). The optimization problem is formulated as a decentralized partially-observable Markov decision process (Dec-POMDP) to maximize the network energy efficiency, while guaranteeing the diversified users' performance, via a joint RIS element selection, coordinated discrete phase-shift control, and power allocation strategy. To solve the above non-convex, strongly coupled, and highly complex mixed integer nonlinear programming (MINLP) problem, we propose a novel multi-agent deep reinforcement learning (MADRL) algorithm, namely graph-embedded value-decomposition actor-critic (GE-VDAC), that embeds the interaction information of agents, and learns a locally optimal solution through a distributed policy. Numerical results demonstrate that the proposed algorithm achieves highly customized communications and outperforms traditional MADRL algorithms.      
### 17.Two-Stage Channel Estimation for Hybrid RIS Assisted MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.07193.pdf)
>  Reconfigurable intelligent surfaces (RISs) have been proposed as a key enabler to improve the coverage of the signals and mitigate the frequent blockages in millimeter wave (mmWave) multiple-input multiple-output (MIMO) communications. However, the channel state information (CSI) acquisition is one of the major challenges for the practical deployment of the RIS. The passive RIS without any baseband processing capabilities brings difficulty on the channel estimation (CE), since the individual channels or the cascaded one can be estimated only at base station (BS) via uplink training or mobile station (MS) via downlink training. In order to facilitate the CSI acquisition, we focus on the hybrid RIS architecture, where a small number of elements are active and able to receive and process the pilot signals at the RIS. The CE is performed in two stages by following the atomic norm minimization to recover the channel parameters, i.e., angles of departure (AoDs), angles of arrival (AoAs), and propagation path gains. Simulation results show that the proposed scheme can outperform the passive RIS CE under the same training overhead. Furthermore, we also study the theoretical performance limits in terms of mean square error (MSE) via Cramér-Rao lower bound (CRLB) analyses.      
### 18.Region-of-Interest Prioritised Sampling for Constrained Autonomous Exploration Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.07186.pdf)
>  Goal oriented autonomous operation of space rovers has been known to increase scientific output of a mission. In this work we present an algorithm, called the RoI Prioritised Sampling (RPS), that prioritises Region-of-Interests (RoIs) in an exploration scenario in order to utilise the limited resources of the imaging instrument on the rover effectively. This prioritisation is based on an estimator that evaluates the change in information content at consecutive spatial scales of the RoIs without calculating the finer scale reconstruction. The estimator, called the Refinement Indicator, is motivated and derived. Multiscale acquisition approaches, based on classical and multi-level compressed sensing, with respect to the single pixel camera architecture are discussed. The performance of the algorithm is verified on airborne sensor images and compared with the state-of-the-art multi-resolution reconstruction algorithms. At the considered sub-sampling rates the RPS is shown to better utilise the system resources for reconstructing the RoIs.      
### 19.Direct-drive ocean wave-powered batch reverse osmosis  [ :arrow_down: ](https://arxiv.org/pdf/2107.07137.pdf)
>  Ocean waves provide a consistent, reliable source of clean energy making them a viable energy source for desalination. Ocean wave energy is useful to coastal communities, especially island nations. However, large capital costs render current wave-powered desalination technologies economically infeasible. This work presents a high efficiency configuration for ocean wave energy powering batch reverse osmosis. The proposed system uses seawater as the working fluid in a hydro-mechanical wave energy converter and replaces the reverse osmosis high-pressure pump with a hydraulic converter for direct-drive coupling. This allows for minimal intermediary power conversions, fewer components, and higher efficiencies. The concept was analyzed with MATLAB to model the transient energy dynamics of the wave energy converter, power take-off system, and desalination load. The fully hydro-mechanical coupling, incorporating energy recovery, could achieve an SEC and LCOW as low as 2.30 kWh/m3 and $1.96, respectively, for different sea states. The results were validated at the sub-system level against existing literature on wave energy models and previous work completed on batch reverse osmosis models, as this system was the first to combine these two technologies. SEC and LCOW values were validated by comparing to known and predicted values for various types of RO systems.      
### 20.DAL: Feature Learning from Overt Speech to Decode Imagined Speech-based EEG Signals with Convolutional Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2107.07064.pdf)
>  Brain-computer interface (BCI) is one of the tools which enables the communication between humans and devices by reflecting intention and status of humans. With the development of artificial intelligence, the interest in communication between humans and drones using electroencephalogram (EEG) is increased. Especially, in the case of controlling drone swarms such as direction or formation, there are many advantages compared with controlling a drone unit. Imagined speech is one of the endogenous BCI paradigms, which can identify intentions of users. When conducting imagined speech, the users imagine the pronunciation as if actually speaking. In contrast, overt speech is a task in which the users directly pronounce the words. When controlling drone swarms using imagined speech, complex commands can be delivered more intuitively, but decoding performance is lower than that of other endogenous BCI paradigms. We proposed the Deep-autoleaner (DAL) to learn EEG features of overt speech for imagined speech-based EEG signals classification. To the best of our knowledge, this study is the first attempt to use EEG features of overt speech to decode imagined speech-based EEG signals with an autoencoder. A total of eight subjects participated in the experiment. When classifying four words, the average accuracy of the DAL was 48.41%. In addition, when comparing the performance between w/o and w/ EEG features of overt speech, there was a performance improvement of 7.42% when including EEG features of overt speech. Hence, we demonstrated that EEG features of overt speech could improve the decoding performance of imagined speech.      
### 21.Learning-based Spectrum Sensing and Access in Cognitive Radios via Approximate POMDPs  [ :arrow_down: ](https://arxiv.org/pdf/2107.07049.pdf)
>  A novel LEarning-based Spectrum Sensing and Access (LESSA) framework is proposed, wherein a cognitive radio (CR) learns a time-frequency correlation model underlying spectrum occupancy of licensed users (LUs) in a radio ecosystem; concurrently, it devises an approximately optimal spectrum sensing and access policy under sensing constraints. A Baum-Welch algorithm is proposed to learn a parametric Markov transition model of LU spectrum occupancy based on noisy spectrum measurements. Spectrum sensing and access are cast as a Partially-Observable Markov Decision Process, approximately optimized via randomized point-based value iteration. Fragmentation, Hamming-distance state filters and Monte-Carlo methods are proposed to alleviate the inherent computational complexity, and a weighted reward metric to regulate the trade-off between CR throughput and LU interference. Numerical evaluations demonstrate that LESSA performs within 5 percent of a genie-aided upper bound with foreknowledge of LU spectrum occupancy, and outperforms state-of-the-art algorithms across the entire trade-off region: 71 percent over correlation-based clustering, 26 percent over Neyman-Pearson detection, 6 percent over the Viterbi algorithm, and 9 percent over an adaptive Deep Q-Network. LESSA is then extended to a distributed Multi-Agent setting (MA-LESSA), by proposing novel neighbor discovery and channel access rank allocation. MA-LESSA improves CR throughput by 43 percent over cooperative TD-SARSA, 84 percent over cooperative greedy distributed learning, and 3x over non-cooperative learning via g-statistics and ACKs. Finally, MA-LESSA is implemented on the DARPA SC2 platform, manifesting superior performance over competitors in a real-world TDWR-UNII WLAN emulation; its implementation feasibility is further validated on a testbed of ESP32 radios, exhibiting 96 percent success probability.      
### 22.Frequency-packed Faster-than-Nyquist Signaling via Symbol-level Precoding for Multi-user MISO Redundant Transmissions  [ :arrow_down: ](https://arxiv.org/pdf/2107.06962.pdf)
>  This work addresses the issue of interference generated by co-channel users in downlink multi-antenna multicarrier systems with frequency-packed faster-than-Nyquist (FTN) signaling. The resulting interference stems from an aggressive strategy for enhancing the throughput via frequency reuse across different users and the squeezing of signals in the time-frequency plane beyond the Nyquist limit. The error-free spectral efficiency is proved to be increasing with the frequency packing and FTN acceleration factors. The lower bound for the FTN sampling period that guarantees information losslesness is derived as a function of the transmitting-filter roll-off factor, the frequency-packing factor, and the number of subcarriers. Space-time-frequency symbol-level precoders (SLPs) that trade off constructive and destructive interblock interference (IBI) at the single-antenna user terminals are proposed. Redundant elements are added as guard interval to cope with vestigial destructive IBI effects. The proposals can handle channels with delay spread longer than the multicarrier-symbol duration. The receiver architecture is simple, for it does not require digital multicarrier demodulation. Simulations indicate that the proposed SLP outperforms zero-forcing precoding and achieves a target balance between spectral and energy efficiencies by controlling the amount of added redundancy from zero (full IBI) to half (destructive IBI-free) the group delay of the equivalent channel.      
### 23.Optimality of the Discrete Fourier Transform for Beamspace Massive MU-MIMO Communication  [ :arrow_down: ](https://arxiv.org/pdf/2107.06953.pdf)
>  Beamspace processing is an emerging technique to reduce baseband complexity in massive multiuser (MU) multiple-input multiple-output (MIMO) communication systems operating at millimeter-wave (mmWave) and terahertz frequencies. The high directionality of wave propagation at such high frequencies ensures that only a small number of transmission paths exist between user equipments and basestation (BS). In order to resolve the sparse nature of wave propagation, beamspace processing traditionally computes a spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS where each DFT output is associated with a specific beam. In this paper, we study optimality conditions of the DFT for sparsity-based beamspace processing with idealistic mmWave channel models and realistic channels. To this end, we propose two algorithms that learn unitary beamspace transforms using an $\ell^4$-norm-based sparsity measure, and we investigate their optimality theoretically and via simulations.      
### 24.Blind Image Quality Assessment for MRI with A Deep Three-dimensional content-adaptive Hyper-Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.06888.pdf)
>  Image Quality Assessment (IQA) is of great value in the workflow of Magnetic Resonance Imaging (MRI)-based analysis. Blind IQA (BIQA) methods are especially required since high-quality reference MRI images are usually not available. Recently, many efforts have been devoted to developing deep learning-based BIQA approaches. However, the performance of these methods is limited due to the utilization of simple content-non-adaptive network parameters and the waste of the important 3D spatial information of the medical images. To address these issues, we design a 3D content-adaptive hyper-network for MRI BIQA. The overall 3D configuration enables the exploration of comprehensive 3D spatial information from MRI images, while the developed content-adaptive hyper-network contributes to the self-adaptive capacity of network parameters and thus, facilitates better BIQA performance. The effectiveness of the proposed method is extensively evaluated on the open dataset, MRIQC. Promising performance is achieved compared with the corresponding baseline and 4 state-of-the-art BIQA methods. We make our code available at \url{<a class="link-external link-https" href="https://git.openi.org.cn/SIAT_Wangshanshan/HyS-Net" rel="external noopener nofollow">this https URL</a>}.      
### 25.Optimization-Based Quadrupedal Hybrid Wheeled-Legged Locomotion  [ :arrow_down: ](https://arxiv.org/pdf/2107.07507.pdf)
>  Hybrid wheeled-legged locomotion is a navigation paradigm only recently opened up by novel robotic designs,e.g. the centaur-type humanoid CENTAURO [1] or the quadruped ANYmal [2] in its configuration featuring non-steerable wheels. The term Hybrid Locomotion is hereafter used to indicate a particular type of locomotion, achieved with simultaneous and coordinate use of legs and wheels,see Fig. 1. Such choice stems at the intersection between legged locomotion and the simpler wheeled navigation, in order to get the best from both techniques: agility and ability to traverse uneven terrains from the first, speed and stability from the second. As a consequence, the problem of planning feasible trajectories for a hybrid robot shares many similarities with the legged locomotion problem: also in the hybrid case the motion of the base is reached through contact of the feet with the environment, taking into account that the wheeled feet can just push on the ground and not pull it. Forces compatible with friction cones have to be considered, while the contacts can slide just along the direction prescribed by the orientation of the wheels.      
### 26.Objective Metrics to Evaluate Residual-Echo Suppression During Double-Talk  [ :arrow_down: ](https://arxiv.org/pdf/2107.07471.pdf)
>  Human subjective evaluation is optimal to assess speech quality for human perception. The recently introduced deep noise suppression mean opinion score (DNSMOS) metric was shown to estimate human ratings with great accuracy. The signal-to-distortion ratio (SDR) metric is widely used to evaluate residual-echo suppression (RES) systems by estimating speech quality during double-talk. However, since the SDR is affected by both speech distortion and residual-echo presence, it does not correlate well with human ratings according to the DNSMOS. To address that, we introduce two objective metrics to separately quantify the desired-speech maintained level (DSML) and residual-echo suppression level (RESL) during double-talk. These metrics are evaluated using a deep learning-based RES-system with a tunable design parameter. Using 280 hours of real and simulated recordings, we show that the DSML and RESL correlate well with the DNSMOS with high generalization to various setups. Also, we empirically investigate the relation between tuning the RES-system design parameter and the DSML-RESL tradeoff it creates and offer a practical design scheme for dynamic system requirements.      
### 27.Rule-based Evaluation and Optimal Control for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2107.07460.pdf)
>  We develop optimal control strategies for autonomous vehicles (AVs) that are required to meet complex specifications imposed as rules of the road (ROTR) and locally specific cultural expectations of reasonable driving behavior. We formulate these specifications as rules, and specify their priorities by constructing a priority structure, called \underline{T}otal \underline{OR}der over e\underline{Q}uivalence classes (TORQ). We propose a recursive framework, in which the satisfaction of the rules in the priority structure are iteratively relaxed in reverse order of priority. <br>Central to this framework is an optimal control problem, where convergence to desired states is achieved using Control Lyapunov Functions (CLFs) and clearance with other road users is enforced through Control Barrier Functions (CBFs). We present offline and online approaches to this problem. In the latter, the AV has limited sensing range that affects the activation of the rules, and the control is generated using a receding horizon (Model Predictive Control, MPC) approach. We also show how the offline method can be used for after-the-fact (offline) pass/fail evaluation of trajectories - a given trajectory is rejected if we can find a controller producing a trajectory that leads to less violation of the rule priority structure. We present case studies with multiple driving scenarios to demonstrate the effectiveness of the algorithms, and to compare the offline and online versions of our proposed framework.      
### 28.CLSRIL-23: Cross Lingual Speech Representations for Indic Languages  [ :arrow_down: ](https://arxiv.org/pdf/2107.07402.pdf)
>  We present a CLSRIL-23, a self supervised learning based audio pre-trained model which learns cross lingual speech representations from raw audio across 23 Indic languages. It is built on top of wav2vec 2.0 which is solved by training a contrastive task over masked latent speech representations and jointly learns the quantization of latents shared across all languages. We compare the language wise loss during pretraining to compare effects of monolingual and multilingual pretraining. Performance on some downstream fine-tuning tasks for speech recognition is also compared and our experiments show that multilingual pretraining outperforms monolingual training, in terms of learning speech representations which encodes phonetic similarity of languages and also in terms of performance on down stream tasks. A decrease of 5% is observed in WER and 9.5% in CER when a multilingual pretrained model is used for finetuning in Hindi. All the code models are also open sourced. CLSRIL-23 is a model trained on $23$ languages and almost 10,000 hours of audio data to facilitate research in speech recognition for Indic languages. We hope that new state of the art systems will be created using the self supervised approach, especially for low resources Indic languages.      
### 29.A Linear Dynamical Perspective on Epidemiology: Interplay Between Early COVID-19 Outbreak and Human Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2107.07380.pdf)
>  This paper investigates the impact of human activity and mobility (HAM) in the spreading dynamics of an epidemic. Specifically, it explores the interconnections between HAM and its effect on the early spread of the COVID-19 virus. During the early stages of the pandemic, effective reproduction numbers exhibited a high correlation with human mobility patterns, leading to a hypothesis that the HAM system can be studied as a coupled system with disease spread dynamics. This study applies the generalized Koopman framework with control inputs to determine the nonlinear disease spread dynamics and the input-output characteristics as a locally linear controlled dynamical system. The approach solely relies on the snapshots of spatiotemporal data and does not require any knowledge of the system's physical laws. We exploit the Koopman operator framework by utilizing the Hankel Dynamic Mode Decomposition with Control (HDMDc) algorithm to obtain a linear disease spread model incorporating human mobility as a control input. The study demonstrated that the proposed methodology could capture the impact of local mobility on the early dynamics of the ongoing global pandemic. The obtained locally linear model can accurately forecast the number of new infections for various prediction windows ranging from two to four weeks. The study corroborates a leader-follower relationship between mobility and disease spread dynamics. In addition, the effect of delay embedding in the HDMDc algorithm is also investigated and reported. A case study was performed using COVID infection data from Florida, US, and HAM data extracted from Google community mobility data report.      
### 30.Sketching sounds: an exploratory study on sound-shape associations  [ :arrow_down: ](https://arxiv.org/pdf/2107.07360.pdf)
>  Sound synthesiser controls typically correspond to technical parameters of signal processing algorithms rather than intuitive sound descriptors that relate to human perception of sound. This makes it difficult to realise sound ideas in a straightforward way. Cross-modal mappings, for example between gestures and sound, have been suggested as a more intuitive control mechanism. A large body of research shows consistency in human associations between sounds and shapes. However, the use of drawings to drive sound synthesis has not been explored to its full extent. This paper presents an exploratory study that asked participants to sketch visual imagery of sounds with a monochromatic digital drawing interface, with the aim to identify different representational approaches and determine whether timbral sound characteristics can be communicated reliably through visual sketches. Results imply that the development of a synthesiser exploiting sound-shape associations is feasible, but a larger and more focused dataset is needed in followup studies.      
### 31.Probabilistic analysis of solar cell optical performance using Gaussian processes  [ :arrow_down: ](https://arxiv.org/pdf/2107.07342.pdf)
>  This work investigates application of different machine learning based prediction methodologies to estimate the performance of silicon based textured cells. Concept of confidence bound regions is introduced and advantages of this concept are discussed in detail. Results show that reflection profiles and depth dependent optical generation profiles can be accurately estimated using Gaussian processes with exact knowledge of uncertainty in the prediction <a class="link-external link-http" href="http://values.It" rel="external noopener nofollow">this http URL</a> is also shown that cell design parameters can be estimated for a desired performance metric.      
### 32.An Overview of Machine Learning-aided Optical Performance Monitoring Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2107.07338.pdf)
>  Future communication systems are faced with increased demand for high capacity, dynamic bandwidth, reliability and heterogeneous traffic. To meet these requirements, networks have become more complex and thus require new design methods and monitoring techniques, as they evolve towards becoming autonomous. Machine learning has come to the forefront in recent years as a promising technology to aid in this evolution. Optical fiber communications can already provide the high capacity required for most applications, however, there is a need for increased scalability and adaptability to changing user demands and link conditions. Accurate performance monitoring is an integral part of this transformation. In this paper we review optical performance monitoring techniques where machine learning algorithms have been applied. Moreover, since alot of OPM depends on knowledge of the signal type, we also review work for modulation format recognition and bitrate identification. We additionally briefly introduce a neuromorphic approach to OPM as an emerging technique that has only recently been applied to this domain.      
### 33.Unsupervised Anomaly Instance Segmentation for Baggage Threat Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.07333.pdf)
>  Identifying potential threats concealed within the baggage is of prime concern for the security staff. Many researchers have developed frameworks that can detect baggage threats from X-ray scans. However, to the best of our knowledge, all of these frameworks require extensive training on large-scale and well-annotated datasets, which are hard to procure in the real world. This paper presents a novel unsupervised anomaly instance segmentation framework that recognizes baggage threats, in X-ray scans, as anomalies without requiring any ground truth labels. Furthermore, thanks to its stylization capacity, the framework is trained only once, and at the inference stage, it detects and extracts contraband items regardless of their scanner specifications. Our one-staged approach initially learns to reconstruct normal baggage content via an encoder-decoder network utilizing a proposed stylization loss function. The model subsequently identifies the abnormal regions by analyzing the disparities within the original and the reconstructed scans. The anomalous regions are then clustered and post-processed to fit a bounding box for their localization. In addition, an optional classifier can also be appended with the proposed framework to recognize the categories of these extracted anomalies. A thorough evaluation of the proposed system on four public baggage X-ray datasets, without any re-training, demonstrates that it achieves competitive performance as compared to the conventional fully supervised methods (i.e., the mean average precision score of 0.7941 on SIXray, 0.8591 on GDXray, 0.7483 on OPIXray, and 0.5439 on COMPASS-XP dataset) while outperforming state-of-the-art semi-supervised and unsupervised baggage threat detection frameworks by 67.37%, 32.32%, 47.19%, and 45.81% in terms of F1 score across SIXray, GDXray, OPIXray, and COMPASS-XP datasets, respectively.      
### 34.Variational Topic Inference for Chest X-Ray Report Generation  [ :arrow_down: ](https://arxiv.org/pdf/2107.07314.pdf)
>  Automating report generation for medical imaging promises to reduce workload and assist diagnosis in clinical practice. Recent work has shown that deep learning models can successfully caption natural images. However, learning from medical data is challenging due to the diversity and uncertainty inherent in the reports written by different radiologists with discrepant expertise and experience. To tackle these challenges, we propose variational topic inference for automatic report generation. Specifically, we introduce a set of topics as latent variables to guide sentence generation by aligning image and language modalities in a latent space. The topics are inferred in a conditional variational inference framework, with each topic governing the generation of a sentence in the report. Further, we adopt a visual attention module that enables the model to attend to different locations in the image and generate more informative descriptions. We conduct extensive experiments on two benchmarks, namely Indiana U. Chest X-rays and MIMIC-CXR. The results demonstrate that our proposed variational topic inference method can generate novel reports rather than mere copies of reports used in training, while still achieving comparable performance to state-of-the-art methods in terms of standard language generation criteria.      
### 35.Training for temporal sparsity in deep neural networks, application in video processing  [ :arrow_down: ](https://arxiv.org/pdf/2107.07305.pdf)
>  Activation sparsity improves compute efficiency and resource utilization in sparsity-aware neural network accelerators. As the predominant operation in DNNs is multiply-accumulate (MAC) of activations with weights to compute inner products, skipping operations where (at least) one of the two operands is zero can make inference more efficient in terms of latency and power. Spatial sparsification of activations is a popular topic in DNN literature and several methods have already been established to bias a DNN for it. On the other hand, temporal sparsity is an inherent feature of bio-inspired spiking neural networks (SNNs), which neuromorphic processing exploits for hardware efficiency. Introducing and exploiting spatio-temporal sparsity, is a topic much less explored in DNN literature, but in perfect resonance with the trend in DNN, to shift from static signal processing to more streaming signal processing. Towards this goal, in this paper we introduce a new DNN layer (called Delta Activation Layer), whose sole purpose is to promote temporal sparsity of activations during training. A Delta Activation Layer casts temporal sparsity into spatial activation sparsity to be exploited when performing sparse tensor multiplications in hardware. By employing delta inference and ``the usual'' spatial sparsification heuristics during training, the resulting model learns to exploit not only spatial but also temporal activation sparsity (for a given input data distribution). One may use the Delta Activation Layer either during vanilla training or during a refinement phase. We have implemented Delta Activation Layer as an extension of the standard Tensoflow-Keras library, and applied it to train deep neural networks on the Human Action Recognition (UCF101) dataset. We report an almost 3x improvement of activation sparsity, with recoverable loss of model accuracy after longer training.      
### 36.A Low-Complexity Radar Detector Outperforming OS-CFAR for Indoor Drone Obstacle Avoidance  [ :arrow_down: ](https://arxiv.org/pdf/2107.07250.pdf)
>  As radar sensors are being miniaturized, there is a growing interest for using them in indoor sensing applications such as indoor drone obstacle avoidance. In those novel scenarios, radars must perform well in dense scenes with a large number of neighboring scatterers. Central to radar performance is the detection algorithm used to separate targets from the background noise and clutter. Traditionally, most radar systems use conventional CFAR detectors but their performance degrades in indoor scenarios with many reflectors. Inspired by the advances in non-linear target detection, we propose a novel high-performance, yet low-complexity target detector and we experimentally validate our algorithm on a dataset acquired using a radar mounted on a drone. We experimentally show that our proposed algorithm drastically outperforms OS-CFAR (standard detector used in automotive systems) for our specific task of indoor drone navigation with more than 19% higher probability of detection for a given probability of false alarm. We also benchmark our proposed detector against a number of recently proposed multi-target CFAR detectors and show an improvement of 16% in probability of detection compared to CHA-CFAR, with even larger improvements compared to both OR-CFAR and TS-LNCFAR in our particular indoor scenario. To the best of our knowledge, this work improves the state of the art for high-performance yet low-complexity radar detection in critical indoor sensing applications.      
### 37.COAST: COntrollable Arbitrary-Sampling NeTwork for Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2107.07225.pdf)
>  Recent deep network-based compressive sensing (CS) methods have achieved great success. However, most of them regard different sampling matrices as different independent tasks and need to train a specific model for each target sampling matrix. Such practices give rise to inefficiency in computing and suffer from poor generalization ability. In this paper, we propose a novel COntrollable Arbitrary-Sampling neTwork, dubbed COAST, to solve CS problems of arbitrary-sampling matrices (including unseen sampling matrices) with one single model. Under the optimization-inspired deep unfolding framework, our COAST exhibits good interpretability. In COAST, a random projection augmentation (RPA) strategy is proposed to promote the training diversity in the sampling space to enable arbitrary sampling, and a controllable proximal mapping module (CPMM) and a plug-and-play deblocking (PnP-D) strategy are further developed to dynamically modulate the network features and effectively eliminate the blocking artifacts, respectively. Extensive experiments on widely used benchmark datasets demonstrate that our proposed COAST is not only able to handle arbitrary sampling matrices with one single model but also to achieve state-of-the-art performance with fast speed. The source code is available on <a class="link-external link-https" href="https://github.com/jianzhangcs/COAST" rel="external noopener nofollow">this https URL</a>.      
### 38.Conflict-free Cooperation Method for Connected and Automated Vehicles at Unsignalized Intersections: Graph-based Modeling and Optimality Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2107.07179.pdf)
>  Connected and automated vehicles have shown great potential in improving traffic mobility and reducing emissions, especially at unsignalized intersections. Previous research has shown that vehicle passing order is the key influencing factor in improving intersection traffic mobility. In this paper, we propose a graph-based cooperation method to formalize the conflict-free scheduling problem at an unsignalized intersection. Based on graphical analysis, a vehicle's trajectory conflict relationship is modeled as a conflict directed graph and a coexisting undirected graph. Then, two graph-based methods are proposed to find the vehicle passing order. The first is an improved depth-first spanning tree algorithm, which aims to find the local optimal passing order vehicle by vehicle. The other novel method is a minimum clique cover algorithm, which identifies the global optimal solution. Finally, a distributed control framework and communication topology are presented to realize the conflict-free cooperation of vehicles. Extensive numerical simulations are conducted for various numbers of vehicles and traffic volumes, and the simulation results prove the effectiveness of the proposed algorithms.      
### 39.DeFed: A Principled Decentralized and Privacy-Preserving Federated Learning Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2107.07171.pdf)
>  Federated learning enables a large number of clients to participate in learning a shared model while maintaining the training data stored in each client, which protects data privacy and security. Till now, federated learning frameworks are built in a centralized way, in which a central client is needed for collecting and distributing information from every other client. This not only leads to high communication pressure at the central client, but also renders the central client highly vulnerable to failure and attack. Here we propose a principled decentralized federated learning algorithm (DeFed), which removes the central client in the classical Federated Averaging (FedAvg) setting and only relies information transmission between clients and their local neighbors. The proposed DeFed algorithm is proven to reach the global minimum with a convergence rate of $O(1/T)$ when the loss function is smooth and strongly convex, where $T$ is the number of iterations in gradient descent. Finally, the proposed algorithm has been applied to a number of toy examples to demonstrate its effectiveness.      
### 40.Frequency-Time Division based Deep Learning for OFDM Channel Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2107.07161.pdf)
>  In this paper, we propose a frequency-time division network (FreqTimeNet) to improve the performance of deep learning (DL) based OFDM channel estimation. This FreqTimeNet is designed based on the orthogonality between the frequency domain and the time domain. In FreqTimeNet, the input signals are processed by parallel frequency blocks first and then go through parallel time blocks. Using 3rd Generation Partnership Project (3GPP) channel models, the mean square error (MSE) performance of FreqTimeNet under different scenarios is evaluated. A method for constructing mixed training data is proposed, which could address the generalization problem in DL. It is observed that FreqTimeNet outperforms other DL networks, with acceptable complexity.      
### 41.NeuSaver: Neural Adaptive Power Consumption Optimization for Mobile Video Streaming  [ :arrow_down: ](https://arxiv.org/pdf/2107.07127.pdf)
>  Video streaming services strive to support high-quality videos at higher resolutions and frame rates to improve the quality of experience (QoE). However, high-quality videos consume considerable amounts of energy on mobile devices. This paper proposes NeuSaver, which reduces the power consumption of mobile devices when streaming videos by applying an adaptive frame rate to each video chunk without compromising user experience. NeuSaver generates an optimal policy that determines the appropriate frame rate for each video chunk using reinforcement learning (RL). The RL model automatically learns the policy that maximizes the QoE goals based on previous observations. NeuSaver also uses an asynchronous advantage actor-critic algorithm to reinforce the RL model quickly and robustly. Streaming servers that support NeuSaver preprocesses videos into segments with various frame rates, which is similar to the process of creating videos with multiple bit rates in dynamic adaptive streaming over HTTP. NeuSaver utilizes the commonly used H.264 video codec. We evaluated NeuSaver in various experiments and a user study through four video categories along with the state-of-the-art model. Our experiments showed that NeuSaver effectively reduces the power consumption of mobile devices when streaming video by an average of 16.14% and up to 23.12% while achieving high QoE.      
### 42.Joint CFO, Gridless Channel Estimation and Data Detection for Underwater Acoustic OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.07101.pdf)
>  In this paper, we propose an iterative receiver based on gridless variational Bayesian line spectra estimation (VALSE) named JCCD-VALSE that \emph{j}ointly estimates the \emph{c}arrier frequency offset (CFO), the \emph{c}hannel with high resolution and carries out \emph{d}ata decoding. Based on a modularized point of view and motivated by the high resolution and low complexity gridless VALSE algorithm, three modules named the VALSE module, the minimum mean squared error (MMSE) module and the decoder module are built. Soft information is exchanged between the modules to progressively improve the channel estimation and data decoding accuracy. Since the delays of multipaths of the channel are treated as continuous parameters, instead of on a grid, the leakage effect is avoided. Besides, the proposed approach is a more complete Bayesian approach as all the nuisance parameters such as the noise variance, the parameters of the prior distribution of the channel, the number of paths are automatically estimated. Numerical simulations and sea test data are utilized to demonstrate that the proposed approach performs significantly better than the existing grid-based generalized approximate message passing (GAMP) based \emph{j}oint \emph{c}hannel and \emph{d}ata decoding approach (JCD-GAMP). Furthermore, it is also verified that joint processing including CFO estimation provides performance gain.      
### 43.Vision-Based Target Localization for a Flapping-Wing Aerial Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2107.07084.pdf)
>  The flapping-wing aerial vehicle (FWAV) is a new type of flying robot that mimics the flight mode of birds and insects. However, FWAVs have their special characteristics of less load capacity and short endurance time, so that most existing systems of ground target localization are not suitable for them. In this paper, a vision-based target localization algorithm is proposed for FWAVs based on a generic camera model. Since sensors exist measurement error and the camera exists jitter and motion blur during flight, Gaussian noises are introduced in the simulation experiment, and then a first-order low-pass filter is used to stabilize the localization values. Moreover, in order to verify the feasibility and accuracy of the target localization algorithm, we design a set of simulation experiments where various noises are added. From the simulation results, it is found that the target localization algorithm has a good performance.      
### 44.EICO: Energy-Harvesting Long-Range Environmental Sensor Nodes with Energy-Information Dynamic Co-Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2107.07072.pdf)
>  Intensive research on energy harvested sensor nodes with traditional battery powered devices has been driven by the challenges in achieving the stringent design goals of battery lifetime, information accuracy, transmission distance, and cost. This challenge is further amplified by the inherent power intensive nature of long-range communication when sensor networks are required to span vast areas such as agricultural fields and remote terrain. Solar power is a common energy source is wireless sensor nodes, however, it is not reliable due to fluctuations in power stemming from the changing seasons and weather conditions. This paper tackles these issues by presenting a perpetually-powered, energy-harvesting sensor node which utilizes a minimally sized solar cell and is capable of long range communication by dynamically co-optimizing energy consumption and information transfer, termed as Energy-Information Dynamic Co-Optimization (EICO). This energy-information intelligence is achieved by adaptive duty cycling of information transfer based on the total amount of energy available from the harvester and charge storage element to optimize the energy consumption of the sensor node, while employing in-sensor analytics (ISA) to minimize loss of information. This is the first reported sensor node &lt; 35cm2 in dimension, which is capable of long-range communication over &gt; 1Km at continuous information transfer rates of upto 1 packet/second which is enabled by EICO and ISA.      
### 45.Distributed Grid Optimization via Distributed Dual Subgradient Methods with Averaging  [ :arrow_down: ](https://arxiv.org/pdf/2107.07061.pdf)
>  A collection of optimization problems central to power system operation requires distributed solution architectures to avoid the need for aggregation of all information at a central location. In this paper, we study distributed dual subgradient methods to solve three such optimization problems. Namely, these are tie-line scheduling in multi-area power systems, coordination of distributed energy resources in radial distribution networks, and joint dispatch of transmission and distribution assets. With suitable relaxations or approximations of the nonconvex power flow equations, all three problems can be reduced to a multi-agent constrained convex optimization problem. We utilize a constant step-size dual subgradient method with averaging on these problems. For this algorithm, we provide a convergence guarantee that is shown to be order-optimal. We illustrate its application on the grid optimization problems.      
### 46.Short-term Hourly Streamflow Prediction with Graph Convolutional GRU Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.07039.pdf)
>  The frequency and impact of floods are expected to increase due to climate change. It is crucial to predict streamflow, consequently flooding, in order to prepare and mitigate its consequences in terms of property damage and fatalities. This paper presents a Graph Convolutional GRUs based model to predict the next 36 hours of streamflow for a sensor location using the upstream river network. As shown in experiment results, the model presented in this study provides better performance than the persistence baseline and a Convolutional Bidirectional GRU network for the selected study area in short-term streamflow prediction.      
### 47.Leveraging Hierarchical Structures for Few-Shot Musical Instrument Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.07029.pdf)
>  Deep learning work on musical instrument recognition has generally focused on instrument classes for which we have abundant data. In this work, we exploit hierarchical relationships between instruments in a few-shot learning setup to enable classification of a wider set of musical instruments, given a few examples at inference. We apply a hierarchical loss function to the training of prototypical networks, combined with a method to aggregate prototypes hierarchically, mirroring the structure of a predefined musical instrument hierarchy. These extensions require no changes to the network architecture and new levels can be easily added or removed. Compared to a non-hierarchical few-shot baseline, our method leads to a significant increase in classification accuracy and significant decrease mistake severity on instrument classes unseen in training.      
### 48.A new class of conditional Markov jump processes with regime switching and path dependence: properties and maximum likelihood estimation  [ :arrow_down: ](https://arxiv.org/pdf/2107.07026.pdf)
>  This paper develops a new class of conditional Markov jump processes with regime switching and paths dependence. The key novel feature of the developed process lies on its ability to switch the transition rate as it moves from one state to another with switching probability depending on the current state and time of the process as well as its past trajectories. As such, the transition from current state to another depends on the holding time of the process in the state. Distributional properties of the process are given explicitly in terms of the speed regimes represented by a finite number of different transition matrices, the probabilities of selecting regime membership within each state, and past realization of the process. In particular, it has distributional equivalent stochastic representation with a general mixture of Markov jump processes introduced in Frydman and Surya (2020). Maximum likelihood estimates (MLE) of the distribution parameters of the process are derived in closed form. The estimation is done iteratively using the EM algorithm. Akaike information criterion is used to assess the goodness-of-fit of the selected model. An explicit observed Fisher information matrix of the MLE is derived for the calculation of standard errors of the MLE. The information matrix takes on a simplified form of the general matrix formula of Louis (1982). Large sample properties of the MLE are presented. In particular, the covariance matrix for the MLE of transition rates is equal to the Cramér-Rao lower bound, and is less for the MLE of regime membership. The simulation study confirms these findings and shows that the parameter estimates are accurate, consistent, and have asymptotic normality as the sample size increases.      
### 49.A Bayesian Compressive Sensing Approach to Robust Near-Field Antenna Characterization  [ :arrow_down: ](https://arxiv.org/pdf/2107.07011.pdf)
>  A novel probabilistic sparsity-promoting method for robust near-field (NF) antenna characterization is proposed. It leverages on the measurements-by-design (MebD) paradigm and it exploits some a-priori information on the antenna under test (AUT) to generate an over-complete representation basis. Accordingly, the problem at hand is reformulated in a compressive sensing (CS) framework as the retrieval of a maximally-sparse distribution (with respect to the overcomplete basis) from a reduced set of measured data and then it is solved by means of a Bayesian strategy. Representative numerical results are presented to, also comparatively, assess the effectiveness of the proposed approach in reducing the "burden/cost" of the acquisition process as well as to mitigate (possible) truncation errors when dealing with space-constrained probing systems.      
### 50.Fast Homotopy for Spacecraft Rendezvous Trajectory Optimization with Discrete Logic  [ :arrow_down: ](https://arxiv.org/pdf/2107.07001.pdf)
>  This paper presents a computationally efficient optimization algorithm for solving nonconvex optimal control problems that involve discrete logic constraints. Traditional solution methods for these constraints require binary variables and mixed-integer programming, which is prohibitively slow and computationally expensive. This paper targets a fast solution that is capable of real-time implementation onboard spacecraft. To do so, a novel algorithm is developed that blends sequential convex programming and numerical continuation into a single iterative solution process. Inside the algorithm, discrete logic constraints are approximated by smooth functions, and a homotopy parameter governs the accuracy of this approximation. As the algorithm converges, the homotopy parameter is updated such that the smooth approximations enforce the exact discrete logic. The effectiveness of this approach is numerically demonstrated for a realistic rendezvous scenario inspired by the Apollo Transposition and Docking maneuver. In under 15 seconds of cumulative solver time, the algorithm is able to reliably find difficult fuel-optimal trajectories that obey the following discrete logic constraints: thruster minimum impulse-bit, range-triggered approach cone, and range-triggered plume impingement. The optimized trajectory uses significantly less fuel than reported NASA design targets.      
### 51.$\ell^p\!-\!\ell^q$-Norm Minimization for Joint Precoding and Peak-to-Average-Power Ratio Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2107.06986.pdf)
>  Wireless communication systems that rely on orthogonal frequency-division multiplexing (OFDM) suffer from a high peak-to-average (power) ratio (PAR), which necessitates power-inefficient radio-frequency (RF) chains to avoid an increase in error-vector magnitude (EVM) and out-of-band (OOB) emissions. The situation is further aggravated in massive multiuser (MU) multiple-input multiple-output (MIMO) systems that would require hundreds of linear RF chains. In this paper, we present a novel approach to joint precoding and PAR reduction that builds upon a novel $\ell^p\!-\!\ell^q$-norm formulation, which is able to find minimum PAR solutions while suppressing MU interference. We provide a theoretical underpinning of our approach and provide simulation results for a massive MU-MIMO-OFDM system that demonstrate significant reductions in PAR at low complexity, without causing an increase in EVM or OOB emissions.      
### 52.FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task  [ :arrow_down: ](https://arxiv.org/pdf/2107.06959.pdf)
>  In this paper, we describe our end-to-end multilingual speech translation system submitted to the IWSLT 2021 evaluation campaign on the Multilingual Speech Translation shared task. Our system is built by leveraging transfer learning across modalities, tasks and languages. First, we leverage general-purpose multilingual modules pretrained with large amounts of unlabelled and labelled data. We further enable knowledge transfer from the text task to the speech task by training two tasks jointly. Finally, our multilingual model is finetuned on speech translation task-specific data to achieve the best translation results. Experimental results show our system outperforms the reported systems, including both end-to-end and cascaded based approaches, by a large margin. <br>In some translation directions, our speech translation results evaluated on the public Multilingual TEDx test set are even comparable with the ones from a strong text-to-text translation system, which uses the oracle speech transcripts as input.      
### 53.FetalNet: Multi-task deep learning framework for fetal ultrasound biometric measurements  [ :arrow_down: ](https://arxiv.org/pdf/2107.06943.pdf)
>  In this paper, we propose an end-to-end multi-task neural network called FetalNet with an attention mechanism and stacked module for spatio-temporal fetal ultrasound scan video analysis. Fetal biometric measurement is a standard examination during pregnancy used for the fetus growth monitoring and estimation of gestational age and fetal weight. The main goal in fetal ultrasound scan video analysis is to find proper standard planes to measure the fetal head, abdomen and femur. Due to natural high speckle noise and shadows in ultrasound data, medical expertise and sonographic experience are required to find the appropriate acquisition plane and perform accurate measurements of the fetus. In addition, existing computer-aided methods for fetal US biometric measurement address only one single image frame without considering temporal features. To address these shortcomings, we propose an end-to-end multi-task neural network for spatio-temporal ultrasound scan video analysis to simultaneously localize, classify and measure the fetal body parts. We propose a new encoder-decoder segmentation architecture that incorporates a classification branch. Additionally, we employ an attention mechanism with a stacked module to learn salient maps to suppress irrelevant US regions and efficient scan plane localization. We trained on the fetal ultrasound video comes from routine examinations of 700 different patients. Our method called FetalNet outperforms existing state-of-the-art methods in both classification and segmentation in fetal ultrasound video recordings.      
### 54.Planning Strategies for Lane Reversals in Transportation Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.06937.pdf)
>  This paper studies strategies to optimize the lane configuration of a transportation network for a given set of Origin-Destination demands using a planning macroscopic network flow model. The lane reversal problem is, in general, NP-hard since the optimization is made over integer variables. To overcome this burden, we reformulate the problem using a piecewise affine approximation of the travel latency function which allows us to exploit the total unimodularity property of Integer Linear Programming (ILP). Consequently, we transform the ILP problem to a linear program by relaxing the integer variables. In addition, our method is capable of solving the problem for a desired number of lane reversals which serves to perform cost-benefit analysis. We perform a case study using the transportation network of Eastern Massachusetts (EMA) and we test our method against the original lane configuration and a projected lower bound solution. Our empirical results quantify the travel time savings for different levels of demand intensity. We observe reduction in travel times up to 40% for certain links in the network.      
