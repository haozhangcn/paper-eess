# ArXiv eess --Fri, 26 Mar 2021
### 1.Zero-shot super-resolution with a physically-motivated downsampling kernel for endomicroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2103.14015.pdf)
>  Super-resolution (SR) methods have seen significant advances thanks to the development of convolutional neural networks (CNNs). CNNs have been successfully employed to improve the quality of endomicroscopy imaging. Yet, the inherent limitation of research on SR in endomicroscopy remains the lack of ground truth high-resolution (HR) images, commonly used for both supervised training and reference-based image quality assessment (IQA). Therefore, alternative methods, such as unsupervised SR are being explored. To address the need for non-reference image quality improvement, we designed a novel zero-shot super-resolution (ZSSR) approach that relies only on the endomicroscopy data to be processed in a self-supervised manner without the need for ground-truth HR images. We tailored the proposed pipeline to the idiosyncrasies of endomicroscopy by introducing both: a physically-motivated Voronoi downscaling kernel accounting for the endomicroscope's irregular fibre-based sampling pattern, and realistic noise patterns. We also took advantage of video sequences to exploit a sequence of images for self-supervised zero-shot image quality improvement. We run ablation studies to assess our contribution in regards to the downscaling kernel and noise simulation. We validate our methodology on both synthetic and original data. Synthetic experiments were assessed with reference-based IQA, while our results for original images were evaluated in a user study conducted with both expert and non-expert observers. The results demonstrated superior performance in image quality of ZSSR reconstructions in comparison to the baseline method. The ZSSR is also competitive when compared to supervised single-image SR, especially being the preferred reconstruction technique by experts.      
### 2.Designing a Practical Degradation Model for Deep Blind Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.14006.pdf)
>  It is widely acknowledged that single image super-resolution (SISR) methods would not perform well if the assumed degradation model deviates from those in real images. Although several degradation models take additional factors into consideration, such as blur, they are still not effective enough to cover the diverse degradations of real images. To address this issue, this paper proposes to design a more complex but practical degradation model that consists of randomly shuffled blur, downsampling and noise degradations. Specifically, the blur is approximated by two convolutions with isotropic and anisotropic Gaussian kernels; the downsampling is randomly chosen from nearest, bilinear and bicubic interpolations; the noise is synthesized by adding Gaussian noise with different noise levels, adopting JPEG compression with different quality factors, and generating processed camera sensor noise via reverse-forward camera image signal processing (ISP) pipeline model and RAW image noise model. To verify the effectiveness of the new degradation model, we have trained a deep blind ESRGAN super-resolver and then applied it to super-resolve both synthetic and real images with diverse degradations. The experimental results demonstrate that the new degradation model can help to significantly improve the practicability of deep super-resolvers, thus providing a powerful alternative solution for real SISR applications.      
### 3.Adversarial Attacks on Deep Learning Based mmWave Beam Prediction in 5G and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2103.13989.pdf)
>  Deep learning provides powerful means to learn from spectrum data and solve complex tasks in 5G and beyond such as beam selection for initial access (IA) in mmWave communications. To establish the IA between the base station (e.g., gNodeB) and user equipment (UE) for directional transmissions, a deep neural network (DNN) can predict the beam that is best slanted to each UE by using the received signal strengths (RSSs) from a subset of possible narrow beams. While improving the latency and reliability of beam selection compared to the conventional IA that sweeps all beams, the DNN itself is susceptible to adversarial attacks. We present an adversarial attack by generating adversarial perturbations to manipulate the over-the-air captured RSSs as the input to the DNN. This attack reduces the IA performance significantly and fools the DNN into choosing the beams with small RSSs compared to jamming attacks with Gaussian or uniform noise.      
### 4.Scaled relative graphs for system analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.13971.pdf)
>  Scaled relative graphs were recently introduced to analyze the convergence of optimization algorithms using two dimensional Euclidean geometry. In this paper, we connect scaled relative graphs to the classical theory of input/output systems. It is shown that the Nyquist diagram of an LTI system on $L_2$ is the convex hull of its scaled relative graph under a particular change of coordinates. The SRG may be used to visualize approximations of static nonlinearities such as the describing function and quadratic constraints, allowing system properties to be verified or disproved. Interconnections of systems correspond to graphical manipulations of their SRGs. This is used to provide a simple, graphical proof of the classical incremental passivity theorem.      
### 5.Nonlinear Estimation for Position-Aided Inertial Navigation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13955.pdf)
>  In this work we solve the position-aided 3D navigation problem using a nonlinear estimation scheme. More precisely, we propose a nonlinear observer to estimate the full state of the vehicle (position, velocity, orientation and gyro bias) from IMU and position measurements. The proposed observer does not introduce additional auxiliary states and is shown to guarantee semi-global exponential stability without any assumption on the acceleration of the vehicle. The performance of the observer is shown, through simulation, to overcome the state-of-the-art approach that assumes negligible accelerations.      
### 6.Transmit Beamspace DDMA Based Automotive MIMO Radar  [ :arrow_down: ](https://arxiv.org/pdf/2103.13892.pdf)
>  The time division multiple access (TDMA) technique has been applied in automotive multiple-input multiple-output (MIMO) radar. However, it suffers from the transmit energy loss, and as a result the parameter estimation performance degradation when the number of transmit elements increases. To tackle these problem, a transmit beamspace (TB) Doppler division multiple access (DDMA) approach is proposed. First, a phase modulation matrix with empty Doppler spectrum is introduced. By exploiting the empty Doppler spectrum, a test function based on sequential detection is developed to mitigate the Doppler ambiguity in DDMA waveform. Then, a discrete Fourier transform (DFT)-based TB in slow-time is formed.The proposed method can achieve waveform diversity in Doppler domain and generate a TB in slow-time that concentrates the transmitted power in a fixed spatial region to improve the transmit energy distribution for automotive MIMO radar, which is favored by medium/long range radar (MRR/LRR) applications. As compared to the conventional TDMA technique, the proposed TB DDMA approach can fully exploit the transmission capabilities of all transmit elements to ensure that the emitted power is efficiently used and inherits easy implementation. Moreover, the proposed TB DDMA method avoids the trade-off between the active time for each transmit antenna and the frame time. Simulation results verify the effectiveness of the proposed TB DDMA approach for automotive MIMO radar.      
### 7.Sample-efficient Plasma Spray Process Configuration with Constrained Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.13881.pdf)
>  Recent work has shown constrained Bayesian optimization to be a powerful technique for the optimization of industrial processes. We adapt this framework to the set-up and optimization of atmospheric plasma spraying processes. We propose and validate a Gaussian process modeling structure to predict coatings properties. We introduce a parallel acquisition procedure tailored on the process characteristics and propose an algorithm that adapts to real-time process measurements to improve reproducibility. We validate our optimization method numerically and experimentally, and demonstrate that it can efficiently find input parameters that produce the desired coating and minimize the process cost.      
### 8.Source Aware Deep Learning Framework for Hand Kinematic Reconstruction using EEG Signal  [ :arrow_down: ](https://arxiv.org/pdf/2103.13862.pdf)
>  The ability to reconstruct the kinematic parameters of hand movement using non-invasive electroencephalography (EEG) is essential for strength and endurance augmentation using exosuit/exoskeleton. For system development, the conventional classification based brain computer interface (BCI) controls external devices by providing discrete control signals to the actuator. A continuous kinematic reconstruction from EEG signal is better suited for practical BCI applications. The state-of-the-art multi-variable linear regression (mLR) method provides a continuous estimate of hand kinematics, achieving maximum correlation of upto 0.67 between the measured and the estimated hand trajectory. In this work, three novel source aware deep learning models are proposed for motion trajectory prediction (MTP). In particular, multi layer perceptron (MLP), convolutional neural network - long short term memory (CNN-LSTM), and wavelet packet decomposition (WPD) CNN-LSTM are presented. Additional novelty of the work includes utilization of brain source localization (using sLORETA) for the reliable decoding of motor intention mapping (channel selection) and accurate EEG time segment selection. Performance of the proposed models are compared with the traditionally utilised mLR technique on the real grasp and lift (GAL) dataset. Effectiveness of the proposed framework is established using the Pearson correlation coefficient and trajectory analysis. A significant improvement in the correlation coefficient is observed when compared with state-of-the-art mLR model. Our work bridges the gap between the control and the actuator block, enabling real time BCI implementation.      
### 9.Abstracting the Sampling Behaviour of Stochastic Linear Periodic Event-Triggered Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13839.pdf)
>  Recently, there have been efforts towards understanding the sampling behaviour of event-triggered control (ETC), for obtaining metrics on its sampling performance and predicting its sampling patterns. Finite-state abstractions, capturing the sampling behaviour of ETC systems, have proven promising in this respect. So far, such abstractions have been constructed for non-stochastic systems. Here, inspired by this framework, we abstract the sampling behaviour of stochastic narrow-sense linear periodic ETC (PETC) systems via Interval Markov Chains (IMCs). Particularly, we define functions over sequences of state-measurements and interevent times that can be expressed as discounted cumulative sums of rewards, and compute bounds on their expected values by constructing appropriate IMCs and equipping them with suitable rewards. Finally, we argue that our results are extendable to more general forms of functions, thus providing a generic framework to define and study various ETC sampling indicators.      
### 10.Deep Learning with robustness to missing data: A novel approach to the detection of COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2103.13833.pdf)
>  In the context of the current global pandemic and the limitations of the RT-PCR test, we propose a novel deep learning architecture, DFCN, (Denoising Fully Connected Network) for the detection of COVID-19 using laboratory tests and chest x-rays. Since medical facilities around the world differ enormously in what laboratory tests or chest imaging may be available, DFCN is designed to be robust to missing input data. An ablation study extensively evaluates the performance benefits of the DFCN architecture as well as its robustness to missing inputs. Data from 1088 patients with confirmed RT-PCR results are obtained from two independent medical facilities. The data collected includes results from 27 laboratory tests and a chest x-ray scored by a deep learning network. Training and test datasets are defined based on the source medical facility. Data is made publicly available. The performance of DFCN in predicting the RT-PCR result is compared with 3 related architectures as well as a Random Forest baseline. All models are trained with varying levels of masked input data to encourage robustness to missing inputs. Missing data is simulated at test time by masking inputs randomly. Using area under the receiver operating curve (AUC) as a metric, DFCN outperforms all other models with statistical significance using random subsets of input data with 2-27 available inputs. When all 28 inputs are available DFCN obtains an AUC of 0.924, higher than achieved by any other model. Furthermore, with clinically meaningful subsets of parameters consisting of just 6 and 7 inputs respectively, DFCN also achieves higher AUCs than any other model, with values of 0.909 and 0.919.      
### 11.Multi-Objective $H_{\infty}$ Control for String Stability of Cooperative Adaptive Cruise Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13830.pdf)
>  Autonomous vehicle following systems are playing a decisive role to increase vehicle density on roads by shortening inter-vehicle time gaps. However, disturbance attenuation along a platoon of vehicles, i.e., string stability, is being a challenging task while time gap is getting shorter. In order to guarantee the string stability of a vehicle platoon, a multi-objective $H_{\infty}$ control formulation for adaptive cruise control and cooperative adaptive cruise control structures has been investigated in this paper. The proposed control method solves an optimization problem and achieves a controller that is able to provide not only the system stability, but also the string stability as distinct from the traditional $H_{\infty}$ control.      
### 12.Prototyping and Evaluation of Infrastructure-Assisted Transition of Control for Cooperative Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.13826.pdf)
>  Automated driving is now possible in diverse road and traffic conditions. However, there are still situations that automated vehicles cannot handle safely and efficiently. In this case, a Transition of Control (ToC) is necessary so that the driver takes control of the driving. Executing a ToC requires the driver to get full situation awareness of the driving environment. If the driver fails to get back the control in a limited time, a Minimum Risk Maneuver (MRM) is executed to bring the vehicle into a safe state (e.g., decelerating to full stop). The execution of ToCs requires some time and can cause traffic disruption and safety risks that increase if several vehicles execute ToCs/MRMs at similar times and in the same area. This study proposes to use novel C-ITS traffic management measures where the infrastructure exploits V2X communications to assist Connected and Automated Vehicles (CAVs) in the execution of ToCs. The infrastructure can suggest a spatial distribution of ToCs, and inform vehicles of the locations where they could execute a safe stop in case of MRM. This paper reports the first field operational tests that validate the feasibility and quantify the benefits of the proposed infrastructure-assisted ToC and MRM management. The paper also presents the CAV and roadside infrastructure prototypes implemented and used in the trials. The conducted field trials demonstrate that infrastructure-assisted traffic management solutions can reduce safety risks and traffic disruptions.      
### 13.Experimental Validation of Linear and Nonlinear MPC on an Articulated Unmanned Ground Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2103.13800.pdf)
>  This paper focuses on the trajectory tracking control problem for an articulated unmanned ground vehicle. We propose and compare two approaches in terms of performance and computational complexity. The first uses a nonlinear mathematical model derived from first principles and combines a nonlinear model predictive controller (NMPC) with a nonlinear moving horizon estimator (NMHE) to produce a control strategy. The second is based on an input-state linearization (ISL) of the original model followed by linear model predictive control (LMPC). A fast real-time iteration scheme is proposed, implemented for the NMHE-NMPC framework and benchmarked against the ISL-LMPC framework, which is a traditional and cheap method. The experimental results for a time-based trajectory show that the NMHE-NMPC framework with the proposed real-time iteration scheme gives better trajectory tracking performance than the ISL-LMPC framework and the required computation time is feasible for real-time applications. Moreover, the ISL-LMPC produces results of a quality comparable to the NMHE-NMPC framework at a significantly reduced computational cost.      
### 14.An Intelligent Bed Sensor System for Non-Contact Respiratory Rate Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2103.13792.pdf)
>  We present an IoT-based intelligent bed sensor system that collects and analyses respiration-associated signals for unobtrusive monitoring in the home, hospitals and care units. A contactless device is used, which contains four load sensors mounted under the bed and one data processing unit (data logger). Various machine learning methods are applied to the data streamed from the data logger to detect the Respiratory Rate (RR). We have implemented Support Vector Machine (SVM) and also Neural Network (NN)-based pattern recognition methods, which are combined with either peak detection or Hilbert transform for robust RR calculation. Experimental results show that our methods could effectively extract RR using the data collected by contactless bed sensors. The proposed methods are robust to outliers and noise, which are caused by body movements. The monitoring system provides a flexible and scalable way for continuous and remote monitoring of sleep, movement and weight using the embedded sensors.      
### 15.AoA-Based Pilot Assignment in Massive MIMO Systems Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.13791.pdf)
>  In this paper, the problem of pilot contamination in a multi-cell massive multiple input multiple output (M-MIMO) system is addressed using deep reinforcement learning (DRL). To this end, a pilot assignment strategy is designed that adapts to the channel variations while maintaining a tolerable pilot contamination effect. Using the angle of arrival (AoA) information of the users, a cost function, portraying the reward, is presented, defining the pilot contamination effects in the system. Numerical results illustrate that the DRL-based scheme is able to track the changes in the environment, learn the near-optimal pilot assignment, and achieve a close performance to that of the optimum pilot assignment performed by exhaustive search, while maintaining a low computational complexity.      
### 16.Shaping oscillations via mixed feedback  [ :arrow_down: ](https://arxiv.org/pdf/2103.13790.pdf)
>  We study the problem of controlling oscillations in closed loop by combining positive and negative feedback in a mixed configuration. We develop a complete design procedure to set the relative strength of the two feedback loops to achieve steady oscillations. The proposed design takes advantage of dominance theory and adopts classical harmonic balance and fast/slow analysis to regulate the frequency of oscillations. The design is illustrated on a simple two-mass system, a setting that reveals the potential of the approach for locomotion, mimicking approaches based on central pattern generators.      
### 17.Statistical Modeling of the Human Body as an Extended Antenna  [ :arrow_down: ](https://arxiv.org/pdf/2103.13747.pdf)
>  In this paper we investigate the possibility of modeling a single antenna alone and in close proximity to a physical object by means of discrete point source scatterers. The scatter point model allows joint modeling of a physical antenna and the human body as a single extended object with direction dependent scattering coefficients for the scatter points. We introduce the term extended antenna describing antenna and human body together. To investigate the identifiability of the model parameters we make use of ultrawideband channel measurements and accurate ground truth position and orientation measurements obtained with an optical tracking system. By comparing measurements of the antenna attached directly to the user with measurements for the antenna without the user nearby, we show the shadowing and scattering effects of the human body and the antenna.      
### 18.Verifying Compositional Refinement of Assume/Guarantee Contracts using Linear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2103.13743.pdf)
>  Verifying specifications for large-scale modern engineering systems can be a time-consuming task, as most formal verification methods are limited to systems of modest size. Recently, contract-based design and verification has been proposed as a modular framework for specifications, and linear-programming-based techniques have been presented for verifying that a given system satisfies a given contract. In this paper, we extend this assume/guarantee framework by presenting necessary and sufficient conditions for a collection of contracts on individual components to refine a contract on the composed system. These conditions can be verified by solving linear programs, whose number grows linearly with the number of specifications defined by the contracts. We exemplify the tools developed using a case study considering safety in a car-following scenario, where noise and time-varying delay are considered.      
### 19.Distributed DoS Attack Detection in SDN: Trade offs in Resource Constrained Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.13705.pdf)
>  The Software-defined networking(SDN) paradigm centralizes control decisions to improve programmability and simplify network management. However, this centralization turns the network vulnerable to denial of service (DoS) attacks, and in the case of resource constrained networks, the vulnerabilities escalate. The main shortcoming in current security solutions is the trade off between detection rate and complexity. In this work, we propose a DoS attack detection algorithm for SDN resource constrained networks, based on recent results on non-parametric real-time change point detection, and lightweight enough to run on individual resource constrained devices. Our experiment results show detection rates and attacker identification probabilities equal or over 0.93.      
### 20.Decentralized Coordination Between Economic Dispatch and Demand Response in Multi-Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13680.pdf)
>  In this paper, we investigate the problem of coor?dination between economic dispatch (ED) and demand response (DR) in multi-energy systems (MESs), aiming to improve the economic utility and reduce the waste of energy in MESs. Since multiple energy sources are coupled through energy hubs (EHs), the supply-demand constraints are nonconvex. To deal with this issue, we propose a linearization method to transform the coordination problem to a convex social welfare optimization one. Then a decentralized algorithm based on parallel Alternating Direction Method of Multipliers (ADMM) and dynamic average tracking protocol is developed, where each agent could only make decisions based on information from their neighbors. Moreover, by using variational inequality and Lyapunov-based techniques, we show that our algorithm could always converge to the global optimal solution. Finally, a case study on the modified IEEE 14-bus network verifies the feasibility and effectiveness of our algorithm.      
### 21.Explainability Guided Multi-Site COVID-19 CT Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.13677.pdf)
>  Radiologist examination of chest CT is an effective way for screening COVID-19 cases. In this work, we overcome three challenges in the automation of this process: (i) the limited number of supervised positive cases, (ii) the lack of region-based supervision, and (iii) the variability across acquisition sites. These challenges are met by incorporating a recent augmentation solution called SnapMix, by a new patch embedding technique, and by performing a test-time stability analysis. The three techniques are complementary and are all based on utilizing the heatmaps produced by the Class Activation Mapping (CAM) explainability method. Compared to the current state of the art, we obtain an increase of five percent in the F1 score on a site with a relatively high number of cases, and a gap twice as large for a site with much fewer training images.      
### 22.Actuator Fault-Tolerant Vehicle Motion Control: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2103.13671.pdf)
>  The advent of automated vehicles operating at SAE levels 4 and 5 poses high fault tolerance demands for all functions contributing to the driving task. At the actuator level, fault-tolerant vehicle motion control, which exploits functional redundancies among the actuators, is one means to achieve the required degree of fault tolerance. Therefore, we give a comprehensive overview of the state of the art in actuator fault-tolerant vehicle motion control with a focus on drive, brake, and steering degradations, as well as tire blowouts. This review shows that actuator fault-tolerant vehicle motion is a widely studied field; yet, the presented approaches differ with respect to many aspects. To provide a starting point for future research, we survey the employed actuator topologies, the tolerated degradations, the presented control approaches, as well as the experiments conducted for validation. Overall, and despite the large number of different approaches, the covered literature reveals the potential of increasing fault tolerance by fault-tolerant vehicle motion control. Thus, besides developing novel approaches or demonstrating real-time applicability, future research should aim at investigating limitations and enabling comparison of fault-tolerant motion control approaches in order to allow for a thorough safety argumentation.      
### 23.Closing the Loop: Joint Rain Generation and Removal via Disentangled Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2103.13660.pdf)
>  Existing deep learning-based image deraining methods have achieved promising performance for synthetic rainy images, typically rely on the pairs of sharp images and simulated rainy counterparts. However, these methods suffer from significant performance drop when facing the real rain, because of the huge gap between the simplified synthetic rain and the complex real rain. In this work, we argue that the rain generation and removal are the two sides of the same coin and should be tightly coupled. To close the loop, we propose to jointly learn real rain generation and removal procedure within a unified disentangled image translation framework. Specifically, we propose a bidirectional disentangled translation network, in which each unidirectional network contains two loops of joint rain generation and removal for both the real and synthetic rain image, respectively. Meanwhile, we enforce the disentanglement strategy by decomposing the rainy image into a clean background and rain layer (rain removal), in order to better preserve the identity background via both the cycle-consistency loss and adversarial loss, and ease the rain layer translating between the real and synthetic rainy image. A counterpart composition with the entanglement strategy is symmetrically applied for rain generation. Extensive experiments on synthetic and real-world rain datasets show the superiority of proposed method compared to state-of-the-arts.      
### 24.A Comprehensive Review of Image Analysis Methods for Microorganism Counting: From Classical Image Processing to Deep Learning Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2103.13625.pdf)
>  Microorganisms such as bacteria and fungi play essential roles in many application fields, like biotechnique, medical technique and industrial domain. Microorganism counting techniques are crucial in microorganism analysis, helping biologists and related researchers quantitatively analyze the microorganisms and calculate their characteristics, such as biomass concentration and biological activity. However, traditional microorganism manual counting methods are time consuming and subjective, which cannot be applied in large-scale applications. In order to improve this situation, image analysis-based microorganism counting systems are developed since 1980s, which consists of digital image processing, image segmentation, image classification and so on. Moreover, image analysis-based microorganism counting methods are efficient comparing with traditional plate counting methods. In this article, we have studied the development of microorganism counting methods using digital image analysis. Firstly, the microorganisms are grouped as bacteria and other microorganisms. Then, the related articles are summarized based on image segmentation methods. Each part of articles are reviewed by time periods. Moreover, commonly used image processing methods for microorganism counting are summarized and analyzed to find technological common points. More than 142 papers are summarized in this article. In conclusion, this article can be referred to researchers to determine the development trend in microorganism counting field and further analyze the potential applications      
### 25.Contextual Information Enhanced Convolutional Neural Networks for Retinal Vessel Segmentation in Color Fundus Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.13622.pdf)
>  Accurate retinal vessel segmentation is a challenging problem in color fundus image analysis. An automatic retinal vessel segmentation system can effectively facilitate clinical diagnosis and ophthalmological research. Technically, this problem suffers from various degrees of vessel thickness, perception of details, and contextual feature fusion. For addressing these challenges, a deep learning based method has been proposed and several customized modules have been integrated into the well-known encoder-decoder architecture U-net, which is mainly employed in medical image segmentation. Structurally, cascaded dilated convolutional modules have been integrated into the intermediate layers, for obtaining larger receptive field and generating denser encoded feature maps. Also, the advantages of the pyramid module with spatial continuity have been taken, for multi-thickness perception, detail refinement, and contextual feature fusion. Additionally, the effectiveness of different normalization approaches has been discussed in network training for different datasets with specific properties. Experimentally, sufficient comparative experiments have been enforced on three retinal vessel segmentation datasets, DRIVE, CHASEDB1, and the unhealthy dataset STARE. As a result, the proposed method outperforms the work of predecessors and achieves state-of-the-art performance in Sensitivity/Recall, F1-score and MCC.      
### 26.Artificial Intelligence in Tumor Subregion Analysis Based on Medical Imaging: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2103.13588.pdf)
>  Medical imaging is widely used in cancer diagnosis and treatment, and artificial intelligence (AI) has achieved tremendous success in various tasks of medical image analysis. This paper reviews AI-based tumor subregion analysis in medical imaging. We summarize the latest AI-based methods for tumor subregion analysis and their applications. Specifically, we categorize the AI-based methods by training strategy: supervised and unsupervised. A detailed review of each category is presented, highlighting important contributions and achievements. Specific challenges and potential AI applications in tumor subregion analysis are discussed.      
### 27.EfficientTDNN: Efficient Architecture Search for Speaker Recognition in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2103.13581.pdf)
>  Speaker recognition refers to audio biometrics that utilizes acoustic characteristics for automatic speaker recognition. These systems have emerged as an essential means of verifying identity in various scenarios, such as smart homes, general business interactions, e-commerce applications, and forensics. However, the mismatch between training and real-world data causes a shift of speaker embedding space and severely degrades the recognition performance. Various complicated neural architectures are presented to address speaker recognition in the wild but neglect the requirements of storage and computation. To address this issue, we propose a neural architecture search-based efficient time-delay neural network (EfficientTDNN) to improve inference efficiency while maintaining recognition accuracy. The proposed EfficientTDNN contains three phases. First, supernet design is to construct a dynamic neural architecture that consists of sequential cells and enables network pruning. Second, progressive training is to optimize randomly sampled subnets that inherit the weights of the supernet. Third, three search methods, including manual grid search, random search, and model predictive evolutionary search, are introduced to find a trade-off between accuracy and efficiency. Results of experiments on the VoxCeleb dataset show EfficientTDNN provides a huge search space including approximately $10^{13}$ subnets and achieves 1.66% EER and 0.156 DCF$_{0.01}$ with 565M MACs. Comprehensive investigation suggests that the trained supernet generalizes cells unseen during training and obtains an acceptable balance between accuracy and efficiency.      
### 28.CHIMERA: A Hybrid Estimation Approach to Limit the Effects of False Data Injection Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2103.13568.pdf)
>  The reliable operation of the electric power systems is supported by energy management systems (EMS) that provide monitoring and control functionalities. Contingency analysis is a critical application of EMS to evaluate the impacts of outage events based on the grid state variables, and allow system operators to prepare for potential system failures. However, false data injection attacks (FDIAs) against state estimation have demonstrated the possibility of compromising sensor measurements and consequently falsifying the estimated power system states. As a result, FDIAs may mislead the system operations and other EMS applications including contingency analysis and optimal power flow routines. In this paper, we assess the effect of FDIAs on contingency analysis and demonstrate that such attacks can affect the resulted number of contingencies in power systems. In order to mitigate the FDIA impact on contingency analysis algorithms, we propose CHIMERA, a hybrid attack-resilient state estimation approach that integrates model-based and data-driven methods. CHIMERA combines the physical grid information with a Long Short Term Memory (LSTM)-based deep learning model by considering a static loss of weighted least square errors and a dynamic loss of the difference between the temporal variations of the actual and the estimated active power. Our simulation experiments based on the load data from New York state demonstrate that CHIMERA can effectively mitigate 91.74% of the attack cases in which FDIAs can maliciously modify the contingency results.      
### 29.Task-Oriented Low-Dose CT Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2103.13557.pdf)
>  The extensive use of medical CT has raised a public concern over the radiation dose to the patient. Reducing the radiation dose leads to increased CT image noise and artifacts, which can adversely affect not only the radiologists judgement but also the performance of downstream medical image analysis tasks. Various low-dose CT denoising methods, especially the recent deep learning based approaches, have produced impressive results. However, the existing denoising methods are all downstream-task-agnostic and neglect the diverse needs of the downstream applications. In this paper, we introduce a novel Task-Oriented Denoising Network (TOD-Net) with a task-oriented loss leveraging knowledge from the downstream tasks. Comprehensive empirical analysis shows that the task-oriented loss complements other task agnostic losses by steering the denoiser to enhance the image quality in the task related regions of interest. Such enhancement in turn brings general boosts on the performance of various methods for the downstream task. The presented work may shed light on the future development of context-aware image denoising methods.      
### 30.Nocturnal Seizure Detection Using Off-the-Shelf WiFi  [ :arrow_down: ](https://arxiv.org/pdf/2103.13556.pdf)
>  Detection of nocturnal seizures in epilepsy patients is essential, both for the quick management of the seizure complications, and for the assessment of the ongoing seizure treatment. Traditional seizure detection products (e.g., wearables), however, are either very costly, uncomfortable, or unreliable. In this paper, we then propose to utilize everyday WiFi signals for robust, fast, and non-invasive detection of nocturnal seizures. We first present a new and rigorous mathematical characterization for the spectral content/bandwidth of the WiFi signal, measured on a WiFi device placed near a sleeping patient, during different kinds of sleep motions: seizures, normal movements (e.g. posture adjustments), and breathing. Based on this mathematical modeling, we propose a novel pipeline for processing the received WiFi signals to robustly detect all nocturnal non-breathing movements, and then classify them into normal body movements or seizures. In order to validate this, we carry out extensive experiments in 7 different typical bedroom locations, where a set of 20 actors simulate the state of having seizures (total of 260 instances), as well as normal sleep movements (total of 410 instances). Our proposed system detects 93.85% of the seizures with a mean response time of only 5.69 seconds since the onset of the seizure. Moreover, our proposed system achieves a probability of false alarm of only 0.0097, when classifying normal sleep movements. Overall, our new mathematical modeling and experimental results show the great potential the ubiquitous WiFi signals have for detecting nocturnal seizures, which can provide better support for epilepsy patients and their caregivers.      
### 31.Constrained Deep Learning-based Model Predictive Control with Improved Constraint Satisfaction  [ :arrow_down: ](https://arxiv.org/pdf/2103.13514.pdf)
>  Machine learning technique can help reduce computational cost of model predictive control (MPC). In this paper, a constrained deep neural networks design is proposed to learn and construct MPC policies for nonlinear input affine dynamic systems. Using constrained training of neural networks helps enforce MPC constraints effectively. We show the asymptotic stability of the learned policies. Additionally, different data sampling strategies are compared in terms of their generalization errors on the learned policy. Furthermore, probabilistic feasibility and optimality guarantees are provided for the learned control policy. The proposed algorithm is implemented on a rotary inverted pendulum experimentally and control performance is demonstrated and compared with the exact MPC and the normally trained learning MPC. The results show that the proposed algorithm improves constraint satisfaction while preserves computational efficiency of the learned policy.      
### 32.Ripple-Type Control for Enhancing Resilience of Networked Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13505.pdf)
>  Distributed control agents have been advocated as an effective means for improving the resiliency of our physical infrastructures under unexpected events. Purely local control has been shown to be insufficient, centralized optimal resource allocation approaches can be slow. In this context, we put forth a hybrid low-communication saturation-driven protocol for the coordination of control agents that are distributed over a physical system and are allowed to communicate with peers over a "hotline" communication network. According to this protocol, agents act on local readings unless their control resources have been depleted, in which case they send a beacon for assistance to peer agents. Our ripple-type scheme triggers communication locally only for the agents with saturated resources and it is proved to converge. Moreover, under a monotonicity assumption on the underlying physical law coupling control outputs to inputs, the devised control is proved to converge to a configuration satisfying safe operational constraints. The assumption is shown to hold for voltage control in electric power systems and pressure control in water distribution networks. Numerical tests corroborate the efficacy of the novel scheme.      
### 33.3D Reasoning for Unsupervised Anomaly Detection in Pediatric WbMRI  [ :arrow_down: ](https://arxiv.org/pdf/2103.13497.pdf)
>  Modern deep unsupervised learning methods have shown great promise for detecting diseases across a variety of medical imaging modalities. While previous generative modeling approaches successfully perform anomaly detection by learning the distribution of healthy 2D image slices, they process such slices independently and ignore the fact that they are correlated, all being sampled from a 3D volume. We show that incorporating the 3D context and processing whole-body MRI volumes is beneficial to distinguishing anomalies from their benign counterparts. In our work, we introduce a multi-channel sliding window generative model to perform lesion detection in whole-body MRI (wbMRI). Our experiments demonstrate that our proposed method significantly outperforms processing individual images in isolation and our ablations clearly show the importance of 3D reasoning. Moreover, our work also shows that it is beneficial to include additional patient-specific features to further improve anomaly detection in pediatric scans.      
### 34.Distributed Newton-like Algorithms and Learning for Optimized Power Dispatch  [ :arrow_down: ](https://arxiv.org/pdf/2103.13493.pdf)
>  This thesis explores a particular class of distributed optimization methods for various separable resource allocation problems, which are of high interest in a wide array of multi-agent settings. A distinctly motivating application for this thesis is real-time power dispatch of distributed energy resources for providing frequency control in a distribution grid or microgrid with high renewable energy penetration. In this application, it is paramount that agent data be shared as sparsely as possible in the interest of conserving user privacy, and it is required that algorithms scale gracefully as the network size increases to the order of thousands or millions of resources and devices. Distributed algorithms are naturally well-poised to address these challenges, in contrast to more traditional centralized algorithms which scale poorly and require global access to information. <br>The class of distributed optimization methods explored here can be broadly described as Newton-like or second-order, implying utilization of second-derivative information of the cost functions, in contrast to well-studied gradient-based or first-order methods. We consider three formulations of separable resource-allocation problems and develop a Newton-like algorithm for each. The analysis and simulation studies in the subsequent chapters demonstrate the advantages of our approaches over existing methods; most commonly, we note that convergence rates are substantially improved. We supplement our algorithm development for these three problem formulations with a network design technique, in which we can construct a maximally-connected network by adding some edges to the underlying communication graph, and a real demonstration of distributed algorithms on a large set of heterogeneous devices on the UC San Diego microgrid.      
### 35.Feature Weighted Non-negative Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2103.13491.pdf)
>  Non-negative Matrix Factorization (NMF) is one of the most popular techniques for data representation and clustering, and has been widely used in machine learning and data analysis. NMF concentrates the features of each sample into a vector, and approximates it by the linear combination of basis vectors, such that the low-dimensional representations are achieved. However, in real-world applications, the features are usually with different importances. To exploit the discriminative features, some methods project the samples into the subspace with a transformation matrix, which disturbs the original feature attributes and neglects the diversity of samples. To alleviate the above problems, we propose the Feature weighted Non-negative Matrix Factorization (FNMF) in this paper. The salient properties of FNMF can be summarized as threefold: 1) it learns the weights of features adaptively according to their importances; 2) it utilizes multiple feature weighting components to preserve the diversity; 3) it can be solved efficiently with the suggested optimization algorithm. Performance on synthetic and real-world datasets demonstrate that the proposed method obtains the state-of-the-art performance.      
### 36.Entropy Minimizing Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2103.13487.pdf)
>  Nonnegative Matrix Factorization (NMF) is a widely-used data analysis technique, and has yielded impressive results in many real-world tasks. Generally, existing NMF methods represent each sample with several centroids, and find the optimal centroids by minimizing the sum of the approximation errors. However, the outliers deviating from the normal data distribution may have large residues, and then dominate the objective value seriously. In this study, an Entropy Minimizing Matrix Factorization framework (EMMF) is developed to tackle the above problem. Considering that the outliers are usually much less than the normal samples, a new entropy loss function is established for matrix factorization, which minimizes the entropy of the residue distribution and allows a few samples to have large approximation errors. In this way, the outliers do not affect the approximation of the normal samples. The multiplicative updating rules for EMMF are also designed, and the convergence is proved both theoretically and experimentally. In addition, a Graph regularized version of EMMF (G-EMMF) is also presented to deal with the complex data structure. Clustering results on various synthetic and real-world datasets demonstrate the reasonableness of the proposed models, and the effectiveness is also verified through the comparison with the state-of-the-arts.      
### 37.Detection of sub-cellular changes by use of $Î»=6.5$ micron laser light interaction in association with Intelligent Laser Speckle Classification (ILSC) technique  [ :arrow_down: ](https://arxiv.org/pdf/2103.13484.pdf)
>  The study is based on a principle of laser physics so that a (coherent) laser light whose wavelength is shorter than a feature under inspection (like sub-cellular component) can interact with such specific feature (or textural features) and generates laser speckle patterns which can characterize those specific features. By the method we have managed to detect differences at sub-cellular scales such as genetic modification, cellular shape deformation, etc. with 87% accuracy. In this study red laser is used whose wavelength (6.5 microns) is shorter than a plant cell (~60 microns) that is suitable to interact with sub-cellular features. The work is assumed to be an initial stage of further application on human cellular changes observation that would be utilized for development of more accurate methods such as better drug delivery assessments, systemic diseases early diagnosis, etc.      
### 38.Semi-Supervised Learning for Bone Mineral Density Estimation in Hip X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.13482.pdf)
>  Bone mineral density (BMD) is a clinically critical indicator of osteoporosis, usually measured by dual-energy X-ray absorptiometry (DEXA). Due to the limited accessibility of DEXA machines and examinations, osteoporosis is often under-diagnosed and under-treated, leading to increased fragility fracture risks. Thus it is highly desirable to obtain BMDs with alternative cost-effective and more accessible medical imaging examinations such as X-ray plain films. In this work, we formulate the BMD estimation from plain hip X-ray images as a regression problem. Specifically, we propose a new semi-supervised self-training algorithm to train the BMD regression model using images coupled with DEXA measured BMDs and unlabeled images with pseudo BMDs. Pseudo BMDs are generated and refined iteratively for unlabeled images during self-training. We also present a novel adaptive triplet loss to improve the model's regression accuracy. On an in-house dataset of 1,090 images (819 unique patients), our BMD estimation method achieves a high Pearson correlation coefficient of 0.8805 to ground-truth BMDs. It offers good feasibility to use the more accessible and cheaper X-ray imaging for opportunistic osteoporosis screening.      
### 39.A High-Gain Observer Approach to Robust Trajectory Estimation and Tracking for a Multi-rotor UAV  [ :arrow_down: ](https://arxiv.org/pdf/2103.13429.pdf)
>  We study the problem of estimating and tracking an unknown trajectory with a multi-rotor UAV in the presence of modeling error and external disturbances. The reference trajectory is unknown and generated from a reference system with unknown or partially known dynamics. We assume the only measurements that are available are the position and orientation of the multi-rotor and the position of the reference system. We adopt an extended high-gain observer (EHGO) estimation framework to estimate the unmeasured multi-rotor states, modeling error, external disturbances, and the reference trajectory. We design a robust output feedback controller for trajectory tracking that comprises a feedback linearizing controller and the EHGO. The proposed control method is rigorously analyzed to establish its stability properties. Finally, we illustrate our theoretical results through numerical simulation and experimental validation in which a multi-rotor tracks a moving ground vehicle with unknown trajectory and dynamics and successfully lands on the vehicle while in motion.      
### 40.Collision-Free MPC for Legged Robots in Static and Dynamic Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2103.13987.pdf)
>  We present a model predictive controller (MPC) that automatically discovers collision-free locomotion while simultaneously taking into account the system dynamics, friction constraints, and kinematic limitations. A relaxed barrier function is added to the optimization's cost function, leading to collision avoidance behavior without increasing the problem's computational complexity. Our holistic approach does not require any heuristics and enables legged robots to find whole-body motions in the presence of static and dynamic obstacles. We use a dynamically generated euclidean signed distance field for static collision checking. Collision checking for dynamic obstacles is modeled with moving cylinders, increasing the responsiveness to fast-moving agents. Furthermore, we include a Kalman filter motion prediction for moving obstacles into our receding horizon planning, enabling the robot to anticipate possible future collisions. Our experiments demonstrate collision-free motions on a quadrupedal robot in challenging indoor environments. The robot handles complex scenes like overhanging obstacles and dynamic agents by exploring motions at the robot's dynamic and kinematic limits.      
### 41.Estimation of Closest In-Path Vehicle (CIPV) by Low-Channel LiDAR and Camera Sensor Fusion for Autonomous Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2103.13952.pdf)
>  In autonomous driving, using a variety of sensors to recognize preceding vehicles in middle and long distance is helpful for improving driving performance and developing various functions. However, if only LiDAR or camera is used in the recognition stage, it is difficult to obtain necessary data due to the limitations of each sensor. In this paper, we proposed a method of converting the tracking data of vision into bird's eye view (BEV) coordinates using an equation that projects LiDAR points onto an image, and a method of fusion between LiDAR and vision tracked data. Thus, the newly proposed method was effective through the results of detecting closest in-path vehicle (CIPV) in various situations. In addition, even when experimenting with the EuroNCAP autonomous emergency braking (AEB) test protocol using the result of fusion, AEB performance is improved through improved cognitive performance than when using only LiDAR. In experimental results, the performance of the proposed method was proved through actual vehicle tests in various scenarios. Consequently, it is convincing that the newly proposed sensor fusion method significantly improves the ACC function in autonomous maneuvering. We expect that this improvement in perception performance will contribute to improving the overall stability of ACC.      
### 42.Data-driven Aerodynamic Analysis of Structures using Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.13877.pdf)
>  An abundant amount of data gathered during wind tunnel testing and health monitoring of structures inspires the use of machine learning methods to replicate the wind forces. These forces are critical for both the design and life-cycle assessment of lifeline structures such as bridges. This paper presents a data-driven Gaussian Process-Nonlinear Finite Impulse Response (GP-NFIR) model of the nonlinear self-excited forces acting on bridges. Constructed in a nondimensional form, the model takes the effective wind angle of attack as lagged exogenous input and outputs a probability distribution of the aerodynamic forces. The nonlinear latent function, mapping the input to the output, is modeled by a GP regression. Consequently, the model is nonparametric, and as such, it avoids setting up the latent function's structure a priori. The training input is designed as band-limited random harmonic motion that consists of vertical and rotational displacements. Once trained, the model can predict the aerodynamic forces for both prescribed input motion and coupled aeroelastic analysis. The presented concept is first verified for a flat plate's analytical, linear solution by predicting the self-excited forces and flutter velocity. Finally, the framework is applied to a streamlined and bluff bridge deck based on Computational Fluid Dynamics (CFD) data. Here, the model's ability to predict nonlinear aerodynamic forces, critical flutter limit, and post-flutter behavior are highlighted. Further applications of the presented framework are foreseen in the design and online real-time monitoring of slender line-like structures.      
### 43.Generative-Adversarial-Networks-based Ghost Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.13858.pdf)
>  Nowadays, target recognition technique plays an important role in many fields. However, the existing image information based methods suffer from the influence of target image quality. In addition, some methods also need image reconstruction, which will bring additional time cost. In this paper, we propose a novel coincidence recognition method combining ghost imaging (GI) and generative adversarial networks (GAN). Based on the mechanism of GI, a set of random speckles sequence is employed to illuminate target, and a bucket detector without resolution is utilized to receive echo signal. The bucket signal sequence formed after continuous detections is constructed into a bucket signal array, which is regarded as the sample of GAN. Then, conditional GAN is used to map bucket signal array and target category. In practical application, the speckles sequence in training step is still employed to illuminate target, and the bucket signal array is input GAN for recognition. The proposed method can improve the problems caused by existing recognition methods that based on image information, and provide a certain turbulence-free ability. Extensive experiments are show that the proposed method achieves promising performance.      
### 44.Searching for waveforms on spatially-filtered epileptic ECoG  [ :arrow_down: ](https://arxiv.org/pdf/2103.13853.pdf)
>  Seizures are one of the defining symptoms in patients with epilepsy, and due to their unannounced occurrence, they can pose a severe risk for the individual that suffers it. New research efforts are showing a promising future for the prediction and preemption of imminent seizures, and with those efforts, a vast and diverse set of features have been proposed for seizure prediction algorithms. However, the data-driven discovery of nonsinusoidal waveforms for seizure prediction is lacking in the literature, which is in stark contrast with recent works that show the close connection between the waveform morphology of neural oscillations and the physiology and pathophysiology of the brain, and especially its use in effectively discriminating between normal and abnormal oscillations in electrocorticographic (ECoG) recordings of epileptic patients. Here, we explore a scalable, energy-guided waveform search strategy on spatially-projected continuous multi-day ECoG data sets. Our work shows that data-driven waveform learning methods have the potential to not only contribute features with predictive power for seizure prediction, but also to facilitate the discovery of oscillatory patterns that could contribute to our understanding of the pathophysiology and etiology of seizures.      
### 45.Characterization and computation of control invariant sets within target regions for linear impulsive control systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13831.pdf)
>  Linear impulsively controlled systems are suitable to describe a venue of real-life problems, going from disease treatment to aerospace guidance. The main characteristic of such systems is that they remain uncontrolled for certain periods of time. As a consequence, punctual equilibria characterizations outside the origin are no longer useful, and the whole concept of equilibrium and its natural extension, the controlled invariant sets, needs to be redefined. Also, an exact characterization of the admissible states, i.e., states such that their uncontrolled evolution between impulse times remain within a predefined set, is required. An approach to such tasks -- based on the Markov-Lukasz theorem -- is presented, providing a tractable and non-conservative characterization, emerging from polynomial positivity that has application to systems with rational eigenvalues. This is in turn the basis for obtaining a tractable approximation to the maximal admissible invariant sets. In this work, it is also demonstrated that, in order for the problem to have a solution, an invariant set (and moreover, an equilibrium set) must be contained within the target zone. To assess the proposal, the so-obtained impulsive invariant set is explicitly used in the formulation of a set-based model predictive controller, with application to zone tracking. In this context, specific MPC theory needs to be considered, as the target is not necessarily stable in the sense of Lyapunov. A zone MPC formulation is proposed, which is able to i) track an invariant set such that the uncontrolled propagation fulfills the zone constraint at all times and ii) converge asymptotically to the set of periodic orbits completely contained within the target zone.      
### 46.RA-BNN: Constructing Robust &amp; Accurate Binary Neural Network to Simultaneously Defend Adversarial Bit-Flip Attack and Improve Accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2103.13813.pdf)
>  Recently developed adversarial weight attack, a.k.a. bit-flip attack (BFA), has shown enormous success in compromising Deep Neural Network (DNN) performance with an extremely small amount of model parameter perturbation. To defend against this threat, we propose RA-BNN that adopts a complete binary (i.e., for both weights and activation) neural network (BNN) to significantly improve DNN model robustness (defined as the number of bit-flips required to degrade the accuracy to as low as a random guess). However, such an aggressive low bit-width model suffers from poor clean (i.e., no attack) inference accuracy. To counter this, we propose a novel and efficient two-stage network growing method, named Early-Growth. It selectively grows the channel size of each BNN layer based on channel-wise binary masks training with Gumbel-Sigmoid function. Apart from recovering the inference accuracy, our RA-BNN after growing also shows significantly higher resistance to BFA. Our evaluation of the CIFAR-10 dataset shows that the proposed RA-BNN can improve the clean model accuracy by ~2-8 %, compared with a baseline BNN, while simultaneously improving the resistance to BFA by more than 125 x. Moreover, on ImageNet, with a sufficiently large (e.g., 5,000) amount of bit-flips, the baseline BNN accuracy drops to 4.3 % from 51.9 %, while our RA-BNN accuracy only drops to 37.1 % from 60.9 % (9 % clean accuracy improvement).      
### 47.Multi-frame Super-resolution from Noisy Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.13778.pdf)
>  Obtaining high resolution images from low resolution data with clipped noise is algorithmically challenging due to the ill-posed nature of the problem. So far such problems have hardly been tackled, and the few existing approaches use simplistic regularisers. We show the usefulness of two adaptive regularisers based on anisotropic diffusion ideas: Apart from evaluating the classical edge-enhancing anisotropic diffusion regulariser, we introduce a novel non-local one with one-sided differences and superior performance. It is termed sector diffusion. We combine it with all six variants of the classical super-resolution observational model that arise from permutations of its three operators for warping, blurring, and downsampling. Surprisingly, the evaluation in a practically relevant noisy scenario produces a different ranking than the one in the noise-free setting in our previous work (SSVM 2017).      
### 48.JDSR-GAN: Constructing A Joint and Collaborative Learning Network for Masked Face Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.13676.pdf)
>  With the growing importance of preventing the COVID-19 virus, face images obtained in most video surveillance scenarios are low resolution with mask simultaneously. However, most of the previous face super-resolution solutions can not handle both tasks in one model. In this work, we treat the mask occlusion as image noise and construct a joint and collaborative learning network, called JDSR-GAN, for the masked face super-resolution task. Given a low-quality face image with the mask as input, the role of the generator composed of a denoising module and super-resolution module is to acquire a high-quality high-resolution face image. The discriminator utilizes some carefully designed loss functions to ensure the quality of the recovered face images. Moreover, we incorporate the identity information and attention mechanism into our network for feasible correlated feature expression and informative feature learning. By jointly performing denoising and face super-resolution, the two tasks can complement each other and attain promising performance. Extensive qualitative and quantitative results show the superiority of our proposed JDSR-GAN over some comparable methods which perform the previous two tasks separately.      
### 49.A General Approach to Robust Controller Analysis and Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2103.13650.pdf)
>  Robust controller synthesis attracts reviving research interest, driven by the rise of learning-based systems where uncertainty and perturbation are ubiquitous. Facing an uncertain situation, a robustly stabilizing controller should maintain stability while operating under a perturbed system deviating from its nominal specification. There have been numerous results for robust controller synthesis in multiple forms and with various goals, including mu-synthesis, robust primal-dual Youla, robust input-output, and robust system level parameterizations. However, their connections with one another are not clear, and we lack a general approach to robust controller analysis and synthesis. <br>To serve this purpose, we derive robust stability conditions for general systems and formulate the general robust controller synthesis problem. The conditions hinge on the realization-stability lemma, a recent analysis tool that unifies existing controller synthesis methods. Not only can the conditions infer a wide range of existing robust results, but they also lead to easier derivations of new ones. Together, we demonstrate the effectiveness of the conditions and provide a unified approach to robust controller analysis and synthesis.      
### 50.Modulated MPC for Arm Inductor-less MVDC MMC with Reduced Computational Burden  [ :arrow_down: ](https://arxiv.org/pdf/2103.13647.pdf)
>  A modulated model predictive controller is designed for an inductor-less modular multilevel converter targeting an MVDC solid-state transformer application. The underlying optimization problem is formulated such that a unique closed-form solution is derived from a highly accurate dynamic system model, which significantly reduces computation time. Unlike other closed-form methods, the proposed controller achieves inductor-less current control, has a reduced sampling speed enabled by a novel model-based circulating energy compensator, and does not require tuned PI controllers to generate current references. Simulation and experimental results demonstrate that the proposed controller achieves transient power flow control and steady state circulating energy control despite the low system inertia.      
### 51.Exploiting Class Similarity for Machine Learning with Confidence Labels and Projective Loss Functions  [ :arrow_down: ](https://arxiv.org/pdf/2103.13607.pdf)
>  Class labels used for machine learning are relatable to each other, with certain class labels being more similar to each other than others (e.g. images of cats and dogs are more similar to each other than those of cats and cars). Such similarity among classes is often the cause of poor model performance due to the models confusing between them. Current labeling techniques fail to explicitly capture such similarity information. In this paper, we instead exploit the similarity between classes by capturing the similarity information with our novel confidence labels. Confidence labels are probabilistic labels denoting the likelihood of similarity, or confusability, between the classes. Often even after models are trained to differentiate between classes in the feature space, the similar classes' latent space still remains clustered. We view this type of clustering as valuable information and exploit it with our novel projective loss functions. Our projective loss functions are designed to work with confidence labels with an ability to relax the loss penalty for errors that confuse similar classes. We use our approach to train neural networks with noisy labels, as we believe noisy labels are partly a result of confusability arising from class similarity. We show improved performance compared to the use of standard loss functions. We conduct a detailed analysis using the CIFAR-10 dataset and show our proposed methods' applicability to larger datasets, such as ImageNet and Food-101N.      
### 52.On the Convexity of Discrete Time Covariance Steering in Stochastic Linear Systems with Wasserstein Terminal Cost  [ :arrow_down: ](https://arxiv.org/pdf/2103.13579.pdf)
>  In this work, we analyze the properties of the solution to the covariance steering problem for discrete time Gaussian linear systems with a squared Wasserstein distance terminal cost. In our previous work, we have shown that by utilizing the state feedback control policy parametrization, this stochastic optimal control problem can be associated with a difference of convex functions program. Here, we revisit the same covariance control problem but this time we focus on the analysis of the problem. Specifically, we establish the existence of solutions to the optimization problem and derive the first and second order conditions for optimality. We provide analytic expressions for the gradient and the Hessian of the performance index by utilizing specialized tools from matrix calculus. Subsequently, we prove that the optimization problem always admits a global minimizer, and finally, we provide a sufficient condition for the performance index to be a strictly convex function (under the latter condition, the problem admits a unique global minimizer). In particular, we show that when the terminal state covariance is upper bounded, with respect to the LÃ¶wner partial order, by the covariance matrix of the desired terminal normal distribution, then our problem admits a unique global minimizing state feedback gain. The results of this paper set the stage for the development of specialized control design tools that exploit the structure of the solution to the covariance steering problem with a squared Wasserstein distance terminal cost.      
### 53.Test-Time Training for Deformable Multi-Scale Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2103.13578.pdf)
>  Registration is a fundamental task in medical robotics and is often a crucial step for many downstream tasks such as motion analysis, intra-operative tracking and image segmentation. Popular registration methods such as ANTs and NiftyReg optimize objective functions for each pair of images from scratch, which are time-consuming for 3D and sequential images with complex deformations. Recently, deep learning-based registration approaches such as VoxelMorph have been emerging and achieve competitive performance. In this work, we construct a test-time training for deep deformable image registration to improve the generalization ability of conventional learning-based registration model. We design multi-scale deep networks to consecutively model the residual deformations, which is effective for high variational deformations. Extensive experiments validate the effectiveness of multi-scale deep registration with test-time training based on Dice coefficient for image segmentation and mean square error (MSE), normalized local cross-correlation (NLCC) for tissue dense tracking tasks. Two videos are in <a class="link-external link-https" href="https://www.youtube.com/watch?v=NvLrCaqCiAE" rel="external noopener nofollow">this https URL</a> and <a class="link-external link-https" href="https://www.youtube.com/watch?v=pEA6ZmtTNuQ" rel="external noopener nofollow">this https URL</a>      
### 54.Pricing and Energy Trading in Peer-to-peer Zero Marginal-cost Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2103.13530.pdf)
>  Efforts to efficiently promote the participation of distributed energy resources in community microgrids require new approaches to energy markets and transactions in power systems. In this paper, we contribute to the promising approach of peer-to-peer (P2P) energy trading. We first formalize a centralized welfare maximization model of an economic dispatch with perfect information based on the value of consumption with zero marginal-cost energy. We characterize the optimal solution and corresponding price to serve as a reference for P2P approaches and show that the profit-maximizing strategy for individuals with storage in response to an optimal price is not unique. Second, we develop a novel P2P algorithm for negotiating energy trades based on iterative price and quantity offers that yields physically feasible and at least weakly Pareto-optimal outcomes. We prove that the P2P algorithm converges to the centralized solution in the case of two agents negotiating for a single period, demonstrate convergence for the multi-agent, multi-period case through a large set of random simulations, and analyze the effects of storage penetration on the solution.      
### 55.Machine Learning-based Automatic Graphene Detection with Color Correction for Optical Microscope Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.13495.pdf)
>  Graphene serves critical application and research purposes in various fields. However, fabricating high-quality and large quantities of graphene is time-consuming and it requires heavy human resource labor costs. In this paper, we propose a Machine Learning-based Automatic Graphene Detection Method with Color Correction (MLA-GDCC), a reliable and autonomous graphene detection from microscopic images. The MLA-GDCC includes a white balance (WB) to correct the color imbalance on the images, a modified U-Net and a support vector machine (SVM) to segment the graphene flakes. Considering the color shifts of the images caused by different cameras, we apply WB correction to correct the imbalance of the color pixels. A modified U-Net model, a convolutional neural network (CNN) architecture for fast and precise image segmentation, is introduced to segment the graphene flakes from the background. In order to improve the pixel-level accuracy, we implement a SVM after the modified U-Net model to separate the monolayer and bilayer graphene flakes. The MLA-GDCC achieves flake-level detection rates of 87.09% for monolayer and 90.41% for bilayer graphene, and the pixel-level accuracy of 99.27% for monolayer and 98.92% for bilayer graphene. MLA-GDCC not only achieves high detection rates of the graphene flakes but also speeds up the latency for the graphene detection process from hours to seconds.      
### 56.Meta-ViterbiNet: Online Meta-Learned Viterbi Equalization for Non-Stationary Channels  [ :arrow_down: ](https://arxiv.org/pdf/2103.13483.pdf)
>  Deep neural networks (DNNs) based digital receivers can potentially operate in complex environments. However, the dynamic nature of communication channels implies that in some scenarios, DNN-based receivers should be periodically retrained in order to track temporal variations in the channel conditions. To this aim, frequent transmissions of lengthy pilot sequences are generally required, at the cost of substantial overhead. In this work we propose a DNN-aided symbol detector, Meta-ViterbiNet, that tracks channel variations with reduced overhead by integrating three complementary techniques: 1) We leverage domain knowledge to implement a model-based/data-driven equalizer, ViterbiNet, that operates with a relatively small number of trainable parameters; 2) We tailor a meta-learning procedure to the symbol detection problem, optimizing the hyperparameters of the learning algorithm to facilitate rapid online adaptation; and 3) We adopt a decision-directed approach based on coded communications to enable online training with short-length pilot blocks. Numerical results demonstrate that Meta-ViterbiNet operates accurately in rapidly-varying channels, outperforming the previous best approach, based on ViterbiNet or conventional recurrent neural networks without meta-learning, by a margin of up to 0.6dB in bit error rate in various challenging scenarios.      
### 57.Time-Varying Optimization of Networked Systems with Human Preferences  [ :arrow_down: ](https://arxiv.org/pdf/2103.13470.pdf)
>  This paper considers a time-varying optimization problem associated with a network of systems, with each of the systems shared by (and affecting) a number of individuals. The objective is to minimize cost functions associated with the individuals' preferences, which are unknown, subject to time-varying constraints that capture physical or operational limits of the network. To this end, the paper develops a distributed online optimization algorithm with concurrent learning of the cost functions. The cost functions are learned on-the-fly based on the users' feedback (provided at irregular intervals) by leveraging tools from shape-constrained Gaussian Processes. The online algorithm is based on a primal-dual method, and acts effectively in a closed-loop fashion where: i) users' feedback is utilized to estimate the cost, and ii) measurements from the network are utilized in the algorithmic steps to bypass the need for sensing of (unknown) exogenous inputs of the network. The performance of the algorithm is analyzed in terms of dynamic network regret and constraint violation. Numerical examples are presented in the context of real-time optimization of distributed energy resources.      
### 58.High-Frequency Electromagnetic Waves on Unshielded Twisted Pairs: Upper Bound on Carrier Frequency  [ :arrow_down: ](https://arxiv.org/pdf/2103.13463.pdf)
>  This paper explores the behaviour of the ubiquitous twisted pairs at high frequencies and wideband excitation of twisted pairs up to 12GHz. Although there is a large quantity of papers on twisted pairs, the papers in the literature mostly focus on the sub-1GHz spectrum, where the current digital subscriber line technologies operate. Higher carrier frequencies on twisted pairs can enable the data rates required by the future communication networks; hence, the existing copper infrastructure can be utilised on the last mile complementing the fibre networks. Towards this objective, we derive analytical expression for the electromagnetic fields and characteristic equation of twisted pairs. With these derivations we show a fundamental limit on the operating frequency of twisted pairs beyond which twisted pairs start to radiate and behave like an antenna. To validate our theory through measurements, we designed a microstrip balun in order to excite the differential mode on the twisted pairs. Unlike off-the-shelf devices, this balun has a nearly linear transmission curve across 1-12GHz. This linearity allows us to detect the radiation which would not have been possible with an off-the-shelf device. At the end, we demonstrate that the standard twisted pairs used in the UK can be used up to 5GHz carrier frequency without any radiation effect and this upper-bound can be moved to higher frequencies by decreasing the twist lengths.      
### 59.Blind Speech Separation and Dereverberation using Neural Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2103.13443.pdf)
>  In this paper, we present the Blind Speech Separation and Dereverberation (BSSD) network, which performs simultaneous speaker separation, dereverberation and speaker identification in a single neural network. Speaker separation is guided by a set of predefined spatial cues. Dereverberation is performed by using neural beamforming, and speaker identification is aided by embedding vectors and triplet mining. We introduce a frequency-domain model which uses complex-valued neural networks, and a time-domain variant which performs beamforming in latent space. Further, we propose a block-online mode to process longer audio recordings, as they occur in meeting scenarios. We evaluate our system in terms of Scale Independent Signal to Distortion Ratio (SI-SDR), Word Error Rate (WER) and Equal Error Rate (EER).      
### 60.A Framework for 3D Tracking of Frontal Dynamic Objects in Autonomous Cars  [ :arrow_down: ](https://arxiv.org/pdf/2103.13430.pdf)
>  Both recognition and 3D tracking of frontal dynamic objects are crucial problems in an autonomous vehicle, while depth estimation as an essential issue becomes a challenging problem using a monocular camera. Since both camera and objects are moving, the issue can be formed as a structure from motion (SFM) problem. In this paper, to elicit features from an image, the YOLOv3 approach is utilized beside an OpenCV tracker. Subsequently, to obtain the lateral and longitudinal distances, a nonlinear SFM model is considered alongside a state-dependent Riccati equation (SDRE) filter and a newly developed observation model. Additionally, a switching method in the form of switching estimation error covariance is proposed to enhance the robust performance of the SDRE filter. The stability analysis of the presented filter is conducted on a class of discrete nonlinear systems. Furthermore, the ultimate bound of estimation error caused by model uncertainties is analytically obtained to investigate the switching significance. Simulations are reported to validate the performance of the switched SDRE filter. Finally, real-time experiments are performed through a multi-thread framework implemented on a Jetson TX2 board, while radar data is used for the evaluation.      
