# ArXiv eess --Tue, 23 Mar 2021
### 1.Meta-learning Based Beamforming Design for MISO Downlink  [ :arrow_down: ](https://arxiv.org/pdf/2103.11978.pdf)
>  Downlink beamforming is an essential technology for wireless cellular networks; however, the design of beamforming vectors that maximize the weighted sum rate (WSR) is an NP-hard problem and iterative algorithms are typically applied to solve it. The weighted minimum mean square error (WMMSE) algorithm is the most widely used one, which iteratively minimizes the WSR and converges to a local optimal. Motivated by the recent developments in meta-learning techniques to solve non-convex optimization problems, we propose a meta-learning based iterative algorithm for WSR maximization in a MISO downlink channel. A long-short-term-memory (LSTM) network-based meta-learning model is built to learn a dynamic optimization strategy to update the variables iteratively. The learned strategy aims to optimize each variable in a less greedy manner compared to WMMSE, which updates variables by computing their first-order stationary points at each iteration step. The proposed algorithm outperforms WMMSE significantly in the high signal to noise ratio(SNR) regime and shows the comparable performance when the SNR is low.      
### 2.Reinforcement Learning based on Scenario-tree MPC for ASVs  [ :arrow_down: ](https://arxiv.org/pdf/2103.11949.pdf)
>  In this paper, we present the use of Reinforcement Learning (RL) based on Robust Model Predictive Control (RMPC) for the control of an Autonomous Surface Vehicle (ASV). The RL-MPC strategy is utilized for obstacle avoidance and target (set-point) tracking. A scenario-tree robust MPC is used to handle potential failures of the ship thrusters. Besides, the wind and ocean current are considered as unknown stochastic disturbances in the real system, which are handled via constraints tightening. The tightening and other cost parameters are adjusted by RL, using a Q-learning technique. An economic cost is considered, minimizing the time and energy required to achieve the ship missions. The method is illustrated in simulation on a nonlinear 3-DOF model of a scaled version of the Cybership 2.      
### 3.Self-Adaptive Manufacturing with Digital Twins  [ :arrow_down: ](https://arxiv.org/pdf/2103.11941.pdf)
>  Digital Twins are part of the vision of Industry 4.0 to represent, control, predict, and optimize the behavior of Cyber-Physical Production Systems (CPPSs). These CPPSs are long-living complex systems deployed to and configured for diverse environments. Due to specific deployment, configuration, wear and tear, or other environmental effects, their behavior might diverge from the intended behavior over time. Properly adapting the configuration of CPPSs then relies on the expertise of human operators. Digital Twins (DTs) that reify this expertise and learn from it to address unforeseen challenges can significantly facilitate self-adaptive manufacturing where experience is very specific and, hence, insufficient to employ deep learning techniques. We leverage the explicit modeling of domain expertise through case-based reasoning to improve the capabilities of Digital Twins for adapting to such situations. To this effect, we present a modeling framework for self-adaptive manufacturing that supports modeling domain-specific cases, describing rules for case similarity and case-based reasoning within a modular Digital Twin. Automatically configuring Digital Twins based on explicitly modeled domain expertise can improve manufacturing times, reduce wastage, and, ultimately, contribute to better sustainable manufacturing.      
### 4.Continuous Prediction of Lower-Limb Kinematics From Multi-Modal Biomedical Signals  [ :arrow_down: ](https://arxiv.org/pdf/2103.11910.pdf)
>  The fast-growing techniques of measuring and fusing multi-modal biomedical signals enable advanced motor intent decoding schemes of lowerlimb exoskeletons, meeting the increasing demand for rehabilitative or assistive applications of take-home healthcare. Challenges of exoskeletons motor intent decoding schemes remain in making a continuous prediction to compensate for the hysteretic response caused by mechanical transmission. In this paper, we solve this problem by proposing an ahead of time continuous prediction of lower limb kinematics, with the prediction of knee angles during level walking as a case study. Firstly, an end-to-end kinematics prediction network(KinPreNet), consisting of a feature extractor and an angle predictor, is proposed and experimentally compared with features and methods traditionally used in ahead-of-time prediction of gait phases. Secondly, inspired by the electromechanical delay(EMD), we further explore our algorithm's capability of compensating response delay of mechanical transmission by validating the performance of the different sections of prediction time. And we experimentally reveal the time boundary of compensating the hysteretic response. Thirdly, a comparison of employing EMG signals or not is performed to reveal the EMG and kinematic signals collaborated contributions to the continuous prediction. During the experiments, EMG signals of nine muscles and knee angles calculated from inertial measurement unit (IMU) signals are recorded from ten healthy subjects. To the best of our knowledge, this is the first study of continuously predicting lower-limb kinematics in an ahead-of-time manner based on the electromechanical delay (EMD).      
### 5.PTSC: a New Definition for Structural Controllability under Numerical Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2103.11908.pdf)
>  This paper proposes a novel definition for structural controllability, namely the perturbation-tolerant structural controllability, on a structured system whose entries can be classified into three categories: fixed zero entries, unknown generic entries whose values are fixed but indeterminate, and perturbed entries which can take arbitrary complex values. Such a system is perturbation-tolerantly structurally controllable if, for almost all values of the unknown generic entries in the parameter space, the corresponding controllable system realizations can preserve controllability under arbitrary complex-valued perturbations with a structure prescribed by the perturbed entries. This property is shown to be generic (in the single-input case). In this paper, we give a necessary and sufficient condition for a single-input system to be perturbation-tolerantly structurally controllable, whose verification has polynomial time complexity. Our results can serve as some feasibility conditions for the conventional structured controllability radius problems from a generic view.      
### 6.MEC-Empowered Non-Terrestrial Network for 6G Wide-Area Time-Sensitive Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2103.11907.pdf)
>  In the upcoming sixth-generation (6G) era, the demand for constructing a wide-area time-sensitive Internet of Things (IoT) keeps increasing. As conventional cellular technologies are hard to be directly used for wide-area timesensitive IoT, it is beneficial to use non-terrestrial infrastructures including satellites and unmanned aerial vehicles (UAVs), where a non-terrestrial network (NTN) can be built under the cell-free architecture. Driven by the timesensitive requirements and uneven distribution of machines, the NTN is required to be empowered by mobile edge computing (MEC) while providing oasis-oriented on-demand coverage for machines. Nevertheless, communication and MEC systems are coupled with each other under the influence of complex propagation environment in the MECempowered NTN, which makes it hard to orchestrate the resources. In this paper, we propose a process-oriented framework to design the communication and MEC systems in a time-decoupled manner. Under this framework, the large-scale channel state information (CSI) is used to characterize the complex propagation environment with an affordable cost, where a non-convex task completion latency minimization problem is formulated. After that, the approximated dual problem is given and it can be decomposed into subproblems. These subproblems are further solved in an iterative way. Simulation results demonstrate the superiority of the proposed process-oriented scheme over other algorithms. These results also indicate that the payload deployments of UAVs should be appropriately predesigned to improve the efficiency of resource use. Furthermore, the results imply that it is advantageous to integrate NTN with MEC for wide-area time-sensitive IoT.      
### 7.Modeling and Control of Internal Oscillations in Energy-Synchronous Direct Antenna Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2103.11906.pdf)
>  Internal oscillations in switched antenna transmitters cause undesirable fluctuations of the stored energy in the system, which is critical to the concept of energy-synchronous direct antenna modulation. A detailed circuit model for a direct antenna modulation system is proposed that includes the high frequency parasitics that lead to these oscillations. Analytical and numerical studies show that the proposed model accurately predicts the oscillations of the system and the resulting signal degradation. To mitigate the parasitic oscillations, a modified direct antenna modulation system with an auxiliary DC source is introduced to stabilize the stored voltage on the antenna. Measured phase shift keyed waveforms transmitted by the modified system show significant increases in signal fidelity, including a 10-20 dB decrease in error vector magnitude compared to an LTI system. Comparison to an equivalent, scalable time-invariant antenna suggests that the switched transmitter behaves as though it has 2-3 times lower Q factor bandwidth and 20% higher radiation efficiency.      
### 8.The Generalized Fourier Transform: A Unified Framework for the Fourier, Laplace, Mellin and $Z$ Transforms  [ :arrow_down: ](https://arxiv.org/pdf/2103.11905.pdf)
>  This paper introduces Generalized Fourier transform (GFT) that is an extension or the generalization of the Fourier transform (FT). The Unilateral Laplace transform (LT) is observed to be the special case of GFT. GFT, as proposed in this work, contributes significantly to the scholarly literature. There are many salient contribution of this work. Firstly, GFT is applicable to a much larger class of signals, some of which cannot be analyzed with FT and LT. For example, we have shown the applicability of GFT on the polynomially decaying functions and super exponentials. Secondly, we demonstrate the efficacy of GFT in solving the initial value problems (IVPs). Thirdly, the generalization presented for FT is extended for other integral transforms with examples shown for wavelet transform and cosine transform. Likewise, generalized Gamma function is also presented. One interesting application of GFT is the computation of generalized moments, for the otherwise non-finite moments, of any random variable such as the Cauchy random variable. Fourthly, we introduce Fourier scale transform (FST) that utilizes GFT with the topological isomorphism of an exponential map. Lastly, we propose Generalized Discrete-Time Fourier transform (GDTFT). The DTFT and unilateral $z$-transform are shown to be the special cases of the proposed GDTFT. The properties of GFT and GDTFT have also been discussed.      
### 9.Tracking Performance of Incremental LMS Algorithm over Adaptive Distributed Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.11903.pdf)
>  In this paper we focus on the tracking performance of incremental adaptive LMS algorithm in an adaptive network. For this reason we consider the unknown weight vector to be a time varying sequence. First we analyze the performance of network in tracking a time varying weight vector and then we explain the estimation of Rayleigh fading channel through a random walk model. Closed-form relations are derived for mean square error (MSE), mean square deviation (MSD) and excess mean square error (EMSE)of analyzed network in tracking Rayleigh fading channel and random walk model. Comparison between theoretical and simulation results shows a perfect match and verifies performed calculations.      
### 10.Autocorrelation-Driven Synthesis of Antenna Arrays -- The Case of DS-Based Planar Isophoric Thinned Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2103.11902.pdf)
>  A new methodology for the design of isophoric thinned arrays with a priori controlled pattern features is introduced. A fully analytical and general (i.e., valid for any lattice and set of weights) relationship between the autocorrelation of the array excitations and the power pattern samples is first derived. Binary 2-D sequences with known autocorrelation properties, namely the difference sets (DSs), are then chosen as a representative benchmark to prove that it is possible to deduce closed-form synthesis formulas that a priori guarantee to fit requirements on the sidelobe level (SLL), the directivity, the half-power beamwidth, and the power pattern in user-defined directions. The selected results from a wide numerical assessment, which also includes full-wave simulations with realistic radiators, are illustrated to validate the reliability and the accuracy of the proposed design equations and the associated performance bounds.      
### 11.An UAV-based Experimental Setup for Propagation Characterization in Urban Environment  [ :arrow_down: ](https://arxiv.org/pdf/2103.11901.pdf)
>  A measurement setup made of millimeter-wave and ultra wideband transceivers mounted on both a customized UAV and a ground station for full 3D wireless propagation analysis is described in this work. The developed system represents a flexible solution for the characterization of wireless channels and especially of urban propagation, as the drone might be easily located almost anywhere from ground level to the buildings rooftop and beyond. The double directional properties of the channel can be achieved by rotating directive antennas at the link ends. Other possible applications in urban contexts include above ground level propagation, outdoor-to-indoor penetration, line-of-sight to non-line-of-sight transition, scattering from buildings and air-to-ground channel characterization for UAV-assisted wireless communications.      
### 12.Glaucoma detection beyond the optic disc: The importance of the peripapillary region using explainable deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.11895.pdf)
>  Today, a large number of glaucoma cases remain undetected, resulting in irreversible blindness. In a quest for cost-effective screening, deep learning-based methods are being evaluated to detect glaucoma from color fundus images. Although unprecedented sensitivity and specificity values are reported, recent glaucoma detection deep learning models lack in decision transparency. Here, we propose a methodology that advances explainable deep learning in the field of glaucoma detection and vertical cup-disc ratio (VCDR), an important risk factor. We trained and evaluated a total of 64 deep learning models using fundus images that undergo a certain cropping policy. We defined the circular crop radius as a percentage of image size, centered on the optic nerve head (ONH), with an equidistant spaced range from 10%-60% (ONH crop policy). The inverse of the cropping mask was also applied to quantify the performance of models trained on ONH information exclusively (periphery crop policy). The performance of the models evaluated on original images resulted in an area under the curve (AUC) of 0.94 [95% CI: 0.92-0.96] for glaucoma detection, and a coefficient of determination (R^2) equal to 77% [95% CI: 0.77-0.79] for VCDR estimation. Models that were trained on images with absence of the ONH are still able to obtain significant performance (0.88 [95% CI: 0.85-0.90] AUC for glaucoma detection and 37% [95% CI: 0.35-0.40] R^2 score for VCDR estimation in the most extreme setup of 60% ONH crop). We validated our glaucoma detection models on a recent public data set (REFUGE) that contains images captured with a different camera, still achieving an AUC of 0.80 [95% CI: 0.76-0.84] when ONH crop policy of 60% image size was applied. Our findings provide the first irrefutable evidence that deep learning can detect glaucoma from fundus image regions outside the ONH.      
### 13.Thresholding Greedy Pursuit for Sparse Recovery Problems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11893.pdf)
>  We study here sparse recovery problems in the presence of additive noise. We analyze a thresholding version of the CoSaMP algorithm, named Thresholding Greedy Pursuit (TGP). We demonstrate that an appropriate choice of thresholding parameter, even without the knowledge of sparsity level of the signal and strength of the noise, can result in exact recovery with no false discoveries as the dimension of the data increases to infinity.      
### 14.Increasing Energy Efficiency of Massive-MIMO Network via Base Stations Switching using Reinforcement Learning and Radio Environment Maps  [ :arrow_down: ](https://arxiv.org/pdf/2103.11891.pdf)
>  Energy Efficiency (EE) is of high importance while considering Massive Multiple-Input Multiple-Output (M-MIMO) networks where base stations (BSs) are equipped with an antenna array composed of up to hundreds of elements. M-MIMO transmission, although highly spectrally efficient, results in high energy consumption growing with the number of antennas. This paper investigates EE improvement through switching on/off underutilized BSs. It is proposed to use the location-aware approach, where data about an optimal active BSs set is stored in a Radio Environment Map (REM). For efficient acquisition, processing and utilization of the REM data, reinforcement learning (RL) algorithms are used. State-of-the-art exploration/exploitation methods including e-greedy, Upper Confidence Bound (UCB), and Gradient Bandit are evaluated. Then analytical action filtering, and an REM-based Exploration Algorithm (REM-EA) are proposed to improve the RL convergence time. Algorithms are evaluated using an advanced, system-level simulator of an M-MIMO Heterogeneous Network (HetNet) utilizing an accurate 3D-ray-tracing radio channel model. The proposed RL-based BSs switching algorithm is proven to provide 70% gains in EE over a state-of-the-art algorithm using an analytical heuristic. Moreover, the proposed action filtering and REM-EA can reduce RL convergence time in relation to the best-performing state-of-the-art exploration method by 60% and 83%, respectively.      
### 15.Coexistence of Communications and Cognitive MIMO Radar: Waveform Design and Prototype  [ :arrow_down: ](https://arxiv.org/pdf/2103.11890.pdf)
>  New generation of radar systems will need to coexist with other radio frequency (RF) systems, anticipating their behavior and reacting appropriately to avoid interference. In light of this requirement, this paper designs, implements, and evaluates the performance of phase-only sequences (with constant power) for intelligent spectrum utilization using the custom built cognitive Multiple Input Multiple Output (MIMO) radar prototype. The proposed transmit waveforms avoid the frequency bands occupied by narrowband interferers or communication links, while simultaneously have a small cross-correlation among each other to enable their separability at the MIMO radar receiver. The performance of the optimized set of sequences obtained through solving a non-convex bi-objective optimization problem, is compared with the state-of-the-art counterparts, and its applicability is illustrated by the developed prototype. A realistic Long Term Evolution (LTE) downlink is used for the communications, and the real-time system implementation is validated and evaluated through the throughput calculations for communications and the detection performance measurement for the radar system.      
### 16.Reinforcement Learning based on MPC/MHE for Unmodeled and Partially Observable Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2103.11871.pdf)
>  This paper proposes an observer-based framework for solving Partially Observable Markov Decision Processes (POMDPs) when an accurate model is not available. We first propose to use a Moving Horizon Estimation-Model Predictive Control (MHE-MPC) scheme in order to provide a policy for the POMDP problem, where the full state of the real process is not measured and necessarily known. We propose to parameterize both MPC and MHE formulations, where certain adjustable parameters are regarded for tuning the policy. In this paper, for the sake of tackling the unmodeled and partially observable dynamics, we leverage the Reinforcement Learning (RL) to tune the parameters of MPC and MHE schemes jointly, with the closed-loop performance of the policy as a goal rather than model fitting or the MHE performance. Illustrations show that the proposed approach can effectively increase the performance of close-loop control of systems formulated as POMDPs.      
### 17.Resilient Control under Quantization and Denial-of-Service: Co-designing a Deadbeat Controller and Transmission Protocol  [ :arrow_down: ](https://arxiv.org/pdf/2103.11862.pdf)
>  This paper is concerned with the problem of stabilizing continuous-time linear time-invariant systems subject to quantization and Denial-of-Service (DoS) attacks. In this context, two DoS-induced challenges emerge with the design of resilient encoding schemes, namely, the coupling between encoding strategies of different signals, and the synchronization between the encoder and decoder. To address these challenges, a novel structure that is equipped with a deadbeat controller as well as a delicate transmission protocol for the input and output channels, co-designed leveraging the controllability index, is put forward. When both input and output channels are subject to DoS attacks and quantization, the proposed structure is shown able to decouple the encoding schemes for input, output, and estimated output signals. This property is further corroborated by designing encoding schemes as well as conditions that ensure exponential stability of the closed-loop system. On the other hand, when only the output channel is subject to network phenomenon, the proposed structure can achieve exponential stabilization without acknowledgment (ACK) signals, in contrast to existing ACK-based results. Finally, a numerical example is given to demonstrate the practical merits of the proposed approach as well as the theory.      
### 18.Generation and Simulation of Yeast Microscopy Imagery with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.11834.pdf)
>  Time-lapse fluorescence microscopy (TLFM) is an important and powerful tool in synthetic biological research. Modeling TLFM experiments based on real data may enable researchers to repeat certain experiments with minor effort. This thesis is a study towards deep learning-based modeling of TLFM experiments on the image level. The modeling of TLFM experiments, by way of the example of trapped yeast cells, is split into two tasks. The first task is to generate synthetic image data based on real image data. To approach this problem, a novel generative adversarial network, for conditionalized and unconditionalized image generation, is proposed. The second task is the simulation of brightfield microscopy images over multiple discrete time-steps. To tackle this simulation task an advanced future frame prediction model is introduced. The proposed models are trained and tested on a novel dataset that is presented in this thesis. The obtained results showed that the modeling of TLFM experiments, with deep learning, is a proper approach, but requires future research to effectively model real-world experiments.      
### 19.DeepOPF-V: Solving AC-OPF Problems Efficiently  [ :arrow_down: ](https://arxiv.org/pdf/2103.11793.pdf)
>  AC optimal power flow (AC-OPF) problems need to be solved more frequently in the future to maintain stable and economic operation. To tackle this challenge, a deep neural network-based voltage-constrained approach (DeepOPF-V) is proposed to find feasible solutions with high computational efficiency. It predicts voltages of all buses and then uses them to obtain all remaining variables. A fast post-processing method is developed to enforce generation constraints. The effectiveness of DeepOPF-V is validated by case studies of several IEEE test systems. Compared with existing approaches, DeepOPF-V achieves a state-of-art computation speedup up to three orders of magnitude and has better performance in preserving the feasibility of the solution.      
### 20.Machine Learning Empowered Resource Allocation in IRS Aided MISO-NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.11791.pdf)
>  A novel framework of intelligent reflecting surface (IRS)-aided multiple-input single-output (MISO) non-orthogonal multiple access (NOMA) network is proposed, where a base station (BS) serves multiple clusters with unfixed number of users in each cluster. The goal is to maximize the sum rate of all users by jointly optimizing the passive beamforming vector at the IRS, decoding order, power allocation coefficient vector and number of clusters, subject to the rate requirements of users. In order to tackle the formulated problem, a three-step approach is proposed. More particularly, a long short-term memory (LSTM) based algorithm is first adopted for predicting the mobility of users. Secondly, a K-means based Gaussian mixture model (K-GMM) algorithm is proposed for user clustering. Thirdly, a deep Q-network (DQN) based algorithm is invoked for jointly determining the phase shift matrix and power allocation policy. Simulation results are provided for demonstrating that the proposed algorithm outperforms the benchmarks, while the throughput gain of 35% can be achieved by invoking NOMA technique instead of orthogonal multiple access (OMA).      
### 21.Competitive Perimeter Defense on a Line  [ :arrow_down: ](https://arxiv.org/pdf/2103.11787.pdf)
>  We consider a perimeter defense problem in which a single vehicle seeks to defend a compact region from intruders in a one-dimensional environment parameterized by the perimeter size and the intruder-to-vehicle speed ratio. The intruders move inward with fixed speed and direction to reach the perimeter. We provide both positive and negative worst-case performance results over the parameter space using competitive analysis. We first establish fundamental limits by identifying the most difficult parameter combinations that admit no $c$-competitive algorithms for any constant $c\geq 1$ and slightly easier parameter combinations in which every algorithm is at best $2$-competitive. We then design three classes of algorithms and prove they are $1$, $2$, and $4$-competitive, respectively, for increasingly difficult parameter combinations. Finally, we present numerical studies that provide insights into the performance of these algorithms against stochastically generated intruders.      
### 22.Automatic Pulmonary Artery and Vein Separation Algorithm Based on Multitask Classification Network and Topology Reconstruction in Chest CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.11736.pdf)
>  With the development of medical computer-aided diagnostic systems, pulmonary artery-vein(A/V) reconstruction plays a crucial role in assisting doctors in preoperative planning for lung cancer surgery. However, distinguishing arterial from venous irrigation in chest CT images remains a challenge due to the similarity and complex structure of the arteries and veins. We propose a novel method for automatic separation of pulmonary arteries and veins from chest CT images. The method consists of three parts. First, global connection information and local feature information are used to construct a complete topological tree and ensure the continuity of vessel reconstruction. Second, the multitask classification network proposed can automatically learn the differences between arteries and veins at different scales to reduce classification errors caused by changes in terminal vessel characteristics. Finally, the topology optimizer considers interbranch and intrabranch topological relationships to maintain spatial consistency to avoid the misclassification of A/V irrigations. We validate the performance of the method on chest CT images. Compared with manual classification, the proposed method achieves an average accuracy of 96.2% on noncontrast chest CT. In addition, the method has been proven to have good generalization, that is, the accuracies of 93.8% and 94.8% are obtained for CT scans from other devices and other modes, respectively. The result of pulmonary artery-vein reconstruction obtained by the proposed method can provide better assistance for preoperative planning of lung cancer surgery.      
### 23.Retinal-inspired Filtering for Dynamic Image Coding  [ :arrow_down: ](https://arxiv.org/pdf/2103.11716.pdf)
>  This paper introduces a novel non-Separable sPAtioteMporal filter (non-SPAM) which enables the spatiotemporal decomposition of a still-image. The construction of this filter is inspired by the model of the retina which is able to selectively transmit information to the brain. The non-SPAM filter mimics the retinal-way to extract necessary information for a dynamic encoding/decoding system. We applied the non-SPAM filter on a still image which is flashed for a long time. We prove that the non-SPAM filter decomposes the still image over a set of time-varying difference of Gaussians, which form a frame. We simulate the analysis and synthesis system based on this frame. This system results in a progressive reconstruction of the input image. Both the theoretical and numerical results show that the quality of the reconstruction improves while the time increases.      
### 24.Spatially Dependent U-Nets: Highly Accurate Architectures for Medical Imaging Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.11713.pdf)
>  In clinical practice, regions of interest in medical imaging often need to be identified through a process of precise image segmentation. The quality of this image segmentation step critically affects the subsequent clinical assessment of the patient status. To enable high accuracy, automatic image segmentation, we introduce a novel deep neural network architecture that exploits the inherent spatial coherence of anatomical structures and is well equipped to capture long-range spatial dependencies in the segmented pixel/voxel space. In contrast to the state-of-the-art solutions based on convolutional layers, our approach leverages on recently introduced spatial dependency layers that have an unbounded receptive field and explicitly model the inductive bias of spatial coherence. Our method performs favourably to commonly used U-Net and U-Net++ architectures as demonstrated by improved Dice and Jaccardscore in three different medical segmentation tasks: nuclei segmentation in microscopy images, polyp segmentation in colonoscopy videos, and liver segmentation in abdominal CT scans.      
### 25.Predicting brain-age from raw T 1 -weighted Magnetic Resonance Imaging data using 3D Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.11695.pdf)
>  Age prediction based on Magnetic Resonance Imaging (MRI) data of the brain is a biomarker to quantify the progress of brain diseases and aging. Current approaches rely on preparing the data with multiple preprocessing steps, such as registering voxels to a standardized brain atlas, which yields a significant computational overhead, hampers widespread usage and results in the predicted brain-age to be sensitive to preprocessing parameters. Here we describe a 3D Convolutional Neural Network (CNN) based on the ResNet architecture being trained on raw, non-registered T$_ 1$-weighted MRI data of N=10,691 samples from the German National Cohort and additionally applied and validated in N=2,173 samples from three independent studies using transfer learning. For comparison, state-of-the-art models using preprocessed neuroimaging data are trained and validated on the same samples. The 3D CNN using raw neuroimaging data predicts age with a mean average deviation of 2.84 years, outperforming the state-of-the-art brain-age models using preprocessed data. Since our approach is invariant to preprocessing software and parameter choices, it enables faster, more robust and more accurate brain-age modeling.      
### 26.Communication Technologies for Smart Grid: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2103.11657.pdf)
>  With the ongoing trends in the energy sector such as vehicular electrification and renewable energy, smart grid is clearly playing a more and more important role in the electric power system industry. One essential feature of the smart grid is the information flow over the high-speed, reliable and secure data communication network in order to manage the complex power systems effectively and intelligently. Smart grids utilize bidirectional communication to function where traditional power grids mainly only use one-way communication. The communication requirements and suitable technique differ depending on the specific environment and scenario. In this paper, we provide a comprehensive and up-to-date survey on the communication technologies used in the smart grid, including the communication requirements, physical layer technologies, network architectures, and research challenges. This survey aims to help the readers identify the potential research problems in the continued research on the topic of smart grid communications.      
### 27.Evaluating glioma growth predictions as a forward ranking problem  [ :arrow_down: ](https://arxiv.org/pdf/2103.11651.pdf)
>  The problem of tumor growth prediction is challenging, but promising results have been achieved with both model-driven and statistical methods. In this work, we present a framework for the evaluation of growth predictions that focuses on the spatial infiltration patterns, and specifically evaluating a prediction of future growth. We propose to frame the problem as a ranking problem rather than a segmentation problem. Using the average precision as a metric, we can evaluate the results with segmentations while using the full spatiotemporal prediction. Furthermore, by separating the model goodness-of-fit from future predictive performance, we show that in some cases, a better fit of model parameters does not guarantee a better the predictive power.      
### 28.Gauging diffraction patterns: field of view and bandwidth estimation in lensless holography  [ :arrow_down: ](https://arxiv.org/pdf/2103.11649.pdf)
>  The purpose of this work is to provide theoretically grounded assessment on both the field-of-view and the bandwidth of a lensless holographic setup. Indeed, while previous works have presented results with super-resolution and field-of-view extrapolation, there is no well established rules to determine them. We show that the theoretical field of view can be hugely large with a spatial-frequency bandwidth only limited by the wavelength leading to an unthinkable number of degrees of freedom. To keep a realistic field of view and bandwidth, we propose several practical bounds based on few setup properties: namely the noise level and the spatio-temporal coherence of the source.      
### 29.Mathematical Theory of Computational Resolution Limit in Multi-dimensions  [ :arrow_down: ](https://arxiv.org/pdf/2103.11632.pdf)
>  Resolving a linear combination of point sources from their band-limited Fourier data is a fundamental problem in imaging and signal processing. With the incomplete Fourier data and the inevitable noise in the measurement, there is a fundamental limit on the separation distance between point sources that can be resolved. This is the so-called resolution limit problem. Characterization of this resolution limit is still a long-standing puzzle despite the prevalent use of the classic Rayleigh limit. It is well-known that Rayleigh limit is heuristic and its drawbacks become prominent when dealing with data that is subjected to delicate processing, as is what modern computational imaging methods do. Therefore, more precise characterization of the resolution limit becomes increasingly necessary with the development of data processing methods. For this purpose, we developed a theory of "computational resolution limit" for both number detection and support recovery in one dimension in [<a class="link-https" data-arxiv-id="2003.02917" href="https://arxiv.org/abs/2003.02917">arXiv:2003.02917</a>[cs.IT], <a class="link-https" data-arxiv-id="1912.05430" href="https://arxiv.org/abs/1912.05430">arXiv:1912.05430</a>[eess.IV]]. In this paper, we extend the one-dimensional theory to multi-dimensions. More precisely, we define and quantitatively characterize the "computational resolution limit" for the number detection and support recovery problems in a general k-dimensional space. Our results indicate that there exists a phase transition phenomenon regarding to the super-resolution factor and the signal-to-noise ratio in each of the two recovery problems. Our main results are derived using a subspace projection strategy. Finally, to verify the theory, we proposed deterministic subspace projection based algorithms for the number detection and support recovery problems in dimension two and three. The numerical results confirm the phase transition phenomenon predicted by the theory.      
### 30.Thomson's Multitaper Method Revisited  [ :arrow_down: ](https://arxiv.org/pdf/2103.11586.pdf)
>  Thomson's multitaper method estimates the power spectrum of a signal from $N$ equally spaced samples by averaging $K$ tapered periodograms. Discrete prolate spheroidal sequences (DPSS) are used as tapers since they provide excellent protection against spectral leakage. Thomson's multitaper method is widely used in applications, but most of the existing theory is qualitative or asymptotic. Furthermore, many practitioners use a DPSS bandwidth $W$ and number of tapers that are smaller than what the theory suggests is optimal because the computational requirements increase with the number of tapers. We revisit Thomson's multitaper method from a linear algebra perspective involving subspace projections. This provides additional insight and helps us establish nonasymptotic bounds on some statistical properties of the multitaper spectral estimate, which are similar to existing asymptotic results. We show using $K=2NW-O(\log(NW))$ tapers instead of the traditional $2NW-O(1)$ tapers better protects against spectral leakage, especially when the power spectrum has a high dynamic range. Our perspective also allows us to derive an $\epsilon$-approximation to the multitaper spectral estimate which can be evaluated on a grid of frequencies using $O(\log(NW)\log\tfrac{1}{\epsilon})$ FFTs instead of $K=O(NW)$ FFTs. This is useful in problems where many samples are taken, and thus, using many tapers is desirable.      
### 31.Integrating Electrochemical Modeling with Machine Learning for Lithium-Ion Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2103.11580.pdf)
>  Mathematical modeling of lithium-ion batteries (LiBs) is a central challenge in advanced battery management. This paper presents a new approach to integrate a physics-based model with machine learning to achieve high-precision modeling for LiBs. This approach uniquely proposes to inform the machine learning model of the dynamic state of the physical model, enabling a deep integration between physics and machine learning. We propose two hybrid physics-machine learning models based on the approach, which blend a single particle model with thermal dynamics (SPMT) with a feedforward neural network (FNN) to perform physics-informed learning of a LiB's dynamic behavior. The proposed models are relatively parsimonious in structure and can provide considerable predictive accuracy even at high C-rates, as shown by extensive simulations.      
### 32.D3PI: Data-Driven Distributed Policy Iteration for Homogeneous Interconnected Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11572.pdf)
>  Control of large-scale networked systems often necessitates the availability of complex models for the interactions amongst the agents. While building accurate models of these interactions could become prohibitive in many applications, data-driven control methods can circumvent model complexities by directly synthesizing a controller from the observed data. In this paper, we propose the Data-Driven Distributed Policy Iteration (D3PI) algorithm to design a feedback mechanism for a potentially large system that enjoys an underlying graph structure characterizing communications among the agents. Rather than having access to system parameters, our algorithm requires temporary "auxiliary" links to boost information exchange of a small portion of the graph during the learning phase. Therein, the costs are partitioned for learning and non-learning agents in order to ensure consistent control of the entire network. After the termination of the learning process, a distributed policy is proposed for the entire networked system by leveraging estimated components obtained in the learning phase. We provide extensive stability and convergence guarantees of the proposed distributed controller throughout the learning phase by exploiting the structure of the system parameters that occur due to the graph topology and existence of the temporary links. The practicality of our method is then illustrated with a simulation.      
### 33.Convex Parameterization and Optimization for Robust Tracking of a Magnetically Levitated Planar Positioning System  [ :arrow_down: ](https://arxiv.org/pdf/2103.11569.pdf)
>  Magnetic levitation positioning technology has attracted considerable research efforts and dedicated attention due to its extremely attractive features. The technology offers high-precision, contactless, dust/lubricant-free, multi-axis, and large-stroke positioning. In this work, we focus on the accurate and smooth tracking problem of a multi-axis magnetically levitated (maglev) planar positioning system for a specific S-curve reference trajectory. The floating characteristics and the multi-axis coupling make accurate identification of the system dynamics difficult, which lead to a challenge to design a high performance control system. Here, the tracking task is achieved by a 2-Degree of Freedom (DoF) controller consisting of a feedforward controller and a robust stabilizing feedback controller with a prescribed sparsity pattern. The approach proposed in this paper utilizes the basis of an H-infinity controller formulation and a suitably established convex inner approximation. Particularly, a subset of robust stabilizable controllers with prescribed structural constraints is characterized in the parameter space, and so thus the re-formulated convex optimization problem can be easily solved by several powerful numerical algorithms and solvers. With this approach, the robust stability of the overall system is ensured with a satisfactory system performance despite the presence of parametric uncertainties. Furthermore, experimental results clearly demonstrate the effectiveness of the proposed approach.      
### 34.Switching Controller Synthesis for Delay Hybrid Systems under Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2103.11565.pdf)
>  Delays are ubiquitous in modern hybrid systems, which exhibit both continuous and discrete dynamical behaviors. Induced by signal transmission, conversion, the nature of plants, and so on, delays may appear either in the continuous evolution of a hybrid system such that the evolution depends not only on the present state but also on its execution history, or in the discrete switching between its different control modes. In this paper we come up with a new model of hybrid systems, called \emph{delay hybrid automata}, to capture the dynamics of systems with the aforementioned two kinds of delays. Furthermore, based upon this model we study the robust switching controller synthesis problem such that the controlled delay system is able to satisfy the specified safety properties regardless of perturbations. To the end, a novel method is proposed to synthesize switching controllers based on the computation of differential invariants for continuous evolution and backward reachable sets of discrete jumps with delays. Finally, we implement a prototypical tool of our approach and demonstrate it on some case studies.      
### 35.DCT and DST Filtering with Sparse Graph Operators  [ :arrow_down: ](https://arxiv.org/pdf/2103.11529.pdf)
>  Graph filtering is a fundamental tool in graph signal processing. Polynomial graph filters (PGFs), defined as polynomials of a fundamental graph operator, can be implemented in the vertex domain, and usually have a lower complexity than frequency domain filter implementations. In this paper, we focus on the design of filters for graphs with graph Fourier transform (GFT) corresponding to a discrete trigonometric transform (DTT), i.e., one of 8 types of discrete cosine transforms (DCT) and 8 discrete sine transforms (DST). In this case, we show that multiple sparse graph operators can be identified, which allows us to propose a generalization of PGF design: multivariate polynomial graph filter (MPGF). First, for the widely used DCT-II (type-2 DCT), we characterize a set of sparse graph operators that share the DCT-II matrix as their common eigenvector matrix. This set contains the well-known connected line graph. These sparse operators can be viewed as graph filters operating in the DCT domain, which allows us to approximate any DCT graph filter by a MPGF, leading to a design with more degrees of freedom than the conventional PGF approach. Then, we extend those results to all of the 16 DTTs as well as their 2D versions, and show how their associated sets of multiple graph operators can be determined. We demonstrate experimentally that ideal low-pass and exponential DCT/DST filters can be approximated with higher accuracy with similar runtime complexity. Finally, we apply our method to transform-type selection in a video codec, AV1, where we demonstrate significant encoding time savings, with a negligible compression loss.      
### 36.Sinusoidal Parameter Estimation from Signed Measurements via Majorization-Minimization Based RELAX  [ :arrow_down: ](https://arxiv.org/pdf/2103.11500.pdf)
>  We consider the problem of sinusoidal parameter estimation using signed observations obtained via one-bit sampling with fixed as well as time-varying thresholds. In a previous paper, a relaxation-based algorithm, referred to as 1bRELAX, has been proposed to iteratively maximize the likelihood function. However, the exhaustive search procedure used in each iteration of 1bRELAX is time-consuming. In this paper, we present a majorization-minimization (MM) based 1bRELAX algorithm, referred to as 1bMMRELAX, to enhance the computational efficiency of 1bRELAX. Using the MM technique, 1bMMRELAX maximizes the likelihood function iteratively using simple FFT operations instead of the more computationally intensive search used by 1bRELAX. Both simulated and experimental results are presented to show that 1bMMRELAX can significantly reduce the computational cost of 1bRELAX while maintaining its excellent estimation accuracy.      
### 37.Occupancy-Driven Stochastic Decision Framework for Ranking Commercial Building Loads  [ :arrow_down: ](https://arxiv.org/pdf/2103.11485.pdf)
>  For effective integration of building operations into the evolving demand response programs of the power grid, real-time decisions concerning the use of building appliances for grid services must excel on multiple criteria, ranging from the added value to occupants' comfort to the quality of the grid services. In this paper, we present a data-driven decision-support framework to dynamically rank load control alternatives in a commercial building, addressing the needs of multiple decision criteria (e.g. occupant comfort, grid service quality) under uncertainties in occupancy patterns. We adopt a stochastic multi-criteria decision algorithm recently applied to prioritize residential on/off loads, and extend it to i) complex load control decisions (e.g. dimming of lights, changing zone temperature set-points) in a commercial building; and ii) systematic integration of zonal occupancy patterns to accurately identify short-term grid service opportunities. We evaluate the performance of the framework for curtailment of air-conditioning, lighting, and plug-loads in a multi-zone office building for a range of design choices. With the help of a prototype system that integrates an interactive \textit{Data Analytics and Visualization} frontend, we demonstrate a way for the building operators to monitor the flexibility in energy consumption and to develop trust in the decision recommendations by interpreting the rationale behind the ranking.      
### 38.Comparison of Short Blocklength Slepian-Wolf Coding for Key Reconciliation  [ :arrow_down: ](https://arxiv.org/pdf/2103.11423.pdf)
>  We focus Slepian-Wolf (SW) coding in the short blocklength for reconciliation in secret key generation and physical unclonable functions. In the problem formulation, two legitimate parties wish to generate a common secret key from a noisy observation of a common random source in the presence of a passive eavesdropper. We consider three different families of codes for key reconciliation. The selected codes show promising performances in information transmission in the short block-length regime. We implement and compare the performance of different codes for SW reconciliation in the terms of reliability and decoding complexity.      
### 39.Cyber-Attack Detection in Socio-Technical Transportation Systems Exploiting Redundancies Between Physical and Social Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.11422.pdf)
>  Cyber-physical-social connectivity is a key element in Intelligent Transportation Systems (ITSs) due to the ever-increasing interaction between human users and technological systems. Such connectivity translates the ITSs into dynamical systems of socio-technical nature. Exploiting this socio-technical feature to our advantage, we propose a cyber-attack detection scheme for ITSs that focuses on cyber-attacks on freeway traffic infrastructure. The proposed scheme combines two parallel macroscopic traffic model-based Partial Differential Equation (PDE) filters whose output residuals are compared to make decision on attack occurrences. One of the filters utilizes physical (vehicle/infrastructure) sensor data as feedback whereas the other utilizes social data from human users' mobile devices as feedback. The Social Data-based Filter is aided by a fake data isolator and a social signal processor that translates the social information into usable feedback signals. Mathematical convergence properties are analyzed for the filters using Lyapunov's stability theory. Lastly, we validate our proposed scheme by presenting simulation results.      
### 40.Deep Learning Based Detection for Spectrally Efficient FDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11409.pdf)
>  In this study we present how to approach the problem of building efficient detectors for spectrally efficient frequency division multiplexing (SEFDM) systems. The superiority of residual convolution neural networks (CNNs) for these types of problems is demonstrated through experimentation with many different types of architectures.      
### 41.Current Advances in Computational Lung Ultrasound Imaging: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2103.11366.pdf)
>  In the field of biomedical imaging, ultrasonography has become increasingly widespread, and an important auxiliary diagnostic tool with unique advantages, such as being non-ionising and often portable. This article reviews the state-of-the-art in medical ultrasound image computing and in particular its application in the examination of the lungs. First, we review the current developments in medical ultrasound technology. We then focus on the characteristics of lung ultrasonography and on its ability to diagnose a variety of diseases through the identification of various artefacts. We review medical ultrasound image processing methods by splitting them into two categories: (1) traditional model-based methods, and (2) data driven methods. For the former, we consider inverse problem based methods by focusing in particular on ultrasound image despeckling, deconvolution, and line artefacts detection. Among the data-driven approaches, we discuss various works based on deep/machine learning, which include various effective network architectures implementing supervised, weakly supervised and unsupervised learning.      
### 42.A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.11326.pdf)
>  A great deal of recent research effort on speech spoofing countermeasures has been invested into back-end neural networks and training criteria. We contribute to this effort with a comparative perspective in this study. Our comparison of countermeasure models on the ASVspoof 2019 logical access scenario takes into account common strategies to deal with input trials of varied length, recently proposed margin-based training criteria, and widely used front ends. We also measured intra-model differences through multiple training-evaluation rounds with random initialization. Our statistical analysis demonstrates that the performance of the same model may be statistically significantly different when just changing the random initial seed. We thus recommend similar statistical analysis or reporting results of multiple runs for further research on the database. Despite the intra-model differences, we observed a few promising techniques, including average pooling, to efficiently process varied-length inputs and a new hyper-parameter-free loss function. The two techniques led to the best single model in our experiment, which achieved an equal error rate of 1.92% and was significantly different in statistical sense from most of the other experimental models.      
### 43.A Proximal Point Approach for Distributed System State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2103.11325.pdf)
>  System state estimation constitutes a key problem in several applications involving multi-agent system architectures. This rests upon the estimation of the state of each agent in the group, which is supposed to access only relative measurements w.r.t. some neighbors state. Exploiting the standard least-squares paradigm, the system state estimation task is faced in this work by deriving a distributed Proximal Point-based iterative scheme. This solution entails the emergence of interesting connections between the structural properties of the stochastic matrices describing the system dynamics and the convergence behavior toward the optimal estimate. A deep analysis of such relations is provided, jointly with a further discussion on the penalty parameter that characterizes the Proximal Point approach.      
### 44.Branching out into Structural Identifiability Analysis with Maple: Interactive Exploration of Uncontrolled Linear Time-Invariant Structures  [ :arrow_down: ](https://arxiv.org/pdf/2103.11309.pdf)
>  Suppose we wish to predict the behaviour of a physical system. We may choose to represent the system by model structure $S$ (a set of related mathematical models defined by parametric relationships between system variables), and a parameter set $\Theta$. Each parameter vector in $\Theta$ is associated with a completely specified model in $S$. We use $S$ with system observations in estimating the "true" (unknown) parameter vector. Inconveniently, multiple parameter vectors may cause $S$ to approximate the data equally well. If we cannot distinguish between such alternatives, and these lead to dissimilar predictions, we cannot confidently use $S$ in decision making. This result may render efforts in data collection and modelling fruitless. This outcome occurs when $S$ lacks the property of structural global identifiability (SGI). Fortunately, we can test various classes of structures for SGI prior to data collection. A non-SGI result may guide changes to our structure or experimental design towards obtaining a better outcome. We aim to assist the testing of structures for SGI through bespoke Maple 2020 procedures. We consider continuous-time, uncontrolled, linear time-invariant state-space structures. Here, the time evolution of the state-variable vector ${\bf x}$ is modelled by a system of constant-coefficient, ordinary differential equations. We utilise the "transfer function" approach, which is also applicable to the "compartmental" subclass (mass is conserved). Our use of Maple's "Explore" enables an interactive consideration of a parent structure and its variants, obtained as the user changes which components of ${\bf x}$ are observed, or have non-zero initial conditions. Such changes may influence the information content of the idealised output available for the SGI test, and hence, its result. Our approach may inform the interactive analysis of structures from other classes.      
### 45.Feedback Linearization Control for Systems with Mismatched Uncertainties via Disturbance Observers  [ :arrow_down: ](https://arxiv.org/pdf/2103.11292.pdf)
>  This paper focuses on a novel feedback linearization control (FLC) law based on a self-learning disturbance observer (SLDO) to counteract mismatched uncertainties. The FLC based on BNDO (FLC-BNDO) demonstrates robust control performance only against mismatched time-invariant uncertainties while the FLC based on SLDO (FLC-SLDO) demonstrates robust control performance against mismatched time-invariant and -varying uncertainties, and both of them maintain the nominal control performance in the absence of mismatched uncertainties. In the estimation scheme for the SLDO, the BNDO is used to provide a conventional estimation law, which is used as being the learning error for the type-2 neuro-fuzzy system (T2NFS), and T2NFS learns mismatched uncertainties. Thus, the T2NFS takes the overall control of the estimation signal entirely in a very short time and gives unbiased estimation results for the disturbance. A novel learning algorithm established on sliding mode control theory is derived for an interval type-2 fuzzy logic system. The stability of the overall system is proven for a second-order nonlinear system with mismatched uncertainties. The simulation results show that the FLC-SLDO demonstrates better control performance than the traditional FLC, FLC with an integral action (FLC-I) and FLC-BNDO.      
### 46.Scalable Extended Object Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2103.11279.pdf)
>  This paper presents a factor graph formulation and particle-based sum-product algorithm (SPA) for scalable detection and tracking of extended objects. The proposed method efficiently performs probabilistic multiple-measurement to object association, represents object extents by random matrices, and introduces the states of newly detected objects dynamically. Scalable detection and tracking of objects is enabled by modeling association uncertainty by measurement-oriented association variables and newly detected objects by a Poisson birth process. Contrary to conventional extended object tracking (EOT) methods with random-matrix models, a fully particle-based approach makes it possible to represent the object extent by different geometric shapes. The proposed method can reliably determine the existence and track a large number of closely-spaced extended objects without gating and clustering of measurements. We demonstrate significant performance advantages of our method compared to the recently proposed Poisson multi-Bernoulli mixture filter in a challenging tracking scenario with ten closely-spaced extended objects.      
### 47.Sliding Mode Control for Systems with Mismatched Time-Varying Uncertainties via a Self-Learning Disturbance Observer  [ :arrow_down: ](https://arxiv.org/pdf/2103.11277.pdf)
>  This paper presents a novel Sliding Mode Control (SMC) algorithm to handle mismatched uncertainties in systems via a novel Self-Learning Disturbance Observer (SLDO). A computationally efficient SLDO is developed within a framework of feedback-error learning scheme in which a conventional estimation law and a Neuro-Fuzzy Structure (NFS) work in parallel. In this framework, the NFS estimates the mismatched disturbances and becomes the leading disturbance estimator while the former feeds the learning error to the NFS to learn system behavior. The simulation results demonstrate that the proposed SMC based on SLDO (SMC-SLDO) ensures the robust control performance in the presence of mismatched time-varying uncertainties when compared to SMC, integral SMC (ISMC) and SMC based on a Basic Nonlinear Disturbance Observer (SMC-BNDO), and also remains the nominal control performance in the absence of mismatched uncertainties. Additionally, the SMC-SLDO not only counteracts mismatched time-varying uncertainties but also improve the transient response performance in the presence of mismatched time-invariant uncertainties. Moreover, the controller gain of the SMC-SLDO is required to be selected larger than the upper bound of the disturbance estimation error rather than the upper bound of the actual disturbance to guarantee the system stability which results in eliminating the chattering effects on the control signal.      
### 48.Sliding Mode Learning Control of Uncertain Nonlinear Systems with Lyapunov Stability Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.11274.pdf)
>  This paper addresses to Sliding Mode Learning Control (SMLC) of uncertain nonlinear systems with Lyapunov stability analysis. In the control scheme, a conventional control term is used to provide the system stability in compact space while a Type-2 Neuro-Fuzzy Controller (T2NFC) learns system behavior so that the T2NFC takes the overall control of the system completely in a very short time period. The stability of the sliding mode learning algorithm was proven in literature; however, it is so restrictive for systems without the overall system stability. To address this shortcoming, a novel control structure with a novel sliding surface is proposed in this paper and the stability of the overall system is proven for nth-order uncertain nonlinear systems. To investigate the capability and effectiveness of the proposed learning and control algorithms, the simulation studies have been achieved under noisy conditions. The simulation results confirm that the developed SMLC algorithm can learn the system behavior in the absence of any mathematical model knowledge and exhibit robust control performance against external disturbances.      
### 49.Networked Supervisor Synthesis Against Lossy Channels with Bounded Network Delays as Non-Networked Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2103.11273.pdf)
>  In this work, we study the problem of supervisory control of networked discrete event systems. We consider lossy communication channels with bounded network delays, for both the control channel and the observation channel. By a model transformation, we transform the networked supervisor synthesis problem into the classical (non-networked) supervisor synthesis problem (for non-deterministic plants), such that the existing supervisor synthesis tools can be used for synthesizing networked supervisors. In particular, we can use the (state-based) normality property for the synthesis of the supremal networked supervisors, whose existence is guaranteed by construction due to our consideration of command non-deterministic supervisors. The effectiveness of our approach is illustrated on a mini-guideway example that is adapted from the literature, for which the supremal networked supervisor has been synthesized in the synthesis tools SuSyNA and TCT.      
### 50.High Data Rate Near-Ultrasonic Communication with Consumer Devices  [ :arrow_down: ](https://arxiv.org/pdf/2103.11261.pdf)
>  Automating device pairing and credential exchange in consumer devices reduce the time users spend with mundane tasks and improve the user experience. Acoustic communication is gaining traction as a practical alternative to Bluetooth or Wi-Fi because it can enable quick and localized information transfer between consumer devices with built-in hardware. However, achieving high data rates (&gt;1 kbps) in such systems has been a challenge because the systems and methods chosen for communication were not tailored to the application. In this work, a high data rate, near-ultrasonic communication (NUSC) system is proposed to transfer personal identification numbers (PINs) to establish a connection between consumer laptops using built-in microphones and speakers. The similarities between indoor near-ultrasonic and underwater acoustic communication (UWAC) channels are identified, and appropriate UWAC techniques are tailored to the NUSC system. The proposed system uses the near-ultrasonic band at 18-20 kHz, and employs coherent modulation and phase-coherent adaptive equalization. The capability of the proposed system is explored in simulated and field experiments that span different device orientations and distances. The experiments demonstrate data rates of 4 kbps over distances of up to 5 meters, which is an order of magnitude higher than the data rates reported with similar systems in the literature.      
### 51.Control and Simulation of a Grid-Forming Inverter for Hybrid PV-Battery Plants in Power System Black Start  [ :arrow_down: ](https://arxiv.org/pdf/2103.11239.pdf)
>  Power system restoration is an important part of system planning. Power utilities are required to maintain black start capable generators that can energize the transmission system and provide cranking power to non-blackstart capable generators. Traditionally, hydro and diesel units are used as black start capable generators. With the increased penetration of bulk size solar farms, inverter based generation can play an important role in faster and parallel black start thus ensuring system can be brought back into service without the conventional delays that can be expected with limited black start generators. Inverter-based photovoltaic (PV) power plants have advantages that are suitable for black start. This paper proposes the modeling, control, and simulation of a grid-forming inverter-based PV-battery power plant that can be used as a black start unit. The inverter control includes both primary and secondary control loops to imitate the control of a conventional synchronous machine. The proposed approach is verified using a test system modified from the IEEE 9-bus system in the time-domain electromagnetic transient simulation tool PSCAD. The simulation results shows voltage and frequency stability during a multi-step black-start and network energization process.      
### 52.Observation-Assisted Heuristic Synthesis of Covert Attackers Against Unknown Supervisors  [ :arrow_down: ](https://arxiv.org/pdf/2103.11197.pdf)
>  In this work, we address the problem of synthesis of covert attackers in the setup where the model of the plant is available, but the model of the supervisor is unknown, to the adversary. To compensate the lack of knowledge on the supervisor, we assume that the adversary has recorded a (prefix-closed) finite set of observations of the runs of the closed-loop system, which can be used for assisting the synthesis. We present a heuristic algorithm for the synthesis of covert damage-reachable attackers, based on the model of the plant and the (finite) set of observations, by a transformation into solving an instance of the partial-observation supervisor synthesis problem. The heuristic algorithm developed in this paper may allow the adversary to synthesize covert attackers without having to know the model of the supervisor, which could be hard to obtain in practice. For simplicity, we shall only consider covert attackers that are able to carry out sensor replacement attacks and actuator disablement attacks. The effectiveness of our approach is illustrated on a water tank example adapted from the literature.      
### 53.Probabilistic Performance Bounds for Randomized Sensor Selection in Kalman Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2103.11182.pdf)
>  We consider the problem of randomly choosing the sensors of a linear time-invariant dynamical system subject to process and measurement noise. We sample the sensors independently and from the same distribution. We measure the performance of a Kalman filter by its estimation error covariance. Using tools from random matrix theory, we derive probabilistic bounds on the estimation error covariance in the semi-definite sense. We indirectly improve the performance of our Kalman filter for the maximum eigenvalue metric and show that under certain conditions the optimal sampling distribution that minimizes the maximum eigenvalue of the upper bound is the solution to an appropriately defined convex optimization problem. Our numerical results show the efficacy of the optimal sampling scheme in improving Kalman filter performance relative to the trivial uniform sampling distribution and a greedy sampling $\textit{with replacement}$ algorithm.      
### 54.Comprehensive Analysis of Continuously Variable Series Reactor Using G-C Framework  [ :arrow_down: ](https://arxiv.org/pdf/2103.11136.pdf)
>  Continuously Variable Series Reactor (CVSR) has the ability to regulate the reactance of an ac circuit using the magnetizing characteristics of its ferromagnetic core, shared by an ac and a dc winding to control power flow, damp oscillations and limit fault currents. In order to understand and utilize a CVSR in the power grid, it is essential to know all of its operational characteristics. The gyrator-capacitor approach has been applied to model electromagnetic coupling between the two circuits, controlled ac circuit and control dc circuit of the device. In this paper, we investigate some of the CVSR side behavior in terms of the induced voltage across the dc winding, flux density within the core's branches, and the power exchange between the two circuits during normal operation and fault conditions.      
### 55.Water Need Models and Irrigation Decision Systems: A Survey on Machine Learning and Control Theory  [ :arrow_down: ](https://arxiv.org/pdf/2103.11133.pdf)
>  Irrigation decision systems and water need models have been important research topics in agriculture since 90s. They improve the efficiency of crop yields, provide an appropriate use of water on the earth and so, prevent the water scarcity in some regions. In this paper, a comprehensive survey on water need models depending on crop growth and irrigation decision systems has been conducted based on machine learning and advanced control theory. The following outcomes and solutions are the main contributions. First, crop growth models and correspondingly water need models are suffer from un-modeled dynamics of the environment and lack of sensory devices. Second, irrigation decision systems based on the controller design are not fully efficient due to the imprecise crop growth models and time-varying environments. Third, water need models are depending on the inaccurate weather forecasts that also causes inefficient irrigation control. The relevant literature basis to these outcomes are surveyed in detail. Then, available and foreseen solutions are discussed and presented on a time-line. Consequently, literature review with the latest developments on water need models, irrigation decision systems, applied control methods and discussions are expected to be useful for the future strategies.      
### 56.The Level Set Kalman Filter for State Estimation of Continuous-discrete Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11130.pdf)
>  We propose a new extension of Kalman filtering for continuous-discrete systems with nonlinear state-space models that we name as the level set Kalman filter (LSKF). The LSKF assumes the probability distribution can be approximated as a Gaussian, and updates the Gaussian distribution through a time-update step and a measurement-update step. The LSKF improves the time-update step when compared to existing methods, such as the continuous-discrete cubature Kalman filter (CD-CKF) by reformulating the underlying Fokker-Planck equation as an ordinary differential equation for the Gaussian, thereby avoiding expansion in time. Together with a carefully picked measurement-update method, numerical experiments show that the LSKF has a consistent performance improvement over CD-CKF for a range of parameters, while also simplifies the implementation, as no user-defined timestep subdivision between measurements is required, and the spatial derivatives of the drift function are not explicitly needed.      
### 57.An Efficient Autocalibration Method for Triaxial Gyroscope without External Device  [ :arrow_down: ](https://arxiv.org/pdf/2103.11097.pdf)
>  Gyroscopes are widely used in various field. The instability of the low-cost gyroscopes makes them need to be calibrated on every boot. To meet the requirement of frequency calibration, finding an efficient in-field calibration method is essential. This paper proposes a fast calibration method that does not require any external equipment. We use the manual rotation angle as a calibration reference and linearize the calibration model. On the basis of this model, a G-optimal experimental design scheme is proposed, which can get enough calibration information with the least number of experiments. The simulations indicate that the calibration error is relatively low, and the results are unbiased. We empirically validate the effectiveness of the proposed method on two commonly used low-cost gyroscope and achieve real-time calibration on a low-energy microcontroller. We validate the proposed method by comparing the above method with the conventional turntable method. The experiment result shows that the error between these two methods is less than $\pm3 \times 10^{-2}$ and the calibration process takes less than 30 seconds. This method might have a practical implication for low-cost gyroscope calibration.      
### 58.Graph Signal Processing: A Signal RepresentationApproach to Convolution and Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2103.11020.pdf)
>  The paper presents sampling in GSP as 1) linear operations (change of bases) between signal representations and 2) downsampling as linear shift invariant filtering and reconstruction (interpolation) as filtering, both in the spectral domain. To achieve this, it considers a spectral shift $M$ that leads to a spectral graph signal processing theory, $\text{GSP}_{\textrm{sp}}$, dual to GSP but that starts from the spectral domain and $M$. The paper introduces alternative signal representations, convolution of graph signals for these alternative representations, presenting a $\textit{fast}$ GSP convolution that uses the DSP FFT algorithm, and sampling as solutions of algebraic linear systems of equations.      
### 59.Model-free LQR based PID controller for trajectory tracking of 2-DoF helicopter: comparison and experimental results  [ :arrow_down: ](https://arxiv.org/pdf/2103.10988.pdf)
>  This paper studies the performance of a model-free LQR based PID (i-LQR-PID) controller designed for tracking control problem of a 2-DoF laboratory helicopter. The control problem addressed in 2-DoF helicopter system aims to track the desired pitch and yaw axes trajectories despite disturbed operating conditions. In addition to the unpredictable variations, the 2-DoF helicopter dynamic is highly nonlinear with having strong cross-couplings in their models as well as being open loop unstable system. Thus, we propose a model-free LQR based PID control strategy in order to achieve better trajectory tracking control objectives. Robustness tests are performed experimentally to show the effectiveness of the model-free control.      
### 60.Monitoring surface deformation over oilfield using MT-InSAR and production well data  [ :arrow_down: ](https://arxiv.org/pdf/2103.10985.pdf)
>  Surface displacements associated with the average subsidence due to hydrocarbon exploitation in southwest of Iran which has a long history in oil production, can lead to significant damages to surface and subsurface structures, and requires serious consideration. In this study, the Small BAseline Subset (SBAS) approach, which is a multi-temporal Interferometric Synthetic Aperture Radar (InSAR) algorithm was employed to resolve ground deformation in the Marun region, Iran. A total of 22 interferograms were generated using 10 Envisat ASAR images. The mean velocity map obtained in the Line-Of-Sight (LOS) direction of satellite to the ground reveals the maximum subsidence on order of 13.5 mm per year over the field due to both tectonic and non-tectonic features. In order to assess the effect of non-tectonic features such as petroleum extraction on ground surface displacement, the results of InSAR have been compared with the oil production rate, which have shown a good agreement.      
### 61.Self-paced ensemble learning for speech and audio classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.11988.pdf)
>  Combining multiple machine learning models into an ensemble is known to provide superior performance levels compared to the individual components forming the ensemble. This is because models can complement each other in taking better decisions. Instead of just combining the models, we propose a self-paced ensemble learning scheme in which models learn from each other over several iterations. During the self-paced learning process based on pseudo-labeling, in addition to improving the individual models, our ensemble also gains knowledge about the target domain. To demonstrate the generality of our self-paced ensemble learning (SPEL) scheme, we conduct experiments on three audio tasks. Our empirical results indicate that SPEL significantly outperforms the baseline ensemble models. We also show that applying self-paced learning on individual models is less effective, illustrating the idea that models in the ensemble actually learn from each other.      
### 62.Wireless Network Coding with Intelligent Reflecting Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2103.11982.pdf)
>  Conventional wireless techniques are becoming inadequate for beyond fifth-generation (5G) networks due to latency and bandwidth considerations. To improve the error performance and throughput of wireless communication systems, we propose physical layer network coding (PNC) in an intelligent reflecting surface (IRS)-assisted environment. We consider an IRS-aided butterfly network, where we propose an algorithm for obtaining the optimal IRS phases. Also, analytic expressions for the bit error rate (BER) are derived. The numerical results demonstrate that the proposed scheme significantly improves the BER performance. For instance, the BER at the relay in the presence of a 32-element IRS is three orders of magnitudes less than that without an IRS.      
### 63.Deep learning-based noise reduction in low dose SPECT Myocardial Perfusion Imaging: Quantitative assessment and clinical performance  [ :arrow_down: ](https://arxiv.org/pdf/2103.11974.pdf)
>  Clinical SPECT-MPI images of 345 patients acquired from a dedicated cardiac SPECT in list-mode format were retrospectively employed to predict normal-dose images from low-dose data at the half, quarter, and one-eighth-dose levels. A generative adversarial network was implemented to predict non-gated normal-dose images in the projection space at the different reduced dose levels. Established metrics including the peak signal-to-noise ratio (PSNR), root mean squared error (RMSE), and structural similarity index metrics (SSIM) in addition to Pearson correlation coefficient analysis and derived parameters from Cedars-Sinai software were used to quantitatively assess the quality of the predicted normal-dose images. For clinical evaluation, the quality of the predicted normal-dose images was evaluated by a nuclear medicine specialist using a seven-point (-3 to +3) grading scheme. By considering PSNR, SSIM, and RMSE quantitative parameters among the different reduced dose levels, the highest PSNR (42.49) and SSIM (0.99), and the lowest RMSE (1.99) were obtained at the half-dose level in the reconstructed images. Pearson correlation coefficients were measured 0.997, 0.994, and 0.987 for the predicted normal-dose images at the half, quarter, and one-eighth-dose levels, respectively. Regarding the normal-dose images as the reference, the Bland-Altman plots sketched for the Cedars-Sinai selected parameters exhibited remarkably less bias and variance in the predicted normal-dose images compared with the low-dose data at the entire reduced dose levels. Overall, considering the clinical assessment performed by a nuclear medicine specialist, 100%, 80%, and 11% of the predicted normal-dose images were clinically acceptable at the half, quarter, and one-eighth-dose levels, respectively.      
### 64.Rate-Diverse Gaussian Multiple Access: Efficient Encoder and Decoder Designs  [ :arrow_down: ](https://arxiv.org/pdf/2103.11873.pdf)
>  In this work, we develop a pair of rate-diverse encoder and decoder for a two-user Gaussian multiple access channel (GMAC). The proposed scheme enables the users to transmit with the same codeword length but different coding rates under diverse user channel conditions. First, we propose the row-combining (RC) method and row-extending (RE) method to design practical low-density parity-check (LDPC) channel codes for rate-diverse GMAC. Second, we develop an iterative rate-diverse joint user messages decoding (RDJD) algorithm for GMAC, where all user messages are decoded with a single parity-check matrix. In contrast to the conventional network-coded multiple access (NCMA) and compute-forward multiple access (CFMA) schemes that first recover a linear combination of the transmitted codewords and then decode both user messages, this work can decode both the user messages simultaneously. Extrinsic information transfer (EXIT) chart analysis and simulation results indicate that RDJD can achieve gains up to 1.0 dB over NCMA and CFMA in the two-user GMAC. In particular, we show that there exists an optimal rate allocation for the two users to achieve the best decoding performance given the channel conditions and sum rate.      
### 65.Recovery of Joint Probability Distribution from one-way marginals: Low rank Tensors and Random Projections  [ :arrow_down: ](https://arxiv.org/pdf/2103.11864.pdf)
>  Joint probability mass function (PMF) estimation is a fundamental machine learning problem. The number of free parameters scales exponentially with respect to the number of random variables. Hence, most work on nonparametric PMF estimation is based on some structural assumptions such as clique factorization adopted by probabilistic graphical models, imposition of low rank on the joint probability tensor and reconstruction from 3-way or 2-way marginals, etc. In the present work, we link random projections of data to the problem of PMF estimation using ideas from tomography. We integrate this idea with the idea of low-rank tensor decomposition to show that we can estimate the joint density from just one-way marginals in a transformed space. We provide a novel algorithm for recovering factors of the tensor from one-way marginals, test it across a variety of synthetic and real-world datasets, and also perform MAP inference on the estimated model for classification.      
### 66.Data-driven output synchronization of heterogeneous leader-follower multi-agent systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11851.pdf)
>  This paper deals with data-driven output synchronization for heterogeneous leader-follower linear multi-agent systems. Given a multi-agent system that consists of one autonomous leader and a number of heterogeneous followers with external disturbances, we provide necessary and sufficient data-based conditions for output synchronization. We also provide a design method for obtaining such output synchronizing protocols directly from data. The results are then extended to the special case that the followers are disturbance-free. Finally, a simulation example is provided to illustrate our results.      
### 67.Graphic relation between amplitude and sound intensity level  [ :arrow_down: ](https://arxiv.org/pdf/2103.11822.pdf)
>  We present a simple experiment that allows us to demonstrate graphically that the intensity of sound waves is proportional to the square of their amplitude, a result that is theoretically analysed in any introductory wave course but rarely demonstrated empirically. To achieve our goal, we use an audio signal generator that, when connected to a loudspeaker, produces sine waves that can be easily observed and measured using an oscilloscope. The measurements made with these instruments allow us to create a plot of amplitude versus sound intensity level, which verifies the mathematical relationship between amplitude and intensity mentioned above. Among the experimental errors, the plot obtained is in excellent agreement with what is theoretically expected.      
### 68.Time-Domain Hybrid PAM for Data-Rate and Distance Adaptive UWOC System  [ :arrow_down: ](https://arxiv.org/pdf/2103.11789.pdf)
>  The challenge for next-generation underwater optical wireless communication systems is to develop optical transceivers that can operate with low power consumption by maximizing the transmission capacity according to the transmission distance between transmitters and receivers. This study proposes an underwater wireless optical communication (UWOC) system using an optical transceiver with an optimum transmission rate for the deep sea with near-pure water properties. As a method for actualizing an optical transceiver with an optimum transmission rate in a UWOC system, time-domain hybrid pulse amplitude modulation (PAM) (TDHP) using a transmission rate and distance-adaptive intensity modulation/direct detection optical transceiver is considered. In the TDHP method, variable transmission capacity is actualized while changing the generation ratio of two intensity-modulated signals with different noise immunities in the time domain. Three different color laser diodes (LDs), red, blue, and green are used in an underwater channel transmission transceiver that comprises the LD and a photodiode. The maximum transmission distance while changing the incidence of PAM 2 and PAM 4 signals that calibrate the TDHP in a pure transmission line and how the maximum transmission distance changes when the optical transmitter/receiver spatial optical system is altered from the optimum conditions are clarified based on numerical calculation and simulation. To the best knowledge of the authors, there is no other research on data-rate and distance adaptive UWOC system that applies the TDHP signal with power optimization between two modulation formats.      
### 69.Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2103.11784.pdf)
>  We present an extremely simple Ultra-Resolution Style Transfer framework, termed URST, to flexibly process arbitrary high-resolution images (e.g., 10000x10000 pixels) style transfer for the first time. Most of the existing state-of-the-art methods would fall short due to massive memory cost and small stroke size when processing ultra-high resolution images. URST completely avoids the memory problem caused by ultra-high resolution images by 1) dividing the image into small patches and 2) performing patch-wise style transfer with a novel Thumbnail Instance Normalization (TIN). Specifically, TIN can extract thumbnail's normalization statistics and apply them to small patches, ensuring the style consistency among different patches. Overall, the URST framework has three merits compared to prior arts. 1) We divide input image into small patches and adopt TIN, successfully transferring image style with arbitrary high-resolution. 2) Experiments show that our URST surpasses existing SOTA methods on ultra-high resolution images benefiting from the effectiveness of the proposed stroke perceptual loss in enlarging the stroke size. 3) Our URST can be easily plugged into most existing style transfer methods and directly improve their performance even without training. Code is available at <a class="link-external link-https" href="https://github.com/czczup/URST" rel="external noopener nofollow">this https URL</a>.      
### 70.A Total-Variation Sparseness-Promoting Method for the Synthesis of Contiguously Clustered Linear Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2103.11778.pdf)
>  By exploiting an innovative total-variation compressive sensing (TV-CS) formulation, a new method for the synthesis of physically contiguous clustered linear arrays is presented. The computation of the feed network excitations is recast as the maximization of the gradient sparsity of the excitation vector subject to matching a user-defined pattern. The arising TV-CS functional is then optimized by means of a deterministic alternating direction algorithm. A selected set of representative numerical results, drawn from a wide validation, is reported to illustrate the potentialities and the limitations of the proposed approach when clustering arrays of both ideal and realistic antenna elements. Comparisons with some competitive state-of-the-art subarraying techniques are performed as well.      
### 71.Efficient numerical room acoustic simulations with parametrized boundaries using the spectral element and reduced basis method  [ :arrow_down: ](https://arxiv.org/pdf/2103.11730.pdf)
>  Numerical methods can be used to simulate wave propagation in rooms, with applications in virtual reality and building design. Such methods can be highly accurate but computationally expensive when simulating high frequencies and large domains for long simulation times. Moreover, it is common that solutions are sought for multiple input parameter values, e.g., in design processes in room acoustics, where different boundary absorption properties are evaluated iteratively. We present a framework that combines a spectral element method (SEM) and a reduced basis method (RBM) to achieve a computational cost reduction for parameterized room acoustic simulations. The SEM provides low dispersion and dissipation properties due to the high-order discretization and the RBM reduces the computational burden further when parametrizing the boundary properties for both frequency-independent and dependent conditions. The problem is solved in the Laplace domain, which avoids instability issues on the reduced model. We demonstrate that the use of high-order discretization and model order reduction has significant advantages for room acoustics in terms of computational efficiency and accuracy.      
### 72.Comprehensive process-molten pool relations modeling using CNN for wire-feed laser additive manufacturing  [ :arrow_down: ](https://arxiv.org/pdf/2103.11588.pdf)
>  Wire-feed laser additive manufacturing (WLAM) is gaining wide interest due to its high level of automation, high deposition rates, and good quality of printed parts. In-process monitoring and feedback controls that would reduce the uncertainty in the quality of the material are in the early stages of development. Machine learning promises the ability to accelerate the adoption of new processes and property design in additive manufacturing by making process-structure-property connections between process setting inputs and material quality outcomes. The molten pool dimensional information and temperature are the indicators for achieving the high quality of the build, which can be directly controlled by processing parameters. For the purpose of in situ quality control, the process parameters should be controlled in real-time based on sensed information from the process, in particular the molten pool. Thus, the molten pool-process relations are of preliminary importance. This paper analyzes experimentally collected in situ sensing data from the molten pool under a set of controlled process parameters in a WLAM system. The variations in the steady-state and transient state of the molten pool are presented with respect to the change of independent process parameters. A multi-modality convolutional neural network (CNN) architecture is proposed for predicting the control parameter directly from the measurable molten pool sensor data for achieving desired geometric and microstructural properties. Dropout and regularization are applied to the CNN architecture to avoid the problem of overfitting. The results highlighted that the multi-modal CNN, which receives temperature profile as an external feature to the features extracted from the image data, has improved prediction performance compared to the image-based uni-modality CNN approach.      
### 73.Brain Image Synthesis with Unsupervised Multivariate Canonical CSC$\ell_4$Net  [ :arrow_down: ](https://arxiv.org/pdf/2103.11587.pdf)
>  Recent advances in neuroscience have highlighted the effectiveness of multi-modal medical data for investigating certain pathologies and understanding human cognition. However, obtaining full sets of different modalities is limited by various factors, such as long acquisition times, high examination costs and artifact suppression. In addition, the complexity, high dimensionality and heterogeneity of neuroimaging data remains another key challenge in leveraging existing randomized scans effectively, as data of the same modality is often measured differently by different machines. There is a clear need to go beyond the traditional imaging-dependent process and synthesize anatomically specific target-modality data from a source input. In this paper, we propose to learn dedicated features that cross both intre- and intra-modal variations using a novel CSC$\ell_4$Net. Through an initial unification of intra-modal data in the feature maps and multivariate canonical adaptation, CSC$\ell_4$Net facilitates feature-level mutual transformation. The positive definite Riemannian manifold-penalized data fidelity term further enables CSC$\ell_4$Net to reconstruct missing measurements according to transformed features. Finally, the maximization $\ell_4$-norm boils down to a computationally efficient optimization problem. Extensive experiments validate the ability and robustness of our CSC$\ell_4$Net compared to the state-of-the-art methods on multiple datasets.      
### 74.ISTA-Net++: Flexible Deep Unfolding Network for Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2103.11554.pdf)
>  While deep neural networks have achieved impressive success in image compressive sensing (CS), most of them lack flexibility when dealing with multi-ratio tasks and multi-scene images in practical applications. To tackle these challenges, we propose a novel end-to-end flexible ISTA-unfolding deep network, dubbed ISTA-Net++, with superior performance and strong flexibility. Specifically, by developing a dynamic unfolding strategy, our model enjoys the adaptability of handling CS problems with different ratios, i.e., multi-ratio tasks, through a single model. A cross-block strategy is further utilized to reduce blocking artifacts and enhance the CS recovery quality. Furthermore, we adopt a balanced dataset for training, which brings more robustness when reconstructing images of multiple scenes. Extensive experiments on four datasets show that ISTA-Net++ achieves state-of-the-art results in terms of both quantitative metrics and visual quality. Considering its flexibility, effectiveness and practicability, our model is expected to serve as a suitable baseline in future CS research. The source code is available on <a class="link-external link-https" href="https://github.com/jianzhangcs/ISTA-Netpp" rel="external noopener nofollow">this https URL</a>.      
### 75.QoS-Constrained Federated Learning Empowered by Intelligent Reflecting Surface  [ :arrow_down: ](https://arxiv.org/pdf/2103.11551.pdf)
>  This paper investigates the model aggregation process in an over-the-air federated learning (AirFL) system, where an intelligent reflecting surface (IRS) is deployed to assist the transmission from users to the base station (BS). With the purpose of overcoming the absence of the security examination against malicious individuals, successive interference cancellation (SIC) is adopted as a basis to support analyzing statistic characteristics of model parameters from devices. The objective of this paper is to minimize the mean-square-error by jointly optimizing the receive beamforming vector at the BS, transmit power allocation at users, and phase shift matrix of the IRS, subject to the transmit power constraint for devices, unit-modulus constraint for reflecting elements, SIC decoding order constraint and quality-of-service constraint. To address this complicated problem, alternating optimization is employed to decompose it into three subproblems, where the optimal receive beamforming vector is obtained by solving the first subproblem with the Lagrange dual method. Then, the convex relaxation method is applied to the transmit power allocation subproblem to find a suboptimal solution. Eventually, the phase shift matrix subproblem is addressed by invoking the semidefinite relaxation. Simulation results validate the availability of IRS and the effectiveness of the proposed scheme in improving federated learning performance.      
### 76.Scatter Correction in X-ray CT by Physics-Inspired Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.11509.pdf)
>  A fundamental problem in X-ray Computed Tomography (CT) is the scatter due to interaction of photons with the imaged object. Unless corrected, scatter manifests itself as degradations in the reconstructions in the form of various artifacts. Scatter correction is therefore critical for reconstruction quality. Scatter correction methods can be divided into two categories: hardware-based; and software-based. Despite success in specific settings, hardware-based methods require modification in the hardware, or increase in the scan time or dose. This makes software-based methods attractive. In this context, Monte-Carlo based scatter estimation, analytical-numerical, and kernel-based methods were developed. Furthermore, data-driven approaches to tackle this problem were recently demonstrated. In this work, two novel physics-inspired deep-learning-based methods, PhILSCAT and OV-PhILSCAT, are proposed. The methods estimate and correct for the scatter in the acquired projection measurements. They incorporate both an initial reconstruction of the object of interest and the scatter-corrupted measurements related to it. They use a common deep neural network architecture and cost function, both tailored to the problem. Numerical experiments with data obtained by Monte-Carlo simulations of the imaging of phantoms reveal significant improvement over a recent purely projection-domain deep neural network scatter correction method.      
### 77.UAV Images Dataset for Moving Object Detection from Moving Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2103.11460.pdf)
>  This paper presents a new high resolution aerial images dataset in which moving objects are labelled manually. It aims to contribute to the evaluation of the moving object detection methods for moving cameras. The problem of recognizing moving objects from aerial images is one of the important issues in computer vision. The biggest problem in the images taken by UAV is that the background is constantly variable due to camera movement. There are various datasets in the literature in which proposed methods for motion detection are evaluated. Prepared dataset consists of challenging images containing small targets compared to other datasets. Two methods in the literature have been tested for the prepared dataset. In addition, a simpler method compared to these methods has been proposed for moving object object in this paper.      
### 78.On the Role of Asymptomatic Carriers in Epidemic Spread Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.11411.pdf)
>  We present an epidemiological compartment model, SAIR(S), that explicitly captures the dynamics of asymptomatic infected individuals in an epidemic spread process. We first present a group model and then discuss networked versions. We provide an investigation of equilibria and stability properties for these models, and present simulation results illustrating the effects of asymptomatic-infected individuals on the spread of the disease. We also discuss local isolation effects on the epidemic dynamics in terms of the networked models. Finally, we provide initial parameter estimation results based on simple least-squares approaches and local test-site data.\par Keywords: Epidemic dynamics, networks, data-informed modeling, stability analysis, parameter estimation      
### 79.Estimating Lower Body Kinematics using a Lie Group Constrained Extended Kalman Filter and Reduced IMU Count  [ :arrow_down: ](https://arxiv.org/pdf/2103.11393.pdf)
>  Goal: This paper presents an algorithm for estimating pelvis, thigh, shank, and foot kinematics during walking using only two or three wearable inertial sensors. Methods: The algorithm makes novel use of a Lie-group-based extended Kalman filter. The algorithm iterates through the prediction (kinematic equation), measurement (pelvis position pseudo-measurements, zero-velocity update, and flat-floor assumption), and constraint update (hinged knee and ankle joints, constant leg lengths). Results: The inertial motion capture algorithm was extensively evaluated on two datasets showing its performance against two standard benchmark approaches in optical motion capture (i.e., plug-in gait (commonly used in gait analysis) and a kinematic fit (commonly used in animation, robotics, and musculoskeleton simulation)), giving insight into the similarity and differences between the said approaches used in different application areas. The overall mean body segment position (relative to mid-pelvis origin) and orientation error magnitude of our algorithm ($n=14$ participants) for free walking was $5.93 \pm 1.33$ cm and $13.43 \pm 1.89^\circ$ when using three IMUs placed on the feet and pelvis, and $6.35 \pm 1.20$ cm and $12.71 \pm 1.60^\circ$ when using only two IMUs placed on the feet. Conclusion: The algorithm was able to track the joint angles in the sagittal plane for straight walking well, but requires improvement for unscripted movements (e.g., turning around, side steps), especially for dynamic movements or when considering clinical applications. Significance: This work has brought us closer to comprehensive remote gait monitoring using IMUs on the shoes. The low computational cost also suggests that it can be used in real-time with gait assistive devices.      
### 80.Optimization Algorithms as Robust Feedback Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2103.11329.pdf)
>  Mathematical optimization is one of the cornerstones of modern engineering research and practice. Yet, throughout application domains, mathematical optimization is, for the most part, considered to be a numerical discipline. Optimization problems are formulated to be solved numerically with specific algorithms running on microprocessors. An emerging alternative is to view optimization algorithms as dynamical systems. While this new perspective is insightful in itself, liberating optimization methods from specific numerical and algorithmic aspects opens up new possibilities to endow complex real-world systems with sophisticated self-optimizing behavior. Towards this goal, it is necessary to understand how numerical optimization algorithms can be converted into feedback controllers to enable robust "closed-loop optimization". In this article, we review several research streams that have been pursued in this direction, including extremum seeking and pertinent methods from model predictive and process control. However, our focus lies on recent methods under the name of "feedback-based optimization". This research stream studies control designs that directly implement optimization algorithms in closed loop with physical systems. Such ideas are finding widespread application in the design and retrofit of control protocols for communication networks and electricity grids. In addition to an overview over continuous-time dynamical systems for optimization, our particular emphasis lies on closed-loop stability as well as the enforcement of physical and operational constraints in closed-loop implementations. We further illustrate these methods in the context of classical problems, namely congestion control in communication networks and optimal frequency control in electricity grids, and we highlight one potential future application in the form of autonomous reserve dispatch in power systems.      
### 81.Tracking error learning control for precise mobile robot path tracking in outdoor environment  [ :arrow_down: ](https://arxiv.org/pdf/2103.11282.pdf)
>  This paper presents a Tracking-Error Learning Control (TELC) algorithm for precise mobile robot path tracking in off-road terrain. In traditional tracking error-based control approaches, feedback and feedforward controllers are designed based on the nominal model which cannot capture the uncertainties, disturbances and changing working conditions so that they cannot ensure precise path tracking performance in the outdoor environment. In TELC algorithm, the feedforward control actions are updated by using the tracking error dynamics and the plant-model mismatch problem is thus discarded. Therefore, the feedforward controller gradually eliminates the feedback controller from the control of the system once the mobile robot has been on-track. In addition to the proof of the stability, it is proven that the cost functions do not have local minima so that the coefficients in TELC algorithm guarantee that the global minimum is reached. The experimental results show that the TELC algorithm results in better path tracking performance than the traditional tracking error-based control method. The mobile robot controlled by TELC algorithm can track a target path precisely with less than $10$ cm error in off-road terrain.      
### 82.High precision control and deep learning-based corn stand counting algorithms for agricultural robot  [ :arrow_down: ](https://arxiv.org/pdf/2103.11276.pdf)
>  This paper presents high precision control and deep learning-based corn stand counting algorithms for a low-cost, ultra-compact 3D printed and autonomous field robot for agricultural operations. Currently, plant traits, such as emergence rate, biomass, vigor, and stand counting, are measured manually. This is highly labor-intensive and prone to errors. The robot, termed TerraSentia, is designed to automate the measurement of plant traits for efficient phenotyping as an alternative to manual measurements. In this paper, we formulate a Nonlinear Moving Horizon Estimator (NMHE) that identifies key terrain parameters using onboard robot sensors and a learning-based Nonlinear Model Predictive Control (NMPC) that ensures high precision path tracking in the presence of unknown wheel-terrain interaction. Moreover, we develop a machine vision algorithm designed to enable an ultra-compact ground robot to count corn stands by driving through the fields autonomously. The algorithm leverages a deep network to detect corn plants in images, and a visual tracking model to re-identify detected objects at different time steps. We collected data from 53 corn plots in various fields for corn plants around 14 days after emergence (stage V3 - V4). The robot predictions have agreed well with the ground truth with $C_{robot}=1.02 \times C_{human}-0.86$ and a correlation coefficient $R=0.96$. The mean relative error given by the algorithm is $-3.78\%$, and the standard deviation is $6.76\%$. These results indicate a first and significant step towards autonomous robot-based real-time phenotyping using low-cost, ultra-compact ground robots for corn and potentially other crops.      
### 83.Spatio-Temporal Data Mining for Aviation Delay Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2103.11221.pdf)
>  To accommodate the unprecedented increase of commercial airlines over the next ten years, the Next Generation Air Transportation System (NextGen) has been implemented in the USA that records large-scale Air Traffic Management (ATM) data to make air travel safer, more efficient, and more economical. A key role of collaborative decision making for air traffic scheduling and airspace resource management is the accurate prediction of flight delay. There has been a lot of attempts to apply data-driven methods such as machine learning to forecast flight delay situation using air traffic data of departures and arrivals. However, most of them omit en-route spatial information of airlines and temporal correlation between serial flights which results in inaccuracy prediction. In this paper, we present a novel aviation delay prediction system based on stacked Long Short-Term Memory (LSTM) networks for commercial flights. The system learns from historical trajectories from automatic dependent surveillance-broadcast (ADS-B) messages and uses the correlative geolocations to collect indispensable features such as climatic elements, air traffic, airspace, and human factors data along posterior routes. These features are integrated and then are fed into our proposed regression model. The latent spatio-temporal patterns of data are abstracted and learned in the LSTM architecture. Compared with previous schemes, our approach is demonstrated to be more robust and accurate for large hub airports.      
### 84.Joint Resource Allocation and Cache Placement for Location-Aware Multi-User Mobile Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2103.11220.pdf)
>  With the growing demand for latency-critical and computation-intensive Internet of Things (IoT) services, mobile edge computing (MEC) has emerged as a promising technique to reinforce the computation capability of the resource-constrained mobile devices. To exploit the cloud-like functions at the network edge, service caching has been implemented to (partially) reuse the computation tasks, thus effectively reducing the delay incurred by data retransmissions and/or the computation burden due to repeated execution of the same task. In a multiuser cache-assisted MEC system, designs for service caching depend on users' preference for different types of services, which is at times highly correlated to the locations where the requests are made. In this paper, we exploit users' location-dependent service preference profiles to formulate a cache placement optimization problem in a multiuser MEC system. Specifically, we consider multiple representative locations, where users at the same location share the same preference profile for a given set of services. In a frequency-division multiple access (FDMA) setup, we jointly optimize the binary cache placement, edge computation resources and bandwidth allocation to minimize the expected weighted-sum energy of the edge server and the users with respect to the users' preference profile, subject to the bandwidth and the computation limitations, and the latency constraints. To effectively solve the mixed-integer non-convex problem, we propose a deep learning based offline cache placement scheme using a novel stochastic quantization based discrete-action generation method. In special cases, we also attain suboptimal caching decisions with low complexity leveraging the structure of the optimal solution. The simulations verify the performance of the proposed scheme and the effectiveness of service caching in general.      
### 85.Joint Analog Beam Selection and Digital Beamforming in Millimeter Wave Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.11199.pdf)
>  Cell-free massive MIMO systems consist of many distributed access points with simple components that jointly serve the users. In millimeter wave bands, only a limited set of predetermined beams can be supported. In a network that consolidates these technologies, downlink analog beam selection stands as a challenging task for the network sum-rate maximization. Low-cost digital filters can improve the network sum-rate further. In this work, we propose low-cost joint designs of analog beam selection and digital filters. The proposed joint designs achieve significantly higher sum-rates than the disjoint design benchmark. Supervised machine learning (ML) algorithms can efficiently approximate the input-output mapping functions of the beam selection decisions of the joint designs with low computational complexities. Since the training of ML algorithms is performed off-line, we propose a well-constructed joint design that combines multiple initializations, iterations, and selection features, as well as beam conflict control, i.e., the same beam cannot be used for multiple users. The numerical results indicate that ML algorithms can retain 99-100% of the original sum-rate results achieved by the proposed well-constructed designs.      
### 86.Radar Information Theory for Joint Communication and Parameter Estimation with Passive Targets  [ :arrow_down: ](https://arxiv.org/pdf/2103.11184.pdf)
>  In this paper, we derive the performance bounds for joint communication data rate and estimation error of radar target parameters from first principles, where the targets are assumed to be passive. Specifically, we let the targets to have control over their passive reflectors in order to transmit their own information back to the radar via reflection-based beamforming or backscattering. Such a setup avoids active radio frequency transmission from battery operated devices such as friendly (or reconnaissance) drones. The concept of target ambiguity function arises naturally from these derivations, which not only poses challenge to waveform designers, but also provides an opportunity for a joint design of waveform and array geometries to achieve an optimal performance. We derive the Cramr-Rao lower bounds for the mean squared error in the estimation of target parameters, and derive lower bounds on the data rates with both radar-only and joint radar and communications scenarios. The challenge of transmit waveform design for joint radar-data communication is illustrated via numerical examples.      
### 87.RIS Configuration, Beamformer Design, and Power Control in Single-Cell and Multi-Cell Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.11165.pdf)
>  Reconfigurable Intelligent Surfaces (RISs) are recently attracting a wide interest due to their capability of tuning wireless propagation environments in order to increase the system performance of wireless networks. In this paper, a multiuser wireless network assisted by a RIS is studied and resource allocation algorithms are presented for several scenarios. First of all, the problem of channel estimation is considered, and an algorithm that permits separate estimation of the mobile user-to-RIS and RIS-to-base stations components is proposed. Then, for the special case of a single-user system, three possible approaches are shown in order to optimize the Signal-to-Noise Ratio with respect to the beamformer used at the base station and to the RIS phase shifts. Next, for a multiuser system with two cells, assuming channel-matched beamforming, the geometric mean of the downlink Signal-to-Interference plus Noise Ratios across users is maximized with respect to the base stations transmit powers and RIS phase shifts configurations. In this scenario, the RIS is placed at the cell-edge and some users are jointly served by two base stations to increase the system performance. Numerical results show that the proposed procedures are effective and that the RIS brings substantial performance improvements to wireless system.      
### 88.Predictive Maintenance -- Bridging Artificial Intelligence and IoT  [ :arrow_down: ](https://arxiv.org/pdf/2103.11148.pdf)
>  This paper highlights the trends in the field of predictive maintenance with the use of machine learning. With the continuous development of the Fourth Industrial Revolution, through IoT, the technologies that use artificial intelligence are evolving. As a result, industries have been using these technologies to optimize their production. Through scientific research conducted for this paper, conclusions were drawn about the trends in Predictive Maintenance applications with the use of machine learning bridging Artificial Intelligence and IoT. These trends are related to the types of industries in which Predictive Maintenance was applied, the models of artificial intelligence were implemented, mainly of machine learning and the types of sensors that are applied through the IoT to the applications. Six sectors were presented and the production sector was dominant as it accounted for 54.54% of total publications. In terms of artificial intelligence models, the most prevalent among ten were the Artificial Neural Networks, Support Vector Machine and Random Forest with 27.84%, 17.72% and 13.92% respectively. Finally, twelve categories of sensors emerged, of which the most widely used were the sensors of temperature and vibration with percentages of 60.71% and 46.42% correspondingly.      
### 89.Force Sensing in Robot-assisted Keyhole Endoscopy: A Systematic Survey  [ :arrow_down: ](https://arxiv.org/pdf/2103.11123.pdf)
>  Instrument-tissue interaction forces in Minimally Invasive Surgery (MIS) provide valuable information that can be used to provide haptic perception, monitor tissue trauma, develop training guidelines, and evaluate the skill level of novice and expert surgeons.Force and tactile sensing is lost in many Robot-Assisted Surgery (RAS) systems. Therefore, many researchers have focused on recovering this information through sensing systems and estimation algorithms. <br>This article provides a comprehensive systematic review of the current force sensing research aimed at RAS and, more generally, keyhole endoscopy, in which instruments enter the body through small incisions. Articles published between January 2011 and May 2020 are considered, following the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines. The literature search resulted in 110 papers on different force estimation algorithms and sensing technologies, sensor design specifications, and fabrication techniques.      
### 90.Model-based Learning Network for 3-D Localization in mmWave Communications  [ :arrow_down: ](https://arxiv.org/pdf/2103.11122.pdf)
>  This study considers the joint location and velocity estimation of UE and scatterers in a three-dimensional mmWave CRAN architecture. Several existing works have achieved satisfactory results with neural networks (NNs) for localization. However, the black box NN localization method has limited performance and relies on a prohibitive amount of training data. Thus, we propose a model-based learning network for localization by combining NNs with geometric models. Specifically, we first develop an unbiased WLS estimator by utilizing hybrid delay/angular measurements, which determine the location and velocity of the UE in only one estimator, and can obtain the location and velocity of scatterers further. The proposed estimator can achieve the CRLB and outperforms state-of-the-art methods. Second, we establish a NN-assisted localization method (NN-WLS) by replacing the linear approximations in the proposed WLS localization model with NNs to learn higher-order error components, thereby enhancing the performance of the estimator. The solution possesses the powerful learning ability of the NN and the robustness of the proposed geometric model. Moreover, the ensemble learning is applied to improve the localization accuracy further. Comprehensive simulations show that the proposed NN-WLS is superior to the benchmark methods in terms of localization accuracy, robustness, and required time resources.      
### 91.Multi-Axis Force Sensing in Robotic Minimally Invasive Surgery With No Instrument Modification  [ :arrow_down: ](https://arxiv.org/pdf/2103.11116.pdf)
>  This paper presents a novel multi-axis force-sensing approach in robotic minimally invasive surgery with no modification to the surgical instrument. Thus, it is adaptable to different surgical instruments. A novel 6-axis optical force sensor, with local signal conditioning and digital electronics, was mounted onto the proximal shaft of a da Vinci EndoWrist instrument. A new cannula design comprising an inner tube and an outer tube was proposed. The inner tube is attached to the cannula interface to the robot base through a compliant leaf spring with adjustable stiffness. It allows bending of the instrument shaft due to the tip forces. The outer tube mechanically filters out the body forces from affecting the instrument bending behavior. A mathematical model of the sensing principle was developed and used for model-based calibration. A data-driven calibration based on a shallow neural network architecture comprising a single 5-nodes hidden layer and a 5x1 output layer is discussed. Extensive testing was conducted to validate that the sensor can successfully measure the lateral forces and moments and the axial torque applied to the instruments distal end within the desired resolution, accuracy, and range requirements.      
### 92.An Efficient Calibration Method for Triaxial Gyroscope  [ :arrow_down: ](https://arxiv.org/pdf/2103.11096.pdf)
>  This paper presents an efficient servomotor-aided calibration method for the triaxial gyroscope. The entire calibration process only takes about one minute, and high-precision equipment is not used. The main idea of this method is that the measurement of the gyroscope should equal to the rotation speed of the servomotor. A six-observation experimental design is proposed to minimize the maximum variance of the estimated scale factors and biases. Besides, a fast converged recursive linear least square estimation method is presented to reduce computational complexity. The simulation results specify the robustness under normal and extreme condition. We experimentally demonstrate the achievability of the proposed method on a robot arm and implements the method on a microcontroller. The calibration results of the proposed method are verified by comparing with a traditional turntable method, and the experiment indicates that the error between these two methods is less than $10^{-3}$. By comparing the calibrated low-cost gyroscope reading with the reading from a high-precision gyroscope, we can infer that our method significantly increases the accuracy of the low-cost gyroscopes.      
### 93.Encrypted Value Iteration and Temporal Difference Learning over Leveled Homomorphic Encryption  [ :arrow_down: ](https://arxiv.org/pdf/2103.11065.pdf)
>  We consider an architecture of confidential cloud-based control synthesis based on Homomorphic Encryption (HE). Our study is motivated by the recent surge of data-driven control such as deep reinforcement learning, whose heavy computational requirements often necessitate an outsourcing to the third party server. To achieve more flexibility than Partially Homomorphic Encryption (PHE) and less computational overhead than Fully Homomorphic Encryption (FHE), we consider a Reinforcement Learning (RL) architecture over Leveled Homomorphic Encryption (LHE). We first show that the impact of the encryption noise under the Cheon-Kim-Kim-Song (CKKS) encryption scheme on the convergence of the model-based tabular Value Iteration (VI) can be analytically bounded. We also consider secure implementations of TD(0), SARSA(0) and Z-learning algorithms over the CKKS scheme, where we numerically demonstrate that the effects of the encryption noise on these algorithms are also minimal.      
### 94.Online Robust Control of Nonlinear Systems with Large Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2103.11055.pdf)
>  Robust control is a core approach for controlling systems with performance guarantees that are robust to modeling error, and is widely used in real-world systems. However, current robust control approaches can only handle small system uncertainty, and thus require significant effort in system identification prior to controller design. We present an online approach that robustly controls a nonlinear system under large model uncertainty. Our approach is based on decomposing the problem into two sub-problems, "robust control design" (which assumes small model uncertainty) and "chasing consistent models", which can be solved using existing tools from control theory and online learning, respectively. We provide a learning convergence analysis that yields a finite mistake bound on the number of times performance requirements are not met and can provide strong safety guarantees, by bounding the worst-case state deviation. To the best of our knowledge, this is the first approach for online robust control of nonlinear systems with such learning theoretic and safety guarantees. We also show how to instantiate this framework for general robotic systems, demonstrating the practicality of our approach.      
### 95.A first step towards automated species recognition from camera trap images of mammals using AI in a European temperate forest  [ :arrow_down: ](https://arxiv.org/pdf/2103.11052.pdf)
>  Camera traps are used worldwide to monitor wildlife. Despite the increasing availability of Deep Learning (DL) models, the effective usage of this technology to support wildlife monitoring is limited. This is mainly due to the complexity of DL technology and high computing requirements. This paper presents the implementation of the light-weight and state-of-the-art YOLOv5 architecture for automated labeling of camera trap images of mammals in the Bialowieza Forest (BF), Poland. The camera trapping data were organized and harmonized using TRAPPER software, an open source application for managing large-scale wildlife monitoring projects. The proposed image recognition pipeline achieved an average accuracy of 85% F1-score in the identification of the 12 most commonly occurring medium-size and large mammal species in BF using a limited set of training and testing data (a total 2659 images with animals). <br>Based on the preliminary results, we concluded that the YOLOv5 object detection and classification model is a promising light-weight DL solution after the adoption of transfer learning technique. It can be efficiently plugged in via an API into existing web-based camera trapping data processing platforms such as e.g. TRAPPER system. Since TRAPPER is already used to manage and classify (manually) camera trapping datasets by many research groups in Europe, the implementation of AI-based automated species classification may significantly speed up the data processing workflow and thus better support data-driven wildlife monitoring and conservation. Moreover, YOLOv5 developers perform better performance on edge devices which may open a new chapter in animal population monitoring in real time directly from camera trap devices.      
### 96.Mode-wise Tensor Decompositions: Multi-dimensional Generalizations of CUR Decompositions  [ :arrow_down: ](https://arxiv.org/pdf/2103.11037.pdf)
>  Low rank tensor approximation is a fundamental tool in modern machine learning and data science. In this paper, we study the characterization, perturbation analysis, and an efficient sampling strategy for two primary tensor CUR approximations, namely Chidori and Fiber CUR. We characterize exact tensor CUR decompositions for low multilinear rank tensors. We also present theoretical error bound of the tensor CUR approximations when (adversarial or Gaussian) noise appears. Moreover, we show that low cost uniform sampling is sufficient for tensor CUR approximations if the tensor has an incoherent structure. Empirical performance evaluations, with both synthetic and real-world datasets, establish the advantage of the tensor CUR approximations over other state-of-the-art low multilinear rank tensor approximations.      
### 97.Multi-Robot Dynamical Source Seeking in Unknown Environments  [ :arrow_down: ](https://arxiv.org/pdf/2103.11016.pdf)
>  This paper presents an algorithmic framework for the distributed on-line source seeking, termed as 'DoSS', with a multi-robot system in an unknown dynamical environment. Our algorithm, building on a novel concept called dummy confidence upper bound (D-UCB), integrates both estimation of the unknown environment and task planning for the multiple robots simultaneously, and as a result, drives the team of robots to a steady state in which multiple sources of interest are located. Unlike the standard UCB algorithm in the context of multi-armed bandits, the introduction of D-UCB significantly reduces the computational complexity in solving subproblems of the multi-robot task planning. This also enables our 'DoSS' algorithm to be implementable in a distributed on-line manner. The performance of the algorithm is theoretically guaranteed by showing a sub-linear upper bound of the cumulative regret. Numerical results on a real-world methane emission seeking problem are also provided to demonstrate the effectiveness of the proposed algorithm.      
### 98.Estrategias para cubrir la demanda insatisfecha en una fbrica alimenticia  [ :arrow_down: ](https://arxiv.org/pdf/2103.10998.pdf)
>  Supply shortage could be a serios problem in production facilities, and an accurate diagnosis of its cause is crucial for its solution. This work presents a case study for determining a solution by means of a nonlinear programming model.      
### 99.Deep embedded clustering of coral reef bioacoustics  [ :arrow_down: ](https://arxiv.org/pdf/2012.09982.pdf)
>  Deep clustering was applied to unlabeled, automatically detected signals in a coral reef soundscape to distinguish fish pulse calls from segments of whale song. Deep embedded clustering (DEC) learned latent features and formed classification clusters using fixed-length power spectrograms of the signals. Handpicked spectral and temporal features were also extracted and clustered with Gaussian mixture models (GMM) and conventional clustering. DEC, GMM, and conventional clustering were tested on simulated datasets of fish pulse calls (fish) and whale song units (whale) with randomized bandwidth, duration, and SNR. Both GMM and DEC achieved high accuracy and identified clusters with fish, whale, and overlapping fish and whale signals. Conventional clustering methods had low accuracy in scenarios with unequal-sized clusters or overlapping signals. Fish and whale signals recorded near Hawaii in February-March 2020 were clustered with DEC, GMM, and conventional clustering. DEC features demonstrated the highest accuracy of 77.5% on a small, manually labeled dataset for classifying signals into fish and whale clusters.      
